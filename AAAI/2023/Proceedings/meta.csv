"index","Title","Authors","Affiliations","keywords","cite_key","abstract","pdf_url"
"25070","Back to the Future: Toward a Hybrid Architecture for Ad Hoc Teamwork","['Hasra Dodampegama', 'Mohan Sridharan']","['University of Birmingham, UK', 'University of Birmingham, UK']","['CMS: Agent & Cognitive Architectures', 'KRR: Applications', 'KRR: Nonmonotonic Reasoning', 'MAS: Agent/AI Theories and Architectures']","Dodampegama, H., & Sridharan, M. (2023). Back to the Future: Toward a Hybrid Architecture for Ad Hoc Teamwork. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 3-10. https://doi.org/10.1609/aaai.v37i1.25070","Abstract 					State of the art methods for ad hoc teamwork, i.e., for collaboration without prior coordination, often use a long history of prior observations to model the behavior of other agents (or agent types) and to determine the ad hoc agent's behavior. In many practical domains, it is difficult to obtain large training datasets, and necessary to quickly revise the existing models to account for changes in team composition or domain attributes. Our architecture builds on the principles of step-wise refinement and ecological rationality to enable an ad hoc agent to perform non-monotonic logical reasoning with prior commonsense domain knowledge and models learned rapidly from limited examples to predict the behavior of other agents. In the simulated multiagent collaboration domain Fort Attack, we experimentally demonstrate that our architecture enables an ad hoc agent to adapt to changes in the behavior of other agents, and provides enhanced transparency and better performance than a state of the art data-driven baseline.","https://ojs.aaai.org/index.php/AAAI/article/view/25070/24842"
"25071","Reducing ANN-SNN Conversion Error through Residual Membrane Potential","['Zecheng Hao', 'Tong Bu', 'Jianhao Ding', 'Tiejun Huang', 'Zhaofei Yu']","['Peking University', 'Peking University', 'Peking University', 'Peking University', 'Peking University']","['CMS: Brain Modeling']","Hao, Z., Bu, T., Ding, J., Huang, T., & Yu, Z. (2023). Reducing ANN-SNN Conversion Error through Residual Membrane Potential. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 11-21. https://doi.org/10.1609/aaai.v37i1.25071","Abstract 					Spiking Neural Networks (SNNs) have received extensive academic attention due to the unique properties of low power consumption and high-speed computing on neuromorphic chips. Among various training methods of SNNs, ANN-SNN conversion has shown the equivalent level of performance as ANNs on large-scale datasets. However, unevenness error, which refers to the deviation caused by different temporal sequences of spike arrival on activation layers, has not been effectively resolved and seriously suffers the performance of SNNs under the condition of short time-steps. In this paper, we make a detailed analysis of unevenness error and divide it into four categories. We point out that the case of the ANN output being zero while the SNN output being larger than zero accounts for the largest percentage. Based on this, we theoretically prove the sufficient and necessary conditions of this case and propose an optimization strategy based on residual membrane potential to reduce unevenness error. The experimental results show that the proposed method achieves state-of-the-art performance on CIFAR-10, CIFAR-100, and ImageNet datasets. For example, we reach top-1 accuracy of 64.32% on ImageNet with 10-steps. To the best of our knowledge, this is the first time ANN-SNN conversion can simultaneously achieve high accuracy and ultra-low-latency on the complex dataset. Code is available at https://github.com/hzc1208/ANN2SNN_SRP.","https://ojs.aaai.org/index.php/AAAI/article/view/25071/24843"
"25072","Hierarchical ConViT with Attention-Based Relational Reasoner for Visual Analogical Reasoning","['Wentao He', 'Jialu Zhang', 'Jianfeng Ren', 'Ruibin Bai', 'Xudong Jiang']","['The Digital Port Technologies Lab, School of Computer Science, University of Nottingham Ningbo China', 'The Digital Port Technologies Lab, School of Computer Science, University of Nottingham Ningbo China', 'The Digital Port Technologies Lab, School of Computer Science, University of Nottingham Ningbo China\nNottingham Ningbo China Beacons of Excellence Research and Innovation Institute, University of Nottingham Ningbo China', 'The Digital Port Technologies Lab, School of Computer Science, University of Nottingham Ningbo China\nNottingham Ningbo China Beacons of Excellence Research and Innovation Institute, University of Nottingham Ningbo China', 'School of Electrical & Electronic Engineering, Nanyang Technological University']","['CMS: Analogical and Conceptual Reasoning', 'CMS: Applications', 'CV: Representation Learning for Vision', 'CV: Scene Analysis & Understanding', 'CV: Visual Reasoning & Symbolic Representations', 'ML: Relational Learning']","He, W., Zhang, J., Ren, J., Bai, R., & Jiang, X. (2023). Hierarchical ConViT with Attention-Based Relational Reasoner for Visual Analogical Reasoning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 22-30. https://doi.org/10.1609/aaai.v37i1.25072","Abstract 					Raven’s Progressive Matrices (RPMs) have been widely used to evaluate the visual reasoning ability of humans. To tackle the challenges of visual perception and logic reasoning on RPMs, we propose a Hierarchical ConViT with Attention-based Relational Reasoner (HCV-ARR). Traditional solution methods often apply relatively shallow convolution networks to visually perceive shape patterns in RPM images, which may not fully model the long-range dependencies of complex pattern combinations in RPMs. The proposed ConViT consists of a convolutional block to capture the low-level attributes of visual patterns, and a transformer block to capture the high-level image semantics such as pattern formations. Furthermore, the proposed hierarchical ConViT captures visual features from multiple receptive fields, where the shallow layers focus on the image fine details while the deeper layers focus on the image semantics. To better model the underlying reasoning rules embedded in RPM images, an Attention-based Relational Reasoner (ARR) is proposed to establish the underlying relations among images. The proposed ARR well exploits the hidden relations among question images through the developed element-wise attentive reasoner. Experimental results on three RPM datasets demonstrate that the proposed HCV-ARR achieves a significant performance gain compared with the state-of-the-art models. The source code is available at: https://github.com/wentaoheunnc/HCV-ARR.","https://ojs.aaai.org/index.php/AAAI/article/view/25072/24844"
"25073","Deep Spiking Neural Networks with High Representation Similarity Model Visual Pathways of Macaque and Mouse","['Liwei Huang', 'Zhengyu Ma', 'Liutao Yu', 'Huihui Zhou', 'Yonghong Tian']","['Peking University\nPeng Cheng Laboratory', 'Peng Cheng Laboratory', 'Peng Cheng Laboratory', 'Peng Cheng Laboratory', 'Peking University\nPeng Cheng Laboratory']","['CMS: Brain Modeling']","Huang, L., Ma, Z., Yu, L., Zhou, H., & Tian, Y. (2023). Deep Spiking Neural Networks with High Representation Similarity Model Visual Pathways of Macaque and Mouse. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 31-39. https://doi.org/10.1609/aaai.v37i1.25073","Abstract 					Deep artificial neural networks (ANNs) play a major role in modeling the visual pathways of primate and rodent. However, they highly simplify the computational properties of neurons compared to their biological counterparts. Instead, Spiking Neural Networks (SNNs) are more biologically plausible models since spiking neurons encode information with time sequences of spikes, just like biological neurons do. However, there is a lack of studies on visual pathways with deep SNNs models. In this study, we model the visual cortex with deep SNNs for the first time, and also with a wide range of state-of-the-art deep CNNs and ViTs for comparison. Using three similarity metrics, we conduct neural representation similarity experiments on three neural datasets collected from two species under three types of stimuli. Based on extensive similarity analyses, we further investigate the functional hierarchy and mechanisms across species. Almost all similarity scores of SNNs are higher than their counterparts of CNNs with an average of 6.6%. Depths of the layers with the highest similarity scores exhibit little differences across mouse cortical regions, but vary significantly across macaque regions, suggesting that the visual processing structure of mice is more regionally homogeneous than that of macaques. Besides, the multi-branch structures observed in some top mouse brain-like neural networks provide computational evidence of parallel processing streams in mice, and the different performance in fitting macaque neural representations under different stimuli exhibits the functional specialization of information processing in macaques. Taken together, our study demonstrates that SNNs could serve as promising candidates to better model and explain the functional hierarchy and mechanisms of the visual system.","https://ojs.aaai.org/index.php/AAAI/article/view/25073/24845"
"25074","A Semi-parametric Model for Decision Making in High-Dimensional Sensory Discrimination Tasks","['Stephen Keeley', 'Benjamin Letham', 'Craig Sanders', 'Chase Tymms', 'Michael Shvartsman']","['Department of Natural Sciences, Fordham University, USA\nMeta', 'Meta', 'Meta', 'Meta', 'Meta']","['CMS: Bayesian Learning', 'CMS: Brain Modeling', 'CMS: Other Foundations of Cognitive Modeling & Systems', 'HAI: Human Computation', 'ML: Bayesian Learning', 'ML: Probabilistic Methods']","Keeley, S., Letham, B., Sanders, C., Tymms, C., & Shvartsman, M. (2023). A Semi-parametric Model for Decision Making in High-Dimensional Sensory Discrimination Tasks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 40-47. https://doi.org/10.1609/aaai.v37i1.25074","Abstract 					Psychometric functions typically characterize binary sensory decisions along a single stimulus dimension. However, real-life sensory tasks vary along a greater variety of dimensions (e.g. color, contrast and luminance for visual stimuli). Approaches to characterizing high-dimensional sensory spaces either require strong parametric assumptions about these additional contextual dimensions, or fail to leverage known properties of classical psychometric curves. We overcome both limitations by introducing a semi-parametric model of sensory discrimination that applies traditional psychophysical models along a stimulus intensity dimension, but puts Gaussian process (GP) priors on the parameters of these models with respect to the remaining dimensions. By combining the flexibility of the GP with the deep literature on parametric psychophysics, our semi-parametric models achieve good performance with much less data than baselines on both synthetic and real-world, high-dimensional psychophysics datasets. We additionally show strong performance in a Bayesian active learning setting, and present a novel active learning paradigm for the semi-parametric model.","https://ojs.aaai.org/index.php/AAAI/article/view/25074/24846"
"25075","A Machine with Short-Term, Episodic, and Semantic Memory Systems","['Taewoon Kim', 'Michael Cochez', 'Vincent Francois-Lavet', 'Mark Neerincx', 'Piek Vossen']","['Vrije Universiteit Amsterdam', 'Vrije Universiteit Amsterdam', 'Vrije Universiteit Amsterdam', 'Technische Universiteit Delft', 'Vrije Universiteit Amsterdam']","['CMS: Memory Storage and Retrieval', 'ML: Lifelong and Continual Learning', 'ML: Bio-Inspired Learning', 'KRR: Common-Sense Reasoning', 'ML: Applications', 'KRR: Applications', 'CMS: Agent & Cognitive Architectures', 'CMS: Brain Modeling', 'CMS: Adaptive Behavior', 'ML: Reinforcement Learning Algorithms']","Kim, T., Cochez, M., Francois-Lavet, V., Neerincx, M., & Vossen, P. (2023). A Machine with Short-Term, Episodic, and Semantic Memory Systems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 48-56. https://doi.org/10.1609/aaai.v37i1.25075","Abstract 					Inspired by the cognitive science theory of the explicit human memory systems, we have modeled an agent with short-term, episodic, and semantic memory systems, each of which is modeled with a knowledge graph. To evaluate this system and analyze the behavior of this agent, we designed and released our own reinforcement learning agent environment, “the Room”, where an agent has to learn how to encode, store, and retrieve memories to maximize its return by answering questions. We show that our deep Q-learning based agent successfully learns whether a short-term memory should be forgotten, or rather be stored in the episodic or semantic memory systems. Our experiments indicate that an agent with human-like memory systems can outperform an agent without this memory structure in the environment.","https://ojs.aaai.org/index.php/AAAI/article/view/25075/24847"
"25076","Persuasion Strategies in Advertisements","['Yaman Kumar', 'Rajat Jha', 'Arunim Gupta', 'Milan Aggarwal', 'Aditya Garg', 'Tushar Malyan', 'Ayush Bhardwaj', 'Rajiv Ratn Shah', 'Balaji Krishnamurthy', 'Changyou Chen']","['Adobe Media and Data Science Research (MDSR)\nIIIT-Delhi\nUniversity at Buffalo', 'IIIT-Delhi', 'IIIT-Delhi', 'Adobe Media and Data Science Research', 'IIIT-Delhi', 'IIIT-Delhi', 'IIIT-Delhi', 'IIIT-Delhi', 'Adobe Media and Data Science Research', 'University at Buffalo']","['CMS: Affective Computing', 'CMS: Applications', 'CMS: Social Cognition and Interaction', 'APP: Business/Marketing/Advertising/E-Commerce', 'APP: Communication']","Kumar, Y., Jha, R., Gupta, A., Aggarwal, M., Garg, A., Malyan, T., Bhardwaj, A., Ratn Shah, R., Krishnamurthy, B., & Chen, C. (2023). Persuasion Strategies in Advertisements. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 57-66. https://doi.org/10.1609/aaai.v37i1.25076","Abstract 					Modeling what makes an advertisement persuasive, i.e., eliciting the desired response from consumer, is critical to the study of propaganda, social psychology, and marketing. Despite its importance, computational modeling of persuasion in computer vision is still in its infancy, primarily due to the lack of benchmark datasets that can provide persuasion-strategy labels associated with ads. Motivated by persuasion literature in social psychology and marketing, we introduce an extensive vocabulary of persuasion strategies and build the first ad image corpus annotated with persuasion strategies. We then formulate the task of persuasion strategy prediction with multi-modal learning, where we design a multi-task attention fusion model that can leverage other ad-understanding tasks to predict persuasion strategies. The dataset also provides image segmentation masks, which labels persuasion strategies in the corresponding ad images on the test split. We publicly release our code and dataset at https://midas-research.github.io/persuasion-advertisements/.","https://ojs.aaai.org/index.php/AAAI/article/view/25076/24848"
"25077","Intensity-Aware Loss for Dynamic Facial Expression Recognition in the Wild","['Hanting Li', 'Hongjing Niu', 'Zhaoqing Zhu', 'Feng Zhao']","['University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China']","['CMS: Affective Computing', 'CV: Object Detection & Categorization', 'CV: Video Understanding & Activity Analysis']","Li, H., Niu, H., Zhu, Z., & Zhao, F. (2023). Intensity-Aware Loss for Dynamic Facial Expression Recognition in the Wild. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 67-75. https://doi.org/10.1609/aaai.v37i1.25077","Abstract 					Compared with the image-based static facial expression recognition (SFER) task, the dynamic facial expression recognition (DFER) task based on video sequences is closer to the natural expression recognition scene. However, DFER is often more challenging. One of the main reasons is that video sequences often contain frames with different expression intensities, especially for the facial expressions in the real-world scenarios, while the images in SFER frequently present uniform and high expression intensities. Nevertheless, if the expressions with different intensities are treated equally, the features learned by the networks will have large intra-class and small inter-class differences, which are harmful to DFER. To tackle this problem, we propose the global convolution-attention block (GCA) to rescale the channels of the feature maps. In addition, we introduce the intensity-aware loss (IAL) in the training process to help the network distinguish the samples with relatively low expression intensities. Experiments on two in-the-wild dynamic facial expression datasets (i.e., DFEW and FERV39k) indicate that our method outperforms the state-of-the-art DFER approaches. The source code will be available at https://github.com/muse1998/IAL-for-Facial-Expression-Recognition.","https://ojs.aaai.org/index.php/AAAI/article/view/25077/24849"
"25078","AVCAffe: A Large Scale Audio-Visual Dataset of Cognitive Load and Affect for Remote Work","['Pritam Sarkar', 'Aaron Posen', 'Ali Etemad']","[""Queen's Univesity, Canada\nVector Institute"", ""Queen's University, Canada"", ""Queen's University, Canada""]","['CMS: Affective Computing', 'HAI: Human-Computer Interaction']","Sarkar, P., Posen, A., & Etemad, A. (2023). AVCAffe: A Large Scale Audio-Visual Dataset of Cognitive Load and Affect for Remote Work. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 76-85. https://doi.org/10.1609/aaai.v37i1.25078","Abstract 					We introduce AVCAffe, the first Audio-Visual dataset consisting of Cognitive load and Affect attributes. We record AVCAffe by simulating remote work scenarios over a video-conferencing platform, where subjects collaborate to complete a number of cognitively engaging tasks. AVCAffe is the largest originally collected (not collected from the Internet) affective dataset in English language. We recruit 106 participants from 18 different countries of origin, spanning an age range of 18 to 57 years old, with a balanced male-female ratio. AVCAffe comprises a total of 108 hours of video, equivalent to more than 58,000 clips along with task-based self-reported ground truth labels for arousal, valence, and cognitive load attributes such as mental demand, temporal demand, effort, and a few others. We believe AVCAffe would be a challenging benchmark for the deep learning research community given the inherent difficulty of classifying affect and cognitive load in particular. Moreover, our dataset fills an existing timely gap by facilitating the creation of learning systems for better self-management of remote work meetings, and further study of hypotheses regarding the impact of remote work on cognitive load and affective states.","https://ojs.aaai.org/index.php/AAAI/article/view/25078/24850"
"25079","ESL-SNNs: An Evolutionary Structure Learning Strategy for Spiking Neural Networks","['Jiangrong Shen', 'Qi Xu', 'Jian K. Liu', 'Yueming Wang', 'Gang Pan', 'Huajin Tang']","['The College of Computer Science and Technology, Zhejiang University, China', 'School of Artificial Intelligence, Dalian University of Technology, China', 'School of Computing, University of Leeds, UK', 'The College of Computer Science and Technology, Zhejiang University, China', 'The College of Computer Science and Technology, Zhejiang University, China', 'The College of Computer Science and Technology, Zhejiang University, China\nResearch Institute of Intelligent Computing, Zhejiang Lab, China']","['CMS: Brain Modeling', 'CMS: Agent & Cognitive Architectures', 'CMS: Structural Learning and Knowledge Capture']","Shen, J., Xu, Q., Liu, J. K., Wang, Y., Pan, G., & Tang, H. (2023). ESL-SNNs: An Evolutionary Structure Learning Strategy for Spiking Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 86-93. https://doi.org/10.1609/aaai.v37i1.25079","Abstract 					Spiking neural networks (SNNs) have manifested remarkable advantages in power consumption and event-driven property during the inference process. To take full advantage of low power consumption and improve the efficiency of these models further, the pruning methods have been explored to find sparse SNNs without redundancy connections after training. However, parameter redundancy still hinders the efficiency of SNNs during training. In the human brain, the rewiring process of neural networks is highly dynamic, while synaptic connections maintain relatively sparse during brain development. Inspired by this, here we propose an efficient evolutionary structure learning (ESL) framework for SNNs, named ESL-SNNs, to implement the sparse SNN training from scratch. The pruning and regeneration of synaptic connections in SNNs evolve dynamically during learning, yet keep the structural sparsity at a certain level. As a result, the ESL-SNNs can search for optimal sparse connectivity by exploring all possible parameters across time. Our experiments show that the proposed ESL-SNNs framework is able to learn SNNs with sparse structures effectively while reducing the limited accuracy. The ESL-SNNs achieve merely 0.28% accuracy loss with 10% connection density on the DVS-Cifar10 dataset. Our work presents a brand-new approach for sparse training of SNNs from scratch with biologically plausible evolutionary mechanisms, closing the gap in the expressibility between sparse training and dense training. Hence, it has great potential for SNN lightweight training and inference with low power consumption and small memory usage.","https://ojs.aaai.org/index.php/AAAI/article/view/25079/24851"
"25080","Zero-Shot Linear Combinations of Grounded Social Interactions with Linear Social MDPs","['Ravi Tejwani', 'Yen-Ling Kuo', 'Tianmin Shu', 'Bennett Stankovits', 'Dan Gutfreund', 'Joshua B. Tenenbaum', 'Boris Katz', 'Andrei Barbu']","['MIT', 'MIT', 'MIT', 'MIT', 'MIT-IBM Watson AI Lab', 'MIT', 'MIT', 'MIT']","['CMS: Social Cognition and Interaction', 'MAS: Coordination and Collaboration', 'MAS: Multiagent Planning', 'MAS: Other Foundations of Multiagent Systems']","Tejwani, R., Kuo, Y.-L., Shu, T., Stankovits, B., Gutfreund, D., Tenenbaum, J. B., Katz, B., & Barbu, A. (2023). Zero-Shot Linear Combinations of Grounded Social Interactions with Linear Social MDPs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 94-101. https://doi.org/10.1609/aaai.v37i1.25080","Abstract 					Humans and animals engage in rich social interactions. It is often theorized that a relatively small number of basic social interactions give rise to the full range of behavior observed. But no computational theory explaining how social interactions combine together has been proposed before. We do so here. We take a model, the Social MDP, which is able to express a range of social interactions, and extend it to represent linear combinations of social interactions. Practically for robotics applications, such models are now able to not just express that an agent should help another agent, but to express goal-centric social interactions. Perhaps an agent is helping someone get dressed, but preventing them from falling, and is happy to exchange stories in the meantime. How an agent responds socially, should depend on what it thinks the other agent is doing at that point in time. To encode this notion, we take linear combinations of social interactions as defined in Social MDPs, and compute the weights on those combinations on the fly depending on the estimated goals of other agents. This new model, the Linear Social MDP, enables zero-shot reasoning about complex social interactions, provides a mathematical basis for the long-standing intuition that social interactions should compose, and leads to interesting new behaviors that we validate using human observers. Complex social interactions are part of the future of intelligent agents, and having principled mathematical models built on a foundation like MDPs will make it possible to bring social interactions to every robotic application.","https://ojs.aaai.org/index.php/AAAI/article/view/25080/24852"
"25081","Complex Dynamic Neurons Improved Spiking Transformer Network for Efficient Automatic Speech Recognition","['Qingyu Wang', 'Tielin Zhang', 'Minglun Han', 'Yi Wang', 'Duzhen Zhang', 'Bo Xu']","['Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'School of Artificial Intelligence, Jilin University', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences\nCenter for Excellence in Brain Science and Intelligence Technology, Chinese Academy of Sciences']","['CMS: Brain Modeling', 'CMS: Agent & Cognitive Architectures', 'CMS: Simulating Humans', 'ML: Bio-Inspired Learning']","Wang, Q., Zhang, T., Han, M., Wang, Y., Zhang, D., & Xu, B. (2023). Complex Dynamic Neurons Improved Spiking Transformer Network for Efficient Automatic Speech Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 102-109. https://doi.org/10.1609/aaai.v37i1.25081","Abstract 					The spiking neural network (SNN) using leaky-integrated-and-fire (LIF) neurons has been commonly used in automatic speech recognition (ASR) tasks. However, the LIF neuron is still relatively simple compared to that in the biological brain. Further research on more types of neurons with different scales of neuronal dynamics is necessary. Here we introduce four types of neuronal dynamics to post-process the sequential patterns generated from the spiking transformer to get the complex dynamic neuron improved spiking transformer neural network (DyTr-SNN). We found that the DyTr-SNN could handle the non-toy automatic speech recognition task well, representing a lower phoneme error rate, lower computational cost, and higher robustness. These results indicate that the further cooperation of SNNs and neural dynamics at the neuron and network scales might have much in store for the future, especially on the ASR tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25081/24853"
"25082","Self-Supervised Graph Learning for Long-Tailed Cognitive Diagnosis","['Shanshan Wang', 'Zhen Zeng', 'Xun Yang', 'Xingyi Zhang']","['Anhui university\nInstitute of Artificial Intelligence, Hefei Comprehensive National Science Center, HeFei, China', 'Anhui University', 'University of Science and Technology of China', 'Anhui University']","['CMS: Applications', 'DMKM: Applications', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Wang, S., Zeng, Z., Yang, X., & Zhang, X. (2023). Self-Supervised Graph Learning for Long-Tailed Cognitive Diagnosis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 110-118. https://doi.org/10.1609/aaai.v37i1.25082","Abstract 					Cognitive diagnosis is a fundamental yet critical research task in the field of intelligent education, which aims to discover the proficiency level of different students on specific knowledge concepts. Despite the effectiveness of existing efforts, previous methods always considered the mastery level on the whole students, so they still suffer from the Long Tail Effect. A large number of students who have sparse interaction records are usually wrongly diagnosed during inference. To relieve the situation, we proposed a Self-supervised Cognitive Diagnosis (SCD) framework which leverages the self-supervised manner to assist the graph-based cognitive diagnosis, then the performance on those students with sparse data can be improved. Specifically, we came up with a graph confusion method that drops edges under some special rules to generate different sparse views of the graph. By maximizing the cross-view consistency of node representations, our model could pay more attention on long-tailed students. Additionally, we proposed an importance-based view generation rule to improve the influence of long-tailed students. Extensive experiments on real-world datasets show the effectiveness of our approach, especially on the students with much sparser interaction records. Our code is available at https://github.com/zeng-zhen/SCD.","https://ojs.aaai.org/index.php/AAAI/article/view/25082/24854"
"25083","CMNet: Contrastive Magnification Network for Micro-Expression Recognition","['Mengting Wei', 'Xingxun Jiang', 'Wenming Zheng', 'Yuan Zong', 'Cheng Lu', 'Jiateng Liu']","['Key Laboratory of Child Development and Learning Science of Ministry of Education\nSchool of Biological Science and Medical Engineering, Southeast University, Nanjing, China', 'Key Laboratory of Child Development and Learning Science of Ministry of Education\nSchool of Biological Science and Medical Engineering, Southeast University, Nanjing, China', 'Key Laboratory of Child Development and Learning Science of Ministry of Education', 'Key Laboratory of Child Development and Learning Science of Ministry of Education', 'Key Laboratory of Child Development and Learning Science of Ministry of Education\nSchool of Information Science and Engineering, Southeast University, Nanjing, China', 'Key Laboratory of Child Development and Learning Science of Ministry of Education\nSchool of Biological Science and Medical Engineering, Southeast University, Nanjing, China']","['CMS: Affective Computing', 'CMS: Applications', 'CV: Applications', 'CV: Video Understanding & Activity Analysis']","Wei, M., Jiang, X., Zheng, W., Zong, Y., Lu, C., & Liu, J. (2023). CMNet: Contrastive Magnification Network for Micro-Expression Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 119-127. https://doi.org/10.1609/aaai.v37i1.25083","Abstract 					Micro-Expression Recognition (MER) is challenging because the Micro-Expressions' (ME) motion is too weak to distinguish. This hurdle can be tackled by enhancing intensity for a more accurate acquisition of movements. However, existing magnification strategies tend to use the features of facial images that include not only intensity clues as intensity features, leading to the intensity representation deficient of credibility. In addition, the intensity variation over time, which is crucial for encoding movements, is also neglected. To this end, we provide a reliable scheme to extract intensity clues while considering their variation on the time scale. First, we devise an Intensity Distillation (ID) loss to acquire the intensity clues by contrasting the difference between frames, given that the difference in the same video lies only in the intensity. Then, the intensity clues are calibrated to follow the trend of the original video. Specifically, due to the lack of truth intensity annotation of the original video, we build the intensity tendency by setting each intensity vacancy an uncertain value, which guides the extracted intensity clues to converge towards this trend rather some fixed values. A Wilcoxon rank sum test (Wrst) method is enforced to implement the calibration. Experimental results on three public ME databases i.e. CASME II, SAMM, and SMIC-HS validate the superiority against state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25083/24855"
"25084","Disentangling Reafferent Effects by Doing Nothing","['Benedict Wilkins', 'Kostas Stathis']","['Royal Holloway University of London', 'Royal Holloway University of London']","['CMS: Other Foundations of Cognitive Modeling & Systems', 'ML: Causal Learning', 'ML: Representation Learning', 'MAS: Agent/AI Theories and Architectures', 'MAS: Modeling Other Agents']","Wilkins, B., & Stathis, K. (2023). Disentangling Reafferent Effects by Doing Nothing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 128-136. https://doi.org/10.1609/aaai.v37i1.25084","Abstract 					An agent's ability to distinguish between sensory effects that are self-caused, and those that are not, is instrumental in the achievement of its goals. This ability is thought to be central to a variety of functions in biological organisms, from perceptual stabilisation and accurate motor control, to higher level cognitive functions such as planning, mirroring and the sense of agency. Although many of these functions are well studied in AI, this important distinction is rarely made explicit and the focus tends to be on the associational relationship between action and sensory effect or success. Toward the development of more general agents, we develop a framework that enables agents to disentangle self-caused and externally-caused sensory effects. Informed by relevant models and experiments in robotics, and in the biological and cognitive sciences, we demonstrate the general applicability of this framework through an extensive experimental evaluation over three different environments.","https://ojs.aaai.org/index.php/AAAI/article/view/25084/24856"
"25085","Learning Temporal-Ordered Representation for Spike Streams Based on Discrete Wavelet Transforms","['Jiyuan Zhang', 'Shanshan Jia', 'Zhaofei Yu', 'Tiejun Huang']","['Peking University', 'Peking University', 'Peking University', 'Peking University']","['CMS: Brain Modeling', 'CV: Computational Photography', 'Image & Video Synthesis']","Zhang, J., Jia, S., Yu, Z., & Huang, T. (2023). Learning Temporal-Ordered Representation for Spike Streams Based on Discrete Wavelet Transforms. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 137-147. https://doi.org/10.1609/aaai.v37i1.25085","Abstract 					Spike camera, a new type of neuromorphic visual sensor that imitates the sampling mechanism of the primate fovea, can capture photons and output 40000 Hz binary spike streams. Benefiting from the asynchronous sampling mechanism, the spike camera can record fast-moving objects and clear images can be recovered from the spike stream at any specified timestamps without motion blurring. Despite these, due to the dense time sequence information of the discrete spike stream, it is not easy to directly apply the existing algorithms of traditional cameras to the spike camera. Therefore, it is necessary and interesting to explore a universally effective representation of dense spike streams to better fit various network architectures. In this paper, we propose to mine temporal-robust features of spikes in time-frequency space with wavelet transforms. We present a novel Wavelet-Guided Spike Enhancing (WGSE) paradigm consisting of three consecutive steps: multi-level wavelet transform, CNN-based learnable module, and inverse wavelet transform. With the assistance of WGSE, the new streaming representation of spikes can be learned. We demonstrate the effectiveness of WGSE on two downstream tasks, achieving state-of-the-art performance on the image reconstruction task and getting considerable performance on semantic segmentation. Furthermore, We build a new spike-based synthesized dataset for semantic segmentation. Code and Datasets are available at https://github.com/Leozhangjiyuan/WGSE-SpikeCamera.","https://ojs.aaai.org/index.php/AAAI/article/view/25085/24857"
"25086","ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges","['Ruizhe Zheng', 'Jun Li', 'Yi Wang', 'Tian Luo', 'Yuguo Yu']","['Fudan University', 'Fudan University', 'Fudan Unniversity', 'Fudan Unniversity', 'Fudan University']","['CMS: Applications', 'CMS: Brain Modeling', 'APP: Biometrics', 'APP: Healthcare', 'Medicine & Wellness']","Zheng, R., Li, J., Wang, Y., Luo, T., & Yu, Y. (2023). ScatterFormer: Locally-Invariant Scattering Transformer for Patient-Independent Multispectral Detection of Epileptiform Discharges. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 148-158. https://doi.org/10.1609/aaai.v37i1.25086","Abstract 					Patient-independent detection of epileptic activities based on visual spectral representation of continuous EEG (cEEG) has been widely used for diagnosing epilepsy. However, precise detection remains a considerable challenge due to subtle variabilities across subjects, channels and time points. Thus, capturing fine-grained, discriminative features of EEG patterns, which is associated with high-frequency textural information, is yet to be resolved. In this work, we propose Scattering Transformer (ScatterFormer), an invariant scattering transform-based hierarchical Transformer that specifically pays attention to subtle features. In particular, the disentangled frequency-aware attention (FAA) enables the Transformer to capture clinically informative high-frequency components, offering a novel clinical explainability based on visual encoding of multichannel EEG signals. Evaluations on two distinct tasks of epileptiform detection demonstrate the effectiveness our method. Our proposed model achieves median AUCROC and accuracy of 98.14%, 96.39% in patients with Rolandic epilepsy. On a neonatal seizure detection benchmark, it outperforms the state-of-the-art by 9% in terms of average AUCROC.","https://ojs.aaai.org/index.php/AAAI/article/view/25086/24858"
"25087","Progress and Limitations of Deep Networks to Recognize Objects in Unusual Poses","['Amro Abbas', 'Stéphane Deny']","['The African Institute For Mathematical Sciences', 'Aalto University']","['CV: Adversarial Attacks & Robustness', 'CV: Scene Analysis & Understanding', 'ML: Deep Neural Architectures']","Abbas, A., & Deny, S. (2023). Progress and Limitations of Deep Networks to Recognize Objects in Unusual Poses. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 160-168. https://doi.org/10.1609/aaai.v37i1.25087","Abstract 					Deep networks should be robust to rare events if they are to be successfully deployed in high-stakes real-world applications. Here we study the capability of deep networks to recognize objects in unusual poses. We create a synthetic dataset of images of objects in unusual orientations, and evaluate the robustness of a collection of 38 recent and competitive deep networks for image classification. We show that classifying these images is still a challenge for all networks tested, with an average accuracy drop of 29.5% compared to when the objects are presented upright. This brittleness is largely unaffected by various design choices, such as training losses, architectures, dataset modalities, and data-augmentation schemes. However, networks trained on very large datasets substantially outperform others, with the best network tested—Noisy Student trained on JFT-300M—showing a relatively small accuracy drop of only 14.5% on unusual poses. Nevertheless, a visual inspection of the failures of Noisy Student reveals a remaining gap in robustness with humans. Furthermore, combining multiple object transformations—3D-rotations and scaling—further degrades the performance of all networks. Our results provide another measurement of the robustness of deep networks to consider when using them in the real world. Code and datasets are available at https://github.com/amro-kamal/ObjectPose.","https://ojs.aaai.org/index.php/AAAI/article/view/25087/24859"
"25088","Denoising after Entropy-Based Debiasing a Robust Training Method for Dataset Bias with Noisy Labels","['Sumyeong Ahn', 'Se-Young Yun']","['KAIST', 'KAIST']","['CV: Bias', 'Fairness & Privacy', 'ML: Bias and Fairness']","Ahn, S., & Yun, S.-Y. (2023). Denoising after Entropy-Based Debiasing a Robust Training Method for Dataset Bias with Noisy Labels. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 169-177. https://doi.org/10.1609/aaai.v37i1.25088","Abstract 					Improperly constructed datasets can result in inaccurate inferences. For instance, models trained on biased datasets perform poorly in terms of generalization (i.e., dataset bias). Recent debiasing techniques have successfully achieved generalization performance by underestimating easy-to-learn samples (i.e., bias-aligned samples) and highlighting difficult-to-learn samples (i.e., bias-conflicting samples). However, these techniques may fail owing to noisy labels, because the trained model recognizes noisy labels as difficult-to-learn and thus highlights them. In this study, we find that earlier approaches that used the provided labels to quantify difficulty could be affected by the small proportion of noisy labels. Furthermore, we find that running denoising algorithms before debiasing is ineffective because denoising algorithms reduce the impact of difficult-to-learn samples, including valuable bias-conflicting samples. Therefore, we propose an approach called denoising after entropy-based debiasing, i.e., DENEB, which has three main stages. (1) The prejudice model is trained by emphasizing (bias-aligned, clean) samples, which are selected using a Gaussian Mixture Model. (2) Using the per-sample entropy from the output of the prejudice model, the sampling probability of each sample that is proportional to the entropy is computed. (3) The final model is trained using existing denoising algorithms with the mini-batches constructed by following the computed sampling probability. Compared to existing debiasing and denoising algorithms, our method achieves better debiasing performance on multiple benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25088/24860"
"25089","Rethinking Interpretation: Input-Agnostic Saliency Mapping of Deep Visual Classifiers","['Naveed Akhtar', 'Mohammad Amir Asim Khan Jalwana']","['The University of Western Australia', 'The University of Western Australia']","['CV: Interpretability and Transparency', 'CV: Learning & Optimization for CV', 'CV: Other Foundations of Computer Vision']","Akhtar, N., & Jalwana, M. A. A. K. (2023). Rethinking Interpretation: Input-Agnostic Saliency Mapping of Deep Visual Classifiers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 178-186. https://doi.org/10.1609/aaai.v37i1.25089","Abstract 					Saliency methods provide post-hoc model interpretation by attributing input features to the model outputs. Current methods mainly achieve this using a single input sample, thereby failing to answer input-independent inquiries about the model. We also show that input-specific saliency mapping is intrinsically susceptible to misleading feature attribution. Current attempts to use `general' input features for model interpretation assume  access to a dataset containing  those features, which biases the interpretation.  Addressing the gap, we introduce a new perspective of input-agnostic saliency mapping that computationally estimates the high-level  features attributed by the model to its outputs. These features are geometrically correlated, and are computed by accumulating model's gradient information with respect to an unrestricted data distribution. To compute these features, we nudge independent data points over the model loss surface towards the local minima associated by a human-understandable concept, e.g., class label for classifiers. With a systematic projection, scaling and refinement process, this information is transformed into an interpretable visualization without compromising its model-fidelity. The visualization serves as a stand-alone qualitative interpretation. With an extensive evaluation, we not only demonstrate successful visualizations for a variety of concepts for large-scale models, but also showcase an interesting utility of this new form of saliency mapping by identifying backdoor signatures in compromised classifiers.","https://ojs.aaai.org/index.php/AAAI/article/view/25089/24861"
"25090","Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation","['Jinwoo Bae', 'Sungho Moon', 'Sunghoon Im']","['DGIST', 'DGIST', 'DGIST']","['CV: 3D Computer Vision', 'CV: Adversarial Attacks & Robustness', 'CV: Applications', 'CV: Vision for Robotics & Autonomous Driving']","Bae, J., Moon, S., & Im, S. (2023). Deep Digging into the Generalization of Self-Supervised Monocular Depth Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 187-196. https://doi.org/10.1609/aaai.v37i1.25090","Abstract 					Self-supervised monocular depth estimation has been widely studied recently. Most of the work has focused on improving performance on benchmark datasets, such as KITTI, but has offered a few experiments on generalization performance. In this paper, we investigate the backbone networks (e.g., CNNs, Transformers, and CNN-Transformer hybrid models) toward the generalization of monocular depth estimation. We first evaluate state-of-the-art models on diverse public datasets, which have never been seen during the network training. Next, we investigate the effects of texture-biased and shape-biased representations using the various texture-shifted datasets that we generated. We observe that Transformers exhibit a strong shape bias and CNNs do a strong texture-bias. We also find that shape-biased models show better generalization performance for monocular depth estimation compared to texture-biased models. Based on these observations, we newly design a CNN-Transformer hybrid network with a multi-level adaptive feature fusion module, called MonoFormer. The design intuition behind MonoFormer is to increase shape bias by employing Transformers while compensating for the weak locality bias of Transformers by adaptively fusing multi-level representations. Extensive experiments show that the proposed method achieves state-of-the-art performance with various public datasets. Our method also shows the best generalization ability among the competitive methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25090/24862"
"25091","Self-Contrastive Learning: Single-Viewed Supervised Contrastive Framework Using Sub-network","['Sangmin Bae', 'Sungnyun Kim', 'Jongwoo Ko', 'Gihun Lee', 'Seungjong Noh', 'Se-Young Yun']","['KAIST', 'KAIST', 'KAIST', 'KAIST', 'SK Hynix', 'KAIST']","['CV: Representation Learning for Vision', 'ML: Deep Neural Network Algorithms', 'ML: Representation Learning']","Bae, S., Kim, S., Ko, J., Lee, G., Noh, S., & Yun, S.-Y. (2023). Self-Contrastive Learning: Single-Viewed Supervised Contrastive Framework Using Sub-network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 197-205. https://doi.org/10.1609/aaai.v37i1.25091","Abstract 					Contrastive loss has significantly improved performance in supervised classification tasks by using a multi-viewed framework that leverages augmentation and label information. The augmentation enables contrast with another view of a single image but enlarges training time and memory usage. To exploit the strength of multi-views while avoiding the high computation cost, we introduce a multi-exit architecture that outputs multiple features of a single image in a single-viewed framework. To this end, we propose Self-Contrastive (SelfCon) learning, which self-contrasts within multiple outputs from the different levels of a single network. The multi-exit architecture efficiently replaces multi-augmented images and leverages various information from different layers of a network. We demonstrate that SelfCon learning improves the classification performance of the encoder network, and empirically analyze its advantages in terms of the single-view and the sub-network. Furthermore, we provide theoretical evidence of the performance increase based on the mutual information bound. For ImageNet classification on ResNet-50, SelfCon improves accuracy by +0.6% with 59% memory and 48% time of Supervised Contrastive learning, and a simple ensemble of multi-exit outputs boosts performance up to +1.5%. Our code is available at https://github.com/raymin0223/self-contrastive-learning.","https://ojs.aaai.org/index.php/AAAI/article/view/25091/24863"
"25092","Layout Representation Learning with Spatial and Structural Hierarchies","['Yue Bai', 'Dipu Manandhar', 'Zhaowen Wang', 'John Collomosse', 'Yun Fu']","['Northeastern University', 'University of Surrey', 'Adobe Research', 'Adobe Research', 'Northeastern University']","['CV: Representation Learning for Vision', 'APP: Design']","Bai, Y., Manandhar, D., Wang, Z., Collomosse, J., & Fu, Y. (2023). Layout Representation Learning with Spatial and Structural Hierarchies. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 206-214. https://doi.org/10.1609/aaai.v37i1.25092","Abstract 					We present a novel hierarchical modeling method for layout representation learning, the core of design documents (e.g., user interface, poster, template). Existing works on layout representation often ignore element hierarchies, which is an important facet of layouts, and mainly rely on the spatial bounding boxes for feature extraction. This paper proposes a Spatial-Structural Hierarchical Auto-Encoder (SSH-AE) that learns hierarchical representation by treating a hierarchically annotated layout as a tree format. On the one side, we model SSH-AE from both spatial (semantic views) and structural (organization and relationships) perspectives, which are two complementary aspects to represent a layout. On the other side, the semantic/geometric properties are associated at multiple resolutions/granularities, naturally handling complex layouts. Our learned representations are used for effective layout search from both spatial and structural similarity perspectives. We also newly involve the tree-edit distance (TED) as an evaluation metric to construct a comprehensive evaluation protocol for layout similarity assessment, which benefits a systematic and customized layout search. We further present a new dataset of POSTER layouts which we believe will be useful for future layout research. We show that our proposed SSH-AE outperforms the existing methods achieving state-of-the-art performance on two benchmark datasets. Code is available at github.com/yueb17/SSH-AE.","https://ojs.aaai.org/index.php/AAAI/article/view/25092/24864"
"25093","Cross-Modal Label Contrastive Learning for Unsupervised Audio-Visual Event Localization","['Peijun Bao', 'Wenhan Yang', 'Boon Poh Ng', 'Meng Hwa Er', 'Alex C. Kot']","['Nanyang Technological University', 'Nanyang Technological University\nPeng Cheng Laboratory', 'Nanyang Technological University', 'Nanyang Technological University', 'Nanyang Technological University']","['CV: Video Understanding & Activity Analysis', 'CV: Image and Video Retrieval', 'CV: Multi-modal Vision', 'SNLP: Speech and Multimodality']","Bao, P., Yang, W., Ng, B. P., Er, M. H., & Kot, A. C. (2023). Cross-Modal Label Contrastive Learning for Unsupervised Audio-Visual Event Localization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 215-222. https://doi.org/10.1609/aaai.v37i1.25093","Abstract 					This paper for the first time explores audio-visual event localization in an unsupervised manner. Previous methods tackle this problem in a supervised setting and require segment-level or video-level event category ground-truth to train the model. However, building large-scale multi-modality datasets with category annotations is human-intensive and thus not scalable to real-world applications. To this end, we propose cross-modal label contrastive learning to exploit multi-modal information among unlabeled audio and visual streams as self-supervision signals. At the feature representation level, multi-modal representations are collaboratively learned from audio and visual components by using self-supervised representation learning. At the label level, we propose a novel self-supervised pretext task i.e. label contrasting to self-annotate videos with pseudo-labels for localization model training. Note that irrelevant background would hinder the acquisition of high-quality pseudo-labels and thus lead to an inferior localization model. To address this issue, we then propose an expectation-maximization algorithm that optimizes the pseudo-label acquisition and localization model in a coarse-to-fine manner. Extensive experiments demonstrate that our unsupervised approach performs reasonably well compared to the state-of-the-art supervised methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25093/24865"
"25094","Multi-Level Compositional Reasoning for Interactive Instruction Following","['Suvaansh Bhambri', 'Byeonghwi Kim', 'Jonghyun Choi']","['Yonsei University', 'Yonsei University', 'Yonsei University']","['CV: Vision for Robotics & Autonomous Driving', 'ROB: Applications']","Bhambri, S., Kim, B., & Choi, J. (2023). Multi-Level Compositional Reasoning for Interactive Instruction Following. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 223-231. https://doi.org/10.1609/aaai.v37i1.25094","Abstract 					Robotic agents performing domestic chores by natural language directives are required to master the complex job of navigating environment and interacting with objects in the environments. The tasks given to the agents are often composite thus are challenging as completing them require to reason about multiple subtasks, e.g., bring a cup of coffee. To address the challenge, we propose to divide and conquer it by breaking the task into multiple subgoals and attend to them individually for better navigation and interaction. We call it Multi-level Compositional Reasoning Agent (MCR-Agent). Specifically, we learn a three-level action policy. At the highest level, we infer a sequence of human-interpretable subgoals to be executed based on language instructions by a high-level policy composition controller. At the middle level, we discriminatively control the agent’s navigation by a master policy by alternating between a navigation policy and various independent interaction policies. Finally, at the lowest level, we infer manipulation actions with the corresponding object masks using the appropriate interaction policy. Our approach not only generates human interpretable subgoals but also achieves 2.03% absolute gain to comparable state of the arts in the efficiency metric (PLWSR in unseen set) without using rule-based planning or a semantic spatial memory. The code is available at https://github.com/yonseivnl/mcr-agent.","https://ojs.aaai.org/index.php/AAAI/article/view/25094/24866"
"25095","Self-Supervised Image Local Forgery Detection by JPEG Compression Trace","['Xiuli Bi', 'Wuqing Yan', 'Bo Liu', 'Bin Xiao', 'Weisheng Li', 'Xinbo Gao']","['Chongqing University of Posts and Telecommunications', 'Chongqing University of Posts and Telecommunications', 'Chongqing University of Posts and Telecommunications', 'Chongqing University of Posts and Telecommunications', 'Chongqing University of Posts and Telecommunications', 'Chongqing University of Posts and Telecommunications']","['CV: Object Detection & Categorization', 'CV: Segmentation']","Bi, X., Yan, W., Liu, B., Xiao, B., Li, W., & Gao, X. (2023). Self-Supervised Image Local Forgery Detection by JPEG Compression Trace. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 232-240. https://doi.org/10.1609/aaai.v37i1.25095","Abstract 					For image local forgery detection, the existing methods require a large amount of labeled data for training, and most of them cannot detect multiple types of forgery simultaneously. In this paper, we firstly analyzed the JPEG compression traces which are mainly caused by different JPEG compression chains, and designed a trace extractor to learn such traces. Then, we utilized the trace extractor as the backbone and trained self-supervised to strengthen the discrimination ability of learned traces. With its benefits, regions with different JPEG compression chains can easily be distinguished within a forged image. Furthermore, our method does not rely on a large amount of training data, and even does not require any forged images for training. Experiments show that the proposed method can detect image local forgery on different datasets without re-training, and keep stable performance over various types of image local forgery.","https://ojs.aaai.org/index.php/AAAI/article/view/25095/24867"
"25096","VASR: Visual Analogies of Situation Recognition","['Yonatan Bitton', 'Ron Yosef', 'Eliyahu Strugo', 'Dafna Shahaf', 'Roy Schwartz', 'Gabriel Stanovsky']","['The Hebrew University of Jerusalem', 'The Hebrew University of Jerusalem', 'The Hebrew University of Jerusalem', 'The Hebrew University of Jerusalem', 'The Hebrew University of Jerusalem', 'The Hebrew University of Jerusalem']","['CV: Scene Analysis & Understanding', 'CV: Language and Vision']","Bitton, Y., Yosef, R., Strugo, E., Shahaf, D., Schwartz, R., & Stanovsky, G. (2023). VASR: Visual Analogies of Situation Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 241-249. https://doi.org/10.1609/aaai.v37i1.25096","Abstract 					A core process in human cognition is analogical mapping: the ability to identify a similar relational structure between different situations. We introduce a novel task, Visual Analogies of Situation Recognition, adapting the classical word-analogy task into the visual domain. Given a triplet of images, the task is to select an image candidate B' that completes the analogy (A to A' is like B to what?). Unlike previous work on visual analogy that focused on simple image transformations, we tackle complex analogies requiring understanding of scenes.   We leverage situation recognition annotations and the CLIP model to generate a large set of 500k candidate analogies. Crowdsourced  annotations for a sample of the data indicate that humans agree with the dataset label ~80% of the time (chance level 25%). Furthermore, we use human annotations to create a gold-standard dataset of 3,820 validated analogies. Our experiments demonstrate that state-of-the-art models do well when distractors are chosen randomly (~86%), but  struggle with carefully chosen distractors (~53%, compared to 90% human accuracy). We hope our dataset will encourage the development of new analogy-making models. Website: https://vasr-dataset.github.io/","https://ojs.aaai.org/index.php/AAAI/article/view/25096/24868"
"25097","Parametric Surface Constrained Upsampler Network for Point Cloud","['Pingping Cai', 'Zhenyao Wu', 'Xinyi Wu', 'Song Wang']","['University of South Carolina', 'University of South Carolina', 'University of South Carolina', 'University of South Carolina']","['CV: 3D Computer Vision', 'CV: Low Level & Physics-Based Vision', 'ML: Deep Neural Architectures']","Cai, P., Wu, Z., Wu, X., & Wang, S. (2023). Parametric Surface Constrained Upsampler Network for Point Cloud. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 250-258. https://doi.org/10.1609/aaai.v37i1.25097","Abstract 					Designing a point cloud upsampler, which aims to generate a clean and dense point cloud given a sparse point representation, is a fundamental and challenging problem in computer vision. A line of attempts achieves this goal by establishing a point-to-point mapping function via deep neural networks. However, these approaches are prone to produce outlier points due to the lack of explicit surface-level constraints. To solve this problem, we introduce a novel surface regularizer into the upsampler network by forcing the neural network to learn the underlying parametric surface represented by bicubic functions and rotation functions, where the new generated points are then constrained on the underlying surface. These designs are integrated into two different networks for two tasks that take advantages of upsampling layers -- point cloud upsampling and point cloud completion for evaluation. The state-of-the-art experimental results on both tasks demonstrate the effectiveness of the proposed method. The implementation code will be available at https://github.com/corecai163/PSCU.","https://ojs.aaai.org/index.php/AAAI/article/view/25097/24869"
"25098","Explicit Invariant Feature Induced Cross-Domain Crowd Counting","['Yiqing Cai', 'Lianggangxu Chen', 'Haoyue Guan', 'Shaohui Lin', 'Changhong Lu', 'Changbo Wang', 'Gaoqi He']","['East China Normal University', 'East China Normal University', 'Johns Hopkins University', 'East China Normal University', 'East China Normal University', 'East China Normal University', 'East China Normal University']","['CV: Applications']","Cai, Y., Chen, L., Guan, H., Lin, S., Lu, C., Wang, C., & He, G. (2023). Explicit Invariant Feature Induced Cross-Domain Crowd Counting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 259-267. https://doi.org/10.1609/aaai.v37i1.25098","Abstract 					Cross-domain crowd counting has shown progressively improved performance. However, most methods fail to explicitly consider the transferability of different features between source and target domains. In this paper, we propose an innovative explicit Invariant Feature induced Cross-domain Knowledge Transformation framework to address the inconsistent domain-invariant features of different domains. The main idea is to explicitly extract domain-invariant features from both source and target domains, which builds a bridge to transfer more rich knowledge between two domains. The framework consists of three parts, global feature decoupling (GFD), relation exploration and alignment (REA), and graph-guided knowledge enhancement (GKE). In the GFD module, domain-invariant features are efficiently decoupled from domain-specific ones in two domains, which allows the model to distinguish crowds features from backgrounds in the complex scenes. In the REA module both inter-domain relation graph (Inter-RG) and intra-domain relation graph (Intra-RG) are built. Specifically, Inter-RG aggregates multi-scale domain-invariant features between two domains and further aligns local-level invariant features. Intra-RG preserves taskrelated specific information to assist the domain alignment. Furthermore, GKE strategy models the confidence of pseudolabels to further enhance the adaptability of the target domain. Various experiments show our method achieves state-of-theart performance on the standard benchmarks. Code is available at https://github.com/caiyiqing/IF-CKT.","https://ojs.aaai.org/index.php/AAAI/article/view/25098/24870"
"25099","Painterly Image Harmonization in Dual Domains","['Junyan Cao', 'Yan Hong', 'Li Niu']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Low Level & Physics-Based Vision']","Cao, J., Hong, Y., & Niu, L. (2023). Painterly Image Harmonization in Dual Domains. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 268-276. https://doi.org/10.1609/aaai.v37i1.25099","Abstract 					Image harmonization aims to produce visually harmonious composite images by adjusting the foreground appearance to be compatible with the background. When the composite image has photographic foreground and painterly background, the task is called painterly image harmonization. There are only few works on this task, which are either time-consuming or weak in generating well-harmonized results. In this work, we propose a novel painterly harmonization network consisting of a dual-domain generator and a dual-domain discriminator, which harmonizes the composite image in both spatial domain and frequency domain. The dual-domain generator performs harmonization by using AdaIN modules in the spatial domain and our proposed ResFFT modules in the frequency domain. The dual-domain discriminator attempts to distinguish the inharmonious patches based on the spatial feature and frequency feature of each patch, which can enhance the ability of generator in an adversarial manner. Extensive experiments on the benchmark dataset show the effectiveness of our method. Our code and model are available at https://github.com/bcmi/PHDNet-Painterly-Image-Harmonization.","https://ojs.aaai.org/index.php/AAAI/article/view/25099/24871"
"25100","MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation","['Yiming Cao', 'Lizhen Cui', 'Lei Zhang', 'Fuqiang Yu', 'Zhen Li', 'Yonghui Xu']","['Shandong University', 'Shandong University', 'Shandong University', 'Shangdong university', 'Qilu Hospital of Shandong University', 'Shandong University']","['CV: Applications', 'CV: Medical and Biological Imaging', 'APP: Healthcare', 'Medicine & Wellness']","Cao, Y., Cui, L., Zhang, L., Yu, F., Li, Z., & Xu, Y. (2023). MMTN: Multi-Modal Memory Transformer Network for Image-Report Consistent Medical Report Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 277-285. https://doi.org/10.1609/aaai.v37i1.25100","Abstract 					Automatic medical report generation is an essential task in applying artificial intelligence to the medical domain, which can lighten the workloads of doctors and promote clinical automation. The state-of-the-art approaches employ Transformer-based encoder-decoder architectures to generate reports for medical images. However, they do not fully explore the relationships between multi-modal medical data, and generate inaccurate and inconsistent reports. To address these issues, this paper proposes a Multi-modal Memory Transformer Network (MMTN) to cope with multi-modal medical data for generating image-report consistent medical reports. On the one hand, MMTN reduces the occurrence of image-report inconsistencies by designing a unique encoder to associate and memorize the relationship between medical images and medical terminologies. On the other hand, MMTN utilizes the cross-modal complementarity of the medical vision and language for the word prediction, which further enhances the accuracy of generating medical reports. Extensive experiments on three real datasets show that MMTN achieves significant effectiveness over state-of-the-art approaches on both automatic metrics and human evaluation.","https://ojs.aaai.org/index.php/AAAI/article/view/25100/24872"
"25101","KT-Net: Knowledge Transfer for Unpaired 3D Shape Completion","['Zhen Cao', 'Wenxiao Zhang', 'Xin Wen', 'Zhen Dong', 'Yu-Shen Liu', 'Xiongwu Xiao', 'Bisheng Yang']","['Wuhan University', 'Singapore University of Technology & Design', 'JD Logistics', 'Wuhan University', 'Tsinghua University', 'Wuhan University', 'Wuhan University']","['CV: 3D Computer Vision', 'CV: Applications']","Cao, Z., Zhang, W., Wen, X., Dong, Z., Liu, Y.-S., Xiao, X., & Yang, B. (2023). KT-Net: Knowledge Transfer for Unpaired 3D Shape Completion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 286-294. https://doi.org/10.1609/aaai.v37i1.25101","Abstract 					Unpaired 3D object completion aims to predict a complete 3D shape from an incomplete input without knowing the correspondence between the complete and incomplete shapes. In this paper, we propose the novel KTNet to solve this task from the new perspective of knowledge transfer. KTNet elaborates a teacher-assistant-student network to establish multiple knowledge transfer processes. Specifically, the teacher network takes complete shape as input and learns the knowledge of complete shape. The student network takes the incomplete one as input and restores the corresponding complete shape. And the assistant modules not only help to transfer the knowledge of complete shape from the teacher to the student, but also judge the learning effect of the student network. As a result, KTNet makes use of a more comprehensive understanding to establish the geometric correspondence between complete and incomplete shapes in a perspective of knowledge transfer, which enables more detailed geometric inference for generating high-quality complete shapes. We conduct comprehensive experiments on several datasets, and the results show that our method outperforms previous methods of unpaired point cloud completion by a large margin. Code is available at https://github.com/a4152684/KT-Net.","https://ojs.aaai.org/index.php/AAAI/article/view/25101/24873"
"25102","Deconstructed Generation-Based Zero-Shot Model","['Dubing Chen', 'Yuming Shen', 'Haofeng Zhang', 'Philip H.S. Torr']","['Nanjing University of Science and Technology', 'University of Oxford', 'Nanjing University of Science and Technology', 'University of Oxford']","['CV: Language and Vision', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Chen, D., Shen, Y., Zhang, H., & Torr, P. H. (2023). Deconstructed Generation-Based Zero-Shot Model. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 295-303. https://doi.org/10.1609/aaai.v37i1.25102","Abstract 					Recent research on Generalized Zero-Shot Learning (GZSL) has focused primarily on generation-based methods. However, current literature has overlooked the fundamental principles of these methods and has made limited progress in a complex manner. In this paper, we aim to deconstruct the generator-classifier framework and provide guidance for its improvement and extension. We begin by breaking down the generator-learned unseen class distribution into class-level and instance-level distributions. Through our analysis of the role of these two types of distributions in solving the GZSL problem, we generalize the focus of the generation-based approach, emphasizing the importance of (i) attribute generalization in generator learning and (ii) independent classifier learning with partially biased data. We present a simple method based on this analysis that outperforms SotAs on four public GZSL datasets, demonstrating the validity of our deconstruction. Furthermore, our proposed method remains effective even without a generative model, representing a step towards simplifying the generator-classifier structure. Our code is available at https://github.com/cdb342/DGZ.","https://ojs.aaai.org/index.php/AAAI/article/view/25102/24874"
"25103","Tracking and Reconstructing Hand Object Interactions from Point Cloud Sequences in the Wild","['Jiayi Chen', 'Mi Yan', 'Jiazhao Zhang', 'Yinzhen Xu', 'Xiaolong Li', 'Yijia Weng', 'Li Yi', 'Shuran Song', 'He Wang']","['Peking University\nBeijing Institute for General AI', 'Peking University', 'Peking University', 'Peking University\nBeijing Institute for General AI', 'Virginia Tech', 'Stanford University', 'Tsinghua University', 'Columbia University', 'Peking University']","['CV: 3D Computer Vision', 'CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Motion & Tracking']","Chen, J., Yan, M., Zhang, J., Xu, Y., Li, X., Weng, Y., Yi, L., Song, S., & Wang, H. (2023). Tracking and Reconstructing Hand Object Interactions from Point Cloud Sequences in the Wild. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 304-312. https://doi.org/10.1609/aaai.v37i1.25103","Abstract 					In this work, we tackle the challenging task of jointly tracking hand object poses and reconstructing their shapes from depth point cloud sequences in the wild, given the initial poses at frame 0. We for the first time propose a point cloud-based hand joint tracking network, HandTrackNet, to estimate the inter-frame hand joint motion. Our HandTrackNet proposes a novel hand pose canonicalization module to ease the tracking task, yielding accurate and robust hand joint tracking. Our pipeline then reconstructs the full hand via converting the predicted hand joints into a MANO hand. For object tracking, we devise a simple yet effective module that estimates the object SDF from the first frame and performs optimization-based tracking. Finally, a joint optimization step is adopted to perform joint hand and object reasoning, which alleviates the occlusion-induced ambiguity and further refines the hand pose. During training, the whole pipeline only sees purely synthetic data, which are synthesized with sufficient variations and by depth simulation for the ease of generalization. The whole pipeline is pertinent to the generalization gaps and thus directly transferable to real in-the-wild data. We evaluate our method on two real hand object interaction datasets, e.g. HO3D and DexYCB, without any fine-tuning. Our experiments demonstrate that the proposed method significantly outperforms the previous state-of-the-art depth-based hand and object pose estimation and tracking methods, running at a frame rate of 9 FPS. We have released our code on https://github.com/PKU-EPIC/HOTrack.","https://ojs.aaai.org/index.php/AAAI/article/view/25103/24875"
"25104","Amodal Instance Segmentation via Prior-Guided Expansion","['Junjie Chen', 'Li Niu', 'Jianfu Zhang', 'Jianlou Si', 'Chen Qian', 'Liqing Zhang']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'SenseTime', 'SenseTime', 'Shanghai Jiao Tong University']","['CV: Segmentation']","Chen, J., Niu, L., Zhang, J., Si, J., Qian, C., & Zhang, L. (2023). Amodal Instance Segmentation via Prior-Guided Expansion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 313-321. https://doi.org/10.1609/aaai.v37i1.25104","Abstract 					Amodal instance segmentation aims to infer the amodal mask, including both the visible part and occluded part of each object instance. Predicting the occluded parts is challenging. Existing methods often produce incomplete amodal boxes and amodal masks, probably due to lacking visual evidences to expand the boxes and masks. To this end, we propose a prior-guided expansion framework, which builds on a two-stage segmentation model (i.e., Mask R-CNN) and performs box-level (resp., pixel-level) expansion for amodal box (resp., mask) prediction, by retrieving regression (resp., flow) transformations from a memory bank of expansion prior. We conduct extensive experiments on KINS, D2SA, and COCOA cls datasets, which show the effectiveness of our method.","https://ojs.aaai.org/index.php/AAAI/article/view/25104/24876"
"25105","SwinRDM: Integrate SwinRNN with Diffusion Model towards High-Resolution and High-Quality Weather Forecasting","['Lei Chen', 'Fei Du', 'Yuan Hu', 'Zhibin Wang', 'Fan Wang']","['Alibaba Group', 'Alibaba Group', 'Alibaba Group', 'Alibaba Group', 'Alibaba Group']","['CV: Applications', 'APP: Energy', 'Environment & Sustainability']","Chen, L., Du, F., Hu, Y., Wang, Z., & Wang, F. (2023). SwinRDM: Integrate SwinRNN with Diffusion Model towards High-Resolution and High-Quality Weather Forecasting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 322-330. https://doi.org/10.1609/aaai.v37i1.25105","Abstract 					Data-driven medium-range weather forecasting has attracted much attention in recent years. However, the forecasting accuracy at high resolution is unsatisfactory currently. Pursuing high-resolution and high-quality weather forecasting, we develop a data-driven model SwinRDM which integrates an improved version of SwinRNN with a diffusion model. SwinRDM performs predictions at 0.25-degree resolution and achieves superior forecasting accuracy to IFS (Integrated Forecast System), the state-of-the-art operational NWP model, on representative atmospheric variables including 500 hPa geopotential (Z500), 850 hPa temperature (T850), 2-m temperature (T2M), and total precipitation (TP), at lead times of up to 5 days. We propose to leverage a two-step strategy to achieve high-resolution predictions at 0.25-degree considering the trade-off between computation memory and forecasting accuracy. Recurrent predictions for future atmospheric fields are firstly performed at 1.40625-degree resolution, and then a diffusion-based super-resolution model is leveraged to recover the high spatial resolution and finer-scale atmospheric details. SwinRDM pushes forward the performance and potential of data-driven models for a large margin towards operational applications.","https://ojs.aaai.org/index.php/AAAI/article/view/25105/24877"
"25106","Take Your Model Further: A General Post-refinement Network for Light Field Disparity Estimation via BadPix Correction","['Rongshan Chen', 'Hao Sheng', 'Da Yang', 'Sizhe Wang', 'Zhenglong Cui', 'Ruixuan Cong']","['School of Computer Science and Engineering, Beihang University\nBeihang Hangzhou Innovation Institute Yuhang', 'School of Computer Science and Engineering, Beihang University\nBeihang Hangzhou Innovation Institute Yuhang\nFaculty of Applied Sciences, Macao Polytechnic University', 'School of Computer Science and Engineering, Beihang University\nBeihang Hangzhou Innovation Institute Yuhang', 'School of Computer Science and Engineering, Beihang University\nBeihang Hangzhou Innovation Institute Yuhang', 'School of Computer Science and Engineering, Beihang University\nBeihang Hangzhou Innovation Institute Yuhang', 'School of Computer Science and Engineering, Beihang University\nBeihang Hangzhou Innovation Institute Yuhang']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Multi-modal Vision', 'CV: Scene Analysis & Understanding', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms']","Chen, R., Sheng, H., Yang, D., Wang, S., Cui, Z., & Cong, R. (2023). Take Your Model Further: A General Post-refinement Network for Light Field Disparity Estimation via BadPix Correction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 331-339. https://doi.org/10.1609/aaai.v37i1.25106","Abstract 					Most existing light field (LF) disparity estimation algorithms focus on handling occlusion, texture-less or other areas that harm LF structure to improve accuracy, while ignoring other potential modeling ideas. In this paper, we propose a novel idea called Bad Pixel (BadPix) correction for method modeling, then implement a general post-refinement network for LF disparity estimation: Bad-pixel Correction Network (BpCNet). Given an initial disparity map generated by a specific algorithm, we assume that all BadPixs on it are in a small range. Then BpCNet is modeled as a fine-grained search strategy, and a more accurate result can be obtained by evaluating the consistency of LF images in this limited range. Due to the assumption and the consistency between input and output, BpCNet can perform as a  general  post-refinement network, and can work on almost all existing algorithms iteratively.  We demonstrate the feasibility of our  theory through extensive experiments, and achieve remarkable performance on the HCI 4D Light Field Benchmark.","https://ojs.aaai.org/index.php/AAAI/article/view/25106/24878"
"25107","Improving Dynamic HDR Imaging with Fusion Transformer","['Rufeng Chen', 'Bolun Zheng', 'Hua Zhang', 'Quan Chen', 'Chenggang Yan', 'Gregory Slabaugh', 'Shanxin Yuan']","['Hangzhou Dianzi University', 'Hangzhou Dianzi Universiy', 'Hangzhou Dianzi University', 'Hangzhou Dianzi University', 'Hangzhou Dianzi University', 'Queen Mary University of London', 'Queen Mary University of London']","['CV: Computational Photography', 'Image & Video Synthesis']","Chen, R., Zheng, B., Zhang, H., Chen, Q., Yan, C., Slabaugh, G., & Yuan, S. (2023). Improving Dynamic HDR Imaging with Fusion Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 340-349. https://doi.org/10.1609/aaai.v37i1.25107","Abstract 					Reconstructing a High Dynamic Range (HDR) image from several Low Dynamic Range (LDR) images with different exposures is a challenging task, especially in the presence of camera and object motion. Though existing models using convolutional neural networks (CNNs) have made great progress, challenges still exist, e.g., ghosting artifacts. Transformers, originating from the field of natural language processing, have shown success in computer vision tasks, due to their ability to address a large receptive field even within a single layer. In this paper, we propose a transformer model for HDR imaging. Our pipeline includes three steps: alignment, fusion, and reconstruction. The key component is the HDR transformer module. Through experiments and ablation studies, we demonstrate that our model outperforms the state-of-the-art by large margins on several popular public datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25107/24879"
"25108","Self-Supervised Joint Dynamic Scene Reconstruction and Optical Flow Estimation for Spiking Camera","['Shiyan Chen', 'Zhaofei Yu', 'Tiejun Huang']","['Peking University', 'Peking University', 'Peking University']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Low Level & Physics-Based Vision', 'ML: Unsupervised & Self-Supervised Learning']","Chen, S., Yu, Z., & Huang, T. (2023). Self-Supervised Joint Dynamic Scene Reconstruction and Optical Flow Estimation for Spiking Camera. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 350-358. https://doi.org/10.1609/aaai.v37i1.25108","Abstract 					Spiking camera, a novel retina-inspired vision sensor, has shown its great potential for capturing high-speed dynamic scenes with a sampling rate of 40,000 Hz. The spiking camera abandons the concept of exposure window, with each of its photosensitive units continuously capturing photons and firing spikes asynchronously. However, the special sampling mechanism prevents the frame-based algorithm from being used to spiking camera. It remains to be a challenge to reconstruct dynamic scenes and perform common computer vision tasks for spiking camera. In this paper, we propose a self-supervised joint learning framework for optical flow estimation and reconstruction of spiking camera. The framework reconstructs clean frame-based spiking representations in a self-supervised manner, and then uses them to train the optical flow networks. We also propose an optical flow based inverse rendering process to achieve self-supervision by minimizing the difference with respect to the original spiking temporal aggregation image. The experimental results demonstrate that our method bridges the gap between synthetic and real-world scenes and achieves desired results in real-world scenarios. To the best of our knowledge, this is the first attempt to jointly reconstruct dynamic scenes and estimate optical flow for spiking camera from a self-supervised learning perspective.","https://ojs.aaai.org/index.php/AAAI/article/view/25108/24880"
"25109","Bidirectional Optical Flow NeRF: High Accuracy and High Quality under Fewer Views","['Shuo Chen', 'Binbin Yan', 'Xinzhu Sang', 'Duo Chen', 'Peng Wang', 'Xiao Guo', 'Chongli Zhong', 'Huaming Wan']","['Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications']","['CV: 3D Computer Vision', 'CV: Computational Photography', 'Image & Video Synthesis']","Chen, S., Yan, B., Sang, X., Chen, D., Wang, P., Guo, X., Zhong, C., & Wan, H. (2023). Bidirectional Optical Flow NeRF: High Accuracy and High Quality under Fewer Views. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 359-368. https://doi.org/10.1609/aaai.v37i1.25109","Abstract 					Neural Radiance Fields (NeRF) can implicitly represent 3D-consistent RGB images and geometric by optimizing an underlying continuous volumetric scene function using a sparse set of input views, which has greatly benefited view synthesis tasks. However, NeRF fails to estimate correct geometry when given fewer views, resulting in failure to synthesize novel views. Existing works rely on introducing depth images or adding depth estimation networks to resolve the problem of poor synthetic view in NeRF with fewer views. However, due to the lack of spatial consistency of the single-depth image and the poor performance of depth estimation with fewer views, the existing methods still have challenges in addressing this problem. So this paper proposes Bidirectional Optical Flow NeRF(BOF-NeRF), which addresses this problem by mining optical flow information between 2D images. Our key insight is that utilizing 2D optical flow images to design a loss can effectively guide NeRF to learn the correct geometry and synthesize the right novel view. We also propose a view-enhanced fusion method based on geometry and color consistency to solve the problem of novel view details loss in NeRF. We conduct extensive experiments on the NeRF-LLFF and DTU MVS benchmarks for novel view synthesis tasks with fewer images in different complex real scenes. We further demonstrate the robustness of BOF-NeRF under different baseline distances on the Middlebury dataset. In all cases, BOF-NeRF outperforms current state-of-the-art baselines for novel view synthesis and scene geometry estimation.","https://ojs.aaai.org/index.php/AAAI/article/view/25109/24881"
"25110","Scalable Spatial Memory for Scene Rendering and Navigation","['Wen-Cheng Chen', 'Chu-Song Chen', 'Wei-Chen Chiu', 'Min-Chun Hu']","['National Cheng Kung University', 'National Taiwan University', 'National Chiao Tung University', 'National Tsing Hua University']","['CV: Scene Analysis & Understanding', 'CV: 3D Computer Vision', 'CV: Vision for Robotics & Autonomous Driving']","Chen, W.-C., Chen, C.-S., Chiu, W.-C., & Hu, M.-C. (2023). Scalable Spatial Memory for Scene Rendering and Navigation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 369-377. https://doi.org/10.1609/aaai.v37i1.25110","Abstract 					Neural scene representation and rendering methods have shown promise in learning the implicit form of scene structure without supervision. However, the implicit representation learned in most existing methods is non-expandable and cannot be inferred online for novel scenes, which makes the learned representation difficult to be applied across different reinforcement learning (RL) tasks. In this work, we introduce Scene Memory Network (SMN) to achieve online spatial memory construction and expansion for view rendering in novel scenes. SMN models the camera projection and back-projection as spatially aware memory control processes, where the memory values store the information of the partial 3D area, and the memory keys indicate the position of that area. The memory controller can learn the geometry property from observations without the camera's intrinsic parameters and depth supervision. We further apply the memory constructed by SMN to exploration and navigation tasks. The experimental results reveal the generalization ability of our proposed SMN in large-scale scene synthesis and its potential to improve the performance of spatial RL tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25110/24882"
"25111","Hybrid CNN-Transformer Feature Fusion for Single Image Deraining","['Xiang Chen', 'Jinshan Pan', 'Jiyang Lu', 'Zhentao Fan', 'Hao Li']","['Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Shenyang Aerospace University', 'Shenyang Aerospace University', 'Nanjing University of Science and Technology']","['CV: Low Level & Physics-Based Vision', 'CV: Applications', 'CV: Computational Photography', 'Image & Video Synthesis', 'CV: Representation Learning for Vision']","Chen, X., Pan, J., Lu, J., Fan, Z., & Li, H. (2023). Hybrid CNN-Transformer Feature Fusion for Single Image Deraining. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 378-386. https://doi.org/10.1609/aaai.v37i1.25111","Abstract 					Since rain streaks exhibit diverse geometric appearances and irregular overlapped phenomena, these complex characteristics challenge the design of an effective single image deraining model. To this end, rich local-global information representations are increasingly indispensable for better satisfying rain removal. In this paper, we propose a lightweight Hybrid CNN-Transformer Feature Fusion Network (dubbed as HCT-FFN) in a stage-by-stage progressive manner, which can harmonize these two architectures to help image restoration by leveraging their individual learning strengths. Specifically, we stack a sequence of the degradation-aware mixture of experts (DaMoE) modules in the CNN-based stage, where appropriate local experts adaptively enable the model to emphasize spatially-varying rain distribution features. As for the Transformer-based stage, a background-aware vision Transformer (BaViT) module is employed to complement spatially-long feature dependencies of images, so as to achieve global texture recovery while preserving the required structure. Considering the indeterminate knowledge discrepancy among CNN features and Transformer features, we introduce an interactive fusion branch at adjacent stages to further facilitate the reconstruction of high-quality deraining results. Extensive evaluations show the effectiveness and extensibility of our developed HCT-FFN. The source code is available at https://github.com/cschenxiang/HCT-FFN.","https://ojs.aaai.org/index.php/AAAI/article/view/25111/24883"
"25112","MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection","['Yingxian Chen', 'Zhengzhe Liu', 'Baoheng Zhang', 'Wilton Fok', 'Xiaojuan Qi', 'Yik-Chung Wu']","['The University of Hong Kong', 'The Chinese University of Hong Kong', 'The University of HongKong', 'The University of Hong Kong', 'The University of Hong Kong', 'The University of Hong Kong']","['CV: Video Understanding & Activity Analysis', 'CV: Applications', 'CV: Motion & Tracking', 'CV: Scene Analysis & Understanding']","Chen, Y., Liu, Z., Zhang, B., Fok, W., Qi, X., & Wu, Y.-C. (2023). MGFN: Magnitude-Contrastive Glance-and-Focus Network for Weakly-Supervised Video Anomaly Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 387-395. https://doi.org/10.1609/aaai.v37i1.25112","Abstract 					Weakly supervised detection of anomalies in surveillance videos is a challenging task. Going beyond existing works that have deficient capabilities to localize anomalies in long videos, we propose a novel glance and focus network to effectively integrate spatial-temporal information for accurate anomaly detection. In addition, we empirically found that existing approaches that use feature magnitudes to represent the degree of anomalies typically ignore the effects of scene variations, and hence result in sub-optimal performance due to the inconsistency of feature magnitudes across scenes. To address this issue, we propose the Feature Amplification Mechanism and a Magnitude Contrastive Loss to enhance the discriminativeness of feature magnitudes for detecting anomalies. Experimental results on two large-scale benchmarks UCF-Crime and XD-Violence manifest that our method outperforms state-of-the-art approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/25112/24884"
"25113","Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval","['Yizhen Chen', 'Jie Wang', 'Lijian Lin', 'Zhongang Qi', 'Jin Ma', 'Ying Shan']","['IPS Search, Tencent PCG', 'IPS Search, Tencent PCG', 'ARC Lab, Tencent PCG', 'ARC Lab, Tencent PCG', 'IPS Search, Tencent PCG', 'ARC Lab, Tencent PCG']","['CV: Image and Video Retrieval', 'CV: Language and Vision', 'CV: Multi-modal Vision', 'CV: Representation Learning for Vision', 'CV: Video Understanding & Activity Analysis']","Chen, Y., Wang, J., Lin, L., Qi, Z., Ma, J., & Shan, Y. (2023). Tagging before Alignment: Integrating Multi-Modal Tags for Video-Text Retrieval. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 396-404. https://doi.org/10.1609/aaai.v37i1.25113","Abstract 					Vision-language alignment learning for video-text retrieval arouses a lot of attention in recent years. Most of the existing methods either transfer the knowledge of image-text pretraining model to video-text retrieval task without fully exploring the multi-modal information of videos, or simply fuse multi-modal features in a brute force manner without explicit guidance. In this paper, we integrate multi-modal information in an explicit manner by tagging, and use the tags as the anchors for better video-text alignment. Various pretrained experts are utilized for extracting the information of multiple modalities, including object, person, motion, audio, etc. To take full advantage of these information, we propose the TABLE (TAgging Before aLignmEnt) network, which consists of a visual encoder, a tag encoder, a text encoder, and a tag-guiding cross-modal encoder for jointly encoding multi-frame visual features and multi-modal tags information. Furthermore, to strengthen the interaction between video and text, we build a joint cross-modal encoder with the triplet input of [vision, tag, text] and perform two additional supervised tasks, Video Text Matching (VTM) and Masked Language Modeling (MLM). Extensive experimental results demonstrate that the TABLE model is capable of achieving State-Of-The-Art (SOTA) performance on various video-text retrieval benchmarks, including MSR-VTT, MSVD, LSMDC and DiDeMo.","https://ojs.aaai.org/index.php/AAAI/article/view/25113/24885"
"25114","DUET: Cross-Modal Semantic Grounding for Contrastive Zero-Shot Learning","['Zhuo Chen', 'Yufeng Huang', 'Jiaoyan Chen', 'Yuxia Geng', 'Wen Zhang', 'Yin Fang', 'Jeff Z. Pan', 'Huajun Chen']","['College of Computer Science and Technology, Zhejiang University\nDonghai Laboratory, Zhoushan 316021, China\nAlibaba-Zhejiang University Joint Institute of Frontier Technologies', 'School of Software Technology, Zhejiang University\nAlibaba-Zhejiang University Joint Institute of Frontier Technologies', 'Department of Computer Science, The University of Manchester', 'College of Computer Science and Technology, Zhejiang University\nAlibaba-Zhejiang University Joint Institute of Frontier Technologies', 'School of Software Technology, Zhejiang University\nAlibaba-Zhejiang University Joint Institute of Frontier Technologies', 'College of Computer Science and Technology, Zhejiang University\nAlibaba-Zhejiang University Joint Institute of Frontier Technologies', 'School of Informatics, The University of Edinburgh', 'College of Computer Science and Technology, Zhejiang University\nDonghai Laboratory, Zhoushan 316021, China\nAlibaba-Zhejiang University Joint Institute of Frontier Technologies']","['CV: Multi-modal Vision', 'CV: Language and Vision', 'CV: Representation Learning for Vision', 'DMKM: Mining of Visual', 'Multimedia & Multimodal Data']","Chen, Z., Huang, Y., Chen, J., Geng, Y., Zhang, W., Fang, Y., Z. Pan, J., & Chen, H. (2023). DUET: Cross-Modal Semantic Grounding for Contrastive Zero-Shot Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 405-413. https://doi.org/10.1609/aaai.v37i1.25114","Abstract 					Zero-shot learning (ZSL) aims to predict unseen classes whose samples have never appeared during training. One of the most effective and widely used semantic information for zero-shot image classification are attributes which are annotations for class-level visual characteristics. However, the current methods often fail to discriminate those subtle visual distinctions between images due to not only the shortage of fine-grained annotations, but also the attribute imbalance and co-occurrence. In this paper, we present a transformer-based end-to-end ZSL method named DUET, which integrates latent semantic knowledge from the pre-trained language models (PLMs) via a self-supervised multi-modal learning paradigm. Specifically, we (1) developed a cross-modal semantic grounding network to investigate the model's capability of disentangling semantic attributes from the images; (2) applied an attribute-level contrastive learning strategy to further enhance the model's discrimination on fine-grained visual characteristics against the attribute co-occurrence and imbalance; (3) proposed a multi-task learning policy for considering multi-model objectives. We find that our DUET can achieve state-of-the-art performance on three standard ZSL benchmarks and a knowledge graph equipped ZSL benchmark. Its components are effective and its predictions are interpretable.","https://ojs.aaai.org/index.php/AAAI/article/view/25114/24886"
"25115","Imperceptible Adversarial Attack via Invertible Neural Networks","['Zihan Chen', 'Ziyue Wang', 'Jun-Jie Huang', 'Wentao Zhao', 'Xiao Liu', 'Dejian Guan']","['National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology']","['CV: Adversarial Attacks & Robustness']","Chen, Z., Wang, Z., Huang, J.-J., Zhao, W., Liu, X., & Guan, D. (2023). Imperceptible Adversarial Attack via Invertible Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 414-424. https://doi.org/10.1609/aaai.v37i1.25115","Abstract 					Adding perturbations via utilizing auxiliary gradient information or discarding existing details of the benign images are two common approaches for generating adversarial examples. Though visual imperceptibility is the desired property of adversarial examples, conventional adversarial attacks still generate traceable adversarial perturbations. In this paper, we introduce a novel Adversarial Attack via Invertible Neural Networks (AdvINN) method to produce robust and imperceptible adversarial examples. Specifically, AdvINN fully takes advantage of the information preservation property of Invertible Neural Networks and thereby generates adversarial examples by simultaneously adding class-specific semantic information of the target class and dropping discriminant information of the original class. Extensive experiments on CIFAR-10, CIFAR-100, and ImageNet-1K demonstrate that the proposed AdvINN method can produce less imperceptible adversarial images than the state-of-the-art methods and AdvINN yields more robust adversarial examples with high confidence compared to other adversarial attacks. Code is available at https://github.com/jjhuangcs/AdvINN.","https://ojs.aaai.org/index.php/AAAI/article/view/25115/24887"
"25116","Cross-Modality Person Re-identification with Memory-Based Contrastive Embedding","['De Cheng', 'Xiaolong Wang', 'Nannan Wang', 'Zhen Wang', 'Xiaoyu Wang', 'Xinbo Gao']","['Xidian University', 'Xidian university', 'Xidian University', 'Zhejiang Lab', 'University of Science and Technology of China', 'Chongqing University of Posts and Telecommunications']","['CV: Representation Learning for Vision', 'CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Multi-modal Vision', 'ML: Multimodal Learning']","Cheng, D., Wang, X., Wang, N., Wang, Z., Wang, X., & Gao, X. (2023). Cross-Modality Person Re-identification with Memory-Based Contrastive Embedding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 425-432. https://doi.org/10.1609/aaai.v37i1.25116","Abstract 					Visible-infrared person re-identification (VI-ReID) aims to retrieve the person images of the same identity from the RGB to infrared image space, which is very important for real-world surveillance system. In practice, VI-ReID is more challenging due to the heterogeneous modality discrepancy, which further aggravates the challenges of traditional single-modality person ReID problem, i.e., inter-class confusion and intra-class variations. In this paper, we propose an aggregated memory-based cross-modality deep metric learning framework, which benefits from the increasing number of learned modality-aware and modality-agnostic centroid proxies for cluster contrast and mutual information learning. Furthermore, to suppress the modality discrepancy, the proposed cross-modality alignment objective simultaneously utilizes both historical and up-to-date learned cluster proxies for enhanced cross-modality association. Such training mechanism helps to obtain hard positive references through increased diversity of learned cluster proxies, and finally achieves stronger ``pulling close'' effect between cross-modality image features. Extensive experiment results demonstrate the effectiveness of the proposed method, surpassing state-of-the-art works significantly by a large margin on the commonly used VI-ReID datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25116/24888"
"25117","User-Controllable Arbitrary Style Transfer via Entropy Regularization","['Jiaxin Cheng', 'Yue Wu', 'Ayush Jaiswal', 'Xu Zhang', 'Pradeep Natarajan', 'Prem Natarajan']","['USC Information Sciences Institute', 'Amazon Alexa Natural Understanding', 'Amazon Alexa Natural Understanding', 'Amazon Alexa Natural Understanding', 'Amazon Alexa Natural Understanding', 'Amazon Alexa Natural Understanding']","['CV: Applications', 'CV: Computational Photography', 'Image & Video Synthesis']","Cheng, J., Wu, Y., Jaiswal, A., Zhang, X., Natarajan, P., & Natarajan, P. (2023). User-Controllable Arbitrary Style Transfer via Entropy Regularization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 433-441. https://doi.org/10.1609/aaai.v37i1.25117","Abstract 					Ensuring the overall end-user experience is a challenging task in arbitrary style transfer (AST) due to the subjective nature of style transfer quality. A good practice is to provide users many instead of one AST result. However, existing approaches require to run multiple AST models or inference a diversified AST (DAST) solution multiple times, and thus they are either slow in speed or limited in diversity. In this paper, we propose a novel solution ensuring both efficiency and diversity for generating multiple user-controllable AST results by systematically modulating AST behavior at run-time. We begin with reformulating three prominent AST methods into a unified assign-and-mix problem and discover that the entropies of their assignment matrices exhibit a large variance. We then solve the unified problem in an optimal transport framework using the Sinkhorn-Knopp algorithm with a user input ε to control the said entropy and thus modulate stylization. Empirical results demonstrate the superiority of the proposed solution, with speed and stylization quality comparable to or better than existing AST and significantly more diverse than previous DAST works. Code is available at https://github.com/cplusx/eps-Assign-and-Mix.","https://ojs.aaai.org/index.php/AAAI/article/view/25117/24889"
"25118","Neural Architecture Search for Wide Spectrum Adversarial Robustness","['Zhi Cheng', 'Yanxi Li', 'Minjing Dong', 'Xiu Su', 'Shan You', 'Chang Xu']","['University of Sydney', 'University of Sydney', 'University of Sydney', 'University of Sydney', 'SenseTime', 'University of Sydney']","['CV: Adversarial Attacks & Robustness', 'ML: Deep Neural Architectures', 'ML: Optimization']","Cheng, Z., Li, Y., Dong, M., Su, X., You, S., & Xu, C. (2023). Neural Architecture Search for Wide Spectrum Adversarial Robustness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 442-451. https://doi.org/10.1609/aaai.v37i1.25118","Abstract 					One major limitation of CNNs is that they are vulnerable to adversarial attacks. Currently, adversarial robustness in neural networks is commonly optimized with respect to a small pre-selected adversarial noise strength, causing them to have potentially limited performance when under attack by larger adversarial noises in real-world scenarios. In this research, we aim to find Neural Architectures that have improved robustness on a wide range of adversarial noise strengths through Neural Architecture Search. In detail, we propose a lightweight Adversarial Noise Estimator to reduce the high cost of generating adversarial noise with respect to different strengths. Besides, we construct an Efficient Wide Spectrum Searcher to reduce the cost of adjusting network architecture with the large adversarial validation set during the search. With the two components proposed, the number of adversarial noise strengths searched can be increased significantly while having a limited increase in search time. Extensive experiments on benchmark datasets such as CIFAR and ImageNet demonstrate that with a significantly richer search signal in robustness, our method can find architectures with improved overall robustness while having a limited impact on natural accuracy and around 40% reduction in search time compared with the naive approach of searching. Codes available at: https://github.com/zhicheng2T0/Wsr-NAS.git","https://ojs.aaai.org/index.php/AAAI/article/view/25118/24890"
"25119","Adversarial Alignment for Source Free Object Detection","['Qiaosong Chu', 'Shuyan Li', 'Guangyi Chen', 'Kai Li', 'Xiu Li']","['Tsinghua Shenzhen International Graduate School, Shenzhen, China\nTsinghua University, Beijing, China', 'Tsinghua Shenzhen International Graduate School, Shenzhen, China\nTsinghua University, Beijing, China', 'Carnegie Mellon University, Pittsburgh PA, USA\nMohamed bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE', 'NEC LABORATORIES AMERICA, INC', 'Tsinghua Shenzhen International Graduate School, Shenzhen, China\nTsinghua University, Beijing, China']","['CV: Object Detection & Categorization', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Chu, Q., Li, S., Chen, G., Li, K., & Li, X. (2023). Adversarial Alignment for Source Free Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 452-460. https://doi.org/10.1609/aaai.v37i1.25119","Abstract 					Source-free object detection (SFOD) aims to transfer a detector pre-trained on a label-rich source domain to an unlabeled target domain without seeing source data. While most existing SFOD methods generate pseudo labels via a source-pretrained model to guide training, these pseudo labels usually contain high noises due to heavy domain discrepancy. In order to obtain better pseudo supervisions, we divide the target domain into source-similar and source-dissimilar parts and align them in the feature space by adversarial learning.Specifically, we design a detection variance-based criterion to divide the target domain. This criterion is motivated by a finding that larger detection variances denote higher recall and larger similarity to the source domain. Then we incorporate an adversarial module into a mean teacher framework to drive the feature spaces of these two subsets indistinguishable. Extensive experiments on multiple cross-domain object detection datasets demonstrate that our proposed method consistently outperforms the compared SFOD methods. Our implementation is available at https://github.com/ChuQiaosong.","https://ojs.aaai.org/index.php/AAAI/article/view/25119/24891"
"25120","Weakly Supervised 3D Multi-Person Pose Estimation for Large-Scale Scenes Based on Monocular Camera and Single LiDAR","['Peishan Cong', 'Yiteng Xu', 'Yiming Ren', 'Juze Zhang', 'Lan Xu', 'Jingya Wang', 'Jingyi Yu', 'Yuexin Ma']","['ShanghaiTech University', 'ShanghaiTech University', 'ShanghaiTech University', 'ShanghaiTech University', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging']","['CV: 3D Computer Vision', 'CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Multi-modal Vision']","Cong, P., Xu, Y., Ren, Y., Zhang, J., Xu, L., Wang, J., Yu, J., & Ma, Y. (2023). Weakly Supervised 3D Multi-Person Pose Estimation for Large-Scale Scenes Based on Monocular Camera and Single LiDAR. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 461-469. https://doi.org/10.1609/aaai.v37i1.25120","Abstract 					Depth estimation is usually ill-posed and ambiguous for monocular camera-based 3D multi-person pose estimation. Since LiDAR can capture accurate depth information in long-range scenes, it can benefit both the global localization of individuals and the 3D pose estimation by providing rich geometry features. Motivated by this, we propose a monocular camera and single LiDAR-based method for 3D multi-person pose estimation in large-scale scenes, which is easy to deploy and insensitive to light. Specifically, we design an effective fusion strategy to take advantage of multi-modal input data, including images and point cloud, and make full use of temporal information to guide the network to learn natural and coherent human motions. Without relying on any 3D pose annotations, our method exploits the inherent geometry constraints of point cloud for self-supervision and utilizes 2D keypoints on images for weak supervision. Extensive experiments on public datasets and our newly collected dataset demonstrate the superiority and generalization capability of our proposed method. Project homepage is at \url{https://github.com/4DVLab/FusionPose.git}.","https://ojs.aaai.org/index.php/AAAI/article/view/25120/24892"
"25121","OctFormer: Efficient Octree-Based Transformer for Point Cloud Compression with Local Enhancement","['Mingyue Cui', 'Junhua Long', 'Mingjian Feng', 'Boyang Li', 'Huang Kai']","['Sun Yat-sen University', 'Sun Yat-sen University', 'Sun Yat-sen University', 'Sun Yat-sen University', 'Sun Yat-Sen University']","['CV: 3D Computer Vision', 'CV: Applications', 'APP: Internet of Things', 'Sensor Networks & Smart Cities', 'ROB: Applications']","Cui, M., Long, J., Feng, M., Li, B., & Kai, H. (2023). OctFormer: Efficient Octree-Based Transformer for Point Cloud Compression with Local Enhancement. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 470-478. https://doi.org/10.1609/aaai.v37i1.25121","Abstract 					Point cloud compression with a higher compression ratio and tiny loss is essential for efficient data transportation. However, previous methods that depend on 3D convolution or frequent multi-head self-attention operations bring huge computations. To address this problem, we propose an octree-based Transformer compression method called OctFormer, which does not rely on the occupancy information of sibling nodes. Our method uses non-overlapped context windows to construct octree node sequences and share the result of a multi-head self-attention operation among a sequence of nodes. Besides, we introduce a locally-enhance module for exploiting the sibling features and a positional encoding generator for enhancing the translation invariance of the octree node sequence. Compared to the previous state-of-the-art works, our method obtains up to 17% Bpp savings compared to the voxel-context-based baseline and saves an overall 99% coding time compared to the attention-based baseline.","https://ojs.aaai.org/index.php/AAAI/article/view/25121/24893"
"25122","Dual-Domain Attention for Image Deblurring","['Yuning Cui', 'Yi Tao', 'Wenqi Ren', 'Alois Knoll']","['Technical University of Munich', 'MIT Universal Village Program', 'Shenzhen Campus of Sun Yat-sen University', 'Technical University of Munich']","['CV: Low Level & Physics-Based Vision', 'CV: Applications', 'CV: Language and Vision', 'CV: Learning & Optimization for CV', 'CV: Other Foundations of Computer Vision', 'CV: Representation Learning for Vision', 'ML: Applications', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms']","Cui, Y., Tao, Y., Ren, W., & Knoll, A. (2023). Dual-Domain Attention for Image Deblurring. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 479-487. https://doi.org/10.1609/aaai.v37i1.25122","Abstract 					As a long-standing and challenging task, image deblurring aims to reconstruct the latent sharp image from its degraded counterpart. In this study, to bridge the gaps between degraded/sharp image pairs in the spatial and frequency domains simultaneously,  we develop the dual-domain attention mechanism for image deblurring. Self-attention is widely used in vision tasks, however, due to the quadratic complexity, it is not applicable to image deblurring with high-resolution images. To alleviate this issue, we propose a novel spatial attention module by implementing self-attention in the style of dynamic group convolution for integrating information from the local region, enhancing the representation learning capability and reducing computational burden. Regarding frequency domain learning, many frequency-based deblurring approaches either treat the spectrum as a whole or decompose frequency components in a complicated manner. In this work, we devise a frequency attention module to compactly decouple the spectrum into distinct frequency parts and accentuate the informative part with extremely lightweight learnable parameters. Finally, we incorporate attention modules into a U-shaped network. Extensive comparisons with prior arts on the common benchmarks show that our model, named Dual-domain Attention Network (DDANet), obtains comparable results with a significantly improved inference speed.","https://ojs.aaai.org/index.php/AAAI/article/view/25122/24894"
"25123","Multi-Resolution Monocular Depth Map Fusion by Self-Supervised Gradient-Based Composition","['Yaqiao Dai', 'Renjiao Yi', 'Chenyang Zhu', 'Hongjun He', 'Kai Xu']","['National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology']","['CV: 3D Computer Vision', 'CV: Scene Analysis & Understanding']","Dai, Y., Yi, R., Zhu, C., He, H., & Xu, K. (2023). Multi-Resolution Monocular Depth Map Fusion by Self-Supervised Gradient-Based Composition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 488-496. https://doi.org/10.1609/aaai.v37i1.25123","Abstract 					Monocular depth estimation is a challenging problem on which deep neural networks have demonstrated great potential. However, depth maps predicted by existing deep models usually lack fine-grained details due to convolution operations and down-samplings in networks. We find that increasing input resolution is helpful to preserve more local details while the estimation at low resolution is more accurate globally. Therefore, we propose a novel depth map fusion module to combine the advantages of estimations with multi-resolution inputs. Instead of merging the low- and high-resolution estimations equally, we adopt the core idea of Poisson fusion, trying to implant the gradient domain of high-resolution depth into the low-resolution depth. While classic Poisson fusion requires a fusion mask as supervision, we propose a self-supervised framework based on guided image filtering. We demonstrate that this gradient-based composition performs much better at noisy immunity, compared with the state-of-the-art depth map fusion method. Our lightweight depth fusion is one-shot and runs in real-time, making it 80X faster than a state-of-the-art depth fusion method. Quantitative evaluations demonstrate that the proposed method can be integrated into many fully convolutional monocular depth estimation backbones with a significant performance boost, leading to state-of-the-art results of detail enhancement on depth maps. Codes are released at https://github.com/yuinsky/gradient-based-depth-map-fusion.","https://ojs.aaai.org/index.php/AAAI/article/view/25123/24895"
"25124","Improving Crowded Object Detection via Copy-Paste","['Jiangfan Deng', 'Dewen Fan', 'Xiaosong Qiu', 'Feng Zhou']","['Aibee Inc.', 'Aibee Inc.', 'Aibee Inc.', 'Aibee Inc.']","['CV: Scene Analysis & Understanding', 'CV: Object Detection & Categorization']","Deng, J., Fan, D., Qiu, X., & Zhou, F. (2023). Improving Crowded Object Detection via Copy-Paste. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 497-505. https://doi.org/10.1609/aaai.v37i1.25124","Abstract 					Crowdedness caused by overlapping among similar objects is a ubiquitous challenge in the field of 2D visual object detection. In this paper, we first underline two main effects of the crowdedness issue: 1) IoU-confidence correlation disturbances (ICD) and 2) confused de-duplication (CDD). Then we explore a pathway of cracking these nuts from the perspective of data augmentation. Primarily, a particular copy- paste scheme is proposed towards making crowded scenes. Based on this operation, we first design a ""consensus learning"" method to further resist the ICD problem and then find out the pasting process naturally reveals a pseudo ""depth"" of object in the scene, which can be potentially used for alleviating CDD dilemma. Both methods are derived from magical using of the copy-pasting without extra cost for hand-labeling. Experiments show that our approach can easily improve the state-of-the-art detector in typical crowded detection task by more than 2% without any bells and whistles. Moreover, this work can outperform existing data augmentation strategies in crowded scenario.","https://ojs.aaai.org/index.php/AAAI/article/view/25124/24896"
"25125","Defending Backdoor Attacks on Vision Transformer via Patch Processing","['Khoa D. Doan', 'Yingjie Lao', 'Peng Yang', 'Ping Li']","['VinUniversity', 'Clemson University', 'Meta Corporation', 'LinkedIn Corporation']","['CV: Bias', 'Fairness & Privacy']","Doan, K. D., Lao, Y., Yang, P., & Li, P. (2023). Defending Backdoor Attacks on Vision Transformer via Patch Processing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 506-515. https://doi.org/10.1609/aaai.v37i1.25125","Abstract 					Vision Transformers (ViTs) have a radically different architecture with significantly less inductive bias than Convolutional Neural Networks. Along with the improvement in performance, security and robustness of ViTs are also of great importance to study. In contrast to many recent works that exploit the robustness of ViTs against adversarial examples, this paper investigates a representative causative attack, i.e., backdoor. We first examine the vulnerability of ViTs against various backdoor attacks and find that ViTs are also quite vulnerable to existing  attacks. However, we observe that the clean-data accuracy and backdoor attack success rate of ViTs respond distinctively to patch transformations before the positional encoding. Then, based on this finding, we propose an effective method for ViTs to defend both patch-based and blending-based trigger backdoor attacks via patch processing. The performances are evaluated on several benchmark datasets, including CIFAR10, GTSRB, and TinyImageNet, which show the proposedds defense is very successful in mitigating backdoor attacks for ViTs. To the best of our knowledge, this paper presents the first defensive strategy that utilizes a unique characteristic of ViTs against backdoor attacks.","https://ojs.aaai.org/index.php/AAAI/article/view/25125/24897"
"25126","Head-Free Lightweight Semantic Segmentation with Linear Transformer","['Bo Dong', 'Pichao Wang', 'Fan Wang']","['Alibaba Group', 'Alibaba Group', 'Alibaba Group']","['CV: Segmentation']","Dong, B., Wang, P., & Wang, F. (2023). Head-Free Lightweight Semantic Segmentation with Linear Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 516-524. https://doi.org/10.1609/aaai.v37i1.25126","Abstract 					Existing semantic segmentation works have been mainly focused on designing effective decoders; however, the computational load introduced by the overall structure has long been ignored, which hinders their applications on resource-constrained hardwares. In this paper, we propose a head-free lightweight architecture specifically for semantic segmentation, named Adaptive Frequency Transformer (AFFormer). AFFormer adopts a parallel architecture to leverage prototype representations as specific learnable local descriptions which replaces the decoder and preserves the rich image semantics on high-resolution features. Although removing the decoder compresses most of the computation, the accuracy of the parallel structure is still limited by low computational resources. Therefore, we employ heterogeneous operators (CNN and vision Transformer) for pixel embedding and prototype representations to further save computational costs. Moreover, it is very difficult to linearize the complexity of the vision Transformer from the perspective of spatial domain. Due to the fact that semantic segmentation is very sensitive to frequency information, we construct a lightweight prototype learning block with adaptive frequency filter of complexity O(n) to replace standard self attention with O(n^2). Extensive experiments on widely adopted datasets demonstrate that AFFormer achieves superior accuracy while retaining only 3M parameters. On the ADE20K dataset, AFFormer achieves 41.8 mIoU and 4.6 GFLOPs, which is 4.4 mIoU higher than Segformer, with  45% less GFLOPs. On the Cityscapes dataset, AFFormer achieves 78.7 mIoU and 34.4 GFLOPs, which is 2.5 mIoU higher than Segformer with 72.5% less GFLOPs. Code is available at https://github.com/dongbo811/AFFormer.","https://ojs.aaai.org/index.php/AAAI/article/view/25126/24898"
"25127","Hierarchical Contrast for Unsupervised Skeleton-Based Action Representation Learning","['Jianfeng Dong', 'Shengkai Sun', 'Zhonglin Liu', 'Shujie Chen', 'Baolong Liu', 'Xun Wang']","['College of Computer Science and Technology, Zhejiang Gongshang University\nZhejiang Key Lab of E-Commerce', 'College of Computer Science and Technology, Zhejiang Gongshang University', 'College of Computer Science and Technology, Zhejiang Gongshang University', 'College of Computer Science and Technology, Zhejiang GongShang University\nZhejiang Key Lab of E-Commerce', 'College of Computer Science and Technology, Zhejiang Gongshang University\nZhejiang Key Lab of E-Commerce', 'College of Computer Science and Technology, Zhejiang Gongshang University\nZhejiang Key Lab of E-Commerce']","['CV: Representation Learning for Vision', 'CV: Video Understanding & Activity Analysis', 'CV: Motion & Tracking', 'CV: Image and Video Retrieval']","Dong, J., Sun, S., Liu, Z., Chen, S., Liu, B., & Wang, X. (2023). Hierarchical Contrast for Unsupervised Skeleton-Based Action Representation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 525-533. https://doi.org/10.1609/aaai.v37i1.25127","Abstract 					This paper targets unsupervised skeleton-based action representation learning and proposes a new Hierarchical Contrast (HiCo) framework. Different from the existing contrastive-based solutions that typically represent an input skeleton sequence into instance-level features and perform contrast holistically, our proposed HiCo represents the input into multiple-level features and performs contrast in a hierarchical manner. Specifically, given a human skeleton sequence, we represent it into multiple feature vectors of different granularities from both temporal and spatial domains via sequence-to-sequence (S2S) encoders and unified downsampling modules. Besides, the hierarchical contrast is conducted in terms of four levels: instance level, domain level, clip level, and part level. Moreover, HiCo is orthogonal to the S2S encoder, which allows us to flexibly embrace state-of-the-art S2S encoders. Extensive experiments on four datasets, i.e., NTU-60, NTU-120, PKU-I and PKU-II, show that HiCo achieves a new state-of-the-art for unsupervised skeleton-based action representation learning in two downstream tasks including action recognition and retrieval, and its learned action representation is of good transferability. Besides, we also show that our framework is effective for semi-supervised skeleton-based action recognition. Our code is available at https://github.com/HuiGuanLab/HiCo.","https://ojs.aaai.org/index.php/AAAI/article/view/25127/24899"
"25128","Exploring Tuning Characteristics of Ventral Stream’s Neurons for Few-Shot Image Classification","['Lintao Dong', 'Wei Zhai', 'Zheng-Jun Zha']","['University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China']","['CV: Object Detection & Categorization', 'ML: Bio-Inspired Learning']","Dong, L., Zhai, W., & Zha, Z.-J. (2023). Exploring Tuning Characteristics of Ventral Stream’s Neurons for Few-Shot Image Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 534-542. https://doi.org/10.1609/aaai.v37i1.25128","Abstract 					Human has the remarkable ability of learning novel objects by browsing extremely few examples, which may be attributed to the generic and robust feature extracted in the ventral stream of our brain for representing visual objects. In this sense, the tuning characteristics of ventral stream's neurons can be useful prior knowledge to improve few-shot classification. Specifically, we computationally model two groups of neurons found in ventral stream which are respectively sensitive to shape cues and color cues. Then we propose the hierarchical feature regularization method with these neuron models to regularize the backbone of a few-shot model, thus making it produce more generic and robust features for few-shot classification. In addition, to simulate the tuning characteristic that neuron firing at a higher rate in response to foreground stimulus elements compared to background elements, which we call belongingness, we design a foreground segmentation algorithm based on the observation that the foreground object usually does not appear at the edge of the picture, then multiply the foreground mask with the backbone of few-shot model. Our method is model-agnostic and can be applied to few-shot models with different backbones, training paradigms and classifiers.","https://ojs.aaai.org/index.php/AAAI/article/view/25128/24900"
"25129","Incremental-DETR: Incremental Few-Shot Object Detection via Self-Supervised Learning","['Na Dong', 'Yongqiang Zhang', 'Mingli Ding', 'Gim Hee Lee']","['National University of Singapore\nHarbin Institute of Technology', 'Harbin institute of Technology', 'Harbin institute of Technology', 'National University of Singapore']","['CV: Object Detection & Categorization', 'CV: Learning & Optimization for CV', 'CV: Representation Learning for Vision']","Dong, N., Zhang, Y., Ding, M., & Lee, G. H. (2023). Incremental-DETR: Incremental Few-Shot Object Detection via Self-Supervised Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 543-551. https://doi.org/10.1609/aaai.v37i1.25129","Abstract 					Incremental few-shot object detection aims at detecting novel classes without forgetting knowledge of the base classes with only a few labeled training data from the novel classes. Most related prior works are on incremental object detection that rely on the availability of abundant training samples per novel class that substantially limits the scalability to real-world setting where novel data can be scarce. In this paper, we propose the Incremental-DETR that does incremental few-shot object detection via fine-tuning and self-supervised learning on the DETR object detector. To alleviate severe over-fitting with few novel class data, we first fine-tune the class-specific components of DETR with self-supervision from additional object proposals generated using Selective Search as pseudo labels. We further introduce an incremental few-shot fine-tuning strategy with knowledge distillation on the class-specific components of DETR to encourage the network in detecting novel classes without forgetting the base classes. Extensive experiments conducted on standard incremental object detection and incremental few-shot object detection settings show that our approach significantly outperforms state-of-the-art methods by a large margin.  Our source code is available at https://github.com/dongnana777/Incremental-DETR.","https://ojs.aaai.org/index.php/AAAI/article/view/25129/24901"
"25130","PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers","['Xiaoyi Dong', 'Jianmin Bao', 'Ting Zhang', 'Dongdong Chen', 'Weiming Zhang', 'Lu Yuan', 'Dong Chen', 'Fang Wen', 'Nenghai Yu', 'Baining Guo']","['University of Science and Technology of China', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Cloud + AI', 'University of Science and Technology of China', 'Microsoft Cloud + AI', 'Microsoft Research Asia', 'Microsoft Research Asia', 'University of Science and Technology of China', 'Microsoft Research Asia']","['CV: Representation Learning for Vision', 'CV: Object Detection & Categorization', 'CV: Segmentation']","Dong, X., Bao, J., Zhang, T., Chen, D., Zhang, W., Yuan, L., Chen, D., Wen, F., Yu, N., & Guo, B. (2023). PeCo: Perceptual Codebook for BERT Pre-training of Vision Transformers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 552-560. https://doi.org/10.1609/aaai.v37i1.25130","Abstract 					This paper explores a better prediction target for  BERT pre-training of vision transformers. We observe that current prediction targets disagree with human perception judgment. This contradiction motivates us to learn a perceptual prediction target. We argue that perceptually similar images should stay close to each other in the prediction target space. We surprisingly find one simple yet effective idea: enforcing perceptual similarity during the dVAE training. Moreover, we adopt a self-supervised transformer model for deep feature extraction and show that it works well for calculating perceptual similarity. We demonstrate that such learned visual tokens indeed exhibit better semantic meanings, and help pre-training achieve superior transfer performance in various downstream tasks. For example, we achieve 84.5% Top-1 accuracy on ImageNet-1K with ViT-B backbone, outperforming the competitive method BEiT by +1.3% under the same pre-training epochs. Our approach also gets significant improvement on object detection and segmentation on COCO and semantic segmentation on ADE20K. Equipped with a larger backbone ViT-H, we achieve the state-of-the-art ImageNet accuracy (88.3%) among methods using only ImageNet-1K data.","https://ojs.aaai.org/index.php/AAAI/article/view/25130/24902"
"25131","Domain-General Crowd Counting in Unseen Scenarios","['Zhipeng Du', 'Jiankang Deng', 'Miaojing Shi']","[""King's College London"", 'Huawei London Research Center', ""Tongji University\nKing's College London""]","['CV: Applications']","Du, Z., Deng, J., & Shi, M. (2023). Domain-General Crowd Counting in Unseen Scenarios. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 561-570. https://doi.org/10.1609/aaai.v37i1.25131","Abstract 					Domain shift across crowd data severely hinders crowd counting models to generalize to unseen scenarios. Although domain adaptive crowd counting approaches close this gap to a certain extent, they are still dependent on the target domain data to adapt (e.g. finetune) their models to the specific domain. In this paper, we instead target to train a model based on a single source domain which can generalize well on any unseen domain. This falls into the realm of domain generalization that remains unexplored in crowd counting. We first introduce a dynamic sub-domain division scheme which divides the source domain into multiple sub-domains such that we can initiate a meta-learning framework for domain generalization. The sub-domain division is dynamically refined during the meta-learning. Next, in order to disentangle domain-invariant information from domain-specific information in image features, we design the domain-invariant and -specific crowd memory modules to re-encode image features. Two types of losses, i.e. feature reconstruction and orthogonal losses, are devised to enable this disentanglement. Extensive experiments on several standard crowd counting benchmarks i.e. SHA, SHB, QNRF, and NWPU, show the strong generalizability of our method. Our code is available at: https://github.com/ZPDu/Domain-general-Crowd-Counting-in-Unseen-Scenarios","https://ojs.aaai.org/index.php/AAAI/article/view/25131/24903"
"25132","Few-Shot Defect Image Generation via Defect-Aware Feature Manipulation","['Yuxuan Duan', 'Yan Hong', 'Li Niu', 'Liqing Zhang']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['CV: Computational Photography', 'Image & Video Synthesis', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Deep Generative Models & Autoencoders']","Duan, Y., Hong, Y., Niu, L., & Zhang, L. (2023). Few-Shot Defect Image Generation via Defect-Aware Feature Manipulation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 571-578. https://doi.org/10.1609/aaai.v37i1.25132","Abstract 					The performances of defect inspection have been severely hindered by insufficient defect images in industries, which can be alleviated by generating more samples as data augmentation. We propose the first defect image generation method in the challenging few-shot cases. Given just a handful of defect images and relatively more defect-free ones, our goal is to augment the dataset with new defect images. Our method consists of two training stages. First, we train a data-efficient StyleGAN2 on defect-free images as the backbone. Second, we attach defect-aware residual blocks to the backbone, which learn to produce reasonable defect masks and accordingly manipulate the features within the masked regions by training the added modules on limited defect images. Extensive experiments on MVTec AD dataset not only validate the effectiveness of our method in generating realistic and diverse defect images, but also manifest the benefits it brings to downstream defect inspection tasks. Codes are available at https://github.com/Ldhlwh/DFMGAN.","https://ojs.aaai.org/index.php/AAAI/article/view/25132/24904"
"25133","Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis","['Wan-Cyuan Fan', 'Yen-Chun Chen', 'DongDong Chen', 'Yu Cheng', 'Lu Yuan', 'Yu-Chiang Frank Wang']","['National Taiwan University', 'Microsoft Corporation', 'Microsoft Corporation', 'Microsoft Corporation', 'Microsoft Corporation', 'National Taiwan University,\nNVIDIA']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Multi-modal Vision']","Fan, W.-C., Chen, Y.-C., Chen, D., Cheng, Y., Yuan, L., & Wang, Y.-C. F. (2023). Frido: Feature Pyramid Diffusion for Complex Scene Image Synthesis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 579-587. https://doi.org/10.1609/aaai.v37i1.25133","Abstract 					Diffusion models (DMs) have shown great potential for high-quality image synthesis. However, when it comes to producing images with complex scenes, how to properly describe both image global structures and object details remains a challenging task. In this paper, we present Frido, a Feature Pyramid Diffusion model performing a multi-scale coarse-to-fine denoising process for image synthesis. Our model decomposes an input image into scale-dependent vector quantized features, followed by a coarse-to-fine gating for producing image output. During the above multi-scale representation learning stage, additional input conditions like text, scene graph, or image layout can be further exploited. Thus, Frido can be also applied for conditional or cross-modality image synthesis. We conduct extensive experiments over various unconditioned and conditional image generation tasks, ranging from text-to-image synthesis, layout-to-image, scene-graph-to-image, to label-to-image. More specifically, we achieved state-of-the-art FID scores on five benchmarks, namely layout-to-image on COCO and OpenImages, scene-graph-to-image on COCO and Visual Genome, and label-to-image on COCO.","https://ojs.aaai.org/index.php/AAAI/article/view/25133/24905"
"25134","Target-Free Text-Guided Image Manipulation","['Wan-Cyuan Fan', 'Cheng-Fu Yang', 'Chiao-An Yang', 'Yu-Chiang Frank Wang']","['National Taiwan University', 'University of California, Los Angeles', 'Purdue University', 'National Taiwan University,\nNVIDIA']","['CV: Language and Vision', 'CV: Applications', 'ML: Deep Generative Models & Autoencoders']","Fan, W.-C., Yang, C.-F., Yang, C.-A., & Wang, Y.-C. F. (2023). Target-Free Text-Guided Image Manipulation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 588-596. https://doi.org/10.1609/aaai.v37i1.25134","Abstract 					We tackle the problem of target-free text-guided image manipulation, which requires one to modify the input reference image based on the given text instruction, while no ground truth target image is observed during training. To address this challenging task, we propose a Cyclic-Manipulation GAN (cManiGAN) in this paper, which is able to realize where and how to edit the image regions of interest. Specifically, the image editor in cManiGAN learns to identify and complete the input image, while cross-modal interpreter and reasoner are deployed to verify the semantic correctness of the output image based on the input instruction. While the former utilizes factual/counterfactual description learning for authenticating the image semantics, the latter predicts the ""undo"" instruction and provides pixel-level supervision for the training of cManiGAN. With the above operational cycle-consistency, our cManiGAN can be trained in the above weakly supervised setting. We conduct extensive experiments on the datasets of CLEVR and COCO datasets, and the effectiveness and generalizability of our proposed method can be successfully verified. Project page: sites.google.com/view/wancyuanfan/projects/cmanigan.","https://ojs.aaai.org/index.php/AAAI/article/view/25134/24906"
"25135","One Is All: Bridging the Gap between Neural Radiance Fields Architectures with Progressive Volume Distillation","['Shuangkang Fang', 'Weixin Xu', 'Heng Wang', 'Yi Yang', 'Yufeng Wang', 'Shuchang Zhou']","['Beihang University', 'Megvii Inc', 'Megvii Inc', 'Megvii Inc', 'Beihang University', 'Megvii Inc']","['CV: 3D Computer Vision', 'CV: Computational Photography', 'Image & Video Synthesis', 'CV: Low Level & Physics-Based Vision']","Fang, S., Xu, W., Wang, H., Yang, Y., Wang, Y., & Zhou, S. (2023). One Is All: Bridging the Gap between Neural Radiance Fields Architectures with Progressive Volume Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 597-605. https://doi.org/10.1609/aaai.v37i1.25135","Abstract 					Neural Radiance Fields (NeRF) methods have proved effective as compact, high-quality and versatile representations for 3D scenes, and enable downstream tasks such as editing, retrieval, navigation, etc.  Various neural architectures are vying for the core structure of NeRF, including the plain Multi-Layer Perceptron (MLP), sparse tensors, low-rank tensors, hashtables and their compositions. Each of these representations has its particular set of trade-offs. For example, the hashtable-based representations admit faster training and rendering but their lack of clear geometric meaning hampers downstream tasks like spatial-relation-aware editing. In this paper, we propose Progressive Volume Distillation (PVD), a systematic distillation method that allows any-to-any conversions between different architectures, including MLP, sparse or low-rank tensors, hashtables and their compositions. PVD consequently empowers downstream applications to optimally adapt the neural representations for the task at hand in a post hoc fashion. The conversions are fast, as distillation is progressively performed on different levels of volume representations, from shallower to deeper. We also employ special treatment of density to deal with its specific numerical instability problem. Empirical evidence is presented to validate our method on the NeRF-Synthetic, LLFF and TanksAndTemples datasets. For example, with PVD, an MLP-based NeRF model can be distilled from a hashtable-based Instant-NGP model at a 10~20X faster speed than being trained the original NeRF from scratch, while achieving a superior level of synthesis quality. Code is available at https://github.com/megvii-research/AAAI2023-PVD.","https://ojs.aaai.org/index.php/AAAI/article/view/25135/24907"
"25136","Weakly-Supervised Semantic Segmentation for Histopathology Images Based on Dataset Synthesis and Feature Consistency Constraint","['Zijie Fang', 'Yang Chen', 'Yifeng Wang', 'Zhi Wang', 'Xiangyang Ji', 'Yongbing Zhang']","['Tsinghua University', 'Tsinghua University', 'Harbin Institute of Technology (Shenzhen)', 'Tsinghua University', 'Tsinghua University', 'Harbin Institute of Technology (Shenzhen)']","['CV: Medical and Biological Imaging', 'CV: Segmentation', 'CV: Applications', 'APP: Bioinformatics']","Fang, Z., Chen, Y., Wang, Y., Wang, Z., Ji, X., & Zhang, Y. (2023). Weakly-Supervised Semantic Segmentation for Histopathology Images Based on Dataset Synthesis and Feature Consistency Constraint. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 606-613. https://doi.org/10.1609/aaai.v37i1.25136","Abstract 					Tissue segmentation is a critical task in computational pathology due to its desirable ability to indicate the prognosis of cancer patients. Currently, numerous studies attempt to use image-level labels to achieve pixel-level segmentation to reduce the need for fine annotations. However, most of these methods are based on class activation map, which suffers from inaccurate segmentation boundaries. To address this problem, we propose a novel weakly-supervised tissue segmentation framework named PistoSeg, which is implemented under a fully-supervised manner by transferring tissue category labels to pixel-level masks. Firstly, a dataset synthesis method is proposed based on Mosaic transformation to generate synthesized images with pixel-level masks. Next, considering the difference between synthesized and real images, this paper devises an attention-based feature consistency, which directs the training process of a proposed pseudo-mask refining module. Finally, the refined pseudo-masks are used to train a precise segmentation model for testing. Experiments based on WSSS4LUAD and BCSS-WSSS validate that PistoSeg outperforms the state-of-the-art methods. The code is released at https://github.com/Vison307/PistoSeg.","https://ojs.aaai.org/index.php/AAAI/article/view/25136/24908"
"25137","Uncertainty-Aware Image Captioning","['Zhengcong Fei', 'Mingyuan Fan', 'Li Zhu', 'Junshi Huang', 'Xiaoming Wei', 'Xiaolin Wei']","['Meituan', 'Meituan', 'Meituan', 'Meituan', 'Meituan', 'Meituan']","['CV: Language and Vision', 'CV: Applications']","Fei, Z., Fan, M., Zhu, L., Huang, J., Wei, X., & Wei, X. (2023). Uncertainty-Aware Image Captioning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 614-622. https://doi.org/10.1609/aaai.v37i1.25137","Abstract 					It is well believed that the higher uncertainty in a word of the caption, the more inter-correlated context information is required to determine it. However, current image captioning methods usually consider the generation of all words in a sentence sequentially and equally. In this paper, we propose an uncertainty-aware image captioning framework, which parallelly and iteratively operates insertion of discontinuous candidate words between existing words from easy to difficult until converged. We hypothesize that high-uncertainty words in a sentence need more prior information to make a correct decision and should be produced at a later stage. The resulting non-autoregressive hierarchy makes the caption generation explainable and intuitive. Specifically, we utilize an image-conditioned bag-of-word model to measure the word uncertainty and apply a dynamic programming algorithm to construct the training pairs. During inference, we devise an uncertainty-adaptive parallel beam search technique that yields an empirically logarithmic time complexity. Extensive experiments on the MS COCO benchmark reveal that our approach outperforms the strong baseline and related methods on both captioning quality as well as decoding speed.","https://ojs.aaai.org/index.php/AAAI/article/view/25137/24909"
"25138","Unsupervised Domain Adaptation for Medical Image Segmentation by Selective Entropy Constraints and Adaptive Semantic Alignment","['Wei Feng', 'Lie Ju', 'Lin Wang', 'Kaimin Song', 'Xin Zhao', 'Zongyuan Ge']","['Monash eResearch Center, Monash University\nMonash Medical AI Group, Monash University\nAirdoc Monash Research Centre, Monash University', 'Monash eResearch Center, Monash University\nMonash Medical AI Group, Monash University\nAirdoc Monash Research Centre, Monash University', 'Monash eResearch Center, Monash University\nMonash Medical AI Group, Monash University\nAirdoc Monash Research Centre, Monash University', 'Airdoc LLC', 'Airdoc LLC', 'Monash eResearch Center, Monash University\nMonash Medical AI Group, Monash University\nAirdoc Monash Research Centre, Monash University']","['CV: Medical and Biological Imaging', 'ML: Unsupervised & Self-Supervised Learning']","Feng, W., Ju, L., Wang, L., Song, K., Zhao, X., & Ge, Z. (2023). Unsupervised Domain Adaptation for Medical Image Segmentation by Selective Entropy Constraints and Adaptive Semantic Alignment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 623-631. https://doi.org/10.1609/aaai.v37i1.25138","Abstract 					Generalizing a deep learning model to new domains is crucial for computer-aided medical diagnosis systems. Most existing unsupervised domain adaptation methods have made significant progress in reducing the domain distribution gap through adversarial training. However, these methods may still produce overconfident but erroneous results on unseen target images. This paper proposes a new unsupervised domain adaptation framework for cross-modality medical image segmentation. Specifically, We first introduce two data augmentation approaches to generate two sets of semantics-preserving augmented images. Based on the model's predictive consistency on these two sets of augmented images, we identify reliable and unreliable pixels. We then perform a selective entropy constraint: we minimize the entropy of reliable pixels to increase their confidence while maximizing the entropy of unreliable pixels to reduce their confidence. Based on the identified reliable and unreliable pixels, we further propose an adaptive semantic alignment module which performs class-level distribution adaptation by minimizing the distance between same class prototypes between domains, where unreliable pixels are removed to derive more accurate prototypes. We have conducted extensive experiments on the cross-modality cardiac structure segmentation task. The experimental results show that the proposed method significantly outperforms the state-of-the-art comparison algorithms. Our code and data are available at https://github.com/fengweie/SE_ASA.","https://ojs.aaai.org/index.php/AAAI/article/view/25138/24910"
"25139","SEFormer: Structure Embedding Transformer for 3D Object Detection","['Xiaoyu Feng', 'Heming Du', 'Hehe Fan', 'Yueqi Duan', 'Yongpan Liu']","['Tsinghua University', 'Australian National University', 'National University of Singapore', 'Tsinghua University', 'Tsinghua University']","['CV: 3D Computer Vision', 'CV: Object Detection & Categorization']","Feng, X., Du, H., Fan, H., Duan, Y., & Liu, Y. (2023). SEFormer: Structure Embedding Transformer for 3D Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 632-640. https://doi.org/10.1609/aaai.v37i1.25139","Abstract 					Effectively  preserving and encoding structure features from objects in irregular and sparse LiDAR points is a crucial challenge to 3D object detection on the point cloud. Recently, Transformer has demonstrated promising performance on many 2D and even 3D vision tasks. Compared with the fixed and rigid convolution kernels, the self-attention mechanism in Transformer can adaptively exclude the unrelated or noisy points and is thus suitable for preserving the local spatial structure in the irregular LiDAR point cloud. However, Transformer only performs a simple sum on the point features, based on the self-attention mechanism, and all the points share the same transformation for value.  A such isotropic operation cannot capture the direction-distance-oriented local structure, which is essential for 3D object detection. In this work, we propose a Structure-Embedding transFormer (SEFormer), which can not only preserve the local structure as a traditional Transformer but also have the ability to encode the local structure. Compared to the self-attention mechanism in traditional Transformer, SEFormer learns different feature transformations for value points based on the relative directions and distances to the query point. Then we propose a SEFormer-based network for high-performance 3D object detection. Extensive experiments show that the proposed architecture can achieve SOTA results on the Waymo Open Dataset, one of the most significant 3D detection benchmarks for autonomous driving. Specifically, SEFormer achieves 79.02% mAP, which is 1.2% higher than existing works. https://github.com/tdzdog/SEFormer.","https://ojs.aaai.org/index.php/AAAI/article/view/25139/24911"
"25140","Exploit Domain-Robust Optical Flow in Domain Adaptive Video Semantic Segmentation","['Yuan Gao', 'Zilei Wang', 'Jiafan Zhuang', 'Yixin Zhang', 'Junjie Li']","['University of Science and Technology of Chlna', 'University of Science and Technology of China', 'Shantou University', 'University of Science and Technology of China\nInstitute of Artificial Intelligence, Hefei Comprehensive National Science Center', 'University of Science and Technology of China']","['CV: Segmentation', 'CV: Video Understanding & Activity Analysis', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Gao, Y., Wang, Z., Zhuang, J., Zhang, Y., & Li, J. (2023). Exploit Domain-Robust Optical Flow in Domain Adaptive Video Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 641-649. https://doi.org/10.1609/aaai.v37i1.25140","Abstract 					Domain adaptive semantic segmentation aims to exploit the pixel-level annotated samples on source domain to assist the segmentation of unlabeled samples on target domain. For such a task, the key is to construct reliable supervision signals on target domain. However, existing methods can only provide unreliable supervision signals constructed by segmentation model (SegNet) that are generally domain-sensitive. In this work, we try to find a domain-robust clue to construct more reliable supervision signals. Particularly, we experimentally observe the domain-robustness of optical flow in video tasks as it mainly represents the motion characteristics of scenes. However, optical flow cannot be directly used as supervision signals of semantic segmentation since both of them essentially represent different information. To tackle this issue, we first propose a novel Segmentation-to-Flow Module (SFM) that converts semantic segmentation maps to optical flows, named the segmentation-based flow (SF), and then propose a Segmentation-based Flow Consistency (SFC) method to impose consistency between SF and optical flow, which can implicitly supervise the training of segmentation model. The extensive experiments on two challenging benchmarks demonstrate the effectiveness of our method, and it outperforms previous state-of-the-art methods with considerable performance improvement. Our code is available at https://github.com/EdenHazardan/SFC.","https://ojs.aaai.org/index.php/AAAI/article/view/25140/24912"
"25141","Scene-Level Sketch-Based Image Retrieval with Minimal Pairwise Supervision","['Ce Ge', 'Jingyu Wang', 'Qi Qi', 'Haifeng Sun', 'Tong Xu', 'Jianxin Liao']","['Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications']","['CV: Scene Analysis & Understanding', 'CV: Applications', 'CV: Image and Video Retrieval', 'CV: Multi-modal Vision', 'CV: Representation Learning for Vision', 'ML: Graph-based Machine Learning', 'ML: Multi-Instance/Multi-View Learning', 'ML: Multimodal Learning', 'ML: Representation Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Unsupervised & Self-Supervised Learning']","Ge, C., Wang, J., Qi, Q., Sun, H., Xu, T., & Liao, J. (2023). Scene-Level Sketch-Based Image Retrieval with Minimal Pairwise Supervision. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 650-657. https://doi.org/10.1609/aaai.v37i1.25141","Abstract 					The sketch-based image retrieval (SBIR) task has long been researched at the instance level, where both query sketches and candidate images are assumed to contain only one dominant object. This strong assumption constrains its application, especially with the increasingly popular intelligent terminals and human-computer interaction technology. In this work, a more general scene-level SBIR task is explored, where sketches and images can both contain multiple object instances. The new general task is extremely challenging due to several factors: (i) scene-level SBIR inherently shares sketch-specific difficulties with instance-level SBIR (e.g., sparsity, abstractness, and diversity), (ii) the cross-modal similarity is measured between two partially aligned domains (i.e., not all objects in images are drawn in scene sketches), and (iii) besides instance-level visual similarity, a more complex multi-dimensional scene-level feature matching problem is imposed (including appearance, semantics, layout, etc.). Addressing these challenges, a novel Conditional Graph Autoencoder model is proposed to deal with scene-level sketch-images retrieval. More importantly, the model can be trained with only pairwise supervision, which distinguishes our study from others in that elaborate instance-level annotations (for example, bounding boxes) are no longer required. Extensive experiments confirm the ability of our model to robustly retrieve multiple related objects at the scene level and exhibit superior performance beyond strong competitors.","https://ojs.aaai.org/index.php/AAAI/article/view/25141/24913"
"25142","Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism","['Chunjiang Ge', 'Shiji Song', 'Gao Huang']","['Department of Automation, BNRist, Tsinghua University', 'Department of Automation, BNRist, Tsinghua University', 'Department of Automation, BNRist, Tsinghua University']","['CV: Applications']","Ge, C., Song, S., & Huang, G. (2023). Causal Intervention for Human Trajectory Prediction with Cross Attention Mechanism. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 658-666. https://doi.org/10.1609/aaai.v37i1.25142","Abstract 					Human trajectory Prediction (HTP) in complex social environments plays a crucial and fundamental role in artificial intelligence systems. Conventional methods make use of both history behaviors and social interactions to forecast future trajectories. However, we demonstrate that the social environment is a confounder that misleads the model to learn spurious correlations between history and future trajectories. To end this, we first formulate the social environment, history and future trajectory variables into a structural causal model to analyze the causalities among them. Based on causal intervention rather than conventional likelihood, we propose a Social Environment ADjustment (SEAD) method, to remove the confounding effect of the social environment. The core of our method is implemented by a Social Cross Attention (SCA) module, which is universal, simple and effective. Our method has consistent improvements on ETH-UCY datasets with three baseline models and achieves competitive performances with existing methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25142/24914"
"25143","Point-Teaching: Weakly Semi-supervised Object Detection with Point Annotations","['Yongtao Ge', 'Qiang Zhou', 'Xinlong Wang', 'Chunhua Shen', 'Zhibin Wang', 'Hao Li']","['The University of Adelaide', 'Alibaba Group', 'Beijing Academy of Artificial Intelligence', 'Zhejiang University', 'Alibaba Group', 'Alibaba Group']","['CV: Object Detection & Categorization']","Ge, Y., Zhou, Q., Wang, X., Shen, C., Wang, Z., & Li, H. (2023). Point-Teaching: Weakly Semi-supervised Object Detection with Point Annotations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 667-675. https://doi.org/10.1609/aaai.v37i1.25143","Abstract 					Point annotations are considerably more time-efficient than bounding box annotations. However, how to use cheap point annotations to boost the performance of semi-supervised object detection is still an open question. In this work, we present Point-Teaching, a weakly- and semi-supervised object detection framework to fully utilize the point annotations. Specifically, we propose a Hungarian-based point-matching method to generate pseudo labels for point-annotated images. We further propose multiple instance learning (MIL) approaches at the level of images and points to supervise the object detector with point annotations. Finally, we propose a simple data augmentation, named Point-Guided Copy-Paste, to reduce the impact of those unmatched points. Experiments demonstrate the effectiveness of our method on a few datasets and various data regimes. In particular, Point-Teaching outperforms the previous best method Group R-CNN by 3.1 AP with 5% fully labeled data and 2.3 AP with 30% fully labeled data on the MS COCO dataset. We believe that our proposed framework can largely lower the bar of learning accurate object detectors and pave the way for its broader applications. The code is available at https://github.com/YongtaoGe/Point-Teaching.","https://ojs.aaai.org/index.php/AAAI/article/view/25143/24915"
"25144","Progressive Multi-View Human Mesh Recovery with Self-Supervision","['Xuan Gong', 'Liangchen Song', 'Meng Zheng', 'Benjamin Planche', 'Terrence Chen', 'Junsong Yuan', 'David Doermann', 'Ziyan Wu']","['University at Buffalo\nUnited Imaging Intelligence', 'University at Buffalo\nUnited Imaging Intelligence', 'United Imaging Intelligence', 'United Imaging Intelligence', 'United Imaging Intelligence', 'University at Buffalo', 'University at Buffalo', 'United Imaging Intelligence']","['CV: 3D Computer Vision', 'CV: Applications', 'CV: Biometrics', 'Face', 'Gesture & Pose', 'ML: Unsupervised & Self-Supervised Learning']","Gong, X., Song, L., Zheng, M., Planche, B., Chen, T., Yuan, J., Doermann, D., & Wu, Z. (2023). Progressive Multi-View Human Mesh Recovery with Self-Supervision. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 676-684. https://doi.org/10.1609/aaai.v37i1.25144","Abstract 					To date, little attention has been given to multi-view 3D human mesh estimation, despite real-life applicability (e.g., motion capture, sport analysis) and robustness to single-view ambiguities. Existing solutions typically suffer from poor generalization performance to new settings, largely due to the limited diversity of image/3D-mesh pairs in multi-view training data. To address this shortcoming, people have explored the use of synthetic images. But besides the usual impact of visual gap between rendered and target data, synthetic-data-driven multi-view estimators also suffer from overfitting to the camera viewpoint distribution sampled during training which usually differs from real-world distributions. Tackling both challenges, we propose a novel simulation-based training pipeline for multi-view human mesh recovery, which (a) relies on intermediate 2D representations which are more robust to synthetic-to-real domain gap; (b) leverages learnable calibration and triangulation to adapt to more diversified camera setups; and (c) progressively aggregates multi-view information in a canonical 3D space to remove ambiguities in 2D representations. Through extensive benchmarking, we demonstrate the superiority of the proposed solution especially for unseen in-the-wild scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/25144/24916"
"25145","Incremental Image De-raining via Associative Memory","['Yi Gu', 'Chao Wang', 'Jie Li']","['Alibaba Cloud Computing Ltd.', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['CV: Computational Photography', 'Image & Video Synthesis']","Gu, Y., Wang, C., & Li, J. (2023). Incremental Image De-raining via Associative Memory. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 685-693. https://doi.org/10.1609/aaai.v37i1.25145","Abstract 					While deep learning models have achieved the state-of-the-art performance on single-image rain removal, most methods only consider learning fixed mapping rules on the single synthetic dataset for lifetime. This limits the real-life application as iterative optimization may change mapping rules and training samples. However, when models learn a sequence of datasets in multiple incremental steps, they are susceptible to catastrophic forgetting that adapts to new incremental episodes while failing to preserve previously acquired mapping rules. In this paper, we argue the importance of sample diversity in the episodes on the iterative optimization, and propose a novel memory management method, Associative Memory, to achieve incremental image de-raining. It bridges connections between current and past episodes for feature reconstruction by sampling domain mappings of past learning steps, and guides the learning to trace the current pathway back to the historical environment without storing extra data. Experiments demonstrate that our method can achieve better performance than existing approaches on both inhomogeneous and incremental datasets within the spectrum of highly compact systems.","https://ojs.aaai.org/index.php/AAAI/article/view/25145/24917"
"25146","Flexible 3D Lane Detection by Hierarchical Shape Matching","['Zhihao Guan', 'Ruixin Liu', 'Zejian Yuan', 'Ao Liu', 'Kun Tang', 'Tong Zhou', 'Erlong Li', 'Chao Zheng', 'Shuqi Mei']","[""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", 'Xi‘an Jiaotong University', 'Tencent', 'Tencent', 'Tencent', 'Tencent', 'Tencent', 'Tencent']","['CV: Object Detection & Categorization', 'CV: Vision for Robotics & Autonomous Driving', 'CV: Scene Analysis & Understanding', 'CV: Applications']","Guan, Z., Liu, R., Yuan, Z., Liu, A., Tang, K., Zhou, T., Li, E., Zheng, C., & Mei, S. (2023). Flexible 3D Lane Detection by Hierarchical Shape Matching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 694-701. https://doi.org/10.1609/aaai.v37i1.25146","Abstract 					As one of the basic while vital technologies for HD map construction, 3D lane detection is still an open problem due to varying visual conditions, complex typologies, and strict demands for precision. In this paper, an end-to-end flexible and hierarchical lane detector is proposed to precisely predict 3D lane lines from point clouds. Specifically, we design a hierarchical network predicting flexible representations of lane shapes at different levels, simultaneously collecting global instance semantics and avoiding local errors. In the global scope, we propose to regress parametric curves w.r.t adaptive axes that help to make more robust predictions towards complex scenes, while in the local vision the structure of lane segment is detected in each of the dynamic anchor cells sampled along the global predicted curves. Moreover, corresponding global and local shape matching losses and anchor cell generation strategies are designed. Experiments on two datasets show that we overwhelm current top methods under high precision standards, and full ablation studies also verify each part of our method. Our codes will be released at https://github.com/Doo-do/FHLD.","https://ojs.aaai.org/index.php/AAAI/article/view/25146/24918"
"25147","Underwater Ranker: Learn Which Is Better and How to Be Better","['Chunle Guo', 'Ruiqi Wu', 'Xin Jin', 'Linghao Han', 'Weidong Zhang', 'Zhi Chai', 'Chongyi Li']","['Nankai University', 'Nankai University', 'Nankai University', 'Nankai University', 'Henan Institute of Science and Technology', 'Beijing Huawei Digital Technologies Co., Ltd.', 'Nanyang Technological University']","['CV: Low Level & Physics-Based Vision', 'CV: Computational Photography', 'Image & Video Synthesis']","Guo, C., Wu, R., Jin, X., Han, L., Zhang, W., Chai, Z., & Li, C. (2023). Underwater Ranker: Learn Which Is Better and How to Be Better. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 702-709. https://doi.org/10.1609/aaai.v37i1.25147","Abstract 					In this paper, we present a ranking-based underwater image quality assessment (UIQA) method, abbreviated as URanker. The URanker is built on the efficient conv-attentional image Transformer. In terms of underwater images, we specially devise (1) the histogram prior that embeds the color distribution of an underwater image as histogram token to attend global degradation and (2) the dynamic cross-scale correspondence to model local degradation. The final prediction depends on the class tokens from different scales, which comprehensively considers multi-scale dependencies. With the margin ranking loss, our URanker can accurately rank the order of underwater images of the same scene enhanced by different underwater image enhancement (UIE) algorithms according to their visual quality. To achieve that, we also contribute a dataset, URankerSet, containing sufficient results enhanced by different UIE algorithms and the corresponding perceptual rankings, to train our URanker. Apart from the good performance of URanker, we found that a simple U-shape UIE network can obtain promising performance when it is coupled with our pre-trained URanker as additional supervision. In addition, we also propose a normalization tail that can significantly improve the performance of UIE networks. Extensive experiments demonstrate the state-of-the-art performance of our method. The key designs of our method are discussed. Our code and dataset are available at https://li-chongyi.github.io/URanker_files/.","https://ojs.aaai.org/index.php/AAAI/article/view/25147/24919"
"25148","ShadowFormer: Global Context Helps Shadow Removal","['Lanqing Guo', 'Siyu Huang', 'Ding Liu', 'Hao Cheng', 'Bihan Wen']","['Nanyang Technological University', 'Harvard University', 'Bytedance', 'Nanyang Technological University', 'Nanyang Technological University']","['CV: Low Level & Physics-Based Vision']","Guo, L., Huang, S., Liu, D., Cheng, H., & Wen, B. (2023). ShadowFormer: Global Context Helps Shadow Removal. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 710-718. https://doi.org/10.1609/aaai.v37i1.25148","Abstract 					Recent deep learning methods have achieved promising results in image shadow removal. However, most of the existing approaches focus on working locally within shadow and non-shadow regions, resulting in severe artifacts around the shadow boundaries as well as inconsistent illumination between shadow and non-shadow regions. It is still challenging for the deep shadow removal model to exploit the global contextual correlation between shadow and non-shadow regions. In this work, we first propose a Retinex-based shadow model, from which we derive a novel transformer-based network, dubbed ShandowFormer, to exploit non-shadow regions to help shadow region restoration. A multi-scale channel attention framework is employed to hierarchically capture the global information. Based on that, we propose a Shadow-Interaction Module (SIM) with Shadow-Interaction Attention (SIA) in the bottleneck stage to effectively model the context correlation between shadow and non-shadow regions. We conduct extensive experiments on three popular public datasets, including ISTD, ISTD+, and SRD,  to evaluate the proposed method. Our method achieves state-of-the-art performance by using up to 150X fewer model parameters.","https://ojs.aaai.org/index.php/AAAI/article/view/25148/24920"
"25149","RAFaRe: Learning Robust and Accurate Non-parametric 3D Face Reconstruction from Pseudo 2D&3D Pairs","['Longwei Guo', 'Hao Zhu', 'Yuanxun Lu', 'Menghua Wu', 'Xun Cao']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University']","['CV: 3D Computer Vision', 'CV: Biometrics', 'Face', 'Gesture & Pose']","Guo, L., Zhu, H., Lu, Y., Wu, M., & Cao, X. (2023). RAFaRe: Learning Robust and Accurate Non-parametric 3D Face Reconstruction from Pseudo 2D&3D Pairs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 719-727. https://doi.org/10.1609/aaai.v37i1.25149","Abstract 					We propose a robust and accurate non-parametric method for single-view 3D face reconstruction (SVFR). While tremendous efforts have been devoted to parametric SVFR, a visible gap still lies between the result 3D shape and the ground truth. We believe there are two major obstacles: 1) the representation of the parametric model is limited to a certain face database; 2) 2D images and 3D shapes in the fitted datasets are distinctly misaligned. To resolve these issues, a large-scale pseudo 2D&3D dataset is created by first rendering the detailed 3D faces, then swapping the face in the wild images with the rendered face. These pseudo 2D&3D pairs are created from publicly available datasets which eliminate the gaps between 2D and 3D data while covering diverse appearances, poses, scenes, and illumination. We further propose a non-parametric scheme to learn a well-generalized SVFR model from the created dataset, and the proposed hierarchical signed distance function turns out to be effective in predicting middle-scale and small-scale 3D facial geometry. Our model outperforms previous methods on FaceScape-wild/lab and MICC benchmarks and is well generalized to various appearances, poses, expressions, and in-the-wild environments. The code is released at https://github.com/zhuhao-nju/rafare.","https://ojs.aaai.org/index.php/AAAI/article/view/25149/24921"
"25150","RankDNN: Learning to Rank for Few-Shot Learning","['Qianyu Guo', 'Gong Haotong', 'Xujun Wei', 'Yanwei Fu', 'Yizhou Yu', 'Wenqiang Zhang', 'Weifeng Ge']","['Nebula AI Group, School of Computer Science, Fudan University,Shanghai,China\nShanghai Key Laboratory of Intelligent Information Processing,Shanghai,China', 'Nebula AI Group, School of Computer Science, Fudan University,Shanghai,China', 'Nebula AI Group, School of Computer Science, Fudan University,Shanghai,China\nAcademy for Engineering & Technology, Fudan University,Shanghai,China', 'Shanghai Key Laboratory of Intelligent Information Processing,Shanghai,China', 'Department of Computer Science, The University of Hong Kong,Hong Kong,China', 'Shanghai Key Laboratory of Intelligent Information Processing,Shanghai,China\nAcademy for Engineering & Technology, Fudan University,Shanghai,China', 'Nebula AI Group, School of Computer Science, Fudan University,Shanghai,China\nShanghai Key Laboratory of Intelligent Information Processing,Shanghai,China']","['CV: Other Foundations of Computer Vision', 'ML: Learning Preferences or Rankings', 'ML: Meta Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Guo, Q., Haotong, G., Wei, X., Fu, Y., Yu, Y., Zhang, W., & Ge, W. (2023). RankDNN: Learning to Rank for Few-Shot Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 728-736. https://doi.org/10.1609/aaai.v37i1.25150","Abstract 					This paper introduces a new few-shot learning pipeline that casts relevance ranking for image retrieval as binary ranking relation classification. In comparison to image classification, ranking relation classification is sample efficient and domain agnostic. Besides, it provides a new perspective on few-shot learning and is complementary to state-of-the-art methods. The core component of our deep neural network is a simple MLP, which takes as input an image triplet encoded as the difference between two vector-Kronecker products, and outputs a binary relevance ranking order. The proposed RankMLP can be built on top of any state-of-the-art feature extractors, and our entire deep neural network is called the ranking deep neural network, or RankDNN. Meanwhile, RankDNN can be flexibly fused with other post-processing methods. During the meta test, RankDNN ranks support images according to their similarity with the query samples, and each query sample is assigned the class label of its nearest neighbor. Experiments demonstrate that RankDNN can effectively improve the performance of its baselines based on a variety of backbones and it outperforms previous state-of-the-art algorithms on multiple few-shot learning benchmarks, including miniImageNet, tieredImageNet, Caltech-UCSD Birds, and CIFAR-FS. Furthermore, experiments on the cross-domain challenge demonstrate the superior transferability of RankDNN.The code is available at: https://github.com/guoqianyu-alberta/RankDNN.","https://ojs.aaai.org/index.php/AAAI/article/view/25150/24922"
"25151","Social Relation Reasoning Based on Triangular Constraints","['Yunfei Guo', 'Fei Yin', 'Wei Feng', 'Xudong Yan', 'Tao Xue', 'Shuqi Mei', 'Cheng-Lin Liu']","['National Laboratory of Pattern Recognition (NLPR), Institute of Automation of Chinese Academy of Sciences, Beijing 100190, China\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China', 'National Laboratory of Pattern Recognition (NLPR), Institute of Automation of Chinese Academy of Sciences, Beijing 100190, China\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China', 'National Laboratory of Pattern Recognition (NLPR), Institute of Automation of Chinese Academy of Sciences, Beijing 100190, China\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China', 'T Lab, Tencent Map, Tencent Technology (Beijing) Co., Ltd., Beijing 100193, China', 'T Lab, Tencent Map, Tencent Technology (Beijing) Co., Ltd., Beijing 100193, China', 'T Lab, Tencent Map, Tencent Technology (Beijing) Co., Ltd., Beijing 100193, China', 'National Laboratory of Pattern Recognition (NLPR), Institute of Automation of Chinese Academy of Sciences, Beijing 100190, China\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing 100049, China\nCAS Center for Excellence of Brain Science and Intelligence Technology, Beijing 100190, China']","['CV: Scene Analysis & Understanding', 'CV: Visual Reasoning & Symbolic Representations']","Guo, Y., Yin, F., Feng, W., Yan, X., Xue, T., Mei, S., & Liu, C.-L. (2023). Social Relation Reasoning Based on Triangular Constraints. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 737-745. https://doi.org/10.1609/aaai.v37i1.25151","Abstract 					Social networks are essentially in a graph structure where persons act as nodes and the edges connecting nodes denote social relations. The prediction of social relations, therefore, relies on the context in graphs to model the higher-order constraints among relations, which has not been exploited sufficiently by previous works, however. In this paper, we formulate the paradigm of the higher-order constraints in social relations into triangular relational closed-loop structures, i.e., triangular constraints, and further introduce the triangular reasoning graph attention network (TRGAT). Our TRGAT employs the attention mechanism to aggregate features with triangular constraints in the graph, thereby exploiting the higher-order context to reason social relations iteratively. Besides, to acquire better feature representations of persons, we introduce node contrastive learning into relation reasoning. Experimental results show that our method outperforms existing approaches significantly, with higher accuracy and better consistency in generating social relation graphs.","https://ojs.aaai.org/index.php/AAAI/article/view/25151/24923"
"25152","CALIP: Zero-Shot Enhancement of CLIP with Parameter-Free Attention","['Ziyu Guo', 'Renrui Zhang', 'Longtian Qiu', 'Xianzheng Ma', 'Xupeng Miao', 'Xuming He', 'Bin Cui']","['School of CS and Key Lab of HCST, Peking University\nThe Chinese University of Hong Kong', 'The Chinese University of Hong Kong\nShanghai AI Laboratory', 'ShanghaiTech University', 'Shanghai AI Laboratory', 'Carnegie Mellon University', 'ShanghaiTech University', 'School of CS and Key Lab of HCST, Peking University']","['CV: Language and Vision', 'CV: Multi-modal Vision', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Guo, Z., Zhang, R., Qiu, L., Ma, X., Miao, X., He, X., & Cui, B. (2023). CALIP: Zero-Shot Enhancement of CLIP with Parameter-Free Attention. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 746-754. https://doi.org/10.1609/aaai.v37i1.25152","Abstract 					Contrastive Language-Image Pre-training (CLIP) has been shown to learn visual representations with promising zero-shot performance. To further improve its downstream accuracy, existing works propose additional learnable modules upon CLIP and fine-tune them by few-shot training sets. However, the resulting extra training cost and data requirement severely hinder the efficiency for model deployment and knowledge transfer. In this paper, we introduce a free-lunch enhancement method, CALIP, to boost CLIP's zero-shot performance via a parameter-free attention module. Specifically, we guide visual and textual representations to interact with each other and explore cross-modal informative features via attention. As the pre-training has largely reduced the embedding distances between two modalities, we discard all learnable parameters in the attention and bidirectionally update the multi-modal features, enabling the whole process to be parameter-free and training-free. In this way, the images are blended with textual-aware signals and the text representations become visual-guided for better adaptive zero-shot alignment. We evaluate CALIP on various benchmarks of 14 datasets for both 2D image and 3D point cloud few-shot classification, showing consistent zero-shot performance improvement over CLIP. Based on that, we further insert a small number of linear layers in CALIP's attention module and verify our robustness under the few-shot settings, which also achieves leading performance compared to existing methods. Those extensive experiments demonstrate the superiority of our approach for efficient enhancement of CLIP. Code is available at https://github.com/ZiyuGuo99/CALIP.","https://ojs.aaai.org/index.php/AAAI/article/view/25152/24924"
"25153","Few-Shot Object Detection via Variational Feature Aggregation","['Jiaming Han', 'Yuqiang Ren', 'Jian Ding', 'Ke Yan', 'Gui-Song Xia']","['Wuhan University', 'Tencent', 'Wuhan University', 'Tencent', 'Wuhan University']","['CV: Object Detection & Categorization']","Han, J., Ren, Y., Ding, J., Yan, K., & Xia, G.-S. (2023). Few-Shot Object Detection via Variational Feature Aggregation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 755-763. https://doi.org/10.1609/aaai.v37i1.25153","Abstract 					As few-shot object detectors are often trained with abundant base samples and fine-tuned on few-shot novel examples, the learned models are usually biased to base classes and sensitive to the variance of novel examples. To address this issue, we propose a meta-learning framework with two novel feature aggregation schemes. More precisely, we first present a Class-Agnostic Aggregation (CAA) method, where the query and support features can be aggregated regardless of their categories. The interactions between different classes encourage class-agnostic representations and reduce confusion between base and novel classes. Based on the CAA, we then propose a Variational Feature Aggregation (VFA) method, which encodes support examples into class-level support features for robust feature aggregation. We use a variational autoencoder to estimate class distributions and sample variational features from distributions that are more robust to the variance of support examples. Besides, we decouple classification and regression tasks so that VFA is performed on the classification branch without affecting object localization. Extensive experiments on PASCAL VOC and COCO demonstrate that our method significantly outperforms a strong baseline (up to 16%) and previous state-of-the-art methods (4% in average).","https://ojs.aaai.org/index.php/AAAI/article/view/25153/24925"
"25154","Generating Transferable 3D Adversarial Point Cloud via Random Perturbation Factorization","['Bangyan He', 'Jian Liu', 'Yiming Li', 'Siyuan Liang', 'Jingzhi Li', 'Xiaojun Jia', 'Xiaochun Cao']","['Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Ant Group', 'Tsinghua University', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Sun Yat-sen University']","['CV: 3D Computer Vision', 'CV: Bias', 'Fairness & Privacy', 'CV: Adversarial Attacks & Robustness']","He, B., Liu, J., Li, Y., Liang, S., Li, J., Jia, X., & Cao, X. (2023). Generating Transferable 3D Adversarial Point Cloud via Random Perturbation Factorization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 764-772. https://doi.org/10.1609/aaai.v37i1.25154","Abstract 					Recent studies have demonstrated that existing deep neural networks (DNNs) on 3D point clouds are vulnerable to adversarial examples, especially under the white-box settings where the adversaries have access to model parameters. However, adversarial 3D point clouds generated by existing white-box methods have limited transferability across different DNN architectures. They have only minor threats in real-world scenarios under the black-box settings where the adversaries can only query the deployed victim model. In this paper, we revisit the transferability of adversarial 3D point clouds. We observe that an adversarial perturbation can be randomly factorized into two sub-perturbations, which are also likely to be adversarial perturbations. It motivates us to consider the effects of the perturbation and its sub-perturbations simultaneously to increase the transferability for sub-perturbations also contain helpful information. In this paper, we propose a simple yet effective attack method to generate more transferable adversarial 3D point clouds. Specifically, rather than simply optimizing the loss of perturbation alone, we combine it with its random factorization. We conduct experiments on benchmark dataset, verifying our method's effectiveness in increasing transferability while preserving high efficiency.","https://ojs.aaai.org/index.php/AAAI/article/view/25154/24926"
"25155","Target-Aware Tracking with Long-Term Context Attention","['Kaijie He', 'Canlong Zhang', 'Sheng Xie', 'Zhixin Li', 'Zhiwen Wang']","['School of Computer Science and Engineering, Guangxi Normal University, China', 'School of Computer Science and Engineering, Guangxi Normal University, China\nGuangxi Key Lab of Multi-source Information Mining and Security, China', 'School of Computer Science and Engineering, Guangxi Normal University, China', 'School of Computer Science and Engineering, Guangxi Normal University, China\nGuangxi Key Lab of Multi-source Information Mining and Security, China', 'School of Computer Science and Technology, Guangxi University of Science and Technology, China']","['CV: Motion & Tracking', 'CV: Applications', 'CV: Other Foundations of Computer Vision']","He, K., Zhang, C., Xie, S., Li, Z., & Wang, Z. (2023). Target-Aware Tracking with Long-Term Context Attention. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 773-780. https://doi.org/10.1609/aaai.v37i1.25155","Abstract 					Most deep trackers still follow the guidance of the siamese paradigms and use a template that contains only the target without any contextual information, which makes it difficult for the tracker to cope with large appearance changes, rapid target movement, and attraction from similar objects. To alleviate the above problem, we propose a long-term context attention (LCA) module that can perform extensive information fusion on the target and its context from long-term frames, and calculate the target correlation while enhancing target features. The complete contextual information contains the location of the target as well as the state around the target. LCA uses the target state from the previous frame to exclude the interference of similar objects and complex backgrounds, thus accurately locating the target and enabling the tracker to obtain higher robustness and regression accuracy. By embedding the LCA module in Transformer, we build a powerful online tracker with a target-aware backbone, termed as TATrack. In addition, we propose a dynamic online update algorithm based on the classification confidence of historical information without additional calculation burden. Our tracker achieves state-of-the-art performance on multiple benchmarks, with 71.1% AUC, 89.3% NP, and 73.0% AO on LaSOT, TrackingNet, and GOT-10k. The code and trained models are available on https://github.com/hekaijie123/TATrack.","https://ojs.aaai.org/index.php/AAAI/article/view/25155/24927"
"25156","Weakly-Supervised Camouflaged Object Detection with Scribble Annotations","['Ruozhen He', 'Qihua Dong', 'Jiaying Lin', 'Rynson W.H. Lau']","['City University of Hong Kong', 'City University of Hong Kong', 'City University of Hong Kong', 'City University of Hong Kong']","['CV: Low Level & Physics-Based Vision', 'CV: Object Detection & Categorization']","He, R., Dong, Q., Lin, J., & W.H. Lau, R. (2023). Weakly-Supervised Camouflaged Object Detection with Scribble Annotations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 781-789. https://doi.org/10.1609/aaai.v37i1.25156","Abstract 					Existing camouflaged object detection (COD) methods rely heavily on large-scale datasets with pixel-wise annotations. However, due to the ambiguous boundary, annotating camouflage objects pixel-wisely is very time-consuming and labor-intensive, taking ~60mins to label one image. In this paper, we propose the first weakly-supervised COD method, using scribble annotations as supervision. To achieve this, we first relabel 4,040 images in existing camouflaged object datasets with scribbles, which takes ~10s to label one image. As scribble annotations only describe the primary structure of objects without details, for the network to learn to localize the boundaries of camouflaged objects, we propose a novel consistency loss composed of two parts: a cross-view loss to attain reliable consistency over different images, and an inside-view loss to maintain consistency inside a single prediction map. Besides, we observe that humans use semantic information to segment regions near the boundaries of camouflaged objects. Hence, we further propose a feature-guided loss, which includes visual features directly extracted from images and semantically significant features captured by the model. Finally, we propose a novel network for COD via scribble learning on structural information and semantic relations. Our network has two novel modules: the local-context contrasted (LCC) module, which mimics visual inhibition to enhance image contrast/sharpness and expand the scribbles into potential camouflaged regions, and the logical semantic relation (LSR) module, which analyzes the semantic relation to determine the regions representing the camouflaged object. Experimental results show that our model outperforms relevant SOTA methods on three COD benchmarks with an average improvement of 11.0% on MAE, 3.2% on S-measure, 2.5% on E-measure, and 4.4% on weighted F-measure.","https://ojs.aaai.org/index.php/AAAI/article/view/25156/24928"
"25157","Efficient Mirror Detection via Multi-Level Heterogeneous Learning","['Ruozhen He', 'Jiaying Lin', 'Rynson W.H. Lau']","['City University of Hong Kong', 'City University of Hong Kong', 'City University of Hong Kong']","['CV: Low Level & Physics-Based Vision', 'CV: Object Detection & Categorization']","He, R., Lin, J., & W.H. Lau, R. (2023). Efficient Mirror Detection via Multi-Level Heterogeneous Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 790-798. https://doi.org/10.1609/aaai.v37i1.25157","Abstract 					We present HetNet (Multi-level Heterogeneous Network), a highly efficient mirror detection network. Current mirror detection methods focus more on performance than efficiency, limiting the real-time applications (such as drones). Their lack of efficiency is aroused by the common design of adopting homogeneous modules at different levels, which ignores the difference between different levels of features. In contrast, HetNet detects potential mirror regions initially through low-level understandings (e.g., intensity contrasts) and then combines with high-level understandings (contextual discontinuity for instance) to finalize the predictions. To perform accurate yet efficient mirror detection, HetNet follows an effective architecture that obtains specific information at different stages to detect mirrors. We further propose a multi-orientation intensity-based contrasted module (MIC) and a reflection semantic logical module (RSL), equipped on HetNet, to predict potential mirror regions by low-level understandings and analyze semantic logic in scenarios by high-level understandings, respectively. Compared to the state-of-the-art method, HetNet runs 664% faster and draws an average performance gain of 8.9% on MAE, 3.1% on IoU, and 2.0% on F-measure on two mirror detection benchmarks. The code is available at https://github.com/Catherine-R-He/HetNet.","https://ojs.aaai.org/index.php/AAAI/article/view/25157/24929"
"25158","TransVCL: Attention-Enhanced Video Copy Localization Network with Flexible Supervision","['Sifeng He', 'Yue He', 'Minlong Lu', 'Chen Jiang', 'Xudong Yang', 'Feng Qian', 'Xiaobo Zhang', 'Lei Yang', 'Jiandong Zhang']","['Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'CPCC']","['CV: Image and Video Retrieval', 'CV: Applications', 'CV: Video Understanding & Activity Analysis']","He, S., He, Y., Lu, M., Jiang, C., Yang, X., Qian, F., Zhang, X., Yang, L., & Zhang, J. (2023). TransVCL: Attention-Enhanced Video Copy Localization Network with Flexible Supervision. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 799-807. https://doi.org/10.1609/aaai.v37i1.25158","Abstract 					Video copy localization aims to precisely localize all the copied segments within a pair of untrimmed videos in video retrieval applications. Previous methods typically start from frame-to-frame similarity matrix generated by cosine similarity between frame-level features of the input video pair, and then detect and refine the boundaries of copied segments on similarity matrix under temporal constraints. In this paper, we propose TransVCL: an attention-enhanced video copy localization network, which is optimized directly from initial frame-level features and trained end-to-end with three main components: a customized Transformer for feature enhancement, a correlation and softmax layer for similarity matrix generation, and a temporal alignment module for copied segments localization. In contrast to previous methods demanding the handcrafted similarity matrix, TransVCL incorporates long-range temporal information between feature sequence pair using self- and cross- attention layers. With the joint design and optimization of three components, the similarity matrix can be learned to present more discriminative copied patterns, leading to significant improvements over previous methods on segment-level labeled datasets (VCSL and VCDB). Besides the state-of-the-art performance in fully supervised setting, the attention architecture facilitates TransVCL to further exploit unlabeled or simply video-level labeled data. Additional experiments of supplementing video-level labeled datasets including SVD and FIVR reveal the high flexibility of TransVCL from full supervision to semi-supervision (with or without video-level annotation). Code is publicly available at https://github.com/transvcl/TransVCL.","https://ojs.aaai.org/index.php/AAAI/article/view/25158/24930"
"25159","Open-Vocabulary Multi-Label Classification via Multi-Modal Knowledge Transfer","['Sunan He', 'Taian Guo', 'Tao Dai', 'Ruizhi Qiao', 'Xiujun Shu', 'Bo Ren', 'Shu-Tao Xia']","['Tsinghua University\nShenzhen University\nYouTu Lab, Tencent', 'YouTu Lab, Tencent', 'Shenzhen University', 'YouTu Lab, Tencent', 'YouTu Lab, Tencent', 'YouTu Lab, Tencent', 'Tsinghua University\nPeng Cheng Laboratory']","['CV: Multi-modal Vision', 'CV: Language and Vision', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification']","He, S., Guo, T., Dai, T., Qiao, R., Shu, X., Ren, B., & Xia, S.-T. (2023). Open-Vocabulary Multi-Label Classification via Multi-Modal Knowledge Transfer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 808-816. https://doi.org/10.1609/aaai.v37i1.25159","Abstract 					Real-world recognition system often encounters the challenge of unseen labels. To identify such unseen labels, multi-label zero-shot learning (ML-ZSL) focuses on transferring knowledge by a pre-trained textual label embedding (e.g., GloVe). However, such methods only exploit single-modal knowledge from a language model, while ignoring the rich semantic information inherent in image-text pairs. Instead, recently developed open-vocabulary (OV) based methods succeed in exploiting such information of image-text pairs in object detection, and achieve impressive performance. Inspired by the success of OV-based methods, we propose a novel open-vocabulary framework, named multi-modal knowledge transfer (MKT), for multi-label classification. Specifically, our method exploits multi-modal knowledge of image-text pairs based on a vision and language pre-training (VLP) model. To facilitate transferring the image-text matching ability of VLP model, knowledge distillation is employed to guarantee the consistency of image and label embeddings, along with prompt tuning to further update the label embeddings. To further enable the recognition of multiple objects, a simple but effective two-stream module is developed to capture both local and global features. Extensive experimental results show that our method significantly outperforms state-of-the-art methods on public benchmark datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25159/24931"
"25160","Parameter-Efficient Model Adaptation for Vision Transformers","['Xuehai He', 'Chunyuan Li', 'Pengchuan Zhang', 'Jianwei Yang', 'Xin Eric Wang']","['University of California, Santa Cruz', 'Microsoft Research', 'Microsoft Research', 'Microsoft Research', 'University of California, Santa Cruz']","['CV: Learning & Optimization for CV', 'CV: Language and Vision', 'CV: Representation Learning for Vision', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","He, X., Li, C., Zhang, P., Yang, J., & Wang, X. E. (2023). Parameter-Efficient Model Adaptation for Vision Transformers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 817-825. https://doi.org/10.1609/aaai.v37i1.25160","Abstract 					In computer vision, it has achieved great transfer learning performance via adapting large-scale pretrained vision models (e.g., vision transformers) to downstream tasks. Common approaches for model adaptation either update all model parameters or leverage linear probes. In this paper, we aim to study parameter-efficient model adaptation strategies for vision transformers on the image classification task. We formulate efficient model adaptation as a subspace training problem and perform a comprehensive benchmarking over different efficient adaptation methods. We conduct an empirical study on each efficient model adaptation method focusing on its performance alongside parameter cost. Furthermore, we propose a parameter-efficient model adaptation framework, which first selects submodules by measuring local intrinsic dimensions and then projects them into subspace for further decomposition via a novel Kronecker Adaptation method. We analyze and compare our method with a diverse set of baseline model adaptation methods (including state-of-the-art methods for pretrained language models). Our method performs the best in terms of the tradeoff between accuracy and parameter efficiency across 20 datasets under the few-shot setting and 7 image classification datasets under the full-shot setting.","https://ojs.aaai.org/index.php/AAAI/article/view/25160/24932"
"25161","DarkFeat: Noise-Robust Feature Detector and Descriptor for Extremely Low-Light RAW Images","['Yuze He', 'Yubin Hu', 'Wang Zhao', 'Jisheng Li', 'Yong-Jin Liu', 'Yuxing Han', 'Jiangtao Wen']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Research Institute of Tsinghua University in Shenzhen', 'Eastern Institute for Advanced Study']","['CV: Vision for Robotics & Autonomous Driving', 'CV: Low Level & Physics-Based Vision']","He, Y., Hu, Y., Zhao, W., Li, J., Liu, Y.-J., Han, Y., & Wen, J. (2023). DarkFeat: Noise-Robust Feature Detector and Descriptor for Extremely Low-Light RAW Images. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 826-834. https://doi.org/10.1609/aaai.v37i1.25161","Abstract 					Low-light visual perception, such as SLAM or SfM at night, has received increasing attention, in which keypoint detection and local feature description play an important role. Both handcraft designs and machine learning methods have been widely studied for local feature detection and description, however, the performance of existing methods degrades in the extreme low-light scenarios in a certain degree, due to the low signal-to-noise ratio in images. To address this challenge, images in RAW format that retain more raw sensing information have been considered in recent works with a denoise-then-detect scheme. However, existing denoising methods are still insufficient for RAW images and heavily time-consuming, which limits the practical applications of such scheme. In this paper, we propose DarkFeat, a deep learning model which directly detects and describes local features from extreme low-light RAW images in an end-to-end manner.  A novel noise robustness map and selective suppression constraints are proposed to effectively mitigate the influence of noise and extract more reliable keypoints. Furthermore, a customized pipeline of synthesizing dataset containing low-light RAW image matching pairs is proposed to extend end-to-end training. Experimental results show that DarkFeat achieves state-of-the-art performance on both indoor and outdoor parts of the challenging MID benchmark, outperforms the denoise-then-detect methods and significantly reduces computational costs up to 70%. Code is available at https://github.com/THU-LYJ-Lab/DarkFeat.","https://ojs.aaai.org/index.php/AAAI/article/view/25161/24933"
"25162","GAM: Gradient Attention Module of Optimization for Point Clouds Analysis","['Haotian Hu', 'Fanyi Wang', 'Zhiwang Zhang', 'Yaonong Wang', 'Laifeng Hu', 'Yanhao Zhang']","['Zhejiang Leapmotor Technology CO., LTD.', 'OPPO Research Institute', 'The University of Sydney', 'Zhejiang Leapmotor Technology CO., LTD.', 'Zhejiang Leapmotor Technology CO., LTD.', 'OPPO Research Institute']","['CV: 3D Computer Vision', 'CV: Segmentation']","Hu, H., Wang, F., Zhang, Z., Wang, Y., Hu, L., & Zhang, Y. (2023). GAM: Gradient Attention Module of Optimization for Point Clouds Analysis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 835-843. https://doi.org/10.1609/aaai.v37i1.25162","Abstract 					In the point cloud analysis task, the existing local feature aggregation descriptors (LFAD) do not fully utilize the neighborhood information of center points. Previous methods only use the distance information to constrain the local aggregation process, which is easy to be affected by abnormal points and cannot adequately fit the original geometry of the point cloud. This paper argues that fine-grained geometric information (FGGI) plays an important role in the aggregation of local features. Based on this, we propose a gradient-based local attention module to address the above problem, which is called Gradient Attention Module (GAM). GAM simplifies the process of extracting the gradient information in the neighborhood to explicit representation using the Zenith Angle matrix and Azimuth Angle matrix, which makes the module 35X faster. The comprehensive experiments on the ScanObjectNN dataset, ShapeNet dataset, S3DIS dataset, Modelnet40 dataset, and KITTI dataset demonstrate the effectiveness, efficientness, and generalization of our newly proposed GAM for 3D point cloud analysis. Especially in S3DIS, GAM achieves the highest index in the current point-based model with mIoU/OA/mAcc of 74.4%/90.6%/83.2%.","https://ojs.aaai.org/index.php/AAAI/article/view/25162/24934"
"25163","Self-Supervised Learning for Multilevel Skeleton-Based Forgery Detection via Temporal-Causal Consistency of Actions","['Liang Hu', 'Dora D. Liu', 'Qi Zhang', 'Usman Naseem', 'Zhong Yuan Lai']","['Tongji University\nDeepBlue Academy of Sciences', 'DeepBlue Academy of Sciences\nBirenTech Research', 'University of Technology Sydney\nDeepBlue Academy of Sciences', 'University of Sydney', 'DeepBlue Academy of Sciences']","['CV: Motion & Tracking', 'CV: Adversarial Attacks & Robustness', 'CV: Biometrics', 'Face', 'Gesture & Pose', 'DMKM: Anomaly/Outlier Detection', 'KRR: Action', 'Change', 'and Causality', 'ML: Unsupervised & Self-Supervised Learning']","Hu, L., Liu, D. D., Zhang, Q., Naseem, U., & Lai, Z. Y. (2023). Self-Supervised Learning for Multilevel Skeleton-Based Forgery Detection via Temporal-Causal Consistency of Actions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 844-853. https://doi.org/10.1609/aaai.v37i1.25163","Abstract 					Skeleton-based human action recognition and analysis have become increasingly attainable in many areas, such as security surveillance and anomaly detection. Given the prevalence of skeleton-based applications, tampering attacks on human skeletal features have emerged very recently. In particular, checking the temporal inconsistency and/or incoherence (TII) in the skeletal sequence of human action is a principle of forgery detection. To this end, we propose an approach to self-supervised learning of the temporal causality behind human action, which can effectively check TII in skeletal sequences. Especially, we design a multilevel skeleton-based forgery detection framework to recognize the forgery on frame level, clip level, and action level in terms of learning the corresponding temporal-causal skeleton representations for each level. Specifically, a hierarchical graph convolution network architecture is designed to learn low-level skeleton representations based on physical skeleton connections and high-level action representations based on temporal-causal dependencies for specific actions. Extensive experiments consistently show state-of-the-art results on multilevel forgery detection tasks and superior performance of our framework compared to current competing methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25163/24935"
"25164","Self-Emphasizing Network for Continuous Sign Language Recognition","['Lianyu Hu', 'Liqing Gao', 'Zekang Liu', 'Wei Feng']","['College of Intelligence and Computing, Tianjin University, Tianjin 300350, China', 'College of Intelligence and Computing, Tianjin University, Tianjin 300350, China', 'College of Intelligence and Computing, Tianjin University, Tianjin 300350, China', 'College of Intelligence and Computing, Tianjin University, Tianjin 300350, China']","['CV: Language and Vision', 'CV: 3D Computer Vision', 'CV: Applications', 'CV: Multi-modal Vision', 'CV: Video Understanding & Activity Analysis']","Hu, L., Gao, L., Liu, Z., & Feng, W. (2023). Self-Emphasizing Network for Continuous Sign Language Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 854-862. https://doi.org/10.1609/aaai.v37i1.25164","Abstract 					Hand and face play an important role in expressing sign language. Their features are usually especially leveraged to improve system performance. However, to effectively extract visual representations and capture trajectories for hands and face, previous methods always come at high computations with increased training complexity. They usually employ extra heavy pose-estimation networks to locate human body keypoints or rely on additional pre-extracted heatmaps for supervision. To relieve this problem, we propose a self-emphasizing network (SEN) to emphasize informative spatial regions in a self-motivated way, with few extra computations and without additional expensive supervision. Specifically, SEN first employs a lightweight subnetwork to incorporate local spatial-temporal features to identify informative regions, and then dynamically augment original features via attention maps. It's also observed that not all frames contribute equally to recognition. We present a temporal self-emphasizing module to adaptively emphasize those discriminative frames and suppress redundant ones. A comprehensive comparison with previous methods equipped with hand and face features demonstrates the superiority of our method, even though they always require huge computations and rely on expensive extra supervision. Remarkably, with few extra computations, SEN achieves new state-of-the-art accuracy on four large-scale datasets, PHOENIX14, PHOENIX14-T, CSL-Daily, and CSL. Visualizations verify the effects of SEN on emphasizing informative spatial and temporal features. Code is available at https://github.com/hulianyuyy/SEN_CSLR","https://ojs.aaai.org/index.php/AAAI/article/view/25164/24936"
"25165","Store and Fetch Immediately: Everything Is All You Need for Space-Time Video Super-resolution","['Mengshun Hu', 'Kui Jiang', 'Zhixiang Nie', 'Jiahuan Zhou', 'Zheng Wang']","['School of Computer Science, Wuhan University', 'Huawei Technologies, Cloud BU', 'School of Computer Science, Wuhan University', 'Wangxuan Institute of Computer Technology, Peking University', 'School of Computer Science, Wuhan University']","['CV: Computational Photography', 'Image & Video Synthesis']","Hu, M., Jiang, K., Nie, Z., Zhou, J., & Wang, Z. (2023). Store and Fetch Immediately: Everything Is All You Need for Space-Time Video Super-resolution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 863-871. https://doi.org/10.1609/aaai.v37i1.25165","Abstract 					Existing space-time video super-resolution (ST-VSR) methods fail to achieve high-quality reconstruction since they fail to fully explore the spatial-temporal correlations, long-range components in particular. Although the recurrent structure for ST-VSR adopts bidirectional propagation to aggregate information from the entire video, collecting the temporal information between the past and future via one-stage representations inevitably loses the long-range relations. To alleviate the limitation, this paper proposes an immediate storeand-fetch network to promote long-range correlation learning, where the stored information from the past and future can be refetched to help the representation of the current frame. Specifically, the proposed network consists of two modules: a backward recurrent module (BRM) and a forward recurrent module (FRM). The former first performs backward inference from future to past, while storing future super-resolution (SR) information for each frame. Following that, the latter performs forward inference from past to future to super-resolve all frames, while storing past SR information for each frame. Since FRM inherits SR information from BRM, therefore, spatial and temporal information from the entire video sequence is immediately stored and fetched, which allows drastic improvement for ST-VSR. Extensive experiments both on ST-VSR and space video super-resolution (S-VSR) as well as time video super-resolution (T-VSR) have demonstrated the effectiveness of our proposed method over other state-of-the-art methods on public datasets. Code is available https://github.com/hhhhhumengshun/SFI-STVR","https://ojs.aaai.org/index.php/AAAI/article/view/25165/24937"
"25166","PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models against Adversarial Examples","['Shengshan Hu', 'Junwei Zhang', 'Wei Liu', 'Junhui Hou', 'Minghui Li', 'Leo Yu Zhang', 'Hai Jin', 'Lichao Sun']","['School of Cyber Science and Engineering, Huazhong University of Science and Technology\nNational Engineering Research Center for Big Data Technology and System\nHubei Engineering Research Center on Big Data Security\nHubei Key Laboratory of Distributed System Security\nServices Computing Technology and System Lab', 'School of Cyber Science and Engineering, Huazhong University of Science and Technology\nNational Engineering Research Center for Big Data Technology and System\nHubei Engineering Research Center on Big Data Security\nHubei Key Laboratory of Distributed System Security\nServices Computing Technology and System Lab', 'School of Cyber Science and Engineering, Huazhong University of Science and Technology\nNational Engineering Research Center for Big Data Technology and System\nHubei Engineering Research Center on Big Data Security\nHubei Key Laboratory of Distributed System Security\nServices Computing Technology and System Lab', 'Department of Computer Science, City University of Hong Kong', 'School of Software Engineering, Huazhong University of Science and Technology', 'School of Information Technology, Deakin University', 'School of Computer Science and Technology, Huazhong University of Science and Technology\nNational Engineering Research Center for Big Data Technology and System\nServices Computing Technology and System Lab\nCluster and Grid Computing Lab', 'Department of Computer Science and Engineering, Lehigh University']","['CV: Adversarial Attacks & Robustness', 'CV: 3D Computer Vision']","Hu, S., Zhang, J., Liu, W., Hou, J., Li, M., Zhang, L. Y., Jin, H., & Sun, L. (2023). PointCA: Evaluating the Robustness of 3D Point Cloud Completion Models against Adversarial Examples. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 872-880. https://doi.org/10.1609/aaai.v37i1.25166","Abstract 					Point cloud completion, as the upstream procedure of 3D recognition and segmentation, has become an essential part of many tasks such as navigation and scene understanding. While various point cloud completion models have demonstrated their powerful capabilities, their robustness against adversarial attacks, which have been proven to be fatally malicious towards deep neural networks, remains unknown. In addition, existing attack approaches towards point cloud classifiers cannot be applied to the completion models due to different output forms and attack purposes. In order to evaluate the robustness of the completion models, we propose PointCA, the first adversarial attack against 3D point cloud completion models. PointCA can generate adversarial point clouds that maintain high similarity with the original ones, while being completed as another object with totally different semantic information. Specifically, we minimize the representation discrepancy between the adversarial example and the target point set to jointly explore the adversarial point clouds in the geometry space and the feature space. Furthermore, to launch a stealthier attack, we innovatively employ the neighbourhood density information to tailor the perturbation constraint, leading to geometry-aware and distribution-adaptive modifications for each point. Extensive experiments against different premier point cloud completion networks show that PointCA can cause the performance degradation from 77.9% to 16.7%, with the structure chamfer distance kept  below 0.01. We conclude that existing completion models are severely vulnerable to adversarial examples, and state-of-the-art defenses for point cloud classification will be partially invalid when applied to incomplete and uneven point cloud data.","https://ojs.aaai.org/index.php/AAAI/article/view/25166/24938"
"25167","High-Resolution Iterative Feedback Network for Camouflaged Object Detection","['Xiaobin Hu', 'Shuo Wang', 'Xuebin Qin', 'Hang Dai', 'Wenqi Ren', 'Donghao Luo', 'Ying Tai', 'Ling Shao']","['Tencent Youtu Lab', 'ETH Zurich', 'Mohamed bin Zayed University of Artificial Intelligence', 'University of Glasgow', 'Sun Yat-Sen University', 'Tencent Youtu Lab', 'Tencent Youtu Lab', 'Terminus Group']","['CV: Scene Analysis & Understanding', 'CV: Object Detection & Categorization', 'CV: Segmentation']","Hu, X., Wang, S., Qin, X., Dai, H., Ren, W., Luo, D., Tai, Y., & Shao, L. (2023). High-Resolution Iterative Feedback Network for Camouflaged Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 881-889. https://doi.org/10.1609/aaai.v37i1.25167","Abstract 					Spotting camouflaged objects that are visually assimilated into the background is tricky for both object detection algorithms and humans who are usually confused or cheated by the perfectly intrinsic similarities between the foreground objects and the background surroundings. To tackle this challenge, we aim to extract the high-resolution texture details to avoid the detail degradation that causes blurred vision in edges and boundaries. We introduce a novel HitNet to refine the low-resolution representations by high-resolution features in an iterative feedback manner, essentially a global loop-based connection among the multi-scale resolutions. To design better feedback feature ﬂow and avoid the feature corruption caused by recurrent path, an iterative feedback strategy is proposed to impose more constraints on each feedback connection. Extensive experiments on four challenging datasets demonstrate that our HitNet breaks the performance bottleneck and achieves significant improvements compared with 29 state-of-the-art methods. In addition, to address the data scarcity in camouflaged scenarios, we provide an application example to convert the salient objects to camouflaged objects, thereby generating more camouflaged training samples from the diverse salient object datasets. Code will be made publicly available.","https://ojs.aaai.org/index.php/AAAI/article/view/25167/24939"
"25168","Leveraging Sub-class Discimination for Compositional Zero-Shot Learning","['Xiaoming Hu', 'Zilei Wang']","['University of Science and Technology of China', 'University of Science and Technology of China']","['CV: Object Detection & Categorization', 'CV: Applications', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Hu, X., & Wang, Z. (2023). Leveraging Sub-class Discimination for Compositional Zero-Shot Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 890-898. https://doi.org/10.1609/aaai.v37i1.25168","Abstract 					Compositional Zero-Shot Learning (CZSL) aims at identifying unseen compositions composed of previously seen attributes and objects during the test phase. In real images, the visual appearances of attributes and objects (primitive concepts) generally interact with each other. Namely, the visual appearances of an attribute may change when composed with different objects, and vice versa. But previous works overlook this important property. In this paper, we introduce a simple yet effective approach with leveraging sub-class discrimination. Specifically, we define the primitive concepts in different compositions as sub-classes, and then maintain the sub-class discrimination to address the above challenge. More specifically, inspired by the observation that the composed recognition models could account for the differences across sub-classes, we first propose to impose the embedding alignment between the composed and disentangled recognition to incorporate sub-class discrimination at the feature level. Then we develop the prototype modulator networks to adjust the class prototypes w.r.t. the composition information, which can enhance sub-class discrimination at the classifier level. We conduct extensive experiments on the challenging benchmark datasets, and the considerable performance improvement over state-of-the-art approaches is achieved, which indicates the effectiveness of our method. Our code is available at https://github.com/hxm97/SCD-CZSL.","https://ojs.aaai.org/index.php/AAAI/article/view/25168/24940"
"25169","GPTR: Gestalt-Perception Transformer for Diagram Object Detection","['Xin Hu', 'Lingling Zhang', 'Jun Liu', 'Jinfu Fan', 'Yang You', 'Yaqiang Wu']","['Xi’an Jiaotong University', ""Xi'an Jiaotong University"", ""Xi'an Jiaotong Univerisity"", 'Tongji Univerisity', 'National University of Singapore', ""Xi'an Jiaotong University\nLenovo Research""]","['CV: Applications', 'CMS: Simulating Humans', 'CV: Object Detection & Categorization', 'CV: Representation Learning for Vision']","Hu, X., Zhang, L., Liu, J., Fan, J., You, Y., & Wu, Y. (2023). GPTR: Gestalt-Perception Transformer for Diagram Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 899-907. https://doi.org/10.1609/aaai.v37i1.25169","Abstract 					Diagram object detection is the key basis of practical applications such as textbook question answering. Because the diagram mainly consists of simple lines and color blocks, its visual features are sparser than those of natural images. In addition, diagrams usually express diverse knowledge, in which there are many low-frequency object categories in diagrams. These lead to the fact that traditional data-driven detection model is not suitable for diagrams. In this work, we propose a gestalt-perception transformer model for diagram object detection, which is based on an encoder-decoder architecture. Gestalt perception contains a series of laws to explain human perception, that the human visual system tends to perceive patches in an image that are similar, close or connected without abrupt directional changes as a perceptual whole object. Inspired by these thoughts, we build a gestalt-perception graph in transformer encoder, which is composed of diagram patches as nodes and the relationships between patches as edges. This graph aims to group these patches into objects via laws of similarity, proximity, and smoothness implied in these edges, so that the meaningful objects can be effectively detected. The experimental results demonstrate that the proposed GPTR achieves the best results in the diagram object detection task. Our model also obtains comparable results over the competitors in natural image object detection.","https://ojs.aaai.org/index.php/AAAI/article/view/25169/24941"
"25170","Resolving Task Confusion in Dynamic Expansion Architectures for Class Incremental Learning","['Bingchen Huang', 'Zhineng Chen', 'Peng Zhou', 'Jiayin Chen', 'Zuxuan Wu']","['Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University\nShanghai Collaborative Innovation Center on Intelligent Visual Computing', 'Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University\nShanghai Collaborative Innovation Center on Intelligent Visual Computing', 'University of Maryland, College Park, MD, USA', 'Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University\nShanghai Collaborative Innovation Center on Intelligent Visual Computing', 'Shanghai Key Lab of Intelligent Information Processing, School of Computer Science, Fudan University\nShanghai Collaborative Innovation Center on Intelligent Visual Computing']","['CV: Object Detection & Categorization', 'ML: Lifelong and Continual Learning']","Huang, B., Chen, Z., Zhou, P., Chen, J., & Wu, Z. (2023). Resolving Task Confusion in Dynamic Expansion Architectures for Class Incremental Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 908-916. https://doi.org/10.1609/aaai.v37i1.25170","Abstract 					The dynamic expansion architecture is becoming popular in class incremental learning, mainly due to its advantages in alleviating catastrophic forgetting. However, task confu- sion is not well assessed within this framework, e.g., the discrepancy between classes of different tasks is not well learned (i.e., inter-task confusion, ITC), and certain prior- ity is still given to the latest class batch (i.e., old-new con- fusion, ONC). We empirically validate the side effects of the two types of confusion. Meanwhile, a novel solution called Task Correlated Incremental Learning (TCIL) is pro- posed to encourage discriminative and fair feature utilization across tasks. TCIL performs a multi-level knowledge distil- lation to propagate knowledge learned from old tasks to the new one. It establishes information flow paths at both fea- ture and logit levels, enabling the learning to be aware of old classes. Besides, attention mechanism and classifier re- scoring are applied to generate more fair classification scores. We conduct extensive experiments on CIFAR100 and Ima- geNet100 datasets. The results demonstrate that TCIL con- sistently achieves state-of-the-art accuracy. It mitigates both ITC and ONC, while showing advantages in battle with catas- trophic forgetting even no rehearsal memory is reserved. Source code: https://github.com/YellowPancake/TCIL.","https://ojs.aaai.org/index.php/AAAI/article/view/25170/24942"
"25171","ClassFormer: Exploring Class-Aware Dependency with Transformer for Medical Image Segmentation","['Huimin Huang', 'Shiao Xie', 'Lanfen Lin', 'Ruofeng Tong', 'Yen-Wei Chen', 'Hong Wang', 'Yuexiang Li', 'Yawen Huang', 'Yefeng Zheng']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University\nZhejiang Lab', 'Ritsumeikan University', 'Tencent Jarvis Lab', 'Tencent Jarvis Lab', 'Tencent Jarvis Lab', 'Tencent Jarvis Lab']","['CV: Segmentation', 'CV: Medical and Biological Imaging']","Huang, H., Xie, S., Lin, L., Tong, R., Chen, Y.-W., Wang, H., Li, Y., Huang, Y., & Zheng, Y. (2023). ClassFormer: Exploring Class-Aware Dependency with Transformer for Medical Image Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 917-925. https://doi.org/10.1609/aaai.v37i1.25171","Abstract 					Vision Transformers have recently shown impressive performances on medical image segmentation. Despite their strong capability of modeling long-range dependencies, the current methods still give rise to two main concerns in a class-level perspective: (1) intra-class problem: the existing methods lacked in extracting class-specific correspondences of different pixels, which may lead to poor object coverage and/or boundary prediction; (2) inter-class problem: the existing methods failed to model explicit category-dependencies among various objects, which may result in inaccurate localization. In light of these two issues, we propose a novel transformer, called ClassFormer, powered by two appealing transformers, i.e., intra-class dynamic transformer and inter-class interactive transformer, to address the challenge of fully exploration on compactness and discrepancy. Technically, the intra-class dynamic transformer is first designed to decouple representations of different categories with an adaptive selection mechanism for compact learning, which optimally highlights the informative features to reflect the salient keys/values from multiple scales. We further introduce the inter-class interactive transformer to capture the category dependency among different objects, and model class tokens as the representative class centers to guide a global semantic reasoning. As a consequence, the feature consistency is ensured with the expense of intra-class penalization, while inter-class constraint strengthens the feature discriminability between different categories. Extensive empirical evidence shows that ClassFormer can be easily plugged into any architecture, and yields improvements over the state-of-the-art methods in three public benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25171/24943"
"25172","NLIP: Noise-Robust Language-Image Pre-training","['Runhui Huang', 'Yanxin Long', 'Jianhua Han', 'Hang Xu', 'Xiwen Liang', 'Chunjing Xu', 'Xiaodan Liang']","['Shenzhen campus of Sun Yat-sen University', 'Shenzhen campus of Sun Yat-sen University', ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", 'Shenzhen campus of Sun Yat-sen University', ""Huawei Noah's Ark Lab"", 'Shenzhen campus of Sun Yat-sen University']","['CV: Language and Vision', 'CV: Representation Learning for Vision']","Huang, R., Long, Y., Han, J., Xu, H., Liang, X., Xu, C., & Liang, X. (2023). NLIP: Noise-Robust Language-Image Pre-training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 926-934. https://doi.org/10.1609/aaai.v37i1.25172","Abstract 					Large-scale cross-modal pre-training paradigms have recently shown ubiquitous success on a wide range of downstream tasks, e.g., zero-shot classification, retrieval and image captioning. However, their successes highly rely on the scale and quality of web-crawled data that naturally contain much incomplete and noisy information (e.g., wrong or irrelevant contents). Existing works either design manual rules to clean data or generate pseudo-targets as auxiliary signals for reducing noise impact, which do not explicitly tackle both the incorrect and incomplete challenges at the same time. In this paper, to automatically mitigate the impact of noise by solely mining over existing data, we propose a principled Noise-robust Language-Image Pre-training framework (NLIP) to stabilize pre-training via two schemes: noise-harmonization and noise-completion. First, in noise-harmonization scheme, NLIP estimates the noise probability of each pair according to the memorization effect of cross-modal transformers, then adopts noise-adaptive regularization to harmonize the cross-modal alignments with varying degrees. Second, in noise-completion scheme, to enrich the missing object information of text, NLIP injects a concept-conditioned cross-modal decoder to obtain semantic-consistent synthetic captions to complete noisy ones, which uses the retrieved visual concepts (i.e., objects’ names) for the corresponding image to guide captioning generation. By collaboratively optimizing noise-harmonization and noise-completion schemes, our NLIP can alleviate the common noise effects during image-text pre-training in a more efficient way. Extensive experiments show the significant performance improvements of our NLIP using only 26M data over existing pre-trained models (e.g., CLIP, FILIP and BLIP) on 12 zero-shot classification datasets (e.g., +8.6% over CLIP on average accuracy), MSCOCO image captioning (e.g., +1.9 over BLIP trained with 129M data on CIDEr) and zero-shot image-text retrieval tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25172/24944"
"25173","Symmetry-Aware Transformer-Based Mirror Detection","['Tianyu Huang', 'Bowen Dong', 'Jiaying Lin', 'Xiaohui Liu', 'Rynson W.H. Lau', 'Wangmeng Zuo']","['Harbin Institute of Technology\nCity University of Hong Kong', 'Harbin Institute of Technology', 'City University of Hong Kong', 'Harbin Institute of Technology', 'City University of Hong Kong', 'Harbin Institute of Technology\nPeng Cheng Laboratory']","['CV: Low Level & Physics-Based Vision']","Huang, T., Dong, B., Lin, J., Liu, X., W.H. Lau, R., & Zuo, W. (2023). Symmetry-Aware Transformer-Based Mirror Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 935-943. https://doi.org/10.1609/aaai.v37i1.25173","Abstract 					Mirror detection aims to identify the mirror regions in the given input image. Existing works mainly focus on integrating the semantic features and structural features to mine specific relations between mirror and non-mirror regions, or introducing mirror properties like depth or chirality to help analyze the existence of mirrors. In this work, we observe that a real object typically forms a loose symmetry relationship with its corresponding reflection in the mirror, which is beneficial in distinguishing mirrors from real objects. Based on this observation, we propose a dual-path Symmetry-Aware Transformer-based mirror detection Network (SATNet), which includes two novel modules: Symmetry-Aware Attention Module (SAAM) and Contrast and Fusion Decoder Module (CFDM). Specifically, we first adopt a transformer backbone to model global information aggregation in images, extracting multi-scale features in two paths. We then feed the high-level dual-path features to SAAMs to capture the symmetry relations. Finally, we fuse the dual-path features and refine our prediction maps progressively with CFDMs to obtain the final mirror mask. Experimental results show that SATNet outperforms both RGB and RGB-D mirror detection methods on all available mirror detection datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25173/24945"
"25174","AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio","['Xiaoyang Huang', 'Yanjun Wang', 'Yang Liu', 'Bingbing Ni', 'Wenjun Zhang', 'Jinxian Liu', 'Teng Li']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'FocusMedia', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Anhui University']","['CV: 3D Computer Vision', 'CV: Applications', 'CV: Biometrics', 'Face', 'Gesture & Pose']","Huang, X., Wang, Y., Liu, Y., Ni, B., Zhang, W., Liu, J., & Li, T. (2023). AudioEar: Single-View Ear Reconstruction for Personalized Spatial Audio. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 944-952. https://doi.org/10.1609/aaai.v37i1.25174","Abstract 					Spatial audio, which focuses on immersive 3D sound rendering, is widely applied in the acoustic industry. One of the key problems of current spatial audio rendering methods is the lack of personalization based on different anatomies of individuals, which is essential to produce accurate sound source positions. In this work, we address this problem from an interdisciplinary perspective. The rendering of spatial audio is strongly correlated with the 3D shape of human bodies, particularly ears. To this end, we propose to achieve personalized spatial audio by reconstructing 3D human ears with single-view images. First, to benchmark the ear reconstruction task, we introduce AudioEar3D, a high-quality 3D ear dataset consisting of 112 point cloud ear scans with RGB images. To self-supervisedly train a reconstruction model, we further collect a 2D ear dataset composed of 2,000 images, each one with manual annotation of occlusion and 55 landmarks, named AudioEar2D. To our knowledge, both datasets have the largest scale and best quality of their kinds for public use. Further, we propose AudioEarM, a reconstruction method guided by a depth estimation network that is trained on synthetic data, with two loss functions tailored for ear data. Lastly, to fill the gap between the vision and acoustics community, we develop a pipeline to integrate the reconstructed ear mesh with an off-the-shelf 3D human body and simulate a personalized Head-Related Transfer Function (HRTF), which is the core of spatial audio rendering. Code and data are publicly available in https://github.com/seanywang0408/AudioEar.","https://ojs.aaai.org/index.php/AAAI/article/view/25174/24946"
"25175","Boosting Point Clouds Rendering via Radiance Mapping","['Xiaoyang Huang', 'Yi Zhang', 'Bingbing Ni', 'Teng Li', 'Kai Chen', 'Wenjun Zhang']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Anhui University', 'Shanghai AI Laboratory', 'Shanghai Jiao Tong University']","['CV: Scene Analysis & Understanding', 'CV: 3D Computer Vision']","Huang, X., Zhang, Y., Ni, B., Li, T., Chen, K., & Zhang, W. (2023). Boosting Point Clouds Rendering via Radiance Mapping. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 953-961. https://doi.org/10.1609/aaai.v37i1.25175","Abstract 					Recent years we have witnessed rapid development in NeRF-based image rendering due to its high quality. However, point clouds rendering is somehow less explored. Compared to NeRF-based rendering which suffers from dense spatial sampling, point clouds rendering is naturally less computation intensive, which enables its deployment in mobile computing device. In this work, we focus on boosting the image quality of point clouds rendering with a compact model design. We first analyze the adaption of the volume rendering formulation on point clouds. Based on the analysis, we simplify the NeRF representation to a spatial mapping function which only requires single evaluation per pixel. Further, motivated by ray marching, we rectify the the noisy raw point clouds to the estimated intersection between rays and surfaces as queried coordinates, which could avoid spatial frequency collapse and neighbor point disturbance. Composed of rasterization, spatial mapping and the refinement stages, our method achieves the state-of-the-art performance on point clouds rendering, outperforming prior works by notable margins, with a smaller model size. We obtain a PSNR of 31.74 on NeRF-Synthetic, 25.88 on ScanNet and 30.81 on DTU. Code and data are publicly available in https://github.com/seanywang0408/RadianceMapping.","https://ojs.aaai.org/index.php/AAAI/article/view/25175/24947"
"25176","FreeEnricher: Enriching Face Landmarks without Additional Cost","['Yangyu Huang', 'Xi Chen', 'Jongyoo Kim', 'Hao Yang', 'Chong Li', 'Jiaolong Yang', 'Dong Chen']","['Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia']","['CV: Object Detection & Categorization', 'CV: Biometrics', 'Face', 'Gesture & Pose']","Huang, Y., Chen, X., Kim, J., Yang, H., Li, C., Yang, J., & Chen, D. (2023). FreeEnricher: Enriching Face Landmarks without Additional Cost. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 962-970. https://doi.org/10.1609/aaai.v37i1.25176","Abstract 					Recent years have witnessed significant growth of face alignment. Though dense facial landmark is highly demanded in various scenarios, e.g., cosmetic medicine and facial beautification, most works only consider sparse face alignment. To address this problem, we present a framework that can enrich landmark density by existing sparse landmark datasets, e.g., 300W with 68 points and WFLW with 98 points. Firstly, we observe that the local patches along each semantic contour are highly similar in appearance. Then, we propose a weakly-supervised idea of learning the refinement ability on original sparse landmarks and adapting this ability to enriched dense landmarks. Meanwhile, several operators are devised and organized together to implement the idea. Finally, the trained model is applied as a plug-and-play module to the existing face alignment networks. To evaluate our method, we manually label the dense landmarks on 300W testset. Our method yields state-of-the-art accuracy not only in newly-constructed dense 300W testset but also in the original sparse 300W and WFLW testsets without additional cost.","https://ojs.aaai.org/index.php/AAAI/article/view/25176/24948"
"25177","PATRON: Perspective-Aware Multitask Model for Referring Expression Grounding Using Embodied Multimodal Cues","['Md Mofijul Islam', 'Alexi Gladstone', 'Tariq Iqbal']","['University of Virginia', 'University of Virginia', 'University of Virginia']","['CV: Language and Vision', 'ML: Multimodal Learning', 'CV: Multi-modal Vision', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Islam, M. M., Gladstone, A., & Iqbal, T. (2023). PATRON: Perspective-Aware Multitask Model for Referring Expression Grounding Using Embodied Multimodal Cues. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 971-979. https://doi.org/10.1609/aaai.v37i1.25177","Abstract 					Humans naturally use referring expressions with verbal utterances and nonverbal gestures to refer to objects and events. As these referring expressions can be interpreted differently from the speaker's or the observer's perspective, people effectively decide on the perspective in comprehending the expressions. However, existing models do not explicitly learn perspective grounding, which often causes the models to perform poorly in understanding embodied referring expressions. To make it exacerbate, these models are often trained on datasets collected in non-embodied settings without nonverbal gestures and curated from an exocentric perspective. To address these issues, in this paper, we present a perspective-aware multitask learning model, called PATRON, for relation and object grounding tasks in embodied settings by utilizing verbal utterances and nonverbal cues. In PATRON, we have developed a guided fusion approach, where a perspective grounding task guides the relation and object grounding task. Through this approach, PATRON learns disentangled task-specific and task-guidance representations, where task-guidance representations guide the extraction of salient multimodal features to ground the relation and object accurately. Furthermore, we have curated a synthetic dataset of embodied referring expressions with multimodal cues, called CAESAR-PRO. The experimental results suggest that PATRON outperforms the evaluated state-of-the-art visual-language models. Additionally, the results indicate that learning to ground perspective helps machine learning models to improve the performance of the relation and object grounding task. Furthermore, the insights from the extensive experimental results and the proposed dataset will enable researchers to evaluate visual-language models' effectiveness in understanding referring expressions in other embodied settings.","https://ojs.aaai.org/index.php/AAAI/article/view/25177/24949"
"25178","Unifying Vision-Language Representation Space with Single-Tower Transformer","['Jiho Jang', 'Chaerin Kong', 'DongHyeon Jeon', 'Seonhoon Kim', 'Nojun Kwak']","['Seoul National University', 'Seoul National University', 'Naver', 'Coupang', 'Seoul National University']","['CV: Language and Vision', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning']","Jang, J., Kong, C., Jeon, D., Kim, S., & Kwak, N. (2023). Unifying Vision-Language Representation Space with Single-Tower Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 980-988. https://doi.org/10.1609/aaai.v37i1.25178","Abstract 					Contrastive learning is a form of distance learning that aims to learn invariant features from two related representations. In this work, we explore the hypothesis that an image and caption can be regarded as two different views of the underlying mutual information, and train a model to learn a unified vision-language representation space that encodes both modalities at once in a modality-agnostic manner. We first identify difficulties in learning a one-tower model for vision-language pretraining (VLP), and propose One Representation (OneR) as a simple yet effective framework for our goal. We discover intriguing properties that distinguish OneR from the previous works that have modality-specific representation spaces such as zero-shot localization, text-guided visual reasoning and multi-modal retrieval, and present analyses to provide insights into this new form of multi-modal representation learning. Thorough evaluations demonstrate the potential of a unified modality-agnostic VLP framework.","https://ojs.aaai.org/index.php/AAAI/article/view/25178/24950"
"25179","Delving Deep into Pixel Alignment Feature for Accurate Multi-View Human Mesh Recovery","['Kai Jia', 'Hongwen Zhang', 'Liang An', 'Yebin Liu']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University']","['CV: 3D Computer Vision', 'CV: Applications', 'CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Motion & Tracking', 'CV: Vision for Robotics & Autonomous Driving']","Jia, K., Zhang, H., An, L., & Liu, Y. (2023). Delving Deep into Pixel Alignment Feature for Accurate Multi-View Human Mesh Recovery. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 989-997. https://doi.org/10.1609/aaai.v37i1.25179","Abstract 					Regression-based methods have shown high efficiency and effectiveness for multi-view human mesh recovery. The key components of a typical regressor lie in the feature extraction of input views and the fusion of multi-view features. In this paper, we present Pixel-aligned Feedback Fusion (PaFF) for accurate yet efficient human mesh recovery from multi-view images. PaFF is an iterative regression framework that performs feature extraction and fusion alternately. At each iteration, PaFF extracts pixel-aligned feedback features from each input view according to the reprojection of the current estimation and fuses them together with respect to each vertex of the downsampled mesh. In this way, our regressor can not only perceive the misalignment status of each view from the feedback features but also correct the mesh parameters more effectively based on the feature fusion on mesh vertices. Additionally, our regressor disentangles the global orientation and translation of the body mesh from the estimation of mesh parameters such that the camera parameters of input views can be better utilized in the regression process. The efficacy of our method is validated in the Human3.6M dataset via comprehensive ablation experiments, where PaFF achieves 33.02 MPJPE and brings significant improvements over the previous best solutions by more than 29%. The project page with code and video results can be found at https://kairobo.github.io/PaFF/.","https://ojs.aaai.org/index.php/AAAI/article/view/25179/24951"
"25180","Semi-attention Partition for Occluded Person Re-identification","['Mengxi Jia', 'Yifan Sun', 'Yunpeng Zhai', 'Xinhua Cheng', 'Yi Yang', 'Ying Li']","['School of Software and Microelectronic, Peking University, Beijing, China', 'Baidu Research', 'Peking University, China', 'Peking University, China', 'College of Computer Science and Technology, Zhejiang University, China', 'National Engineering Center of Software Engineering, Peking University, Beijing, China']","['CV: Image and Video Retrieval', 'CV: Representation Learning for Vision']","Jia, M., Sun, Y., Zhai, Y., Cheng, X., Yang, Y., & Li, Y. (2023). Semi-attention Partition for Occluded Person Re-identification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 998-1006. https://doi.org/10.1609/aaai.v37i1.25180","Abstract 					This paper proposes a Semi-Attention Partition (SAP) method to learn well-aligned part features for occluded person re-identification (re-ID). Currently, the mainstream methods employ either external semantic partition or attention-based partition, and the latter manner is usually better than the former one. Under this background, this paper explores a potential that the weak semantic partition can be a good teacher for the strong attention-based partition. In other words, the attention-based student can substantially surpass its noisy semantic-based teacher, contradicting the common sense that the student usually achieves inferior (or comparable) accuracy. A key to this effect is: the proposed SAP encourages the attention-based partition of the (transformer) student to be partially consistent with the semantic-based teacher partition through knowledge distillation, yielding the so-called semi-attention. Such partial consistency allows the student to have both consistency and reasonable conflict with the noisy teacher. More specifically, on the one hand, the attention is guided by the semantic partition from the teacher. On the other hand, the attention mechanism itself still has some degree of freedom to comply with the inherent similarity between different patches, thus gaining resistance against noisy supervision. Moreover, we integrate a battery of well-engineered designs into SAP to reinforce their cooperation (e.g., multiple forms of teacher-student consistency), as well as to promote reasonable conflict (e.g., mutual absorbing partition refinement and a supervision signal dropout strategy). Experimental results confirm that the transformer student achieves substantial improvement after this semi-attention learning scheme, and produces new state-of-the-art accuracy on several standard re-ID benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25180/24952"
"25181","Fast Online Hashing with Multi-Label Projection","['Wenzhe Jia', 'Yuan Cao', 'Junwei Liu', 'Jie Gui']","['Ocean University of China\nState Key Laboratory of Integrated Services Networks (Xidian University)', 'Ocean University of China\nState Key Laboratory of Integrated Services Networks (Xidian University)', 'Ocean University of China', 'Southeast University\nPurple Mountain Laboratories']","['CV: Image and Video Retrieval', 'ML: Representation Learning']","Jia, W., Cao, Y., Liu, J., & Gui, J. (2023). Fast Online Hashing with Multi-Label Projection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1007-1014. https://doi.org/10.1609/aaai.v37i1.25181","Abstract 					Hashing has been widely researched to solve the large-scale approximate nearest neighbor search problem owing to its time and storage superiority. In recent years, a number of online hashing methods have emerged, which can update the hash functions to adapt to the new stream data and realize dynamic  retrieval. However, existing online hashing methods are required to update the whole database with the latest hash functions when a query arrives, which leads to low retrieval efficiency with the continuous increase of the stream data. On the other hand, these methods ignore the supervision relationship among the examples, especially in the multi-label case. In this paper, we propose a novel Fast Online Hashing (FOH) method which only updates the binary codes of a small part of the database. To be specific, we first build a query pool in which the nearest neighbors of each central point are recorded. When a new query arrives, only the binary codes of the corresponding potential neighbors are updated. In addition, we create a similarity matrix which takes the multi-label supervision information into account and bring in the multi-label projection loss to further preserve the similarity among the multi-label data. The experimental results on two common benchmarks show that the proposed FOH can achieve dramatic superiority on query time up to 6.28 seconds less than state-of-the-art baselines with competitive retrieval accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25181/24953"
"25182","Fourier-Net: Fast Image Registration with Band-Limited Deformation","['Xi Jia', 'Joseph Bartlett', 'Wei Chen', 'Siyang Song', 'Tianyang Zhang', 'Xinxing Cheng', 'Wenqi Lu', 'Zhaowen Qiu', 'Jinming Duan']","['School of Computer Science, University of Birmingham, UK', 'School of Computer Science, University of Birmingham, UK\nDepartment of Biomedical Engineering, University of Melbourne, Australia', 'School of Computer Science, University of Birmingham, UK', 'Department of Computer Science and Technology, University of Cambridge, UK', 'School of Computer Science, University of Birmingham, UK', 'School of Computer Science, University of Birmingham, UK', 'Department of Computer Science, University of Warwick, UK', 'Institute of Information Computer Engineering, Northeast Forestry University, China', 'School of Computer Science, University of Birmingham, UK\nAlan Turing Institute, UK']","['CV: Medical and Biological Imaging']","Jia, X., Bartlett, J., Chen, W., Song, S., Zhang, T., Cheng, X., Lu, W., Qiu, Z., & Duan, J. (2023). Fourier-Net: Fast Image Registration with Band-Limited Deformation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1015-1023. https://doi.org/10.1609/aaai.v37i1.25182","Abstract 					Unsupervised image registration commonly adopts U-Net style networks to predict dense displacement fields in the full-resolution spatial domain. For high-resolution volumetric image data, this process is however resource-intensive and time-consuming. To tackle this problem, we propose the Fourier-Net, replacing the expansive path in a U-Net style network with a parameter-free model-driven decoder. Specifically, instead of our Fourier-Net learning to output a full-resolution displacement field in the spatial domain, we learn its low-dimensional representation in a band-limited Fourier domain. This representation is then decoded by our devised model-driven decoder (consisting of a zero padding layer and an inverse discrete Fourier transform layer) to the dense, full-resolution displacement field in the spatial domain. These changes allow our unsupervised Fourier-Net to contain fewer parameters and computational operations, resulting in faster inference speeds. Fourier-Net is then evaluated on two public 3D brain datasets against various state-of-the-art approaches. For example, when compared to a recent transformer-based method, named TransMorph, our Fourier-Net, which only uses 2.2% of its parameters and 6.66% of the multiply-add operations, achieves a 0.5% higher Dice score and an 11.48 times faster inference speed. Code is available at https://github.com/xi-jia/Fourier-Net.","https://ojs.aaai.org/index.php/AAAI/article/view/25182/24954"
"25183","Semi-supervised Deep Large-Baseline Homography Estimation with Progressive Equivalence Constraint","['Hai Jiang', 'Haipeng Li', 'Yuhang Lu', 'Songchen Han', 'Shuaicheng Liu']","['Sichuan University; Megvii Technology', 'University of Electronic Science and Technology of China; Megvii Technology', 'University of South Carolina', 'Sichuan University', 'University of Electronic Science and Technology of China; Megvii Technology']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Low Level & Physics-Based Vision']","Jiang, H., Li, H., Lu, Y., Han, S., & Liu, S. (2023). Semi-supervised Deep Large-Baseline Homography Estimation with Progressive Equivalence Constraint. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1024-1032. https://doi.org/10.1609/aaai.v37i1.25183","Abstract 					Homography estimation is erroneous in the case of large-baseline due to the low image overlay and limited receptive field. To address it, we propose a progressive estimation strategy by converting large-baseline homography into multiple intermediate ones, cumulatively multiplying these intermediate items can reconstruct the initial homography. Meanwhile, a semi-supervised homography identity loss, which consists of two components: a supervised objective and an unsupervised objective, is introduced. The first supervised loss is acting to optimize intermediate homographies, while the second unsupervised one helps to estimate a large-baseline homography without photometric losses. To validate our method, we propose a large-scale dataset that covers regular and challenging scenes. Experiments show that our method achieves state-of-the-art performance in large-baseline scenes while keeping competitive performance in small-baseline scenes. Code and dataset are available at https://github.com/megvii-research/LBHomo.","https://ojs.aaai.org/index.php/AAAI/article/view/25183/24955"
"25184","Multi-Modality Deep Network for Extreme Learned Image Compression","['Xuhao Jiang', 'Weimin Tan', 'Tian Tan', 'Bo Yan', 'Liquan Shen']","['Fudan University', 'Fudan University', 'Fudan University', 'Fudan University', 'Shanghai University']","['CV: Multi-modal Vision', 'CV: Low Level & Physics-Based Vision']","Jiang, X., Tan, W., Tan, T., Yan, B., & Shen, L. (2023). Multi-Modality Deep Network for Extreme Learned Image Compression. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1033-1041. https://doi.org/10.1609/aaai.v37i1.25184","Abstract 					Image-based single-modality compression learning approaches have demonstrated exceptionally powerful encoding and decoding capabilities in the past few years , but suffer from blur and severe semantics loss at extremely low bitrates. To address this issue, we propose a multimodal machine learning method for text-guided image compression, in which the semantic information of text is used as prior information to guide image compression for better compression performance. We fully study the role of text description in different components of the codec, and demonstrate its effectiveness. In addition, we adopt the image-text attention module and image-request complement module to better fuse image and text features, and propose an improved multimodal semantic-consistent loss to produce semantically complete reconstructions. Extensive experiments, including a user study, prove that our method can obtain visually pleasing results at extremely low bitrates, and achieves a comparable or even better performance than state-of-the-art methods, even though these methods are at 2x to 4x bitrates of ours.","https://ojs.aaai.org/index.php/AAAI/article/view/25184/24956"
"25185","PolarFormer: Multi-Camera 3D Object Detection with Polar Transformer","['Yanqin Jiang', 'Li Zhang', 'Zhenwei Miao', 'Xiatian Zhu', 'Jin Gao', 'Weiming Hu', 'Yu-Gang Jiang']","['NLPR, Institute of Automation, Chinese Academy of Sciences,\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'School of Data Science, Fudan University, 3School of Computer Science, Fudan University', 'Alibaba DAMO Academy', 'Surrey Institute for People-Centred Artificial Intelligence, CVSSP, University of Surrey', 'NLPR, Institute of Automation, Chinese Academy of Sciences,\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'NLPR, Institute of Automation, Chinese Academy of Sciences,\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences,\nSchool of Information Science and Technology, ShanghaiTech University', 'School of Computer Science, Fudan University']","['CV: Object Detection & Categorization', 'CV: Vision for Robotics & Autonomous Driving', 'CV: 3D Computer Vision']","Jiang, Y., Zhang, L., Miao, Z., Zhu, X., Gao, J., Hu, W., & Jiang, Y.-G. (2023). PolarFormer: Multi-Camera 3D Object Detection with Polar Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1042-1050. https://doi.org/10.1609/aaai.v37i1.25185","Abstract 					3D object detection in autonomous driving aims to reason “what” and “where” the objects of interest present in a 3D world. Following the conventional wisdom of previous 2D object detection, existing methods often adopt the canonical Cartesian coordinate system with perpendicular axis. However, we conjugate that this does not fit the nature of the ego car’s perspective, as each onboard camera perceives the world in shape of wedge intrinsic to the imaging geometry with radical (non perpendicular) axis. Hence, in this paper we advocate the exploitation of the Polar coordinate system and propose a new Polar Transformer (PolarFormer) for more accurate 3D object detection in the bird’s-eye-view (BEV) taking as input only multi-camera 2D images. Specifically, we design a cross-attention based Polar detection head without restriction to the shape of input structure to deal with irregular Polar grids. For tackling the unconstrained object scale variations along Polar’s distance dimension, we further introduce a multi-scale Polar representation learning strategy. As a result, our model can make best use of the Polar representation rasterized via attending to the corresponding image observation in a sequence-to-sequence fashion subject to the geometric constraints. Thorough experiments on the nuScenes dataset demonstrate that our PolarFormer outperforms significantly state-of-the-art 3D object detection alternatives.","https://ojs.aaai.org/index.php/AAAI/article/view/25185/24957"
"25186","3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation","['Zutao Jiang', 'Guansong Lu', 'Xiaodan Liang', 'Jihua Zhu', 'Wei Zhang', 'Xiaojun Chang', 'Hang Xu']","['School of Software Engineering, Xi’an Jiaotong University\nPengCheng Laboratory', ""Huawei Noah's Ark Lab"", 'Sun Yat-sen University MBZUAI', ""Xi'an Jiaotong University"", ""Huawei Noah's Ark Lab"", 'ReLER, AAII, University of Technology Sydney', ""Huawei Noah's Ark Lab""]","['CV: Multi-modal Vision']","Jiang, Z., Lu, G., Liang, X., Zhu, J., Zhang, W., Chang, X., & Xu, H. (2023). 3D-TOGO: Towards Text-Guided Cross-Category 3D Object Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1051-1059. https://doi.org/10.1609/aaai.v37i1.25186 (Original work published June 26, 2023)","Abstract This article has been updated and an error has been fixed in published paper. An Erratum to this article was published on 6 September 2023.  Text-guided 3D object generation aims to generate 3D objects described by user-defined captions, which paves a flexible way to visualize what we imagined. Although some works have been devoted to solving this challenging task, these works either utilize some explicit 3D representations (e.g., mesh), which lack texture and require post-processing for rendering photo-realistic views; or require individual time-consuming optimization for every single case. Here, we make the first attempt to achieve generic text-guided cross-category 3D object generation via a new 3D-TOGO model, which integrates a text-to-views generation module and a views-to-3D generation module. The text-to-views generation module is designed to generate different views of the target 3D object given an input caption. prior-guidance, caption-guidance and view contrastive learning are proposed for achieving better view-consistency and caption similarity. Meanwhile, a pixelNeRF model is adopted for the views-to-3D generation module to obtain the implicit 3D neural representation from the previously-generated views. Our 3D-TOGO model generates 3D objects in the form of the neural radiance field with good texture and requires no time-cost optimization for every single caption. Besides, 3D-TOGO can control the category, color and shape of generated 3D objects with the input caption. Extensive experiments on the largest 3D object dataset (i.e., ABO) are conducted to verify that 3D-TOGO can better generate high-quality 3D objects according to the input captions across 98 different categories, in terms of PSNR, SSIM, LPIPS and CLIP-score, compared with text-NeRF and Dreamfields.","https://ojs.aaai.org/index.php/AAAI/article/view/25186/27093"
"25187","FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer","['Shibo Jie', 'Zhi-Hong Deng']","['Peking University', 'Peking University']","['CV: Learning & Optimization for CV', 'CV: Object Detection & Categorization', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Jie, S., & Deng, Z.-H. (2023). FacT: Factor-Tuning for Lightweight Adaptation on Vision Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1060-1068. https://doi.org/10.1609/aaai.v37i1.25187","Abstract 					Recent work has explored the potential to adapt a pre-trained vision transformer (ViT) by updating only a few parameters so as to improve storage efficiency, called parameter-efficient transfer learning (PETL). Current PETL methods have shown that by tuning only 0.5% of the parameters, ViT can be adapted to downstream tasks with even better performance than full fine-tuning. In this paper, we aim to further promote the efficiency of PETL to meet the extreme storage constraint in real-world applications. To this end, we propose a tensorization-decomposition framework to store the weight increments, in which the weights of each ViT are tensorized into a single 3D tensor, and their increments are then decomposed into lightweight factors. In the fine-tuning process, only the factors need to be updated and stored, termed Factor-Tuning (FacT). On VTAB-1K benchmark, our method performs on par with NOAH, the state-of-the-art PETL method, while being 5x more parameter-efficient. We also present a tiny version that only uses 8K (0.01% of ViT's parameters) trainable parameters but outperforms full fine-tuning and many other PETL methods such as VPT and BitFit. In few-shot settings, FacT also beats all PETL baselines using the fewest parameters, demonstrating its strong capability in the low-data regime.","https://ojs.aaai.org/index.php/AAAI/article/view/25187/24959"
"25188","Estimating Reflectance Layer from a Single Image: Integrating Reflectance Guidance and Shadow/Specular Aware Learning","['Yeying Jin', 'Ruoteng Li', 'Wenhan Yang', 'Robby T. Tan']","['National University of Singapore', 'National University of Singapore\nByteDance', 'Peng Cheng Laboratory', 'National University of Singapore\nYale-NUS College']","['CV: Applications', 'CV: Low Level & Physics-Based Vision']","Jin, Y., Li, R., Yang, W., & Tan, R. T. (2023). Estimating Reflectance Layer from a Single Image: Integrating Reflectance Guidance and Shadow/Specular Aware Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1069-1077. https://doi.org/10.1609/aaai.v37i1.25188","Abstract 					Estimating the reflectance layer from a single image is a challenging task. It becomes more challenging when the input image contains shadows or specular highlights, which often render an inaccurate estimate of the reflectance layer. Therefore, we propose a two-stage learning method, including reflectance guidance and a Shadow/Specular-Aware (S-Aware) network to tackle the problem. In the first stage, an initial reflectance layer free from shadows and specularities is obtained with the constraint of novel losses that are guided by prior-based shadow-free and specular-free images. To further enforce the reflectance layer to be independent of shadows and specularities in the second-stage refinement, we introduce an S-Aware network that distinguishes the reflectance image from the input image. Our network employs a classifier to categorize shadow/shadow-free, specular/specular-free classes, enabling the activation features to function as attention maps that focus on shadow/specular regions. Our quantitative and qualitative evaluations show that our method outperforms the state-of-the-art methods in the reflectance layer estimation that is free from shadows and specularities.","https://ojs.aaai.org/index.php/AAAI/article/view/25188/24960"
"25189","Weakly-Guided Self-Supervised Pretraining for Temporal Activity Detection","['Kumara Kahatapitiya', 'Zhou Ren', 'Haoxiang Li', 'Zhenyu Wu', 'Michael S. Ryoo', 'Gang Hua']","['Stony Brook University', 'Wormpex AI Research', 'Wormpex AI Research', 'Wormpex AI Research', 'Stony Brook University', 'Wormpex AI Research']","['CV: Video Understanding & Activity Analysis', 'CV: Representation Learning for Vision']","Kahatapitiya, K., Ren, Z., Li, H., Wu, Z., Ryoo, M. S., & Hua, G. (2023). Weakly-Guided Self-Supervised Pretraining for Temporal Activity Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1078-1086. https://doi.org/10.1609/aaai.v37i1.25189","Abstract 					Temporal Activity Detection aims to predict activity classes per frame, in contrast to video-level predictions in Activity Classification (i.e., Activity Recognition). Due to the expensive frame-level annotations required for detection, the scale of detection datasets is limited. Thus, commonly, previous work on temporal activity detection resorts to fine-tuning a classification model pretrained on large-scale classification datasets (e.g., Kinetics-400). However, such pretrained models are not ideal for downstream detection, due to the disparity between the pretraining and the downstream fine-tuning tasks. In this work, we propose a novel weakly-guided self-supervised pretraining method for detection. We leverage weak labels (classification) to introduce a self-supervised pretext task (detection) by generating frame-level pseudo labels, multi-action frames, and action segments. Simply put, we design a detection task similar to downstream, on large-scale classification data, without extra annotations. We show that the models pretrained with the proposed weakly-guided self-supervised detection task outperform prior work on multiple challenging activity detection benchmarks, including Charades and MultiTHUMOS. Our extensive ablations further provide insights on when and how to use the proposed models for activity detection. Code is available at github.com/kkahatapitiya/SSDet.","https://ojs.aaai.org/index.php/AAAI/article/view/25189/24961"
"25190","Correlation Loss: Enforcing Correlation between Classification and Localization","['Fehmi Kahraman', 'Kemal Oksuz', 'Sinan Kalkan', 'Emre Akbas']","['Middle East Technical University', 'Middle East Technical University', 'Middle East Technical University', 'Middle East Technical University']","['CV: Object Detection & Categorization', 'CV: Segmentation']","Kahraman, F., Oksuz, K., Kalkan, S., & Akbas, E. (2023). Correlation Loss: Enforcing Correlation between Classification and Localization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1087-1095. https://doi.org/10.1609/aaai.v37i1.25190","Abstract 					Object detectors are conventionally trained by a weighted sum of classification and localization losses. Recent studies (e.g., predicting IoU with an auxiliary head, Generalized Focal Loss, Rank & Sort Loss) have shown that forcing these two loss terms to interact with each other in non-conventional ways creates a useful inductive bias and improves performance. Inspired by these works, we focus on the correlation between classification and localization and make two main contributions: (i) We provide an analysis about the effects of correlation between classification and localization tasks in object detectors.  We identify why correlation affects the performance of various NMS-based and NMS-free detectors, and we devise measures to evaluate the effect of correlation and use them to analyze common detectors. (ii) Motivated by our observations, e.g., that NMS-free detectors can also benefit from correlation, we propose Correlation Loss, a novel plug-in loss function that improves the performance of various object detectors by directly optimizing correlation coefficients: E.g., Correlation Loss on Sparse R-CNN, an NMS-free method, yields 1.6 AP gain on COCO and 1.8 AP gain on Cityscapes dataset. Our best model on Sparse R-CNN reaches 51.0 AP without test-time augmentation on COCO test-dev, reaching state-of-the-art.  Code is available at: https://github.com/fehmikahraman/CorrLoss.","https://ojs.aaai.org/index.php/AAAI/article/view/25190/24962"
"25191","GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps","['Minsoo Kang', 'Suhyun Kim']","['Korea Institute of Science and Technology\nKorea University', 'Korea Institute of Science and Technology']","['CV: Learning & Optimization for CV', 'CV: Adversarial Attacks & Robustness']","Kang, M., & Kim, S. (2023). GuidedMixup: An Efficient Mixup Strategy Guided by Saliency Maps. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1096-1104. https://doi.org/10.1609/aaai.v37i1.25191","Abstract 					Data augmentation is now an essential part of the image training process, as it effectively prevents overfitting and makes the model more robust against noisy datasets. Recent mixing augmentation strategies have advanced to generate the mixup mask that can enrich the saliency information, which is a supervisory signal. However, these methods incur a significant computational burden to optimize the mixup mask. From this motivation, we propose a novel saliency-aware mixup method, GuidedMixup, which aims to retain the salient regions in mixup images with low computational overhead. We develop an efficient pairing algorithm that pursues to minimize the conflict of salient regions of paired images and achieve rich saliency in mixup images. Moreover, GuidedMixup controls the mixup ratio for each pixel to better preserve the salient region by interpolating two paired images smoothly. The experiments on several datasets demonstrate that GuidedMixup provides a good trade-off between augmentation overhead and generalization performance on classification datasets. In addition, our method shows good performance in experiments with corrupted or reduced datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25191/24963"
"25192","3D Human Pose Lifting with Grid Convolution","['Yangyuxuan Kang', 'Yuyang Liu', 'Anbang Yao', 'Shandong Wang', 'Enhua Wu']","['SKLCS, Institute of Software Chinese Academy of Sciences', 'Tsinghua University', 'Intel Labs China', 'Intel Labs China', 'SKLCS, Institute of Software, Chinese Academy of Sciences, Beijing, China；Faculty of Science and Technology, University of Macau, Macao, China']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: 3D Computer Vision']","Kang, Y., Liu, Y., Yao, A., Wang, S., & Wu, E. (2023). 3D Human Pose Lifting with Grid Convolution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1105-1113. https://doi.org/10.1609/aaai.v37i1.25192","Abstract 					Existing lifting networks for regressing 3D human poses from 2D single-view poses are typically constructed with linear layers based on graph-structured representation learning. In sharp contrast to them, this paper presents Grid Convolution (GridConv), mimicking the wisdom of regular convolution operations in image space. GridConv is based on a novel Semantic Grid Transformation (SGT) which leverages a binary assignment matrix to map the irregular graph-structured human pose onto a regular weave-like grid pose representation joint by joint, enabling layer-wise feature learning with GridConv operations. We provide two ways to implement SGT, including handcrafted and learnable designs. Surprisingly, both designs turn out to achieve promising results and the learnable one is better, demonstrating the great potential of this new lifting representation learning formulation. To improve the ability of GridConv to encode contextual cues, we introduce an attention module over the convolutional kernel, making grid convolution operations input-dependent, spatial-aware and grid-specific. We show that our fully convolutional grid lifting network outperforms state-of-the-art methods with noticeable margins under (1) conventional evaluation on Human3.6M and (2) cross-evaluation on MPI-INF-3DHP. Code is available at https://github.com/OSVAI/GridConv.","https://ojs.aaai.org/index.php/AAAI/article/view/25192/24964"
"25193","Bidirectional Domain Mixup for Domain Adaptive Semantic Segmentation","['Daehan Kim', 'Minseok Seo', 'Kwanyong Park', 'Inkyu Shin', 'Sanghyun Woo', 'In So Kweon', 'Dong-Geol Choi']","['Hanbat National University', 'SI-Analytics', 'KAIST', 'KAIST', 'KAIST', 'KAIST', 'Hanbat National University']","['CV: Segmentation', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Unsupervised & Self-Supervised Learning']","Kim, D., Seo, M., Park, K., Shin, I., Woo, S., Kweon, I. S., & Choi, D.-G. (2023). Bidirectional Domain Mixup for Domain Adaptive Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1114-1123. https://doi.org/10.1609/aaai.v37i1.25193","Abstract 					Mixup provides interpolated training samples and allows the model to obtain smoother decision boundaries for better generalization. The idea can be naturally applied to the domain adaptation task, where we can mix the source and target samples to obtain domain-mixed samples for better adaptation. However, the extension of the idea from classification to segmentation (i.e., structured output) is nontrivial. This paper systematically studies the impact of mixup under the domain adaptive semantic segmentation task and presents a simple yet effective mixup strategy called Bidirectional Domain Mixup (BDM). In specific, we achieve domain mixup in two-step: cut and paste. Given the warm-up model trained from any adaptation techniques, we forward the source and target samples and perform a simple threshold-based cut out of the unconfident regions (cut). After then, we fill-in the dropped regions with the other domain region patches (paste). In doing so, we jointly consider class distribution, spatial structure, and pseudo label confidence. Based on our analysis, we found that BDM leaves domain transferable regions by cutting, balances the dataset-level class distribution while preserving natural scene context by pasting. We coupled our proposal with various state-of-the-art adaptation models and observe significant improvement consistently. We also provide extensive ablation experiments to empirically verify our main components of the framework. Visit our project page with the code at https://sites.google.com/view/bidirectional-domain-mixup","https://ojs.aaai.org/index.php/AAAI/article/view/25193/24965"
"25194","Frequency Selective Augmentation for Video Representation Learning","['Jinhyung Kim', 'Taeoh Kim', 'Minho Shim', 'Dongyoon Han', 'Dongyoon Wee', 'Junmo Kim']","['LG AI Research', 'NAVER CLOVA Video', 'NAVER CLOVA Video', 'NAVER AI Lab', 'NAVER CLOVA Video', 'KAIST']","['CV: Representation Learning for Vision', 'CV: Video Understanding & Activity Analysis', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning']","Kim, J., Kim, T., Shim, M., Han, D., Wee, D., & Kim, J. (2023). Frequency Selective Augmentation for Video Representation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1124-1132. https://doi.org/10.1609/aaai.v37i1.25194","Abstract 					Recent self-supervised video representation learning methods focus on maximizing the similarity between multiple augmented views from the same video and largely rely on the quality of generated views. However, most existing methods lack a mechanism to prevent representation learning from bias towards static information in the video. In this paper, we propose frequency augmentation (FreqAug), a spatio-temporal data augmentation method in the frequency domain for video representation learning. FreqAug stochastically removes specific frequency components from the video so that learned representation captures essential features more from the remaining information for various downstream tasks. Specifically, FreqAug pushes the model to focus more on dynamic features rather than static features in the video via dropping spatial or temporal low-frequency components. To verify the generality of the proposed method, we experiment with FreqAug on multiple self-supervised learning frameworks along with standard augmentations. Transferring the improved representation to five video action recognition and two temporal action localization downstream tasks shows consistent improvements over baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/25194/24966"
"25195","Pose-Guided 3D Human Generation in Indoor Scene","['Minseok Kim', 'Changwoo Kang', 'Jeongin Park', 'Kyungdon Joo']","['UNIST', 'UNIST', 'UNIST', 'UNIST']","['CV: 3D Computer Vision', 'ML: Deep Generative Models & Autoencoders']","Kim, M., Kang, C., Park, J., & Joo, K. (2023). Pose-Guided 3D Human Generation in Indoor Scene. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1133-1141. https://doi.org/10.1609/aaai.v37i1.25195","Abstract 					In this work, we address the problem of scene-aware 3D human avatar generation based on human-scene interactions. In particular, we pay attention to the fact that physical contact between a 3D human and a scene (i.e., physical human-scene interactions) requires a geometrical alignment to generate natural 3D human avatar. Motivated by this fact, we present a new 3D human generation framework that considers geometric alignment on potential contact areas between 3D human avatars and their surroundings. In addition, we introduce a compact yet effective human pose classifier that classifies the human pose and provides potential contact areas of the 3D human avatar. It allows us to adaptively use geometric alignment loss according to the classified human pose. Compared to state-of-the-art method, our method can generate physically and semantically plausible 3D humans that interact naturally with 3D scenes without additional post-processing. In our evaluations, we achieve the improvements with more plausible interactions and more variety of poses than prior research in qualitative and quantitative analysis. Project page: https://bupyeonghealer.github.io/phin/.","https://ojs.aaai.org/index.php/AAAI/article/view/25195/24967"
"25196","Semantic-Aware Superpixel for Weakly Supervised Semantic Segmentation","['Sangtae Kim', 'Daeyoung Park', 'Byonghyo Shim']","['Seoul National University', 'Inha University', 'Seoul National University']","['CV: Segmentation', 'ML: Classification and Regression', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Deep Neural Network Algorithms', 'ML: Clustering', 'ML: Unsupervised & Self-Supervised Learning']","Kim, S., Park, D., & Shim, B. (2023). Semantic-Aware Superpixel for Weakly Supervised Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1142-1150. https://doi.org/10.1609/aaai.v37i1.25196","Abstract 					Weakly-supervised semantic segmentation aims to train a semantic segmentation network using weak labels. Among weak labels, image-level label has been the most popular choice due to its simplicity. However, since image-level labels lack accurate object region information, additional modules such as saliency detector have been exploited in weakly supervised semantic segmentation, which requires pixel-level label for training. In this paper, we explore a self-supervised vision transformer to mitigate the heavy efforts on generation of pixel-level annotations. By exploiting the features obtained from self-supervised vision transformer, our superpixel discovery method finds out the semantic-aware superpixels based on the feature similarity in an unsupervised manner. Once we obtain the superpixels, we train the semantic segmentation network using superpixel-guided seeded region growing method. Despite its simplicity, our approach achieves the competitive result with the state-of-the-arts on PASCAL VOC 2012 and MS-COCO 2014 semantic segmentation datasets for weakly supervised semantic segmentation. Our code is available at https://github.com/st17kim/semantic-aware-superpixel.","https://ojs.aaai.org/index.php/AAAI/article/view/25196/24968"
"25197","Multispectral Invisible Coating: Laminated Visible-Thermal Physical Attack against Multispectral Object Detectors Using Transparent Low-E Films","['Taeheon Kim', 'Youngjoon Yu', 'Yong Man Ro']","['KAIST', 'KAIST', 'KAIST']","['CV: Adversarial Attacks & Robustness', 'CV: Applications', 'CV: Multi-modal Vision', 'CV: Object Detection & Categorization']","Kim, T., Yu, Y., & Ro, Y. M. (2023). Multispectral Invisible Coating: Laminated Visible-Thermal Physical Attack against Multispectral Object Detectors Using Transparent Low-E Films. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1151-1159. https://doi.org/10.1609/aaai.v37i1.25197","Abstract 					Multispectral object detection plays a vital role in safety-critical vision systems that require an around-the-clock operation and encounter dynamic real-world situations(e.g., self-driving cars and autonomous surveillance systems). Despite its crucial competence in safety-related applications, its security against physical attacks is severely understudied. We investigate the vulnerability of multispectral detectors against physical attacks by proposing a new physical method: Multispectral Invisible Coating. Utilizing transparent Low-e films, we realize a laminated visible-thermal physical attack by attaching Low-e films over a visible attack printing. Moreover, we apply our physical method to manufacture a Multispectral Invisible Suit that hides persons from the multiple view angles of Multispectral detectors. To simulate our attack under various surveillance scenes, we constructed a large-scale multispectral pedestrian dataset which we will release in public. Extensive experiments show that our proposed method effectively attacks the state-of-the-art multispectral detector both in the digital space and the physical world.","https://ojs.aaai.org/index.php/AAAI/article/view/25197/24969"
"25198","CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion Transformer","['Youngseok Kim', 'Sanmin Kim', 'Jun Won Choi', 'Dongsuk Kum']","['Korea Advanced Institute of Science and Technology', 'Korea Advanced Institute of Science and Technology', 'Hanyang University', 'Korea Advanced Institute of Science and Technology']","['CV: Vision for Robotics & Autonomous Driving', 'CV: 3D Computer Vision', 'CV: Multi-modal Vision', 'CV: Object Detection & Categorization', 'ROB: Multimodal Perception & Sensor Fusion']","Kim, Y., Kim, S., Choi, J. W., & Kum, D. (2023). CRAFT: Camera-Radar 3D Object Detection with Spatio-Contextual Fusion Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1160-1168. https://doi.org/10.1609/aaai.v37i1.25198","Abstract 					Camera and radar sensors have significant advantages in cost, reliability, and maintenance compared to LiDAR. Existing fusion methods often fuse the outputs of single modalities at the result-level, called the late fusion strategy. This can benefit from using off-the-shelf single sensor detection algorithms, but late fusion cannot fully exploit the complementary properties of sensors, thus having limited performance despite the huge potential of camera-radar fusion. Here we propose a novel proposal-level early fusion approach that effectively exploits both spatial and contextual properties of camera and radar for 3D object detection. Our fusion framework first associates image proposal with radar points in the polar coordinate system to efficiently handle the discrepancy between the coordinate system and spatial properties. Using this as a first stage, following consecutive cross-attention based feature fusion layers adaptively exchange spatio-contextual information between camera and radar, leading to a robust and attentive fusion. Our camera-radar fusion approach achieves the state-of-the-art 41.1% mAP and 52.3% NDS on the nuScenes test set, which is 8.7 and 10.8 points higher than the camera-only baseline, as well as yielding competitive performance on the LiDAR method.","https://ojs.aaai.org/index.php/AAAI/article/view/25198/24970"
"25199","Simple and Effective Synthesis of Indoor 3D Scenes","['Jing Yu Koh', 'Harsh Agrawal', 'Dhruv Batra', 'Richard Tucker', 'Austin Waters', 'Honglak Lee', 'Yinfei Yang', 'Jason Baldridge', 'Peter Anderson']","['Google Research', 'Georgia Institute of Technology', 'Georgia Institute of Technology', 'Google Research', 'Google Research', 'University of Michigan', 'Apple', 'Google Research', 'Google Research']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Language and Vision', 'CV: Vision for Robotics & Autonomous Driving']","Koh, J. Y., Agrawal, H., Batra, D., Tucker, R., Waters, A., Lee, H., Yang, Y., Baldridge, J., & Anderson, P. (2023). Simple and Effective Synthesis of Indoor 3D Scenes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1169-1178. https://doi.org/10.1609/aaai.v37i1.25199","Abstract 					We study the problem of synthesizing immersive 3D indoor scenes from one or a few images. Our aim is to generate high-resolution images and videos from novel viewpoints, including viewpoints that extrapolate far beyond the input images while maintaining 3D consistency. Existing approaches are highly complex, with many separately trained stages and components. We propose a simple alternative: an image-to-image GAN that maps directly from reprojections of incomplete point clouds to full high-resolution RGB-D images. On the Matterport3D and RealEstate10K datasets, our approach significantly outperforms prior work when evaluated by humans, as well as on FID scores. Further, we show that our model is useful for generative data augmentation. A vision-and-language navigation (VLN) agent trained with trajectories spatially-perturbed by our model improves success rate by up to 1.5% over a state of the art baseline on the mature R2R benchmark. Our code will be made available to facilitate generative data augmentation and applications to downstream robotics and embodied AI tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25199/24971"
"25200","MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term Motion-Guided Temporal Attention for 3D Object Detection","['Junho Koh', 'Junhyung Lee', 'Youngwoo Lee', 'Jaekyum Kim', 'Jun Won Choi']","['Hanyang University', 'Hanyang University', 'Hanyang University', 'Hanyang University', 'Hanyang University']","['CV: Vision for Robotics & Autonomous Driving', 'CV: Object Detection & Categorization']","Koh, J., Lee, J., Lee, Y., Kim, J., & Choi, J. W. (2023). MGTANet: Encoding Sequential LiDAR Points Using Long Short-Term Motion-Guided Temporal Attention for 3D Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1179-1187. https://doi.org/10.1609/aaai.v37i1.25200","Abstract 					Most scanning LiDAR sensors generate a sequence of point clouds in real-time. While conventional 3D object detectors use a set of unordered LiDAR points acquired over a fixed time interval, recent studies have revealed that substantial performance improvement can be achieved by exploiting the spatio-temporal context present in a sequence of LiDAR point sets. In this paper, we propose a novel 3D object detection architecture, which can encode LiDAR point cloud sequences acquired by multiple successive scans. The encoding process of the point cloud sequence is performed on two different time scales. We first design a short-term motion-aware voxel encoding that captures the short-term temporal changes of point clouds driven by the motion of objects in each voxel. We also propose long-term motion-guided bird’s eye view (BEV) feature enhancement that adaptively aligns and aggregates the BEV feature maps obtained by the short-term voxel encoding by utilizing the dynamic motion context inferred from the sequence of the feature maps. The experiments conducted on the public nuScenes benchmark demonstrate that the proposed 3D object detector offers significant improvements in performance compared to the baseline methods and that it sets a state-of-the-art performance for certain 3D object detection categories. Code is available at https://github.com/HYjhkoh/MGTANet.git.","https://ojs.aaai.org/index.php/AAAI/article/view/25200/24972"
"25201","InstanceFormer: An Online Video Instance Segmentation Framework","['Rajat Koner', 'Tanveer Hannan', 'Suprosanna Shit', 'Sahand Sharifzadeh', 'Matthias Schubert', 'Thomas Seidl', 'Volker Tresp']","['Ludwig Maximilian University of Munich\nMCML', 'Ludwig Maximilian University of Munich\nMCML', 'Technical University of Munich', 'Ludwig Maximilian University of Munich', 'Ludwig Maximilian University of Munich\nMCML', 'Ludwig Maximilian University of Munich\nMCML', 'Ludwig Maximilian University of Munich\nMCML']","['CV: Segmentation', 'CV: Motion & Tracking', 'CV: Video Understanding & Activity Analysis']","Koner, R., Hannan, T., Shit, S., Sharifzadeh, S., Schubert, M., Seidl, T., & Tresp, V. (2023). InstanceFormer: An Online Video Instance Segmentation Framework. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1188-1195. https://doi.org/10.1609/aaai.v37i1.25201","Abstract 					Recent transformer-based offline video instance segmentation (VIS) approaches achieve encouraging results and significantly outperform online approaches. However, their reliance on the whole video and the immense computational complexity caused by full Spatio-temporal attention limit them in real-life applications such as processing lengthy videos. In this paper, we propose a single-stage transformer-based efficient online VIS framework named InstanceFormer, which is especially suitable for long and challenging videos. We propose three novel components to model short-term and long-term dependency and temporal coherence. First, we propagate the representation, location, and semantic information of prior instances to model short-term changes. Second, we propose a novel memory cross-attention in the decoder, which allows the network to look into earlier instances within a certain temporal window. Finally, we employ a temporal contrastive loss to impose coherence in the representation of an instance across all frames. Memory attention and temporal coherence are particularly beneficial to long-range dependency modeling, including challenging scenarios like occlusion. The proposed InstanceFormer outperforms previous online benchmark methods by a large margin across multiple datasets. Most importantly, InstanceFormer surpasses offline approaches for challenging and long datasets such as YouTube-VIS-2021 and OVIS. Code is available at https://github.com/rajatkoner08/InstanceFormer.","https://ojs.aaai.org/index.php/AAAI/article/view/25201/24973"
"25202","Pixel-Wise Warping for Deep Image Stitching","['Hyeokjun Kweon', 'Hyeonseong Kim', 'Yoonsu Kang', 'Youngho Yoon', 'WooSeong Jeong', 'Kuk-Jin Yoon']","['KAIST', 'KAIST', 'KAIST', 'KAIST', 'KAIST', 'KAIST']","['CV: Applications']","Kweon, H., Kim, H., Kang, Y., Yoon, Y., Jeong, W., & Yoon, K.-J. (2023). Pixel-Wise Warping for Deep Image Stitching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1196-1204. https://doi.org/10.1609/aaai.v37i1.25202","Abstract 					Existing image stitching approaches based on global or local homography estimation are not free from the parallax problem and suffer from undesired artifacts. In this paper, instead of relying on the homography-based warp, we propose a novel deep image stitching framework exploiting the pixel-wise warp field to handle the large-parallax problem. The proposed deep image stitching framework consists of a Pixel-wise Warping Module (PWM) and a Stitched Image Generating Module (SIGMo). For PWM, we obtain pixel-wise warp in a similar manner as estimating an optical flow (OF). In the stitching scenario, the input images usually include non-overlap (NOV) regions of which warp cannot be directly estimated, unlike the overlap (OV) regions. To help the PWM predict a reasonable warp on the NOV region, we impose two geometrical constraints: an epipolar loss and a line-preservation loss. With the obtained warp field, we relocate the pixels of the target image using forward warping. Finally, the SIGMo is trained by the proposed multi-branch training framework to generate a stitched image from a reference image and a warped target image. For training and evaluating the proposed framework, we build and publish a novel dataset including image pairs with corresponding pixel-wise ground truth warp and stitched result images. We show that the results of the proposed framework are quantitatively and qualitatively superior to those of the conventional methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25202/24974"
"25203","Learning to Learn Better for Video Object Segmentation","['Meng Lan', 'Jing Zhang', 'Lefei Zhang', 'Dacheng Tao']","['Institute of Artificial Intelligence and School of Computer Science, Wuhan University, China', 'The University of Sydney, Australia', 'Institute of Artificial Intelligence and School of Computer Science, Wuhan University, China\nHubei Luojia Laboratory, China', 'JD Explore Academy, China\nThe University of Sydney, Australia']","['CV: Segmentation', 'CV: Video Understanding & Activity Analysis']","Lan, M., Zhang, J., Zhang, L., & Tao, D. (2023). Learning to Learn Better for Video Object Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1205-1212. https://doi.org/10.1609/aaai.v37i1.25203","Abstract 					Recently, the joint learning framework (JOINT) integrates matching based transductive reasoning and online inductive learning to achieve accurate and robust semi-supervised video object segmentation (SVOS). However, using the mask embedding as the label to guide the generation of target features in the two branches may result in inadequate target representation and degrade the performance. Besides, how to reasonably fuse the target features in the two different branches rather than simply adding them together to avoid the adverse effect of one dominant branch has not been investigated. In this paper, we propose a novel framework that emphasizes Learning to Learn Better (LLB) target features for SVOS, termed LLB, where we design the discriminative label generation module (DLGM) and the adaptive fusion module to address these issues. Technically, the DLGM takes the background-filtered frame instead of the target mask as input and adopts a lightweight encoder to generate the target features, which serves as the label of the online few-shot learner and the value of the decoder in the transformer to guide the two branches to learn more discriminative target representation. The adaptive fusion module maintains a learnable gate for each branch, which reweighs the element-wise feature representation and allows an adaptive amount of target information in each branch flowing to the fused target feature, thus preventing one branch from being dominant and making the target feature more robust to distractor. Extensive experiments on public benchmarks show that our proposed LLB method achieves state-of-the-art performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25203/24975"
"25204","Curriculum Multi-Negative Augmentation for Debiased Video Grounding","['Xiaohan Lan', 'Yitian Yuan', 'Hong Chen', 'Xin Wang', 'Zequn Jie', 'Lin Ma', 'Zhi Wang', 'Wenwu Zhu']","['Tsinghua University', 'Meituan Inc.', 'Tsinghua University', 'Tsinghua University', 'Meituan Inc.', 'Meituan Inc.', 'Tsinghua University', 'Tsinghua University']","['CV: Video Understanding & Activity Analysis', 'CV: Language and Vision', 'CV: Multi-modal Vision']","Lan, X., Yuan, Y., Chen, H., Wang, X., Jie, Z., Ma, L., Wang, Z., & Zhu, W. (2023). Curriculum Multi-Negative Augmentation for Debiased Video Grounding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1213-1221. https://doi.org/10.1609/aaai.v37i1.25204","Abstract 					Video Grounding (VG) aims to locate the desired segment from a video given a sentence query. Recent studies have found that current VG models are prone to over-rely the groundtruth moment annotation distribution biases in the training set. To discourage the standard VG model's behavior of exploiting such temporal annotation biases and improve the model generalization ability, we propose multiple negative augmentations in a hierarchical way, including cross-video augmentations from clip-/video-level, and self-shuffled augmentations with masks. These augmentations can effectively diversify the data distribution so that the model can make more reasonable predictions instead of merely fitting the temporal biases. However, directly adopting such data augmentation strategy may inevitably carry some noise shown in our cases, since not all of the handcrafted augmentations are semantically irrelevant to the groundtruth video. To further denoise and improve the grounding accuracy, we design a multi-stage curriculum strategy to adaptively train the standard VG model from easy to hard negative augmentations. Experiments on newly collected Charades-CD and ActivityNet-CD datasets demonstrate our proposed strategy can improve the performance of the base model on both i.i.d and o.o.d scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/25204/24976"
"25205","Weakly Supervised 3D Segmentation via Receptive-Driven Pseudo Label Consistency and Structural Consistency","['Yuxiang Lan', 'Yachao Zhang', 'Yanyun Qu', 'Cong Wang', 'Chengyang Li', 'Jia Cai', 'Yuan Xie', 'Zongze Wu']","['Xiamen University', 'Xiamen University', 'Xiamen University', 'Huawei Technologies', 'East China Normal University', 'East China Normal University', 'East China Normal University', 'Guangdong University of Technology']","['CV: 3D Computer Vision', 'CV: Segmentation']","Lan, Y., Zhang, Y., Qu, Y., Wang, C., Li, C., Cai, J., Xie, Y., & Wu, Z. (2023). Weakly Supervised 3D Segmentation via Receptive-Driven Pseudo Label Consistency and Structural Consistency. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1222-1230. https://doi.org/10.1609/aaai.v37i1.25205","Abstract 					As manual point-wise label is time and labor-intensive for fully supervised large-scale point cloud  semantic segmentation, weakly supervised method is increasingly active. However, existing methods fail to generate high-quality pseudo labels effectively, leading to unsatisfactory results. In this paper, we propose a weakly supervised point cloud semantic segmentation framework via receptive-driven pseudo label consistency and structural consistency to mine potential knowledge. Specifically, we propose three consistency contrains: pseudo label consistency among different scales,  semantic structure consistency between intra-class features and class-level relation structure consistency between pair-wise categories.  Three consistency constraints are jointly used to effectively prepares and utilizes pseudo labels simultaneously for stable training. Finally, extensive experimental results on three challenging datasets demonstrate that our method significantly outperforms state-of-the-art weakly supervised methods and even achieves comparable performance to the fully supervised methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25205/24977"
"25206","MultiAct: Long-Term 3D Human Motion Generation from Multiple Action Labels","['Taeryung Lee', 'Gyeongsik Moon', 'Kyoung Mu Lee']","['Seoul National University', 'Meta Reality Labs Research', 'Seoul National University']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Motion & Tracking']","Lee, T., Moon, G., & Lee, K. M. (2023). MultiAct: Long-Term 3D Human Motion Generation from Multiple Action Labels. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1231-1239. https://doi.org/10.1609/aaai.v37i1.25206","Abstract 					We tackle the problem of generating long-term 3D human motion from multiple action labels. Two main previous approaches, such as action- and motion-conditioned methods, have limitations to solve this problem. The action-conditioned methods generate a sequence of motion from a single action. Hence, it cannot generate long-term motions composed of multiple actions and transitions between actions. Meanwhile, the motion-conditioned methods generate future motions from initial motion. The generated future motions only depend on the past, so they are not controllable by the user's desired actions. We present MultiAct, the first framework to generate long-term 3D human motion from multiple action labels. MultiAct takes account of both action and motion conditions with a unified recurrent generation system. It repetitively takes the previous motion and action label; then, it generates a smooth transition and the motion of the given action. As a result, MultiAct produces realistic long-term motion controlled by the given sequence of multiple action labels. The code is publicly available in https://github.com/TaeryungLee/MultiAct RELEASE.","https://ojs.aaai.org/index.php/AAAI/article/view/25206/24978"
"25207","Not All Neighbors Matter: Point Distribution-Aware Pruning for 3D Point Cloud","['Yejin Lee', 'Donghyun Lee', 'JungUk Hong', 'Jae W. Lee', 'Hongil Yoon']","['Seoul National University', 'Seoul National University', 'Seoul National University', 'Seoul National University', 'Google']","['CV: 3D Computer Vision', 'ML: Learning on the Edge & Model Compression']","Lee, Y., Lee, D., Hong, J., Lee, J. W., & Yoon, H. (2023). Not All Neighbors Matter: Point Distribution-Aware Pruning for 3D Point Cloud. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1240-1249. https://doi.org/10.1609/aaai.v37i1.25207","Abstract 					Applying deep neural networks to 3D point cloud processing has demonstrated a rapid pace of advancement in those domains where 3D geometry information can greatly boost task performance, such as AR/VR, robotics, and autonomous driving. However, as the size of both the neural network model and 3D point cloud continues to scale, reducing the entailed computation and memory access overhead is a primary challenge to meet strict latency and energy constraints of practical applications. This paper proposes a new weight pruning technique for 3D point cloud based on spatial point distribution. We identify that particular groups of neighborhood voxels in 3D point cloud contribute more frequently to actual output features than others. Based on this observation, we propose to selectively prune less contributing groups of neighborhood voxels first to reduce the computation overhead while minimizing the impact on model accuracy. We apply our proposal to three representative sparse 3D convolution libraries. Our proposal reduces the inference latency by 1.60× on average and energy consumption by 1.74× on NVIDIA GV100 GPU with no loss in accuracy metric","https://ojs.aaai.org/index.php/AAAI/article/view/25207/24979"
"25208","Symbolic Replay: Scene Graph as Prompt for Continual Learning on VQA Task","['Stan Weixian Lei', 'Difei Gao', 'Jay Zhangjie Wu', 'Yuxuan Wang', 'Wei Liu', 'Mengmi Zhang', 'Mike Zheng Shou']","['National University of Singapore', 'National University of Singapore', 'National University of Singapore', 'National University of Singapore', 'Tencent Data Platform', 'CFAR and I2R, Agency for Science, Technology, and Research (A*STAR), Singapore', 'National University of Singapore']","['CV: Language and Vision', 'ML: Lifelong and Continual Learning']","Lei, S. W., Gao, D., Wu, J. Z., Wang, Y., Liu, W., Zhang, M., & Shou, M. Z. (2023). Symbolic Replay: Scene Graph as Prompt for Continual Learning on VQA Task. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1250-1259. https://doi.org/10.1609/aaai.v37i1.25208","Abstract 					VQA is an ambitious task aiming to answer any image-related question. However, in reality, it is hard to build such a system once for all since the needs of users are continuously updated, and the system has to implement new functions. Thus, Continual Learning (CL) ability is a must in developing advanced VQA systems. Recently, a pioneer work split a VQA dataset into disjoint answer sets to study this topic. However, CL on VQA involves not only the expansion of label sets (new Answer sets). It is crucial to study how to answer questions when deploying VQA systems to new environments (new Visual scenes) and how to answer questions requiring new functions (new Question types). Thus, we propose CLOVE, a benchmark for Continual Learning On Visual quEstion answering, which contains scene- and function-incremental settings for the two aforementioned CL scenarios. In terms of methodology, the main difference between CL on VQA and classification is that the former additionally involves expanding and preventing forgetting of reasoning mechanisms, while the latter focusing on class representation. Thus, we propose a real-data-free replay-based method tailored for CL on VQA, named Scene Graph as Prompt for Symbolic Replay. Using a piece of scene graph as a prompt, it replays pseudo scene graphs to represent the past images, along with correlated QA pairs. A unified VQA model is also proposed to utilize the current and replayed data to enhance its QA ability. Finally, experimental results reveal challenges in CLOVE and demonstrate the effectiveness of our method. Code and data are available at https://github.com/showlab/CLVQA.","https://ojs.aaai.org/index.php/AAAI/article/view/25208/24980"
"25209","Linking People across Text and Images Based on Social Relation Reasoning","['Yang Lei', 'Peizhi Zhao', 'Pijian Li', 'Yi Cai', 'Qingbao Huang']","['School of Electrical Engineering, Guangxi University', 'School of Electrical Engineering, Guangxi University', 'School of Electrical Engineering, Guangxi University, Nanning, Guangxi', 'School of Software Engineering, South China University of Technology', 'School of Electrical Engineering, Guangxi University, Nanning, Guangxi, China']","['CV: Language and Vision']","Lei, Y., Zhao, P., Li, P., Cai, Y., & Huang, Q. (2023). Linking People across Text and Images Based on Social Relation Reasoning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1260-1268. https://doi.org/10.1609/aaai.v37i1.25209","Abstract 					As a sub-task of visual grounding, linking people across text and images aims to localize target people in images with corresponding sentences. Existing approaches tend to capture superficial features of people (e.g., dress and location) that suffer from the incompleteness information across text and images. We observe that humans are adept at exploring social relations to assist identifying people. Therefore, we propose a Social Relation Reasoning (SRR) model to address the aforementioned issues. Firstly, we design a Social Relation Extraction (SRE) module to extract social relations between people in the input sentence. Specially, the SRE module based on zero-shot learning is able to extract social relations even though they are not defined in the existing datasets. A Reasoning based Cross-modal Matching (RCM) module is further used to generate matching matrices by reasoning on the social relations and visual features. Experimental results show that the accuracy of our proposed SRR model outperforms the state-of-the-art models on the challenging datasets Who's Waldo and FL: MSRE, by more than 5\% and 7\%, respectively. Our source code is available at https://github.com/VILAN-Lab/SRR.","https://ojs.aaai.org/index.php/AAAI/article/view/25209/24981"
"25210","ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing","['Bingchuan Li', 'Tianxiang Ma', 'Peng Zhang', 'Miao Hua', 'Wei Liu', 'Qian He', 'Zili Yi']","['Bytedance Ltd, Beijing, China', 'Bytedance Ltd, Beijing, China', 'Bytedance Ltd, Beijing, China', 'Bytedance Ltd, Beijing, China', 'Bytedance Ltd, Beijing, China', 'Bytedance Ltd, Beijing, China', 'ByteDance Ltd, Beijing, China']","['CV: Computational Photography', 'Image & Video Synthesis']","Li, B., Ma, T., Zhang, P., Hua, M., Liu, W., He, Q., & Yi, Z. (2023). ReGANIE: Rectifying GAN Inversion Errors for Accurate Real Image Editing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1269-1277. https://doi.org/10.1609/aaai.v37i1.25210","Abstract 					The StyleGAN family succeed in high-fidelity image generation and allow for flexible and plausible editing of generated images by manipulating the semantic-rich latent style space. However, projecting a real image into its latent space encounters an inherent trade-off between inversion quality and editability. Existing encoder-based or optimization-based StyleGAN inversion methods attempt to mitigate the trade-off but see limited performance. To fundamentally resolve this problem, we propose a novel two-phase framework by designating two separate networks to tackle editing and reconstruction respectively, instead of balancing the two. Specifically, in Phase I, a W-space-oriented StyleGAN inversion network is trained and used to perform image inversion and edit- ing, which assures the editability but sacrifices reconstruction quality. In Phase II, a carefully designed rectifying network is utilized to rectify the inversion errors and perform ideal reconstruction. Experimental results show that our approach yields near-perfect reconstructions without sacrificing the editability, thus allowing accurate manipulation of real images. Further, we evaluate the performance of our rectifying net- work, and see great generalizability towards unseen manipulation types and out-of-domain images.","https://ojs.aaai.org/index.php/AAAI/article/view/25210/24982"
"25211","SWBNet: A Stable White Balance Network for sRGB Images","['Chunxiao Li', 'Xuejing Kang', 'Zhifeng Zhang', 'Anlong Ming']","['Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Applications', 'CV: Low Level & Physics-Based Vision']","Li, C., Kang, X., Zhang, Z., & Ming, A. (2023). SWBNet: A Stable White Balance Network for sRGB Images. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1278-1286. https://doi.org/10.1609/aaai.v37i1.25211","Abstract 					The white balance methods for sRGB images (sRGB-WB)  aim to directly remove their color temperature shifts. Despite  achieving promising white balance (WB) performance, the  existing methods suffer from WB instability, i.e., their results  are inconsistent for images with different color temperatures. We propose a stable white balance network (SWBNet) to alleviate this problem. It learns the color temperature-insensitive  features to generate white-balanced images, resulting in  consistent WB results. Specifically, the color temperatureinsensitive features are learned by implicitly suppressing lowfrequency information sensitive to color temperatures. Then,  a color temperature contrastive loss is introduced to facilitate the most information shared among features of the same  scene and different color temperatures. This way, features  from the same scene are more insensitive to color temperatures regardless of the inputs. We also present a color temperature sensitivity-oriented transformer that globally perceives multiple color temperature shifts within an image  and corrects them by different weights. It helps to improve  the accuracy of stabilized SWBNet, especially for multiillumination sRGB images. Experiments indicate that our SWBNet achieves stable and remarkable WB performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25211/24983"
"25212","Frequency Domain Disentanglement for Arbitrary Neural Style Transfer","['Dongyang Li', 'Hao Luo', 'Pichao Wang', 'Zhibin Wang', 'Shang Liu', 'Fan Wang']","['Alibaba Group', 'Alibaba group', 'Alibaba Group', 'Alibaba Group', 'Alibaba Group', 'Alibaba Group']","['CV: Low Level & Physics-Based Vision', 'CV: Applications']","Li, D., Luo, H., Wang, P., Wang, Z., Liu, S., & Wang, F. (2023). Frequency Domain Disentanglement for Arbitrary Neural Style Transfer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1287-1295. https://doi.org/10.1609/aaai.v37i1.25212","Abstract 					Arbitrary neural style transfer has been a popular research topic due to its rich application scenarios. Effective disentanglement of content and style is the critical factor for synthesizing an image with arbitrary style. The existing methods focus on disentangling feature representations of content and style in the spatial domain where the content and style components are innately entangled and difficult to be disentangled clearly. Therefore, these methods always suffer from low-quality results because of the sub-optimal disentanglement. To address such a challenge, this paper proposes the frequency mixer (FreMixer) module that disentangles and re-entangles the frequency spectrum of content and style components in the frequency domain. Since content and style components have different frequency-domain characteristics (frequency bands and frequency patterns), the FreMixer could well disentangle these two components. Based on the FreMixer module, we design a novel Frequency Domain Disentanglement (FDD) framework for arbitrary neural style transfer. Qualitative and quantitative experiments verify that the proposed method can render better stylized results compared to the state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25212/24984"
"25213","Pose-Oriented Transformer with Uncertainty-Guided Refinement for 2D-to-3D Human Pose Estimation","['Han Li', 'Bowen Shi', 'Wenrui Dai', 'Hongwei Zheng', 'Botao Wang', 'Yu Sun', 'Min Guo', 'Chenglin Li', 'Junni Zou', 'Hongkai Xiong']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Qualcomm AI Research', 'Qualcomm AI Research', 'Qualcomm AI Research', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['CV: 3D Computer Vision']","Li, H., Shi, B., Dai, W., Zheng, H., Wang, B., Sun, Y., Guo, M., Li, C., Zou, J., & Xiong, H. (2023). Pose-Oriented Transformer with Uncertainty-Guided Refinement for 2D-to-3D Human Pose Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1296-1304. https://doi.org/10.1609/aaai.v37i1.25213","Abstract 					There has been a recent surge of interest in introducing transformers to 3D human pose estimation (HPE) due to their powerful capabilities in modeling long-term dependencies. However, existing transformer-based methods treat body joints as equally important inputs and ignore the prior knowledge of human skeleton topology in the self-attention mechanism. To tackle this issue, in this paper, we propose a Pose-Oriented Transformer (POT) with uncertainty guided refinement for 3D HPE. Specifically, we first develop novel pose-oriented self-attention mechanism and distance-related position embedding for POT to explicitly exploit the human skeleton topology. The pose-oriented self-attention mechanism explicitly models the topological interactions between body joints, whereas the distance-related position embedding encodes the distance of joints to the root joint to distinguish groups of joints with different difficulties in regression. Furthermore, we present an Uncertainty-Guided Refinement Network (UGRN) to refine pose predictions from POT, especially for the difficult joints, by considering the estimated uncertainty of each joint with uncertainty-guided sampling strategy and self-attention mechanism. Extensive experiments demonstrate that our method significantly outperforms the state-of-the-art methods with reduced model parameters on 3D HPE benchmarks such as Human3.6M and MPI-INF-3DHP.","https://ojs.aaai.org/index.php/AAAI/article/view/25213/24985"
"25214","CEE-Net: Complementary End-to-End Network for 3D Human Pose Generation and Estimation","['Haolun Li', 'Chi-Man Pun']","['University of Macau', 'University of Macau']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: 3D Computer Vision']","Li, H., & Pun, C.-M. (2023). CEE-Net: Complementary End-to-End Network for 3D Human Pose Generation and Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1305-1313. https://doi.org/10.1609/aaai.v37i1.25214","Abstract 					The limited number of actors and actions in existing datasets make 3D pose estimators tend to overfit, which can be seen from the performance degradation of the algorithm on cross-datasets, especially for rare and complex poses. Although previous data augmentation works have increased the diversity of the training set, the changes in camera viewpoint and position play a dominant role in improving the accuracy of the estimator, while the generated 3D poses are limited and still heavily rely on the source dataset. In addition, these works do not consider the adaptability of the pose estimator to generated data, and complex poses will cause training collapse. In this paper, we propose the CEE-Net, a Complementary End-to-End Network for 3D human pose generation and estimation. The generator extremely expands the distribution of each joint-angle in the existing dataset and limits them to a reasonable range. By learning the correlations within and between the torso and limbs, the estimator can combine different body-parts more effectively and weaken the influence of specific joint-angle changes on the global pose, improving the generalization ability. Extensive ablation studies show that our pose generator greatly strengthens the joint-angle distribution, and our pose estimator can utilize these poses positively. Compared with the state-of-the-art methods, our method can achieve much better performance on various cross-datasets, rare and complex poses.","https://ojs.aaai.org/index.php/AAAI/article/view/25214/24986"
"25215","Real-World Deep Local Motion Deblurring","['Haoying Li', 'Ziran Zhang', 'Tingting Jiang', 'Peng Luo', 'Huajun Feng', 'Zhihai Xu']","['College of Optical Science and Engineering at Zhejiang University\nResearch Center for Intelligent Sensing Systems at Zhejiang Laboratory', 'College of Optical Science and Engineering at Zhejiang University', 'Research Center for Intelligent Sensing Systems at Zhejiang Laboratory', 'College of Optical Science and Engineering at Zhejiang University', 'College of Optical Science and Engineering at Zhejiang University', 'College of Optical Science and Engineering, Zhejiang University']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Low Level & Physics-Based Vision']","Li, H., Zhang, Z., Jiang, T., Luo, P., Feng, H., & Xu, Z. (2023). Real-World Deep Local Motion Deblurring. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1314-1322. https://doi.org/10.1609/aaai.v37i1.25215","Abstract 					Most existing deblurring methods focus on removing global blur caused by camera shake, while they cannot well handle local blur caused by object movements. To fill the vacancy of local deblurring in real scenes, we establish the first real local motion blur dataset (ReLoBlur), which is captured by a synchronized beam-splitting photographing system and corrected by a post-progressing pipeline. Based on ReLoBlur, we propose a Local Blur-Aware Gated network (LBAG) and several local blur-aware techniques to bridge the gap between global and local deblurring: 1) a blur detection approach based on background subtraction to localize blurred regions; 2) a gate mechanism to guide our network to focus on blurred regions; and 3) a blur-aware patch cropping strategy to address data imbalance problem. Extensive experiments prove the reliability of ReLoBlur dataset, and demonstrate that LBAG achieves better performance than state-of-the-art global deblurring methods and our proposed local blur-aware techniques are effective.","https://ojs.aaai.org/index.php/AAAI/article/view/25215/24987"
"25216","Disentangle and Remerge: Interventional Knowledge Distillation for Few-Shot Object Detection from a Conditional Causal Perspective","['Jiangmeng Li', 'Yanan Zhang', 'Wenwen Qiang', 'Lingyu Si', 'Chengbo Jiao', 'Xiaohui Hu', 'Changwen Zheng', 'Fuchun Sun']","['University of Chinese Academy of Sciences\nInstitute of Software Chinese Academy of Sciences', 'University of Chinese Academy of Sciences\nInstitute of Software Chinese Academy of Sciences', 'University of Chinese Academy of Sciences\nInstitute of Software Chinese Academy of Sciences', 'University of Chinese Academy of Sciences\nInstitute of Software Chinese Academy of Sciences', 'University of Electronic Science and Technology of China', 'Institute of Software Chinese Academy of Sciences', 'Institute of Software Chinese Academy of Sciences', 'Tsinghua University']","['CV: Object Detection & Categorization', 'CV: Multi-modal Vision', 'ML: Causal Learning', 'ML: Representation Learning', 'RU: Causality']","Li, J., Zhang, Y., Qiang, W., Si, L., Jiao, C., Hu, X., Zheng, C., & Sun, F. (2023). Disentangle and Remerge: Interventional Knowledge Distillation for Few-Shot Object Detection from a Conditional Causal Perspective. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1323-1333. https://doi.org/10.1609/aaai.v37i1.25216","Abstract 					Few-shot learning models learn representations with limited human annotations, and such a learning paradigm demonstrates practicability in various tasks, e.g., image classification, object detection, etc. However, few-shot object detection methods suffer from an intrinsic defect that the limited training data makes the model cannot sufficiently explore semantic information. To tackle this, we introduce knowledge distillation to the few-shot object detection learning paradigm. We further run a motivating experiment, which demonstrates that in the process of knowledge distillation, the empirical error of the teacher model degenerates the prediction performance of the few-shot object detection model as the student. To understand the reasons behind this phenomenon, we revisit the learning paradigm of knowledge distillation on the few-shot object detection task from the causal theoretic standpoint, and accordingly, develop a Structural Causal Model. Following the theoretical guidance, we propose a backdoor adjustment-based knowledge distillation method for the few-shot object detection task, namely Disentangle and Remerge (D&R), to perform conditional causal intervention toward the corresponding Structural Causal Model. Empirically, the experiments on benchmarks demonstrate that D&R can yield significant performance boosts in few-shot object detection. Code is available at https://github.com/ZYN-1101/DandR.git.","https://ojs.aaai.org/index.php/AAAI/article/view/25216/24988"
"25217","Learning Motion-Robust Remote Photoplethysmography through Arbitrary Resolution Videos","['Jianwei Li', 'Zitong Yu', 'Jingang Shi']","['Xi’an Jiaotong University', 'Great Bay University', ""Xi'an Jiaotong University""]","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Medical and Biological Imaging']","Li, J., Yu, Z., & Shi, J. (2023). Learning Motion-Robust Remote Photoplethysmography through Arbitrary Resolution Videos. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1334-1342. https://doi.org/10.1609/aaai.v37i1.25217","Abstract 					Remote photoplethysmography (rPPG) enables non-contact heart rate (HR) estimation from facial videos which gives significant convenience compared with traditional contact-based measurements. In the real-world long-term health monitoring scenario, the distance of the participants and their head movements usually vary by time, resulting in the inaccurate rPPG measurement due to the varying face resolution and complex motion artifacts. Different from the previous rPPG models designed for a constant distance between camera and participants, in this paper, we propose two plug-and-play blocks (i.e., physiological signal feature extraction block (PFE) and temporal face alignment block (TFA)) to alleviate the degradation of changing distance and head motion. On one side, guided with representative-area information, PFE adaptively encodes the arbitrary resolution facial frames to the fixed-resolution facial structure features. On the other side, leveraging the estimated optical flow, TFA is able to counteract the rPPG signal confusion caused by the head movement thus benefit the motion-robust rPPG signal recovery. Besides, we also train the model with a cross-resolution constraint using a two-stream dual-resolution framework, which further helps PFE learn resolution-robust facial rPPG features. Extensive experiments on three benchmark datasets (UBFC-rPPG, COHFACE and PURE) demonstrate the superior performance of the proposed method. One highlight is that with PFE and TFA, the off-the-shelf spatio-temporal rPPG models can predict more robust rPPG signals under both varying face resolution and severe head movement scenarios. The codes are available at https://github.com/LJWGIT/Arbitrary_Resolution_rPPG.","https://ojs.aaai.org/index.php/AAAI/article/view/25217/24989"
"25218","FSR: A General Frequency-Oriented Framework to Accelerate Image Super-resolution Networks","['Jinmin Li', 'Tao Dai', 'Mingyan Zhu', 'Bin Chen', 'Zhi Wang', 'Shu-Tao Xia']","['Tsinghua University\nShenzhen University', 'Shenzhen University', 'Tsinghua University\nPeng Cheng Laboratory', 'Harbin Institute of Technology, Shenzhen\nPeng Cheng Laboratory', 'Tsinghua University', 'Tsinghua University\nPeng Cheng Laboratory']","['CV: Low Level & Physics-Based Vision', 'CV: Applications', 'CV: Computational Photography', 'Image & Video Synthesis']","Li, J., Dai, T., Zhu, M., Chen, B., Wang, Z., & Xia, S.-T. (2023). FSR: A General Frequency-Oriented Framework to Accelerate Image Super-resolution Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1343-1350. https://doi.org/10.1609/aaai.v37i1.25218","Abstract 					Deep neural networks (DNNs) have witnessed remarkable achievement in image super-resolution (SR), and plenty of DNN-based SR models with elaborated network designs have recently been proposed. However, existing methods usually require substantial computations by operating in spatial domain. To address this issue, we propose a general frequency-oriented framework (FSR) to accelerate SR networks by considering data characteristics in frequency domain. Our FSR mainly contains dual feature aggregation module (DFAM) to extract informative features in both spatial and transform domains, followed by a four-path SR-Module with different capacities to super-resolve in the frequency domain. Specifically, DFAM further consists of a transform attention block (TABlock) and a spatial context block (SCBlock) to extract global spectral information and local spatial information, respectively, while SR-Module is a parallel network container that contains four to-be-accelerated branches. Furthermore, we propose an adaptive weight strategy for a trade-off between image details recovery and visual quality. Extensive experiments show that our FSR can save FLOPs by almost 40% while reducing inference time by 50% for other SR methods (e.g., FSRCNN, CARN, SRResNet and RCAN). Code is available at https://github.com/THU-Kingmin/FSR.","https://ojs.aaai.org/index.php/AAAI/article/view/25218/24990"
"25219","Learning Polysemantic Spoof Trace: A Multi-Modal Disentanglement Network for Face Anti-spoofing","['Kaicheng Li', 'Hongyu Yang', 'Binghui Chen', 'Pengyu Li', 'Biao Wang', 'Di Huang']","['Beihang University, China', 'Beihang University, China', 'No affiliation', 'No affiliation', 'No affiliation', 'Beihang University, China']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Multi-modal Vision']","Li, K., Yang, H., Chen, B., Li, P., Wang, B., & Huang, D. (2023). Learning Polysemantic Spoof Trace: A Multi-Modal Disentanglement Network for Face Anti-spoofing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1351-1359. https://doi.org/10.1609/aaai.v37i1.25219","Abstract 					Along with the widespread use of face recognition systems, their vulnerability has become highlighted. While existing face anti-spoofing methods can be generalized between attack types, generic solutions are still challenging due to the diversity of spoof characteristics. Recently, the spoof trace disentanglement framework has shown great potential for coping with both seen and unseen spoof scenarios, but the performance is largely restricted by the single-modal input. This paper focuses on this issue and presents a multi-modal disentanglement model which targetedly learns polysemantic spoof traces for more accurate and robust generic attack detection. In particular, based on the adversarial learning mechanism, a two-stream disentangling network is designed to estimate spoof patterns from the RGB and depth inputs, respectively. In this case, it captures complementary spoofing clues inhering in different attacks. Furthermore, a fusion module is exploited, which recalibrates both representations at multiple stages to promote the disentanglement in each individual modality. It then performs cross-modality aggregation to deliver a more comprehensive spoof trace representation for prediction. Extensive evaluations are conducted on multiple benchmarks, demonstrating that learning polysemantic spoof traces favorably contributes to anti-spoofing with more perceptible and interpretable results.","https://ojs.aaai.org/index.php/AAAI/article/view/25219/24991"
"25220","Stroke Extraction of Chinese Character Based on Deep Structure Deformable Image Registration","['Meng Li', 'Yahan Yu', 'Yi Yang', 'Guanghao Ren', 'Jian Wang']","['Institute of Automation, Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences', 'Institute of Automation，Chinese Academy of Sciences']","['CV: Other Foundations of Computer Vision', 'CV: Applications', 'CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Computational Photography', 'Image & Video Synthesis', 'CV: Medical and Biological Imaging', 'CV: Object Detection & Categorization']","Li, M., Yu, Y., Yang, Y., Ren, G., & Wang, J. (2023). Stroke Extraction of Chinese Character Based on Deep Structure Deformable Image Registration. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1360-1367. https://doi.org/10.1609/aaai.v37i1.25220","Abstract 					Stroke extraction of Chinese characters plays an important role in the field of character recognition and generation. The most existing character stroke extraction methods focus on image morphological features. These methods usually lead to errors of cross strokes extraction and stroke matching due to rarely using stroke semantics and prior information. In this paper, we propose a deep learning-based character stroke extraction method that takes semantic features and prior information of strokes into consideration. This method consists of three parts: image registration-based stroke registration that establishes the rough registration of the reference strokes and the target as prior information; image semantic segmentation-based stroke segmentation that preliminarily separates target strokes into seven categories; and high-precision extraction of single strokes. In the stroke registration, we propose a structure deformable image registration network to achieve structure-deformable transformation while maintaining the stable morphology of single strokes for character images with complex structures. In order to verify the effectiveness of the method, we construct two datasets respectively for calligraphy characters and regular handwriting characters. The experimental results show that our method strongly outperforms the baselines. Code is available at https://github.com/MengLi-l1/StrokeExtraction.","https://ojs.aaai.org/index.php/AAAI/article/view/25220/24992"
"25221","Spatial-Spectral Transformer for Hyperspectral Image Denoising","['Miaoyu Li', 'Ying Fu', 'Yulun Zhang']","['Beijing Institue of Technology', 'Beijing Institute of Technology', 'ETH Zurich']","['CV: Low Level & Physics-Based Vision', 'CV: Computational Photography', 'Image & Video Synthesis']","Li, M., Fu, Y., & Zhang, Y. (2023). Spatial-Spectral Transformer for Hyperspectral Image Denoising. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1368-1376. https://doi.org/10.1609/aaai.v37i1.25221","Abstract 					Hyperspectral image (HSI) denoising is a crucial preprocessing procedure for the subsequent HSI applications. Unfortunately, though witnessing the development of deep learning in HSI denoising area, existing convolution-based methods face the trade-off between computational efficiency and capability to model non-local characteristics of HSI. In this paper, we propose a Spatial-Spectral Transformer (SST) to alleviate this problem. To fully explore intrinsic similarity characteristics in both spatial dimension and spectral dimension, we conduct non-local spatial self-attention and global spectral self-attention with Transformer architecture. The window-based spatial self-attention focuses on the spatial similarity beyond the neighboring region. While, the spectral self-attention exploits the long-range dependencies between highly correlative bands. Experimental results show that our proposed method outperforms the state-of-the-art HSI denoising methods in quantitative quality and visual results. The code is released at https://github.com/MyuLi/SST.","https://ojs.aaai.org/index.php/AAAI/article/view/25221/24993"
"25222","Learning Semantic Alignment with Global Modality Reconstruction for Video-Language Pre-training towards Retrieval","['Mingchao Li', 'Xiaoming Shi', 'Haitao Leng', 'Wei Zhou', 'Hai-Tao Zheng', 'Kuncai Zhang']","['Tsinghua University\nAlibaba Group', 'Shanghai Artificial Intelligence Laboratory', 'Alibaba Group', 'Alibaba Group', 'Tsinghua University\nPeng Cheng Laboratory', 'Alibaba Group']","['CV: Image and Video Retrieval', 'CV: Multi-modal Vision']","Li, M., Shi, X., Leng, H., Zhou, W., Zheng, H.-T., & Zhang, K. (2023). Learning Semantic Alignment with Global Modality Reconstruction for Video-Language Pre-training towards Retrieval. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1377-1385. https://doi.org/10.1609/aaai.v37i1.25222","Abstract 					Video-language pre-training for text-based video retrieval tasks is vitally important. Previous pre-training methods suffer from the semantic misalignments. The reason is that these methods ignore sequence alignments but focusing on critical token alignment. To alleviate the problem, we propose a video-language pre-training framework, termed videolanguage pre-training For lEarning sEmantic aLignments (FEEL), to learn semantic alignments at the sequence level. Specifically, the global modality reconstruction and the cross- modal self-contrasting method is utilized to learn the alignments at the sequence level better. Extensive experimental results demonstrate the effectiveness of FEEL on text-based video retrieval and text-based video corpus moment retrieval.","https://ojs.aaai.org/index.php/AAAI/article/view/25222/24994"
"25223","Layout-Aware Dreamer for Embodied Visual Referring Expression Grounding","['Mingxiao Li', 'Zehao Wang', 'Tinne Tuytelaars', 'Marie-Francine Moens']","['KU Leuven', 'KU Leuven', 'KU Leuven', 'KU Leuven']","['CV: Language and Vision', 'CV: Multi-modal Vision']","Li, M., Wang, Z., Tuytelaars, T., & Moens, M.-F. (2023). Layout-Aware Dreamer for Embodied Visual Referring Expression Grounding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1386-1395. https://doi.org/10.1609/aaai.v37i1.25223","Abstract 					In this work, we study the problem of Embodied Referring Expression Grounding, where an agent needs to navigate in a previously unseen environment and localize a remote object described by a concise high-level natural language instruction. When facing such a situation, a human tends to imagine what the destination may look like and to explore the environment based on prior knowledge of the environmental layout, such as the fact that a bathroom is more likely to be found near a bedroom than a kitchen. We have designed an autonomous agent called Layout-aware Dreamer (LAD), including two novel modules, that is, the Layout Learner and the Goal Dreamer to mimic this cognitive decision process. The Layout Learner learns to infer the room category distribution of neighboring unexplored areas along the path for coarse layout estimation, which effectively introduces layout common sense of room-to-room transitions to our agent. To learn an effective exploration of the environment, the Goal Dreamer imagines the destination beforehand. Our agent achieves new state-of-the-art performance on the public leaderboard of REVERIE dataset in challenging unseen test environments with improvement on navigation success rate (SR) by 4.02% and remote grounding success (RGS) by 3.43% comparing to previous previous state of the art. The code is released at https://github.com/zehao-wang/LAD.","https://ojs.aaai.org/index.php/AAAI/article/view/25223/24995"
"25224","NeAF: Learning Neural Angle Fields for Point Normal Estimation","['Shujuan Li', 'Junsheng Zhou', 'Baorui Ma', 'Yu-Shen Liu', 'Zhizhong Han']","['School of Software, Tsinghua University', 'School of Software, Tsinghua University', 'School of Software, Tsinghua university', 'School of Software, Tsinghua University', 'Department of Computer Science, Wayne State University']","['CV: 3D Computer Vision']","Li, S., Zhou, J., Ma, B., Liu, Y.-S., & Han, Z. (2023). NeAF: Learning Neural Angle Fields for Point Normal Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1396-1404. https://doi.org/10.1609/aaai.v37i1.25224","Abstract 					Normal estimation for unstructured point clouds is an important task in 3D computer vision. Current methods achieve encouraging results by mapping local patches to normal vectors or learning local surface fitting using neural networks. However, these methods are not generalized well to unseen scenarios and are sensitive to parameter settings. To resolve these issues, we propose an implicit function to learn an angle field around the normal of each point in the spherical coordinate system, which is dubbed as Neural Angle Fields (NeAF). Instead of directly predicting the normal of an input point, we predict the angle offset between the ground truth normal and a randomly sampled query normal. This strategy pushes the network to observe more diverse samples, which leads to higher prediction accuracy in a more robust manner. To predict normals from the learned angle fields at inference time, we randomly sample query vectors in a unit spherical space and take the vectors with minimal angle values as the predicted normals. To further leverage the prior learned by NeAF, we propose to refine the predicted normal vectors by minimizing the angle offsets. The experimental results with synthetic data and real scans show significant improvements over the state-of-the-art under widely used benchmarks. Project page: https://lisj575.github.io/NeAF/.","https://ojs.aaai.org/index.php/AAAI/article/view/25224/24996"
"25225","CLIP-ReID: Exploiting Vision-Language Model for Image Re-identification without Concrete Text Labels","['Siyuan Li', 'Li Sun', 'Qingli Li']","['East China Normal University', 'East China Normal University', 'East China Normal University']","['CV: Language and Vision', 'CV: Image and Video Retrieval', 'CV: Multi-modal Vision', 'CV: Representation Learning for Vision']","Li, S., Sun, L., & Li, Q. (2023). CLIP-ReID: Exploiting Vision-Language Model for Image Re-identification without Concrete Text Labels. Proceedings of the AAAI Conference on Artificial Intelligence, 37(1), 1405-1413. https://doi.org/10.1609/aaai.v37i1.25225","Abstract 					Pre-trained vision-language models like CLIP have recently shown superior performances on various downstream tasks, including image classification and segmentation. However, in fine-grained image re-identification (ReID), the labels are indexes, lacking concrete text descriptions. Therefore, it remains to be determined how such models could be applied to these tasks. This paper first finds out that simply fine-tuning the visual model initialized by the image encoder in CLIP, has already obtained competitive performances in various ReID tasks. Then we propose a two-stage strategy to facilitate a better visual representation. The key idea is to fully exploit the cross-modal description ability in CLIP through a set of learnable text tokens for each ID and give them to the text encoder to form ambiguous descriptions. In the first training stage, image and text encoders from CLIP keep fixed, and only the text tokens are optimized from scratch by the contrastive loss computed within a batch. In the second stage, the ID-specific text tokens and their encoder become static, providing constraints for fine-tuning the image encoder. With the help of the designed loss in the downstream task, the image encoder is able to represent data as vectors in the feature embedding accurately. The effectiveness of the proposed strategy is validated on several datasets for the person or vehicle ReID tasks. Code is available at https://github.com/Syliz517/CLIP-ReID.","https://ojs.aaai.org/index.php/AAAI/article/view/25225/24997"
"25226","DC-Former: Diverse and Compact Transformer for Person Re-identification","['Wen Li', 'Cheng Zou', 'Meng Wang', 'Furong Xu', 'Jianan Zhao', 'Ruobing Zheng', 'Yuan Cheng', 'Wei Chu']","['Ant Group', 'Ant Group', 'Ant group', 'Ant Group', 'Ant Group', 'Ant Group', 'Artificial Intelligence Innovation and Incubation Institute, Fudan University', 'Ant Group']","['CV: Image and Video Retrieval', 'CV: Representation Learning for Vision']","Li, W., Zou, C., Wang, M., Xu, F., Zhao, J., Zheng, R., Cheng, Y., & Chu, W. (2023). DC-Former: Diverse and Compact Transformer for Person Re-identification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1415-1423. https://doi.org/10.1609/aaai.v37i2.25226","Abstract 					In person re-identification (ReID) task, it is still challenging to learn discriminative representation by deep learning, due to limited data. Generally speaking, the model will get better performance when increasing the amount of data. The addition of similar classes strengthens the ability of the classifier to identify similar identities, thereby improving the discrimination of representation. In this paper, we propose a Diverse and Compact Transformer (DC-Former) that can achieve a similar effect by splitting embedding space into multiple diverse and compact subspaces. Compact embedding subspace helps model learn more robust and discriminative embedding to identify similar classes. And the fusion of these diverse embeddings containing more fine-grained information can further improve the effect of ReID. Specifically, multiple class tokens are used in vision transformer to represent multiple embedding spaces. Then, a self-diverse constraint (SDC) is applied to these spaces to push them away from each other, which makes each embedding space diverse and compact. Further, a dynamic weight controller (DWC) is further designed for balancing the relative importance among them during training. The experimental results of our method are promising, which surpass previous state-of-the-art methods on several commonly used person ReID benchmarks. Our code is available at https://github.com/ant-research/Diverse-and-Compact-Transformer.","https://ojs.aaai.org/index.php/AAAI/article/view/25226/24998"
"25227","Panoramic Video Salient Object Detection with Ambisonic Audio Guidance","['Xiang Li', 'Haoyuan Cao', 'Shijie Zhao', 'Junlin Li', 'Li Zhang', 'Bhiksha Raj']","['Carnegie Mellon University', 'ByteDance Inc.', 'Bytedance Inc.', 'ByteDance Inc.', 'Bytedance Inc.', 'Carnegie Mellon University\nMohammed bin Zayed University of AI']","['CV: Video Understanding & Activity Analysis', 'CV: Multi-modal Vision', 'CV: Object Detection & Categorization', 'CV: Segmentation']","Li, X., Cao, H., Zhao, S., Li, J., Zhang, L., & Raj, B. (2023). Panoramic Video Salient Object Detection with Ambisonic Audio Guidance. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1424-1432. https://doi.org/10.1609/aaai.v37i2.25227","Abstract 					Video salient object detection (VSOD), as a fundamental computer vision problem, has been extensively discussed in the last decade. However, all existing works focus on addressing the VSOD problem in 2D scenarios. With the rapid development of VR devices, panoramic videos have been a promising alternative to 2D videos to provide immersive feelings of the real world. In this paper, we aim to tackle the video salient object detection problem for panoramic videos, with their corresponding ambisonic audios. A multimodal fusion module equipped with two pseudo-siamese audio-visual context fusion (ACF) blocks is proposed to effectively conduct audio-visual interaction. The ACF block equipped with spherical positional encoding enables the fusion in the 3D context to capture the spatial correspondence between pixels and sound sources from the equirectangular frames and ambisonic audios. Experimental results verify the effectiveness of our proposed components and demonstrate that our method achieves state-of-the-art performance on the ASOD60K dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/25227/24999"
"25228","LWSIS: LiDAR-Guided Weakly Supervised Instance Segmentation for Autonomous Driving","['Xiang Li', 'Junbo Yin', 'Botian Shi', 'Yikang Li', 'Ruigang Yang', 'Jianbing Shen']","['Beijing Institute of Technology', 'Beijing Institute of Technology', 'Shanghai AI Lab', 'Shanghai AI Lab', 'Inceptio', 'SKL-IOTSC, CIS, University of Macau']","['CV: Vision for Robotics & Autonomous Driving', 'CV: Multi-modal Vision', 'CV: Segmentation']","Li, X., Yin, J., Shi, B., Li, Y., Yang, R., & Shen, J. (2023). LWSIS: LiDAR-Guided Weakly Supervised Instance Segmentation for Autonomous Driving. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1433-1441. https://doi.org/10.1609/aaai.v37i2.25228","Abstract 					Image instance segmentation is a fundamental research topic in autonomous driving, which is crucial for scene understanding and road safety. Advanced learning-based approaches often rely on the costly 2D mask annotations for training.  In this paper, we present a more artful framework, LiDAR-guided Weakly Supervised Instance Segmentation (LWSIS), which leverages the off-the-shelf 3D data, i.e., Point Cloud, together with the 3D boxes, as natural weak supervisions for training the 2D image instance segmentation models. Our LWSIS not only exploits the complementary information in multimodal data during training but also significantly reduces the annotation cost of the dense 2D masks. In detail, LWSIS consists of two crucial modules, Point Label Assignment (PLA) and Graph-based Consistency Regularization (GCR). The former module aims to automatically assign the 3D point cloud as 2D point-wise labels, while the atter further refines the predictions by enforcing geometry and appearance consistency of the multimodal data. Moreover, we conduct a secondary instance segmentation annotation on the nuScenes, named nuInsSeg, to encourage further research on multimodal perception tasks. Extensive experiments on the nuInsSeg, as well as the large-scale Waymo, show that LWSIS can substantially improve existing weakly supervised segmentation models by only involving 3D data during training. Additionally, LWSIS can also be incorporated into 3D object detectors like PointPainting to boost the 3D detection performance for free. The code and dataset are available at https://github.com/Serenos/LWSIS.","https://ojs.aaai.org/index.php/AAAI/article/view/25228/25000"
"25229","Adaptive Texture Filtering for Single-Domain Generalized Segmentation","['Xinhui Li', 'Mingjia Li', 'Yaxing Wang', 'Chuan-Xian Ren', 'Xiaojie Guo']","['Tianjin University', 'Tianjin University', 'Nankai University', 'Sun Yat-Sen University', 'Tianjin University']","['CV: Segmentation', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Li, X., Li, M., Wang, Y., Ren, C.-X., & Guo, X. (2023). Adaptive Texture Filtering for Single-Domain Generalized Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1442-1450. https://doi.org/10.1609/aaai.v37i2.25229","Abstract 					Domain generalization in semantic segmentation aims to alleviate the performance degradation on unseen domains through learning domain-invariant features. Existing methods diversify images in the source domain by adding complex or even abnormal textures to reduce the sensitivity to domain-specific features. However, these approaches depends heavily on the richness of the texture bank and training them can be time-consuming. In contrast to importing textures arbitrarily or augmenting styles randomly, we focus on the single source domain itself to achieve the generalization. In this paper, we present a novel adaptive texture filtering mechanism to suppress the influence of texture without using augmentation, thus eliminating the interference of domain-specific features. Further, we design a hierarchical guidance generalization network equipped with structure-guided enhancement modules, which purpose to learn the domain-invariant generalized knowledge. Extensive experiments together with ablation studies on widely-used datasets are conducted to verify the effectiveness of the proposed model, and reveal its superiority over other state-of-the-art alternatives.","https://ojs.aaai.org/index.php/AAAI/article/view/25229/25001"
"25230","MEID: Mixture-of-Experts with Internal Distillation for Long-Tailed Video Recognition","['Xinjie Li', 'Huijuan Xu']","['Pennsylvania State University', 'Pennsylvania State University']","['CV: Video Understanding & Activity Analysis']","Li, X., & Xu, H. (2023). MEID: Mixture-of-Experts with Internal Distillation for Long-Tailed Video Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1451-1459. https://doi.org/10.1609/aaai.v37i2.25230","Abstract 					The long-tailed video recognition problem is especially challenging, as videos tend to be long and untrimmed, and each video may contain multiple classes, causing frame-level class imbalance. The previous method tackles the long-tailed video recognition only through frame-level sampling for class re-balance without distinguishing the frame-level feature representation between head and tail classes. To improve the frame-level feature representation of tail classes, we modulate the frame-level features with an auxiliary distillation loss to reduce the distribution distance between head and tail classes. Moreover, we design a mixture-of-experts framework with two different expert designs, i.e., the first expert with an attention-based classification network handling the original long-tailed distribution, and the second expert dealing with the re-balanced distribution from class-balanced sampling. Notably, in the second expert, we specifically focus on the frames unsolved by the first expert through designing a complementary frame selection module, which inherits the attention weights from the first expert and selects frames with low attention weights, and we also enhance the motion feature representation for these selected frames. To highlight the multi-label challenge in long-tailed video recognition, we create two additional benchmarks based on Charades and CharadesEgo videos with the multi-label property, called CharadesLT and CharadesEgoLT. Extensive experiments are conducted on the existing long-tailed video benchmark VideoLT and the two new benchmarks to verify the effectiveness of our proposed method with state-of-the-art performance. The code and proposed benchmarks are released at https://github.com/VisionLanguageLab/MEID.","https://ojs.aaai.org/index.php/AAAI/article/view/25230/25002"
"25231","Gradient Corner Pooling for Keypoint-Based Object Detection","['Xuyang Li', 'Xuemei Xie', 'Mingxuan Yu', 'Jiakai Luo', 'Chengwei Rao', 'Guangming Shi']","['Xidian University', 'Xidian University\nPazhou Lab, Huangpu', 'Xidian University', 'Xidian University', 'Xidian University', 'Xidian University\nPeng Cheng Laboratory']","['CV: Object Detection & Categorization', 'CV: Learning & Optimization for CV']","Li, X., Xie, X., Yu, M., Luo, J., Rao, C., & Shi, G. (2023). Gradient Corner Pooling for Keypoint-Based Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1460-1467. https://doi.org/10.1609/aaai.v37i2.25231","Abstract 					Detecting objects as multiple keypoints is an important approach in the anchor-free object detection methods while corner pooling is an effective feature encoding method for corner positioning. The corners of the bounding box are located by summing the feature maps which are max-pooled in the x and y directions respectively by corner pooling. In the unidirectional max pooling operation, the features of the densely arranged objects of the same class are prone to occlusion. To this end, we propose a method named Gradient Corner Pooling. The spatial distance information of objects on the feature map is encoded during the unidirectional pooling process, which effectively alleviates the occlusion of the homogeneous object features. Further, the computational complexity of gradient corner pooling is the same as traditional corner pooling and hence it can be implemented efficiently. Gradient corner pooling obtains consistent improvements for various keypoint-based methods by directly replacing corner pooling. We verify the gradient corner pooling algorithm on the dataset and in real scenarios, respectively. The networks with gradient corner pooling located the corner points earlier in the training process and achieve an average accuracy improvement of 0.2%-1.6% on the MS-COCO dataset. The detectors with gradient corner pooling show better angle adaptability for arrayed objects in the actual scene test.","https://ojs.aaai.org/index.php/AAAI/article/view/25231/25003"
"25232","Towards Real-Time Segmentation on the Edge","['Yanyu Li', 'Changdi Yang', 'Pu Zhao', 'Geng Yuan', 'Wei Niu', 'Jiexiong Guan', 'Hao Tang', 'Minghai Qin', 'Qing Jin', 'Bin Ren', 'Xue Lin', 'Yanzhi Wang']","['Northeastern University', 'Northeastern University', 'Northeastern University', 'Northeastern University', 'College of William & Mary', 'College of William & Mary', 'CVL, ETH Zurich', 'Northeastern University', 'Northeastern University', 'College of William & Mary', 'Northeastern University', 'Northeastern University']","['CV: Segmentation', 'ML: Auto ML and Hyperparameter Tuning', 'ML: Learning on the Edge & Model Compression']","Li, Y., Yang, C., Zhao, P., Yuan, G., Niu, W., Guan, J., Tang, H., Qin, M., Jin, Q., Ren, B., Lin, X., & Wang, Y. (2023). Towards Real-Time Segmentation on the Edge. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1468-1476. https://doi.org/10.1609/aaai.v37i2.25232","Abstract 					The research in real-time segmentation mainly focuses on desktop GPUs.  However, autonomous driving and many other applications rely on real-time segmentation on the edge, and current arts are far from the goal.  In addition, recent advances in vision transformers also inspire us to re-design the network architecture for dense prediction task.  In this work, we propose to combine the self attention block with lightweight convolutions to form new building blocks, and employ latency constraints to search an efficient sub-network.  We train an MLP latency model based on generated architecture configurations and their latency measured on mobile devices, so that we can predict the latency of subnets during search phase.  To the best of our knowledge, we are the first to achieve over 74% mIoU on Cityscapes with semi-real-time inference (over 15 FPS) on mobile GPU from an off-the-shelf phone.","https://ojs.aaai.org/index.php/AAAI/article/view/25232/25004"
"25233","BEVDepth: Acquisition of Reliable Depth for Multi-View 3D Object Detection","['Yinhao Li', 'Zheng Ge', 'Guanyi Yu', 'Jinrong Yang', 'Zengran Wang', 'Yukang Shi', 'Jianjian Sun', 'Zeming Li']","['Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, CAS;University of Chinese Academy of Sciences', 'MEGVII Technology', 'MEGVII Technology', 'Huazhong University of Science and Technology', 'MEGVII Technology', 'Xi’an Jiaotong University', 'MEGVII Technology', 'MEGVII Technology']","['CV: 3D Computer Vision', 'CV: Vision for Robotics & Autonomous Driving']","Li, Y., Ge, Z., Yu, G., Yang, J., Wang, Z., Shi, Y., Sun, J., & Li, Z. (2023). BEVDepth: Acquisition of Reliable Depth for Multi-View 3D Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1477-1485. https://doi.org/10.1609/aaai.v37i2.25233","Abstract 					In this research, we propose a new 3D object detector with a trustworthy depth estimation,  dubbed BEVDepth, for camera-based Bird's-Eye-View~(BEV) 3D object detection. Our work is based on a key observation -- depth estimation in recent approaches is surprisingly inadequate given the fact that depth is essential to camera 3D detection. Our BEVDepth resolves this by leveraging explicit depth supervision. A camera-awareness depth estimation module is also introduced to facilitate the depth predicting capability. Besides, we design a novel Depth Refinement Module to counter the side effects carried by imprecise feature unprojection. Aided by customized Efficient Voxel Pooling and multi-frame mechanism, BEVDepth achieves the new state-of-the-art 60.9% NDS on the challenging nuScenes test set while maintaining high efficiency. For the first time, the NDS score of a camera model reaches 60%. Codes have been released.","https://ojs.aaai.org/index.php/AAAI/article/view/25233/25005"
"25234","BEVStereo: Enhancing Depth Estimation in Multi-View 3D Object Detection with Temporal Stereo","['Yinhao Li', 'Han Bao', 'Zheng Ge', 'Jinrong Yang', 'Jianjian Sun', 'Zeming Li']","['Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, CAS\nUniversity of Chinese Academy of Sciences', 'State Key Lab of Processors, Institute of Computing Technology, CAS\nUniversity of Chinese Academy of Sciences', 'MEGVII Technology', 'Huazhong University of Science and Technology', 'MEGVII Technology', 'MEGVII Technology']","['CV: 3D Computer Vision', 'CV: Vision for Robotics & Autonomous Driving']","Li, Y., Bao, H., Ge, Z., Yang, J., Sun, J., & Li, Z. (2023). BEVStereo: Enhancing Depth Estimation in Multi-View 3D Object Detection with Temporal Stereo. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1486-1494. https://doi.org/10.1609/aaai.v37i2.25234","Abstract 					Restricted by the ability of depth perception, all Multi-view 3D object detection methods fall into the bottleneck of depth accuracy. By constructing temporal stereo, depth estimation is quite reliable in indoor scenarios. However, there are two difficulties in directly integrating temporal stereo into outdoor multi-view 3D object detectors: 1) The construction of temporal stereos for all views results in high computing costs. 2) Unable to adapt to challenging outdoor scenarios. In this study, we propose an effective method for creating temporal stereo by dynamically determining the center and range of the temporal stereo. The most confident center is found using the EM algorithm. Numerous experiments on nuScenes have shown the BEVStereo's ability to deal with complex outdoor scenarios that other stereo-based methods are unable to handle.  For the first time, a stereo-based approach shows superiority in scenarios like a static ego vehicle and moving objects. BEVStereo achieves the new state-of-the-art in the camera-only track of nuScenes dataset while maintaining memory efficiency.  Codes have been released.","https://ojs.aaai.org/index.php/AAAI/article/view/25234/25006"
"25235","Learning Single Image Defocus Deblurring with Misaligned Training Pairs","['Yu Li', 'Dongwei Ren', 'Xinya Shu', 'Wangmeng Zuo']","['Harbin Institute of Technology', 'Harbin Institute of Technology', 'Harbin Institute of Technology', 'Harbin Institute of Technology\nPeng Cheng Laboratory']","['CV: Low Level & Physics-Based Vision']","Li, Y., Ren, D., Shu, X., & Zuo, W. (2023). Learning Single Image Defocus Deblurring with Misaligned Training Pairs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1495-1503. https://doi.org/10.1609/aaai.v37i2.25235","Abstract 					By adopting popular pixel-wise loss, existing methods for defocus deblurring heavily rely on well aligned training image pairs. Although training pairs of ground-truth and blurry images are carefully collected, e.g., DPDD dataset, misalignment is inevitable between training pairs, making existing methods possibly suffer from deformation artifacts. In this paper, we propose a joint deblurring and reblurring learning (JDRL) framework for single image defocus deblurring with misaligned training pairs. Generally, JDRL consists of a deblurring module and a spatially invariant reblurring module, by which deblurred result can be adaptively supervised by ground-truth image to recover sharp textures while maintaining spatial consistency with the blurry image. First, in the deblurring module, a bi-directional optical flow-based deformation is introduced to tolerate spatial misalignment between deblurred and ground-truth images. Second, in the reblurring module, deblurred result is reblurred to be spatially aligned with blurry image, by predicting a set of isotropic blur kernels and weighting maps. Moreover, we establish a new single image defocus deblurring (SDD) dataset, further validating our JDRL and also benefiting future research. Our JDRL can be applied to boost defocus deblurring networks in terms of both quantitative metrics and visual quality on DPDD, RealDOF and our SDD datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25235/25007"
"25236","Curriculum Temperature for Knowledge Distillation","['Zheng Li', 'Xiang Li', 'Lingfeng Yang', 'Borui Zhao', 'Renjie Song', 'Lei Luo', 'Jun Li', 'Jian Yang']","['Nankai University', 'Nankai University', 'Nanjing University of Science and Technology', 'Megvii Technology', 'Megvii Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nankai University']","['CV: Learning & Optimization for CV', 'ML: Learning on the Edge & Model Compression']","Li, Z., Li, X., Yang, L., Zhao, B., Song, R., Luo, L., Li, J., & Yang, J. (2023). Curriculum Temperature for Knowledge Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1504-1512. https://doi.org/10.1609/aaai.v37i2.25236","Abstract 					Most existing distillation methods ignore the flexible role of the temperature in the loss function and fix it as a hyper-parameter that can be decided by an inefficient grid search. In general, the temperature controls the discrepancy between two distributions and can faithfully determine the difficulty level of the distillation task. Keeping a constant temperature, i.e., a fixed level of task difficulty, is usually sub-optimal for a growing student during its progressive learning stages. In this paper, we propose a simple curriculum-based technique, termed Curriculum Temperature for Knowledge Distillation (CTKD), which controls the task difficulty level during the student's learning career through a dynamic and learnable temperature. Specifically, following an easy-to-hard curriculum, we gradually increase the distillation loss w.r.t. the temperature, leading to increased distillation difficulty in an adversarial manner. As an easy-to-use plug-in technique, CTKD can be seamlessly integrated into existing knowledge distillation frameworks and brings general improvements at a negligible additional computation cost. Extensive experiments on CIFAR-100, ImageNet-2012, and MS-COCO demonstrate the effectiveness of our method.","https://ojs.aaai.org/index.php/AAAI/article/view/25236/25008"
"25237","Actionness Inconsistency-Guided Contrastive Learning for Weakly-Supervised Temporal Action Localization","['Zhilin Li', 'Zilei Wang', 'Qinying Liu']","['University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China']","['CV: Video Understanding & Activity Analysis', 'ML: Representation Learning']","Li, Z., Wang, Z., & Liu, Q. (2023). Actionness Inconsistency-Guided Contrastive Learning for Weakly-Supervised Temporal Action Localization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1513-1521. https://doi.org/10.1609/aaai.v37i2.25237","Abstract 					Weakly-supervised temporal action localization (WTAL) aims to detect action instances given only video-level labels. To address the challenge, recent methods commonly employ a two-branch framework, consisting of a class-aware branch and a class-agnostic branch. In principle, the two branches are supposed to produce the same actionness activation. However, we observe that there are actually many inconsistent activation regions. These inconsistent regions usually contain some challenging segments whose semantic information (action or background) is ambiguous. In this work, we propose a novel Actionness Inconsistency-guided Contrastive Learning (AICL) method which utilizes the consistent segments to boost the representation learning of the inconsistent segments. Specifically, we first define the consistent and inconsistent segments by comparing the predictions of two branches and then construct positive and negative pairs between consistent segments and inconsistent segments for contrastive learning. In addition, to avoid the trivial case where there is no consistent sample, we introduce an action consistency constraint to control the difference between the two branches. We conduct extensive experiments on THUMOS14, ActivityNet v1.2, and ActivityNet v1.3 datasets, and the results show the effectiveness of AICL with state-of-the-art performance. Our code is available at https://github.com/lizhilin-ustc/AAAI2023-AICL.","https://ojs.aaai.org/index.php/AAAI/article/view/25237/25009"
"25238","READ: Large-Scale Neural Scene Rendering for Autonomous Driving","['Zhuopeng Li', 'Lu Li', 'Jianke Zhu']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University,\nAlibaba-Zhejiang University Joint Institute of Frontier Technologies']","['CV: Vision for Robotics & Autonomous Driving', 'ROB: Applications']","Li, Z., Li, L., & Zhu, J. (2023). READ: Large-Scale Neural Scene Rendering for Autonomous Driving. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1522-1529. https://doi.org/10.1609/aaai.v37i2.25238","Abstract 					With the development of advanced driver assistance systems~(ADAS) and autonomous vehicles, conducting experiments in various scenarios becomes an urgent need. Although having been capable of synthesizing photo-realistic street scenes, conventional image-to-image translation methods cannot produce coherent scenes due to the lack of 3D information. In this paper, a large-scale neural rendering method is proposed to synthesize the autonomous driving scene~(READ), which makes it possible to generate large-scale driving scenes in real time on a PC through a variety of sampling schemes. In order to effectively represent driving scenarios, we propose an ω-net rendering network to learn neural descriptors from sparse point clouds. Our model can not only synthesize photo-realistic driving scenes but also stitch and edit them. The promising experimental results show that our model performs well in large-scale driving scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/25238/25010"
"25239","CDTA: A Cross-Domain Transfer-Based Attack with Contrastive Learning","['Zihan Li', 'Weibin Wu', 'Yuxin Su', 'Zibin Zheng', 'Michael R. Lyu']","['Sun Yat-sen University', 'Sun Yat-sen University', 'Sun Yat-sen University', 'Sun Yat-sen University', 'The Chinese University of Hong Kong']","['CV: Adversarial Attacks & Robustness', 'ML: Adversarial Learning & Robustness']","Li, Z., Wu, W., Su, Y., Zheng, Z., & Lyu, M. R. (2023). CDTA: A Cross-Domain Transfer-Based Attack with Contrastive Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1530-1538. https://doi.org/10.1609/aaai.v37i2.25239","Abstract 					Despite the excellent performance, deep neural networks (DNNs) have been shown to be vulnerable to adversarial examples. Besides, these examples are often transferable among different models. In other words, the same adversarial example can fool multiple models with different architectures at the same time. Based on this property, many black-box transfer-based attack techniques have been developed. However, current transfer-based attacks generally focus on the cross-architecture setting, where the attacker has access to the training data of the target model, which is not guaranteed in realistic situations. In this paper, we design a Cross-Domain Transfer-Based Attack (CDTA), which works in the cross-domain scenario. In this setting, attackers have no information about the target model, such as its architecture and training data. Specifically, we propose a contrastive spectral training method to train a feature extractor on a source domain (e.g., ImageNet) and use it to craft adversarial examples on target domains (e.g., Oxford 102 Flower). Our method corrupts the semantic information of the benign image by scrambling the outputs of both the intermediate feature layers and the final layer of the feature extractor. We evaluate CDTA with 16 target deep models on four datasets with widely varying styles. The results confirm that, in terms of the attack success rate, our approach can consistently outperform the state-of-the-art baselines by an average of 11.45% across all target models. Our code is available at https://github.com/LiulietLee/CDTA.","https://ojs.aaai.org/index.php/AAAI/article/view/25239/25011"
"25240","HybridCap: Inertia-Aid Monocular Capture of Challenging Human Motions","['Han Liang', 'Yannan He', 'Chengfeng Zhao', 'Mutian Li', 'Jingya Wang', 'Jingyi Yu', 'Lan Xu']","['School of Information Science and Technology, ShanghaiTech University', 'School of Information Science and Technology, ShanghaiTech University', 'School of Information Science and Technology, ShanghaiTech University', 'School of Information Science and Technology, ShanghaiTech University', 'School of Information Science and Technology, ShanghaiTech University\nShanghai Frontiers Science Center of Human-centered Artificial Intelligence', 'School of Information Science and Technology, ShanghaiTech University\nShanghai Frontiers Science Center of Human-centered Artificial Intelligence', 'School of Information Science and Technology, ShanghaiTech University\nShanghai Frontiers Science Center of Human-centered Artificial Intelligence']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Computational Photography', 'Image & Video Synthesis', 'CV: Motion & Tracking', 'CV: Multi-modal Vision']","Liang, H., He, Y., Zhao, C., Li, M., Wang, J., Yu, J., & Xu, L. (2023). HybridCap: Inertia-Aid Monocular Capture of Challenging Human Motions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1539-1548. https://doi.org/10.1609/aaai.v37i2.25240","Abstract 					Monocular 3D motion capture (mocap) is beneficial to many applications. The use of a single camera, however, often fails to handle occlusions of different body parts and hence it is limited to capture relatively simple movements. We present a light-weight, hybrid mocap technique called HybridCap that augments the camera with only 4 Inertial Measurement Units (IMUs) in a novel learning-and-optimization framework. We first employ a weakly-supervised and hierarchical motion inference module based on cooperative pure residual recurrent blocks that serve as limb, body and root trackers as well as an inverse kinematics solver. Our network effectively narrows the search space of plausible motions via coarse-to-fine pose estimation and manages to tackle challenging movements with high efficiency. We further develop a hybrid optimization scheme that combines inertial feedback and visual cues to improve tracking accuracy. Extensive experiments on various datasets demonstrate HybridCap can robustly handle challenging movements ranging from fitness actions to Latin dance. It also achieves real-time performance up to 60 fps with state-of-the-art accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25240/25012"
"25241","Global Dilated Attention and Target Focusing Network for Robust Tracking","['Yun Liang', 'Qiaoqiao Li', 'Fumian Long']","['South China Agricultural University', 'South China Agricultural University', 'South China Agricultural University']","['CV: Motion & Tracking']","Liang, Y., Li, Q., & Long, F. (2023). Global Dilated Attention and Target Focusing Network for Robust Tracking. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1549-1557. https://doi.org/10.1609/aaai.v37i2.25241","Abstract 					Self Attention has shown the excellent performance in tracking due to its global modeling capability. However, it brings two challenges: First, its global receptive field has less attention on local structure and inter-channel associations, which limits the semantics to distinguish objects and backgrounds; Second, its feature fusion with linear process cannot avoid the interference of non-target semantic objects. To solve the above issues, this paper proposes a robust tracking method named GdaTFT by defining the Global Dilated Attention (GDA) and Target Focusing Network (TFN). The GDA provides a new global semantics modeling approach to enhance the semantic objects while eliminating the background. It is defined via the local focusing module, dilated attention and channel adaption module. Thus, it promotes semantics by focusing local key information, building long-range dependencies and enhancing the semantics of channels. Subsequently, to distinguish the target and non-target objects both with rich semantics, the TFN is proposed to accurately focus the target region. Different from the present feature fusion, it uses the template as the query to build a point-to-point correlation between the template and search region, and finally achieves part-level augmentation of target feature in the search region. Thus, the TFN efficiently augments the target embedding while weakening the non-target objects. Experiments on challenging benchmarks (LaSOT, TrackingNet, GOT-10k, OTB-100) demonstrate that the GdaTFT outperforms many state-of-the-art trackers and achieves leading performance. Code will be available.","https://ojs.aaai.org/index.php/AAAI/article/view/25241/25013"
"25242","Only a Few Classes Confusing: Pixel-Wise Candidate Labels Disambiguation for Foggy Scene Understanding","['Liang Liao', 'Wenyi Chen', 'Zhen Zhang', 'Jing Xiao', 'Yan Yang', 'Chia-Wen Lin', ""Shin'ichi Satoh""]","['Nanyang Technological University', 'Wuhan University', 'Wuhan University', 'Wuhan University', 'Wuhan University', 'National Tsing Hua University', 'National Institute of Informatics']","['CV: Scene Analysis & Understanding', 'CV: Segmentation']","Liao, L., Chen, W., Zhang, Z., Xiao, J., Yang, Y., Lin, C.-W., & Satoh, S. (2023). Only a Few Classes Confusing: Pixel-Wise Candidate Labels Disambiguation for Foggy Scene Understanding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1558-1567. https://doi.org/10.1609/aaai.v37i2.25242","Abstract 					Not all semantics become confusing when deploying a semantic segmentation model for real-world scene understanding of adverse weather. The true semantics of most pixels have a high likelihood of appearing in the few top classes according to confidence ranking. In this paper, we replace the one-hot pseudo label with a candidate label set (CLS) that consists of only a few ambiguous classes and exploit its effects on self-training-based unsupervised domain adaptation. Specifically, we formulate the problem as a coarse-to-fine process. In the coarse-level process, adaptive CLS selection is proposed to pick a minimal set of confusing candidate labels based on the reliability of label predictions. Then, representation learning and label rectification are iteratively performed to facilitate feature clustering in an embedding space and to disambiguate the confusing semantics. Experimentally, our method outperforms the state-of-the-art methods on three realistic foggy benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25242/25014"
"25243","Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation","['Bingqian Lin', 'Yi Zhu', 'Xiaodan Liang', 'Liang Lin', 'Jianzhuang Liu']","['Shenzhen Campus of Sun Yat-sen University, Shenzhen', 'Huawei Noah’s Ark Lab', 'Shenzhen Campus of Sun Yat-sen University, Shenzhen\nPengCheng Laboratory', 'Sun Yat-sen University', ""Huawei Noah's Ark Lab""]","['CV: Language and Vision']","Lin, B., Zhu, Y., Liang, X., Lin, L., & Liu, J. (2023). Actional Atomic-Concept Learning for Demystifying Vision-Language Navigation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1568-1576. https://doi.org/10.1609/aaai.v37i2.25243","Abstract 					Vision-Language Navigation (VLN) is a challenging task which requires an agent to align complex visual observations to language instructions to reach the goal position. Most existing VLN agents directly learn to align the raw directional features and visual features trained using one-hot labels to linguistic instruction features. However, the big semantic gap among these multi-modal inputs makes the alignment difficult and therefore limits the navigation performance. In this paper, we propose Actional Atomic-Concept Learning (AACL), which maps visual observations to actional atomic concepts for facilitating the alignment. Specifically, an actional atomic concept is a natural language phrase containing an atomic action and an object, e.g., ``go up stairs''. These actional atomic concepts, which serve as the bridge between observations and instructions, can effectively mitigate the semantic gap and simplify the alignment. AACL contains three core components: 1) a concept mapping module to map the observations to the actional atomic concept representations through the VLN environment and the recently proposed Contrastive Language-Image Pretraining (CLIP) model, 2) a concept refining adapter to encourage more instruction-oriented object concept extraction by re-ranking the predicted object concepts by CLIP, and 3) an observation co-embedding module which utilizes concept representations to regularize the observation representations. Our AACL establishes new state-of-the-art results on both fine-grained (R2R) and high-level (REVERIE and R2R-Last) VLN benchmarks. Moreover, the visualization shows that AACL significantly improves the interpretability in action decision. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/VLN-AACL.","https://ojs.aaai.org/index.php/AAAI/article/view/25243/25015"
"25244","Probability Guided Loss for Long-Tailed Multi-Label Image Classification","['Dekun Lin']","['Chengdu Institute of Computer Applications, Chinese Academy of Sciences']","['CV: Learning & Optimization for CV', 'CV: Applications', 'CV: Representation Learning for Vision']","Lin, D. (2023). Probability Guided Loss for Long-Tailed Multi-Label Image Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1577-1585. https://doi.org/10.1609/aaai.v37i2.25244","Abstract 					Long-tailed learning has attracted increasing attention in very recent years. Long-tailed multi-label image classification is one subtask and remains challenging and poorly researched. In this paper, we provide a fresh perspective from probability to tackle this problem. More specifically, we find that existing cost-sensitive learning methods for long-tailed multi-label classification will affect the predicted probability of positive and negative labels in varying degrees during training, and different processes of probability will affect the final performance in turn. We thus propose a probability guided loss which contains two components to control this process. One is the probability re-balancing which can flexibly adjust the process of training probability. And the other is the adaptive probability-aware focal which can further reduce the probability gap between positive and negative labels. We conduct extensive experiments on two long-tailed multi-label image classification datasets: VOC-LT and COCO-LT. The results demonstrate the rationality and superiority of our strategy.","https://ojs.aaai.org/index.php/AAAI/article/view/25244/25016"
"25245","Self-Supervised Image Denoising Using Implicit Deep Denoiser Prior","['Huangxing Lin', 'Yihong Zhuang', 'Xinghao Ding', 'Delu Zeng', 'Yue Huang', 'Xiaotong Tu', 'John Paisley']","['Xiamen University', 'Xiamen University', 'Xiamen University', 'South China University of Technology', 'Xiamen University', 'Xiamen University', 'Columbia University']","['CV: Low Level & Physics-Based Vision', 'ML: Unsupervised & Self-Supervised Learning']","Lin, H., Zhuang, Y., Ding, X., Zeng, D., Huang, Y., Tu, X., & Paisley, J. (2023). Self-Supervised Image Denoising Using Implicit Deep Denoiser Prior. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1586-1594. https://doi.org/10.1609/aaai.v37i2.25245","Abstract 					We devise a new regularization for denoising with self-supervised learning. The regularization uses a deep image prior learned by the network, rather than a traditional predefined prior. Specifically, we treat the output of the network as a ``prior'' that we again denoise after ``re-noising.'' The network is updated to minimize the discrepancy between the twice-denoised image and its prior. We demonstrate that this regularization enables the network to learn to denoise even if it has not seen any clean images. The effectiveness of our method is based on the fact that CNNs naturally tend to capture low-level image statistics. Since our method utilizes the image prior implicitly captured by the deep denoising CNN to guide denoising, we refer to this training strategy as an Implicit Deep Denoiser Prior (IDDP). IDDP can be seen as a mixture of learning-based methods and traditional model-based denoising methods, in which regularization is adaptively formulated using the output of the network. We apply IDDP to various denoising tasks using only observed corrupted data and show that it achieves better denoising results than other self-supervised denoising methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25245/25017"
"25246","Accelerating the Training of Video Super-resolution Models","['Lijian Lin', 'Xintao Wang', 'Zhongang Qi', 'Ying Shan']","['ARC Lab, Tencent PCG', 'ARC Lab, Tencent PCG', 'ARC Lab, Tencent PCG', 'ARC Lab, Tencent PCG']","['CV: Low Level & Physics-Based Vision']","Lin, L., Wang, X., Qi, Z., & Shan, Y. (2023). Accelerating the Training of Video Super-resolution Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1595-1603. https://doi.org/10.1609/aaai.v37i2.25246","Abstract 					Despite that convolution neural networks (CNN) have recently demonstrated high-quality reconstruction for video super-resolution (VSR), efficiently training competitive VSR models remains a challenging problem. It usually takes an order of magnitude more time than training their counterpart image models, leading to long research cycles. Existing VSR methods typically train models with fixed spatial and temporal sizes from beginning to end. The fixed sizes are usually set to large values for good performance, resulting to slow training. However, is such a rigid training strategy necessary for VSR? In this work, we show that it is possible to gradually train video models from small to large spatial/temporal sizes, \ie, in an easy-to-hard manner. In particular, the whole training is divided into several stages and the earlier stage has smaller training spatial shape. Inside each stage, the temporal size also varies from short to long while the spatial size remains unchanged. Training is accelerated by such a multigrid training strategy, as most of computation is performed on smaller spatial and shorter temporal shapes. For further acceleration with GPU parallelization, we also investigate the large minibatch training without the loss in accuracy. Extensive experiments demonstrate that our method is capable of largely speeding up training (up to $6.2\times$ speedup in wall-clock training time) without performance drop for various VSR models.","https://ojs.aaai.org/index.php/AAAI/article/view/25246/25018"
"25247","SelectAugment: Hierarchical Deterministic Sample Selection for Data Augmentation","['Shiqi Lin', 'Zhizheng Zhang', 'Xin Li', 'Zhibo Chen']","['University of Science and Technology of China', 'Microsoft Research', 'University of Science and Technology of China', 'University of Science and Technology of China']","['CV: Learning & Optimization for CV', 'ML: Classification and Regression']","Lin, S., Zhang, Z., Li, X., & Chen, Z. (2023). SelectAugment: Hierarchical Deterministic Sample Selection for Data Augmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1604-1612. https://doi.org/10.1609/aaai.v37i2.25247","Abstract 					Data augmentation (DA) has been extensively studied to facilitate model optimization in many tasks. Prior DA works focus on designing augmentation operations themselves, while leaving selecting suitable samples for augmentation out of consideration. This might incur visual ambiguities and further induce training biases. In this paper, we propose an effective approach, dubbed SelectAugment, to select samples for augmentation in a deterministic and online manner based on the sample contents and the network training status. To facilitate the policy learning, in each batch, we exploit the hierarchy of this task by first determining the augmentation ratio and then deciding whether to augment each training sample under this ratio. We model this process as two-step decision-making and adopt Hierarchical Reinforcement Learning (HRL) to learn the selection policy. In this way, the negative effects of the randomness in selecting samples to augment can be effectively alleviated and the effectiveness of DA is improved. Extensive experiments demonstrate that our proposed SelectAugment significantly improves various off-the-shelf DA methods on image classification and fine-grained image recognition.","https://ojs.aaai.org/index.php/AAAI/article/view/25247/25019"
"25248","AdaCM: Adaptive ColorMLP for Real-Time Universal Photo-Realistic Style Transfer","['Tianwei Lin', 'Honglin Lin', 'Fu Li', 'Dongliang He', 'Wenhao Wu', 'Meiling Wang', 'Xin Li', 'Yong Liu']","['Baidu Inc.', 'Zhejiang University', 'Baidu Inc.', 'Baidu Inc.', 'The University of Sydney\nBaidu Inc.', 'Baidu Inc.', 'Baidu Inc.', 'Zhejiang University']","['CV: Computational Photography', 'Image & Video Synthesis']","Lin, T., Lin, H., Li, F., He, D., Wu, W., Wang, M., Li, X., & Liu, Y. (2023). AdaCM: Adaptive ColorMLP for Real-Time Universal Photo-Realistic Style Transfer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1613-1621. https://doi.org/10.1609/aaai.v37i2.25248","Abstract 					Photo-realistic style transfer aims at migrating the artistic style from an exemplar style image to a content image, producing a result image without spatial distortions or unrealistic artifacts. Impressive results have been achieved by recent deep models. However, deep neural network based methods are too expensive to run in real-time. Meanwhile, bilateral grid based methods are much faster but still contain artifacts like overexposure. In this work, we propose the Adaptive ColorMLP (AdaCM), an effective and efficient framework for universal photo-realistic style transfer. First, we find the complex non-linear color mapping between input and target domain can be efficiently modeled by a small multi-layer perceptron (ColorMLP) model. Then, in AdaCM, we adopt a CNN encoder to adaptively predict all parameters for the ColorMLP conditioned on each input content and style image pair. Experimental results demonstrate that AdaCM can generate vivid and high-quality stylization results. Meanwhile, our AdaCM is ultrafast and can process a 4K resolution image in 6ms on one V100 GPU.","https://ojs.aaai.org/index.php/AAAI/article/view/25248/25020"
"25249","SEPT: Towards Scalable and Efficient Visual Pre-training","['Yiqi Lin', 'Huabin Zheng', 'Huaping Zhong', 'Jinjing Zhu', 'Weijia Li', 'Conghui He', 'Lin Wang']","['AI Thrust, Information Hub, HKUST (Guangzhou), Guangzhou, China', 'SenseTime Research', 'SenseTime Research', 'AI Thrust, Information Hub, HKUST (Guangzhou), Guangzhou, China', 'Sun Yat-Sen University', 'SenseTime Research', 'AI Thrust, Information Hub, HKUST (Guangzhou), Guangzhou, China\nDepartment of Computer Science and Engineering, HKUST, Hong Kong, China']","['CV: Representation Learning for Vision', 'CV: Applications', 'CV: Other Foundations of Computer Vision']","Lin, Y., Zheng, H., Zhong, H., Zhu, J., Li, W., He, C., & Wang, L. (2023). SEPT: Towards Scalable and Efficient Visual Pre-training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1622-1630. https://doi.org/10.1609/aaai.v37i2.25249","Abstract 					Recently, the self-supervised pre-training paradigm has shown great potential in leveraging large-scale unlabeled data to improve downstream task performance. However, increasing the scale of unlabeled pre-training data in real-world scenarios requires prohibitive computational costs and faces the challenge of uncurated samples. To address these issues, we build a task-specific self-supervised pre-training framework from a data selection perspective based on a simple hypothesis that pre-training on the unlabeled samples with similar distribution to the target task can bring substantial performance gains. Buttressed by the hypothesis, we propose the first yet novel framework for Scalable and Efficient visual Pre-Training (SEPT) by introducing a retrieval pipeline for data selection. SEPT first leverage a self-supervised pre-trained model to extract the features of the entire unlabeled dataset for retrieval pipeline initialization. Then, for a specific target task, SEPT retrievals the most similar samples from the unlabeled dataset based on feature similarity for each target instance for pre-training. Finally, SEPT pre-trains the target model with the selected unlabeled samples in a self-supervised manner for target data finetuning. By decoupling the scale of pre-training and available upstream data for a target task, SEPT achieves high scalability of the upstream dataset and high efficiency of pre-training, resulting in high model architecture flexibility. Results on various downstream tasks demonstrate that SEPT can achieve competitive or even better performance compared with ImageNet pre-training while reducing the size of training samples by one magnitude without resorting to any extra annotations.","https://ojs.aaai.org/index.php/AAAI/article/view/25249/25021"
"25250","Cross-Modality Earth Mover’s Distance for Visible Thermal Person Re-identification","['Yongguo Ling', 'Zhun Zhong', 'Zhiming Luo', 'Fengxiang Yang', 'Donglin Cao', 'Yaojin Lin', 'Shaozi Li', 'Nicu Sebe']","['Xiamen University', 'University of Trento', 'Xiamen University', 'Xiamen University', 'Xiamen University', 'Minnan Normal University', 'Xiamen University, China', 'University of Trento']","['CV: Image and Video Retrieval', 'CV: Multi-modal Vision', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Ling, Y., Zhong, Z., Luo, Z., Yang, F., Cao, D., Lin, Y., Li, S., & Sebe, N. (2023). Cross-Modality Earth Mover’s Distance for Visible Thermal Person Re-identification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1631-1639. https://doi.org/10.1609/aaai.v37i2.25250","Abstract 					Visible thermal person re-identification (VT-ReID) suffers from inter-modality discrepancy and intra-identity variations. Distribution alignment is a popular solution for VT-ReID, however, it is usually restricted to the influence of the intra-identity variations. In this paper, we propose the Cross-Modality Earth Mover's Distance (CM-EMD) that can alleviate the impact of the intra-identity variations during modality alignment. CM-EMD selects an optimal transport strategy and assigns high weights to pairs that have a smaller intra-identity variation. In this manner, the model will focus on reducing the inter-modality discrepancy while paying less attention to intra-identity variations, leading to a more effective modality alignment. Moreover, we introduce two techniques to improve the advantage of CM-EMD. First, Cross-Modality Discrimination Learning (CM-DL) is designed to overcome the discrimination degradation problem caused by modality alignment. By reducing the ratio between intra-identity and inter-identity variances, CM-DL leads the model to learn more discriminative representations. Second, we construct the Multi-Granularity Structure (MGS), enabling us to align modalities from both coarse- and fine-grained levels with the proposed CM-EMD. Extensive experiments show the benefits of the proposed CM-EMD and its auxiliary techniques (CM-DL and MGS). Our method achieves state-of-the-art performance on two VT-ReID benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25250/25022"
"25251","Hypotheses Tree Building for One-Shot Temporal Sentence Localization","['Daizong Liu', 'Xiang Fang', 'Pan Zhou', 'Xing Di', 'Weining Lu', 'Yu Cheng']","['Huazhong University of Science and Technology\nPeking University', 'Nanyang Technological University', 'Huazhong University of Science and Technology', 'Protagolabs Inc.', 'Tsinghua University', 'Microsoft Research']","['CV: Language and Vision']","Liu, D., Fang, X., Zhou, P., Di, X., Lu, W., & Cheng, Y. (2023). Hypotheses Tree Building for One-Shot Temporal Sentence Localization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1640-1648. https://doi.org/10.1609/aaai.v37i2.25251","Abstract 					Given an untrimmed video, temporal sentence localization (TSL) aims to localize a specific segment according to a given sentence query. Though respectable works have made decent achievements in this task, they severely rely on dense video frame annotations, which require a tremendous amount of human effort to collect. In this paper, we target another more practical and challenging setting: one-shot temporal sentence localization (one-shot TSL), which learns to retrieve the query information among the entire video with only one annotated frame. Particularly, we propose an effective and novel tree-structure baseline for one-shot TSL, called Multiple Hypotheses Segment Tree (MHST), to capture the query-aware discriminative frame-wise information under the insufficient annotations. Each video frame is taken as the leaf-node, and the adjacent frames sharing the same visual-linguistic semantics will be merged into the upper non-leaf node for tree building. At last, each root node is an individual segment hypothesis containing the consecutive frames of its leaf-nodes. During the tree construction, we also introduce a pruning strategy to eliminate the interference of query-irrelevant nodes. With our designed self-supervised loss functions, our MHST is able to generate high-quality segment hypotheses for ranking and selection with the query. Experiments on two challenging datasets demonstrate that MHST achieves competitive performance compared to existing methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25251/25023"
"25252","The Devil Is in the Frequency: Geminated Gestalt Autoencoder for Self-Supervised Visual Pre-training","['Hao Liu', 'Xinghua Jiang', 'Xin Li', 'Antai Guo', 'Yiqing Hu', 'Deqiang Jiang', 'Bo Ren']","['Tencent', 'Tencent', 'Tencent', 'Tencent', 'Tencent', 'Tencent', 'Tencent']","['CV: Representation Learning for Vision', 'CV: Applications']","Liu, H., Jiang, X., Li, X., Guo, A., Hu, Y., Jiang, D., & Ren, B. (2023). The Devil Is in the Frequency: Geminated Gestalt Autoencoder for Self-Supervised Visual Pre-training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1649-1656. https://doi.org/10.1609/aaai.v37i2.25252","Abstract 					The self-supervised Masked Image Modeling (MIM) schema, following ""mask-and-reconstruct"" pipeline of recovering contents from masked image, has recently captured the increasing interest in the community, owing to the excellent ability of learning visual representation from unlabeled data. Aiming at learning representations with high semantics abstracted, a group of works attempts to reconstruct non-semantic pixels with large-ratio masking strategy, which may suffer from ""over-smoothing"" problem, while others directly infuse semantics into targets in off-line way requiring extra data. Different from them, we shift the perspective to the Fourier domain which naturally has global perspective and present a new Masked Image Modeling (MIM), termed Geminated Gestalt Autoencoder (Ge^2-AE) for visual pre-training. Specifically, we equip our model with geminated decoders in charge of reconstructing image contents from both pixel and frequency space, where each other serves as not only the complementation but also the reciprocal constraints. Through this way, more robust representations can be learned in the pre-trained encoders, of which the effectiveness is confirmed by the juxtaposing experimental results on downstream recognition tasks. We also conduct several quantitative and qualitative experiments to investigate the learning behavior of our method. To our best knowledge, this is the first MIM work to solve the visual pre-training through the lens of frequency domain.","https://ojs.aaai.org/index.php/AAAI/article/view/25252/25024"
"25253","M3AE: Multimodal Representation Learning for Brain Tumor Segmentation with Missing Modalities","['Hong Liu', 'Dong Wei', 'Donghuan Lu', 'Jinghan Sun', 'Liansheng Wang', 'Yefeng Zheng']","['School of informatics, Xiamen University, Xiamen, China\nTencent Jarvis Lab', 'Tencent Jarvis Lab', 'Tencent Jarvis Lab', 'Tencent Jarvis Lab\nSchool of Medicine, Xiamen University, Xiamen, China', 'School of informatics, Xiamen University, Xiamen, China', 'Tencent Jarvis Lab']","['CV: Medical and Biological Imaging', 'CV: Multi-modal Vision', 'CV: Segmentation', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning']","Liu, H., Wei, D., Lu, D., Sun, J., Wang, L., & Zheng, Y. (2023). M3AE: Multimodal Representation Learning for Brain Tumor Segmentation with Missing Modalities. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1657-1665. https://doi.org/10.1609/aaai.v37i2.25253","Abstract 					Multimodal magnetic resonance imaging (MRI) provides complementary information for sub-region analysis of brain tumors. Plenty of methods have been proposed for automatic brain tumor segmentation using four common MRI modalities and achieved remarkable performance. In practice, however, it is common to have one or more modalities missing due to image corruption, artifacts, acquisition protocols, allergy to contrast agents, or simply cost. In this work, we propose a novel two-stage framework for brain tumor segmentation with missing modalities. In the first stage, a multimodal masked autoencoder (M3AE) is proposed, where both random modalities (i.e., modality dropout) and random patches of the remaining modalities are masked for a reconstruction task, for self-supervised learning of robust multimodal representations against missing modalities. To this end, we name our framework M3AE. Meanwhile, we employ model inversion to optimize a representative full-modal image at marginal extra cost, which will be used to substitute for the missing modalities and boost performance during inference. Then in the second stage, a memory-efficient self distillation is proposed to distill knowledge between heterogenous missing-modal situations while fine-tuning the model for supervised segmentation. Our M3AE belongs to the ‘catch-all’ genre where a single model can be applied to all possible subsets of modalities, thus is economic for both training and deployment. Extensive experiments on BraTS 2018 and 2020 datasets demonstrate its superior performance to existing state-of-the-art methods with missing modalities, as well as the efficacy of its components. Our code is available at: https://github.com/ccarliu/m3ae.","https://ojs.aaai.org/index.php/AAAI/article/view/25253/25025"
"25254","From Coarse to Fine: Hierarchical Pixel Integration for Lightweight Image Super-resolution","['Jie Liu', 'Chao Chen', 'Jie Tang', 'Gangshan Wu']","['State Key Laboratory for Novel Software Technology, Nanjing University, China', 'State Key Laboratory for Novel Software Technology, Nanjing University, China', 'State Key Laboratory for Novel Software Technology, Nanjing University, China', 'State Key Laboratory for Novel Software Technology, Nanjing University, China']","['CV: Low Level & Physics-Based Vision', 'CV: Computational Photography', 'Image & Video Synthesis']","Liu, J., Chen, C., Tang, J., & Wu, G. (2023). From Coarse to Fine: Hierarchical Pixel Integration for Lightweight Image Super-resolution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1666-1674. https://doi.org/10.1609/aaai.v37i2.25254","Abstract 					Image super-resolution (SR) serves as a fundamental tool for the processing and transmission of multimedia data. Recently, Transformer-based models have achieved competitive performances in image SR. They divide images into fixed-size patches and apply self-attention on these patches to model long-range dependencies among pixels. However, this architecture design is originated for high-level vision tasks, which lacks design guideline from SR knowledge. In this paper, we aim to design a new attention block whose insights are from the interpretation of Local Attribution Map (LAM) for SR networks.  Specifically, LAM presents a hierarchical importance map where the most important pixels are located in a fine area of a patch and some less important pixels are spread in a coarse area of the whole image. To access pixels in the coarse area, instead of using a very large patch size, we propose a lightweight Global Pixel Access (GPA) module that applies cross-attention with the most similar patch in an image. In the fine area, we use an Intra-Patch Self-Attention (IPSA) module to model long-range pixel dependencies in a local patch, and then a spatial convolution is applied to process the finest details. In addition, a Cascaded Patch Division (CPD) strategy is proposed to enhance perceptual quality of recovered images. Extensive experiments suggest that our method outperforms state-of-the-art lightweight SR methods by a large margin. Code is available at https://github.com/passerer/HPINet.","https://ojs.aaai.org/index.php/AAAI/article/view/25254/25026"
"25255","Fast Fluid Simulation via Dynamic Multi-Scale Gridding","['Jinxian Liu', 'Ye Chen', 'Bingbing Ni', 'Wei Ren', 'Zhenbo Yu', 'Xiaoyang Huang']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'HUAWEI Hisilicon', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['CV: 3D Computer Vision', 'CV: Applications']","Liu, J., Chen, Y., Ni, B., Ren, W., Yu, Z., & Huang, X. (2023). Fast Fluid Simulation via Dynamic Multi-Scale Gridding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1675-1682. https://doi.org/10.1609/aaai.v37i2.25255","Abstract 					Recent works on learning-based frameworks for Lagrangian (i.e., particle-based) fluid simulation, though bypassing iterative pressure projection via efficient convolution operators, are still time-consuming due to excessive amount of particles. To address this challenge, we propose a dynamic multi-scale gridding method to reduce the magnitude of elements that have to be processed, by observing repeated particle motion patterns within certain consistent regions. Specifically, we hierarchically generate multi-scale micelles in Euclidean space by grouping particles that share similar motion patterns/characteristics based on super-light motion and scale estimation modules. With little internal motion variation, each micelle is modeled as a single rigid body with convolution only applied to a single representative particle. In addition, a distance-based interpolation is conducted to propagate relative motion message among micelles. With our efficient design, the network produces high visual fidelity fluid simulations with the inference time to be only 4.24 ms/frame (with 6K fluid particles), hence enables real-time human-computer interaction and animation. Experimental results on multiple datasets show that our work achieves great simulation acceleration with negligible prediction error increase.","https://ojs.aaai.org/index.php/AAAI/article/view/25255/25027"
"25256","TransLO: A Window-Based Masked Point Transformer Framework for Large-Scale LiDAR Odometry","['Jiuming Liu', 'Guangming Wang', 'Chaokang Jiang', 'Zhe Liu', 'Hesheng Wang']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'China University of Mining and Technology', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['CV: Vision for Robotics & Autonomous Driving', 'CV: 3D Computer Vision']","Liu, J., Wang, G., Jiang, C., Liu, Z., & Wang, H. (2023). TransLO: A Window-Based Masked Point Transformer Framework for Large-Scale LiDAR Odometry. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1683-1691. https://doi.org/10.1609/aaai.v37i2.25256","Abstract 					Recently, transformer architecture has gained great success in the computer vision community, such as image classification, object detection, etc. Nonetheless, its application for 3D vision remains to be explored, given that point cloud is inherently sparse, irregular, and unordered. Furthermore, existing point transformer frameworks usually feed raw point cloud of N×3 dimension into transformers, which limits the point processing scale because of their quadratic computational costs to the input size N. In this paper, we rethink the structure of point transformer. Instead of directly applying transformer to points, our network (TransLO) can process tens of thousands of points simultaneously by projecting points onto a 2D surface and then feeding them into a local transformer with linear complexity. Specifically, it is mainly composed of two components: Window-based Masked transformer with Self Attention (WMSA) to capture long-range dependencies; Masked Cross-Frame Attention (MCFA) to associate two frames and predict pose estimation. To deal with the sparsity issue of point cloud, we propose a binary mask to remove invalid and dynamic points. To our knowledge, this is the first transformer-based LiDAR odometry network. The experiment results on the KITTI odometry dataset show that our average rotation and translation RMSE achieves 0.500°/100m and 0.993% respectively. The performance of our network surpasses all recent learning-based methods and even outperforms LOAM on most evaluation sequences.Codes will be released on https://github.com/IRMVLab/TransLO.","https://ojs.aaai.org/index.php/AAAI/article/view/25256/25028"
"25257","Low-Light Video Enhancement with Synthetic Event Guidance","['Lin Liu', 'Junfeng An', 'Jianzhuang Liu', 'Shanxin Yuan', 'Xiangyu Chen', 'Wengang Zhou', 'Houqiang Li', 'Yan Feng Wang', 'Qi Tian']","['University of Science and Technology of China', 'Independent researcher', ""Huawei Noah's Ark Lab"", 'Queen Mary University of London', 'University of Macau;\nShenzhen Institute of Advanced Technology (SIAT)', 'University of Science and Technology of China', 'University of Science and Technology of China', 'Cooperative medianet innovation center of Shanghai Jiao Tong University', 'Huawei Cloud BU']","['CV: Low Level & Physics-Based Vision', 'CV: Computational Photography', 'Image & Video Synthesis', 'CV: Multi-modal Vision']","Liu, L., An, J., Liu, J., Yuan, S., Chen, X., Zhou, W., Li, H., Wang, Y. F., & Tian, Q. (2023). Low-Light Video Enhancement with Synthetic Event Guidance. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1692-1700. https://doi.org/10.1609/aaai.v37i2.25257","Abstract 					Low-light video enhancement (LLVE) is an important yet challenging task with many applications such as photographing and autonomous driving. Unlike single image low-light enhancement, most LLVE methods utilize temporal information from adjacent frames to restore the color and remove the noise of the target frame. However, these algorithms, based on the framework of multi-frame alignment and enhancement, may produce multi-frame fusion artifacts when encountering extreme low light or fast motion. In this paper, inspired by the low latency and high dynamic range of events, we use synthetic events from multiple frames to guide the enhancement and restoration of low-light videos. Our method contains three stages: 1) event synthesis and enhancement, 2) event and image fusion, and 3) low-light enhancement. In this framework, we design two novel modules (event-image fusion transform and event-guided dual branch) for the second and third stages, respectively. Extensive experiments show that our method outperforms existing low-light video or single image enhancement approaches on both synthetic and real LLVE datasets. Our code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/LLVE-SEG.","https://ojs.aaai.org/index.php/AAAI/article/view/25257/25029"
"25258","Novel Motion Patterns Matter for Practical Skeleton-Based Action Recognition","['Mengyuan Liu', 'Fanyang Meng', 'Chen Chen', 'Songtao Wu']","['Key Laboratory of Machine Perception, Peking University, Shenzhen Graduate School', 'Peng Cheng Laboratory', 'University of Central Florida', 'Sony R&D Center China']","['CV: 3D Computer Vision', 'CV: Video Understanding & Activity Analysis']","Liu, M., Meng, F., Chen, C., & Wu, S. (2023). Novel Motion Patterns Matter for Practical Skeleton-Based Action Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1701-1709. https://doi.org/10.1609/aaai.v37i2.25258","Abstract 					Most skeleton-based action recognition methods assume that the same type of action samples in the training set and the test set share similar motion patterns. However, action samples in real scenarios usually contain novel motion patterns which are not involved in the training set. As it is laborious to collect sufficient training samples to enumerate various types of novel motion patterns, this paper presents a practical skeleton-based action recognition task where the training set contains common motion patterns of action samples and the test set contains action samples that suffer from novel motion patterns. For this task, we present a Mask Graph Convolutional Network (Mask-GCN) to focus on learning action-specific skeleton joints that mainly convey action information meanwhile masking action-agnostic skeleton joints that convey rare action information and suffer more from novel motion patterns. Specifically, we design a policy network to learn layer-wise body masks to construct masked adjacency matrices, which guide a GCN-based backbone to learn stable yet informative action features from dynamic graph structure. Extensive experiments on our newly collected dataset verify that Mask-GCN outperforms most GCN-based methods when testing with various novel motion patterns.","https://ojs.aaai.org/index.php/AAAI/article/view/25258/25030"
"25259","EMEF: Ensemble Multi-Exposure Image Fusion","['Renshuai Liu', 'Chengyang Li', 'Haitao Cao', 'Yinglin Zheng', 'Ming Zeng', 'Xuan Cheng']","['School of Informatics, Xiamen Univeristy', 'School of Informatics, Xiamen University', 'School of Informatics, Xiamen University', 'School of Informatics, Xiamen University', 'School of Informatics, Xiamen University', 'School of Informatics, Xiamen Univeristy']","['CV: Computational Photography', 'Image & Video Synthesis']","Liu, R., Li, C., Cao, H., Zheng, Y., Zeng, M., & Cheng, X. (2023). EMEF: Ensemble Multi-Exposure Image Fusion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1710-1718. https://doi.org/10.1609/aaai.v37i2.25259","Abstract 					Although remarkable progress has been made in recent years, current multi-exposure image fusion (MEF) research is still bounded by the lack of real ground truth, objective evaluation function, and robust fusion strategy. In this paper, we study the MEF problem from a new perspective. We don’t utilize any synthesized ground truth, design any loss function, or develop any fusion strategy. Our proposed method EMEF takes advantage of the wisdom of multiple imperfect MEF contributors including both conventional and deep learning-based methods. Specifically, EMEF consists of two main stages: pre-train an imitator network and tune the imitator in the runtime. In the first stage, we make a unified network imitate different MEF targets in a style modulation way. In the second stage, we tune the imitator network by optimizing the style code, in order to find an optimal fusion result for each input pair. In the experiment, we construct EMEF from four state-of-the-art MEF methods and then make comparisons with the individuals and several other competitive methods on the latest released MEF benchmark dataset. The promising experimental results demonstrate that our ensemble framework can “get the best of all worlds”. The code is available at https://github.com/medalwill/EMEF.","https://ojs.aaai.org/index.php/AAAI/article/view/25259/25031"
"25260","Reducing Domain Gap in Frequency and Spatial Domain for Cross-Modality Domain Adaptation on Medical Image Segmentation","['Shaolei Liu', 'Siqi Yin', 'Linhao Qu', 'Manning Wang']","['Digital Medical Research Center, School of Basic Medical Science, Fudan University, Shanghai 200032, China\nShanghai Key Lab of Medical Image Computing and Computer Assisted Intervention, Shanghai 200032, China', 'Digital Medical Research Center, School of Basic Medical Science, Fudan University, Shanghai 200032, China\nShanghai Key Lab of Medical Image Computing and Computer Assisted Intervention, Shanghai 200032, China', 'Digital Medical Research Center, School of Basic Medical Science, Fudan University, Shanghai 200032, China\nShanghai Key Lab of Medical Image Computing and Computer Assisted Intervention, Shanghai 200032, China', 'Digital Medical Research Center, School of Basic Medical Science, Fudan University, Shanghai 200032, China\nShanghai Key Lab of Medical Image Computing and Computer Assisted Intervention, Shanghai 200032, China']","['CV: Medical and Biological Imaging', 'CV: Segmentation', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Liu, S., Yin, S., Qu, L., & Wang, M. (2023). Reducing Domain Gap in Frequency and Spatial Domain for Cross-Modality Domain Adaptation on Medical Image Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1719-1727. https://doi.org/10.1609/aaai.v37i2.25260","Abstract 					Unsupervised domain adaptation (UDA) aims to learn a model trained on source domain and performs well on unlabeled target domain. In medical image segmentation field, most existing UDA methods depend on adversarial learning to address the domain gap between different image modalities, which is ineffective due to its complicated training process. In this paper, we propose a simple yet effective UDA method based on frequency and spatial domain transfer under multi-teacher distillation framework. In the frequency domain, we first introduce non-subsampled contourlet transform for identifying domain-invariant and domain-variant frequency components (DIFs and DVFs), and then keep the DIFs unchanged while replacing the DVFs of the source domain images with that of the target domain images to narrow the domain gap. In the spatial domain, we propose a batch momentum update-based histogram matching strategy to reduce the domain-variant image style bias. Experiments on two commonly used cross-modality medical image segmentation datasets show that our proposed method achieves superior performance compared to state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25260/25032"
"25261","DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and Grounding","['Shilong Liu', 'Shijia Huang', 'Feng Li', 'Hao Zhang', 'Yaoyuan Liang', 'Hang Su', 'Jun Zhu', 'Lei Zhang']","['Dept. of CST, BNRist Center, Inst. for AI, Tsinghua-Bosch Joint Center for ML, Tsinghua University\nInternational Digital Economy Academy (IDEA)', 'The Chinese University of Hong Kong', 'International Digital Economy Academy (IDEA)\nThe Hong Kong University of Science and Technology', 'International Digital Economy Academy (IDEA)\nThe Hong Kong University of Science and Technology', 'Tsinghua-Berkeley Shenzhen Institute, Tsinghua University.', 'Dept. of CST, BNRist Center, Inst. for AI, Tsinghua-Bosch Joint Center for ML, Tsinghua University', 'Dept. of CST, BNRist Center, Inst. for AI, Tsinghua-Bosch Joint Center for ML, Tsinghua University', 'International Digital Economy Academy (IDEA)']","['CV: Multi-modal Vision', 'CV: Object Detection & Categorization', 'CV: Representation Learning for Vision']","Liu, S., Huang, S., Li, F., Zhang, H., Liang, Y., Su, H., Zhu, J., & Zhang, L. (2023). DQ-DETR: Dual Query Detection Transformer for Phrase Extraction and Grounding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1728-1736. https://doi.org/10.1609/aaai.v37i2.25261","Abstract 					In this paper, we study the problem of visual grounding by considering both phrase extraction and grounding (PEG). In contrast to the previous phrase-known-at-test setting, PEG requires a model to extract phrases from text and locate objects from image simultaneously, which is a more practical setting in real applications. As phrase extraction can be regarded as a 1D text segmentation problem, we formulate PEG as a dual detection problem and propose a novel DQ-DETR model, which introduces dual queries to probe different features from image and text for object prediction and phrase mask prediction. Each pair of dual queries are designed to have shared positional parts but different content parts. Such a design effectively alleviates the difficulty of modality alignment between image and text (in contrast to a single query design) and empowers Transformer decoder to leverage phrase mask-guided attention to improve the performance. To evaluate the performance of PEG, we also propose a new metric CMAP (cross-modal average precision), analogous to the AP metric in object detection. The new metric overcomes the ambiguity of Recall@1 in many-box-to-one-phrase cases in phrase grounding. As a result, our PEG pre-trained DQ-DETR establishes new state-of-the-art results on all visual grounding benchmarks with a ResNet-101 backbone. For example, it achieves 91.04% and 83.51% in terms of recall rate on RefCOCO testA and testB with a ResNet-101 backbone.","https://ojs.aaai.org/index.php/AAAI/article/view/25261/25033"
"25262","Progressive Neighborhood Aggregation for Semantic Segmentation Refinement","['Ting Liu', 'Yunchao Wei', 'Yanning Zhang']","['Northwestern Polytechnical University', 'Beijing Jiaotong University', 'Northwestern Polytechnical University']","['CV: Segmentation', 'CV: Applications', 'CV: Scene Analysis & Understanding', 'ML: Applications', 'ML: Deep Neural Architectures']","Liu, T., Wei, Y., & Zhang, Y. (2023). Progressive Neighborhood Aggregation for Semantic Segmentation Refinement. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1737-1745. https://doi.org/10.1609/aaai.v37i2.25262","Abstract 					Multi-scale features from backbone networks have been widely applied to recover object details in segmentation tasks. Generally, the multi-level features are fused in a certain manner for further pixel-level dense prediction. Whereas, the spatial structure information is not fully explored, that is similar nearby pixels can be used to complement each other. In this paper, we investigate a progressive neighborhood aggregation (PNA) framework to refine the semantic segmentation prediction, resulting in an end-to-end solution that can perform the coarse prediction and refinement in a unified network. Specifically, we first present a neighborhood aggregation module, the neighborhood similarity matrices for each pixel are estimated on multi-scale features, which are further used to progressively aggregate the high-level feature for recovering the spatial structure. In addition, to further integrate the high-resolution details into the aggregated feature, we apply a self-aggregation module on the low-level features to emphasize important semantic information for complementing losing spatial details. Extensive experiments on five segmentation datasets, including Pascal VOC 2012, CityScapes, COCO-Stuff 10k, DeepGlobe, and Trans10k, demonstrate that the proposed framework can be cascaded into existing segmentation models providing consistent improvements. In particular, our method achieves new state-of-the-art performances on two challenging datasets, DeepGlobe and Trans10k. The code is available at https://github.com/liutinglt/PNA.","https://ojs.aaai.org/index.php/AAAI/article/view/25262/25034"
"25263","CoordFill: Efficient High-Resolution Image Inpainting via Parameterized Coordinate Querying","['Weihuang Liu', 'Xiaodong Cun', 'Chi-Man Pun', 'Menghan Xia', 'Yong Zhang', 'Jue Wang']","['University of Macau', 'Tencent AI Lab', 'University of Macau', 'Tencent AI Lab', 'Tencent AI Lab', 'Tencent AI Lab']","['CV: Computational Photography', 'Image & Video Synthesis']","Liu, W., Cun, X., Pun, C.-M., Xia, M., Zhang, Y., & Wang, J. (2023). CoordFill: Efficient High-Resolution Image Inpainting via Parameterized Coordinate Querying. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1746-1754. https://doi.org/10.1609/aaai.v37i2.25263","Abstract 					Image inpainting aims to fill the missing hole of the input. It is hard to solve this task efficiently when facing high-resolution images due to two reasons: (1) Large reception field needs to be handled for high-resolution image inpainting. (2) The general encoder and decoder network synthesizes many background pixels synchronously due to the form of the image matrix. In this paper, we try to break the above limitations for the first time thanks to the recent development of continuous implicit representation. In detail, we down-sample and encode the degraded image to produce the spatial-adaptive parameters for each spatial patch via an attentional Fast Fourier Convolution (FFC)-based parameter generation network. Then, we take these parameters as the weights and biases of a series of multi-layer perceptron (MLP), where the input is the encoded continuous coordinates and the output is the synthesized color value. Thanks to the proposed structure, we only encode the high-resolution image in a relatively low resolution for larger reception field capturing. Then, the continuous position encoding will be helpful to synthesize the photo-realistic high-frequency textures by re-sampling the coordinate in a higher resolution. Also, our framework enables us to query the coordinates of missing pixels only in parallel, yielding a more efficient solution than the previous methods. Experiments show that the proposed method achieves real-time performance on the 2048X2048 images using a single GTX 2080 Ti GPU and can handle 4096X4096 images, with much better performance than existing state-of-the-art methods visually and numerically. The code is available at: https://github.com/NiFangBaAGe/CoordFill.","https://ojs.aaai.org/index.php/AAAI/article/view/25263/25035"
"25264","CCQ: Cross-Class Query Network for Partially Labeled Organ Segmentation","['Xuyang Liu', 'Bingbing Wen', 'Sibei Yang']","['School of Information Science and Technology, ShanghaiTech University', 'Information School, University of Washington', 'School of Information Science and Technology, ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging']","['CV: Medical and Biological Imaging']","Liu, X., Wen, B., & Yang, S. (2023). CCQ: Cross-Class Query Network for Partially Labeled Organ Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1755-1763. https://doi.org/10.1609/aaai.v37i2.25264","Abstract 					Learning multi-organ segmentation from multiple partially-labeled datasets attracts increasing attention. It can be a promising solution for the scarcity of large-scale, fully labeled 3D medical image segmentation datasets. However, existing algorithms of multi-organ segmentation on partially-labeled datasets neglect the semantic relations and anatomical priors between different categories of organs, which is crucial for partially-labeled multi-organ segmentation. In this paper, we tackle the limitations above by proposing the Cross-Class Query Network (CCQ). CCQ consists of an image encoder, a cross-class query learning module, and an attentive refinement segmentation module. More specifically, the image encoder captures the long-range dependency of a single image via the transformer encoder. Cross-class query learning module first generates query vectors that represent semantic concepts of different categories and then utilizes these query vectors to find the class-relevant features of image representation for segmentation. The attentive refinement segmentation module with an attentive skip connection incorporates the high-resolution image details and eliminates the class-irrelevant noise. Extensive experiment results demonstrate that CCQ outperforms all the state-of-the-art models on the MOTS dataset, which consists of seven organ and tumor segmentation tasks. Code is available at https://github.com/Yang-007/CCQ.git.","https://ojs.aaai.org/index.php/AAAI/article/view/25264/25036"
"25265","Counterfactual Dynamics Forecasting – a New Setting of Quantitative Reasoning","['Yanzhu Liu', 'Ying Sun', 'Joo-Hwee Lim']","['Institute for Infocomm Research (I2R) & Centre for Frontier AI Research (CFAR), A*STAR, Singapore', 'Institute for Infocomm Research (I2R) & Centre for Frontier AI Research (CFAR), A*STAR, Singapore', 'Institute for Infocomm Research (I2R) & Centre for Frontier AI Research (CFAR), A*STAR, Singapore']","['CV: Visual Reasoning & Symbolic Representations', 'CV: Applications', 'CV: Interpretability and Transparency', 'CV: Low Level & Physics-Based Vision', 'CV: Representation Learning for Vision', 'ML: Causal Learning', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms']","Liu, Y., Sun, Y., & Lim, J.-H. (2023). Counterfactual Dynamics Forecasting – a New Setting of Quantitative Reasoning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1764-1771. https://doi.org/10.1609/aaai.v37i2.25265","Abstract 					Rethinking and introspection are important elements of human intelligence. To mimic these capabilities, counterfactual reasoning has attracted attention of AI researchers recently, which aims to forecast the alternative outcomes for hypothetical scenarios (“what-if”). However, most existing approaches focused on qualitative reasoning (e.g., casual-effect relationship). It lacks a well-defined description of the differences between counterfactuals and facts, as well as how these differences evolve over time. This paper defines a new problem formulation - counterfactual dynamics forecasting - which is described in middle-level abstraction under the structural causal models (SCM) framework and derived as ordinary differential equations (ODEs) as low-level quantitative computation. Based on it, we propose a method to infer counterfactual dynamics considering the factual dynamics as demonstration. Moreover, the evolution of differences between facts and counterfactuals are modelled by an explicit temporal component. The experimental results on two dynamical systems demonstrate the effectiveness of the proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/25265/25037"
"25266","Self-Decoupling and Ensemble Distillation for Efficient Segmentation","['Yuang Liu', 'Wei Zhang', 'Jun Wang']","['East China Normal University', 'East China Normal University', 'East China Normal University']","['CV: Segmentation', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms', 'ML: Ensemble Methods', 'ML: Learning on the Edge & Model Compression']","Liu, Y., Zhang, W., & Wang, J. (2023). Self-Decoupling and Ensemble Distillation for Efficient Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1772-1780. https://doi.org/10.1609/aaai.v37i2.25266","Abstract 					Knowledge distillation (KD) is a promising teacher-student learning paradigm that transfers information from a cumbersome teacher to a student network. To avoid the training cost of a large teacher network, the recent studies propose to distill knowledge from the student itself, called Self-KD. However, due to the limitations of the performance and capacity of the student, the soft-labels or features distilled by the student barely provide reliable guidance. Moreover, most of the Self-KD algorithms are specific to classification tasks based on soft-labels, and not suitable for semantic segmentation. To alleviate these contradictions, we revisit the label and feature distillation problem in segmentation, and propose Self-Decoupling and Ensemble Distillation for Efficient Segmentation (SDES). Specifically, we design a decoupled prediction ensemble distillation (DPED) algorithm that generates reliable soft-labels with multiple expert decoders, and a decoupled feature ensemble distillation (DFED) mechanism to utilize more important channel-wise feature maps for encoder learning. The extensive experiments on three public segmentation datasets demonstrate the superiority of our approach and the efficacy of each component in the framework through the ablation study.","https://ojs.aaai.org/index.php/AAAI/article/view/25266/25038"
"25267","Token Mixing: Parameter-Efficient Transfer Learning from Image-Language to Video-Language","['Yuqi Liu', 'Luhui Xu', 'Pengfei Xiong', 'Qin Jin']","['Renmin University of China\nTencent', 'Tencent', 'Tencent', 'Renmin University of China']","['CV: Language and Vision']","Liu, Y., Xu, L., Xiong, P., & Jin, Q. (2023). Token Mixing: Parameter-Efficient Transfer Learning from Image-Language to Video-Language. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1781-1789. https://doi.org/10.1609/aaai.v37i2.25267","Abstract 					Applying large scale pre-trained image-language model to video-language tasks has recently become a trend, which brings two challenges. One is how to effectively transfer knowledge from static images to dynamic videos, and the other is how to deal with the prohibitive cost of fully fine-tuning due to growing model size. Existing works that attempt to realize parameter-efficient image-language to video-language transfer learning can be categorized into two types: 1) appending a sequence of temporal transformer blocks after the 2D Vision Transformer (ViT), and 2) inserting a temporal block into the ViT architecture. While these two types of methods only require fine-tuning the newly added components, there are still many parameters to update, and they are only validated on a single video-language task. In this work, based on our analysis of the core ideas of different temporal modeling components in existing approaches, we propose a token mixing strategy to enable cross-frame interactions, which enables transferring from the pre-trained image-language model to video-language tasks through selecting and mixing a key set and a value set from the input video samples. As token mixing does not require the addition of any components or modules, we can directly partially fine-tune the pre-trained image-language model to achieve parameter-efficiency. We carry out extensive experiments to compare our proposed token mixing method with other parameter-efficient transfer learning methods. Our token mixing method outperforms other methods on both understanding tasks and generation tasks. Besides, our method achieves new records on multiple video-language tasks. The code is available at https://github.com/yuqi657/video_language_model.","https://ojs.aaai.org/index.php/AAAI/article/view/25267/25039"
"25268","StereoDistill: Pick the Cream from LiDAR for Distilling Stereo-Based 3D Object Detection","['Zhe Liu', 'Xiaoqing Ye', 'Xiao Tan', 'Errui Ding', 'Xiang Bai']","['Huazhong University of Science and Technology', 'Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.', 'Huazhong University of Science and Technology']","['CV: 3D Computer Vision', 'CV: Multi-modal Vision', 'CV: Vision for Robotics & Autonomous Driving']","Liu, Z., Ye, X., Tan, X., Ding, E., & Bai, X. (2023). StereoDistill: Pick the Cream from LiDAR for Distilling Stereo-Based 3D Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1790-1798. https://doi.org/10.1609/aaai.v37i2.25268","Abstract 					In this paper, we propose a cross-modal distillation method named StereoDistill to narrow the gap between the stereo and LiDAR-based approaches via distilling the stereo detectors from the superior LiDAR model at the response level, which is usually overlooked in 3D object detection distillation. The key designs of StereoDistill are: the X-component Guided Distillation~(XGD) for regression and the Cross-anchor Logit Distillation~(CLD) for classification. In XGD, instead of empirically adopting a threshold to select the high-quality teacher predictions as soft targets, we decompose the predicted 3D box into  sub-components and retain the corresponding part for distillation if the teacher component pilot is consistent with ground truth to largely boost the number of positive predictions and alleviate the mimicking difficulty of the student model. For CLD, we aggregate the probability distribution of all anchors at the same position  to encourage the highest probability anchor rather than individually distill the distribution at the anchor level.  Finally, our StereoDistill achieves state-of-the-art results for stereo-based 3D detection on the KITTI test benchmark and extensive experiments on KITTI and Argoverse Dataset validate the effectiveness.","https://ojs.aaai.org/index.php/AAAI/article/view/25268/25040"
"25269","Good Helper Is around You: Attention-Driven Masked Image Modeling","['Zhengqi Liu', 'Jie Gui', 'Hao Luo']","['Southeast University', 'Southeast University\nPurple Mountain Laboratories', 'Alibaba group']","['CV: Representation Learning for Vision', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning']","Liu, Z., Gui, J., & Luo, H. (2023). Good Helper Is around You: Attention-Driven Masked Image Modeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1799-1807. https://doi.org/10.1609/aaai.v37i2.25269","Abstract 					It has been witnessed that masked image modeling (MIM) has shown a huge potential in self-supervised learning in the past year. Benefiting from the universal backbone vision transformer, MIM learns self-supervised visual representations through masking a part of patches of the image while attempting to recover the missing pixels. Most previous works mask patches of the image randomly, which underutilizes the semantic information that is beneficial to visual representation learning. On the other hand, due to the large size of the backbone, most previous works have to spend much time on pre-training. In this paper, we propose Attention-driven Masking and Throwing Strategy (AMT), which could solve both problems above. We first leverage the self-attention mechanism to obtain the semantic information of the image during the training process automatically without using any supervised methods. Masking strategy can be guided by that information to mask areas selectively, which is helpful for representation learning. Moreover, a redundant patch throwing strategy is proposed, which makes learning more efficient. As a plug-and-play module for masked image modeling, AMT improves the linear probing accuracy of MAE by 2.9% ~ 5.9% on CIFAR-10/100, STL-10, Tiny ImageNet, and ImageNet-1K, and obtains an improved performance with respect to fine-tuning accuracy of MAE and SimMIM. Moreover, this design also achieves superior performance on downstream detection and segmentation tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25269/25041"
"25270","RADIANT: Radar-Image Association Network for 3D Object Detection","['Yunfei Long', 'Abhinav Kumar', 'Daniel Morris', 'Xiaoming Liu', 'Marcos Castro', 'Punarjay Chakravarty']","['Michigan State University', 'Michigan State University', 'Michigan State University', 'Michigan State University', 'Ford Motor Company', 'Ford Motor Company']","['CV: Object Detection & Categorization', 'CV: Vision for Robotics & Autonomous Driving', 'CV: 3D Computer Vision']","Long, Y., Kumar, A., Morris, D., Liu, X., Castro, M., & Chakravarty, P. (2023). RADIANT: Radar-Image Association Network for 3D Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1808-1816. https://doi.org/10.1609/aaai.v37i2.25270","Abstract 					As a direct depth sensor, radar holds promise as a tool to improve monocular 3D object detection, which suffers from depth errors, due in part to the depth-scale ambiguity. On the other hand, leveraging radar depths is hampered by difficulties in precisely associating radar returns with 3D estimates from monocular methods, effectively erasing its benefits. This paper proposes a fusion network that addresses this radar-camera association challenge. We train our network to predict the 3D offsets between radar returns and object centers, enabling radar depths to enhance the accuracy of 3D monocular detection. By using parallel radar and camera backbones, our network fuses information at both the feature level and detection level, while at the same time leveraging a state-of-the-art monocular detection technique without retraining it. Experimental results show significant improvement in mean average precision and translation error on the nuScenes dataset over monocular counterparts. Our source code is available at https://github.com/longyunf/radiant.","https://ojs.aaai.org/index.php/AAAI/article/view/25270/25042"
"25271","CRIN: Rotation-Invariant Point Cloud Analysis and Rotation Estimation via Centrifugal Reference Frame","['Yujing Lou', 'Zelin Ye', 'Yang You', 'Nianjuan Jiang', 'Jiangbo Lu', 'Weiming Wang', 'Lizhuang Ma', 'Cewu Lu']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'SmartMore', 'SmartMore', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['CV: 3D Computer Vision', 'CV: Representation Learning for Vision', 'CV: Object Detection & Categorization', 'CV: Segmentation']","Lou, Y., Ye, Z., You, Y., Jiang, N., Lu, J., Wang, W., Ma, L., & Lu, C. (2023). CRIN: Rotation-Invariant Point Cloud Analysis and Rotation Estimation via Centrifugal Reference Frame. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1817-1825. https://doi.org/10.1609/aaai.v37i2.25271","Abstract 					Various recent methods attempt to implement rotation-invariant 3D deep learning by replacing the input coordinates of points with relative distances and angles. Due to the incompleteness of these low-level features, they have to undertake the expense of losing global information. In this paper, we propose the CRIN, namely Centrifugal Rotation-Invariant Network. CRIN directly takes the coordinates of points as input and transforms local points into rotation-invariant representations via centrifugal reference frames. Aided by centrifugal reference frames, each point corresponds to a discrete rotation so that the information of rotations can be implicitly stored in point features. Unfortunately, discrete points are far from describing the whole rotation space. We further introduce a continuous distribution for 3D rotations based on points. Furthermore, we propose an attention-based down-sampling strategy to sample points invariant to rotations. A relation module is adopted at last for reinforcing the long-range dependencies between sampled points and predicts the anchor point for unsupervised rotation estimation. Extensive experiments show that our method achieves rotation invariance, accurately estimates the object rotation, and obtains state-of-the-art results on rotation-augmented classification and part segmentation. Ablation studies validate the effectiveness of the network design.","https://ojs.aaai.org/index.php/AAAI/article/view/25271/25043"
"25272","See Your Emotion from Gait Using Unlabeled Skeleton Data","['Haifeng Lu', 'Xiping Hu', 'Bin Hu']","['School of Information Science and Engineering, Lanzhou University', 'School of Information Science and Engineering, Lanzhou University\nSchool of Medical Technology, Beijing Institute of Technology', 'School of Information Science and Engineering, Lanzhou University\nSchool of Medical Technology, Beijing Institute of Technology']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CMS: Affective Computing', 'CMS: Applications', 'CV: Applications']","Lu, H., Hu, X., & Hu, B. (2023). See Your Emotion from Gait Using Unlabeled Skeleton Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1826-1834. https://doi.org/10.1609/aaai.v37i2.25272","Abstract 					This paper focuses on contrastive learning for gait-based emotion recognition. The existing contrastive learning approaches are rarely suitable for learning skeleton-based gait representations, which suffer from limited gait diversity and inconsistent semantics. In this paper, we propose a Cross-coordinate contrastive learning framework utilizing Ambiguity samples for self-supervised Gait-based Emotion representation (CAGE). First, we propose ambiguity transform to push positive samples into ambiguous semantic space. By learning similarities between ambiguity samples and positive samples, our model can learn higher-level semantics of the gait sequences and maintain semantic diversity. Second, to encourage learning the semantic invariance, we uniquely propose cross-coordinate contrastive learning between the Cartesian coordinate and the Spherical coordinate, which brings rich supervisory signals to learn the intrinsic semantic consistency information. Exhaustive experiments show that CAGE improves existing self-supervised methods by 5%–10% accuracy, and it achieves comparable or even superior performance to supervised methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25272/25044"
"25273","Learning Progressive Modality-Shared Transformers for Effective Visible-Infrared Person Re-identification","['Hu Lu', 'Xuezhang Zou', 'Pingping Zhang']","['Jiangsu University', 'Jiangsu University', 'Dalian University of Technology']","['CV: Multi-modal Vision', 'CV: Image and Video Retrieval']","Lu, H., Zou, X., & Zhang, P. (2023). Learning Progressive Modality-Shared Transformers for Effective Visible-Infrared Person Re-identification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1835-1843. https://doi.org/10.1609/aaai.v37i2.25273","Abstract 					Visible-Infrared Person Re-Identification (VI-ReID) is a challenging retrieval task under complex modality changes. Existing methods usually focus on extracting discriminative visual features while ignoring the reliability and commonality of visual features between different modalities. In this paper, we propose a novel deep learning framework named Progressive Modality-shared Transformer (PMT) for effective VI-ReID. To reduce the negative effect of modality gaps, we first take the gray-scale images as an auxiliary modality and propose a progressive learning strategy. Then, we propose a Modality-Shared Enhancement Loss (MSEL) to guide the model to explore more reliable identity information from modality-shared features. Finally, to cope with the problem of large intra-class differences and small inter-class differences, we propose a Discriminative Center Loss (DCL) combined with the MSEL to further improve the discrimination of reliable features. Extensive experiments on SYSU-MM01 and RegDB datasets show that our proposed framework performs better than most state-of-the-art methods. For model reproduction, we release the source code at https://github.com/hulu88/PMT.","https://ojs.aaai.org/index.php/AAAI/article/view/25273/25045"
"25274","Breaking Immutable: Information-Coupled Prototype Elaboration for Few-Shot Object Detection","['Xiaonan Lu', 'Wenhui Diao', 'Yongqiang Mao', 'Junxi Li', 'Peijin Wang', 'Xian Sun', 'Kun Fu']","['Aerospace Information Research Institute, Chinese Academy of Sciences\nKey Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences\nSchool of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences\nKey Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences\nSchool of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences\nKey Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences\nSchool of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences\nKey Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences\nSchool of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences\nKey Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences\nKey Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences\nSchool of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences\nKey Laboratory of Network Information System Technology (NIST), Aerospace Information Research Institute, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences\nSchool of Electronic, Electrical and Communication Engineering, University of Chinese Academy of Sciences']","['CV: Object Detection & Categorization', 'ML: Meta Learning']","Lu, X., Diao, W., Mao, Y., Li, J., Wang, P., Sun, X., & Fu, K. (2023). Breaking Immutable: Information-Coupled Prototype Elaboration for Few-Shot Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1844-1852. https://doi.org/10.1609/aaai.v37i2.25274","Abstract 					Few-shot object detection, expecting detectors to detect novel classes with a few instances, has made conspicuous progress. However, the prototypes extracted by existing meta-learning based methods still suffer from insufficient representative information and lack awareness of query images, which cannot be adaptively tailored to different query images. Firstly, only the support images are involved for extracting prototypes, resulting in scarce perceptual information of query images. Secondly, all pixels of all support images are treated equally when aggregating features into prototype vectors, thus the salient objects are overwhelmed by the cluttered background. In this paper, we propose an Information-Coupled Prototype Elaboration (ICPE) method to generate specific and representative prototypes for each query image. Concretely, a conditional information coupling module is introduced to couple information from the query branch to the support branch, strengthening the query-perceptual information in support features. Besides, we design a prototype dynamic aggregation module that dynamically adjusts intra-image and inter-image aggregation weights to highlight the salient information useful for detecting query images. Experimental results on both Pascal VOC and MS COCO demonstrate that our method achieves state-of-the-art performance in almost all settings. Code will be available at: https://github.com/lxn96/ICPE.","https://ojs.aaai.org/index.php/AAAI/article/view/25274/25046"
"25275","ParaFormer: Parallel Attention Transformer for Efficient Feature Matching","['Xiaoyong Lu', 'Yaping Yan', 'Bin Kang', 'Songlin Du']","['Southeast University', 'Southeast University', 'Nanjing University of Posts and Telecommunication', 'Southeast University']","['CV: 3D Computer Vision']","Lu, X., Yan, Y., Kang, B., & Du, S. (2023). ParaFormer: Parallel Attention Transformer for Efficient Feature Matching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1853-1860. https://doi.org/10.1609/aaai.v37i2.25275","Abstract 					Heavy computation is a bottleneck limiting deep-learning-based feature matching algorithms to be applied in many real-time applications. However, existing lightweight networks optimized for Euclidean data cannot address classical feature matching tasks, since sparse keypoint based descriptors are expected to be matched. This paper tackles this problem and proposes two concepts: 1) a novel parallel attention model entitled ParaFormer and 2) a graph based U-Net architecture with attentional pooling. First, ParaFormer fuses features and keypoint positions through the concept of amplitude and phase, and integrates self- and cross-attention in a parallel manner which achieves a win-win performance in terms of accuracy and efficiency. Second, with U-Net architecture and proposed attentional pooling, the ParaFormer-U variant significantly reduces computational complexity, and minimize performance loss caused by downsampling. Sufficient experiments on various applications, including homography estimation, pose estimation, and image matching, demonstrate that ParaFormer achieves state-of-the-art performance while maintaining high efficiency. The efficient ParaFormer-U variant achieves comparable performance with less than 50% FLOPs of the existing attention-based models.","https://ojs.aaai.org/index.php/AAAI/article/view/25275/25047"
"25276","Robust One-Shot Segmentation of Brain Tissues via Image-Aligned Style Transformation","['Jinxin Lv', 'Xiaoyu Zeng', 'Sheng Wang', 'Ran Duan', 'Zhiwei Wang', 'Qiang Li']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology']","['CV: Medical and Biological Imaging', 'CV: Segmentation']","Lv, J., Zeng, X., Wang, S., Duan, R., Wang, Z., & Li, Q. (2023). Robust One-Shot Segmentation of Brain Tissues via Image-Aligned Style Transformation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1861-1869. https://doi.org/10.1609/aaai.v37i2.25276","Abstract 					One-shot segmentation of brain tissues is typically a dual-model iterative learning: a registration model (reg-model) warps a carefully-labeled atlas onto unlabeled images to initialize their pseudo masks for training a segmentation model (seg-model); the seg-model revises the pseudo masks to enhance the reg-model for a better warping in the next iteration. However, there is a key weakness in such dual-model iteration that the spatial misalignment inevitably caused by the reg-model could misguide the seg-model, which makes it converge on an inferior segmentation performance eventually. In this paper, we propose a novel image-aligned style transformation to reinforce the dual-model iterative learning for robust one-shot segmentation of brain tissues. Specifically, we first utilize the reg-model to warp the atlas onto an unlabeled image, and then employ the Fourier-based amplitude exchange with perturbation to transplant the style of the unlabeled image into the aligned atlas. This allows the subsequent seg-model to learn on the aligned and style-transferred copies of the atlas instead of unlabeled images, which naturally guarantees the correct spatial correspondence of an image-mask training pair, without sacrificing the diversity of intensity patterns carried by the unlabeled images. Furthermore, we introduce a feature-aware content consistency in addition to the image-level similarity to constrain the reg-model for a promising initialization, which avoids the collapse of image-aligned style transformation in the first iteration. Experimental results on two public datasets demonstrate 1) a competitive segmentation performance of our method compared to the fully-supervised method, and 2) a superior performance over other state-of-the-art with an increase of average Dice by up to 4.67%. The source code is available at: https://github.com/JinxLv/One-shot-segmentation-via-IST.","https://ojs.aaai.org/index.php/AAAI/article/view/25276/25048"
"25277","HRDoc: Dataset and Baseline Method toward Hierarchical Reconstruction of Document Structures","['Jiefeng Ma', 'Jun Du', 'Pengfei Hu', 'Zhenrong Zhang', 'Jianshu Zhang', 'Huihui Zhu', 'Cong Liu']","['University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China', 'iFLYTEK Research', 'iFLYTEK Research', 'iFLYTEK Research']","['CV: Language and Vision', 'CV: Applications', 'DMKM: Mining of Visual', 'Multimedia & Multimodal Data', 'SNLP: Applications']","Ma, J., Du, J., Hu, P., Zhang, Z., Zhang, J., Zhu, H., & Liu, C. (2023). HRDoc: Dataset and Baseline Method toward Hierarchical Reconstruction of Document Structures. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1870-1877. https://doi.org/10.1609/aaai.v37i2.25277","Abstract 					The problem of document structure reconstruction refers to converting digital or scanned documents into corresponding semantic structures. Most existing works mainly focus on splitting the boundary of each element in a single document page, neglecting the reconstruction of semantic structure in multi-page documents. This paper introduces hierarchical reconstruction of document structures as a novel task suitable for NLP and CV fields. To better evaluate the system performance on the new task, we built a large-scale dataset named HRDoc, which consists of 2,500 multi-page documents with nearly 2 million semantic units. Every document in HRDoc has line-level annotations including categories and relations obtained from rule-based extractors and human annotators. Moreover, we proposed an encoder-decoder-based hierarchical document structure parsing system (DSPS) to tackle this problem. By adopting a multi-modal bidirectional encoder and a structure-aware GRU decoder with soft-mask operation, the DSPS model surpass the baseline method by a large margin. All scripts and datasets will be made publicly available at https://github.com/jfma-USTC/HRDoc.","https://ojs.aaai.org/index.php/AAAI/article/view/25277/25049"
"25278","Semantic 3D-Aware Portrait Synthesis and Manipulation Based on Compositional Neural Radiance Field","['Tianxiang Ma', 'Bingchuan Li', 'Qian He', 'Jing Dong', 'Tieniu Tan']","['School of Artificial Intelligence, University of Chinese Academy of Sciences\nCRIPAC & NLPR, Institute of Automation, Chinese Academy of Sciences', 'ByteDance Ltd, Beijing, China', 'ByteDance Ltd, Beijing, China', 'CRIPAC & NLPR, Institute of Automation, Chinese Academy of Sciences', 'CRIPAC & NLPR, Institute of Automation, Chinese Academy of Sciences\nNanjing University']","['CV: Computational Photography', 'Image & Video Synthesis']","Ma, T., Li, B., He, Q., Dong, J., & Tan, T. (2023). Semantic 3D-Aware Portrait Synthesis and Manipulation Based on Compositional Neural Radiance Field. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1878-1886. https://doi.org/10.1609/aaai.v37i2.25278","Abstract 					Recently 3D-aware GAN methods with neural radiance field have developed rapidly. However, current methods model the whole image as an overall neural radiance field, which limits the partial semantic editability of synthetic results. Since NeRF renders an image pixel by pixel, it is possible to split NeRF in the spatial dimension. We propose a Compositional Neural Radiance Field (CNeRF) for semantic 3D-aware portrait synthesis and manipulation. CNeRF divides the image by semantic regions and learns an independent neural radiance field for each region, and finally fuses them and renders the complete image. Thus we can manipulate the synthesized semantic regions independently, while fixing the other parts unchanged. Furthermore, CNeRF is also designed to decouple shape and texture within each semantic region. Compared to state-of-the-art 3D-aware GAN methods, our approach enables fine-grained semantic region manipulation, while maintaining high-quality 3D-consistent synthesis. The ablation studies show the effectiveness of the structure and loss function used by our method. In addition real image inversion and cartoon portrait 3D editing experiments demonstrate the application potential of our method.","https://ojs.aaai.org/index.php/AAAI/article/view/25278/25050"
"25279","CFFT-GAN: Cross-Domain Feature Fusion Transformer for Exemplar-Based Image Translation","['Tianxiang Ma', 'Bingchuan Li', 'Wei Liu', 'Miao Hua', 'Jing Dong', 'Tieniu Tan']","['School of Artificial Intelligence, University of Chinese Academy of Sciences\nCRIPAC & NLPR, Institute of Automation, Chinese Academy of Sciences', 'ByteDance Ltd, Beijing, China', 'ByteDance Ltd, Beijing, China', 'ByteDance Ltd, Beijing, China', 'CRIPAC & NLPR, Institute of Automation, Chinese Academy of Sciences', 'CRIPAC & NLPR, Institute of Automation, Chinese Academy of Sciences\nNanjing University']","['CV: Computational Photography', 'Image & Video Synthesis']","Ma, T., Li, B., Liu, W., Hua, M., Dong, J., & Tan, T. (2023). CFFT-GAN: Cross-Domain Feature Fusion Transformer for Exemplar-Based Image Translation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1887-1895. https://doi.org/10.1609/aaai.v37i2.25279","Abstract 					Exemplar-based image translation refers to the task of generating images with the desired style, while conditioning on certain input image. Most of the current methods learn the correspondence between two input domains and lack the mining of information within the domain. In this paper, we propose a more general learning approach by considering two domain features as a whole and learning both inter-domain correspondence and intra-domain potential information interactions. Specifically, we propose a Cross-domain Feature Fusion Transformer (CFFT) to learn inter- and intra-domain feature fusion. Based on CFFT, the proposed CFFT-GAN works well on exemplar-based image translation. Moreover, CFFT-GAN is able to decouple and fuse features from multiple domains by cascading CFFT modules. We conduct rich quantitative and qualitative experiments on several image translation tasks, and the results demonstrate the superiority of our approach compared to state-of-the-art methods. Ablation studies show the importance of our proposed CFFT. Application experimental results reflect the potential of our method.","https://ojs.aaai.org/index.php/AAAI/article/view/25279/25051"
"25280","StyleTalk: One-Shot Talking Head Generation with Controllable Speaking Styles","['Yifeng Ma', 'Suzhen Wang', 'Zhipeng Hu', 'Changjie Fan', 'Tangjie Lv', 'Yu Ding', 'Zhidong Deng', 'Xin Yu']","['Department of Computer Science and Technology, BNRist, THUAI, State Key Laboratory of Intelligent Technology and Systems, Tsinghua University', 'Virtual Human Group, Netease Fuxi AI Lab', 'Virtual Human Group, Netease Fuxi AI Lab\nZhejiang University', 'Virtual Human Group, Netease Fuxi AI Lab', 'Virtual Human Group, Netease Fuxi AI Lab', 'Virtual Human Group, Netease Fuxi AI Lab\nZhejiang University', 'Department of Computer Science and Technology, BNRist, THUAI, State Key Laboratory of Intelligent Technology and Systems, Tsinghua University', 'University of Technology Sydney']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Language and Vision', 'CV: Multi-modal Vision']","Ma, Y., Wang, S., Hu, Z., Fan, C., Lv, T., Ding, Y., Deng, Z., & Yu, X. (2023). StyleTalk: One-Shot Talking Head Generation with Controllable Speaking Styles. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1896-1904. https://doi.org/10.1609/aaai.v37i2.25280","Abstract 					Different people speak with diverse personalized speaking styles. Although existing one-shot talking head methods have made significant progress in lip sync, natural facial expressions, and stable head motions, they still cannot generate diverse speaking styles in the final talking head videos. To tackle this problem, we propose a one-shot style-controllable talking face generation framework. In a nutshell, we aim to attain a speaking style from an arbitrary reference speaking video and then drive the one-shot portrait to speak with the reference speaking style and another piece of audio. Specifically, we first develop a style encoder to extract dynamic facial motion patterns of a style reference video and then encode them into a style code. Afterward, we introduce a style-controllable decoder to synthesize stylized facial animations from the speech content and style code. In order to integrate the reference speaking style into generated videos, we design a style-aware adaptive transformer, which enables the encoded style code to adjust the weights of the feed-forward layers accordingly. Thanks to the style-aware adaptation mechanism, the reference speaking style can be better embedded into synthesized videos during decoding. Extensive experiments demonstrate that our method is capable of generating talking head videos with diverse speaking styles from only one portrait image and an audio clip while achieving authentic visual effects. Project Page: https://github.com/FuxiVirtualHuman/styletalk.","https://ojs.aaai.org/index.php/AAAI/article/view/25280/25052"
"25281","Intriguing Findings of Frequency Selection for Image Deblurring","['Xintian Mao', 'Yiming Liu', 'Fengze Liu', 'Qingli Li', 'Wei Shen', 'Yan Wang']","['Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University', 'Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University', 'Johns Hopkins University', 'Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University', 'MoE Key Lab of Artificial Intelligence, AI Institute, Shanghai Jiao Tong University', 'Shanghai Key Laboratory of Multidimensional Information Processing, East China Normal University']","['CV: Low Level & Physics-Based Vision', 'CV: Applications']","Mao, X., Liu, Y., Liu, F., Li, Q., Shen, W., & Wang, Y. (2023). Intriguing Findings of Frequency Selection for Image Deblurring. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1905-1913. https://doi.org/10.1609/aaai.v37i2.25281","Abstract 					Blur was naturally analyzed in the frequency domain, by estimating the latent sharp image and the blur kernel given a blurry image. Recent progress on image deblurring always designs end-to-end architectures and aims at learning the difference between blurry and sharp image pairs from pixel-level, which inevitably overlooks the importance of blur kernels. This paper reveals an intriguing phenomenon that simply applying ReLU operation on the frequency domain of a blur image followed by inverse Fourier transform, i.e., frequency selection, provides faithful information about the blur pattern (e.g., the blur direction and blur level, implicitly shows the kernel pattern). Based on this observation, we attempt to leverage kernel-level information for image deblurring networks by inserting Fourier transform, ReLU operation, and inverse Fourier transform to the standard ResBlock. 1 × 1 convolution is further added to let the network modulate flexible thresholds for frequency selection. We term our newly built block as Res FFT-ReLU Block, which takes advantages of both kernel-level and pixel-level features via learning frequency-spatial dual-domain representations. Extensive experiments are conducted to acquire a thorough analysis on the insights of the method. Moreover, after plugging the proposed block into NAFNet, we can achieve 33.85 dB in PSNR on GoPro dataset. Our method noticeably improves backbone architectures without introducing many parameters, while maintaining low computational complexity. Code is available at https://github.com/DeepMed-Lab/DeepRFT-AAAI2023.","https://ojs.aaai.org/index.php/AAAI/article/view/25281/25053"
"25282","DocEdit: Language-Guided Document Editing","['Puneet Mathur', 'Rajiv Jain', 'Jiuxiang Gu', 'Franck Dernoncourt', 'Dinesh Manocha', 'Vlad I. Morariu']","['University of Maryland, College Park', 'Adobe Research', 'Adobe Research', 'Adobe Research', 'University of Maryland, College Park', 'Adobe Research']","['CV: Language and Vision', 'CV: Applications']","Mathur, P., Jain, R., Gu, J., Dernoncourt, F., Manocha, D., & Morariu, V. I. (2023). DocEdit: Language-Guided Document Editing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1914-1922. https://doi.org/10.1609/aaai.v37i2.25282","Abstract 					Professional document editing tools require a certain level of expertise to perform complex edit operations. To make editing tools accessible to increasingly novice users, we investigate intelligent document assistant systems that can make or suggest edits based on a user's natural language request. Such a system should be able to understand the user's ambiguous requests and contextualize them to the visual cues and textual content found in a document image to edit localized unstructured text and structured layouts. To this end, we propose a new task of language-guided localized document editing, where the user provides a document and an open vocabulary editing request, and the intelligent system produces a command that can be used to automate edits in real-world document editing software. In support of this task, we curate the DocEdit dataset, a collection of approximately 28K instances of user edit requests over PDF and design templates along with their corresponding ground truth software executable commands. To our knowledge, this is the first dataset that provides a diverse mix of edit operations with direct and indirect references to the embedded text and visual objects such as paragraphs, lists, tables, etc. We also propose DocEditor, a Transformer-based localization-aware multimodal (textual, spatial, and visual) model that performs the new task. The model attends to both document objects and related text contents which may be referred to in a user edit request, generating a multimodal embedding that is used to predict an edit command and associated bounding box localizing it. Our proposed model empirically outperforms other baseline deep learning approaches by 15-18%, providing a strong starting point for future work.","https://ojs.aaai.org/index.php/AAAI/article/view/25282/25054"
"25283","Progressive Few-Shot Adaptation of Generative Model with Align-Free Spatial Correlation","['Jongbo Moon', 'Hyunjun Kim', 'Jae-Pil Heo']","['Sungkyunkwan University', 'Sungkyunkwan University', 'Sungkyunkwan University']","['CV: Computational Photography', 'Image & Video Synthesis']","Moon, J., Kim, H., & Heo, J.-P. (2023). Progressive Few-Shot Adaptation of Generative Model with Align-Free Spatial Correlation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1923-1930. https://doi.org/10.1609/aaai.v37i2.25283","Abstract 					In few-shot generative model adaptation, the model for target domain is prone to the mode-collapse. Recent studies attempted to mitigate the problem by matching the relationship among samples generated from the same latent codes in source and target domains. The objective is further extended to image patch-level to transfer the spatial correlation within an instance. However, the patch-level approach assumes the consistency of spatial structure between source and target domains. For example, the positions of eyes in two domains are almost identical. Thus, it can bring visual artifacts if source and target domain images are not nicely aligned. In this paper, we propose a few-shot generative model adaptation method free from such assumption, based on a motivation that generative models are progressively adapting from the source domain to the target domain. Such progressive changes allow us to identify semantically coherent image regions between instances generated by models at a neighboring training iteration to consider the spatial correlation. We also propose an importance-based patch selection strategy to reduce the complexity of patch-level correlation matching. Our method shows the state-of-the-art few-shot domain adaptation performance in the qualitative and quantitative evaluations.","https://ojs.aaai.org/index.php/AAAI/article/view/25283/25055"
"25284","Minority-Oriented Vicinity Expansion with Attentive Aggregation for Video Long-Tailed Recognition","['WonJun Moon', 'Hyun Seok Seong', 'Jae-Pil Heo']","['Sungkyunkwan University', 'Sungkyunkwan University', 'Sungkyunkwan University']","['CV: Object Detection & Categorization', 'CV: Video Understanding & Activity Analysis']","Moon, W., Seong, H. S., & Heo, J.-P. (2023). Minority-Oriented Vicinity Expansion with Attentive Aggregation for Video Long-Tailed Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1931-1939. https://doi.org/10.1609/aaai.v37i2.25284","Abstract 					A dramatic increase in real-world video volume with extremely diverse and emerging topics naturally forms a long-tailed video distribution in terms of their categories, and it spotlights the need for Video Long-Tailed Recognition (VLTR). In this work, we summarize the challenges in VLTR and explore how to overcome them. The challenges are: (1) it is impractical to re-train the whole model for high-quality features, (2) acquiring frame-wise labels requires extensive cost, and (3) long-tailed data triggers biased training. Yet, most existing works for VLTR unavoidably utilize image-level features extracted from pretrained models which are task-irrelevant, and learn by video-level labels. Therefore, to deal with such (1) task-irrelevant features and (2) video-level labels, we introduce two complementary learnable feature aggregators. Learnable layers in each aggregator are to produce task-relevant representations, and each aggregator is to assemble the snippet-wise knowledge into a video representative. Then, we propose Minority-Oriented Vicinity Expansion (MOVE) that explicitly leverages the class frequency into approximating the vicinity distributions to alleviate (3) biased training. By combining these solutions, our approach achieves state-of-the-art results on large-scale VideoLT and synthetically induced Imbalanced-MiniKinetics200.  With VideoLT features from ResNet-50, it attains 18% and 58% relative improvements on head and tail classes over the previous state-of-the-art method, respectively.  Code and dataset are available at https://github.com/wjun0830/MOVE.","https://ojs.aaai.org/index.php/AAAI/article/view/25284/25056"
"25285","Show, Interpret and Tell: Entity-Aware Contextualised Image Captioning in Wikipedia","['Khanh Nguyen', 'Ali Furkan Biten', 'Andres Mafla', 'Lluis Gomez', 'Dimosthenis Karatzas']","['Computer Vision Center, Universitat Autonoma de Barcelona, Barcelona, Spain', 'Computer Vision Center, Universitat Autonoma de Barcelona, Barcelona, Spain', 'Computer Vision Center, Universitat Autonoma de Barcelona, Barcelona, Spain', 'Computer Vision Center, Universitat Autonoma de Barcelona, Barcelona, Spain', 'Computer Vision Center, Universitat Autonoma de Barcelona, Barcelona, Spain']","['CV: Language and Vision']","Nguyen, K., Biten, A. F., Mafla, A., Gomez, L., & Karatzas, D. (2023). Show, Interpret and Tell: Entity-Aware Contextualised Image Captioning in Wikipedia. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1940-1948. https://doi.org/10.1609/aaai.v37i2.25285","Abstract 					Humans exploit prior knowledge to describe images, and are able to adapt their explanation to specific contextual information given, even to the extent of inventing plausible explanations when contextual information and images do not match. In this work, we propose the novel task of captioning Wikipedia images by integrating contextual knowledge. Specifically, we produce models that jointly reason over Wikipedia articles, Wikimedia images and their associated descriptions to produce contextualized captions. The same Wikimedia image can be used to illustrate different articles, and the produced caption needs to be adapted to the specific context allowing us to explore the limits of the model to adjust captions to different contextual information. Dealing with out-of-dictionary words and Named Entities is a challenging task in this domain. To address this, we propose a pre-training objective, Masked Named Entity Modeling (MNEM), and show that this pretext task results to significantly improved models. Furthermore, we verify that a model pre-trained in Wikipedia generalizes well to News Captioning datasets. We further define two different test splits according to the difficulty of the captioning task. We offer insights on the role and the importance of each modality and highlight the limitations of our model.","https://ojs.aaai.org/index.php/AAAI/article/view/25285/25057"
"25286","TaCo: Textual Attribute Recognition via Contrastive Learning","['Chang Nie', 'Yiqing Hu', 'Yanqiu Qu', 'Hao Liu', 'Deqiang Jiang', 'Bo Ren']","['Tencent', 'Tencent', 'Tencent', 'Tencent', 'Tencent', 'Tencent']","['CV: Applications', 'CV: Representation Learning for Vision']","Nie, C., Hu, Y., Qu, Y., Liu, H., Jiang, D., & Ren, B. (2023). TaCo: Textual Attribute Recognition via Contrastive Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1949-1956. https://doi.org/10.1609/aaai.v37i2.25286","Abstract 					As textual attributes like font are core design elements of document format and page style, automatic attributes recognition favor comprehensive practical applications. Existing approaches already yield satisfactory performance in differentiating disparate attributes, but they still suffer in distinguishing similar attributes with only subtle difference. Moreover, their performance drop severely in real-world scenarios where unexpected and obvious imaging distortions appear. In this paper, we aim to tackle these problems by proposing TaCo, a contrastive framework for textual attribute recognition tailored toward the most common document scenes. Specifically, TaCo leverages contrastive learning to dispel the ambiguity trap arising from vague and open-ended attributes.  To realize this goal, we design the learning paradigm from three perspectives: 1) generating attribute views, 2) extracting subtle but crucial details, and 3) exploiting valued view pairs for learning, to fully unlock the pre-training potential.  Extensive experiments show that TaCo surpasses the supervised counterparts and advances the state-of-the-art remarkably on multiple attribute recognition tasks. Online services of TaCo will be made available.","https://ojs.aaai.org/index.php/AAAI/article/view/25286/25058"
"25287","GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds","['Jiahao Nie', 'Zhiwei He', 'Yuxiang Yang', 'Mingyu Gao', 'Jing Zhang']","['Hangzhou Dianzi University', 'Hangzhou Dianzi University', 'Hangzhou Dianzi University', 'Hangzhou DianZi University', 'The University of Sydney']","['CV: 3D Computer Vision', 'CV: Motion & Tracking', 'CV: Vision for Robotics & Autonomous Driving']","Nie, J., He, Z., Yang, Y., Gao, M., & Zhang, J. (2023). GLT-T: Global-Local Transformer Voting for 3D Single Object Tracking in Point Clouds. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1957-1965. https://doi.org/10.1609/aaai.v37i2.25287","Abstract 					Current 3D single object tracking methods are typically based on VoteNet, a 3D region proposal network. Despite the success, using a single seed point feature as the cue for offset learning in VoteNet prevents high-quality 3D proposals from being generated. Moreover, seed points with different importance are treated equally in the voting process, aggravating this defect. To address these issues, we propose a novel global-local transformer voting scheme to provide more informative cues and guide the model pay more attention on potential seed points, promoting the generation of high-quality 3D proposals. Technically, a global-local transformer (GLT) module is employed to integrate object- and patch-aware prior into seed point features to effectively form strong feature representation for geometric positions of the seed points, thus providing more robust and accurate cues for offset learning. Subsequently, a simple yet effective training strategy is designed to train the GLT module. We develop an importance prediction branch to learn the potential importance of the seed points and treat the output weights vector as a training constraint term. By incorporating the above components together, we exhibit a superior tracking method GLT-T. Extensive experiments on challenging KITTI and NuScenes benchmarks demonstrate that GLT-T achieves state-of-the-art performance in the 3D single object tracking task. Besides, further ablation studies show the advantages of the proposed global-local transformer voting scheme over the original VoteNet. Code and models will be available at https://github.com/haooozi/GLT-T.","https://ojs.aaai.org/index.php/AAAI/article/view/25287/25059"
"25288","Adapting Object Size Variance and Class Imbalance for Semi-supervised Object Detection","['Yuxiang Nie', 'Chaowei Fang', 'Lechao Cheng', 'Liang Lin', 'Guanbin Li']","['Sun Yat-sen University', 'Xidian University', 'Zhejiang Lab', 'Sun Yat-sen University', 'Sun Yat-sen University']","['CV: Object Detection & Categorization', 'CV: Learning & Optimization for CV', 'CV: Representation Learning for Vision', 'ML: Representation Learning', 'ML: Semi-Supervised Learning']","Nie, Y., Fang, C., Cheng, L., Lin, L., & Li, G. (2023). Adapting Object Size Variance and Class Imbalance for Semi-supervised Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1966-1974. https://doi.org/10.1609/aaai.v37i2.25288","Abstract 					Semi-supervised object detection (SSOD) attracts extensive research interest due to its great significance in reducing the data annotation effort. Collecting high-quality and category-balanced pseudo labels for unlabeled images is critical to addressing the SSOD problem. However, most of the existing pseudo-labeling-based methods depend on a large and fixed threshold to select high-quality pseudo labels from the predictions of a teacher model. Considering different object classes usually have different detection difficulty levels due to scale variance and data distribution imbalance, conventional pseudo-labeling-based methods are arduous to explore the value of unlabeled data sufficiently. To address these issues, we propose an adaptive pseudo labeling strategy, which can assign thresholds to classes with respect to their “hardness”. This is beneficial for ensuring the high quality of easier classes and increasing the quantity of harder classes simultaneously. Besides, label refinement modules are set up based on box jittering for guaranteeing the localization quality of pseudo labels. To further improve the algorithm’s robustness against scale variance and make the most of pseudo labels, we devise a joint feature-level and prediction-level consistency learning pipeline for transferring the information of the teacher model to the student model. Extensive experiments on COCO and VOC datasets indicate that our method achieves state-of-the-art performance. Especially, it brings mean average precision gains of 2.08 and 1.28 on MS-COCO dataset with 5% and 10% labeled images, respectively.","https://ojs.aaai.org/index.php/AAAI/article/view/25288/25060"
"25289","MIMO Is All You Need：A Strong Multi-in-Multi-Out Baseline for Video Prediction","['Shuliang Ning', 'Mengcheng Lan', 'Yanran Li', 'Chaofeng Chen', 'Qian Chen', 'Xunlai Chen', 'Xiaoguang Han', 'Shuguang Cui']","['FNii, CUHKSZ\nSSE, CUHKSZ', 'SSE, CUHKSZ', 'The University of Edinburgh', 'Nanyang Technological University', 'Shenzhen Meteorological Bureau', 'Shenzhen Meteorological Bureau', 'SSE, CUHKSZ\nFNii, CUHKSZ', 'SSE, CUHKSZ\nFNii, CUHKSZ']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Video Understanding & Activity Analysis']","Ning, S., Lan, M., Li, Y., Chen, C., Chen, Q., Chen, X., Han, X., & Cui, S. (2023). MIMO Is All You Need：A Strong Multi-in-Multi-Out Baseline for Video Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1975-1983. https://doi.org/10.1609/aaai.v37i2.25289","Abstract 					The mainstream of the existing approaches for video prediction builds up their models based on a Single-In-Single-Out (SISO) architecture, which takes the current frame as input to predict the next frame in a recursive manner. This way often leads to severe performance degradation when they try to extrapolate a longer period of future, thus limiting the practical use of the prediction model. Alternatively, a Multi-In-Multi-Out (MIMO) architecture that outputs all the future frames at one shot naturally breaks the recursive manner and therefore prevents error accumulation. However, only a few MIMO models for video prediction are proposed and they only achieve inferior performance due to the date.  The real strength of the MIMO model in this area is not well noticed and is largely under-explored. Motivated by that, we conduct a comprehensive investigation in this paper to thoroughly exploit how far a simple MIMO architecture can go. Surprisingly, our empirical studies reveal that a simple MIMO model can outperform the state-of-the-art work with a large margin much more than expected, especially in dealing with long-term error accumulation.  After exploring a number of ways and designs, we propose a new MIMO architecture based on extending the pure Transformer with local spatio-temporal blocks and a new multi-output decoder, namely MIMO-VP, to establish a new standard in video prediction. We evaluate our model in four highly competitive benchmarks.  Extensive experiments show that our model wins 1st place on all the benchmarks with remarkable performance gains and surpasses the best SISO model in all aspects including efficiency, quantity, and quality. A dramatic error reduction is achieved when predicting 10 frames on Moving MNIST and Weather datasets respectively. We believe our model can serve as a new baseline to facilitate the future research of video prediction tasks. The code will be released.","https://ojs.aaai.org/index.php/AAAI/article/view/25289/25061"
"25290","Universe Points Representation Learning for Partial Multi-Graph Matching","['Zhakshylyk Nurlanov', 'Frank R. Schmidt', 'Florian Bernard']","['University of Bonn\nRobert Bosch GmbH', 'Robert Bosch GmbH', 'University of Bonn']","['CV: Representation Learning for Vision', 'CV: Learning & Optimization for CV', 'ML: Graph-based Machine Learning']","Nurlanov, Z., Schmidt, F. R., & Bernard, F. (2023). Universe Points Representation Learning for Partial Multi-Graph Matching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1984-1992. https://doi.org/10.1609/aaai.v37i2.25290","Abstract 					Many challenges from natural world can be formulated as a graph matching problem. Previous deep learning-based methods mainly consider a full two-graph matching setting. In this work, we study the more general partial matching problem with multi-graph cycle consistency guarantees. Building on a recent progress in deep learning on graphs, we propose a novel data-driven method (URL) for partial multi-graph matching, which uses an object-to-universe formulation and learns latent representations of abstract universe points. The proposed approach advances the state of the art in semantic keypoint matching problem, evaluated on Pascal VOC, CUB, and Willow datasets. Moreover, the set of controlled experiments on a synthetic graph matching dataset demonstrates the scalability of our method to graphs with large number of nodes and its robustness to high partiality.","https://ojs.aaai.org/index.php/AAAI/article/view/25290/25062"
"25291","Robust Image Denoising of No-Flash Images Guided by Consistent Flash Images","['Geunwoo Oh', 'Jonghee Back', 'Jae-Pil Heo', 'Bochang Moon']","['Gwangju Institute of Science and Technology', 'Gwangju Institute of Science and Technology', 'Sungkyunkwan University', 'Gwangju Institute of Science and Technology']","['CV: Low Level & Physics-Based Vision', 'ML: Deep Neural Network Algorithms']","Oh, G., Back, J., Heo, J.-P., & Moon, B. (2023). Robust Image Denoising of No-Flash Images Guided by Consistent Flash Images. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 1993-2001. https://doi.org/10.1609/aaai.v37i2.25291","Abstract 					Images taken in low light conditions typically contain distracting noise, and eliminating such noise is a crucial computer vision problem. Additional photos captured with a camera flash can guide an image denoiser to preserve edges since the flash images often contain fine details with reduced noise. Nonetheless, a denoiser can be misled by inconsistent flash images, which have image structures (e.g., edges) that do not exist in no-flash images. Unfortunately, this disparity frequently occurs as the flash/no-flash pairs are taken in different light conditions. We propose a learning-based technique that robustly fuses the image pairs while considering their inconsistency. Our framework infers consistent flash image patches locally, which have similar image structures with the ground truth, and denoises no-flash images using the inferred ones via a combination model. We demonstrate that our technique can produce more robust results than state-of-the-art methods, given various flash/no-flash pairs with inconsistent image structures. The source code is available at https://github.com/CGLab-GIST/RIDFnF.","https://ojs.aaai.org/index.php/AAAI/article/view/25291/25063"
"25292","Coarse2Fine: Local Consistency Aware Re-prediction for Weakly Supervised Object Localization","['Yixuan Pan', 'Yao Yao', 'Yichao Cao', 'Chongjin Chen', 'Xiaobo Lu']","['School of Automation, Southeast University, Nanjing, China.\nKey Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Nanjing, China.', 'Shanghai Institute of Microsystem and Information Technology, Chinese Academy of Sciences Shanghai, China.\nUniversity of Chinese Academy of Sciences, Beijing, China.', 'School of Automation, Southeast University, Nanjing, China.\nKey Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Nanjing, China.', 'School of Automation, Southeast University, Nanjing, China.\nKey Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Nanjing, China.', 'School of Automation, Southeast University, Nanjing, China.\nKey Laboratory of Measurement and Control of Complex Systems of Engineering, Ministry of Education, Nanjing, China.']","['CV: Object Detection & Categorization', 'CV: Applications', 'CV: Representation Learning for Vision']","Pan, Y., Yao, Y., Cao, Y., Chen, C., & Lu, X. (2023). Coarse2Fine: Local Consistency Aware Re-prediction for Weakly Supervised Object Localization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2002-2010. https://doi.org/10.1609/aaai.v37i2.25292","Abstract 					Weakly supervised object localization aims to localize objects of interest by using only image-level labels. Existing methods generally segment activation map by threshold to obtain mask and generate bounding box. However, the activation map is locally inconsistent, i.e., similar neighboring pixels of the same object are not equally activated, which leads to the blurred boundary issue: the localization result is sensitive to the threshold, and the mask obtained directly from the activation map loses the fine contours of the object, making it difficult to obtain a tight bounding box. In this paper, we introduce the Local Consistency Aware Re-prediction (LCAR) framework, which aims to recover the complete fine object mask from locally inconsistent activation map and hence obtain a tight bounding box. To this end, we propose the self-guided re-prediction module (SGRM), which employs a novel superpixel aggregation network to replace the post-processing of threshold segmentation. In order to derive more reliable pseudo label from the activation map to supervise the SGRM, we further design an affinity refinement module (ARM) that utilizes the original image feature to better align the activation map with the image appearance, and design a self-distillation CAM (SD-CAM) to alleviate the locator dependence on saliency. Experiments demonstrate that our LCAR outperforms the state-of-the-art on both the CUB-200-2011 and ILSVRC datasets, achieving 95.89% and 70.72% of GT-Know localization accuracy, respectively.","https://ojs.aaai.org/index.php/AAAI/article/view/25292/25064"
"25293","Find Beauty in the Rare: Contrastive Composition Feature Clustering for Nontrivial Cropping Box Regression","['Zhiyu Pan', 'Yinpeng Chen', 'Jiale Zhang', 'Hao Lu', 'Zhiguo Cao', 'Weicai Zhong']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huawei CBG Consumer Cloud Service Search Product & Big Data Platform Department']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Applications']","Pan, Z., Chen, Y., Zhang, J., Lu, H., Cao, Z., & Zhong, W. (2023). Find Beauty in the Rare: Contrastive Composition Feature Clustering for Nontrivial Cropping Box Regression. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2011-2019. https://doi.org/10.1609/aaai.v37i2.25293","Abstract 					Automatic image cropping algorithms aim to recompose images like human-being photographers by generating the cropping boxes with improved composition quality. Cropping box regression approaches learn the beauty of composition from annotated cropping boxes. However, the bias of annotations leads to quasi-trivial recomposing results, which has an obvious tendency to the average location of training samples. The crux of this predicament is that the task is naively treated as a box regression problem, where rare samples might be dominated by normal samples, and the composition patterns of rare samples are not well exploited. Observing that similar composition patterns tend to be shared by the cropping boundaries annotated nearly, we argue to find the beauty of composition from the rare samples by clustering the samples with similar cropping boundary annotations, i.e., similar composition patterns. We propose a novel Contrastive Composition Clustering (C2C) to regularize the composition features by contrasting dynamically established similar and dissimilar pairs. In this way, common composition patterns of multiple images can be better summarized, which especially benefits the rare samples and endows our model with better generalizability to render nontrivial results. Extensive experimental results show the superiority of our model compared with prior arts. We also illustrate the philosophy of our design with an interesting analytical visualization.","https://ojs.aaai.org/index.php/AAAI/article/view/25293/25065"
"25294","Domain Decorrelation with Potential Energy Ranking","['Sen Pei', 'Jiaxi Sun', 'Richard Yi Da Xu', 'Shiming Xiang', 'Gaofeng Meng']","['NLPR, Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'NLPR, Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Hong Kong Baptist University', 'NLPR, Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'NLPR, Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences\nCAIR, HK Institute of Science and Innovation, Chinese Academy of Sciences']","['CV: Representation Learning for Vision', 'ML: Classification and Regression', 'CV: Other Foundations of Computer Vision', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Clustering']","Pei, S., Sun, J., Xu, R. Y. D., Xiang, S., & Meng, G. (2023). Domain Decorrelation with Potential Energy Ranking. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2020-2028. https://doi.org/10.1609/aaai.v37i2.25294","Abstract 					Machine learning systems, especially the methods based on deep learning, enjoy great success in modern computer vision tasks under ideal experimental settings. Generally, these classic deep learning methods are built on the i.i.d. assumption, supposing the training and test data are drawn from the same distribution independently and identically. However, the aforementioned i.i.d. assumption is, in general, unavailable in the real-world scenarios, and as a result, leads to sharp performance decay of deep learning algorithms. Behind this, domain shift is one of the primary factors to be blamed. In order to tackle this problem, we propose using Potential Energy Ranking (PoER) to decouple the object feature and the domain feature in given images, promoting the learning of label-discriminative representations while filtering out the irrelevant correlations between the objects and the background. PoER employs the ranking loss in shallow layers to make features with identical category and domain labels close to each other and vice versa. This makes the neural networks aware of both objects and background characteristics, which is vital for generating domain-invariant features. Subsequently, with the stacked convolutional blocks, PoER further uses the contrastive loss to make features within the same categories distribute densely no matter domains, filtering out the domain information progressively for feature alignment. PoER reports superior performance on domain generalization benchmarks, improving the average top-1 accuracy by at least 1.20% compared to the existing methods. Moreover, we use PoER in the ECCV 2022 NICO Challenge, achieving top place with only a vanilla ResNet-18 and winning the jury award. The code has been made publicly available at: https://github.com/ForeverPs/PoER.","https://ojs.aaai.org/index.php/AAAI/article/view/25294/25066"
"25295","PDRF: Progressively Deblurring Radiance Field for Fast Scene Reconstruction from Blurry Images","['Cheng Peng', 'Rama Chellappa']","['Johns Hopkins University', 'Johns Hopkins University']","['CV: 3D Computer Vision']","Peng, C., & Chellappa, R. (2023). PDRF: Progressively Deblurring Radiance Field for Fast Scene Reconstruction from Blurry Images. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2029-2037. https://doi.org/10.1609/aaai.v37i2.25295","Abstract 					We present Progressively Deblurring Radiance Field (PDRF), a novel approach to efficiently reconstruct high quality radiance fields from blurry images. While current State-of-The-Art (SoTA) scene reconstruction methods achieve photo-realistic renderings from clean source views, their performances suffer when the source views are affected by blur, which is commonly observed in the wild. Previous deblurring methods either do not account for 3D geometry, or are computationally intense. To addresses these issues, PDRF uses a progressively deblurring scheme for radiance field modeling, which can accurately model blur with 3D scene context. PDRF further uses an efficient importance sampling scheme that results in fast scene optimization. We perform extensive experiments and show that PDRF is 15X faster than previous SoTA while achieving better performance on both synthetic and real scenes.","https://ojs.aaai.org/index.php/AAAI/article/view/25295/25067"
"25296","Efficient End-to-End Video Question Answering with Pyramidal Multimodal Transformer","['Min Peng', 'Chongyang Wang', 'Yu Shi', 'Xiang-Dong Zhou']","['Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences\nChongqing School, University of Chinese Academy of Sciences', 'Tsinghua University', 'Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences', 'Chongqing Institute of Green and Intelligent Technology, Chinese Academy of Sciences']","['CV: Language and Vision', 'CV: Scene Analysis & Understanding', 'CV: Video Understanding & Activity Analysis', 'ML: Multimodal Learning', 'SNLP: Question Answering']","Peng, M., Wang, C., Shi, Y., & Zhou, X.-D. (2023). Efficient End-to-End Video Question Answering with Pyramidal Multimodal Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2038-2046. https://doi.org/10.1609/aaai.v37i2.25296","Abstract 					This paper presents a new method for end-to-end Video Question Answering (VideoQA), aside from the current popularity of using large-scale pre-training with huge feature extractors. We achieve this with a pyramidal multimodal transformer (PMT) model, which simply incorporates a learnable word embedding layer, a few convolutional and transformer layers. We use the anisotropic pyramid to fulfill video-language interactions across different spatio-temporal scales. In addition to the canonical pyramid, which includes both bottom-up and top-down pathways with lateral connections, novel strategies are proposed to decompose the visual feature stream into spatial and temporal sub-streams at different scales and implement their interactions with the linguistic semantics while preserving the integrity of local and global semantics. We demonstrate better or on-par performances with high computational efficiency against state-of-the-art methods on five VideoQA benchmarks. Our ablation study shows the scalability of our model that achieves competitive results for text-to-video retrieval by leveraging feature extractors with reusable pre-trained weights, and also the effectiveness of the pyramid. Code available at: https://github.com/Trunpm/PMT-AAAI23.","https://ojs.aaai.org/index.php/AAAI/article/view/25296/25068"
"25297","CL3D: Unsupervised Domain Adaptation for Cross-LiDAR 3D Detection","['Xidong Peng', 'Xinge Zhu', 'Yuexin Ma']","['ShanghaiTech University', 'The Chinese University of Hong Kong', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging']","['CV: 3D Computer Vision', 'CV: Object Detection & Categorization', 'CV: Vision for Robotics & Autonomous Driving', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Peng, X., Zhu, X., & Ma, Y. (2023). CL3D: Unsupervised Domain Adaptation for Cross-LiDAR 3D Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2047-2055. https://doi.org/10.1609/aaai.v37i2.25297","Abstract 					Domain adaptation for Cross-LiDAR 3D detection is challenging due to the large gap on the raw data representation with disparate point densities and point arrangements. By exploring domain-invariant 3D geometric characteristics and motion patterns, we present an unsupervised domain adaptation method that overcomes above difficulties. First, we propose the Spatial Geometry Alignment module to extract similar 3D shape geometric features of the same object class to align two domains, while eliminating the effect of distinct point distributions. Second, we present Temporal Motion Alignment module to utilize motion features in sequential frames of data to match two domains. Prototypes generated from two modules are incorporated into the pseudo-label reweighting procedure and contribute to our effective self-training framework for the target domain. Extensive experiments show that our method achieves state-of-the-art performance on cross-device datasets, especially for the datasets with large gaps captured by mechanical scanning LiDARs and solid-state LiDARs in various scenes. Project homepage is at https://github.com/4DVLab/CL3D.git.","https://ojs.aaai.org/index.php/AAAI/article/view/25297/25069"
"25298","Better and Faster: Adaptive Event Conversion for Event-Based Object Detection","['Yansong Peng', 'Yueyi Zhang', 'Peilin Xiao', 'Xiaoyan Sun', 'Feng Wu']","['University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China']","['CV: Object Detection & Categorization', 'CV: Applications']","Peng, Y., Zhang, Y., Xiao, P., Sun, X., & Wu, F. (2023). Better and Faster: Adaptive Event Conversion for Event-Based Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2056-2064. https://doi.org/10.1609/aaai.v37i2.25298","Abstract 					Event cameras are a kind of bio-inspired imaging sensor, which asynchronously collect sparse event streams with many advantages. In this paper, we focus on building better and faster event-based object detectors. To this end, we first propose a computationally efficient event representation Hyper Histogram, which adequately preserves both the polarity and temporal information of events. Then we devise an Adaptive Event Conversion module, which converts events into Hyper Histograms according to event density via an adaptive queue. Moreover, we introduce a novel event-based augmentation method Shadow Mosaic, which significantly improves the event sample diversity and enhances the generalization ability of detection models. We equip our proposed modules on three representative object detection models: YOLOv5, Deformable-DETR, and RetinaNet. Experimental results on three event-based detection datasets (1Mpx, Gen1, and MVSEC-NIGHTL21) demonstrate that our proposed approach outperforms other state-of-the-art methods by a large margin, while achieving a much faster running speed (< 14 ms and < 4 ms for 50 ms event data on the 1Mpx and Gen1 datasets).","https://ojs.aaai.org/index.php/AAAI/article/view/25298/25070"
"25299","CSTAR: Towards Compact and Structured Deep Neural Networks with Adversarial Robustness","['Huy Phan', 'Miao Yin', 'Yang Sui', 'Bo Yuan', 'Saman Zonouz']","['Rutgers University', 'Rutgers University', 'Rutgers University', 'Rutgers University', 'Georgia Institute of Technology']","['CV: Adversarial Attacks & Robustness', 'ML: Adversarial Learning & Robustness', 'ML: Matrix & Tensor Methods']","Phan, H., Yin, M., Sui, Y., Yuan, B., & Zonouz, S. (2023). CSTAR: Towards Compact and Structured Deep Neural Networks with Adversarial Robustness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2065-2073. https://doi.org/10.1609/aaai.v37i2.25299","Abstract 					Model compression and model defense for deep neural networks (DNNs) have been extensively and individually studied. Considering the co-importance of model compactness and robustness in practical applications, several prior works have explored to improve the adversarial robustness of the sparse neural networks. However, the structured sparse models obtained by the existing works suffer severe performance degradation for both benign and robust accuracy, thereby causing a challenging dilemma between robustness and structuredness of compact DNNs. To address this problem, in this paper, we propose CSTAR, an efficient solution that simultaneously impose Compactness, high STructuredness and high Adversarial Robustness on the target DNN models. By formulating the structuredness and robustness requirement within the same framework, the compressed DNNs can simultaneously achieve high compression performance and strong adversarial robustness. Evaluations for various DNN models on different datasets demonstrate the effectiveness of CSTAR. Compared with the state-of-the-art robust structured pruning, CSTAR shows consistently better performance. For instance, when compressing ResNet-18 on CIFAR-10, CSTAR achieves up to 20.07% and 11.91% improvement for benign accuracy and robust accuracy, respectively. For compressing ResNet-18 with 16x compression ratio on Imagenet, CSTAR obtains 8.58% benign accuracy gain and 4.27% robust accuracy gain compared to the existing robust structured pruning.","https://ojs.aaai.org/index.php/AAAI/article/view/25299/25071"
"25300","Exploring Stochastic Autoregressive Image Modeling for Visual Representation","['Yu Qi', 'Fan Yang', 'Yousong Zhu', 'Yufei Liu', 'Liwei Wu', 'Rui Zhao', 'Wei Li']","['Tsinghua University', 'SenseTime Research', 'Institute of Automation, Chinese Academy of Sciences', 'Tsinghua University', 'SenseTime Research', 'SenseTime Research\nQing Yuan Research Institute, Shanghai Jiao Tong University, Shanghai, China', 'SenseTime Research']","['CV: Representation Learning for Vision']","Qi, Y., Yang, F., Zhu, Y., Liu, Y., Wu, L., Zhao, R., & Li, W. (2023). Exploring Stochastic Autoregressive Image Modeling for Visual Representation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2074-2081. https://doi.org/10.1609/aaai.v37i2.25300","Abstract 					Autoregressive language modeling (ALM) has been successfully used in self-supervised pre-training in Natural language processing (NLP). However, this paradigm has not achieved comparable results with other self-supervised approaches in computer vision (e.g., contrastive learning, masked image modeling). In this paper, we try to find the reason why autoregressive modeling does not work well on vision tasks. To tackle this problem, we fully analyze the limitation of visual autoregressive methods and proposed a novel stochastic autoregressive image modeling (named SAIM) by the two simple designs. First, we serialize the image into patches. Second, we employ the stochastic permutation strategy to generate an effective and robust image context which is critical for vision tasks. To realize this task, we create a parallel encoder-decoder training process in which the encoder serves a similar role to the standard vision transformer focusing on learning the whole contextual information, and meanwhile the decoder predicts the content of the current position so that the encoder and decoder can reinforce each other. Our method significantly improves the performance of autoregressive image modeling and achieves the best accuracy (83.9%) on the vanilla ViT-Base model among methods using only ImageNet-1K data. Transfer performance in downstream tasks also shows that our model achieves competitive performance. Code is available at https://github.com/qiy20/SAIM.","https://ojs.aaai.org/index.php/AAAI/article/view/25300/25072"
"25301","Context-Aware Transformer for 3D Point Cloud Automatic Annotation","['Xiaoyan Qian', 'Chang Liu', 'Xiaojuan Qi', 'Siew-Chong Tan', 'Edmund Lam', 'Ngai Wong']","['The University of Hong Kong', 'The University of Hong Kong', 'The University of Hong Kong', 'The University of Hong Kong', 'The University of Hong Kong', 'The University of Hong Kong']","['CV: 3D Computer Vision', 'CV: Object Detection & Categorization', 'ML: Classification and Regression']","Qian, X., Liu, C., Qi, X., Tan, S.-C., Lam, E., & Wong, N. (2023). Context-Aware Transformer for 3D Point Cloud Automatic Annotation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2082-2090. https://doi.org/10.1609/aaai.v37i2.25301","Abstract 					3D automatic annotation has received increased attention since manually annotating 3D point clouds is laborious. However, existing methods are usually complicated, e.g., pipelined training for 3D foreground/background segmentation, cylindrical object proposals, and point completion. Furthermore, they often overlook the inter-object feature correlation that is particularly informative to hard samples for 3D annotation.  To this end, we propose a simple yet effective end-to-end Context-Aware Transformer (CAT) as an automated 3D-box labeler to generate precise 3D box annotations from 2D boxes, trained with a small number of human annotations. We adopt the general encoder-decoder architecture, where the CAT encoder consists of an intra-object encoder (local) and an inter-object encoder (global), performing self-attention along the sequence and batch dimensions, respectively. The former models intra-object interactions among points and the latter extracts feature relations among different objects, thus boosting scene-level understanding. Via local and global encoders, CAT can generate high-quality 3D box annotations with a streamlined workflow, allowing it to outperform existing state-of-the-arts by up to 1.79% 3D AP on the hard task of the KITTI test set.","https://ojs.aaai.org/index.php/AAAI/article/view/25301/25073"
"25302","Data-Efficient Image Quality Assessment with Attention-Panel Decoder","['Guanyi Qin', 'Runze Hu', 'Yutao Liu', 'Xiawu Zheng', 'Haotian Liu', 'Xiu Li', 'Yan Zhang']","['Tsinghua University', 'Beijing Institute of Technology', 'Ocean University of China', 'Peng Cheng Laboratory\nXiamen University', 'TsingHua University', 'Tsinghua University', 'Xiamen University']","['CV: Representation Learning for Vision', 'CV: Applications', 'CV: Other Foundations of Computer Vision']","Qin, G., Hu, R., Liu, Y., Zheng, X., Liu, H., Li, X., & Zhang, Y. (2023). Data-Efficient Image Quality Assessment with Attention-Panel Decoder. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2091-2100. https://doi.org/10.1609/aaai.v37i2.25302","Abstract 					Blind Image Quality Assessment (BIQA) is a fundamental task in computer vision, which however remains unresolved due to the complex distortion conditions and diversified image contents. To confront this challenge, we in this paper propose a novel BIQA pipeline based on the Transformer architecture, which achieves an efficient quality-aware feature representation with much fewer data. More specifically, we consider the traditional fine-tuning in BIQA as an interpretation of the pre-trained model. In this way, we further introduce a Transformer decoder to refine the perceptual information of the CLS token from different perspectives. This enables our model to establish the quality-aware feature manifold efficiently while attaining a strong generalization capability. Meanwhile, inspired by the subjective evaluation behaviors of human, we introduce a novel attention panel mechanism, which improves the model performance and reduces the prediction uncertainty simultaneously. The proposed BIQA method maintains a light-weight design with only one layer of the decoder, yet extensive experiments on eight standard BIQA datasets (both synthetic and authentic) demonstrate its superior performance to the state-of-the-art BIQA methods, i.e., achieving the SRCC values of 0.875 (vs. 0.859 in LIVEC) and 0.980 (vs. 0.969 in LIVE). Checkpoints, logs and code will be available at https://github.com/narthchin/DEIQT.","https://ojs.aaai.org/index.php/AAAI/article/view/25302/25074"
"25303","FoPro: Few-Shot Guided Robust Webly-Supervised Prototypical Learning","['Yulei Qin', 'Xingyu Chen', 'Chao Chen', 'Yunhang Shen', 'Bo Ren', 'Yun Gu', 'Jie Yang', 'Chunhua Shen']","['Tencent YouTu Lab', 'Tencent YouTu Lab', 'Tencent YouTu Lab', 'Tencent YouTu Lab', 'Tencent YouTu Lab', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Zhejiang University']","['CV: Representation Learning for Vision']","Qin, Y., Chen, X., Chen, C., Shen, Y., Ren, B., Gu, Y., Yang, J., & Shen, C. (2023). FoPro: Few-Shot Guided Robust Webly-Supervised Prototypical Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2101-2109. https://doi.org/10.1609/aaai.v37i2.25303","Abstract 					Recently, webly supervised learning (WSL) has been studied to leverage numerous and accessible data from the Internet. Most existing methods focus on learning noise-robust models from web images while neglecting the performance drop caused by the differences between web domain and real-world domain. However, only by tackling the performance gap above can we fully exploit the practical value of web datasets. To this end, we propose a Few-shot guided Prototypical (FoPro) representation learning method, which only needs a few labeled examples from reality and can significantly improve the performance in the real-world domain. Specifically, we initialize each class center with few-shot real-world data as the ``realistic"" prototype. Then, the intra-class distance between web instances and ``realistic"" prototypes is narrowed by contrastive learning. Finally, we measure image-prototype distance with a learnable metric. Prototypes are polished by adjacent high-quality web images and involved in removing distant out-of-distribution samples. In experiments, FoPro is trained on web datasets with a few real-world examples guided and evaluated on real-world datasets. Our method achieves the state-of-the-art performance on three fine-grained datasets and two large-scale datasets. Compared with existing WSL methods under the same few-shot settings, FoPro still excels in real-world generalization. Code is available at https://github.com/yuleiqin/fopro.","https://ojs.aaai.org/index.php/AAAI/article/view/25303/25075"
"25304","Exposing the Self-Supervised Space-Time Correspondence Learning via Graph Kernels","['Zheyun Qin', 'Xiankai Lu', 'Xiushan Nie', 'Yilong Yin', 'Jianbing Shen']","['Shandong university', 'Shandong University', 'Shandong Jianzhu University', 'Shandong University', 'University of Macau']","['CV: Video Understanding & Activity Analysis', 'CV: Representation Learning for Vision', 'CV: Scene Analysis & Understanding', 'CV: Segmentation']","Qin, Z., Lu, X., Nie, X., Yin, Y., & Shen, J. (2023). Exposing the Self-Supervised Space-Time Correspondence Learning via Graph Kernels. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2110-2118. https://doi.org/10.1609/aaai.v37i2.25304","Abstract 					Self-supervised space-time correspondence learning is emerging as a promising way of leveraging unlabeled video. Currently, most methods adapt contrastive learning with mining negative samples or reconstruction adapted from the image domain, which requires dense affinity across multiple frames or optical flow constraints. Moreover, video correspondence predictive models require mining more inherent properties in videos, such as structural information. In this work, we propose the VideoHiGraph, a space-time correspondence framework based on a learnable graph kernel. Concerning the video as the spatial-temporal graph, the learning objectives of VideoHiGraph are emanated in a self-supervised manner for predicting unobserved hidden graphs via graph kernel manner. We learn a representation of the temporal coherence across frames in which pairwise similarity defines the structured hidden graph, such that a biased random walk graph kernel along the sub-graph can predict long-range correspondence. Then, we learn a refined representation across frames on the node-level via a dense graph kernel. The self-supervision of the model training is formed by the structural and temporal consistency of the graph. VideoHiGraph achieves superior performance and demonstrates its robustness across the benchmark of label propagation tasks involving objects, semantic parts, keypoints, and instances. Our algorithm implementations have been made publicly available at https://github.com/zyqin19/VideoHiGraph.","https://ojs.aaai.org/index.php/AAAI/article/view/25304/25076"
"25305","Exploring Stroke-Level Modifications for Scene Text Editing","['Yadong Qu', 'Qingfeng Tan', 'Hongtao Xie', 'Jianjun Xu', 'YuXin Wang', 'Yongdong Zhang']","['University of Science and Technology of China', 'Cyberspace Institute of Advanced Technology, GuangZhou University, GuangZhou, China', 'University of Science and Technology of China', 'University of science and technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Learning & Optimization for CV', 'CV: Multi-modal Vision', 'ML: Deep Neural Architectures']","Qu, Y., Tan, Q., Xie, H., Xu, J., Wang, Y., & Zhang, Y. (2023). Exploring Stroke-Level Modifications for Scene Text Editing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2119-2127. https://doi.org/10.1609/aaai.v37i2.25305","Abstract 					Scene text editing (STE) aims to replace text with the desired one while preserving background and styles of the original text. However, due to the complicated background textures and various text styles, existing methods fall short in generating clear and legible edited text images. In this study, we attribute the poor editing performance to two problems: 1) Implicit decoupling structure. Previous methods of editing the whole image have to learn different translation rules of background and text regions simultaneously. 2) Domain gap. Due to the lack of edited real scene text images, the network can only be well trained on synthetic pairs and performs poorly on real-world images. To handle the above problems, we propose a novel network by MOdifying Scene Text image at strokE Level (MOSTEL). Firstly, we generate stroke guidance maps to explicitly indicate regions to be edited. Different from the implicit one by directly modifying all the pixels at image level, such explicit instructions filter out the distractions from background and guide the network to focus on editing rules of text regions. Secondly, we propose a Semi-supervised Hybrid Learning to train the network with both labeled synthetic images and unpaired real scene text images. Thus, the STE model is adapted to real-world datasets distributions. Moreover, two new datasets (Tamper-Syn2k and Tamper-Scene) are proposed to fill the blank of public evaluation datasets. Extensive experiments demonstrate that our MOSTEL outperforms previous methods both qualitatively and quantitatively. Datasets and code will be available at https://github.com/qqqyd/MOSTEL.","https://ojs.aaai.org/index.php/AAAI/article/view/25305/25077"
"25306","Unsupervised Deep Learning for Phase Retrieval via Teacher-Student Distillation","['Yuhui Quan', 'Zhile Chen', 'Tongyao Pang', 'Hui Ji']","['South China University of Technology\nPazhou Lab', 'South China University of Technology\nPazhou Lab', 'National University of Singapore', 'National University of Singapore']","['CV: Low Level & Physics-Based Vision', 'ML: Unsupervised & Self-Supervised Learning', 'CV: Computational Photography', 'Image & Video Synthesis']","Quan, Y., Chen, Z., Pang, T., & Ji, H. (2023). Unsupervised Deep Learning for Phase Retrieval via Teacher-Student Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2128-2136. https://doi.org/10.1609/aaai.v37i2.25306","Abstract 					Phase retrieval (PR) is a challenging nonlinear inverse problem in scientific imaging that involves reconstructing the phase of a signal from its intensity measurements. Recently, there has been an increasing interest in deep learning-based PR. Motivated by the challenge of collecting ground-truth (GT) images in many domains, this paper proposes a fully-unsupervised learning approach for PR, which trains an end-to-end deep model via a GT-free teacher-student online distillation framework. Specifically, a teacher model is trained using a self-expressive loss with noise resistance, while a student model is trained with a consistency loss on augmented data to exploit the teacher's dark knowledge. Additionally, we develop an enhanced unfolding  network for both the teacher and student models. Extensive experiments show that our proposed approach outperforms existing unsupervised PR methods with higher computational efficiency and performs competitively against supervised methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25306/25078"
"25307","A Learnable Radial Basis Positional Embedding for Coordinate-MLPs","['Sameera Ramasinghe', 'Simon Lucey']","['Amazon', 'University of Adelaide']","['CV: Representation Learning for Vision', 'CV: 3D Computer Vision']","Ramasinghe, S., & Lucey, S. (2023). A Learnable Radial Basis Positional Embedding for Coordinate-MLPs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2137-2145. https://doi.org/10.1609/aaai.v37i2.25307","Abstract 					We propose a novel method to enhance the performance of coordinate-MLPs (also referred to as neural fields) by learning instance-specific positional embeddings. End-to-end optimization of positional embedding parameters along with network weights leads to poor generalization performance. Instead, we develop a generic framework to learn the positional embedding based on the classic graph-Laplacian regularization, which can implicitly balance the trade-off between memorization and generalization. This framework is then used to propose a novel positional embedding scheme, where the hyperparameters are learned per coordinate (i.e instance)  to deliver optimal performance. We show that the proposed embedding achieves better performance with higher stability compared to the well-established random Fourier features (RFF). Further, we demonstrate that the proposed embedding scheme yields stable gradients, enabling seamless integration into deep architectures as intermediate layers.","https://ojs.aaai.org/index.php/AAAI/article/view/25307/25079"
"25308","Action-Conditioned Generation of Bimanual Object Manipulation Sequences","['Haziq Razali', 'Yiannis Demiris']","['Imperial College London', 'Imperial College London']","['CV: Motion & Tracking', 'ROB: Human-Robot Interaction']","Razali, H., & Demiris, Y. (2023). Action-Conditioned Generation of Bimanual Object Manipulation Sequences. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2146-2154. https://doi.org/10.1609/aaai.v37i2.25308","Abstract 					The generation of bimanual object manipulation sequences given a semantic action label has broad applications in collaborative robots or augmented reality. This relatively new problem differs from existing works that generate whole-body motions without any object interaction as it now requires the model to additionally learn the spatio-temporal relationship that exists between the human joints and object motion given said label. To tackle this task, we leverage the varying degree each muscle or joint is involved during object manipulation. For instance, the wrists act as the prime movers for the objects while the finger joints are angled to provide a firm grip. The remaining body joints are the least involved in that they are positioned as naturally and comfortably as possible. We thus design an architecture that comprises 3 main components: (i) a graph recurrent network that generates the wrist and object motion, (ii) an attention-based recurrent network that estimates the required finger joint angles given the graph configuration, and (iii) a recurrent network that reconstructs the body pose given the locations of the wrist. We evaluate our approach on the KIT Motion Capture and KIT RGBD Bimanual Manipulation datasets and show improvements over a simplified approach that treats the entire body as a single entity, and existing whole-body-only methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25308/25080"
"25309","Mean-Shifted Contrastive Loss for Anomaly Detection","['Tal Reiss', 'Yedid Hoshen']","['The Hebrew University of Jerusalem', 'The Hebrew University of Jerusalem']","['CV: Representation Learning for Vision', 'CV: Applications']","Reiss, T., & Hoshen, Y. (2023). Mean-Shifted Contrastive Loss for Anomaly Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2155-2162. https://doi.org/10.1609/aaai.v37i2.25309","Abstract 					Deep anomaly detection methods learn representations that separate between normal and anomalous images. Although self-supervised representation learning is commonly used, small dataset sizes limit its effectiveness. It was previously shown that utilizing external, generic datasets (e.g. ImageNet classification) can significantly improve anomaly detection performance. One approach is outlier exposure, which fails when the external datasets do not resemble the anomalies. We take the approach of transferring representations pre-trained on external datasets for anomaly detection. Anomaly detection performance can be significantly improved by fine-tuning the pre-trained representations on the normal training images. In this paper, we first demonstrate and analyze that contrastive learning, the most popular self-supervised learning paradigm cannot be naively applied to pre-trained features.  The reason is that pre-trained feature initialization causes poor conditioning for standard contrastive objectives, resulting in bad optimization dynamics. Based on our analysis, we provide a modified contrastive objective, the Mean-Shifted Contrastive Loss. Our method is highly effective and achieves a new state-of-the-art anomaly detection performance including 98.6% ROC-AUC on the CIFAR-10 dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/25309/25081"
"25310","Two Heads Are Better than One: Image-Point Cloud Network for Depth-Based 3D Hand Pose Estimation","['Pengfei Ren', 'Yuchen Chen', 'Jiachang Hao', 'Haifeng Sun', 'Qi Qi', 'Jingyu Wang', 'Jianxin Liao']","['Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: 3D Computer Vision']","Ren, P., Chen, Y., Hao, J., Sun, H., Qi, Q., Wang, J., & Liao, J. (2023). Two Heads Are Better than One: Image-Point Cloud Network for Depth-Based 3D Hand Pose Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2163-2171. https://doi.org/10.1609/aaai.v37i2.25310","Abstract 					Depth images and point clouds are the two most commonly used data representations for depth-based 3D hand pose estimation. Benefiting from the structuring of image data and the inherent inductive biases of the 2D Convolutional Neural Network (CNN), image-based methods are highly efficient and effective. However, treating the depth data as a 2D image inevitably ignores the 3D nature of depth data. Point cloud-based methods can better mine the 3D geometric structure of depth data. However, these methods suffer from the disorder and non-structure of point cloud data, which is computationally inefficient. In this paper, we propose an Image-Point cloud Network (IPNet) for accurate and robust 3D hand pose estimation. IPNet utilizes 2D CNN to extract visual representations in 2D image space and performs iterative correction in 3D point cloud space to exploit the 3D geometry information of depth data. In particular, we propose a sparse anchor-based ""aggregation-interaction-propagation'' paradigm to enhance point cloud features and refine the hand pose, which reduces irregular data access. Furthermore, we introduce a 3D hand model to the iterative correction process, which significantly improves the robustness of IPNet to occlusion and depth holes. Experiments show that IPNet outperforms state-of-the-art methods on three challenging hand datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25310/25082"
"25311","MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-robust Classifier","['Mozhdeh Rouhsedaghat', 'Masoud Monajatipoor', 'C.-C. Jay Kuo', 'Iacopo Masi']","['University of Southern California', 'University of California, Los Angeles', 'University of Southern California', 'Sapienza, University of Rome']","['CV: Applications', 'CV: Computational Photography', 'Image & Video Synthesis']","Rouhsedaghat, M., Monajatipoor, M., Kuo, C.-C. J., & Masi, I. (2023). MAGIC: Mask-Guided Image Synthesis by Inverting a Quasi-robust Classifier. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2172-2179. https://doi.org/10.1609/aaai.v37i2.25311","Abstract 					We offer a method for one-shot mask-guided image synthesis that allows controlling manipulations of a single image by inverting a quasi-robust classifier equipped with strong regularizers. Our proposed method, entitled MAGIC, leverages structured gradients from a pre-trained quasi-robust classifier to better preserve the input semantics while preserving its classification accuracy, thereby guaranteeing credibility in the synthesis. Unlike current methods that use complex primitives to supervise the process or use attention maps as a weak supervisory signal, MAGIC aggregates gradients over the input, driven by a guide binary mask that enforces a strong, spatial prior. MAGIC implements a series of manipulations with a single framework achieving shape and location control, intense non-rigid shape deformations, and copy/move operations in the presence of repeating objects and gives users firm control over the synthesis by requiring to simply specify binary guide masks.  Our study and findings are supported by various qualitative comparisons with the state-of-the-art on the same images sampled from ImageNet and quantitative analysis using machine perception along with a user survey of 100+ participants that endorse our synthesis quality.","https://ojs.aaai.org/index.php/AAAI/article/view/25311/25083"
"25312","Domain Generalised Faster R-CNN","['Karthik Seemakurthy', 'Charles Fox', 'Erchan Aptoula', 'Petra Bosilj']","['Lincoln Institute of Agri-Food Technology, University of Lincoln', 'School of Computer Science, University of Lincoln', 'Faculty of Engineering and Natural Sciences (VPALab), Sabanci University', 'School of Computer Science, University of Lincoln\nLincoln Institute of Agri-Food Technology, University of Lincoln']","['CV: Object Detection & Categorization', 'CV: Other Foundations of Computer Vision', 'CV: Representation Learning for Vision', 'CV: Vision for Robotics & Autonomous Driving', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Seemakurthy, K., Fox, C., Aptoula, E., & Bosilj, P. (2023). Domain Generalised Faster R-CNN. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2180-2190. https://doi.org/10.1609/aaai.v37i2.25312","Abstract 					Domain generalisation (i.e. out-of-distribution generalisation) is an open problem in machine learning, where the goal is to train a model via one or more source domains, that will generalise well to unknown target domains. While the topic is attracting increasing interest, it has not been studied in detail in the context of object detection. The established approaches all operate under the covariate shift assumption, where the conditional distributions are assumed to be approximately equal across source domains. This is the first paper to address domain generalisation in the context of object detection, with a rigorous mathematical analysis of domain shift, without the covariate shift assumption. We focus on improving the generalisation ability of object detection by proposing new regularisation terms to address the domain shift that arises due to both classification and bounding box regression. Also, we include an additional consistency regularisation term to align the local and global level predictions. The proposed approach is implemented as a Domain Generalised Faster R-CNN and evaluated using four object detection datasets which provide domain metadata (GWHD, Cityscapes, BDD100K, Sim10K) where it exhibits a consistent performance improvement over the baselines. All the codes for replicating the results in this paper can be found at https://github.com/karthikiitm87/domain-generalisation.git","https://ojs.aaai.org/index.php/AAAI/article/view/25312/25084"
"25313","MIDMs: Matching Interleaved Diffusion Models for Exemplar-Based Image Translation","['Junyoung Seo', 'Gyuseong Lee', 'Seokju Cho', 'Jiyoung Lee', 'Seungryong Kim']","['Korea University', 'Korea University', 'Korea University', 'NAVER AI Lab', 'Korea University']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Applications']","Seo, J., Lee, G., Cho, S., Lee, J., & Kim, S. (2023). MIDMs: Matching Interleaved Diffusion Models for Exemplar-Based Image Translation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2191-2199. https://doi.org/10.1609/aaai.v37i2.25313","Abstract 					We present a novel method for exemplar-based image translation, called matching interleaved diffusion models (MIDMs). Most existing methods for this task were formulated as GAN-based matching-then-generation framework. However, in this framework, matching errors induced by the difficulty of semantic matching across cross-domain, e.g., sketch and photo, can be easily propagated to the generation step, which in turn leads to the degenerated results. Motivated by the recent success of diffusion models, overcoming the shortcomings of GANs, we incorporate the diffusion models to overcome these limitations. Specifically, we formulate a diffusion-based matching-and-generation framework that interleaves cross-domain matching and diffusion steps in the latent space by iteratively feeding the intermediate warp into the noising process and denoising it to generate a translated image. In addition, to improve the reliability of diffusion process, we design confidence-aware process using cycle-consistency to consider only confident regions during translation. Experimental results show that our MIDMs generate more plausible images than state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25313/25085"
"25314","JR2Net: Joint Monocular 3D Face Reconstruction and Reenactment","['Jiaxiang Shang', 'Yu Zeng', 'Xin Qiao', 'Xin Wang', 'Runze Zhang', 'Guangyuan Sun', 'Vishal Patel', 'Hongbo Fu']","['Hong Kong University of Science and Technology', 'Johns Hopkins University', 'Tencent', 'Tencent', 'Tencent', 'Tencent', 'Johns Hopkins University', 'City University of Hong Kong']","['CV: Biometrics', 'Face', 'Gesture & Pose']","Shang, J., Zeng, Y., Qiao, X., Wang, X., Zhang, R., Sun, G., Patel, V., & Fu, H. (2023). JR2Net: Joint Monocular 3D Face Reconstruction and Reenactment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2200-2208. https://doi.org/10.1609/aaai.v37i2.25314","Abstract 					Face reenactment and reconstruction benefit various applications in self-media, VR, etc. Recent face reenactment methods use 2D facial landmarks to implicitly retarget facial expressions and poses from driving videos to source images, while they suffer from pose and expression preservation issues for cross-identity scenarios, i.e., when the source and the driving subjects are different. Current self-supervised face reconstruction methods also demonstrate impressive results. However, these methods do not handle large expressions well, since their training data lacks samples of large expressions, and 2D facial attributes are inaccurate on such samples. To mitigate the above problems, we propose to explore the inner connection between the two tasks, i.e., using face reconstruction to provide  sufficient 3D information for reenactment, and synthesizing videos paired with captured face model parameters through face reenactment to enhance the expression module of face reconstruction. In particular, we propose a novel cascade framework named JR2Net for Joint Face Reconstruction and Reenactment, which begins with the training of a coarse reconstruction network, followed by a 3D-aware face reenactment network based on the coarse reconstruction results. In the end, we train an expression tracking network based on our synthesized videos composed by image-face model parameter pairs. Such an expression tracking network can further enhance the coarse face reconstruction. Extensive experiments show that our JR2Net outperforms the state-of-the-art methods on several face reconstruction and reenactment benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25314/25086"
"25315","HVTSurv: Hierarchical Vision Transformer for Patient-Level Survival Prediction from Whole Slide Image","['Zhuchen Shao', 'Yang Chen', 'Hao Bian', 'Jian Zhang', 'Guojun Liu', 'Yongbing Zhang']","['Tsinghua Shenzhen International Graduate School, Tsinghua University', 'Tsinghua Shenzhen International Graduate School, Tsinghua University', 'Tsinghua Shenzhen International Graduate School, Tsinghua University', 'Peking University Shenzhen Graduate School', 'Harbin Institute of Technology, China', 'Harbin Institute of Technology (Shenzhen)']","['CV: Medical and Biological Imaging', 'ML: Multi-Instance/Multi-View Learning']","Shao, Z., Chen, Y., Bian, H., Zhang, J., Liu, G., & Zhang, Y. (2023). HVTSurv: Hierarchical Vision Transformer for Patient-Level Survival Prediction from Whole Slide Image. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2209-2217. https://doi.org/10.1609/aaai.v37i2.25315","Abstract 					Survival prediction based on whole slide images (WSIs) is a challenging task for patient-level multiple instance learning (MIL). Due to the vast amount of data for a patient (one or multiple gigapixels WSIs) and the irregularly shaped property of WSI, it is difficult to fully explore spatial, contextual, and hierarchical interaction in the patient-level bag. Many studies adopt random sampling pre-processing strategy and WSI-level aggregation models, which inevitably lose critical prognostic information in the patient-level bag. In this work, we propose a hierarchical vision Transformer framework named HVTSurv, which can encode the local-level relative spatial information, strengthen WSI-level context-aware communication, and establish patient-level hierarchical interaction. Firstly, we design a feature pre-processing strategy, including feature rearrangement and random window masking. Then, we devise three layers to progressively obtain patient-level representation, including a local-level interaction layer adopting Manhattan distance, a WSI-level interaction layer employing spatial shuffle, and a patient-level interaction layer using attention pooling. Moreover, the design of hierarchical network helps the model become more computationally efficient. Finally, we validate HVTSurv with 3,104 patients and 3,752 WSIs across 6 cancer types from The Cancer Genome Atlas (TCGA). The average C-Index is  2.50-11.30% higher than all the prior weakly supervised methods over 6 TCGA datasets. Ablation study and attention visualization further verify the superiority of the proposed HVTSurv. Implementation is available at: https://github.com/szc19990412/HVTSurv.","https://ojs.aaai.org/index.php/AAAI/article/view/25315/25087"
"25316","Channel Regeneration: Improving Channel Utilization for Compact DNNs","['Ankit Sharma', 'Hassan Foroosh']","['University of Central Florida', 'University of Central Florida']","['CV: Applications', 'CV: Object Detection & Categorization', 'CV: Other Foundations of Computer Vision']","Sharma, A., & Foroosh, H. (2023). Channel Regeneration: Improving Channel Utilization for Compact DNNs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2218-2226. https://doi.org/10.1609/aaai.v37i2.25316","Abstract 					Overparameterized deep neural networks have redundant neurons that do not contribute to the network's accuracy. In this paper, we introduce a novel channel regeneration technique that reinvigorates these redundant channels by re-initializing its batch normalization scaling factor gamma. This re-initialization of BN gamma promotes regular weight updates during training. Furthermore, we show that channel regeneration encourages the channels to contribute equally to the learned representation and further boosts the generalization accuracy. We apply our technique at regular intervals of the training cycle to improve channel utilization. The solutions proposed in previous works either raise the total computational cost or increase the model complexity. Integrating the proposed channel regeneration technique into the training methodology of efficient architectures requires minimal effort and comes at no additional cost in size or memory. Extensive experiments on several image classification and semantic segmentation benchmarks demonstrate the effectiveness of applying the channel regeneration technique to compact architectures.","https://ojs.aaai.org/index.php/AAAI/article/view/25316/25088"
"25317","Adaptive Dynamic Filtering Network for Image Denoising","['Hao Shen', 'Zhong-Qiu Zhao', 'Wandi Zhang']","['Hefei University of Technology', 'Hefei University of Technology', 'Hefei University of Technology']","['CV: Low Level & Physics-Based Vision', 'CV: Computational Photography', 'Image & Video Synthesis']","Shen, H., Zhao, Z.-Q., & Zhang, W. (2023). Adaptive Dynamic Filtering Network for Image Denoising. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2227-2235. https://doi.org/10.1609/aaai.v37i2.25317","Abstract 					In image denoising networks, feature scaling is widely used to enlarge the receptive field size and reduce computational costs. This practice, however, also leads to the loss of high-frequency information and fails to consider within-scale characteristics. Recently, dynamic convolution has exhibited powerful capabilities in processing high-frequency information (e.g., edges, corners, textures), but previous works lack sufficient spatial contextual information in filter generation. To alleviate these issues, we propose to employ dynamic convolution to improve the learning of high-frequency and multi-scale features. Specifically, we design a spatially enhanced kernel generation (SEKG) module to improve dynamic convolution, enabling the learning of spatial context information with a very low computational complexity. Based on the SEKG module, we propose a dynamic convolution block (DCB) and a multi-scale dynamic convolution block (MDCB). The former enhances the high-frequency information via dynamic convolution and preserves low-frequency information via skip connections. The latter utilizes shared adaptive dynamic kernels and the idea of dilated convolution to achieve efficient multi-scale feature extraction. The proposed multi-dimension feature integration (MFI) mechanism further fuses the multi-scale features, providing precise and contextually enriched feature representations. Finally, we build an efficient denoising network with the proposed DCB and MDCB, named ADFNet. It achieves better performance with low computational complexity on real-world and synthetic Gaussian noisy datasets. The source code is available at https://github.com/it-hao/ADFNet.","https://ojs.aaai.org/index.php/AAAI/article/view/25317/25089"
"25318","Edge Structure Learning via Low Rank Residuals for Robust Image Classification","['Xiang-Jun Shen', 'Stanley Ebhohimhen Abhadiomhen', 'Yang Yang', 'Zhifeng Liu', 'Sirui Tian']","['Jiangsu University', 'Jiangsu University\nUniversity of Nigeria', 'Jiangsu University', 'School of Computer Science and Communication Engineering, Jiangsu University', 'Nanjing University of Science and Technology']","['CV: Representation Learning for Vision', 'CV: Multi-modal Vision', 'ML: Classification and Regression', 'ML: Dimensionality Reduction/Feature Selection', 'ML: Multi-Instance/Multi-View Learning', 'ML: Multimodal Learning', 'ML: Representation Learning']","Shen, X.-J., Abhadiomhen, S. E., Yang, Y., Liu, Z., & Tian, S. (2023). Edge Structure Learning via Low Rank Residuals for Robust Image Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2236-2244. https://doi.org/10.1609/aaai.v37i2.25318","Abstract 					Traditional low-rank methods overlook residuals as corruptions, but we discovered that low-rank residuals actually keep image edges together with corrupt components. Therefore, filtering out such structural information could hamper the discriminative details in images, especially in heavy corruptions. In order to address this limitation, this paper proposes a novel method named ESL-LRR, which preserves image edges by finding image projections from low-rank residuals. Specifically, our approach is built in a manifold learning framework where residuals are regarded as another view of image data. Edge preserved image projections are then pursued using a dynamic affinity graph regularization to capture the more accurate similarity between residuals while suppressing the influence of corrupt ones. With this adaptive approach, the proposed method can also find image intrinsic low-rank representation, and much discriminative edge preserved projections. As a result, a new classification strategy is introduced, aligning both modalities to enhance accuracy. Experiments are conducted on several benchmark image datasets, including MNIST, LFW, and COIL100. The results show that the proposed method has clear advantages over compared state-of-the-art (SOTA) methods, such as Low-Rank Embedding (LRE), Low-Rank Preserving Projection via Graph Regularized Reconstruction (LRPP_GRR), and Feature Selective Projection (FSP) with more than 2% improvement, particularly in corrupted cases.","https://ojs.aaai.org/index.php/AAAI/article/view/25318/25090"
"25319","Memory-Oriented Structural Pruning for Efficient Image Restoration","['Xiangsheng Shi', 'Xuefei Ning', 'Lidong Guo', 'Tianchen Zhao', 'Enshu Liu', 'Yi Cai', 'Yuhan Dong', 'Huazhong Yang', 'Yu Wang']","['Department of Electronic Engineering, Tsinghua University\nShenzhen International Graduate School, Tsinghua University', 'Department of Electronic Engineering, Tsinghua University', 'School of Materials Science and Engineering, Tsinghua University', 'Department of Electronic Engineering, Tsinghua University', 'Department of Electronic Engineering, Tsinghua University', 'Department of Electronic Engineering, Tsinghua University', 'Shenzhen International Graduate School, Tsinghua University', 'Department of Electronic Engineering, Tsinghua University', 'Department of Electronic Engineering, Tsinghua University']","['CV: Low Level & Physics-Based Vision', 'ML: Learning on the Edge & Model Compression']","Shi, X., Ning, X., Guo, L., Zhao, T., Liu, E., Cai, Y., Dong, Y., Yang, H., & Wang, Y. (2023). Memory-Oriented Structural Pruning for Efficient Image Restoration. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2245-2253. https://doi.org/10.1609/aaai.v37i2.25319","Abstract 					Deep learning (DL) based methods have significantly pushed forward the state-of-the-art for image restoration (IR) task. Nevertheless, DL-based IR models are highly computation- and memory-intensive. The surging demands for processing higher-resolution images and multi-task paralleling in practical mobile usage further add to their computation and memory burdens. In this paper, we reveal the overlooked memory redundancy of the IR models and propose a Memory-Oriented Structural Pruning (MOSP) method. To properly compress the long-range skip connections (a major source of the memory burden), we introduce a compactor module onto each skip connection to decouple the pruning of the skip connections and the main branch. MOSP progressively prunes the original model layers and the compactors to cut down the peak memory while maintaining high IR quality. Experiments on real image denoising, image super-resolution and low-light image enhancement show that MOSP can yield models with higher memory efficiency while better preserving performance compared with baseline pruning methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25319/25091"
"25320","YOLOV: Making Still Image Object Detectors Great at Video Object Detection","['Yuheng Shi', 'Naiyan Wang', 'Xiaojie Guo']","['Tianjin University', 'TuSimple', 'Tianjin University']","['CV: Object Detection & Categorization', 'CV: Motion & Tracking', 'CV: Video Understanding & Activity Analysis']","Shi, Y., Wang, N., & Guo, X. (2023). YOLOV: Making Still Image Object Detectors Great at Video Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2254-2262. https://doi.org/10.1609/aaai.v37i2.25320","Abstract 					Video object detection (VID) is challenging because of the high variation of object appearance as well as the diverse deterioration in some frames. On the positive side, the detection in a certain frame of a video, compared with that in a still image, can draw support from other frames. Hence, how to aggregate features across different frames is pivotal to VID problem. Most of existing aggregation algorithms are customized for two-stage detectors. However, these detectors are usually computationally expensive due to their two-stage nature. This work proposes a simple yet effective strategy to address the above concerns, which costs marginal overheads with significant gains in accuracy. Concretely, different from traditional two-stage pipeline, we select important regions after the one-stage detection to avoid processing massive low-quality candidates. Besides, we evaluate the relationship between a target frame and reference frames to guide the aggregation. We conduct extensive experiments and ablation studies to verify the efficacy of our design, and reveal its superiority over other state-of-the-art VID approaches in both effectiveness and efficiency. Our YOLOX-based model can achieve promising performance (e.g., 87.5% AP50 at over 30 FPS on the ImageNet VID dataset on a single 2080Ti GPU), making it attractive for large-scale or real-time applications. The implementation is simple, we have made the demo codes and models available at https://github.com/YuHengsss/YOLOV.","https://ojs.aaai.org/index.php/AAAI/article/view/25320/25092"
"25321","FeedFormer: Revisiting Transformer Decoder for Efficient Semantic Segmentation","['Jae-hun Shim', 'Hyunwoo Yu', 'Kyeongbo Kong', 'Suk-Ju Kang']","['Sogang University', 'Sogang university', 'Pukyong National University', 'Sogang University']","['CV: Segmentation', 'CV: Vision for Robotics & Autonomous Driving']","Shim, J.- hun, Yu, H., Kong, K., & Kang, S.-J. (2023). FeedFormer: Revisiting Transformer Decoder for Efficient Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2263-2271. https://doi.org/10.1609/aaai.v37i2.25321","Abstract 					With the success of Vision Transformer (ViT) in image classification, its variants have yielded great success in many downstream vision tasks. Among those, the semantic segmentation task has also benefited greatly from the advance of ViT variants. However, most studies of the transformer for semantic segmentation only focus on designing efficient transformer encoders, rarely giving attention to designing the decoder. Several studies make attempts in using the transformer decoder as the segmentation decoder with class-wise learnable query. Instead, we aim to directly use the encoder features as the queries. This paper proposes the Feature Enhancing Decoder transFormer (FeedFormer) that enhances structural information using the transformer decoder. Our goal is to decode the high-level encoder features using the lowest-level encoder feature. We do this by formulating high-level features as queries, and the lowest-level feature as the key and value. This enhances the high-level features by collecting the structural information from the lowest-level feature. Additionally, we use a simple reformation trick of pushing the encoder blocks to take the place of the existing self-attention module of the decoder to improve efficiency. We show the superiority of our decoder with various light-weight transformer-based decoders on popular semantic segmentation datasets. Despite the minute computation, our model has achieved state-of-the-art performance in the performance computation trade-off. Our model FeedFormer-B0 surpasses SegFormer-B0 with 1.8% higher mIoU and 7.1% less computation on ADE20K, and 1.7% higher mIoU and 14.4% less computation on Cityscapes, respectively. Code will be released at: https://github.com/jhshim1995/FeedFormer.","https://ojs.aaai.org/index.php/AAAI/article/view/25321/25093"
"25322","Task-Specific Scene Structure Representations","['Jisu Shin', 'Seunghyun Shin', 'Hae-Gon Jeon']","['GIST', 'GIST', 'GIST']","['CV: Low Level & Physics-Based Vision', 'CV: Scene Analysis & Understanding']","Shin, J., Shin, S., & Jeon, H.-G. (2023). Task-Specific Scene Structure Representations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2272-2281. https://doi.org/10.1609/aaai.v37i2.25322","Abstract 					Understanding the informative structures of scenes is essential for low-level vision tasks. Unfortunately, it is difficult to obtain a concrete visual definition of the informative structures because influences of visual features are task-specific. In this paper, we propose a single general neural network architecture for extracting task-specific structure guidance for scenes. To do this, we first analyze traditional spectral clustering methods, which computes a set of eigenvectors to model a segmented graph forming small compact structures on image domains. We then unfold the traditional graph-partitioning problem into a learnable network, named Scene Structure Guidance Network (SSGNet), to represent the task-specific informative structures. The SSGNet yields a set of coefficients of eigenvectors that produces explicit feature representations of image structures. In addition, our SSGNet is light-weight (56K parameters), and can be used as a plug-and-play module for off-the-shelf architectures. We optimize the SSGNet without any supervision by proposing two novel training losses that enforce task-specific scene structure generation during training. Our main contribution is to show that such a simple network can achieve state-of-the-art results for several low-level vision applications including joint upsampling and image denoising. We also demonstrate that our SSGNet generalizes well on unseen datasets, compared to existing methods which use structural embedding frameworks. Our source codes are available at https://github.com/jsshin98/SSGNet.","https://ojs.aaai.org/index.php/AAAI/article/view/25322/25094"
"25323","Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion","['Jungwook Shin', 'Jaeill Kim', 'Kyungeun Lee', 'Hyunghun Cho', 'Wonjong Rhee']","['Seoul National University', 'Seoul National University', 'Seoul National University', 'Seoul National University', 'Seoul National University']","['CV: Vision for Robotics & Autonomous Driving', 'CV: 3D Computer Vision', 'CV: Object Detection & Categorization']","Shin, J., Kim, J., Lee, K., Cho, H., & Rhee, W. (2023). Diversified and Realistic 3D Augmentation via Iterative Construction, Random Placement, and HPR Occlusion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2282-2291. https://doi.org/10.1609/aaai.v37i2.25323","Abstract 					In autonomous driving, data augmentation is commonly used for improving 3D object detection. The most basic methods include insertion of copied objects and rotation and scaling of the entire training frame. Numerous variants have been developed as well. The existing methods, however, are considerably limited when compared to the variety of the real world possibilities. In this work, we develop a diversified and realistic augmentation method that can flexibly construct a whole-body object, freely locate and rotate the object, and apply self-occlusion and external-occlusion accordingly. To improve the diversity of the whole-body object construction, we develop an iterative method that stochastically combines multiple objects observed from the real world into a single object. Unlike the existing augmentation methods, the constructed objects can be randomly located and rotated in the training frame because proper occlusions can be reflected to the whole-body objects in the final step. Finally, proper self-occlusion at each local object level and external-occlusion at the global frame level are applied using the Hidden Point Removal (HPR) algorithm that is computationally efficient. HPR is also used for adaptively controlling the point density of each object according to the object's distance from the LiDAR. Experiment results show that the proposed DR.CPO algorithm is data-efficient and model-agnostic without incurring any computational overhead. Also, DR.CPO can improve mAP performance by 2.08% when compared to the best 3D detection result known for KITTI dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/25323/25095"
"25324","SHUNIT: Style Harmonization for Unpaired Image-to-Image Translation","['Seokbeom Song', 'Suhyeon Lee', 'Hongje Seong', 'Kyoungwon Min', 'Euntai Kim']","['Yonsei University', 'Yonsei University', 'Yonsei University', 'Korea Electronics Technology Institute', 'Yonsei University']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Applications']","Song, S., Lee, S., Seong, H., Min, K., & Kim, E. (2023). SHUNIT: Style Harmonization for Unpaired Image-to-Image Translation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2292-2302. https://doi.org/10.1609/aaai.v37i2.25324","Abstract 					We propose a novel solution for unpaired image-to-image (I2I) translation. To translate complex images with a wide range of objects to a different domain, recent approaches often use the object annotations to perform per-class source-to-target style mapping. However, there remains a point for us to exploit in the I2I. An object in each class consists of multiple components, and all the sub-object components have different characteristics. For example, a car in CAR class consists of a car body, tires, windows and head and tail lamps, etc., and they should be handled separately for realistic I2I translation. The simplest solution to the problem will be to use more detailed annotations with sub-object component annotations than the simple object annotations, but it is not possible. The key idea of this paper is to bypass the sub-object component annotations by leveraging the original style of the input image because the original style will include the information about the characteristics of the sub-object components. Specifically, for each pixel, we use not only the per-class style gap between the source and target domains but also the pixel’s original style to determine the target style of a pixel. To this end, we present Style Harmonization for unpaired I2I translation (SHUNIT). Our SHUNIT generates a new style by harmonizing the target domain style retrieved from a class memory and an original source image style. Instead of direct source-to-target style mapping, we aim for source and target styles harmonization. We validate our method with extensive experiments and achieve state-of-the-art performance on the latest benchmark sets. The source code is available online: https://github.com/bluejangbaljang/SHUNIT.","https://ojs.aaai.org/index.php/AAAI/article/view/25324/25096"
"25325","Siamese-Discriminant Deep Reinforcement Learning for Solving Jigsaw Puzzles with Large Eroded Gaps","['Xingke Song', 'Jiahuan Jin', 'Chenglin Yao', 'Shihe Wang', 'Jianfeng Ren', 'Ruibin Bai']","['University of Nottingham Ningbo China', 'University of Nottingham Ningbo China', 'University of Nottingham Ningbo China', 'University of Nottingham Ningbo China', 'University of Nottingham Ningbo China', 'University of Nottingham Ningbo China']","['CV: Visual Reasoning & Symbolic Representations', 'CV: Learning & Optimization for CV', 'ML: Deep Neural Network Algorithms', 'SO: Other Foundations of Search & Optimization']","Song, X., Jin, J., Yao, C., Wang, S., Ren, J., & Bai, R. (2023). Siamese-Discriminant Deep Reinforcement Learning for Solving Jigsaw Puzzles with Large Eroded Gaps. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2303-2311. https://doi.org/10.1609/aaai.v37i2.25325","Abstract 					Jigsaw puzzle solving has recently become an emerging research area. The developed techniques have been widely used in applications beyond puzzle solving. This paper focuses on solving Jigsaw Puzzles with Large Eroded Gaps (JPwLEG). We formulate the puzzle reassembly as a combinatorial optimization problem and propose a Siamese-Discriminant Deep Reinforcement Learning (SD2RL) to solve it. A Deep Q-network (DQN) is designed to visually understand the puzzles, which consists of two sets of Siamese Discriminant Networks, one set to perceive the pairwise relations between vertical neighbors and another set for horizontal neighbors. The proposed DQN considers not only the evidence from the incumbent fragment but also the support from its four neighbors. The DQN is trained using replay experience with carefully designed rewards to guide the search for a sequence of fragment swaps to reach the correct puzzle solution. Two JPwLEG datasets are constructed to evaluate the proposed method, and the experimental results show that the proposed SD2RL significantly outperforms state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25325/25097"
"25326","CLIPVG: Text-Guided Image Manipulation Using Differentiable Vector Graphics","['Yiren Song', 'Xuning Shao', 'Kang Chen', 'Weidong Zhang', 'Zhongliang Jing', 'Minzhe Li']","['Shanghai Jiao Tong University\nNetease Games AI Lab', 'Netease Games AI Lab', 'NetEase Games AI Lab', 'Netease Games AI Lab', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['CV: Applications', 'CV: Language and Vision', 'ML: Unsupervised & Self-Supervised Learning']","Song, Y., Shao, X., Chen, K., Zhang, W., Jing, Z., & Li, M. (2023). CLIPVG: Text-Guided Image Manipulation Using Differentiable Vector Graphics. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2312-2320. https://doi.org/10.1609/aaai.v37i2.25326","Abstract 					Considerable progress has recently been made in leveraging CLIP (Contrastive Language-Image Pre-Training) models for text-guided image manipulation. However, all existing works rely on additional generative models to ensure the quality of results, because CLIP alone cannot provide enough guidance information for fine-scale pixel-level changes. In this paper, we introduce CLIPVG, a text-guided image manipulation framework using differentiable vector graphics,  which is also the first CLIP-based general image manipulation framework that does not require any additional generative models. We demonstrate that CLIPVG can not only achieve state-of-art performance in both semantic correctness and synthesis quality, but also is flexible enough to support various applications far beyond the capability of all existing methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25326/25098"
"25327","Compact Transformer Tracker with Correlative Masked Modeling","['Zikai Song', 'Run Luo', 'Junqing Yu', 'Yi-Ping Phoebe Chen', 'Wei Yang']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science & Technology', 'La Trobe University', 'Huazhong University of Science and Technology']","['CV: Motion & Tracking', 'CV: Applications', 'CV: Language and Vision', 'CV: Learning & Optimization for CV', 'CV: Other Foundations of Computer Vision']","Song, Z., Luo, R., Yu, J., Chen, Y.-P. P., & Yang, W. (2023). Compact Transformer Tracker with Correlative Masked Modeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2321-2329. https://doi.org/10.1609/aaai.v37i2.25327","Abstract 					Transformer framework has been showing superior performances in visual object tracking for its great strength in information aggregation across the template and search image with the well-known attention mechanism. Most recent advances focus on exploring attention mechanism variants for better information aggregation. We find these schemes are equivalent to or even just a subset of the basic self-attention mechanism. In this paper, we prove that the vanilla self-attention structure is sufficient for information aggregation, and structural adaption is unnecessary. The key is not the attention structure,  but how to extract the discriminative feature for tracking and enhance the communication between the target and search image. Based on this finding, we adopt the basic vision transformer (ViT) architecture as our main tracker and concatenate the template and search image for feature embedding. To guide the encoder to capture the invariant feature for tracking, we attach a lightweight correlative masked decoder which reconstructs the original template and search image from the corresponding masked tokens. The correlative masked decoder serves as a plugin for the compact transformer tracker and is skipped in inference. Our compact tracker uses the most simple structure which only consists of a ViT backbone and a box head, and can run at 40 fps. Extensive experiments show the proposed compact transform tracker outperforms existing approaches, including advanced attention variants, and demonstrates the sufficiency of self-attention in tracking tasks. Our method achieves state-of-the-art performance on five challenging datasets, along with the VOT2020, UAV123, LaSOT, TrackingNet, and GOT-10k benchmarks. Our project is available at https://github.com/HUSTDML/CTTrack.","https://ojs.aaai.org/index.php/AAAI/article/view/25327/25099"
"25328","Text-DIAE: A Self-Supervised Degradation Invariant Autoencoder for Text Recognition and Document Enhancement","['Mohamed Ali Souibgui', 'Sanket Biswas', 'Andres Mafla', 'Ali Furkan Biten', 'Alicia Fornés', 'Yousri Kessentini', 'Josep Lladós', 'Lluis Gomez', 'Dimosthenis Karatzas']","['Computer Vision Center, Universitat Autònoma de Barcelona, Spain', 'Computer Vision Center, Universitat Autònoma de Barcelona, Spain', 'Computer Vision Center, Universitat Autònoma de Barcelona, Spain', 'Computer Vision Center, Universitat Autònoma de Barcelona, Spain', 'Computer Vision Center, Universitat Autònoma de Barcelona, Spain', 'Digital Research Center of Sfax, SM@RTS Laboratory, Sfax, Tunisia', 'Computer Vision Center, Universitat Autònoma de Barcelona, Spain', 'Computer Vision Center, Universitat Autònoma de Barcelona, Spain', 'Computer Vision Center, Universitat Autònoma de Barcelona, Spain']","['CV: Representation Learning for Vision', 'CV: Applications', 'CV: Language and Vision', 'ML: Unsupervised & Self-Supervised Learning']","Souibgui, M. A., Biswas, S., Mafla, A., Biten, A. F., Fornés, A., Kessentini, Y., Lladós, J., Gomez, L., & Karatzas, D. (2023). Text-DIAE: A Self-Supervised Degradation Invariant Autoencoder for Text Recognition and Document Enhancement. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2330-2338. https://doi.org/10.1609/aaai.v37i2.25328","Abstract 					In this paper, we propose  a Text-Degradation Invariant Auto Encoder (Text-DIAE), a self-supervised model designed to tackle two tasks, text recognition (handwritten or scene-text) and document image enhancement. We start by employing a transformer-based architecture that incorporates three pretext tasks as learning objectives to be optimized during pre-training without the usage of labelled data. Each of the pretext objectives is specifically tailored for the final downstream tasks. We conduct several ablation experiments that confirm the design choice of the selected pretext tasks. Importantly, the proposed model does not exhibit limitations of previous state-of-the-art methods based on contrastive losses, while at the same time requiring substantially fewer data samples to converge. Finally, we demonstrate that our method surpasses the state-of-the-art in existing supervised and self-supervised settings in handwritten and scene text recognition and document image enhancement. Our code and trained models will be made publicly available at https://github.com/dali92002/SSL-OCR","https://ojs.aaai.org/index.php/AAAI/article/view/25328/25100"
"25329","PUPS: Point Cloud Unified Panoptic Segmentation","['Shihao Su', 'Jianyun Xu', 'Huanyu Wang', 'Zhenwei Miao', 'Xin Zhan', 'Dayang Hao', 'Xi Li']","['Zhejiang University', 'DAMO Academy, Alibaba Group', 'Zhejiang University', 'DAMO Academy, Alibaba Group', 'DAMO Academy, Alibaba Group', 'DAMO Academy, Alibaba Group', 'Zhejiang University\nShanghai Institute for Advanced Study, Zhejiang University\nShanghai AI Laboratory']","['CV: Vision for Robotics & Autonomous Driving', 'CV: Segmentation']","Su, S., Xu, J., Wang, H., Miao, Z., Zhan, X., Hao, D., & Li, X. (2023). PUPS: Point Cloud Unified Panoptic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2339-2347. https://doi.org/10.1609/aaai.v37i2.25329","Abstract 					Point cloud panoptic segmentation is a challenging task that seeks a holistic solution for both semantic and instance segmentation to predict groupings of coherent points. Previous approaches treat semantic and instance segmentation as surrogate tasks, and they either use clustering methods or bounding boxes to gather instance groupings with costly computation and hand-craft designs in the instance segmentation task. In this paper, we propose a simple but effective point cloud unified panoptic segmentation (PUPS) framework, which use a set of point-level classifiers to directly predict semantic and instance groupings in an end-to-end manner. To realize PUPS, we introduce bipartite matching to our training pipeline so that our classifiers are able to exclusively predict groupings of instances, getting rid of hand-crafted designs, e.g. anchors and Non-Maximum Suppression (NMS). In order to achieve better grouping results, we utilize a transformer decoder to iteratively refine the point classifiers and develop a context-aware CutMix augmentation to overcome the class imbalance problem. As a result, PUPS achieves 1st place on the leader board of SemanticKITTI panoptic segmentation task and state-of-the-art results on nuScenes.","https://ojs.aaai.org/index.php/AAAI/article/view/25329/25101"
"25330","Efficient Edge-Preserving Multi-View Stereo Network for Depth Estimation","['Wanjuan Su', 'Wenbing Tao']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology']","['CV: 3D Computer Vision']","Su, W., & Tao, W. (2023). Efficient Edge-Preserving Multi-View Stereo Network for Depth Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2348-2356. https://doi.org/10.1609/aaai.v37i2.25330","Abstract 					Over the years, learning-based multi-view stereo methods have achieved great success based on their coarse-to-fine depth estimation frameworks.  However, 3D CNN-based cost volume regularization inevitably leads to over-smoothing problems at object boundaries due to its smooth properties. Moreover, discrete and sparse depth hypothesis sampling exacerbates the difficulty in recovering the depth of thin structures and object boundaries. To this end, we present an Efficient edge-Preserving multi-view stereo Network (EPNet) for practical depth estimation. To keep delicate estimation at details, a Hierarchical Edge-Preserving Residual learning (HEPR) module is proposed to progressively rectify the upsampling errors and help refine multi-scale depth estimation. After that, a Cross-view Photometric Consistency (CPC) is proposed to enhance the gradient flow for detailed structures, which further boosts the estimation accuracy. Last, we design a lightweight cascade framework and inject the above two strategies into it to achieve better efficiency and performance trade-offs. Extensive experiments show that our method achieves state-of-the-art performance with fast inference speed and low memory usage. Notably, our method tops the first place on challenging Tanks and Temples advanced dataset and ETH3D high-res benchmark among all published learning-based methods. Code will be available at https://github.com/susuwj/EPNet.","https://ojs.aaai.org/index.php/AAAI/article/view/25330/25102"
"25331","Referring Expression Comprehension Using Language Adaptive Inference","['Wei Su', 'Peihan Miao', 'Huanzhang Dou', 'Yongjian Fu', 'Xi Li']","['College of Computer Science & Technology, Zhejiang University', 'School of Software Technology, Zhejiang University', 'College of Computer Science & Technology, Zhejiang University', 'College of Computer Science & Technology, Zhejiang University', 'College of Computer Science & Technology, Zhejiang University\nShanghai Institute for Advanced Study, Zhejiang University\nShanghai AI Laboratory']","['CV: Language and Vision', 'CV: Multi-modal Vision']","Su, W., Miao, P., Dou, H., Fu, Y., & Li, X. (2023). Referring Expression Comprehension Using Language Adaptive Inference. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2357-2365. https://doi.org/10.1609/aaai.v37i2.25331","Abstract 					Different from universal object detection, referring expression comprehension (REC) aims to locate specific objects referred to by natural language expressions. The expression provides high-level concepts of relevant visual and contextual patterns, which vary significantly with different expressions and account for only a few of those encoded in the REC model. This leads us to a question: do we really need the entire network with a fixed structure for various referring expressions? Ideally, given an expression, only expression-relevant components of the REC model are required. These components should be small in number as each expression only contains very few visual and contextual clues. This paper explores the adaptation between expressions and REC models for dynamic inference. Concretely, we propose a neat yet efficient framework named Language Adaptive Dynamic Subnets (LADS), which can extract language-adaptive subnets from the REC model conditioned on the referring expressions. By using the compact subnet, the inference can be more economical and efficient. Extensive experiments on RefCOCO, RefCOCO+, RefCOCOg, and Referit show that the proposed method achieves faster inference speed and higher accuracy against state-of-the-art approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/25331/25103"
"25332","Rethinking Data Augmentation for Single-Source Domain Generalization in Medical Image Segmentation","['Zixian Su', 'Kai Yao', 'Xi Yang', 'Kaizhu Huang', 'Qiufeng Wang', 'Jie Sun']","[""University of Liverpool, Liverpool, the United Kingdom\nXi'an Jiaotong-Liverpool University, Suzhou, China"", ""University of Liverpool, Liverpool, the United Kingdom\nXi'an Jiaotong-Liverpool University, Suzhou, China"", 'Xi’an Jiaotong Liverpool University, Suzhou, China', 'Duke Kunshan University, Kunshan, China', ""Xi'an Jiaotong-Liverpool University, Suzhou, China"", ""Xi'an Jiaotong-Liverpool University, Suzhou, China""]","['CV: Medical and Biological Imaging']","Su, Z., Yao, K., Yang, X., Huang, K., Wang, Q., & Sun, J. (2023). Rethinking Data Augmentation for Single-Source Domain Generalization in Medical Image Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2366-2374. https://doi.org/10.1609/aaai.v37i2.25332","Abstract 					Single-source domain generalization (SDG) in medical image segmentation is a challenging yet essential task as domain shifts are quite common among clinical image datasets. Previous attempts most conduct global-only/random augmentation.  Their augmented samples are usually insufficient in diversity and informativeness, thus failing to cover the possible target domain distribution. In this paper, we rethink the data augmentation strategy for SDG in medical image segmentation. Motivated by the class-level representation invariance and style mutability of medical images, we hypothesize that  unseen target data can be sampled from a linear combination of C (the class number) random variables, where each variable follows a location-scale distribution at the class level. Accordingly, data augmented can be readily made by sampling the random variables through a general form. On the empirical front, we implement such strategy with constrained Bezier transformation on both  global and  local (i.e. class-level) regions, which can largely increase the augmentation diversity.  A Saliency-balancing Fusion mechanism is further proposed to enrich the informativeness by engaging the gradient information, guiding augmentation with proper orientation and magnitude. As an important contribution, we prove theoretically that our proposed augmentation can lead to an upper bound of the generalization risk on the unseen  target domain, thus confirming our hypothesis. Combining the two strategies, our Saliency-balancing Location-scale Augmentation (SLAug) exceeds the state-of-the-art works by a large margin in two challenging SDG tasks. Code is available at https://github.com/Kaiseem/SLAug.","https://ojs.aaai.org/index.php/AAAI/article/view/25332/25104"
"25333","Hybrid Pixel-Unshuffled Network for Lightweight Image Super-resolution","['Bin Sun', 'Yulun Zhang', 'Songyao Jiang', 'Yun Fu']","['Northeastern University\nAInnovation Labs Inc.', 'ETH Zurich', 'Northeastern University', 'Northeastern University\nAInnovation Labs Inc.']","['CV: Low Level & Physics-Based Vision']","Sun, B., Zhang, Y., Jiang, S., & Fu, Y. (2023). Hybrid Pixel-Unshuffled Network for Lightweight Image Super-resolution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2375-2383. https://doi.org/10.1609/aaai.v37i2.25333","Abstract 					Convolutional neural network (CNN) has achieved great success on image super-resolution (SR). However, most deep CNN-based SR models take massive computations to obtain high performance. Downsampling features for multi-resolution fusion is an efficient and effective way to improve the performance of visual recognition. Still, it is counter-intuitive in the SR task, which needs to project a low-resolution input to high-resolution. In this paper, we propose a novel Hybrid Pixel-Unshuffled Network (HPUN) by introducing an efficient and effective downsampling module into the SR task. The network contains pixel-unshuffled downsampling and Self-Residual Depthwise Separable Convolutions. Specifically, we utilize pixel-unshuffle operation to downsample the input features and use grouped convolution to reduce the channels. Besides, we enhance the depthwise convolution's performance by adding the input feature to its output. The comparison findings demonstrate that, with fewer parameters and computational costs, our HPUN achieves and surpasses the state-of-the-art performance on SISR. All results are provided in the github https://github.com/Sun1992/HPUN.","https://ojs.aaai.org/index.php/AAAI/article/view/25333/25105"
"25334","Learning Event-Relevant Factors for Video Anomaly Detection","['Che Sun', 'Chenrui Shi', 'Yunde Jia', 'Yuwei Wu']","['Beijing Key Laboratory of Intelligent Information Technology, School of Computer Science & Technology, Beijing Institute of Technology, China', 'Beijing Key Laboratory of Intelligent Information Technology, School of Computer Science & Technology, Beijing Institute of Technology, China', 'Guangdong Laboratory of Machine Perception and Intelligent Computing, Shenzhen MSU-BIT University, China\nBeijing Key Laboratory of Intelligent Information Technology, School of Computer Science & Technology, Beijing Institute of Technology, China', 'Beijing Key Laboratory of Intelligent Information Technology, School of Computer Science & Technology, Beijing Institute of Technology, China\nGuangdong Laboratory of Machine Perception and Intelligent Computing, Shenzhen MSU-BIT University, China']","['CV: Video Understanding & Activity Analysis', 'CV: Applications']","Sun, C., Shi, C., Jia, Y., & Wu, Y. (2023). Learning Event-Relevant Factors for Video Anomaly Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2384-2392. https://doi.org/10.1609/aaai.v37i2.25334","Abstract 					Most video anomaly detection methods discriminate events that deviate from normal patterns as anomalies. However, these methods are prone to interferences from event-irrelevant factors,  such as background textures and object scale variations,  incurring an increased false detection rate. In this paper, we propose to explicitly learn event-relevant factors to eliminate the interferences from event-irrelevant factors on anomaly predictions.  To this end, we introduce a causal generative model to separate the event-relevant factors and event-irrelevant ones in videos, and learn the prototypes of event-relevant factors in a memory augmentation module.   We design a causal objective function to optimize the causal generative model and develop a counterfactual learning strategy to guide anomaly predictions, which increases the influence of the event-relevant factors. The extensive experiments show the effectiveness of our method for video anomaly detection.","https://ojs.aaai.org/index.php/AAAI/article/view/25334/25106"
"25335","Superpoint Transformer for 3D Scene Instance Segmentation","['Jiahao Sun', 'Chunmei Qing', 'Junpeng Tan', 'Xiangmin Xu']","['South China University of Technology', 'South China University of Technology', 'South China University of Technology', 'South China University of Technology']","['CV: 3D Computer Vision', 'CV: Segmentation']","Sun, J., Qing, C., Tan, J., & Xu, X. (2023). Superpoint Transformer for 3D Scene Instance Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2393-2401. https://doi.org/10.1609/aaai.v37i2.25335","Abstract 					Most existing methods realize 3D instance segmentation by extending those models used for 3D object detection or 3D semantic segmentation. However, these non-straightforward methods suffer from two drawbacks: 1) Imprecise bounding boxes or unsatisfactory semantic predictions limit the performance of the overall 3D instance segmentation framework. 2) Existing method requires a time-consuming intermediate step of aggregation. To address these issues, this paper proposes a novel end-to-end 3D instance segmentation method based on Superpoint Transformer, named as SPFormer. It groups potential features from point clouds into superpoints, and directly predicts instances through query vectors without relying on the results of object detection or semantic segmentation. The key step in this framework is a novel query decoder with transformers that can capture the instance information through the superpoint cross-attention mechanism and generate the superpoint masks of the instances. Through bipartite matching based on superpoint masks, SPFormer can implement the network training without the intermediate aggregation step, which accelerates the network. Extensive experiments on ScanNetv2 and S3DIS benchmarks verify that our method is concise yet efficient. Notably, SPFormer exceeds compared state-of-the-art methods by 4.3% on ScanNetv2 hidden test set in terms of mAP and keeps fast inference speed (247ms per frame) simultaneously. Code is available at https://github.com/sunjiahao1999/SPFormer.","https://ojs.aaai.org/index.php/AAAI/article/view/25335/25107"
"25336","Asynchronous Event Processing with Local-Shift Graph Convolutional Network","['Linhui Sun', 'Yifan Zhang', 'Jian Cheng', 'Hanqing Lu']","['Institute of Automation, Chinese Academy of Sciences, 100190, Beijing, China\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences, 100049, Beijing, China\nAIRIA, 211135, Nanjing, China', 'Institute of Automation, Chinese Academy of Sciences, 100190, Beijing, China\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences, 100049, Beijing, China\nAIRIA, 211135, Nanjing, China', 'Institute of Automation, Chinese Academy of Sciences, 100190, Beijing, China\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences, 100049, Beijing, China\nAIRIA, 211135, Nanjing, China', 'Institute of Automation, Chinese Academy of Sciences, 100190, Beijing, China\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences, 100049, Beijing, China']","['CV: Object Detection & Categorization']","Sun, L., Zhang, Y., Cheng, J., & Lu, H. (2023). Asynchronous Event Processing with Local-Shift Graph Convolutional Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2402-2410. https://doi.org/10.1609/aaai.v37i2.25336","Abstract 					Event cameras are bio-inspired sensors that produce sparse and asynchronous event streams instead of frame-based images at a high-rate. Recent works utilizing graph convolutional networks (GCNs) have achieved remarkable performance in recognition tasks, which model event stream as spatio-temporal graph. However, the computational mechanism of graph convolution introduces redundant computation when aggregating neighbor features, which limits the low-latency nature of the events. And they perform a synchronous inference process, which can not achieve a fast response to the asynchronous event signals. This paper proposes a local-shift graph convolutional network (LSNet), which utilizes a novel local-shift operation equipped with a local spatio-temporal attention component to achieve efficient and adaptive aggregation of neighbor features. To improve the efficiency of pooling operation in feature extraction, we design a node-importance based parallel pooling method (NIPooling) for sparse and low-latency event data. Based on the calculated importance of each node, NIPooling can efficiently obtain uniform sampling results in parallel, which retains the diversity of event streams. Furthermore, for achieving a fast response to asynchronous event signals, an asynchronous event processing procedure is proposed to restrict the network nodes which need to recompute activations only to those affected by the new arrival event. Experimental results show that the computational cost can be reduced by nearly 9 times through using local-shift operation and the proposed asynchronous procedure can further improve the inference efficiency, while achieving state-of-the-art performance on gesture recognition and object recognition.","https://ojs.aaai.org/index.php/AAAI/article/view/25336/25108"
"25337","DENet: Disentangled Embedding Network for Visible Watermark Removal","['Ruizhou Sun', 'Yukun Su', 'Qingyao Wu']","['South China University of Technology\nKey Laboratory of Big Data and Intelligent Robot, Ministry of Education', 'South China University of Technology\nPazhou Lab, Guangzhou, China', 'South China University of Technology\nPeng Cheng Laboratory, China']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Applications', 'CV: Learning & Optimization for CV', 'CV: Representation Learning for Vision']","Sun, R., Su, Y., & Wu, Q. (2023). DENet: Disentangled Embedding Network for Visible Watermark Removal. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2411-2419. https://doi.org/10.1609/aaai.v37i2.25337","Abstract 					Adding visible watermark into image is a common copyright protection method of medias. Meanwhile, public research on watermark removal can be utilized as an adversarial technology to help the further development of watermarking.  Existing watermark removal methods mainly adopt multi-task learning networks, which locate the watermark and restore the background simultaneously. However, these approaches view the task as an image-to-image reconstruction problem, where they only impose supervision after the final output, making the high-level semantic features shared between different tasks.  To this end, inspired by the two-stage coarse-refinement network, we propose a novel contrastive learning mechanism to disentangle the high-level embedding semantic information of the images and watermarks, driving the respective network branch more oriented. Specifically, the proposed mechanism is leveraged for watermark image decomposition, which aims to decouple the clean image and watermark hints in the high-level embedding space. This can guarantee the learning representation of the restored image enjoy more task-specific cues. In addition, we introduce a self-attention-based enhancement module, which promotes the network's ability to capture semantic information among different regions, leading to further improvement on the contrastive learning mechanism.  To validate the effectiveness of our proposed method, extensive experiments are conducted on different challenging benchmarks. Experimental evaluations show that our approach can achieve state-of-the-art performance and yield high-quality images. The code is available at: https://github.com/lianchengmingjue/DENet.","https://ojs.aaai.org/index.php/AAAI/article/view/25337/25109"
"25338","Deep Manifold Attack on Point Clouds via Parameter Plane Stretching","['Keke Tang', 'Jianpeng Wu', 'Weilong Peng', 'Yawen Shi', 'Peng Song', 'Zhaoquan Gu', 'Zhihong Tian', 'Wenping Wang']","['Guangzhou University', 'Guangzhou University', 'Guangzhou University', 'Guangzhou University', 'Singapore University of Technology and Design', 'Harbin Institute of Technology (Shenzhen)\nPeng Cheng Laboratory', 'Guangzhou University', 'Texas A&M University']","['CV: Adversarial Attacks & Robustness', 'CV: 3D Computer Vision', 'ML: Adversarial Learning & Robustness']","Tang, K., Wu, J., Peng, W., Shi, Y., Song, P., Gu, Z., Tian, Z., & Wang, W. (2023). Deep Manifold Attack on Point Clouds via Parameter Plane Stretching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2420-2428. https://doi.org/10.1609/aaai.v37i2.25338","Abstract 					Adversarial attack on point clouds plays a vital role in evaluating and improving the adversarial robustness of 3D deep learning models. Current attack methods are mainly applied by point perturbation in a non-manifold manner. In this paper, we formulate a novel manifold attack, which deforms the underlying 2-manifold surfaces via parameter plane stretching to generate adversarial point clouds. First, we represent the mapping between the parameter plane and underlying surface using generative-based networks. Second, the stretching is learned in the 2D parameter domain such that the generated 3D point cloud fools a pretrained classifier with minimal geometric distortion. Extensive experiments show that adversarial point clouds generated by manifold attack are smooth, undefendable and transferable, and outperform those samples generated by the state-of-the-art non-manifold ones.","https://ojs.aaai.org/index.php/AAAI/article/view/25338/25110"
"25339","Fair Generative Models via Transfer Learning","['Christopher T.H. Teo', 'Milad Abdollahzadeh', 'Ngai-Man Cheung']","['Singapore University of Technology and Design', 'Singapore University of Technology and Design', 'Singapore University of Technology and Design']","['CV: Bias', 'Fairness & Privacy', 'ML: Bias and Fairness']","Teo, C. T., Abdollahzadeh, M., & Cheung, N.-M. (2023). Fair Generative Models via Transfer Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2429-2437. https://doi.org/10.1609/aaai.v37i2.25339","Abstract 					This work addresses fair generative models. Dataset biases have been a major cause of unfairness in deep generative models. Previous work had proposed to augment large, biased datasets with small, unbiased reference datasets. Under this setup, a weakly-supervised approach has been proposed, which achieves state-of-the-art quality and fairness in generated samples. In our work, based on this setup, we propose a simple yet effective approach. Specifically, first, we propose fairTL, a transfer learning approach to learn fair generative models. Under fairTL, we pre-train the generative model with the available large, biased datasets and subsequently adapt the model using the small, unbiased reference dataset. We find that our fairTL can learn expressive sample generation during pre-training, thanks to the large (biased) dataset. This knowledge is then transferred to the target model during adaptation, which also learns to capture the underlying fair distribution of the small reference dataset. Second, we propose fairTL++, where we introduce two additional innovations to improve upon fairTL: (i) multiple feedback and (ii) Linear-Probing followed by Fine-Tuning (LP-FT). Taking one step further, we consider an alternative, challenging setup when only a pre-trained (potentially biased) model is available but the dataset that was used to pre-train the model is inaccessible. We demonstrate that our proposed fairTL and fairTL++ remain very effective under this setup. We note that previous work requires access to the large, biased datasets and is incapable of handling this more challenging setup. Extensive experiments show that fairTL and fairTL++ achieve state-of-the-art in both quality and fairness of generated samples. The code and additional resources can be found at bearwithchris.github.io/fairTL/.","https://ojs.aaai.org/index.php/AAAI/article/view/25339/25111"
"25340","Learning Context-Aware Classifier for Semantic Segmentation","['Zhuotao Tian', 'Jiequan Cui', 'Li Jiang', 'Xiaojuan Qi', 'Xin Lai', 'Yixin Chen', 'Shu Liu', 'Jiaya Jia']","['SmartMore\nChinese University of Hong Kong', 'Chinese University of Hong Kong', 'Max Planck Institute for Informatics', 'The University of Hong Kong', 'The Chinese University of Hong Kong', 'Chinese University of Hong Kong', 'SmartMore', 'SmartMore\nChinese University of Hong Kong']","['CV: Representation Learning for Vision', 'CV: Segmentation', 'ML: Representation Learning']","Tian, Z., Cui, J., Jiang, L., Qi, X., Lai, X., Chen, Y., Liu, S., & Jia, J. (2023). Learning Context-Aware Classifier for Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2438-2446. https://doi.org/10.1609/aaai.v37i2.25340","Abstract 					Semantic segmentation is still a challenging task for parsing diverse contexts in different scenes, thus the fixed classifier might not be able to well address varying feature distributions during testing.  Different from the mainstream literature where the efficacy of strong backbones and effective decoder heads has been well studied, in this paper, additional contextual hints are instead exploited via learning a context-aware classifier whose content is data-conditioned, decently adapting to different latent distributions. Since only the classifier is dynamically altered, our method is model-agnostic and can be easily applied to generic segmentation models. Notably, with only negligible additional parameters and +2\% inference time, decent performance gain has been achieved on both small and large models with challenging benchmarks, manifesting substantial practical merits brought by our simple yet effective method. The implementation is available at https://github.com/tianzhuotao/CAC.","https://ojs.aaai.org/index.php/AAAI/article/view/25340/25112"
"25341","TopicFM: Robust and Interpretable Topic-Assisted Feature Matching","['Khang Truong Giang', 'Soohwan Song', 'Sungho Jo']","['KAIST', 'Electronics and Telecommunications Research Institute (ETRI)', 'KAIST']","['CV: 3D Computer Vision', 'CV: Representation Learning for Vision', 'CV: Vision for Robotics & Autonomous Driving', 'ML: Probabilistic Methods']","Truong Giang, K., Song, S., & Jo, S. (2023). TopicFM: Robust and Interpretable Topic-Assisted Feature Matching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2447-2455. https://doi.org/10.1609/aaai.v37i2.25341","Abstract 					This study addresses an image-matching problem in challenging cases, such as large scene variations or textureless scenes. To gain robustness to such situations, most previous studies have attempted to encode the global contexts of a scene via graph neural networks or transformers. However, these contexts do not explicitly represent high-level contextual information, such as structural shapes or semantic instances; therefore, the encoded features are still not sufficiently discriminative in challenging scenes. We propose a novel image-matching method that applies a topic-modeling strategy to encode high-level contexts in images. The proposed method trains latent semantic instances called topics. It explicitly models an image as a multinomial distribution of topics, and then performs probabilistic feature matching. This approach improves the robustness of matching by focusing on the same semantic areas between the images. In addition, the inferred topics provide interpretability for matching the results, making our method explainable. Extensive experiments on outdoor and indoor datasets show that our method outperforms other state-of-the-art methods, particularly in challenging cases.","https://ojs.aaai.org/index.php/AAAI/article/view/25341/25113"
"25342","Learning Fractals by Gradient Descent","['Cheng-Hao Tu', 'Hong-You Chen', 'David Carlyn', 'Wei-Lun Chao']","['The Ohio State University', 'The Ohio State University', 'The Ohio State University', 'The Ohio State University']","['CV: Learning & Optimization for CV', 'CV: Applications', 'CV: Other Foundations of Computer Vision', 'ML: Deep Neural Architectures']","Tu, C.-H., Chen, H.-Y., Carlyn, D., & Chao, W.-L. (2023). Learning Fractals by Gradient Descent. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2456-2464. https://doi.org/10.1609/aaai.v37i2.25342","Abstract 					Fractals are geometric shapes that can display complex and self-similar patterns found in nature (e.g., clouds and plants). Recent works in visual recognition have leveraged this property to create random fractal images for model pre-training. In this paper, we study the inverse problem --- given a target image (not necessarily a fractal), we aim to generate a fractal image that looks like it. We propose a novel approach that learns the parameters underlying a fractal image via gradient descent. We show that our approach can find fractal parameters of high visual quality and be compatible with different loss functions, opening up several potentials, e.g., learning fractals for downstream tasks, scientific understanding, etc.","https://ojs.aaai.org/index.php/AAAI/article/view/25342/25114"
"25343","Leveraging Weighted Cross-Graph Attention for Visual and Semantic Enhanced Video Captioning Network","['Deepali Verma', 'Arya Haldar', 'Tanima Dutta']","['Department of Computer Science and Engineering, IIT (BHU), Varanasi', 'Department of Computer Science and Engineering, IIT (BHU), Varanasi', 'Department of Computer Science and Engineering, IIT (BHU), Varanasi']","['CV: Language and Vision', 'CMS: Analogical and Conceptual Reasoning', 'CV: Visual Reasoning & Symbolic Representations', 'ML: Deep Neural Architectures']","Verma, D., Haldar, A., & Dutta, T. (2023). Leveraging Weighted Cross-Graph Attention for Visual and Semantic Enhanced Video Captioning Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2465-2473. https://doi.org/10.1609/aaai.v37i2.25343","Abstract 					Video captioning has become a broad and interesting research area. Attention-based encoder-decoder methods are extensively used for caption generation. However, these methods mostly utilize the visual attentive feature to highlight the video regions while overlooked the semantic features of the available captions. These semantic features contain significant information that helps to generate highly informative human description-like captions. Therefore, we propose a novel visual and semantic enhanced video captioning network, named as VSVCap, that efficiently utilizes multiple ground truth captions. We aim to generate captions that are visually and semantically enhanced by exploiting both video and text modalities. To achieve this, we propose a fine-grained cross-graph attention mechanism that captures detailed graph embedding correspondence between visual graphs and textual knowledge graphs. We have performed node-level matching and structure-level reasoning between the weighted regional graph and knowledge graph. The proposed network achieves promising results on three benchmark datasets, i.e., YouTube2Text, MSR-VTT, and VATEX. The experimental results show that our network accurately captures all key objects, relationships, and semantically enhanced events of a video to generate human annotation-like captions.","https://ojs.aaai.org/index.php/AAAI/article/view/25343/25115"
"25344","Doodle to Object: Practical Zero-Shot Sketch-Based 3D Shape Retrieval","['Bingrui Wang', 'Yuan Zhou']","['Tianjin University', 'Tianjin University']","['CV: Image and Video Retrieval', 'CV: Multi-modal Vision', 'ML: Deep Neural Network Algorithms', 'ML: Multimodal Learning']","Wang, B., & Zhou, Y. (2023). Doodle to Object: Practical Zero-Shot Sketch-Based 3D Shape Retrieval. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2474-2482. https://doi.org/10.1609/aaai.v37i2.25344","Abstract 					Zero-shot (ZS) sketch-based three-dimensional (3D) shape retrieval (SBSR) is challenging due to the abstraction of sketches, cross-domain discrepancies between two-dimensional sketches and 3D shapes, and ZS-driven semantic knowledge transference from seen to unseen categories. Extant SBSR datasets suffer from lack of data, and no current SBSR methods consider ZS scenarios. In this paper, we contribute a new Doodle2Object (D2O) dataset consisting of 8,992 3D shapes and over 7M sketches spanning 50 categories. Then, we propose a novel prototype contrastive learning (PCL) method that effectively extracts features from different domains and adapts them to unseen categories. Specifically, our PCL method combines the ideas of contrastive and cluster-based prototype learning, and several randomly selected prototypes of different classes are assigned to each sample. By comparing these prototypes, a given sample can be moved closer to the same semantic class of samples while moving away from negative ones. Extensive experiments on two common SBSR benchmarks and our D2O dataset demonstrate the efficacy of the proposed PCL method for ZS-SBSR. Resource is available at https://github.com/yigohw/doodle2object.","https://ojs.aaai.org/index.php/AAAI/article/view/25344/25116"
"25345","Controlling Class Layout for Deep Ordinal Classification via Constrained Proxies Learning","['Cong Wang', 'Zhiwei Jiang', 'Yafeng Yin', 'Zifeng Cheng', 'Shiping Ge', 'Qing Gu']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University']","['CV: Object Detection & Categorization', 'ML: Classification and Regression', 'ML: Representation Learning']","Wang, C., Jiang, Z., Yin, Y., Cheng, Z., Ge, S., & Gu, Q. (2023). Controlling Class Layout for Deep Ordinal Classification via Constrained Proxies Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2483-2491. https://doi.org/10.1609/aaai.v37i2.25345","Abstract 					For deep ordinal classification, learning a well-structured feature space specific to ordinal classification is helpful to properly capture the ordinal nature among classes. Intuitively, when Euclidean distance metric is used, an ideal ordinal layout in feature space would be that the sample clusters are arranged in class order along a straight line in space. However, enforcing samples to conform to a specific layout in the feature space is a challenging problem. To address this problem, in this paper, we propose a novel Constrained Proxies Learning (CPL) method, which can learn a proxy for each ordinal class and then adjusts the global layout of classes by constraining these proxies. Specifically, we propose two kinds of strategies: hard layout constraint and soft layout constraint. The hard layout constraint is realized by directly controlling the generation of proxies to force them to be placed in a strict linear layout or semicircular layout (i.e., two instantiations of strict ordinal layout). The soft layout constraint is realized by constraining that the proxy layout should always produce unimodal proxy-to-proxies similarity distribution for each proxy (i.e., to be a relaxed ordinal layout). Experiments show that the proposed CPL method outperforms previous deep ordinal classification methods under the same setting of feature extractor.","https://ojs.aaai.org/index.php/AAAI/article/view/25345/25117"
"25346","Dual Memory Aggregation Network for Event-Based Object Detection with Learnable Representation","['Dongsheng Wang', 'Xu Jia', 'Yang Zhang', 'Xinyu Zhang', 'Yaoyuan Wang', 'Ziyang Zhang', 'Dong Wang', 'Huchuan Lu']","['Dalian University of Technology', 'Dalian University of Technology', 'Dalian University of Technology', 'Dalian University of Technology', 'Huawei Technologies Co., Ltd.', 'Huawei Technologies Co., Ltd.', 'Dalian University of Technology', 'Dalian University of Technology']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Vision for Robotics & Autonomous Driving']","Wang, D., Jia, X., Zhang, Y., Zhang, X., Wang, Y., Zhang, Z., Wang, D., & Lu, H. (2023). Dual Memory Aggregation Network for Event-Based Object Detection with Learnable Representation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2492-2500. https://doi.org/10.1609/aaai.v37i2.25346","Abstract 					Event-based cameras are bio-inspired sensors that capture brightness change of every pixel in an asynchronous manner. Compared with frame-based sensors, event cameras have microsecond-level latency and high dynamic range, hence showing great potential for object detection under high-speed motion and poor illumination conditions. Due to sparsity and asynchronism nature with event streams, most of existing approaches resort to hand-crafted methods to convert event data into 2D grid representation. However, they are sub-optimal in aggregating information from event stream for object detection. In this work, we propose to learn an event representation optimized for event-based object detection. Specifically, event streams are divided into grids in the x-y-t coordinates for both positive and negative polarity, producing a set of pillars as 3D tensor representation. To fully exploit information with event streams to detect objects, a dual-memory aggregation network (DMANet) is proposed to leverage both long and short memory along event streams to aggregate effective information for object detection. Long memory is encoded in the hidden state of adaptive convLSTMs while short memory is modeled by computing spatial-temporal correlation between event pillars at neighboring time intervals. Extensive experiments on the recently released event-based automotive detection dataset demonstrate the effectiveness of the proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/25346/25118"
"25347","Text to Point Cloud Localization with Relation-Enhanced Transformer","['Guangzhi Wang', 'Hehe Fan', 'Mohan Kankanhalli']","['National University of Singapore', 'National University of Singapore', 'National University of Singapore,']","['CV: 3D Computer Vision', 'CV: Multi-modal Vision']","Wang, G., Fan, H., & Kankanhalli, M. (2023). Text to Point Cloud Localization with Relation-Enhanced Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2501-2509. https://doi.org/10.1609/aaai.v37i2.25347","Abstract 					Automatically localizing a position based on a few natural language instructions is essential for future robots to communicate and collaborate with humans. To approach this goal, we focus on a text-to-point-cloud cross-modal localization problem. Given a textual query, it aims to identify the described location from city-scale point clouds. The task involves two challenges. 1) In city-scale point clouds, similar ambient instances may exist in several locations. Searching each location in a huge point cloud with only instances as guidance may lead to less discriminative signals and incorrect results. 2) In textual descriptions, the hints are provided separately. In this case, the relations among those hints are not explicitly described, leaving the difficulties of learning relations to the agent itself. To alleviate the two challenges, we propose a unified Relation-Enhanced Transformer (RET) to improve representation discriminability for both point cloud and nature language queries. The core of the proposed RET is a novel Relation-enhanced Self-Attention (RSA) mechanism, which explicitly encodes instance (hint)-wise relations for the two modalities. Moreover, we propose a fine-grained cross-modal matching method to further refine the location predictions in a subsequent instance-hint matching stage. Experimental results on the KITTI360Pose dataset demonstrate that our approach surpasses the previous state-of-the-art method by large margins.","https://ojs.aaai.org/index.php/AAAI/article/view/25347/25119"
"25348","UCoL: Unsupervised Learning of Discriminative Facial Representations via Uncertainty-Aware Contrast","['Hao Wang', 'Min Li', 'Yangyang Song', 'Youjian Zhang', 'Liying Chi']","['ByteDance Inc.', 'ByteDance Inc.', 'ByteDance Inc.', 'The University of Sydney', 'ByteDance Inc.']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Representation Learning for Vision']","Wang, H., Li, M., Song, Y., Zhang, Y., & Chi, L. (2023). UCoL: Unsupervised Learning of Discriminative Facial Representations via Uncertainty-Aware Contrast. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2510-2518. https://doi.org/10.1609/aaai.v37i2.25348","Abstract 					This paper presents Uncertainty-aware Contrastive Learning (UCoL): a fully unsupervised framework for discriminative facial representation learning. Our UCoL is built upon a momentum contrastive network, referred to as Dual-path Momentum Network. Specifically, two flows of pairwise contrastive training are conducted simultaneously:  one is formed with intra-instance self augmentation, and the other is to identify positive pairs collected by online pairwise prediction. We introduce a novel uncertainty-aware consistency K-nearest neighbors algorithm to generate predicted positive pairs, which enables efficient discriminative learning from large-scale open-world unlabeled data. Experiments show that UCoL significantly improves the baselines of unsupervised models and performs on par with the semi-supervised and supervised face representation learning methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25348/25120"
"25349","Calibrated Teacher for Sparsely Annotated Object Detection","['Haohan Wang', 'Liang Liu', 'Boshen Zhang', 'Jiangning Zhang', 'Wuhao Zhang', 'Zhenye Gan', 'Yabiao Wang', 'Chengjie Wang', 'Haoqian Wang']","['Tsinghua Shenzhen International Graduate School', 'Tencent', 'Tencent', 'Tencent', 'Tencent', 'Tencent', 'Tencent', 'Tencent\nShanghai Jiao Tong University', 'Tsinghua Shenzhen International Graduate School, Tsinghua University']","['CV: Object Detection & Categorization', 'ML: Semi-Supervised Learning']","Wang, H., Liu, L., Zhang, B., Zhang, J., Zhang, W., Gan, Z., Wang, Y., Wang, C., & Wang, H. (2023). Calibrated Teacher for Sparsely Annotated Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2519-2527. https://doi.org/10.1609/aaai.v37i2.25349","Abstract 					Fully supervised object detection requires training images in which all instances are annotated. This is actually impractical due to the high labor and time costs and the unavoidable missing annotations. As a result, the incomplete annotation in each image could provide misleading supervision and harm the training. Recent works on sparsely annotated object detection alleviate this problem by generating pseudo labels for the missing annotations. Such a mechanism is sensitive to the threshold of the pseudo label score. However, the effective threshold is different in different training stages and among different object detectors. Therefore, the current methods with fixed thresholds have sub-optimal performance, and are difficult to be applied to other detectors. In order to resolve this obstacle, we propose a Calibrated Teacher, of which the confidence estimation of the prediction is well calibrated to match its real precision. In this way, different detectors in different training stages would share a similar distribution of the output confidence, so that multiple detectors could share the same fixed threshold and achieve better performance. Furthermore, we present a simple but effective Focal IoU Weight (FIoU) for the classification loss. FIoU aims at reducing the loss weight of false negative samples caused by the missing annotation, and thus works as the complement of the teacher-student paradigm. Extensive experiments show that our methods set new state-of-the-art under all different sparse settings in COCO. Code will be available at https://github.com/Whileherham/CalibratedTeacher.","https://ojs.aaai.org/index.php/AAAI/article/view/25349/25121"
"25350","Towards Real-Time Panoptic Narrative Grounding by an End-to-End Grounding Network","['Haowei Wang', 'Jiayi Ji', 'Yiyi Zhou', 'Yongjian Wu', 'Xiaoshuai Sun']","['Xiamen University', 'Xiamen University', 'Xiamen University', 'Tencent Youtu Lab', 'Xiamen University']","['CV: Language and Vision', 'CV: Segmentation']","Wang, H., Ji, J., Zhou, Y., Wu, Y., & Sun, X. (2023). Towards Real-Time Panoptic Narrative Grounding by an End-to-End Grounding Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2528-2536. https://doi.org/10.1609/aaai.v37i2.25350","Abstract 					Panoptic Narrative Grounding (PNG) is an emerging cross-modal grounding task, which locates the target regions of an image corresponding to the text description. Existing approaches for PNG are mainly based on a two-stage paradigm, which is computationally expensive. In this paper, we propose a one-stage network for real-time PNG, termed End-to-End Panoptic Narrative Grounding network (EPNG), which directly generates masks for referents. Specifically, we propose two innovative designs, i.e., Locality-Perceptive Attention (LPA) and a bidirectional Semantic Alignment Loss (SAL), to properly handle the many-to-many relationship between textual expressions and visual objects. LPA embeds the local spatial priors into attention modeling, i.e., a pixel may belong to multiple masks at different scales, thereby improving segmentation. To help understand the complex semantic relationships, SAL proposes a bidirectional contrastive objective to regularize the semantic consistency inter modalities. Extensive experiments on the PNG benchmark dataset demonstrate the effectiveness and efficiency of our method. Compared to the single-stage baseline, our method achieves a significant improvement of up to 9.4% accuracy. More importantly, our EPNG is 10 times faster than the two-stage model. Meanwhile, the generalization ability of EPNG is also validated by zero-shot experiments on other grounding tasks. The source codes and trained models for all our experiments are publicly available at https://github.com/Mr-Neko/EPNG.git.","https://ojs.aaai.org/index.php/AAAI/article/view/25350/25122"
"25351","LeNo: Adversarial Robust Salient Object Detection Networks with Learnable Noise","['He Wang', 'Lin Wan', 'He Tang']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology']","['CV: Object Detection & Categorization', 'CV: Adversarial Attacks & Robustness', 'ML: Deep Neural Architectures']","Wang, H., Wan, L., & Tang, H. (2023). LeNo: Adversarial Robust Salient Object Detection Networks with Learnable Noise. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2537-2545. https://doi.org/10.1609/aaai.v37i2.25351","Abstract 					Pixel-wise prediction with deep neural network has become an effective paradigm for salient object detection (SOD) and achieved remarkable performance. However, very few SOD models are robust against adversarial attacks which are visually imperceptible for human visual attention. The previous work robust saliency (ROSA) shuffles the pre-segmented superpixels and then refines the coarse saliency map by the densely connected conditional random field (CRF). Different from ROSA that rely on various pre- and post-processings, this paper proposes a light-weight Learnable Noise (LeNo) to defend adversarial attacks for SOD models. LeNo preserves accuracy of SOD models on both adversarial and clean images, as well as inference speed. In general, LeNo consists of a simple shallow noise and noise estimation that embedded in the encoder and decoder of arbitrary SOD networks respectively. Inspired by the center prior of human visual attention mechanism, we initialize the shallow noise with a cross-shaped gaussian distribution for better defense against adversarial attacks. Instead of adding additional network components for post-processing, the proposed noise estimation modifies only one channel of the decoder. With the deeply-supervised noise-decoupled training on state-of-the-art RGB and RGB-D SOD networks, LeNo outperforms previous works not only on adversarial images but also on clean images, which contributes stronger robustness for SOD. Our code is available at https://github.com/ssecv/LeNo.","https://ojs.aaai.org/index.php/AAAI/article/view/25351/25123"
"25352","Defending Black-Box Skeleton-Based Human Activity Classifiers","['He Wang', 'Yunfeng Diao', 'Zichang Tan', 'Guodong Guo']","['University of Leeds, UK', 'Hefei University of Technology, China', 'Baidu Research, China', 'IDL, Baidu Research, China']","['CV: Adversarial Attacks & Robustness', 'CV: Motion & Tracking']","Wang, H., Diao, Y., Tan, Z., & Guo, G. (2023). Defending Black-Box Skeleton-Based Human Activity Classifiers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2546-2554. https://doi.org/10.1609/aaai.v37i2.25352","Abstract 					Skeletal motions have been heavily relied upon for human activity recognition (HAR). Recently, a universal vulnerability of skeleton-based HAR has been identified across a variety of classifiers and data, calling for mitigation. To this end, we propose the first black-box defense method for skeleton-based HAR to our best knowledge. Our method is featured by full Bayesian treatments of the clean data, the adversaries and the classifier, leading to (1) a new Bayesian Energy-based formulation of robust discriminative classifiers, (2) a new adversary sampling scheme based on natural motion manifolds, and (3) a new post-train Bayesian strategy for black-box defense. We name our framework Bayesian Energy-based Adversarial Training or BEAT. BEAT is straightforward but elegant, which turns vulnerable black-box classifiers into robust ones without sacrificing accuracy. It demonstrates surprising and universal effectiveness across a wide range of skeletal HAR classifiers and datasets, under various attacks. Appendix and code are available.","https://ojs.aaai.org/index.php/AAAI/article/view/25352/25124"
"25353","Exploring CLIP for Assessing the Look and Feel of Images","['Jianyi Wang', 'Kelvin C.K. Chan', 'Chen Change Loy']","['Nanyang Technological University', 'Nanyang Technological University', 'Nanyang Technological University']","['CV: Low Level & Physics-Based Vision']","Wang, J., Chan, K. C., & Loy, C. C. (2023). Exploring CLIP for Assessing the Look and Feel of Images. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2555-2563. https://doi.org/10.1609/aaai.v37i2.25353","Abstract 					Measuring the perception of visual content is a long-standing problem in computer vision. Many mathematical models have been developed to evaluate the look or quality of an image. Despite the effectiveness of such tools in quantifying degradations such as noise and blurriness levels, such quantification is loosely coupled with human language. When it comes to more abstract perception about the feel of visual content, existing methods can only rely on supervised models that are explicitly trained with labeled data collected via laborious user study. In this paper, we go beyond the conventional paradigms by exploring the rich visual language prior encapsulated in Contrastive Language-Image Pre-training (CLIP) models for assessing both the quality perception (look) and abstract perception (feel) of images without explicit task-specific training. In particular, we discuss effective prompt designs and show an effective prompt pairing strategy to harness the prior. We also provide extensive experiments on controlled datasets and Image Quality Assessment (IQA) benchmarks. Our results show that CLIP captures meaningful priors that generalize well to different perceptual assessments.","https://ojs.aaai.org/index.php/AAAI/article/view/25353/25125"
"25354","Robust Video Portrait Reenactment via Personalized Representation Quantization","['Kaisiyuan Wang', 'Changcheng Liang', 'Hang Zhou', 'Jiaxiang Tang', 'Qianyi Wu', 'Dongliang He', 'Zhibin Hong', 'Jingtuo Liu', 'Errui Ding', 'Ziwei Liu', 'Jingdong Wang']","['The University of Sydney', 'Xidian University', 'Baidu Inc.', 'Peking University', 'Monash University', 'Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.', 'Nanyang Technological University', 'Baidu Inc.']","['CV: Computational Photography', 'Image & Video Synthesis']","Wang, K., Liang, C., Zhou, H., Tang, J., Wu, Q., He, D., Hong, Z., Liu, J., Ding, E., Liu, Z., & Wang, J. (2023). Robust Video Portrait Reenactment via Personalized Representation Quantization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2564-2572. https://doi.org/10.1609/aaai.v37i2.25354","Abstract 					While progress has been made in the field of portrait reenactment, the problem of how to produce high-fidelity and robust videos remains. Recent studies normally find it challenging to handle rarely seen target poses due to the limitation of source data. This paper proposes the Video Portrait via Non-local Quantization Modeling (VPNQ) framework, which produces pose- and disturbance-robust reenactable video portraits. Our key insight is to learn position-invariant quantized local patch representations and build a mapping between simple driving signals and local textures with non-local spatial-temporal modeling. Specifically, instead of learning a universal quantized codebook, we identify that a personalized one can be trained to preserve desired position-invariant local details better. Then, a simple representation of projected landmarks can be used as sufficient driving signals to avoid 3D rendering. Following, we employ a carefully designed Spatio-Temporal Transformer to predict reasonable and temporally consistent quantized tokens from the driving signal. The predicted codes can be decoded back to robust and high-quality videos. Comprehensive experiments have been conducted to validate the effectiveness of our approach.","https://ojs.aaai.org/index.php/AAAI/article/view/25354/25126"
"25355","De-biased Teacher: Rethinking IoU Matching for Semi-supervised Object Detection","['Kuo Wang', 'Jingyu Zhuang', 'Guanbin Li', 'Chaowei Fang', 'Lechao Cheng', 'Liang Lin', 'Fan Zhou']","['Sun Yat-sen University', 'Sun Yat-sen University', 'Sun Yat-sen University', 'Xidian University', 'Zhejiang Lab', 'Sun Yat-sen University', 'Sun Yat-sen university']","['CV: Object Detection & Categorization', 'CV: Scene Analysis & Understanding', 'ML: Semi-Supervised Learning']","Wang, K., Zhuang, J., Li, G., Fang, C., Cheng, L., Lin, L., & Zhou, F. (2023). De-biased Teacher: Rethinking IoU Matching for Semi-supervised Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2573-2580. https://doi.org/10.1609/aaai.v37i2.25355","Abstract 					Most of the recent research in semi-supervised object detection follows the pseudo-labeling paradigm evolved from the semi-supervised image classification task. However, the training paradigm of the two-stage object detector inevitably makes the pseudo-label learning process for unlabeled images full of bias. Specifically, the IoU matching scheme used for selecting and labeling candidate boxes is based on the assumption that the matching source~(ground truth) is accurate enough in terms of the number of objects, object position and object category. Obviously, pseudo-labels generated for unlabeled images cannot satisfy such a strong assumption, which makes the produced training proposals extremely unreliable and thus severely spoil the follow-up training. To de-bias the training proposals generated by the pseudo-label-based IoU matching, we propose a general framework -- De-biased Teacher, which abandons both the IoU matching and pseudo labeling processes by directly generating favorable training proposals for consistency regularization between the weak/strong augmented image pairs. Moreover, a distribution-based refinement scheme is designed to eliminate the scattered class predictions of significantly low values for higher efficiency. Extensive experiments demonstrate that the proposed De-biased Teacher consistently outperforms other state-of-the-art methods on the MS-COCO and PASCAL VOC benchmarks. Source codes are available at https://github.com/wkfdb/De-biased-Teracher.","https://ojs.aaai.org/index.php/AAAI/article/view/25355/25127"
"25356","Learning to Generate an Unbiased Scene Graph by Using Attribute-Guided Predicate Features","['Lei Wang', 'Zejian Yuan', 'Badong Chen']","['Xi’an Jiaotong University', 'Xi‘an Jiaotong University', ""Xi'an Jiaotong University""]","['CV: Scene Analysis & Understanding', 'CV: Language and Vision']","Wang, L., Yuan, Z., & Chen, B. (2023). Learning to Generate an Unbiased Scene Graph by Using Attribute-Guided Predicate Features. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2581-2589. https://doi.org/10.1609/aaai.v37i2.25356","Abstract 					Scene Graph Generation (SGG) aims to capture the semantic information in an image and build a structured representation, which facilitates downstream tasks. The current challenge in SGG is to tackle the biased predictions caused by the long-tailed distribution of predicates. Since multiple predicates in SGG are coupled in an image, existing data re-balancing methods cannot completely balance the head and tail predicates. In this work, a decoupled learning framework is proposed for unbiased scene graph generation by using attribute-guided predicate features to construct a balanced training set. Specifically, the predicate recognition is decoupled into Predicate Feature Representation Learning (PFRL) and predicate classifier training with a class-balanced predicate feature set, which is constructed by our proposed Attribute-guided Predicate Feature Generation (A-PFG) model. In the A-PFG model, we first define the class labels of  and corresponding visual feature as attributes to describe a predicate. Then the predicate feature and the attribute embedding are mapped into a shared hidden space by a dual Variational Auto-encoder (VAE), and finally the synthetic predicate features are forced to learn the contextual information in the attributes via cross reconstruction and distribution alignment. To demonstrate the effectiveness of our proposed method, our decoupled learning framework and A-PFG model are applied to various SGG models. The empirical results show that our method is substantially improved on all benchmarks and achieves new state-of-the-art performance for unbiased scene graph generation. Our code is available at https://github.com/wanglei0618/A-PFG.","https://ojs.aaai.org/index.php/AAAI/article/view/25356/25128"
"25357","Alignment-Enriched Tuning for Patch-Level Pre-trained Document Image Models","['Lei Wang', 'Jiabang He', 'Xing Xu', 'Ning Liu', 'Hui Liu']","['University of Electronic Science and Technology of China\nSingapore Management University', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'Beijing Forestry University', 'Beijing Rongda Technology Co., Ltd.']","['CV: Multi-modal Vision', 'CV: Visual Reasoning & Symbolic Representations', 'ML: Multimodal Learning', 'SNLP: Applications']","Wang, L., He, J., Xu, X., Liu, N., & Liu, H. (2023). Alignment-Enriched Tuning for Patch-Level Pre-trained Document Image Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2590-2598. https://doi.org/10.1609/aaai.v37i2.25357","Abstract 					Alignment between image and text has shown promising improvements on patch-level pre-trained document image models. However, investigating more effective or finer-grained alignment techniques during pre-training requires a large amount of computation cost and time. Thus, a question naturally arises: Could we fine-tune the pre-trained models adaptive to downstream tasks with alignment objectives and achieve comparable or better performance? In this paper, we propose a new model architecture with alignment-enriched tuning (dubbed AETNet) upon pre-trained document image models, to adapt downstream tasks with the joint task-specific supervised and alignment-aware contrastive objective. Specifically, we introduce an extra visual transformer as the alignment-ware image encoder and an extra text transformer as the alignment-ware text encoder before multimodal fusion. We consider alignment in the following three aspects: 1) document-level alignment by leveraging the cross-modal and intra-modal contrastive loss; 2) global-local alignment for modeling localized and structural information in document images; and 3) local-level alignment for more accurate patch-level information. Experiments on various downstream tasks show that AETNet can achieve state-of-the-art performance on various downstream tasks. Notably, AETNet consistently outperforms state-of-the-art pre-trained models, such as LayoutLMv3 with fine-tuning techniques, on three different downstream tasks. Code is available at https://github.com/MAEHCM/AET.","https://ojs.aaai.org/index.php/AAAI/article/view/25357/25129"
"25358","Flora: Dual-Frequency LOss-Compensated ReAl-Time Monocular 3D Video Reconstruction","['Likang Wang', 'Yue Gong', 'Qirui Wang', 'Kaixuan Zhou', 'Lei Chen']","['Department of Computer Science and Engineering, The Hong Kong University of Science and Technology', 'Distributed and Parallel Software Lab, Huawei Technologies', 'Distributed and Parallel Software Lab, Huawei Technologies', 'Riemann Lab, Huawei Technologies\nFundamental Software Innovation Lab, Huawei Technologies', 'Department of Computer Science and Engineering, The Hong Kong University of Science and Technology\nData Science and Analytics Thrust, The Hong Kong University of Science and Technology (Guangzhou)']","['CV: 3D Computer Vision', 'CV: Multi-modal Vision', 'CV: Vision for Robotics & Autonomous Driving', 'ML: Deep Neural Network Algorithms']","Wang, L., Gong, Y., Wang, Q., Zhou, K., & Chen, L. (2023). Flora: Dual-Frequency LOss-Compensated ReAl-Time Monocular 3D Video Reconstruction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2599-2607. https://doi.org/10.1609/aaai.v37i2.25358","Abstract 					In this work, we propose a real-time monocular 3D video reconstruction approach named Flora for reconstructing delicate and complete 3D scenes from RGB video sequences in an end-to-end manner. Specifically, we introduce a novel method with two main contributions. Firstly, the proposed feature aggregation module retains both color and reliability in a dual-frequency form. Secondly, the loss compensation module solves missing structure by correcting losses for falsely pruned voxels. The dual-frequency feature aggregation module enhances reconstruction quality in both precision and recall, and the loss compensation module benefits the recall. Notably, both proposed contributions achieve great results with negligible inferencing overhead. Our state-of-the-art experimental results on real-world datasets demonstrate Flora's leading performance in both effectiveness and efficiency. The code is available at https://github.com/NoOneUST/Flora.","https://ojs.aaai.org/index.php/AAAI/article/view/25358/25130"
"25359","Efficient Image Captioning for Edge Devices","['Ning Wang', 'Jiangrong Xie', 'Hang Luo', 'Qinglin Cheng', 'Jihao Wu', 'Mingbo Jia', 'Linlin Li']","['Huawei Inc.', 'Huawei Inc.', 'Huawei Inc.', 'Huawei Inc.', 'Huawei Inc.', 'Huawei Inc.', 'Huawei Inc.']","['CV: Language and Vision', 'CV: Multi-modal Vision']","Wang, N., Xie, J., Luo, H., Cheng, Q., Wu, J., Jia, M., & Li, L. (2023). Efficient Image Captioning for Edge Devices. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2608-2616. https://doi.org/10.1609/aaai.v37i2.25359","Abstract 					Recent years have witnessed the rapid progress of image captioning. However, the demands for large memory storage and heavy computational burden prevent these captioning models from being deployed on mobile devices. The main obstacles lie in the heavyweight visual feature extractors (i.e., object detectors) and complicated cross-modal fusion networks. To this end, we propose LightCap, a lightweight image captioner for resource-limited devices. The core design is built on the recent CLIP model for efficient image captioning. To be specific, on the one hand, we leverage the CLIP model to extract the compact grid features without relying on the time-consuming object detectors. On the other hand, we transfer the image-text retrieval design of CLIP to image captioning scenarios by devising a novel visual concept extractor and a cross-modal modulator. We further optimize the cross-modal fusion model and parallel prediction heads via sequential and ensemble distillations. With the carefully designed architecture, our model merely contains 40M parameters, saving the model size by more than 75% and the FLOPs by more than 98% in comparison with the current state-of-the-art methods. In spite of the low capacity, our model still exhibits state-of-the-art performance on prevalent datasets, e.g., 136.6 CIDEr on COCO Karpathy test split. Testing on the smartphone with only a single CPU, the proposed LightCap exhibits a fast inference speed of 188ms per image, which is ready for practical applications.","https://ojs.aaai.org/index.php/AAAI/article/view/25359/25131"
"25360","Controllable Image Captioning via Prompting","['Ning Wang', 'Jiahao Xie', 'Jihao Wu', 'Mingbo Jia', 'Linlin Li']","['Huawei Inc.', 'Huawei Inc.', 'Huawei Inc.', 'Huawei Inc.', 'Huawei Inc.']","['CV: Language and Vision', 'CV: Multi-modal Vision']","Wang, N., Xie, J., Wu, J., Jia, M., & Li, L. (2023). Controllable Image Captioning via Prompting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2617-2625. https://doi.org/10.1609/aaai.v37i2.25360","Abstract 					Despite the remarkable progress of image captioning, existing captioners typically lack the controllable capability to generate desired image captions, e.g., describing the image in a rough or detailed manner, in a factual or emotional view, etc. In this paper, we show that a unified model is qualified to perform well in diverse domains and freely switch among multiple styles. Such a controllable capability is achieved by embedding the prompt learning into the image captioning framework. To be specific, we design a set of prompts to fine-tune the pre-trained image captioner. These prompts allow the model to absorb stylized data from different domains for joint training, without performance degradation in each domain. Furthermore, we optimize the prompts with learnable vectors in the continuous word embedding space, avoiding the heuristic prompt engineering and meanwhile exhibiting superior performance. In the inference stage, our model is able to generate desired stylized captions by choosing the corresponding prompts. Extensive experiments verify the controllable capability of the proposed method. Notably, we achieve outstanding performance on two diverse image captioning benchmarks including COCO Karpathy split and TextCaps using a unified model.","https://ojs.aaai.org/index.php/AAAI/article/view/25360/25132"
"25361","ECO-3D: Equivariant Contrastive Learning for Pre-training on Perturbed 3D Point Cloud","['Ruibin Wang', 'Xianghua Ying', 'Bowei Xing', 'Jinfa Yang']","['Peking University', 'Peking University', 'Peking University', 'Peking University']","['CV: 3D Computer Vision', 'CV: Object Detection & Categorization', 'CV: Representation Learning for Vision', 'ML: Unsupervised & Self-Supervised Learning']","Wang, R., Ying, X., Xing, B., & Yang, J. (2023). ECO-3D: Equivariant Contrastive Learning for Pre-training on Perturbed 3D Point Cloud. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2626-2634. https://doi.org/10.1609/aaai.v37i2.25361","Abstract 					In this work, we investigate contrastive learning on perturbed point clouds and find that the contrasting process may widen the domain gap caused by random perturbations, making the pre-trained network fail to generalize on testing data. To this end, we propose the Equivariant COntrastive framework which closes the domain gap before contrasting, further introduces the equivariance property, and enables pre-training networks under more perturbation types to obtain meaningful features. Specifically, to close the domain gap, a pre-trained VAE is adopted to convert perturbed point clouds into less perturbed point embedding of similar domains and separated perturbation embedding. The contrastive pairs can then be generated by mixing the point embedding with different perturbation embedding. Moreover, to pursue the equivariance property, a Vector Quantizer is adopted during VAE training, discretizing the perturbation embedding into one-hot tokens which indicate the perturbation labels. By correctly predicting the perturbation labels from the perturbed point cloud, the property of equivariance can be encouraged in the learned features. Experiments on synthesized and real-world perturbed datasets show that ECO-3D outperforms most existing pre-training strategies under various downstream tasks, achieving SOTA performance for lots of perturbations.","https://ojs.aaai.org/index.php/AAAI/article/view/25361/25133"
"25362","Global-Local Characteristic Excited Cross-Modal Attacks from Images to Videos","['Ruikui Wang', 'Yuanfang Guo', 'Yunhong Wang']","['School of Computer Science and Engineering, Beihang University, China', 'School of Computer Science and Engineering, Beihang University, China\nZhongguancun Laboratory, Beijing, China', 'School of Computer Science and Engineering, Beihang University, China']","['CV: Adversarial Attacks & Robustness', 'ML: Adversarial Learning & Robustness']","Wang, R., Guo, Y., & Wang, Y. (2023). Global-Local Characteristic Excited Cross-Modal Attacks from Images to Videos. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2635-2643. https://doi.org/10.1609/aaai.v37i2.25362","Abstract 					The transferability of adversarial examples is the key property in practical black-box scenarios. Currently, numerous methods improve the transferability across different models trained on the same modality of data. The investigation of generating video adversarial examples with imagebased substitute models to attack the target video models, i.e., cross-modal transferability of adversarial examples, is rarely explored. A few works on cross-modal transferability directly apply image attack methods for each frame and no factors especial for video data are considered, which limits the cross-modal transferability of adversarial examples. In this paper, we propose an effective cross-modal attack method which considers both the global and local characteristics of video data. Firstly, from the global perspective, we introduce inter-frame interaction into attack process to induce more diverse and stronger gradients rather than perturb each frame separately. Secondly, from the local perspective, we disrupt the inherently local correlation of frames within a video, which prevents black-box video model from capturing valuable temporal clues. Extensive experiments on the UCF-101 and Kinetics-400 validate the proposed method significantly improves cross-modal transferability and even surpasses strong baseline using video models as substitute model. Our source codes are available at https://github.com/lwmming/Cross-Modal-Attack.","https://ojs.aaai.org/index.php/AAAI/article/view/25362/25134"
"25363","Fine-Grained Retrieval Prompt Tuning","['Shijie Wang', 'Jianlong Chang', 'Zhihui Wang', 'Haojie Li', 'Wanli Ouyang', 'Qi Tian']","['International School of Information Science & Engineering, Dalian University of Technology, China', 'Huawei Cloud & AI, China', 'International School of Information Science & Engineering, Dalian University of Technology, China', 'International School of Information Science & Engineering, Dalian University of Technology, China\nCollege of Computer and Engineering, Shandong University of Science and Technology, China', 'SenseTime Computer Vision Research Group, The University of Sydney, Australia', 'Huawei Cloud & AI, China']","['CV: Image and Video Retrieval']","Wang, S., Chang, J., Wang, Z., Li, H., Ouyang, W., & Tian, Q. (2023). Fine-Grained Retrieval Prompt Tuning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(2), 2644-2652. https://doi.org/10.1609/aaai.v37i2.25363","Abstract 					Fine-grained object retrieval aims to learn discriminative representation to retrieve visually similar objects. However, existing top-performing works usually impose pairwise similarities on the semantic embedding spaces or design a localization sub-network to continually fine-tune the entire model in limited data scenarios, thus resulting in convergence to suboptimal solutions. In this paper, we develop Fine-grained Retrieval Prompt Tuning (FRPT), which steers a frozen pre-trained model to perform the fine-grained retrieval task from the perspectives of sample prompting and feature adaptation. Specifically, FRPT only needs to learn fewer parameters in the prompt and adaptation instead of fine-tuning the entire model, thus solving the issue of convergence to suboptimal solutions caused by fine-tuning the entire model. Technically, a discriminative perturbation prompt (DPP) is introduced and deemed as a sample prompting process, which amplifies and even exaggerates some discriminative elements contributing to category prediction via a content-aware inhomogeneous sampling operation. In this way, DPP can make the fine-grained retrieval task aided by the perturbation prompts close to the solved task during the original pre-training. Thereby, it preserves the generalization and discrimination of representation extracted from input samples. Besides, a category-specific awareness head is proposed and regarded as feature adaptation, which removes the species discrepancies in features extracted by the pre-trained model using category-guided instance normalization. And thus, it makes the optimized features only include the discrepancies among subcategories. Extensive experiments demonstrate that our FRPT with fewer learnable parameters achieves the state-of-the-art performance on three widely-used fine-grained datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25363/25135"
"25364","Ultra-High-Definition Low-Light Image Enhancement: A Benchmark and Transformer-Based Method","['Tao Wang', 'Kaihao Zhang', 'Tianrun Shen', 'Wenhan Luo', 'Bjorn Stenger', 'Tong Lu']","['Nanjing University', 'Australian National University', 'Nanjing University', 'Shenzhen Campus of Sun Yat-sen University', 'Rakuten Institute of Technology', 'Nanjing University']","['CV: Low Level & Physics-Based Vision', 'CV: Computational Photography', 'Image & Video Synthesis', 'CV: Scene Analysis & Understanding', 'CMS: Applications']","Wang, T., Zhang, K., Shen, T., Luo, W., Stenger, B., & Lu, T. (2023). Ultra-High-Definition Low-Light Image Enhancement: A Benchmark and Transformer-Based Method. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2654-2662. https://doi.org/10.1609/aaai.v37i3.25364","Abstract 					As the quality of optical sensors improves, there is a need for processing large-scale images. In particular, the ability of devices to capture ultra-high definition (UHD) images and video places new demands on the image processing pipeline. In this paper, we consider the task of low-light image enhancement (LLIE) and introduce a large-scale database consisting of images at 4K and 8K resolution. We conduct systematic benchmarking studies and provide a comparison of current LLIE algorithms. As a second contribution, we introduce LLFormer, a transformer-based low-light enhancement method. The core components of LLFormer are the axis-based multi-head self-attention and cross-layer attention fusion block, which significantly reduces the linear complexity. Extensive experiments on the new dataset and existing public datasets show that LLFormer outperforms state-of-the-art methods. We also show that employing existing LLIE methods trained on our benchmark as a pre-processing step significantly improves the performance of downstream tasks, e.g., face detection in low-light conditions. The source code and pre-trained models are available at https://github.com/TaoWangzj/LLFormer.","https://ojs.aaai.org/index.php/AAAI/article/view/25364/25136"
"25365","3D Assembly Completion","['Weihao Wang', 'Rufeng Zhang', 'Mingyu You', 'Hongjun Zhou', 'Bin He']","['Tongji University', 'Tongji University', 'Tongji University', 'Tongji University', 'Tongji University']","['CV: 3D Computer Vision', 'CV: Applications', 'ROB: Applications']","Wang, W., Zhang, R., You, M., Zhou, H., & He, B. (2023). 3D Assembly Completion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2663-2671. https://doi.org/10.1609/aaai.v37i3.25365","Abstract 					Automatic assembly is a promising research topic in 3D computer vision and robotics. Existing works focus on generating assembly (e.g., IKEA furniture) from scratch with a set of parts, namely 3D part assembly. In practice, there are higher demands for the robot to take over and finish an incomplete assembly (e.g., a half-assembled IKEA furniture) with an off-the-shelf toolkit, especially in human-robot and multi-agent collaborations. Compared to 3D part assembly, it is more complicated in nature and remains unexplored yet. The robot must understand the incomplete structure, infer what parts are missing, single out the correct parts from the toolkit and finally, assemble them with appropriate poses to finish the incomplete assembly. Geometrically similar parts in the toolkit can interfere, and this problem will be exacerbated with more missing parts. To tackle this issue, we propose a novel task called 3D assembly completion. Given an incomplete assembly, it aims to find its missing parts from a toolkit and predict the 6-DoF poses to make the assembly complete. To this end, we propose FiT, a framework for Finishing the incomplete 3D assembly with Transformer. We employ the encoder to model the incomplete assembly into memories. Candidate parts interact with memories in a memory-query paradigm for final candidate classification and pose prediction. Bipartite part matching and symmetric transformation consistency are embedded to refine the completion. For reasonable evaluation and further reference, we design two standard toolkits of different difficulty, containing different compositions of candidate parts. We conduct extensive comparisons with several baseline methods and ablation studies, demonstrating the effectiveness of the proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/25365/25137"
"25366","A Benchmark and Asymmetrical-Similarity Learning for Practical Image Copy Detection","['Wenhao Wang', 'Yifan Sun', 'Yi Yang']","['University of Technology Sydney\nBaidu Research', 'Baidu Research', 'Zhejiang University']","['CV: Image and Video Retrieval', 'CV: Representation Learning for Vision']","Wang, W., Sun, Y., & Yang, Y. (2023). A Benchmark and Asymmetrical-Similarity Learning for Practical Image Copy Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2672-2679. https://doi.org/10.1609/aaai.v37i3.25366","Abstract 					Image copy detection (ICD) aims to determine whether a query image is an edited copy of any image from a reference set. Currently, there are very limited public benchmarks for ICD, while all overlook a critical challenge in real-world applications, i.e., the distraction from hard negative queries. Specifically, some queries are not edited copies but are inherently similar to some reference images. These hard negative queries are easily false recognized as edited copies, significantly compromising the ICD accuracy. This observation motivates us to build the first ICD benchmark featuring this characteristic. Based on existing ICD datasets, this paper constructs a new dataset by additionally adding 100,000 and 24, 252 hard negative pairs into the training and test set, respectively. Moreover, this paper further reveals a unique difficulty for solving the hard negative problem in ICD, i.e., there is a fundamental conflict between current metric learning and ICD. This conflict is: the metric learning adopts symmetric distance while the edited copy is an asymmetric (unidirectional) process, e.g., a partial crop is close to its holistic reference image and is an edited copy, while the latter cannot be the edited copy of the former (in spite the distance is equally small). This insight results in an Asymmetrical-Similarity Learning (ASL) method, which allows the similarity in two directions (the query ↔ the reference image) to be different from each other. Experimental results show that ASL outperforms state-of-the-art methods by a clear margin, confirming that solving the symmetric-asymmetric conflict is critical for ICD. The NDEC dataset and code are available at https://github.com/WangWenhao0716/ASL.","https://ojs.aaai.org/index.php/AAAI/article/view/25366/25138"
"25367","Revisiting Unsupervised Local Descriptor Learning","['Wufan Wang', 'Lei Zhang', 'Hua Huang']","['Beijing Institute of Technology', 'Beijing Institute of Technology', 'Beijing Normal University']","['CV: 3D Computer Vision', 'ML: Unsupervised & Self-Supervised Learning', 'CV: Image and Video Retrieval', 'CV: Learning & Optimization for CV', 'CV: Motion & Tracking', 'CV: Representation Learning for Vision', 'CV: Vision for Robotics & Autonomous Driving', 'ROB: Localization', 'Mapping', 'and Navigation', 'CV: Applications']","Wang, W., Zhang, L., & Huang, H. (2023). Revisiting Unsupervised Local Descriptor Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2680-2688. https://doi.org/10.1609/aaai.v37i3.25367","Abstract 					Constructing accurate training tuples is crucial for unsupervised local descriptor learning, yet challenging due to the absence of patch labels. The state-of-the-art approach constructs tuples with heuristic rules, which struggle to precisely depict real-world patch transformations, in spite of enabling fast model convergence. A possible solution to alleviate the problem is the clustering-based approach, which can capture realistic patch variations and learn more accurate class decision boundaries, but suffers from slow model convergence. This paper presents HybridDesc, an unsupervised approach that learns powerful local descriptor models with fast convergence speed by combining the rule-based and clustering-based approaches to construct training tuples. In addition, HybridDesc also contributes two concrete enhancing mechanisms: (1) a Differentiable Hyperparameter Search (DHS) strategy to find the optimal hyperparameter setting of the rule-based approach so as to provide accurate prior for the clustering-based approach, (2) an On-Demand Clustering (ODC) method to reduce the clustering overhead of the clustering-based approach without eroding its advantage. Extensive experimental results show that HybridDesc can efficiently learn local descriptors that surpass existing unsupervised local descriptors and even rival competitive supervised ones.","https://ojs.aaai.org/index.php/AAAI/article/view/25367/25139"
"25368","Crafting Monocular Cues and Velocity Guidance for Self-Supervised Multi-Frame Depth Learning","['Xiaofeng Wang', 'Zheng Zhu', 'Guan Huang', 'Xu Chi', 'Yun Ye', 'Ziwei Chen', 'Xingang Wang']","['Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Phigent Robotics', 'Phigent Robotics', 'Phigent Robotics', 'Phigent Robotics', 'Southeast University', 'Institute of Automation, Chinese Academy of Sciences']","['CV: Vision for Robotics & Autonomous Driving', 'CV: 3D Computer Vision']","Wang, X., Zhu, Z., Huang, G., Chi, X., Ye, Y., Chen, Z., & Wang, X. (2023). Crafting Monocular Cues and Velocity Guidance for Self-Supervised Multi-Frame Depth Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2689-2697. https://doi.org/10.1609/aaai.v37i3.25368","Abstract 					Self-supervised monocular methods can efficiently learn depth information of weakly textured surfaces or reflective objects. However, the depth accuracy is limited due to the inherent ambiguity in monocular geometric modeling. In contrast, multi-frame depth estimation methods improve depth accuracy thanks to the success of Multi-View Stereo (MVS), which directly makes use of geometric constraints. Unfortunately, MVS often suffers from texture-less regions, non-Lambertian surfaces, and moving objects, especially in real-world video sequences without known camera motion and depth supervision. Therefore, we propose MOVEDepth, which exploits the MOnocular cues and VElocity guidance to improve multi-frame Depth learning. Unlike existing methods that enforce consistency between MVS depth and monocular depth, MOVEDepth boosts multi-frame depth learning by directly addressing the inherent problems of MVS. The key of our approach is to utilize monocular depth as a geometric priority to construct MVS cost volume, and adjust depth candidates of cost volume under the guidance of predicted camera velocity. We further fuse monocular depth and MVS depth by learning uncertainty in the cost volume, which results in a robust depth estimation against ambiguity in multi-view geometry. Extensive experiments show MOVEDepth achieves state-of-the-art performance: Compared with Monodepth2 and PackNet, our method relatively improves the depth accuracy by 20% and 19.8% on the KITTI benchmark. MOVEDepth also generalizes to the more challenging DDAD benchmark, relatively outperforming ManyDepth by 7.2%. The code is available at https://github.com/JeffWang987/MOVEDepth.","https://ojs.aaai.org/index.php/AAAI/article/view/25368/25140"
"25369","Learning Continuous Depth Representation via Geometric Spatial Aggregator","['Xiaohang Wang', 'Xuanhong Chen', 'Bingbing Ni', 'Zhengyan Tong', 'Hang Wang']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Low Level & Physics-Based Vision']","Wang, X., Chen, X., Ni, B., Tong, Z., & Wang, H. (2023). Learning Continuous Depth Representation via Geometric Spatial Aggregator. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2698-2706. https://doi.org/10.1609/aaai.v37i3.25369","Abstract 					Depth map super-resolution (DSR) has been a fundamental task for 3D computer vision. While arbitrary scale DSR is a more realistic setting in this scenario, previous approaches predominantly suffer from the issue of inefficient real-numbered scale upsampling. To explicitly address this issue, we propose a novel continuous depth representation for DSR. The heart of this representation is our proposed Geometric Spatial Aggregator (GSA), which exploits a distance field modulated by arbitrarily upsampled target gridding, through which the geometric information is explicitly introduced into feature aggregation and target generation. Furthermore, bricking with GSA, we present a transformer-style backbone named GeoDSR, which possesses a principled way to construct the functional mapping between local coordinates and the high-resolution output results, empowering our model with the advantage of arbitrary shape transformation ready to help diverse zooming demand. Extensive experimental results on standard depth map benchmarks, e.g., NYU v2, have demonstrated that the proposed framework achieves significant restoration gain in arbitrary scale depth map super-resolution compared with the prior art. Our codes are available at https://github.com/nana01219/GeoDSR.","https://ojs.aaai.org/index.php/AAAI/article/view/25369/25141"
"25370","SSDA3D: Semi-supervised Domain Adaptation for 3D Object Detection from Point Cloud","['Yan Wang', 'Junbo Yin', 'Wei Li', 'Pascal Frossard', 'Ruigang Yang', 'Jianbing Shen']","['Beijing Institute of Technology', 'Beijing Institute of Technology', 'Inceptio', 'École Polytechnique Fédérale de Lausanne (EPFL)', 'Inceptio', 'SKL-IOTSC, CIS, University of Macau']","['CV: 3D Computer Vision', 'CV: Object Detection & Categorization']","Wang, Y., Yin, J., Li, W., Frossard, P., Yang, R., & Shen, J. (2023). SSDA3D: Semi-supervised Domain Adaptation for 3D Object Detection from Point Cloud. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2707-2715. https://doi.org/10.1609/aaai.v37i3.25370","Abstract 					LiDAR-based 3D object detection is an indispensable task in advanced autonomous driving systems. Though impressive detection results have been achieved by superior 3D detectors, they suffer from significant performance degeneration when facing unseen domains, such as different LiDAR configurations, different cities, and weather conditions. The mainstream approaches tend to solve these challenges by leveraging unsupervised domain adaptation (UDA) techniques. However, these UDA solutions just yield unsatisfactory 3D detection results when there is a severe domain shift, e.g., from Waymo (64-beam) to nuScenes (32-beam). To address this, we present a novel Semi-Supervised Domain Adaptation method for 3D object detection (SSDA3D), where only a few labeled target data is available, yet can significantly improve the adaptation performance. In particular, our SSDA3D includes an Inter-domain Adaptation stage and an Intra-domain Generalization stage. In the first stage, an Inter-domain Point-CutMix module is presented to efficiently align the point cloud distribution across domains. The Point-CutMix generates mixed samples of an intermediate domain, thus encouraging to learn domain-invariant knowledge. Then, in the second stage, we further enhance the model for better generalization on the unlabeled target set. This is achieved by exploring Intra-domain Point-MixUp in semi-supervised learning, which essentially regularizes the pseudo label distribution. Experiments from Waymo to nuScenes show that, with only 10% labeled target data, our SSDA3D can surpass the fully-supervised oracle model with 100% target label. Our code is available at  https://github.com/yinjunbo/SSDA3D.","https://ojs.aaai.org/index.php/AAAI/article/view/25370/25142"
"25371","High-Resolution GAN Inversion for Degraded Images in Large Diverse Datasets","['Yanbo Wang', 'Chuming Lin', 'Donghao Luo', 'Ying Tai', 'Zhizhong Zhang', 'Yuan Xie']","['East China Normal University', 'Tencent YouTu Lab', 'Tencent YouTu Lab', 'Tencent YouTu Lab', 'East China Normal University', 'East China Normal University']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Low Level & Physics-Based Vision']","Wang, Y., Lin, C., Luo, D., Tai, Y., Zhang, Z., & Xie, Y. (2023). High-Resolution GAN Inversion for Degraded Images in Large Diverse Datasets. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2716-2723. https://doi.org/10.1609/aaai.v37i3.25371","Abstract 					The last decades are marked by massive and diverse image data, which shows increasingly high resolution and quality. However, some images we obtained may be corrupted, affecting the perception and the application of downstream tasks. A generic method for generating a high-quality image from the degraded one is in demand. In this paper, we present a novel GAN inversion framework that utilizes the powerful generative ability of StyleGAN-XL for this problem. To ease the inversion challenge with StyleGAN-XL, Clustering \& Regularize Inversion (CRI) is proposed. Specifically, the latent space is firstly divided into finer-grained sub-spaces by clustering. Instead of initializing the inversion with the average latent vector, we approximate a centroid latent vector from the clusters, which generates an image close to the input image. Then, an offset with a regularization term is introduced to keep the inverted latent vector within a certain range. We validate our CRI scheme on multiple restoration tasks (i.e., inpainting, colorization, and super-resolution) of complex natural images, and show preferable quantitative and qualitative results. We further demonstrate our technique is robust in terms of data and different GAN models. To our best knowledge, we are the first to adopt StyleGAN-XL for generating high-quality natural images from diverse degraded inputs. Code is available at https://github.com/Booooooooooo/CRI.","https://ojs.aaai.org/index.php/AAAI/article/view/25371/25143"
"25372","GAN Prior Based Null-Space Learning for Consistent Super-resolution","['Yinhuai Wang', 'Yujie Hu', 'Jiwen Yu', 'Jian Zhang']","['Peking University Shenzhen Graduate School', 'Peking University Shenzhen Graduate School', 'Peking University Shenzhen Graduate School', 'Peking University Shenzhen Graduate School\nPeng Cheng Laboratory']","['CV: Low Level & Physics-Based Vision', 'CV: Computational Photography', 'Image & Video Synthesis', 'CV: Learning & Optimization for CV', 'CV: Other Foundations of Computer Vision']","Wang, Y., Hu, Y., Yu, J., & Zhang, J. (2023). GAN Prior Based Null-Space Learning for Consistent Super-resolution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2724-2732. https://doi.org/10.1609/aaai.v37i3.25372","Abstract 					Consistency and realness have always been the two critical issues of image super-resolution. While the realness has been dramatically improved with the use of GAN prior, the state-of-the-art methods still suffer inconsistencies in local structures and colors (e.g., tooth and eyes). In this paper, we show that these inconsistencies can be analytically eliminated by learning only the null-space component while fixing the range-space part. Further, we design a pooling-based decomposition (PD), a universal range-null space decomposition for super-resolution tasks, which is concise, fast, and parameter-free. PD can be easily applied to state-of-the-art GAN Prior based SR methods to eliminate their inconsistencies, neither compromise the realness nor bring extra parameters or computational costs. Besides, our ablation studies reveal that PD can replace pixel-wise losses for training and achieve better generalization performance when facing unseen downsamplings or even real-world degradation. Experiments show that the use of PD refreshes state-of-the-art SR performance and speeds up the convergence of training up to 2~10 times.","https://ojs.aaai.org/index.php/AAAI/article/view/25372/25144"
"25373","Contrastive Masked Autoencoders for Self-Supervised Video Hashing","['Yuting Wang', 'Jinpeng Wang', 'Bin Chen', 'Ziyun Zeng', 'Shu-Tao Xia']","['Tsinghua Shenzhen International Graduate School, Tsinghua University\nResearch Center of Artificial Intelligence, Peng Cheng Laboratory', 'Tsinghua Shenzhen International Graduate School, Tsinghua University\nResearch Center of Artificial Intelligence, Peng Cheng Laboratory', 'Harbin Institute of Technology, Shenzhen', 'Tsinghua Shenzhen International Graduate School, Tsinghua University\nResearch Center of Artificial Intelligence, Peng Cheng Laboratory', 'Tsinghua Shenzhen International Graduate School, Tsinghua University\nResearch Center of Artificial Intelligence, Peng Cheng Laboratory']","['CV: Image and Video Retrieval']","Wang, Y., Wang, J., Chen, B., Zeng, Z., & Xia, S.-T. (2023). Contrastive Masked Autoencoders for Self-Supervised Video Hashing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2733-2741. https://doi.org/10.1609/aaai.v37i3.25373","Abstract 					Self-Supervised Video Hashing (SSVH) models learn to generate short binary representations for videos without ground-truth supervision, facilitating large-scale video retrieval efficiency and attracting increasing research attention. The success of SSVH lies in the understanding of video content and the ability to capture the semantic relation among unlabeled videos. Typically, state-of-the-art SSVH methods consider these two points in a two-stage training pipeline, where they firstly train an auxiliary network by instance-wise mask-and-predict tasks and secondly train a hashing model to preserve the pseudo-neighborhood structure transferred from the auxiliary network. This consecutive training strategy is inflexible and also unnecessary. In this paper, we propose a simple yet effective one-stage SSVH method called ConMH, which incorporates video semantic information and video similarity relationship understanding in a single stage. To capture video semantic information for better hashing learning, we adopt an encoder-decoder structure to reconstruct the video from its temporal-masked frames. Particularly, we find that a higher masking ratio helps video understanding. Besides, we fully exploit the similarity relationship between videos by maximizing agreement between two augmented views of a video, which contributes to more discriminative and robust hash codes. Extensive experiments on three large-scale video datasets (i.e., FCVID, ActivityNet and YFCC) indicate that ConMH achieves state-of-the-art results. Code is available at https://github.com/huangmozhi9527/ConMH.","https://ojs.aaai.org/index.php/AAAI/article/view/25373/25145"
"25374","MicroAST: Towards Super-fast Ultra-Resolution Arbitrary Style Transfer","['Zhizhong Wang', 'Lei Zhao', 'Zhiwen Zuo', 'Ailin Li', 'Haibo Chen', 'Wei Xing', 'Dongming Lu']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Applications', 'APP: Art/Music/Creativity', 'ML: Deep Generative Models & Autoencoders']","Wang, Z., Zhao, L., Zuo, Z., Li, A., Chen, H., Xing, W., & Lu, D. (2023). MicroAST: Towards Super-fast Ultra-Resolution Arbitrary Style Transfer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2742-2750. https://doi.org/10.1609/aaai.v37i3.25374","Abstract 					Arbitrary style transfer (AST) transfers arbitrary artistic styles onto content images. Despite the recent rapid progress, existing AST methods are either incapable or too slow to run at ultra-resolutions (e.g., 4K) with limited resources, which heavily hinders their further applications. In this paper, we tackle this dilemma by learning a straightforward and lightweight model, dubbed MicroAST. The key insight is to completely abandon the use of cumbersome pre-trained Deep Convolutional Neural Networks (e.g., VGG) at inference. Instead, we design two micro encoders (content and style encoders) and one micro decoder for style transfer. The content encoder aims at extracting the main structure of the content image. The style encoder, coupled with a modulator, encodes the style image into learnable dual-modulation signals that modulate both intermediate features and convolutional filters of the decoder, thus injecting more sophisticated and flexible style signals to guide the stylizations. In addition, to boost the ability of the style encoder to extract more distinct and representative style signals, we also introduce a new style signal contrastive loss in our model. Compared to the state of the art, our MicroAST not only produces visually superior results but also is 5-73 times smaller and 6-18 times faster, for the first time enabling super-fast (about 0.5 seconds) AST at 4K ultra-resolutions.","https://ojs.aaai.org/index.php/AAAI/article/view/25374/25146"
"25375","Truncate-Split-Contrast: A Framework for Learning from Mislabeled Videos","['Zixiao Wang', 'Junwu Weng', 'Chun Yuan', 'Jue Wang']","['Tsinghua University', 'Tencent AI Lab', 'Tsinghua University', 'Tencent AI Lab']","['CV: Video Understanding & Activity Analysis']","Wang, Z., Weng, J., Yuan, C., & Wang, J. (2023). Truncate-Split-Contrast: A Framework for Learning from Mislabeled Videos. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2751-2758. https://doi.org/10.1609/aaai.v37i3.25375","Abstract 					Learning with noisy label is a classic problem that has been extensively studied for image tasks, but much less for video in the literature. A straightforward migration from images to videos without considering temporal semantics and computational cost is not a sound choice. In this paper, we propose two new strategies for video analysis with noisy labels: 1) a lightweight channel selection method dubbed as Channel Truncation for feature-based label noise detection. This method selects the most discriminative channels to split clean and noisy instances in each category. 2) A novel contrastive strategy dubbed as Noise Contrastive Learning, which constructs the relationship between clean and noisy instances to regularize model training. Experiments on three well-known benchmark datasets for video classification show that our proposed truNcatE-split-contrAsT (NEAT) significantly outperforms the existing baselines. By reducing the dimension to 10% of it, our method achieves over 0.4 noise detection F1-score and 5% classification accuracy improvement on Mini-Kinetics dataset under severe noise (symmetric-80%). Thanks to Noise Contrastive Learning, the average classification accuracy improvement on Mini-Kinetics and Sth-Sth-V1 is over 1.6%.","https://ojs.aaai.org/index.php/AAAI/article/view/25375/25147"
"25376","Active Token Mixer","['Guoqiang Wei', 'Zhizheng Zhang', 'Cuiling Lan', 'Yan Lu', 'Zhibo Chen']","['University of Science and Technology of China', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'University of Science and Technology of China']","['CV: Other Foundations of Computer Vision', 'CV: Learning & Optimization for CV', 'CV: Object Detection & Categorization', 'CV: Segmentation']","Wei, G., Zhang, Z., Lan, C., Lu, Y., & Chen, Z. (2023). Active Token Mixer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2759-2767. https://doi.org/10.1609/aaai.v37i3.25376","Abstract 					The three existing dominant network families, i.e., CNNs, Transformers and MLPs, differ from each other mainly in the ways of fusing spatial contextual information, leaving designing more effective token-mixing mechanisms at the core of backbone architecture development. In this work, we propose an innovative token-mixer, dubbed Active Token Mixer (ATM), to actively incorporate contextual information from other tokens in the global scope into the given query token. This fundamental operator actively predicts where to capture useful contexts and learns how to fuse the captured contexts with the query token at channel level. In this way, the spatial range of token-mixing can be expanded to a global scope with limited computational complexity, where the way of token-mixing is reformed. We take ATMs as the primary operators and assemble them into a cascade architecture, dubbed ATMNet. Extensive experiments demonstrate that ATMNet is generally applicable and comprehensively surpasses different families of SOTA vision backbones by a clear margin on a broad range of vision tasks, including visual recognition and dense prediction tasks.  Code is available at https://github.com/microsoft/ActiveMLP.","https://ojs.aaai.org/index.php/AAAI/article/view/25376/25148"
"25377","Exploring Non-target Knowledge for Improving Ensemble Universal Adversarial Attacks","['Juanjuan Weng', 'Zhiming Luo', 'Zhun Zhong', 'Dazhen Lin', 'Shaozi Li']","['Department of Artificial Intelligence, Xiamen University, China', 'Department of Artificial Intelligence, Xiamen University, China\nFujian Key Laboratory of Big Data Application and Intellectualization for Tea Industry, Wuyi University, China', 'Department of Information Engineering and Computer Science, University of Trento, Italy', 'Department of Artificial Intelligence, Xiamen University, China', 'Department of Artificial Intelligence, Xiamen University, China']","['CV: Adversarial Attacks & Robustness']","Weng, J., Luo, Z., Zhong, Z., Lin, D., & Li, S. (2023). Exploring Non-target Knowledge for Improving Ensemble Universal Adversarial Attacks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2768-2775. https://doi.org/10.1609/aaai.v37i3.25377","Abstract 					The ensemble attack with average weights can be leveraged for increasing the transferability of universal adversarial perturbation (UAP) by training with multiple Convolutional Neural Networks (CNNs). However, after analyzing the Pearson Correlation Coefficients (PCCs) between the ensemble logits and individual logits of the crafted UAP trained by the ensemble attack, we find that one CNN plays a dominant role during the optimization. Consequently, this average weighted strategy will weaken the contributions of other CNNs and thus limit the transferability for other black-box CNNs. To deal with this bias issue, the primary attempt is to leverage the Kullback–Leibler (KL) divergence loss to encourage the joint contribution from different CNNs, which is still insufficient. After decoupling the KL loss into a target-class part and a non-target-class part, the main issue lies in that the non-target knowledge will be significantly suppressed due to the increasing logit of the target class.  In this study, we simply adopt a KL loss that only considers the non-target classes for addressing the dominant bias issue. Besides, to further boost the transferability, we incorporate the min-max learning framework to self-adjust the ensemble weights for each CNN. Experiments results validate that considering the non-target KL loss can achieve superior transferability than the original KL loss by a large margin, and the min-max training can provide a mutual benefit in adversarial ensemble attacks. The source code is available at: https://github.com/WJJLL/ND-MM.","https://ojs.aaai.org/index.php/AAAI/article/view/25377/25149"
"25378","Towards Good Practices for Missing Modality Robust Action Recognition","['Sangmin Woo', 'Sumin Lee', 'Yeonju Park', 'Muhammad Adi Nugroho', 'Changick Kim']","['KAIST', 'KAIST', 'KAIST', 'KAIST', 'KAIST']","['CV: Multi-modal Vision', 'ML: Multimodal Learning', 'CV: Video Understanding & Activity Analysis']","Woo, S., Lee, S., Park, Y., Nugroho, M. A., & Kim, C. (2023). Towards Good Practices for Missing Modality Robust Action Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2776-2784. https://doi.org/10.1609/aaai.v37i3.25378","Abstract 					Standard multi-modal models assume the use of the same modalities in training and inference stages. However, in practice, the environment in which multi-modal models operate may not satisfy such assumption. As such, their performances degrade drastically if any modality is missing in the inference stage. We ask: how can we train a model that is robust to missing modalities? This paper seeks a set of good practices for multi-modal action recognition, with a particular interest in circumstances where some modalities are not available at an inference time. First, we show how to effectively regularize the model during training (e.g., data augmentation). Second, we investigate on fusion methods for robustness to missing modalities: we find that transformer-based fusion shows better robustness for missing modality than summation or concatenation. Third, we propose a simple modular network, ActionMAE, which learns missing modality predictive coding by randomly dropping modality features and tries to reconstruct them with the remaining modality features. Coupling these good practices, we build a model that is not only effective in multi-modal action recognition but also robust to modality missing. Our model achieves the state-of-the-arts on multiple benchmarks and maintains competitive performances even in missing modality scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/25378/25150"
"25379","Reject Decoding via Language-Vision Models for Text-to-Image Synthesis","['Fuxiang Wu', 'Liu Liu', 'Fusheng Hao', 'Fengxiang He', 'Lei Wang', 'Jun Cheng']","['Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences', 'The University of Sydney', 'Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences', 'JD.com', 'Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences', 'Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences']","['CV: Language and Vision', 'CV: Computational Photography', 'Image & Video Synthesis']","Wu, F., Liu, L., Hao, F., He, F., Wang, L., & Cheng, J. (2023). Reject Decoding via Language-Vision Models for Text-to-Image Synthesis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2785-2794. https://doi.org/10.1609/aaai.v37i3.25379","Abstract 					Transformer-based text-to-image synthesis generates images from abstractive textual conditions and achieves prompt results. Since transformer-based models predict visual tokens step by step in testing, where the early error is hard to be corrected and would be propagated. To alleviate this issue, the common practice is drawing multi-paths from the transformer-based models and re-ranking the multi-images decoded from multi-paths to find the best one and filter out others. Therefore, the computing procedure of excluding images may be inefficient. To improve the effectiveness and efficiency of decoding, we exploit a reject decoding algorithm with tiny multi-modal models to enlarge the searching space and exclude the useless paths as early as possible. Specifically, we build tiny multi-modal models to evaluate the similarities between the partial paths and the caption at multi scales. Then, we propose a reject decoding algorithm to exclude some lowest quality partial paths at the inner steps. Thus, under the same computing load as the original decoding, we could search across more multi-paths to improve the decoding efficiency and synthesizing quality. The experiments conducted on the MS-COCO dataset and large-scale datasets show that the proposed reject decoding algorithm can exclude the useless paths and enlarge the searching paths to improve the synthesizing quality by consuming less time.","https://ojs.aaai.org/index.php/AAAI/article/view/25379/25151"
"25380","Transformation-Equivariant 3D Object Detection for Autonomous Driving","['Hai Wu', 'Chenglu Wen', 'Wei Li', 'Xin Li', 'Ruigang Yang', 'Cheng Wang']","['School of Informatics, Xiamen University', 'School of Informatics, Xiamen University', 'Inceptio Technology', 'School of Performance, Visualization, and Fine Art, Texas A&M University', 'Inceptio Technology', 'School of Informatics, Xiamen University']","['CV: 3D Computer Vision', 'CV: Object Detection & Categorization']","Wu, H., Wen, C., Li, W., Li, X., Yang, R., & Wang, C. (2023). Transformation-Equivariant 3D Object Detection for Autonomous Driving. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2795-2802. https://doi.org/10.1609/aaai.v37i3.25380","Abstract 					3D object detection received increasing attention in autonomous driving recently. Objects in 3D scenes are distributed with diverse orientations. Ordinary detectors do not explicitly model the variations of rotation and reflection transformations. Consequently, large networks and extensive data augmentation are required for robust detection. Recent equivariant networks explicitly model the transformation variations by applying shared networks on multiple transformed point clouds, showing great potential in object geometry modeling. However, it is difficult to apply such networks to 3D object detection in autonomous driving due to its large computation cost and slow reasoning speed. In this work, we present TED, an efficient Transformation-Equivariant 3D Detector to overcome the computation cost and speed issues. TED first applies a sparse convolution backbone to extract multi-channel transformation-equivariant voxel features; and then aligns and aggregates these equivariant features into lightweight and compact representations for high-performance 3D object detection. On the highly competitive KITTI 3D car detection leaderboard, TED ranked 1st among all submissions with competitive efficiency. Code is available at https://github.com/hailanyi/TED.","https://ojs.aaai.org/index.php/AAAI/article/view/25380/25152"
"25381","Super-efficient Echocardiography Video Segmentation via Proxy- and Kernel-Based Semi-supervised Learning","['Huisi Wu', 'Jingyin Lin', 'Wende Xie', 'Jing Qin']","['Shenzhen University', 'Shenzhen University', 'Shenzhen University', 'The Hong Kong Polytechnic University']","['CV: Segmentation', 'CV: Medical and Biological Imaging']","Wu, H., Lin, J., Xie, W., & Qin, J. (2023). Super-efficient Echocardiography Video Segmentation via Proxy- and Kernel-Based Semi-supervised Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2803-2811. https://doi.org/10.1609/aaai.v37i3.25381","Abstract 					Automatic segmentation of left ventricular endocardium in echocardiography videos is critical for assessing various cardiac functions and improving the diagnosis of cardiac diseases. It is yet a challenging task due to heavy speckle noise, significant shape variability of cardiac structure, and limited labeled data. Particularly, the real-time demand in clinical practice makes this task even harder. In this paper, we propose a novel proxy- and kernel-based semi-supervised segmentation network (PKEcho-Net) to comprehensively address these challenges. We first propose a multi-scale region proxy (MRP) mechanism to model the region-wise contexts, in which a learnable region proxy with an arbitrary shape is developed in each layer of the encoder, allowing the network to identify homogeneous semantics and hence alleviate the influence of speckle noise on segmentation. To sufficiently and efficiently exploit temporal consistency, different from traditional methods which only utilize the temporal contexts of two neighboring frames via feature warping or self-attention mechanism, we formulate the semi-supervised segmentation with a group of learnable kernels, which can naturally and uniformly encode the appearances of left ventricular endocardium, as well as extracting the inter-frame contexts across the whole video to resist the fast shape variability of cardiac structures. Extensive experiments have been conducted on two famous public echocardiography video datasets, EchoNet-Dynamic and CAMUS. Our model achieves the best performance-efficiency trade-off when compared with other state-of-the-art approaches, attaining comparative accuracy with a much faster speed. The code is available at https://github.com/JingyinLin/PKEcho-Net.","https://ojs.aaai.org/index.php/AAAI/article/view/25381/25153"
"25382","ACL-Net: Semi-supervised Polyp Segmentation via Affinity Contrastive Learning","['Huisi Wu', 'Wende Xie', 'Jingyin Lin', 'Xinrong Guo']","['Shenzhen University', 'Shenzhen University', 'Shenzhen University', 'Shenzhen University']","['CV: Segmentation', 'CV: Medical and Biological Imaging']","Wu, H., Xie, W., Lin, J., & Guo, X. (2023). ACL-Net: Semi-supervised Polyp Segmentation via Affinity Contrastive Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2812-2820. https://doi.org/10.1609/aaai.v37i3.25382","Abstract 					Automatic polyp segmentation from colonoscopy images is an essential prerequisite for the development of computer-assisted therapy. However, the complex semantic information and the blurred edges of polyps make segmentation extremely difficult. In this paper, we propose a novel semi-supervised polyp segmentation framework using affinity contrastive learning (ACL-Net), which is implemented between student and teacher networks to consistently refine the pseudo-labels for semi-supervised polyp segmentation. By aligning the affinity maps between the two branches, a better polyp region activation can be obtained to fully exploit the appearance-level context encoded in the feature maps, thereby improving the capability of capturing not only global localization and shape context, but also the local textural and boundary details. By utilizing the rich inter-image affinity context and establishing a global affinity context based on the memory bank, a cross-image affinity aggregation (CAA) module is also implemented to further refine the affinity aggregation between the two branches. By continuously and adaptively refining pseudo-labels with optimized affinity, we can improve the semi-supervised polyp segmentation based on the mutually reinforced knowledge interaction among contrastive learning and consistency learning iterations. Extensive experiments on five benchmark datasets, including Kvasir-SEG, CVC-ClinicDB, CVC-300, CVC-ColonDB and ETIS, demonstrate the effectiveness and superiority of our method. Codes are available at https://github.com/xiewende/ACL-Net.","https://ojs.aaai.org/index.php/AAAI/article/view/25382/25154"
"25383","Bi-directional Feature Reconstruction Network for Fine-Grained Few-Shot Image Classification","['Jijie Wu', 'Dongliang Chang', 'Aneeshan Sain', 'Xiaoxu Li', 'Zhanyu Ma', 'Jie Cao', 'Jun Guo', 'Yi-Zhe Song']","['Lanzhou University of Technology', 'Beijing University of Posts and Telecommunications', 'University of Surrey', 'Lanzhou University of Technology', 'Beijing University of Posts and Telecommunications', 'Lanzhou University of Technology', 'Beijing University of Posts and Telecommunications', 'University of Surrey']","['CV: Object Detection & Categorization', 'CV: Learning & Optimization for CV', 'CV: Other Foundations of Computer Vision', 'CV: Representation Learning for Vision', 'ML: Classification and Regression', 'ML: Deep Learning Theory', 'ML: Deep Neural Network Algorithms', 'ML: Learning Theory', 'ML: Meta Learning', 'ML: Optimization', 'ML: Representation Learning']","Wu, J., Chang, D., Sain, A., Li, X., Ma, Z., Cao, J., Guo, J., & Song, Y.-Z. (2023). Bi-directional Feature Reconstruction Network for Fine-Grained Few-Shot Image Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2821-2829. https://doi.org/10.1609/aaai.v37i3.25383","Abstract 					The main challenge for fine-grained few-shot image classification is to learn feature representations with higher inter-class and lower intra-class variations, with a mere few labelled samples. Conventional few-shot learning methods however cannot be naively adopted for this fine-grained setting -- a quick pilot study reveals that they in fact push for the opposite (i.e., lower inter-class variations and higher intra-class variations). To alleviate this problem, prior works predominately use a support set to reconstruct the query image and then utilize metric learning to determine its category. Upon careful inspection, we further reveal that such unidirectional reconstruction methods only help to increase inter-class variations and are not effective in tackling intra-class variations. In this paper, we for the first time introduce a bi-reconstruction mechanism that can simultaneously accommodate for inter-class and intra-class variations. In addition to using the support set to reconstruct the query set for increasing inter-class variations, we further use the query set to reconstruct the support set for reducing intra-class variations. This design effectively helps the model to explore more subtle and discriminative features which is key for the fine-grained problem in hand. Furthermore, we also construct a self-reconstruction module to work alongside the bi-directional module to make the features even more discriminative. Experimental results on three widely used fine-grained image classification datasets consistently show considerable improvements compared with other methods. Codes are available at: https://github.com/PRIS-CV/Bi-FRN.","https://ojs.aaai.org/index.php/AAAI/article/view/25383/25155"
"25384","Preserving Structural Consistency in Arbitrary Artist and Artwork Style Transfer","['Jingyu Wu', 'Lefan Hou', 'Zejian Li', 'Jun Liao', 'Li Liu', 'Lingyun Sun']","['Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Zhejiang University', 'Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Zhejiang University', 'School of Software Technology, Zhejiang University\nAlibaba-Zhejiang University Joint Institute of Frontier Technologies, Zhejiang University', 'School of Big Data & Software Engineering, Chongqing University', 'School of Big Data & Software Engineering, Chongqing University', 'Alibaba-Zhejiang University Joint Institute of Frontier Technologies, Zhejiang University\nZhejiang-Singapore Innovation and AI Joint Research Lab']","['CV: Computational Photography', 'Image & Video Synthesis']","Wu, J., Hou, L., Li, Z., Liao, J., Liu, L., & Sun, L. (2023). Preserving Structural Consistency in Arbitrary Artist and Artwork Style Transfer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2830-2838. https://doi.org/10.1609/aaai.v37i3.25384","Abstract 					Deep generative models are effective in style transfer.  Previous methods learn one or several specific artist-style from a collection of artworks. These methods not only homogenize the artist-style of different artworks of the same artist but also lack generalization for the unseen artists. To solve these challenges, we propose a double-style transferring module (DSTM). It extracts different artist-style and artwork-style from different artworks (even untrained) and preserves the intrinsic diversity between different artworks of the same artist. DSTM swaps the two styles in the adversarial training and encourages realistic image generation given arbitrary style combinations. However, learning style from single artwork can often cause over-adaption to it, resulting in the introduction of structural features of style image. We further propose an edge enhancing module (EEM) which derives edge information from multi-scale and multi-level features to enhance structural consistency. We broadly evaluate our method across six large-scale benchmark datasets. Empirical results show that our method achieves arbitrary artist-style and artwork-style extraction from a single artwork, and effectively avoids introducing the style image’s structural features. Our method improves the state-of-the-art deception rate from 58.9% to 67.2% and the average FID from 48.74 to 42.83.","https://ojs.aaai.org/index.php/AAAI/article/view/25384/25156"
"25385","End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge Distillation","['Mingrui Wu', 'Jiaxin Gu', 'Yunhang Shen', 'Mingbao Lin', 'Chao Chen', 'Xiaoshuai Sun']","['Xiamen University\nYoutu Laboratory', 'Baidu Inc.', 'Youtu Laboratory', 'Youtu Laboratory', 'Youtu Laboratory', 'Xiamen University']","['CV: Scene Analysis & Understanding', 'CV: Language and Vision']","Wu, M., Gu, J., Shen, Y., Lin, M., Chen, C., & Sun, X. (2023). End-to-End Zero-Shot HOI Detection via Vision and Language Knowledge Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2839-2846. https://doi.org/10.1609/aaai.v37i3.25385","Abstract 					Most existing Human-Object Interaction (HOI) Detection methods rely heavily on full annotations with predefined HOI categories, which is limited in diversity and costly to scale further. We aim at advancing zero-shot HOI detection to detect both seen and unseen HOIs simultaneously. The fundamental challenges are to discover potential human-object pairs and identify novel HOI categories. To overcome the above challenges, we propose a novel End-to-end zero-shot HOI Detection (EoID) framework via vision-language knowledge distillation. We first design an Interactive Score module combined with a Two-stage Bipartite Matching algorithm to achieve interaction distinguishment for human-object pairs in an action-agnostic manner. Then we transfer the distribution of action probability from the pretrained vision-language teacher as well as the seen ground truth to the HOI model to attain zero-shot HOI classification. Extensive experiments on HICO-Det dataset demonstrate that our model discovers potential interactive pairs and enables the recognition of unseen HOIs. Finally, our method outperforms the previous SOTA under various zero-shot settings. Moreover, our method is generalizable to large-scale object detection data to further scale up the action sets. The source code is available at: https://github.com/mrwu-mac/EoID.","https://ojs.aaai.org/index.php/AAAI/article/view/25385/25157"
"25386","Revisiting Classifier: Transferring Vision-Language Models for Video Recognition","['Wenhao Wu', 'Zhun Sun', 'Wanli Ouyang']","['The University of Sydney, NSW, Australia', 'Baidu Inc., Beijing, China', 'Shanghai Artificial Intelligence Laboratory, Shanghai, China']","['CV: Video Understanding & Activity Analysis', 'CV: Applications', 'CV: Scene Analysis & Understanding', 'CV: Language and Vision']","Wu, W., Sun, Z., & Ouyang, W. (2023). Revisiting Classifier: Transferring Vision-Language Models for Video Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2847-2855. https://doi.org/10.1609/aaai.v37i3.25386","Abstract 					Transferring knowledge from task-agnostic pre-trained deep models for downstream tasks is an important topic in computer vision research. Along with the growth of computational capacity, we now have open-source vision-language pre-trained models in large scales of the model architecture and amount of data. In this study, we focus on transferring knowledge for video classification tasks. Conventional methods randomly initialize the linear classifier head for vision classification, but they leave the usage of the text encoder for downstream visual recognition tasks undiscovered. In this paper, we revise the role of the linear classifier and replace the classifier with the different knowledge from pre-trained model. We utilize the well-pretrained language model to generate good semantic target for efficient transferring learning. The empirical study shows that our method improves both the performance and the training speed of video classification, with a negligible change in the model. Our simple yet effective tuning paradigm achieves state-of-the-art performance and efficient training on various video recognition scenarios, i.e., zero-shot, few-shot, general recognition. In particular, our paradigm achieves the state-of-the-art accuracy of 87.8% on Kinetics-400, and also surpasses previous methods by 20~50% absolute top-1 accuracy under zero-shot, few-shot settings on five video datasets. Code and models are available at https://github.com/whwu95/Text4Vis.","https://ojs.aaai.org/index.php/AAAI/article/view/25386/25158"
"25387","Scene Graph to Image Synthesis via Knowledge Consensus","['Yang Wu', 'Pengxu Wei', 'Liang Lin']","['School of Computer Science and Engineering, Sun Yat-sen University', 'School of Computer Science and Engineering, Sun Yat-sen University', 'School of Computer Science and Engineering, Sun Yat-sen University\nGuangDong Province Key Laboratory of Information Security Technology']","['CV: Applications', 'CV: Computational Photography', 'Image & Video Synthesis', 'CV: Multi-modal Vision', 'CV: Visual Reasoning & Symbolic Representations', 'KRR: Knowledge Engineering']","Wu, Y., Wei, P., & Lin, L. (2023). Scene Graph to Image Synthesis via Knowledge Consensus. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2856-2865. https://doi.org/10.1609/aaai.v37i3.25387","Abstract 					In this paper, we study graph-to-image generation conditioned exclusively on scene graphs, in which we seek to disentangle the veiled semantics between knowledge graphs and images.  While most existing research resorts to laborious auxiliary information such as object layouts or segmentation masks, it is also of interest to unveil the generality of the model with limited supervision, moreover, avoiding extra cross-modal alignments.  To tackle this challenge, we delve into the causality of the adversarial generation process, and reason out a new principle to realize a simultaneous semantic disentanglement with an alignment on target and model distributions.  This principle is named knowledge consensus, which explicitly describes a triangle causal dependency among observed images, graph semantics and hidden visual representations.  The consensus also determines a new graph-to-image generation framework, carried on several adversarial optimization objectives.  Extensive experimental results demonstrate that, even conditioned only on scene graphs, our model surprisingly achieves superior performance on semantics-aware image generation, without losing the competence on manipulating the generation through knowledge graphs.","https://ojs.aaai.org/index.php/AAAI/article/view/25387/25159"
"25388","Synthetic Data Can Also Teach: Synthesizing Effective Data for Unsupervised Visual Representation Learning","['Yawen Wu', 'Zhepeng Wang', 'Dewen Zeng', 'Yiyu Shi', 'Jingtong Hu']","['University of Pittsburgh\nUniversity of Notre Dame', 'George Mason University', 'University of Notre Dame', 'University of Notre Dame', 'University of Pittsburgh']","['CV: Representation Learning for Vision', 'ML: Semi-Supervised Learning', 'ML: Unsupervised & Self-Supervised Learning']","Wu, Y., Wang, Z., Zeng, D., Shi, Y., & Hu, J. (2023). Synthetic Data Can Also Teach: Synthesizing Effective Data for Unsupervised Visual Representation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2866-2874. https://doi.org/10.1609/aaai.v37i3.25388","Abstract 					Contrastive learning (CL), a self-supervised learning approach, can effectively learn visual representations from unlabeled data. Given the CL training data, generative models can be trained to generate synthetic data to supplement the real data. Using both synthetic and real data for CL training has the potential to improve the quality of learned representations. However, synthetic data usually has lower quality than real data, and using synthetic data may not improve CL compared with using real data. To tackle this problem, we propose a data generation framework with two methods to improve CL training by joint sample generation and contrastive learning. The first approach generates hard samples for the main model. The generator is jointly learned with the main model to dynamically customize hard samples based on the training state of the main model. Besides, a pair of data generators are proposed to generate similar but distinct samples as positive pairs. In joint learning, the hardness of a positive pair is progressively increased by decreasing their similarity. Experimental results on multiple datasets show superior accuracy and data efficiency of the proposed data generation methods applied to CL. For example, about 4.0%, 3.5%, and 2.6% accuracy improvements for linear classification are observed on ImageNet-100, CIFAR-100, and CIFAR-10, respectively. Besides, up to 2× data efficiency for linear classification and up to 5× data efficiency for transfer learning are achieved.","https://ojs.aaai.org/index.php/AAAI/article/view/25388/25160"
"25389","Multi-Stream Representation Learning for Pedestrian Trajectory Prediction","['Yuxuan Wu', 'Le Wang', 'Sanping Zhou', 'Jinghai Duan', 'Gang Hua', 'Wei Tang']","[""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", 'Wormpex AI Research', 'University of Illinois at Chicago']","['CV: Video Understanding & Activity Analysis', 'CV: Vision for Robotics & Autonomous Driving', 'CV: Motion & Tracking']","Wu, Y., Wang, L., Zhou, S., Duan, J., Hua, G., & Tang, W. (2023). Multi-Stream Representation Learning for Pedestrian Trajectory Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2875-2882. https://doi.org/10.1609/aaai.v37i3.25389","Abstract 					Forecasting the future trajectory of pedestrians is an important task in computer vision with a range of applications, from security cameras to autonomous driving. It is very challenging because pedestrians not only move individually across time but also interact spatially, and the spatial and temporal information is deeply coupled with one another in a multi-agent scenario. Learning such complex spatio-temporal correlation is a fundamental issue in pedestrian trajectory prediction. Inspired by the procedure that the hippocampus processes and integrates spatio-temporal information to form memories, we propose a novel multi-stream representation learning module to learn complex spatio-temporal features of pedestrian trajectory. Specifically, we learn temporal, spatial and cross spatio-temporal correlation features in three respective pathways and then adaptively integrate these features with learnable weights by a gated network. Besides, we leverage the sparse attention gate to select informative interactions and correlations brought by complex spatio-temporal modeling and reduce complexity of our model. We evaluate our proposed method on two commonly used datasets, i.e. ETH-UCY and SDD, and the experimental results demonstrate our method achieves the state-of-the-art performance. Code: https://github.com/YuxuanIAIR/MSRL-master","https://ojs.aaai.org/index.php/AAAI/article/view/25389/25161"
"25390","Pixel Is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection","['Zhenyu Wu', 'Lin Wang', 'Wei Wang', 'Qing Xia', 'Chenglizhao Chen', 'Aimin Hao', 'Shuo Li']","['State Key Laboratory of Virtual Reality Technology and Systems, Beihang University', 'School of Transportation Science and Engineering, Beihang University', 'Harbin Institute of Technology', 'SenseTime Group Limited', 'China University of Petroleum', 'State Key Laboratory of Virtual Reality Technology and Systems, Beihang University\nPeng Cheng Laboratory', 'Case Western Reserve University']","['CV: Segmentation', 'CV: Low Level & Physics-Based Vision']","Wu, Z., Wang, L., Wang, W., Xia, Q., Chen, C., Hao, A., & Li, S. (2023). Pixel Is All You Need: Adversarial Trajectory-Ensemble Active Learning for Salient Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2883-2891. https://doi.org/10.1609/aaai.v37i3.25390","Abstract 					Although weakly-supervised techniques can reduce the labeling effort, it is unclear whether a saliency model trained with weakly-supervised data (e.g., point annotation) can achieve the equivalent performance of its fully-supervised version. This paper attempts to answer this unexplored question by proving a hypothesis: there is a point-labeled dataset where saliency models trained on it can achieve equivalent performance when trained on the densely annotated dataset. To prove this conjecture, we proposed a novel yet effective adversarial trajectory-ensemble active learning (ATAL). Our contributions are three-fold:  1) Our proposed adversarial attack triggering uncertainty can conquer the overconfidence of existing active learning methods and accurately locate these uncertain pixels. 2) Our proposed trajectory-ensemble uncertainty estimation method maintains the advantages of the ensemble networks while significantly reducing the computational cost. 3) Our proposed relationship-aware diversity sampling algorithm can conquer oversampling while boosting performance. Experimental results show that our ATAL can find such a point-labeled dataset, where a saliency model trained on it obtained 97%-99% performance of its fully-supervised version with only 10 annotated points per image.","https://ojs.aaai.org/index.php/AAAI/article/view/25390/25162"
"25391","Attention-Based Depth Distillation with 3D-Aware Positional Encoding for Monocular 3D Object Detection","['Zizhang Wu', 'Yunzhe Wu', 'Jian Pu', 'Xianzhi Li', 'Xiaoquan Wang']","['ZongmuTech', 'ZongmuTech', 'Fudan University', 'Huazhong University of Science and Technology', 'ZongmuTech']","['CV: 3D Computer Vision', 'CV: Applications']","Wu, Z., Wu, Y., Pu, J., Li, X., & Wang, X. (2023). Attention-Based Depth Distillation with 3D-Aware Positional Encoding for Monocular 3D Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2892-2900. https://doi.org/10.1609/aaai.v37i3.25391","Abstract 					Monocular 3D object detection is a low-cost but challenging task, as it requires generating accurate 3D localization solely from a single image input. Recent developed depth-assisted methods show promising results by using explicit depth maps as intermediate features, which are either precomputed by monocular depth estimation networks or jointly evaluated with 3D object detection. However, inevitable errors from estimated depth priors may lead to misaligned semantic information and 3D localization, hence resulting in feature smearing and suboptimal predictions. To mitigate this issue, we propose ADD, an Attention-based Depth knowledge Distillation framework with 3D-aware positional encoding. Unlike previous knowledge distillation frameworks that adopt stereo- or LiDAR-based teachers, we build up our teacher with identical architecture as the student but with extra ground-truth depth as input. Credit to our teacher design, our framework is seamless, domain-gap free, easily implementable, and is compatible with object-wise ground-truth depth. Specifically, we leverage intermediate features and responses for knowledge distillation. Considering long-range 3D dependencies, we propose 3D-aware self-attention and target-aware cross-attention modules for student adaptation. Extensive experiments are performed to verify the effectiveness of our framework on the challenging KITTI 3D object detection benchmark. We implement our framework on three representative monocular detectors, and we achieve state-of-the-art performance with no additional inference computational cost relative to baseline models. Our code is available at https://github.com/rockywind/ADD.","https://ojs.aaai.org/index.php/AAAI/article/view/25391/25163"
"25392","Skating-Mixer: Long-Term Sport Audio-Visual Modeling with MLPs","['Jingfei Xia', 'Mingchen Zhuge', 'Tiantian Geng', 'Shun Fan', 'Yuantai Wei', 'Zhenyu He', 'Feng Zheng']","['Southern University of Science and Technology\nThe Chinese University of Hong Kong', 'Southern University of Science and Technology\nAI Initiative, King Abdullah University of Science and Technology', 'Southern University of Science and Technology', 'Southern University of Science and Technology', 'Southern University of Science and Technology', 'Harbin Institute of Technology (Shenzhen)', 'Southern University of Science and Technology']","['CV: Multi-modal Vision', 'CV: Applications', 'CV: Video Understanding & Activity Analysis']","Xia, J., Zhuge, M., Geng, T., Fan, S., Wei, Y., He, Z., & Zheng, F. (2023). Skating-Mixer: Long-Term Sport Audio-Visual Modeling with MLPs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2901-2909. https://doi.org/10.1609/aaai.v37i3.25392","Abstract 					Figure skating scoring is challenging because it requires judging players’ technical moves as well as coordination with the background music. Most learning-based methods struggle for two reasons: 1) each move in figure skating changes quickly, hence simply applying traditional frame sampling will lose a lot of valuable information, especially in 3 to 5 minutes lasting videos; 2) prior methods rarely considered the critical audio-visual relationship in their models. Due to these reasons, we introduce a novel architecture, named Skating-Mixer. It extends the MLP framework into a multimodal fashion and effectively learns long-term representations through our designed memory recurrent unit (MRU). Aside from the model, we collected a high-quality audio-visual FS1000 dataset, which contains over 1000 videos on 8 types of programs with 7 different rating metrics, overtaking other datasets in both quantity and diversity. Experiments show the proposed method achieves SOTAs over all major metrics on the public Fis-V and our FS1000 dataset. In addition, we include an analysis applying our method to the recent competitions in Beijing 2022 Winter Olympic Games, proving our method has strong applicability.","https://ojs.aaai.org/index.php/AAAI/article/view/25392/25164"
"25393","SVFI: Spiking-Based Video Frame Interpolation for High-Speed Motion","['Lujie Xia', 'Jing Zhao', 'Ruiqin Xiong', 'Tiejun Huang']","['National Engineering Research Center of Visual Technology (NERCVT), Peking University\nInstitute of Digital Media, School of Computer Science, Peking University', 'National Engineering Research Center of Visual Technology (NERCVT), Peking University\nInstitute of Digital Media, School of Computer Science, Peking University\nNational Computer Network Emergency Response Technical Team/Coordination Center of China', 'National Engineering Research Center of Visual Technology (NERCVT), Peking University\nInstitute of Digital Media, School of Computer Science, Peking University', 'National Engineering Research Center of Visual Technology (NERCVT), Peking University\nInstitute of Digital Media, School of Computer Science, Peking University\nBeijing Academy of Artificial Intelligence']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Low Level & Physics-Based Vision']","Xia, L., Zhao, J., Xiong, R., & Huang, T. (2023). SVFI: Spiking-Based Video Frame Interpolation for High-Speed Motion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2910-2918. https://doi.org/10.1609/aaai.v37i3.25393","Abstract 					Occlusion and motion blur make it challenging to interpolate video frame, since estimating complex motions between two frames is hard and unreliable, especially in highly dynamic scenes. This paper aims to address these issues by exploiting spike stream as auxiliary visual information between frames to synthesize target frames. Instead of estimating motions by optical flow from RGB frames, we present a new dual-modal pipeline adopting both RGB frames and the corresponding spike stream as inputs (SVFI). It extracts the scene structure and objects' outline feature maps of the target frames from spike stream. Those feature maps are fused with the color and texture feature maps extracted from RGB frames to synthesize target frames. Benefited by the spike stream that contains consecutive information between two frames, SVFI can directly extract the information in occlusion and motion blur areas of target frames from spike stream, thus it is more robust than previous optical flow-based methods. Experiments show SVFI outperforms the SOTA methods on wide variety of datasets. For instance, in 7 and 15 frame skip evaluations, it shows up to 5.58 dB and 6.56 dB improvements in terms of PSNR over the corresponding second best methods BMBC and DAIN. SVFI also shows visually impressive performance in real-world scenes.","https://ojs.aaai.org/index.php/AAAI/article/view/25393/25165"
"25394","FEditNet: Few-Shot Editing of Latent Semantics in GAN Spaces","['Mengfei Xia', 'Yezhi Shu', 'Yuji Wang', 'Yu-Kun Lai', 'Qiang Li', 'Pengfei Wan', 'Zhongyuan Wang', 'Yong-Jin Liu']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Cardiff University', 'Kuaishou Technology', 'Kuaishou Technology', 'Kuaishou Technology', 'Tsinghua University']","['CV: Computational Photography', 'Image & Video Synthesis']","Xia, M., Shu, Y., Wang, Y., Lai, Y.-K., Li, Q., Wan, P., Wang, Z., & Liu, Y.-J. (2023). FEditNet: Few-Shot Editing of Latent Semantics in GAN Spaces. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2919-2927. https://doi.org/10.1609/aaai.v37i3.25394","Abstract 					Generative Adversarial networks (GANs) have demonstrated their powerful capability of synthesizing high-resolution images, and great efforts have been made to interpret the semantics in the latent spaces of GANs. However, existing works still have the following limitations: (1) the majority of works rely on either pretrained attribute predictors or large-scale labeled datasets, which are difficult to collect in most cases, and (2) some other methods are only suitable for restricted cases, such as focusing on interpretation of human facial images using prior facial semantics. In this paper, we propose a GAN-based method called FEditNet, aiming to discover latent semantics using very few labeled data without any pretrained predictors or prior knowledge. Specifically, we reuse the knowledge from the pretrained GANs, and by doing so, avoid overfitting during the few-shot training of FEditNet. Moreover, our layer-wise objectives which take content consistency into account also ensure the disentanglement between attributes. Qualitative and quantitative results demonstrate that our method outperforms the state-of-the-art methods on various datasets. The code is available at https://github.com/THU-LYJ-Lab/FEditNet.","https://ojs.aaai.org/index.php/AAAI/article/view/25394/25166"
"25395","Toward Robust Diagnosis: A Contour Attention Preserving Adversarial Defense for COVID-19 Detection","['Kun Xiang', 'Xing Zhang', 'Jinwen She', 'Jinpeng Liu', 'Haohan Wang', 'Shiqi Deng', 'Shancheng Jiang']","['Sun Yat-sen University', 'Shuguang Hospital, Shanghai University of Traditional Chinese Medicine', 'Sun Yat-sen University', 'Sun Yat-sen University', 'University of Illinois Urbana-Champaign', 'Sun Yat-sen University', 'Sun Yat-sen University\nGuangdong Provincial Key Laboratory of Fire Science and Technology']","['CV: Adversarial Attacks & Robustness', 'CV: Applications', 'CV: Medical and Biological Imaging', 'ML: Adversarial Learning & Robustness', 'ML: Applications']","Xiang, K., Zhang, X., She, J., Liu, J., Wang, H., Deng, S., & Jiang, S. (2023). Toward Robust Diagnosis: A Contour Attention Preserving Adversarial Defense for COVID-19 Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2928-2937. https://doi.org/10.1609/aaai.v37i3.25395","Abstract 					As the COVID-19 pandemic puts pressure on healthcare systems worldwide, the computed tomography image based AI diagnostic system has become a sustainable solution for early diagnosis. However, the model-wise vulnerability under adversarial perturbation hinders its deployment in practical situation. The existing adversarial training strategies are difficult to generalized into medical imaging field challenged by complex medical texture features. To overcome this challenge, we propose a Contour Attention Preserving (CAP) method based on lung cavity edge extraction. The contour prior features are injected to attention layer via a parameter regularization and we optimize the robust empirical risk with hybrid distance metric. We then introduce a new cross-nation CT scan dataset to evaluate the generalization capability of the adversarial robustness under distribution shift. Experimental results indicate that the proposed method achieves state-of-the-art performance in multiple adversarial defense and generalization tasks. The code and dataset are available at https://github.com/Quinn777/CAP.","https://ojs.aaai.org/index.php/AAAI/article/view/25395/25167"
"25396","Boosting Semi-Supervised Semantic Segmentation with Probabilistic Representations","['Haoyu Xie', 'Changqi Wang', 'Mingkai Zheng', 'Minjing Dong', 'Shan You', 'Chong Fu', 'Chang Xu']","['Northeastern University', 'Northeastern University', 'The University of Sydney', 'University of Sydney', 'SenseTime', 'Northeastern University', 'University of Sydney']","['CV: Segmentation', 'CV: Representation Learning for Vision', 'ML: Semi-Supervised Learning', 'ML: Unsupervised & Self-Supervised Learning']","Xie, H., Wang, C., Zheng, M., Dong, M., You, S., Fu, C., & Xu, C. (2023). Boosting Semi-Supervised Semantic Segmentation with Probabilistic Representations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2938-2946. https://doi.org/10.1609/aaai.v37i3.25396","Abstract 					Recent breakthroughs in semi-supervised semantic segmentation have been developed through contrastive learning. In prevalent pixel-wise contrastive learning solutions, the model maps pixels to deterministic representations and regularizes them in the latent space. However, there exist inaccurate pseudo-labels which map the ambiguous representations of pixels to the wrong classes due to the limited cognitive ability of the model. In this paper, we define pixel-wise representations from a new perspective of probability theory and propose a Probabilistic Representation Contrastive Learning (PRCL) framework that improves representation quality by taking its probability into consideration. Through modelling the mapping from pixels to representations as the probability via multivariate Gaussian distributions, we can tune the contribution of the ambiguous representations to tolerate the risk of inaccurate pseudo-labels. Furthermore, we define prototypes in the form of distributions, which indicates the confidence of a class, while the point prototype cannot. More- over, we propose to regularize the distribution variance to enhance the reliability of representations. Taking advantage of these benefits, high-quality feature representations can be derived in the latent space, thereby the performance of se- mantic segmentation can be further improved. We conduct sufficient experiment to evaluate PRCL on Pascal VOC and CityScapes to demonstrate its superiority. The code is available at https://github.com/Haoyu-Xie/PRCL.","https://ojs.aaai.org/index.php/AAAI/article/view/25396/25168"
"25397","Less Is More Important: An Attention Module Guided by Probability Density Function for Convolutional Neural Networks","['Jingfen Xie', 'Jian Zhang']","['Peking University Shenzhen Graduate School', 'Peking University Shenzhen Graduate School']","['CV: Representation Learning for Vision', 'CV: Interpretability and Transparency', 'CV: Other Foundations of Computer Vision']","Xie, J., & Zhang, J. (2023). Less Is More Important: An Attention Module Guided by Probability Density Function for Convolutional Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2947-2955. https://doi.org/10.1609/aaai.v37i3.25397","Abstract 					Attention modules, which adaptively weight and refine features according to the importance of the input, have become a critical technique to boost the capability of convolutional neural networks. However, most existing attention modules are heuristic without a sound interpretation, and thus, require empirical engineering to design structure and operators within the modules. To handle the above issue, based on our 'less is more important' observation, we propose an Attention Module guided by Probability Density Function (PDF), dubbed PdfAM, which enjoys a rational motivation and requires few empirical structure designs. Concretely, we observe that pixels with less occurrence are prone to be textural details or foreground objects with much importance to aid vision tasks. Thus, with PDF values adopted as a smooth and anti-noise alternative to the pixel occurrence frequency, we design our PdfAM by first estimating the PDF based on some distribution assumption, and then predicting a 3D attention map via applying a negative correlation between the attention weights and the estimated PDF values. Furthermore, we develop learnable PDF-rescale parameters so as to adaptively transform the estimated PDF and predict a customized negative correlation. Experiments show that our PdfAM consistently boosts various networks under both high- and low-level vision tasks, and also performs favorably against other attention modules in terms of accuracy and convergence.","https://ojs.aaai.org/index.php/AAAI/article/view/25397/25169"
"25398","Mitigating Artifacts in Real-World Video Super-resolution Models","['Liangbin Xie', 'Xintao Wang', 'Shuwei Shi', 'Jinjin Gu', 'Chao Dong', 'Ying Shan']","['Shenzhen Institutes of Advanced Technology, Chinese Academy of Sciences, China', 'Tencent', 'Tsinghua University', 'The University of Sydney', 'SIAT', 'Tencent']","['CV: Low Level & Physics-Based Vision']","Xie, L., Wang, X., Shi, S., Gu, J., Dong, C., & Shan, Y. (2023). Mitigating Artifacts in Real-World Video Super-resolution Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2956-2964. https://doi.org/10.1609/aaai.v37i3.25398","Abstract 					The recurrent structure is a prevalent framework for the task of video super-resolution, which models the temporal dependency between frames via hidden states. When applied to real-world scenarios with unknown and complex degradations, hidden states tend to contain unpleasant artifacts and propagate them to restored frames. In this circumstance, our analyses show that such artifacts can be largely alleviated when the hidden state is replaced with a cleaner counterpart. Based on the observations, we propose a Hidden State Attention (HSA) module to mitigate artifacts in real-world video super-resolution. Specifically, we first adopt various cheap filters to produce a hidden state pool. For example, Gaussian blur filters are for smoothing artifacts while sharpening filters are for enhancing details. To aggregate a new hidden state that contains fewer artifacts from the hidden state pool, we devise a Selective Cross Attention (SCA) module, in which the attention between input features and each hidden state is calculated. Equipped with HSA, our proposed method, namely FastRealVSR, is able to achieve 2x speedup while obtaining better performance than Real-BasicVSR. Codes will be available at https://github.com/TencentARC/FastRealVSR.","https://ojs.aaai.org/index.php/AAAI/article/view/25398/25170"
"25399","Just Noticeable Visual Redundancy Forecasting: A Deep Multimodal-Driven Approach","['Wuyuan Xie', 'Shukang Wang', 'Sukun Tian', 'Lirong Huang', 'Ye Liu', 'Miaohui Wang']","['Shenzhen University', 'Shenzhen University', 'Peking University', 'Shenzhen University', 'Nanjing University of Posts and Telecommunications', 'Shenzhen University']","['CV: Applications', 'CMS: Brain Modeling', 'CV: Low Level & Physics-Based Vision', 'CV: Multi-modal Vision']","Xie, W., Wang, S., Tian, S., Huang, L., Liu, Y., & Wang, M. (2023). Just Noticeable Visual Redundancy Forecasting: A Deep Multimodal-Driven Approach. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2965-2973. https://doi.org/10.1609/aaai.v37i3.25399","Abstract 					Just noticeable difference (JND) refers to the maximum visual change that human eyes cannot perceive, and it has a wide range of applications in multimedia systems. However, most existing JND approaches only focus on a single modality, and rarely consider the complementary effects of multimodal information. In this article, we investigate the JND modeling from an end-to-end homologous multimodal perspective, namely hmJND-Net. Specifically, we explore three important visually sensitive modalities, including saliency, depth, and segmentation. To better utilize homologous multimodal information, we establish an effective fusion method via summation enhancement and subtractive offset, and align homologous multimodal features based on a self-attention driven encoder-decoder paradigm. Extensive experimental results on eight different benchmark datasets validate the superiority of our hmJND-Net over eight representative methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25399/25171"
"25400","Cross-Modal Contrastive Learning for Domain Adaptation in 3D Semantic Segmentation","['Bowei Xing', 'Xianghua Ying', 'Ruibin Wang', 'Jinfa Yang', 'Taiyan Chen']","['Peking University', 'Peking University', 'Peking University', 'Peking University', 'Peking University']","['CV: 3D Computer Vision', 'CV: Applications', 'CV: Multi-modal Vision', 'CV: Segmentation', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Xing, B., Ying, X., Wang, R., Yang, J., & Chen, T. (2023). Cross-Modal Contrastive Learning for Domain Adaptation in 3D Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2974-2982. https://doi.org/10.1609/aaai.v37i3.25400","Abstract 					Domain adaptation for 3D point cloud has attracted a lot of interest since it can avoid the time-consuming labeling process of 3D data to some extent. A recent work named xMUDA leveraged multi-modal data to domain adaptation task of 3D semantic segmentation by mimicking the predictions between 2D and 3D modalities, and outperformed the previous single modality methods only using point clouds. Based on it, in this paper, we propose a novel cross-modal contrastive learning scheme to further improve the adaptation effects. By employing constraints from the correspondences between 2D pixel features and 3D point features, our method not only facilitates interaction between the two different modalities, but also boosts feature representations in both labeled source domain and unlabeled target domain. Meanwhile, to sufficiently utilize 2D context information for domain adaptation through cross-modal learning, we introduce a neighborhood feature aggregation module to enhance pixel features. The module employs neighborhood attention to aggregate nearby pixels in the 2D image, which relieves the mismatching between the two different modalities, arising from projecting relative sparse point cloud to dense image pixels. We evaluate our method on three unsupervised domain adaptation scenarios, including country-to-country, day-to-night, and dataset-to-dataset. Experimental results show that our approach outperforms existing methods, which demonstrates the effectiveness of the proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/25400/25172"
"25401","ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient Self-Supervised Monocular Depth Estimation","['Daitao Xing', 'Jinglin Shen', 'Chiuman Ho', 'Anthony Tzes']","['New York University', 'OPPO US Research Center', 'OPPO US Research Center', 'New York University Abu Dhabi and Center for Artificial Intelligence and Robotics']","['CV: Representation Learning for Vision', 'CV: 3D Computer Vision', 'CV: Scene Analysis & Understanding', 'CV: Segmentation', 'ML: Multimodal Learning', 'ML: Representation Learning', 'ML: Semi-Supervised Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Unsupervised & Self-Supervised Learning']","Xing, D., Shen, J., Ho, C., & Tzes, A. (2023). ROIFormer: Semantic-Aware Region of Interest Transformer for Efficient Self-Supervised Monocular Depth Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2983-2991. https://doi.org/10.1609/aaai.v37i3.25401","Abstract 					The exploration of mutual-benefit cross-domains has shown great potential toward accurate self-supervised depth estimation. In this work, we revisit feature fusion between depth and semantic information and propose an efficient local adaptive attention method for geometric aware representation enhancement. Instead of building global connections or deforming attention across the feature space without restraint, we bound the spatial interaction within a learnable region of interest. In particular, we leverage geometric cues from semantic information to learn local adaptive bounding boxes to guide unsupervised feature aggregation. The local areas preclude most irrelevant reference points from attention space, yielding more selective feature learning and faster convergence. We naturally extend the paradigm into a multi-head and hierarchic way to enable the information distillation in different semantic levels and improve the feature discriminative ability for fine-grained depth estimation. Extensive experiments on the KITTI dataset show that our proposed method establishes a new state-of-the-art in self-supervised monocular depth estimation task, demonstrating the effectiveness of our approach over former Transformer variants.","https://ojs.aaai.org/index.php/AAAI/article/view/25401/25173"
"25402","LORE: Logical Location Regression Network for Table Structure Recognition","['Hangdi Xing', 'Feiyu Gao', 'Rujiao Long', 'Jiajun Bu', 'Qi Zheng', 'Liangcheng Li', 'Cong Yao', 'Zhi Yu']","['Zhejiang Provincial Key Laboratory of Service Robot, College of Computer Science, Zhejiang University', 'DAMO Academy, Alibaba Group, Hangzhou, China', 'DAMO Academy, Alibaba Group, Hangzhou, China', 'Zhejiang Provincial Key Laboratory of Service Robot, College of Computer Science, Zhejiang University', 'DAMO Academy, Alibaba Group, Hangzhou, China', 'Zhejiang Provincial Key Laboratory of Service Robot, College of Computer Science, Zhejiang University', 'DAMO Academy, Alibaba Group, Hangzhou, China', 'Zhejiang Provincial Key Laboratory of Service Robot, School of Software Technology, Zhejiang University']","['CV: Object Detection & Categorization', 'CV: Scene Analysis & Understanding']","Xing, H., Gao, F., Long, R., Bu, J., Zheng, Q., Li, L., Yao, C., & Yu, Z. (2023). LORE: Logical Location Regression Network for Table Structure Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 2992-3000. https://doi.org/10.1609/aaai.v37i3.25402","Abstract 					Table structure recognition (TSR) aims at extracting tables in images into machine-understandable formats. Recent methods solve this problem by predicting the adjacency relations of detected cell boxes, or learning to generate the corresponding markup sequences from the table images. However, they either count on additional heuristic rules to recover the table structures, or require a huge amount of training data and time-consuming sequential decoders. In this paper, we propose an alternative paradigm. We model TSR as a logical location regression problem and propose a new TSR framework called LORE, standing for LOgical location REgression network, which for the first time combines logical location regression together with spatial location regression of table cells. Our proposed LORE is conceptually simpler, easier to train and more accurate than previous TSR models of other paradigms. Experiments on standard benchmarks demonstrate that LORE consistently outperforms prior arts. Code is available at https:// github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/DocumentUnderstanding/LORE-TSR.","https://ojs.aaai.org/index.php/AAAI/article/view/25402/25174"
"25403","Revisiting the Spatial and Temporal Modeling for Few-Shot Action Recognition","['Jiazheng Xing', 'Mengmeng Wang', 'Yong Liu', 'Boyu Mu']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University']","['CV: Image and Video Retrieval', 'CV: Representation Learning for Vision', 'CV: Video Understanding & Activity Analysis']","Xing, J., Wang, M., Liu, Y., & Mu, B. (2023). Revisiting the Spatial and Temporal Modeling for Few-Shot Action Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3001-3009. https://doi.org/10.1609/aaai.v37i3.25403","Abstract 					Spatial and temporal modeling is one of the most core aspects of few-shot action recognition. Most previous works mainly focus on long-term temporal relation modeling based on high-level spatial representations, without considering the crucial low-level spatial features and short-term temporal relations. Actually, the former feature could bring rich local semantic information, and the latter feature could represent motion characteristics of adjacent frames, respectively. In this paper, we propose SloshNet, a new framework that revisits the spatial and temporal modeling for few-shot action recognition in a finer manner. First, to exploit the low-level spatial features, we design a feature fusion architecture search module to automatically search for the best combination of the low-level and high-level spatial features. Next, inspired by the recent transformer, we introduce a long-term temporal modeling module to model the global temporal relations based on the extracted spatial appearance features. Meanwhile, we design another short-term temporal modeling module to encode the motion characteristics between adjacent frame representations. After that, the final predictions can be obtained by feeding the embedded rich spatial-temporal features to a common frame-level class prototype matcher. We extensively validate the proposed SloshNet on four few-shot action recognition datasets, including Something-Something V2, Kinetics, UCF101, and HMDB51. It achieves favorable results against state-of-the-art methods in all datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25403/25175"
"25404","Unsupervised Multi-Exposure Image Fusion Breaking Exposure Limits via Contrastive Learning","['Han Xu', 'Liang Haochen', 'Jiayi Ma']","['Wuhan University', 'Wuhan University', 'Wuhan University']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Low Level & Physics-Based Vision', 'CV: Multi-modal Vision']","Xu, H., Haochen, L., & Ma, J. (2023). Unsupervised Multi-Exposure Image Fusion Breaking Exposure Limits via Contrastive Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3010-3017. https://doi.org/10.1609/aaai.v37i3.25404","Abstract 					This paper proposes an unsupervised multi-exposure image fusion (MEF) method via contrastive learning, termed as MEF-CL. It breaks exposure limits and performance bottleneck faced by existing methods. MEF-CL firstly designs similarity constraints to preserve contents in source images. It eliminates the need for ground truth (actually not exist and created artificially) and thus avoids negative impacts of inappropriate ground truth on performance and generalization. Moreover, we explore a latent feature space and apply contrastive learning in this space to guide fused image to approximate normal-light samples and stay away from inappropriately exposed ones. In this way, characteristics of fused images (e.g., illumination, colors) can be further improved without being subject to source images. Therefore, MEF-CL is applicable to image pairs of any multiple exposures rather than a pair of under-exposed and over-exposed images mandated by existing methods. By alleviating dependence on source images, MEF-CL shows better generalization for various scenes. Consequently, our results exhibit appropriate illumination, detailed textures, and saturated colors. Qualitative, quantitative, and ablation experiments validate the superiority and generalization of MEF-CL. Our code is publicly available at https://github.com/hanna-xu/MEF-CL.","https://ojs.aaai.org/index.php/AAAI/article/view/25404/25176"
"25405","CasFusionNet: A Cascaded Network for Point Cloud Semantic Scene Completion by Dense Feature Fusion","['Jinfeng Xu', 'Xianzhi Li', 'Yuan Tang', 'Qiao Yu', 'Yixue Hao', 'Long Hu', 'Min Chen']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology']","['CV: 3D Computer Vision', 'CV: Applications', 'CV: Scene Analysis & Understanding', 'CV: Segmentation', 'CV: Vision for Robotics & Autonomous Driving', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms']","Xu, J., Li, X., Tang, Y., Yu, Q., Hao, Y., Hu, L., & Chen, M. (2023). CasFusionNet: A Cascaded Network for Point Cloud Semantic Scene Completion by Dense Feature Fusion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3018-3026. https://doi.org/10.1609/aaai.v37i3.25405","Abstract 					Semantic scene completion (SSC) aims to complete a partial 3D scene and predict its semantics simultaneously. Most existing works adopt the voxel representations, thus suffering from the growth of memory and computation cost as the voxel resolution increases. Though a few works attempt to solve SSC from the perspective of 3D point clouds, they have not fully exploited the correlation and complementarity between the two tasks of scene completion and semantic segmentation. In our work, we present CasFusionNet, a novel cascaded network for point cloud semantic scene completion by dense feature fusion. Specifically, we design (i) a global completion module (GCM) to produce an upsampled and completed but coarse point set, (ii) a semantic segmentation module (SSM) to predict the per-point semantic labels of the completed points generated by GCM, and (iii) a local refinement module (LRM) to further refine the coarse completed points and the associated labels from a local perspective. We organize the above three modules via dense feature fusion in each level, and cascade a total of four levels, where we also employ feature fusion between each level for sufficient information usage. Both quantitative and qualitative results on our compiled two point-based datasets validate the effectiveness and superiority of our CasFusionNet compared to state-of-the-art methods in terms of both scene completion and semantic segmentation. The codes and datasets are available at: https://github.com/JinfengX/CasFusionNet.","https://ojs.aaai.org/index.php/AAAI/article/view/25405/25177"
"25406","Learning a Generalized Gaze Estimator from Gaze-Consistent Feature","['Mingjie Xu', 'Haofei Wang', 'Feng Lu']","['Beihang University', 'Peng Cheng Laboratory', 'Beihang University\nPeng Cheng Laboratory']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'CV: Adversarial Attacks & Robustness']","Xu, M., Wang, H., & Lu, F. (2023). Learning a Generalized Gaze Estimator from Gaze-Consistent Feature. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3027-3035. https://doi.org/10.1609/aaai.v37i3.25406","Abstract 					Gaze estimator computes the gaze direction based on face images. Most existing gaze estimation methods perform well under within-dataset settings, but can not generalize to unseen domains. In particular, the ground-truth labels in unseen domain are often unavailable. In this paper, we propose a new domain generalization method based on gaze-consistent features. Our idea is to consider the gaze-irrelevant factors as unfavorable interference and disturb the training data against them, so that the model cannot fit to these gaze-irrelevant factors, instead, only fits to the gaze-consistent features. To this end, we first disturb the training data via adversarial attack or data augmentation based on the gaze-irrelevant factors, i.e., identity, expression, illumination and tone. Then we extract the gaze-consistent features by aligning the gaze features from disturbed data with non-disturbed gaze features. Experimental results show that our proposed method achieves state-of-the-art performance on gaze domain generalization task. Furthermore, our proposed method also improves domain adaption performance on gaze estimation. Our work provides new insight on gaze domain generalization task.","https://ojs.aaai.org/index.php/AAAI/article/view/25406/25178"
"25407","Class Overwhelms: Mutual Conditional Blended-Target Domain Adaptation","['Pengcheng Xu', 'Boyu Wang', 'Charles Ling']","['Western University, London, ON N6A 5B7, Canada', 'Western University, London, ON N6A 5B7, Canada\nVector Institute, Toronto, ON M5G 1M1, Canada', 'Western University, London, ON N6A 5B7, Canada']","['CV: Applications', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Xu, P., Wang, B., & Ling, C. (2023). Class Overwhelms: Mutual Conditional Blended-Target Domain Adaptation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3036-3044. https://doi.org/10.1609/aaai.v37i3.25407","Abstract 					Current methods of blended targets domain adaptation (BTDA) usually infer or consider domain label information but underemphasize hybrid categorical feature structures of targets, which yields limited performance, especially under the label distribution shift. We demonstrate that domain labels are not directly necessary for BTDA if categorical distributions of various domains are sufficiently aligned even facing the imbalance of domains and the label distribution shift of classes. However, we observe that the cluster assumption in BTDA does not comprehensively hold. The hybrid categorical feature space hinders the modeling of categorical distributions and the generation of reliable pseudo labels for categorical alignment. To address these, we propose a categorical domain discriminator guided by uncertainty to explicitly model and directly align categorical distributions P(Z|Y). Simultaneously, we utilize the low-level features to augment the single source features with diverse target styles to rectify the biased classifier P(Y|Z) among diverse targets. Such a mutual conditional alignment of P(Z|Y) and P(Y|Z) forms a mutual reinforced mechanism. Our approach outperforms the state-of-the-art in BTDA even compared with methods utilizing domain labels, especially under the label distribution shift, and in single target DA on DomainNet.","https://ojs.aaai.org/index.php/AAAI/article/view/25407/25179"
"25408","Self Correspondence Distillation for End-to-End Weakly-Supervised Semantic Segmentation","['Rongtao Xu', 'Changwei Wang', 'Jiaxi Sun', 'Shibiao Xu', 'Weiliang Meng', 'Xiaopeng Zhang']","['Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence,University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'School of Artificial Intelligence, Beijing University of Posts and Telecommunications', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence,University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences']","['CV: Representation Learning for Vision', 'CV: Scene Analysis & Understanding', 'ML: Deep Neural Network Algorithms', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning']","Xu, R., Wang, C., Sun, J., Xu, S., Meng, W., & Zhang, X. (2023). Self Correspondence Distillation for End-to-End Weakly-Supervised Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3045-3053. https://doi.org/10.1609/aaai.v37i3.25408","Abstract 					Efficiently training accurate deep models for weakly supervised semantic segmentation (WSSS) with image-level labels is challenging and important. Recently, end-to-end WSSS methods have become the focus of research due to their high training efficiency. However, current methods suffer from insufficient extraction of comprehensive semantic information, resulting in low-quality pseudo-labels and sub-optimal solutions for end-to-end WSSS. To this end, we propose a simple and novel Self Correspondence Distillation (SCD) method to refine pseudo-labels without introducing external supervision. Our SCD enables the network to utilize feature correspondence derived from itself as a distillation target, which can enhance the network's feature learning process by complementing semantic information. In addition, to further improve the segmentation accuracy, we design a Variation-aware Refine Module to enhance the local consistency of pseudo-labels by computing pixel-level variation. Finally, we present an efficient end-to-end Transformer-based framework (TSCD) via SCD and Variation-aware Refine Module for the accurate WSSS task. Extensive experiments on the PASCAL VOC 2012 and MS COCO 2014 datasets demonstrate that our method significantly outperforms other state-of-the-art methods.  Our code is available at https://github.com/Rongtao-Xu/RepresentationLearning/tree/main/SCD-AAAI2023.","https://ojs.aaai.org/index.php/AAAI/article/view/25408/25180"
"25409","Deep Parametric 3D Filters for Joint Video Denoising and Illumination Enhancement in Video Super Resolution","['Xiaogang Xu', 'Ruixing Wang', 'Chi-Wing Fu', 'Jiaya Jia']","['The Chinese University of Hong Kong\nSmartMore', 'SmartMore', 'The Chinese University of Hong Kong', 'The Chinese University of Hong Kong\nSmartMore']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Low Level & Physics-Based Vision']","Xu, X., Wang, R., Fu, C.-W., & Jia, J. (2023). Deep Parametric 3D Filters for Joint Video Denoising and Illumination Enhancement in Video Super Resolution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3054-3062. https://doi.org/10.1609/aaai.v37i3.25409","Abstract 					Despite the quality improvement brought by the recent methods, video super-resolution (SR) is still very challenging, especially for videos that are low-light and noisy. The current best solution is to subsequently employ best models of video SR, denoising, and illumination enhancement, but doing so often lowers the image quality, due to the inconsistency between the models. This paper presents a new parametric representation called the Deep Parametric 3D Filters (DP3DF), which incorporates local spatiotemporal information to enable simultaneous denoising, illumination enhancement, and SR efficiently in a single encoder-and-decoder network. Also, a dynamic residual frame is jointly learned with the DP3DF via a shared backbone to further boost the SR quality. We performed extensive experiments, including a large-scale user study, to show our method's effectiveness. Our method consistently surpasses the best state-of-the-art methods on all the challenging real datasets with top PSNR and user ratings, yet having a very fast run time. The code is available at https://github.com/xiaogang00/DP3DF.","https://ojs.aaai.org/index.php/AAAI/article/view/25409/25181"
"25410","Inter-image Contrastive Consistency for Multi-Person Pose Estimation","['Xixia Xu', 'Yingguo Gao', 'Xingjia Pan', 'Ke Yan', 'Xiaoyu Chen', 'Qi Zou']","['Beijing Jiaotong University', 'Tencent', 'Tencent', 'Tencent', 'Beijing Jiaotong University', 'Beijing Jiaotong University']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Object Detection & Categorization', 'CV: Representation Learning for Vision', 'CV: Video Understanding & Activity Analysis']","Xu, X., Gao, Y., Pan, X., Yan, K., Chen, X., & Zou, Q. (2023). Inter-image Contrastive Consistency for Multi-Person Pose Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3063-3071. https://doi.org/10.1609/aaai.v37i3.25410","Abstract 					Multi-person pose estimation (MPPE) has achieved impressive progress in recent years. However, due to the large variance of appearances among images or occlusions, the model can hardly learn consistent patterns enough, which leads to severe location jitter and missing issues. In this study, we propose a novel framework, termed Inter-image Contrastive consistency (ICON), to strengthen the keypoint consistency among images for MPPE. Concretely, we consider two-fold consistency constraints, which include single keypoint contrastive consistency (SKCC) and pair relation contrastive consistency (PRCC). The SKCC learns to strengthen the consistency of individual keypoints across images in the same category to improve the category-specific robustness. Only with SKCC, the model can effectively reduce location errors caused by large appearance variations, but remains challenging with extreme postures (e.g., occlusions) due to lack of relational guidance. Therefore, PRCC is proposed to strengthen the consistency of pair-wise joint relation between images to preserve the instructive relation. Cooperating with SKCC, PRCC further improves structure aware robustness in handling extreme postures. Extensive experiments on kinds of architectures across three datasets (i.e., MS-COCO, MPII, CrowdPose) show the proposed ICON achieves substantial improvements over baselines. Furthermore, ICON under the semi-supervised setup can obtain comparable results with the fully-supervised methods using only 30% labeled data.","https://ojs.aaai.org/index.php/AAAI/article/view/25410/25182"
"25411","DeMT: Deformable Mixer Transformer for Multi-Task Learning of Dense Prediction","['Yangyang Xu', 'Yibo Yang', 'Lefei Zhang']","['National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, China', 'JD Explore Academy, China', 'National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, China\nHubei Luojia Laboratory, China']","['CV: Scene Analysis & Understanding', 'CV: Representation Learning for Vision']","Xu, Y., Yang, Y., & Zhang, L. (2023). DeMT: Deformable Mixer Transformer for Multi-Task Learning of Dense Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3072-3080. https://doi.org/10.1609/aaai.v37i3.25411","Abstract 					Convolution neural networks (CNNs) and Transformers have their own advantages and both have been widely used for dense prediction in multi-task learning (MTL). Most of the current studies on MTL solely rely on CNN or Transformer. In this work, we present a novel MTL model by combining both merits of deformable CNN and query-based Transformer for multi-task learning of dense prediction. Our method, named DeMT, is based on a simple and effective encoder-decoder architecture (i.e., deformable mixer encoder and task-aware transformer decoder). First, the deformable mixer encoder contains two types of operators: the channel-aware mixing operator leveraged to allow communication among different channels (i.e., efficient channel location mixing), and the spatial-aware deformable operator with deformable convolution applied to efficiently sample more informative spatial locations (i.e., deformed features). Second, the task-aware transformer decoder consists of the task interaction block and task query block. The former is applied to capture task interaction features via self-attention. The latter leverages the deformed features and task-interacted features to generate the corresponding task-specific feature through a query-based Transformer for corresponding task predictions. Extensive experiments on two dense image prediction datasets, NYUD-v2 and PASCAL-Context, demonstrate that our model uses fewer GFLOPs and significantly outperforms current Transformer- and CNN-based competitive models on a variety of metrics. The code is available at https://github.com/yangyangxu0/DeMT.","https://ojs.aaai.org/index.php/AAAI/article/view/25411/25183"
"25412","VLTinT: Visual-Linguistic Transformer-in-Transformer for Coherent Video Paragraph Captioning","['Kashu Yamazaki', 'Khoa Vo', 'Quang Sang Truong', 'Bhiksha Raj', 'Ngan Le']","['University of Arkansas', 'University of Arkansas', 'University of Arkansas', 'Carnegie Mellon University\nMohammed bin Zayed University of AI', 'University of Arkansas']","['CV: Applications', 'CV: Language and Vision', 'CV: Multi-modal Vision', 'CV: Video Understanding & Activity Analysis']","Yamazaki, K., Vo, K., Truong, Q. S., Raj, B., & Le, N. (2023). VLTinT: Visual-Linguistic Transformer-in-Transformer for Coherent Video Paragraph Captioning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3081-3090. https://doi.org/10.1609/aaai.v37i3.25412","Abstract 					Video Paragraph Captioning aims to generate a multi-sentence description of an untrimmed video with multiple temporal event locations in a coherent storytelling.  Following the human perception process, where the scene is effectively understood by decomposing it into visual (e.g. human, animal) and non-visual components (e.g. action, relations) under the mutual influence of vision and language, we first propose a visual-linguistic (VL) feature. In the proposed VL feature, the scene is modeled by three modalities including (i) a global visual environment; (ii) local visual main agents; (iii) linguistic scene elements. We then introduce an autoregressive Transformer-in-Transformer (TinT) to simultaneously capture the semantic coherence of intra- and inter-event contents within a video. Finally, we present a new VL contrastive loss function to guarantee the learnt embedding features are consistent with the captions semantics. Comprehensive experiments and extensive ablation studies on the ActivityNet Captions and YouCookII datasets show that the proposed Visual-Linguistic Transformer-in-Transform (VLTinT) outperforms previous state-of-the-art methods in terms of accuracy and diversity. The source code is made publicly available at: https://github.com/UARK-AICV/VLTinT.","https://ojs.aaai.org/index.php/AAAI/article/view/25412/25184"
"25413","Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity","['Qingsong Yan', 'Qiang Wang', 'Kaiyong Zhao', 'Bo Li', 'Xiaowen Chu', 'Fei Deng']","['Wuhan University, Wuhan, China\nThe Hong Kong University of Science and Technology, Hong Kong SAR, China', 'Harbin Institute of Technology (Shenzhen), Shenzhen, China', 'XGRIDS, Shenzhen, China', 'The Hong Kong University of Science and Technology, Hong Kong SAR, China', 'The Hong Kong University of Science and Technology (Guangzhou), Guangzhou, China\nThe Hong Kong University of Science and Technology, Hong Kong SAR, China', 'Wuhan University']","['CV: 3D Computer Vision', 'CV: Vision for Robotics & Autonomous Driving']","Yan, Q., Wang, Q., Zhao, K., Li, B., Chu, X., & Deng, F. (2023). Rethinking Disparity: A Depth Range Free Multi-View Stereo Based on Disparity. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3091-3099. https://doi.org/10.1609/aaai.v37i3.25413","Abstract 					Existing learning-based multi-view stereo (MVS) methods rely on the depth range to build the 3D cost volume and may fail when the range is too large or unreliable. To address this problem, we propose a disparity-based MVS method based on the epipolar disparity flow (E-flow), called DispMVS, which infers the depth information from the pixel movement between two views. The core of DispMVS is to construct a 2D cost volume on the image plane along the epipolar line between each pair (between the reference image and several source images) for pixel matching and fuse uncountable depths triangulated from each pair by multi-view geometry to ensure multi-view consistency. To be robust, DispMVS starts from a randomly initialized depth map and iteratively refines the depth map with the help of the coarse-to-fine strategy. Experiments on DTUMVS and Tanks\&Temple datasets show that DispMVS is not sensitive to the depth range and achieves state-of-the-art results with lower GPU memory.","https://ojs.aaai.org/index.php/AAAI/article/view/25413/25185"
"25414","Video-Text Pre-training with Learned Regions for Retrieval","['Rui Yan', 'Mike Zheng Shou', 'Yixiao Ge', 'Jinpeng Wang', 'Xudong Lin', 'Guanyu Cai', 'Jinhui Tang']","['Nanjing University of Science and Technology', 'National University of Singapore', 'Tencent PCG', 'National University of Singapore', 'Columbia University', 'Tongji University', 'Nanjing University of Science and Technology']","['CV: Image and Video Retrieval', 'CV: Language and Vision', 'CV: Multi-modal Vision', 'CV: Video Understanding & Activity Analysis']","Yan, R., Shou, M. Z., Ge, Y., Wang, J., Lin, X., Cai, G., & Tang, J. (2023). Video-Text Pre-training with Learned Regions for Retrieval. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3100-3108. https://doi.org/10.1609/aaai.v37i3.25414","Abstract 					Video-Text pre-training aims at learning transferable representations from large-scale video-text pairs via aligning the semantics between visual and textual information. State-of-the-art approaches extract visual features from raw pixels in an end-to-end fashion. However, these methods operate at frame-level directly and thus overlook the spatio-temporal structure of objects in video, which yet has a strong synergy with nouns in textual descriptions. In this work, we propose a simple yet effective module for video-text representation learning, namely RegionLearner, which can take into account the structure of objects during pre-training on large-scale video-text pairs. Given a video, our module (1) first quantizes continuous visual features via clustering patch-features into the same cluster according to content similarity, then (2) generates learnable masks to aggregate fragmentary features into regions with complete semantics, and finally (3) models the spatio-temporal dependencies between different semantic regions. In contrast to using off-the-shelf object detectors, our proposed module does not require explicit supervision and is much more computationally efficient. We pre-train the proposed approach on the public WebVid2M and CC3M datasets. Extensive evaluations on four downstream video-text retrieval benchmarks clearly demonstrate the effectiveness of our RegionLearner.","https://ojs.aaai.org/index.php/AAAI/article/view/25414/25186"
"25415","DesNet: Decomposed Scale-Consistent Network for Unsupervised Depth Completion","['Zhiqiang Yan', 'Kun Wang', 'Xiang Li', 'Zhenyu Zhang', 'Jun Li', 'Jian Yang']","['Nanjing University of Science and Tenchnology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology']","['CV: Multi-modal Vision', 'CV: Vision for Robotics & Autonomous Driving']","Yan, Z., Wang, K., Li, X., Zhang, Z., Li, J., & Yang, J. (2023). DesNet: Decomposed Scale-Consistent Network for Unsupervised Depth Completion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3109-3117. https://doi.org/10.1609/aaai.v37i3.25415","Abstract 					Unsupervised depth completion aims to recover dense depth from the sparse one without using the ground-truth annotation. Although depth measurement obtained from LiDAR is usually sparse, it contains valid and real distance information, i.e., scale-consistent absolute depth values. Meanwhile, scale-agnostic counterparts seek to estimate relative depth and have achieved impressive performance. To leverage both the inherent characteristics, we thus suggest to model scale-consistent depth upon unsupervised scale-agnostic frameworks. Specifically, we propose the decomposed scale-consistent learning (DSCL) strategy, which disintegrates the absolute depth into relative depth prediction and global scale estimation, contributing to individual learning benefits. But unfortunately, most existing unsupervised scale-agnostic frameworks heavily suffer from depth holes due to the extremely sparse depth input and weak supervisory signal. To tackle this issue, we introduce the global depth guidance (GDG) module, which attentively propagates dense depth reference into the sparse target via novel dense-to-sparse attention. Extensive experiments show the superiority of our method on outdoor KITTI, ranking 1st and outperforming the best KBNet more than 12% in RMSE. Additionally, our approach achieves state-of-the-art performance on indoor NYUv2 benchmark as well.","https://ojs.aaai.org/index.php/AAAI/article/view/25415/25187"
"25416","Self-Supervised Video Representation Learning via Latent Time Navigation","['Di Yang', 'Yaohui Wang', 'Quan Kong', 'Antitza Dantcheva', 'Lorenzo Garattoni', 'Gianpiero Francesca', 'François Brémond']","['Inria, 2004 Rte des Lucioles, Valbonne, France\nUniversite Cote d’Azur, 28 Av. de Valrose, Nice, France', 'Inria, 2004 Rte des Lucioles, Valbonne, France\nUniversite Cote d’Azur, 28 Av. de Valrose, Nice, France\nShanghai AI Laboratory, 701 Yunjin Road, Shanghai, China', 'Woven Planet Holdings, 3-2-1 Nihonbashimuromachi, Chuo-ku, Tokyo, Japan', 'Inria, 2004 Rte des Lucioles, Valbonne, France\nUniversite Cote d’Azur, 28 Av. de Valrose, Nice, France', 'Toyota Motor Europe, 60 Av. du Bourget, Brussels, Belgium', 'Toyota Motor Europe, 60 Av. du Bourget, Brussels, Belgium', 'Inria, 2004 Rte des Lucioles, Valbonne, France\nUniversite Cote d’Azur, 28 Av. de Valrose, Nice, France']","['CV: Video Understanding & Activity Analysis']","Yang, D., Wang, Y., Kong, Q., Dantcheva, A., Garattoni, L., Francesca, G., & Brémond, F. (2023). Self-Supervised Video Representation Learning via Latent Time Navigation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3118-3126. https://doi.org/10.1609/aaai.v37i3.25416","Abstract 					Self-supervised video representation learning aimed at maximizing similarity between different temporal segments of one video, in order to enforce feature persistence over time. This leads to loss of pertinent information related to temporal relationships, rendering actions such as `enter' and `leave' to be indistinguishable. To mitigate this limitation, we propose Latent Time Navigation (LTN), a time parameterized contrastive learning strategy that is streamlined to capture fine-grained motions. Specifically, we maximize the representation similarity between different video segments from one video, while maintaining their representations time-aware along a subspace of the latent representation code including an orthogonal basis to represent temporal changes. Our extensive experimental analysis suggests that learning video representations by LTN consistently improves performance of action classification in fine-grained and human-oriented tasks (e.g., on Toyota Smarthome dataset). In addition, we demonstrate that our proposed model, when pre-trained on Kinetics-400, generalizes well onto the unseen real world video benchmark datasets UCF101 and HMDB51, achieving state-of-the-art performance in action recognition.","https://ojs.aaai.org/index.php/AAAI/article/view/25416/25188"
"25417","One-Shot Replay: Boosting Incremental Object Detection via Retrospecting One Object","['Dongbao Yang', 'Yu Zhou', 'Xiaopeng Hong', 'Aoting Zhang', 'Weiping Wang']","['Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Harbin Institute of Technology', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences']","['CV: Object Detection & Categorization', 'ML: Lifelong and Continual Learning']","Yang, D., Zhou, Y., Hong, X., Zhang, A., & Wang, W. (2023). One-Shot Replay: Boosting Incremental Object Detection via Retrospecting One Object. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3127-3135. https://doi.org/10.1609/aaai.v37i3.25417","Abstract 					Modern object detectors are ill-equipped to incrementally learn new emerging object classes over time due to the well-known phenomenon of catastrophic forgetting. Due to data privacy or limited storage, few or no images of the old data can be stored for replay. In this paper, we design a novel One-Shot Replay (OSR) method for incremental object detection, which is an augmentation-based method. Rather than storing original images, only one object-level sample for each old class is stored to reduce memory usage significantly, and we find that copy-paste is a harmonious way to replay for incremental object detection. In the incremental learning procedure, diverse augmented samples with co-occurrence of old and new objects to existing training data are generated. To introduce more variants for objects of old classes, we propose two augmentation modules. The object augmentation module aims to enhance the ability of the detector to perceive potential unknown objects. The feature augmentation module explores the relations between old and new classes and augments the feature space via analogy. Extensive experimental results on VOC2007 and COCO demonstrate that OSR can outperform the state-of-the-art incremental object detection methods without using extra wild data.","https://ojs.aaai.org/index.php/AAAI/article/view/25417/25189"
"25418","Video Event Extraction via Tracking Visual States of Arguments","['Guang Yang', 'Manling Li', 'Jiajie Zhang', 'Xudong Lin', 'Heng Ji', 'Shih-Fu Chang']","['Tsinghua University', 'University of Illinois at Urbana-Champaign', 'Tsinghua University', 'Columbia University', 'University of Illinois at Urbana-Champaign', 'Columbia University']","['CV: Video Understanding & Activity Analysis', 'SNLP: Information Extraction']","Yang, G., Li, M., Zhang, J., Lin, X., Ji, H., & Chang, S.-F. (2023). Video Event Extraction via Tracking Visual States of Arguments. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3136-3144. https://doi.org/10.1609/aaai.v37i3.25418","Abstract 					Video event extraction aims to detect salient events from a video and identify the arguments for each event as well as their semantic roles. Existing methods focus on capturing the overall visual scene of each frame, ignoring fine-grained argument-level information. Inspired by the definition of events as changes of  states, we propose a novel framework to detect video events by tracking the changes in the visual states of all involved arguments, which are expected to provide the most informative evidence for the extraction of video events. In order to capture the visual state changes of arguments, we decompose them into changes in pixels within objects, displacements of objects, and interactions among multiple arguments. We further propose Object State Embedding, Object Motion-aware Embedding and Argument Interaction Embedding to encode and track these changes respectively. Experiments on various video event extraction tasks demonstrate significant improvements compared to state-of-the-art models. In particular, on verb classification, we achieve 3.49% absolute gains (19.53% relative gains) in F1@5 on Video Situation Recognition. Our Code is publicly available at https://github.com/Shinetism/VStates for research purposes.","https://ojs.aaai.org/index.php/AAAI/article/view/25418/25190"
"25419","CoMAE: Single Model Hybrid Pre-training on Small-Scale RGB-D Datasets","['Jiange Yang', 'Sheng Guo', 'Gangshan Wu', 'Limin Wang']","['State Key Laboratory for Novel Software Technology, Nanjing University, China', 'MYbank, Ant Group, China', 'State Key Laboratory for Novel Software Technology, Nanjing University, China', 'State Key Laboratory for Novel Software Technology, Nanjing University, China']","['CV: Scene Analysis & Understanding', 'CV: Multi-modal Vision', 'CV: Representation Learning for Vision', 'ML: Unsupervised & Self-Supervised Learning']","Yang, J., Guo, S., Wu, G., & Wang, L. (2023). CoMAE: Single Model Hybrid Pre-training on Small-Scale RGB-D Datasets. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3145-3154. https://doi.org/10.1609/aaai.v37i3.25419","Abstract 					Current RGB-D scene recognition approaches often train two standalone backbones for RGB and depth modalities with the same Places or ImageNet pre-training. However, the pre-trained depth network is still biased by RGB-based models which may result in a suboptimal solution. In this paper, we present a single-model self-supervised hybrid pre-training framework for RGB and depth modalities, termed as CoMAE. Our CoMAE presents a curriculum learning strategy to unify the two popular self-supervised representation learning algorithms: contrastive learning and masked image modeling.  Specifically, we first build a patch-level alignment task to pre-train a single encoder shared by two modalities via cross-modal contrastive learning. Then, the pre-trained contrastive encoder is passed to a multi-modal masked autoencoder to capture the finer context features from a generative perspective.  In addition, our single-model design without requirement of fusion module is very flexible and robust to generalize to unimodal scenario in both training and testing phases.  Extensive experiments on SUN RGB-D and NYUDv2 datasets demonstrate the effectiveness of our CoMAE for RGB and depth representation learning.  In addition, our experiment results reveal that CoMAE is a data-efficient representation learner. Although we only use the small-scale and unlabeled training set for pre-training, our CoMAE pre-trained models are still competitive to the state-of-the-art methods with extra large-scale and supervised RGB dataset pre-training. Code will be released at https://github.com/MCG-NJU/CoMAE.","https://ojs.aaai.org/index.php/AAAI/article/view/25419/25191"
"25420","Self-Asymmetric Invertible Network for Compression-Aware Image Rescaling","['Jinhai Yang', 'Mengxi Guo', 'Shijie Zhao', 'Junlin Li', 'Li Zhang']","['Bytedance Inc.', 'Bytedance Inc.', 'Bytedance Inc.', 'Bytedance Inc.', 'Bytedance Inc.']","['CV: Low Level & Physics-Based Vision', 'CV: Applications']","Yang, J., Guo, M., Zhao, S., Li, J., & Zhang, L. (2023). Self-Asymmetric Invertible Network for Compression-Aware Image Rescaling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3155-3163. https://doi.org/10.1609/aaai.v37i3.25420","Abstract 					High-resolution (HR) images are usually downscaled to low-resolution (LR) ones for better display and afterward upscaled back to the original size to recover details. Recent work in image rescaling formulates downscaling and upscaling as a unified task and learns a bijective mapping between HR and LR via invertible networks. However, in real-world applications (e.g., social media), most images are compressed for transmission. Lossy compression will lead to irreversible information loss on LR images, hence damaging the inverse upscaling procedure and degrading the reconstruction accuracy. In this paper, we propose the Self-Asymmetric Invertible Network (SAIN) for compression-aware image rescaling. To tackle the distribution shift, we first develop an end-to-end asymmetric framework with two separate bijective mappings for high-quality and compressed LR images, respectively. Then, based on empirical analysis of this framework, we model the distribution of the lost information (including downscaling and compression) using isotropic Gaussian mixtures and propose the Enhanced Invertible Block to derive high-quality/compressed LR images in one forward pass. Besides, we design a set of losses to regularize the learned LR images and enhance the invertibility. Extensive experiments demonstrate the consistent improvements of SAIN across various image rescaling datasets in terms of both quantitative and qualitative evaluation under standard image compression formats (i.e., JPEG and WebP). Code is available at https://github.com/yang-jin-hai/SAIN.","https://ojs.aaai.org/index.php/AAAI/article/view/25420/25192"
"25421","Stop-Gradient Softmax Loss for Deep Metric Learning","['Lu Yang', 'Peng Wang', 'Yanning Zhang']","['Northwestern Polytechnical University\nNational Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology', 'Northwestern Polytechnical University\nNational Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology', 'Northwestern Polytechnical University\nNational Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology']","['CV: Image and Video Retrieval', 'CV: Learning & Optimization for CV', 'CV: Representation Learning for Vision']","Yang, L., Wang, P., & Zhang, Y. (2023). Stop-Gradient Softmax Loss for Deep Metric Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3164-3172. https://doi.org/10.1609/aaai.v37i3.25421","Abstract 					Deep metric learning aims to learn a feature space that models the similarity between images, and feature normalization is a critical step for boosting performance. However directly optimizing L2-normalized softmax loss cause the network to fail to converge. Therefore some SOTA approaches appends a scale layer after the inner product to relieve the convergence problem, but it incurs a new problem that it's difficult to learn the best scaling parameters. In this letter, we look into the characteristic of softmax-based approaches and propose a novel learning objective function Stop-Gradient Softmax Loss (SGSL) to solve the convergence problem in softmax-based deep metric learning with L2-normalization. In addition, we found a useful trick named Remove the last BN-ReLU (RBR). It removes the last BN-ReLU in the backbone to reduce the learning burden of the model. Experimental results on four fine-grained image retrieval benchmarks show that our proposed approach outperforms most existing approaches, i.e., our approach achieves 75.9% on CUB-200-2011, 94.7% on CARS196 and 83.1% on SOP which outperforms other approaches at least 1.7%, 2.9% and 1.7% on Recall@1.","https://ojs.aaai.org/index.php/AAAI/article/view/25421/25193"
"25422","Local Path Integration for Attribution","['Peiyu Yang', 'Naveed Akhtar', 'Zeyi Wen', 'Ajmal Mian']","['The University of Western Australia', 'The University of Western Australia', 'Hong Kong University of Science and Technology (Guangzhou), Hong Kong University of Science and Technology', 'The University of Western Australia']","['CV: Interpretability and Transparency', 'ML: Transparent', 'Interpretable', 'Explainable ML']","Yang, P., Akhtar, N., Wen, Z., & Mian, A. (2023). Local Path Integration for Attribution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3173-3180. https://doi.org/10.1609/aaai.v37i3.25422","Abstract 					Path attribution methods are a popular tool to interpret a visual model's prediction on an input. They integrate model gradients for the input features over a path defined between the input and a reference, thereby satisfying certain desirable theoretical properties. However, their reliability hinges on the choice of the reference. Moreover, they do not exhibit weak dependence on the input, which leads to counter-intuitive feature attribution mapping. We show that path-based attribution can account for the weak dependence property by choosing the reference from the local distribution of the input. We devise a method to identify the local input distribution and propose a technique to stochastically integrate the model gradients over the paths defined by the references sampled from that distribution. Our local path integration (LPI) method is found to consistently outperform existing path attribution techniques when evaluated on deep visual models. Contributing to the ongoing search of reliable evaluation metrics for the interpretation methods, we also introduce DiffID metric that uses the relative difference between insertion and deletion games to alleviate the distribution shift problem faced by existing metrics. Our code is available at https://github.com/ypeiyu/LPI.","https://ojs.aaai.org/index.php/AAAI/article/view/25422/25194"
"25423","Spatiotemporal Deformation Perception for Fisheye Video Rectification","['Shangrong Yang', 'Chunyu Lin', 'Kang Liao', 'Yao Zhao']","['Beijing Jiaotong University', 'Beijing Jiaotong University', 'Beijing Jiaotong University', 'Beijing Jiaotong University']","['CV: Low Level & Physics-Based Vision', 'CV: Computational Photography', 'Image & Video Synthesis', 'CV: Other Foundations of Computer Vision', 'CV: Vision for Robotics & Autonomous Driving']","Yang, S., Lin, C., Liao, K., & Zhao, Y. (2023). Spatiotemporal Deformation Perception for Fisheye Video Rectification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3181-3189. https://doi.org/10.1609/aaai.v37i3.25423","Abstract 					Although the distortion correction of fisheye images has been extensively studied, the correction of fisheye videos is still an elusive challenge. For different frames of the fisheye video, the existing image correction methods ignore the correlation of sequences, resulting in temporal jitter in the corrected video. To solve this problem, we propose a temporal weighting scheme to get a plausible global optical flow, which mitigates the jitter effect by progressively reducing the weight of frames. Subsequently, we observe that the inter-frame optical flow of the video is facilitated to perceive the local spatial deformation of the fisheye video. Therefore, we derive the spatial deformation through the flows of fisheye and distorted-free videos, thereby enhancing the local accuracy of the predicted result. However, the independent correction for each frame disrupts the temporal correlation. Due to the property of fisheye video, a distorted moving object may be able to find its distorted-free pattern at another moment. To this end, a temporal deformation aggregator is designed to reconstruct the deformation correlation between frames and provide a reliable global feature. Our method achieves an end-to-end correction and demonstrates superiority in correction quality and stability compared with the SOTA correction methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25423/25195"
"25424","Contrastive Multi-Task Dense Prediction","['Siwei Yang', 'Hanrong Ye', 'Dan Xu']","['Key Laboratory of Embedded System and Service Computing, Tongji University\nHong Kong University of Science and Technology', 'Hong Kong University of Science and Technology', 'Hong Kong University of Science and Technology']","['CV: Scene Analysis & Understanding']","Yang, S., Ye, H., & Xu, D. (2023). Contrastive Multi-Task Dense Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3190-3197. https://doi.org/10.1609/aaai.v37i3.25424","Abstract 					This paper targets the problem of multi-task dense prediction which aims to achieve simultaneous learning and inference on a bunch of multiple dense prediction tasks in a single framework. A core objective in design is how to effectively model cross-task interactions to achieve a comprehensive improvement on different tasks based on their inherent complementarity and consistency. Existing works typically design extra expensive distillation modules to perform explicit interaction computations among different task-specific features in both training and inference, bringing difficulty in adaptation for different task sets, and reducing efficiency due to clearly increased size of multi-task models. In contrast, we introduce feature-wise contrastive consistency into modeling the cross-task interactions for multi-task dense prediction. We propose a novel multi-task contrastive regularization method based on the consistency to effectively boost the representation learning of the different sub-tasks, which can also be easily generalized to different multi-task dense prediction frameworks, and costs no additional computation in the inference. Extensive experiments on two challenging datasets (i.e. NYUD-v2 and Pascal-Context) clearly demonstrate the superiority of the proposed multi-task contrastive learning approach for dense predictions, establishing new state-of-the-art performances.","https://ojs.aaai.org/index.php/AAAI/article/view/25424/25196"
"25425","AutoStegaFont: Synthesizing Vector Fonts for Hiding Information in Documents","['Xi Yang', 'Jie Zhang', 'Han Fang', 'Chang Liu', 'Zehua Ma', 'Weiming Zhang', 'Nenghai Yu']","['University of Science and Technology of China', 'University of Science and Technology of China\nUniversity of Waterloo', 'National University of Singapore', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China']","['CV: Applications', 'CV: Multi-modal Vision', 'SNLP: Applications']","Yang, X., Zhang, J., Fang, H., Liu, C., Ma, Z., Zhang, W., & Yu, N. (2023). AutoStegaFont: Synthesizing Vector Fonts for Hiding Information in Documents. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3198-3205. https://doi.org/10.1609/aaai.v37i3.25425","Abstract 					Hiding information in text documents has been a hot topic recently, with the most typical schemes of utilizing fonts. By constructing several fonts with similar appearances, information can be effectively represented and embedded in documents. However, due to the unstructured characteristic, font vectors are more difficult to synthesize than font images. Existing methods mainly use handcrafted features to design the fonts manually, which is time-consuming and labor-intensive. Moreover, due to the diversity of fonts, handcrafted features are not generalizable to different fonts. Besides, in practice, since documents might be distorted through transmission, ensuring extractability under distortions is also an important requirement. Therefore, three requirements are imposed on vector font generation in this domain: automaticity, generalizability, and robustness. However, none of the existing methods can satisfy these requirements well and simultaneously. To satisfy the above requirements, we propose AutoStegaFont, an automatic vector font synthesis scheme for hiding information in documents. Specifically, we design a two-stage and dual-modality learning framework. In the first stage, we jointly train an encoder and a decoder to invisibly encode the font images with different information. To ensure robustness, we target designing a noise layer to work with the encoder and decoder during training. In the second stage, we employ a differentiable rasterizer to establish a connection between the image and the vector modality. Then, we design an optimization algorithm to convey the information from the encoded image to the corresponding vector. Thus the encoded font vectors can be automatically generated. Extensive experiments demonstrate the superior performance of our scheme in automatically synthesizing vector fonts for hiding information in documents, with robustness to distortions caused by low-resolution screenshots, printing, and photography. Besides, the proposed framework has better generalizability to fonts with diverse styles and languages.","https://ojs.aaai.org/index.php/AAAI/article/view/25425/25197"
"25426","Towards Global Video Scene Segmentation with Context-Aware Transformer","['Yang Yang', 'Yurui Huang', 'Weili Guo', 'Baohua Xu', 'Dingyin Xia']","['Nanjing University of Science and Technology\nMIIT Key Lab. of Pattern Analysis and Machine Intelligence, NUAA\nState Key Lab. for Novel Software Technology, NJU', 'Nanjing University Of Science And Technology', 'Nanjing University of Science and Technology', 'Huawei Technologies Company', 'Huawei Technologies Company']","['CV: Video Understanding & Activity Analysis', 'ML: Classification and Regression', 'ML: Unsupervised & Self-Supervised Learning']","Yang, Y., Huang, Y., Guo, W., Xu, B., & Xia, D. (2023). Towards Global Video Scene Segmentation with Context-Aware Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3206-3213. https://doi.org/10.1609/aaai.v37i3.25426","Abstract 					Videos such as movies or TV episodes usually need to divide the long storyline into cohesive units, i.e., scenes, to facilitate the understanding of video semantics. The key challenge lies in finding the boundaries of scenes by comprehensively considering the complex temporal structure and semantic information. To this end, we introduce a novel Context-Aware Transformer (CAT) with a self-supervised learning framework to learn high-quality shot representations, for generating well-bounded scenes. More specifically, we design the CAT with local-global self-attentions, which can effectively consider both the long-term and short-term context to improve the shot encoding. For training the CAT, we adopt the self-supervised learning schema. Firstly, we leverage shot-to-scene level pretext tasks to facilitate the pre-training with pseudo boundary, which guides CAT to learn the discriminative shot representations that maximize intra-scene similarity and inter-scene discrimination in an unsupervised manner. Then, we transfer contextual representations for fine-tuning the CAT with supervised data, which encourages CAT to accurately detect the boundary for scene segmentation. As a result, CAT is able to learn the context-aware shot representations and provides global guidance for scene segmentation. Our empirical analyses show that CAT can achieve state-of-the-art performance when conducting the scene segmentation task on the MovieNet dataset, e.g., offering 2.15 improvements on AP.","https://ojs.aaai.org/index.php/AAAI/article/view/25426/25198"
"25427","Low-Light Image Enhancement Network Based on Multi-Scale Feature Complementation","['Yong Yang', 'Wenzhi Xu', 'Shuying Huang', 'Weiguo Wan']","['Tiangong University', 'Jiangxi University of Finance and Economics', 'Tiangong University', 'Jiangxi University of Finance and Economics']","['CV: Applications', 'ML: Applications', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms']","Yang, Y., Xu, W., Huang, S., & Wan, W. (2023). Low-Light Image Enhancement Network Based on Multi-Scale Feature Complementation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3214-3221. https://doi.org/10.1609/aaai.v37i3.25427","Abstract 					Images captured in low-light environments have problems of insufficient brightness and low contrast, which will affect subsequent image processing tasks. Although most current enhancement methods can obtain high-contrast images, they still suffer from noise amplification and color distortion. To address these issues, this paper proposes a low-light image enhancement network based on multi-scale feature complementation (LIEN-MFC), which is a U-shaped encoder-decoder network supervised by multiple images of different scales. In the encoder, four feature extraction branches are constructed to extract features of low-light images at different scales. In the decoder, to ensure the integrity of the learned features at each scale, a feature supplementary fusion module (FSFM) is proposed to complement and integrate features from different branches of the encoder and decoder. In addition, a feature restoration module (FRM) and an image reconstruction module (IRM) are built in each branch to reconstruct the restored features and output enhanced images. To better train the network, a joint loss function is defined, in which a discriminative loss term is designed to ensure that the enhanced results better meet the visual properties of the human eye. Extensive experiments on benchmark datasets show that the proposed method outperforms some state-of-the-art methods subjectively and objectively.","https://ojs.aaai.org/index.php/AAAI/article/view/25427/25199"
"25428","Semantics-Aware Dynamic Localization and Refinement for Referring Image Segmentation","['Zhao Yang', 'Jiaqi Wang', 'Yansong Tang', 'Kai Chen', 'Hengshuang Zhao', 'Philip H.S. Torr']","['University of Oxford', 'Shanghai AI Laboratory', 'Tsinghua-Berkeley Shenzhen Institute, Tsinghua University', 'Shanghai AI Laboratory', 'The University of Hong Kong', 'University of Oxford']","['CV: Multi-modal Vision', 'CV: Language and Vision', 'CV: Segmentation', 'ML: Representation Learning']","Yang, Z., Wang, J., Tang, Y., Chen, K., Zhao, H., & Torr, P. H. (2023). Semantics-Aware Dynamic Localization and Refinement for Referring Image Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3222-3230. https://doi.org/10.1609/aaai.v37i3.25428","Abstract 					Referring image segmentation segments an image from a language expression. With the aim of producing high-quality masks, existing methods often adopt iterative learning approaches that rely on RNNs or stacked attention layers to refine vision-language features. Despite their complexity, RNN-based methods are subject to specific encoder choices, while attention-based methods offer limited gains. In this work, we introduce a simple yet effective alternative for progressively learning discriminative multi-modal features. The core idea of our approach is to leverage a continuously updated query as the representation of the target object and at each iteration, strengthen multi-modal features strongly correlated to the query while weakening less related ones. As the query is initialized by language features and successively updated by object features, our algorithm gradually shifts from being localization-centric to segmentation-centric. This strategy enables the incremental recovery of missing object parts and/or removal of extraneous parts through iteration. Compared to its counterparts, our method is more versatile—it can be plugged into prior arts straightforwardly and consistently bring improvements. Experimental results on the challenging datasets of RefCOCO, RefCOCO+, and G-Ref demonstrate its advantage with respect to the state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25428/25200"
"25429","LidarMultiNet: Towards a Unified Multi-Task Network for LiDAR Perception","['Dongqiangzi Ye', 'Zixiang Zhou', 'Weijia Chen', 'Yufei Xie', 'Yu Wang', 'Panqu Wang', 'Hassan Foroosh']","['TuSimple', 'TuSimple\nUniversity of Central Florida', 'TuSimple', 'TuSimple', 'Tusimple', 'TuSimple', 'University of Central Florida']","['CV: Vision for Robotics & Autonomous Driving', 'CV: 3D Computer Vision', 'CV: Object Detection & Categorization', 'CV: Segmentation']","Ye, D., Zhou, Z., Chen, W., Xie, Y., Wang, Y., Wang, P., & Foroosh, H. (2023). LidarMultiNet: Towards a Unified Multi-Task Network for LiDAR Perception. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3231-3240. https://doi.org/10.1609/aaai.v37i3.25429","Abstract 					LiDAR-based 3D object detection, semantic segmentation, and panoptic segmentation are usually implemented in specialized networks with distinctive architectures that are difficult to adapt to each other. This paper presents LidarMultiNet, a LiDAR-based multi-task network that unifies these three major LiDAR perception tasks. Among its many benefits, a multi-task network can reduce the overall cost by sharing weights and computation among multiple tasks. However, it typically underperforms compared to independently combined single-task models. The proposed LidarMultiNet aims to bridge the performance gap between the multi-task network and multiple single-task networks. At the core of LidarMultiNet is a strong 3D voxel-based encoder-decoder architecture with a Global Context Pooling (GCP) module extracting global contextual features from a LiDAR frame. Task-specific heads are added on top of the network to perform the three LiDAR perception tasks. More tasks can be implemented simply by adding new task-specific heads while introducing little additional cost. A second stage is also proposed to refine the first-stage segmentation and generate accurate panoptic segmentation results. LidarMultiNet is extensively tested on both Waymo Open Dataset and nuScenes dataset, demonstrating for the first time that major LiDAR perception tasks can be unified in a single strong network that is trained end-to-end and achieves state-of-the-art performance. Notably, LidarMultiNet reaches the official 1 place in the Waymo Open Dataset 3D semantic segmentation challenge 2022 with the highest mIoU and the best accuracy for most of the 22 classes on the test set, using only LiDAR points as input. It also sets the new state-of-the-art for a single model on the Waymo 3D object detection benchmark and three nuScenes benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25429/25201"
"25430","DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in Transformer","['Maoyuan Ye', 'Jing Zhang', 'Shanshan Zhao', 'Juhua Liu', 'Bo Du', 'Dacheng Tao']","['Research Center for Graphic Communication, Printing and Packaging, Institute of Artificial Intelligence, Wuhan University', 'The University of Sydney', 'JD Explore Academy', 'Research Center for Graphic Communication, Printing and Packaging, Institute of Artificial Intelligence, Wuhan University', 'National Engineering Research Center for Multimedia Software, Institute of Artificial Intelligence, School of Computer Science and Hubei Key Laboratory of Multimedia and Network Communication Engineering, Wuhan University', 'JD Explore Academy\nThe University of Sydney']","['CV: Scene Analysis & Understanding', 'CV: Applications', 'CV: Object Detection & Categorization']","Ye, M., Zhang, J., Zhao, S., Liu, J., Du, B., & Tao, D. (2023). DPText-DETR: Towards Better Scene Text Detection with Dynamic Points in Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3241-3249. https://doi.org/10.1609/aaai.v37i3.25430","Abstract 					Recently, Transformer-based methods, which predict polygon points or Bezier curve control points for localizing texts, are popular in scene text detection. However, these methods built upon detection transformer framework might achieve sub-optimal training efficiency and performance due to coarse positional query modeling. In addition, the point label form exploited in previous works implies the reading order of humans, which impedes the detection robustness from our observation. To address these challenges, this paper proposes a concise Dynamic Point Text DEtection TRansformer network, termed DPText-DETR. In detail, DPText-DETR directly leverages explicit point coordinates to generate position queries and dynamically updates them in a progressive way. Moreover, to improve the spatial inductive bias of non-local self-attention in Transformer, we present an Enhanced Factorized Self-Attention module which provides point queries within each instance with circular shape guidance. Furthermore, we design a simple yet effective positional label form to tackle the side effect of the previous form. To further evaluate the impact of different label forms on the detection robustness in real-world scenario, we establish an Inverse-Text test set containing 500 manually labeled images. Extensive experiments prove the high training efficiency, robustness, and state-of-the-art performance of our method on popular benchmarks. The code and the Inverse-Text test set are available at https://github.com/ymy-k/DPText-DETR.","https://ojs.aaai.org/index.php/AAAI/article/view/25430/25202"
"25431","Learning Second-Order Attentive Context for Efficient Correspondence Pruning","['Xinyi Ye', 'Weiyue Zhao', 'Hao Lu', 'Zhiguo Cao']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology']","['CV: 3D Computer Vision', 'CV: Representation Learning for Vision']","Ye, X., Zhao, W., Lu, H., & Cao, Z. (2023). Learning Second-Order Attentive Context for Efficient Correspondence Pruning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3250-3258. https://doi.org/10.1609/aaai.v37i3.25431","Abstract 					Correspondence pruning aims to search consistent correspondences (inliers) from a set of putative correspondences. It is challenging because of the disorganized spatial distribution of numerous outliers, especially when putative correspondences are largely dominated by outliers. It's more challenging to ensure effectiveness while maintaining efficiency. In this paper, we propose an effective and efficient method for correspondence pruning. Inspired by the success of attentive context in correspondence problems, we first extend the attentive context to the first-order attentive context and then introduce the idea of attention in attention (ANA) to model second-order attentive context for correspondence pruning. Compared with first-order attention that focuses on feature-consistent context, second-order attention dedicates to attention weights itself and provides an additional source to encode consistent context from the attention map. For efficiency, we derive two approximate formulations for the naive implementation of second-order attention to optimize the cubic complexity to linear complexity, such that second-order attention can be used with negligible computational overheads. We further implement our formulations in a second-order context layer and then incorporate the layer in an ANA block. Extensive experiments demonstrate that our method is effective and efficient in pruning outliers, especially in high-outlier-ratio cases. Compared with the state-of-the-art correspondence pruning approach LMCNet, our method  runs 14 times faster while maintaining a competitive accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25431/25203"
"25432","Infusing Definiteness into Randomness: Rethinking Composition Styles for Deep Image Matting","['Zixuan Ye', 'Yutong Dai', 'Chaoyi Hong', 'Zhiguo Cao', 'Hao Lu']","['Huazhong University of Science and Technology', 'The University of Adelaide', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology']","['CV: Segmentation', 'CV: Low Level & Physics-Based Vision']","Ye, Z., Dai, Y., Hong, C., Cao, Z., & Lu, H. (2023). Infusing Definiteness into Randomness: Rethinking Composition Styles for Deep Image Matting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3259-3266. https://doi.org/10.1609/aaai.v37i3.25432","Abstract 					We study the composition style in deep image matting, a notion that characterizes a data generation flow on how to exploit limited foregrounds and random backgrounds to form a training dataset. Prior art executes this flow in a completely random manner by simply going through the foreground pool or by optionally combining two foregrounds before foreground-background composition. In this work, we first show that naive foreground combination can be problematic and therefore derive an alternative formulation to reasonably combine foregrounds. Our second contribution is an observation that matting performance can benefit from a certain occurrence frequency of combined foregrounds and their associated source foregrounds during training. Inspired by this, we introduce a novel composition style that binds the source and combined foregrounds in a definite triplet. In addition, we also find that different orders of foreground combination lead to different foreground patterns, which further inspires a quadruplet-based composition style. Results under controlled experiments on four matting baselines show that our composition styles outperform existing ones and invite consistent performance improvement on both composited and real-world datasets. Code is available at: https://github.com/coconuthust/composition_styles","https://ojs.aaai.org/index.php/AAAI/article/view/25432/25204"
"25433","Can We Find Strong Lottery Tickets in Generative Models?","['Sangyeop Yeo', 'Yoojin Jang', 'Jy-yong Sohn', 'Dongyoon Han', 'Jaejun Yoo']","['UNIST', 'UNIST', 'University of Wisconsin-Madison', 'NAVER AI Lab', 'UNIST']","['CV: Learning & Optimization for CV', 'CV: Representation Learning for Vision', 'ML: Deep Generative Models & Autoencoders']","Yeo, S., Jang, Y., Sohn, J.- yong, Han, D., & Yoo, J. (2023). Can We Find Strong Lottery Tickets in Generative Models?. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3267-3275. https://doi.org/10.1609/aaai.v37i3.25433","Abstract 					Yes. In this paper, we investigate strong lottery tickets in generative models, the subnetworks that achieve good generative performance without any weight update. Neural network pruning is considered the main cornerstone of model compression for reducing the costs of computation and memory. Unfortunately, pruning a generative model has not been extensively explored, and all existing pruning algorithms suffer from excessive weight-training costs, performance degradation, limited generalizability, or complicated training. To address these problems, we propose to find a strong lottery ticket via moment-matching scores. Our experimental results show that the discovered subnetwork can perform similarly or better than the trained dense model even when only 10% of the weights remain. To the best of our knowledge, we are the first to show the existence of strong lottery tickets in generative models and provide an algorithm to find it stably. Our code and supplementary materials are publicly available at https://lait-cvlab.github.io/SLT-in-Generative-Models/.","https://ojs.aaai.org/index.php/AAAI/article/view/25433/25205"
"25434","Class-Independent Regularization for Learning with Noisy Labels","['Rumeng Yi', 'Dayan Guan', 'Yaping Huang', 'Shijian Lu']","['Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing Jiaotong University, China', 'Mohamed bin Zayed University of Artificial Intelligence, UAE', 'Beijing Key Laboratory of Traffic Data Analysis and Mining, Beijing Jiaotong University, China', 'School of Computer Science and Engineering, Nanyang Technological University, Singapore']","['CV: Object Detection & Categorization', 'CV: Other Foundations of Computer Vision']","Yi, R., Guan, D., Huang, Y., & Lu, S. (2023). Class-Independent Regularization for Learning with Noisy Labels. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3276-3284. https://doi.org/10.1609/aaai.v37i3.25434","Abstract 					Training deep neural networks (DNNs) with noisy labels often leads to poorly generalized models as DNNs tend to memorize the noisy labels in training. Various strategies have been developed for improving sample selection precision and mitigating the noisy label memorization issue. However, most existing works adopt a class-dependent softmax classifier that is vulnerable to noisy labels by entangling the classification of multi-class features. This paper presents a class-independent regularization (CIR) method that can effectively alleviate the negative impact of noisy labels in DNN training. CIR regularizes the class-dependent softmax classifier by introducing multi-binary classifiers each of which takes care of one class only. Thanks to its class-independent nature, CIR is tolerant to noisy labels as misclassification by one binary classifier does not affect others. For effective training of CIR, we design a heterogeneous adaptive co-teaching strategy that forces the class-independent and class-dependent classifiers to focus on sample selection and image classification, respectively, in a cooperative manner. Extensive experiments show that CIR achieves superior performance consistently across multiple benchmarks with both synthetic and real images. Code is available at https://github.com/RumengYi/CIR.","https://ojs.aaai.org/index.php/AAAI/article/view/25434/25206"
"25435","Unbiased Heterogeneous Scene Graph Generation with Relation-Aware Message Passing Neural Network","['Kanghoon Yoon', 'Kibum Kim', 'Jinyoung Moon', 'Chanyoung Park']","['Dept. of Industrial and Systems Engineering, KAIST, Daejeon, Republic of Korea', 'Dept. of Industrial and Systems Engineering, KAIST, Daejeon, Republic of Korea', 'Electronics and Telecommunications Research Institute, 218 Gajeong-ro, Yuseong-gu, Daejeon, Republic of Korea;\nETRI School, University of Science and Technology, 218 Gajeong-ro, Yuseong-gu, Daejeon, Republic of Korea', 'Dept. of Industrial and Systems Engineering, KAIST, Daejeon, Republic of Korea;\nGraduate School of Artificial Intelligence, KAIST, Daejeon, Republic of Korea']","['CV: Scene Analysis & Understanding', 'ML: Graph-based Machine Learning']","Yoon, K., Kim, K., Moon, J., & Park, C. (2023). Unbiased Heterogeneous Scene Graph Generation with Relation-Aware Message Passing Neural Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3285-3294. https://doi.org/10.1609/aaai.v37i3.25435","Abstract 					Recent scene graph generation (SGG) frameworks have focused on learning complex relationships among multiple objects in an image. Thanks to the nature of the message passing neural network (MPNN) that models high-order interactions between objects and their neighboring objects, they are dominant representation learning modules for SGG. However, existing MPNN-based frameworks assume the scene graph as a homogeneous graph, which restricts the context-awareness of visual relations between objects. That is, they overlook the fact that the relations tend to be highly dependent on the objects with which the relations are associated. In this paper, we propose an unbiased heterogeneous scene graph generation (HetSGG) framework that captures relation-aware context using message passing neural networks. We devise a novel message passing layer, called relation-aware message passing neural network (RMP), that aggregates the contextual information of an image considering the predicate type between objects. Our extensive evaluations demonstrate that HetSGG outperforms state-of-the-art methods, especially outperforming on tail predicate classes. The source code for HetSGG is available at https://github.com/KanghoonYoon/hetsgg-torch","https://ojs.aaai.org/index.php/AAAI/article/view/25435/25207"
"25436","Lifelong Person Re-identification via Knowledge Refreshing and Consolidation","['Chunlin Yu', 'Ye Shi', 'Zimo Liu', 'Shenghua Gao', 'Jingya Wang']","['Shanghaitech University', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging', 'Peng Cheng Laboratory', 'Shanghaitech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Image and Video Retrieval', 'ML: Lifelong and Continual Learning']","Yu, C., Shi, Y., Liu, Z., Gao, S., & Wang, J. (2023). Lifelong Person Re-identification via Knowledge Refreshing and Consolidation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3295-3303. https://doi.org/10.1609/aaai.v37i3.25436","Abstract 					Lifelong person re-identification (LReID) is in significant demand for real-world development as a large amount of ReID data is captured from diverse locations over time and cannot be accessed at once inherently. However, a key challenge for LReID is how to incrementally preserve old knowledge and gradually add new capabilities to the system. Unlike most existing LReID methods, which mainly focus on dealing with catastrophic forgetting, our focus is on a more challenging problem, which is, not only trying to reduce the forgetting on old tasks but also aiming to improve the model performance on both new and old tasks during the lifelong learning process. Inspired by the biological process of human cognition where the somatosensory neocortex and the hippocampus work together in memory consolidation, we formulated a model called Knowledge Refreshing and Consolidation (KRC) that achieves both positive forward and backward transfer. More specifically, a knowledge refreshing scheme is incorporated with the knowledge rehearsal mechanism to enable bi-directional knowledge transfer by introducing a dynamic memory model and an adaptive working model. Moreover, a knowledge consolidation scheme operating on the dual space further improves model stability over the long-term. Extensive evaluations show KRC’s superiority over the state-of-the-art LReID methods with challenging pedestrian benchmarks.  Code is available at https://github.com/cly234/LReID-KRKC.","https://ojs.aaai.org/index.php/AAAI/article/view/25436/25208"
"25437","Generalizing Multiple Object Tracking to Unseen Domains by Introducing Natural Language Representation","['En Yu', 'Songtao Liu', 'Zhuoling Li', 'Jinrong Yang', 'Zeming Li', 'Shoudong Han', 'Wenbing Tao']","['Huazhong University of Science and Technology', 'Megvii(Face++) Inc', 'Tsinghua University', 'Huazhong University of Science and Technology', 'Megvii(Face++) Inc', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology']","['CV: Motion & Tracking', 'CV: Language and Vision', 'CV: Multi-modal Vision']","Yu, E., Liu, S., Li, Z., Yang, J., Li, Z., Han, S., & Tao, W. (2023). Generalizing Multiple Object Tracking to Unseen Domains by Introducing Natural Language Representation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3304-3312. https://doi.org/10.1609/aaai.v37i3.25437","Abstract 					Although existing multi-object tracking (MOT) algorithms have obtained competitive performance on various benchmarks, almost all of them train and validate models on the same domain. The domain generalization problem of MOT is hardly studied. To bridge this gap, we first draw the observation that the high-level information contained in natural language is domain invariant to different tracking domains. Based on this observation, we propose to introduce natural language representation into visual MOT models for boosting the domain generalization ability. However, it is infeasible to label every tracking target with a textual description. To tackle this problem, we design two modules, namely visual context prompting (VCP) and visual-language mixing (VLM). Specifically, VCP generates visual prompts based on the input frames. VLM joints the information in the generated visual prompts and the textual prompts from a pre-defined Trackbook to obtain instance-level pseudo textual description, which is domain invariant to different tracking scenes. Through training models on MOT17 and validating them on MOT20, we observe that the pseudo textual descriptions generated by our proposed modules improve the generalization performance of query-based trackers by large margins.","https://ojs.aaai.org/index.php/AAAI/article/view/25437/25209"
"25438","Rethinking Rotation Invariance with Point Cloud Registration","['Jianhui Yu', 'Chaoyi Zhang', 'Weidong Cai']","['University of Sydney', 'University of Sydney', 'University of Sydney']","['CV: 3D Computer Vision']","Yu, J., Zhang, C., & Cai, W. (2023). Rethinking Rotation Invariance with Point Cloud Registration. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3313-3321. https://doi.org/10.1609/aaai.v37i3.25438","Abstract 					Recent investigations on rotation invariance for 3D point clouds have been devoted to devising rotation-invariant feature descriptors or learning canonical spaces where objects are semantically aligned. Examinations of learning frameworks for invariance have seldom been looked into. In this work, we review rotation invariance (RI) in terms of point cloud registration (PCR) and propose an effective framework for rotation invariance learning via three sequential stages, namely rotation-invariant shape encoding, aligned feature integration, and deep feature registration. We first encode shape descriptors constructed with respect to reference frames defined over different scales, e.g., local patches and global topology, to generate rotation-invariant latent shape codes. Within the integration stage, we propose an Aligned Integration Transformer (AIT) to produce a discriminative feature representation by integrating point-wise self- and cross-relations established within the shape codes. Meanwhile, we adopt rigid transformations between reference frames to align the shape codes for feature consistency across different scales. Finally, the deep integrated feature is registered to both rotation-invariant shape codes to maximize their feature similarities, such that rotation invariance of the integrated feature is preserved and shared semantic information is implicitly extracted from shape codes. Experimental results on 3D shape classification, part segmentation, and retrieval tasks prove the feasibility of our framework. Our project page is released at: https://rotation3d.github.io/.","https://ojs.aaai.org/index.php/AAAI/article/view/25438/25210"
"25439","Frame-Level Label Refinement for Skeleton-Based Weakly-Supervised Action Recognition","['Qing Yu', 'Kent Fujiwara']","['The University of Tokyo', 'LINE Corporation']","['CV: Motion & Tracking', 'CV: 3D Computer Vision', 'CV: Scene Analysis & Understanding']","Yu, Q., & Fujiwara, K. (2023). Frame-Level Label Refinement for Skeleton-Based Weakly-Supervised Action Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3322-3330. https://doi.org/10.1609/aaai.v37i3.25439","Abstract 					In recent years, skeleton-based action recognition has achieved remarkable performance in understanding human motion from sequences of skeleton data, which is an important medium for synthesizing realistic human movement in various applications. However, existing methods assume that each action clip is manually trimmed to contain one specific action, which requires a significant amount of effort for annotation. To solve this problem, we consider a novel problem of skeleton-based weakly-supervised temporal action localization (S-WTAL), where we need to recognize and localize human action segments in untrimmed skeleton videos given only the video-level labels. Although this task is challenging due to the sparsity of skeleton data and the lack of contextual clues from interaction with other objects and the environment, we present a frame-level label refinement framework based on a spatio-temporal graph convolutional network (ST-GCN) to overcome these difficulties. We use multiple instance learning (MIL) with video-level labels to generate the frame-level predictions. Inspired by advances in handling the noisy label problem, we introduce a label cleaning strategy of the frame-level pseudo labels to guide the learning process. The network parameters and the frame-level predictions are alternately updated to obtain the final results. We extensively evaluate the effectiveness of our learning approach on skeleton-based action recognition benchmarks. The state-of-the-art experimental results demonstrate that the proposed method can recognize and localize action segments of the skeleton data.","https://ojs.aaai.org/index.php/AAAI/article/view/25439/25211"
"25440","Recurrent Structure Attention Guidance for Depth Super-resolution","['Jiayi Yuan', 'Haobo Jiang', 'Xiang Li', 'Jianjun Qian', 'Jun Li', 'Jian Yang']","['Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology']","['CV: 3D Computer Vision', 'CV: Multi-modal Vision']","Yuan, J., Jiang, H., Li, X., Qian, J., Li, J., & Yang, J. (2023). Recurrent Structure Attention Guidance for Depth Super-resolution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3331-3339. https://doi.org/10.1609/aaai.v37i3.25440","Abstract 					Image guidance is an effective strategy for depth super-resolution. Generally, most existing methods employ hand-crafted operators to decompose the high-frequency (HF) and low-frequency (LF) ingredients from low-resolution depth maps and guide the HF ingredients by directly concatenating them with image features. However, the hand-designed operators usually cause inferior HF maps (e.g., distorted or structurally missing) due to the diverse appearance of complex depth maps. Moreover, the direct concatenation often results in weak guidance because not all image features have a positive effect on the HF maps. In this paper, we develop a recurrent structure attention guided (RSAG) framework, consisting of two important parts. First, we introduce a deep contrastive network with multi-scale filters for adaptive frequency-domain separation, which adopts contrastive networks from large filters to small ones to calculate the pixel contrasts for adaptive high-quality HF predictions. Second, instead of the coarse concatenation guidance, we propose a recurrent structure attention block, which iteratively utilizes the latest depth estimation and the image features to jointly select clear patterns and boundaries, aiming at providing refined guidance for accurate depth recovery. In addition, we fuse the features of HF maps to enhance the edge structures in the decomposed LF maps. Extensive experiments show that our approach obtains superior performance compared with state-of-the-art depth super-resolution methods. Our code is available at: https://github.com/Yuanjiayii/DSR-RSAG.","https://ojs.aaai.org/index.php/AAAI/article/view/25440/25212"
"25441","Structure Flow-Guided Network for Real Depth Super-resolution","['Jiayi Yuan', 'Haobo Jiang', 'Xiang Li', 'Jianjun Qian', 'Jun Li', 'Jian Yang']","['Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology']","['CV: 3D Computer Vision', 'CV: Multi-modal Vision']","Yuan, J., Jiang, H., Li, X., Qian, J., Li, J., & Yang, J. (2023). Structure Flow-Guided Network for Real Depth Super-resolution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3340-3348. https://doi.org/10.1609/aaai.v37i3.25441","Abstract 					Real depth super-resolution (DSR), unlike synthetic settings, is a challenging task due to the structural distortion and the edge noise caused by the natural degradation in real-world low-resolution (LR) depth maps. These defeats result in significant structure inconsistency between the depth map and the RGB guidance, which potentially confuses the RGB-structure guidance and thereby degrades the DSR quality. In this paper, we propose a novel structure flow-guided DSR framework, where a cross-modality flow map is learned to guide the RGB-structure information transferring for precise depth upsampling. Specifically, our framework consists of a cross-modality flow-guided upsampling network (CFUNet) and a flow-enhanced pyramid edge attention network (PEANet). CFUNet contains a trilateral self-attention module combining both the geometric and semantic correlations for reliable cross-modality flow learning. Then, the learned flow maps are combined with the grid-sampling mechanism for coarse high-resolution (HR) depth prediction. PEANet targets at integrating the learned flow map as the edge attention into a pyramid network to hierarchically learn the edge-focused guidance feature for depth edge refinement. Extensive experiments on real and synthetic DSR datasets verify that our approach achieves excellent performance compared to state-of-the-art methods. Our code is available at: https://github.com/Yuanjiayii/DSR-SFG.","https://ojs.aaai.org/index.php/AAAI/article/view/25441/25213"
"25442","Pseudo Label-Guided Model Inversion Attack via Conditional Generative Adversarial Network","['Xiaojian Yuan', 'Kejiang Chen', 'Jie Zhang', 'Weiming Zhang', 'Nenghai Yu', 'Yang Zhang']","['University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China\nUniversity of Waterloo', 'University of Science and Technology of China', 'University of Science and Technology of China', 'CISPA Helmholtz Center for Information Security']","['CV: Bias', 'Fairness & Privacy', 'ML: Privacy-Aware ML']","Yuan, X., Chen, K., Zhang, J., Zhang, W., Yu, N., & Zhang, Y. (2023). Pseudo Label-Guided Model Inversion Attack via Conditional Generative Adversarial Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3349-3357. https://doi.org/10.1609/aaai.v37i3.25442","Abstract 					Model inversion (MI) attacks have raised increasing concerns about privacy, which can reconstruct training data from public models. Indeed, MI attacks can be formalized as an optimization problem that seeks private data in a certain space. Recent MI attacks leverage a generative adversarial network (GAN) as an image prior to narrow the search space, and can successfully reconstruct even the high-dimensional data (e.g., face images). However, these generative MI attacks do not fully exploit the potential capabilities of the target model, still leading to a vague and coupled search space, i.e., different classes of images are coupled in the search space. Besides, the widely used cross-entropy loss in these attacks suffers from gradient vanishing. To address these problems, we propose Pseudo Label-Guided MI (PLG-MI) attack via conditional GAN (cGAN). At first, a top-n selection strategy is proposed to provide pseudo-labels for public data, and use pseudo-labels to guide the training of the cGAN. In this way, the search space is decoupled for different classes of images. Then a max-margin loss is introduced to improve the search process on the subspace of a target class. Extensive experiments demonstrate that our PLG-MI attack significantly improves the attack success rate and visual quality for various datasets and models, notably, 2 ∼ 3× better than state-of-the-art attacks under large distributional shifts. Our code is available at: https://github.com/LetheSec/PLG-MI-Attack.","https://ojs.aaai.org/index.php/AAAI/article/view/25442/25214"
"25443","Cyclically Disentangled Feature Translation for Face Anti-spoofing","['Haixiao Yue', 'Keyao Wang', 'Guosheng Zhang', 'Haocheng Feng', 'Junyu Han', 'Errui Ding', 'Jingdong Wang']","['Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.']","['CV: Biometrics', 'Face', 'Gesture & Pose']","Yue, H., Wang, K., Zhang, G., Feng, H., Han, J., Ding, E., & Wang, J. (2023). Cyclically Disentangled Feature Translation for Face Anti-spoofing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3358-3366. https://doi.org/10.1609/aaai.v37i3.25443","Abstract 					Current domain adaptation methods for face anti-spoofing leverage labeled source domain data and unlabeled target domain data to obtain a promising generalizable decision boundary. However, it is usually difficult for these methods to achieve a perfect domain-invariant liveness feature disentanglement, which may degrade the final classification performance by domain differences in illumination, face category, spoof type, etc. In this work, we tackle cross-scenario face anti-spoofing by proposing a novel domain adaptation method called cyclically disentangled feature translation network (CDFTN). Specifically, CDFTN generates pseudo-labeled samples that possess: 1) source domain-invariant liveness features and 2) target domain-specific content features, which are disentangled through domain adversarial training. A robust classifier is trained based on the synthetic pseudo-labeled images under the supervision of source domain labels. We further extend CDFTN for multi-target domain adaptation by leveraging data from more unlabeled target domains. Extensive experiments on several public datasets demonstrate that our proposed approach significantly outperforms the state of the art. Code and models are available at https://github.com/vis-face/CDFTN.","https://ojs.aaai.org/index.php/AAAI/article/view/25443/25215"
"25444","FlowFace: Semantic Flow-Guided Shape-Aware Face Swapping","['Hao Zeng', 'Wei Zhang', 'Changjie Fan', 'Tangjie Lv', 'Suzhen Wang', 'Zhimeng Zhang', 'Bowen Ma', 'Lincheng Li', 'Yu Ding', 'Xin Yu']","['Virtual Human Group, Netease Fuxi AI Lab', 'Virtual Human Group, Netease Fuxi AI Lab', 'Virtual Human Group, NetEase Fuxi AI Lab', 'Virtual Human Group, NetEase Fuxi AI Lab', 'Virtual Human Group, Netease Fuxi AI Lab', 'Virtual Human Group, Netease Fuxi AI Lab', 'Virtual Human Group, Netease Fuxi AI Lab', 'Virtual Human Group, NetEase Fuxi AI Lab', 'Virtual Human Group, Netease Fuxi AI Lab\nZhejiang University', 'University of Technology Sydney']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Applications', 'CV: Biometrics', 'Face', 'Gesture & Pose']","Zeng, H., Zhang, W., Fan, C., Lv, T., Wang, S., Zhang, Z., Ma, B., Li, L., Ding, Y., & Yu, X. (2023). FlowFace: Semantic Flow-Guided Shape-Aware Face Swapping. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3367-3375. https://doi.org/10.1609/aaai.v37i3.25444","Abstract 					In this work, we propose a semantic flow-guided two-stage framework for shape-aware face swapping, namely FlowFace. Unlike most previous methods that focus on transferring the source inner facial features but neglect facial contours, our FlowFace can transfer both of them to a target face, thus leading to more realistic face swapping. Concretely, our FlowFace consists of a face reshaping network and a face swapping network. The face reshaping network addresses the shape outline differences between the source and target faces. It first estimates a semantic flow (i.e. face shape differences) between the source and the target face, and then explicitly warps the target face shape with the estimated semantic flow. After reshaping, the face swapping network generates inner facial features that exhibit the identity of the source face. We employ a pre-trained face masked autoencoder (MAE) to extract facial features from both the source face and the target face. In contrast to previous methods that use identity embedding to preserve identity information, the features extracted by our encoder can better capture facial appearances and identity information. Then, we develop a cross-attention fusion module to adaptively fuse inner facial features from the source face with the target facial attributes, thus leading to better identity preservation. Extensive quantitative and qualitative experiments on in-the-wild faces demonstrate that our FlowFace outperforms the state-of-the-art significantly.","https://ojs.aaai.org/index.php/AAAI/article/view/25444/25216"
"25445","Multi-Modal Knowledge Hypergraph for Diverse Image Retrieval","['Yawen Zeng', 'Qin Jin', 'Tengfei Bao', 'Wenfeng Li']","['ByteDance AI Lab', 'Renmin University of China', 'ByteDance AI Lab', 'ByteDance AI Lab']","['CV: Image and Video Retrieval', 'DMKM: Mining of Visual', 'Multimedia & Multimodal Data', 'DMKM: Web Search & Information Retrieval']","Zeng, Y., Jin, Q., Bao, T., & Li, W. (2023). Multi-Modal Knowledge Hypergraph for Diverse Image Retrieval. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3376-3383. https://doi.org/10.1609/aaai.v37i3.25445","Abstract 					The task of keyword-based diverse image retrieval has received considerable attention due to its wide demand in real-world scenarios. Existing methods either rely on a multi-stage re-ranking strategy based on human design to diversify results, or extend sub-semantics via an implicit generator, which either relies on manual labor or lacks explainability. To learn more diverse and explainable representations, we capture sub-semantics in an explicit manner by leveraging the multi-modal knowledge graph (MMKG) that contains richer entities and relations. However, the huge domain gap between the off-the-shelf MMKG and retrieval datasets, as well as the semantic gap between images and texts, make the fusion of MMKG difficult. In this paper, we pioneer a degree-free hypergraph solution that models many-to-many relations to address the challenge of heterogeneous sources and heterogeneous modalities. Specifically, a hyperlink-based solution, Multi-Modal Knowledge Hyper Graph (MKHG) is proposed, which bridges heterogeneous data via various hyperlinks to diversify sub-semantics. Among them, a hypergraph construction module first customizes various hyperedges to link the heterogeneous MMKG and retrieval databases. A multi-modal instance bagging module then explicitly selects instances to diversify the semantics. Meanwhile, a diverse concept aggregator flexibly adapts key sub-semantics. Finally, several losses are adopted to optimize the semantic space. Extensive experiments on two real-world datasets have well verified the effectiveness and explainability of our proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/25445/25217"
"25446","Learnable Blur Kernel for Single-Image Defocus Deblurring in the Wild","['Jucai Zhai', 'Pengcheng Zeng', 'Chihao Ma', 'Jie Chen', 'Yong Zhao']","['Peking University', 'Peking University', 'Peking University', 'Peking University\nPeng Cheng Laboratory', 'Peking University']","['CV: Low Level & Physics-Based Vision', 'CV: 3D Computer Vision', 'CV: Applications', 'CV: Computational Photography', 'Image & Video Synthesis']","Zhai, J., Zeng, P., Ma, C., Chen, J., & Zhao, Y. (2023). Learnable Blur Kernel for Single-Image Defocus Deblurring in the Wild. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3384-3392. https://doi.org/10.1609/aaai.v37i3.25446","Abstract 					Recent research showed that the dual-pixel sensor has made great progress in defocus map estimation and image defocus deblurring. However, extracting real-time dual-pixel views is troublesome and complex in algorithm deployment. Moreover, the deblurred image generated by the defocus deblurring network lacks high-frequency details, which is unsatisfactory in human perception. To overcome this issue, we propose a novel defocus deblurring method that uses the guidance of the defocus map to implement image deblurring. The proposed method consists of a learnable blur kernel to estimate the defocus map, which is an unsupervised method, and a single-image defocus deblurring generative adversarial network (DefocusGAN) for the first time. The proposed network can learn the deblurring of different regions and recover realistic details. We propose a defocus adversarial loss to guide this training process. Competitive experimental results confirm that with a learnable blur kernel, the generated defocus map can achieve results comparable to supervised methods. In the single-image defocus deblurring task, the proposed method achieves state-of-the-art results, especially significant improvements in perceptual quality, where PSNR reaches 25.56 dB and LPIPS reaches 0.111.","https://ojs.aaai.org/index.php/AAAI/article/view/25446/25218"
"25447","Darwinian Model Upgrades: Model Evolving with Selective Compatibility","['Binjie Zhang', 'Shupeng Su', 'Yixiao Ge', 'Xuyuan Xu', 'Yexin Wang', 'Chun Yuan', 'Mike Zheng Shou', 'Ying Shan']","['National University of Singapore\nARC Lab, Tencent PCG\nTsinghua University', 'ARC Lab, Tencent PCG', 'ARC Lab, Tencent PCG', 'AI Technology Center of Tencent Video', 'AI Technology Center of Tencent Video', 'Tsinghua University', 'National University of Singapore', 'ARC Lab, Tencent PCG']","['CV: Image and Video Retrieval', 'CV: Representation Learning for Vision']","Zhang, B., Su, S., Ge, Y., Xu, X., Wang, Y., Yuan, C., Shou, M. Z., & Shan, Y. (2023). Darwinian Model Upgrades: Model Evolving with Selective Compatibility. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3393-3400. https://doi.org/10.1609/aaai.v37i3.25447","Abstract 					The traditional model upgrading paradigm for retrieval requires recomputing all gallery embeddings before deploying the new model (dubbed as ""backfilling""), which is quite expensive and time-consuming considering billions of instances in industrial applications. BCT presents the first step towards backward-compatible model upgrades to get rid of backfilling. It is workable but leaves the new model in a dilemma between new feature discriminativeness and new-to-old compatibility due to the undifferentiated compatibility constraints. In this work, we propose Darwinian Model Upgrades (DMU), which disentangle the inheritance and variation in the model evolving with selective backward compatibility and forward adaptation, respectively. The old-to-new heritable knowledge is measured by old feature discriminativeness, and the gallery features, especially those of poor quality, are evolved in a lightweight manner to become more adaptive in the new latent space. We demonstrate the superiority of DMU through comprehensive experiments on large-scale landmark retrieval and face recognition benchmarks. DMU effectively alleviates the new-to-new degradation at the same time improving new-to-old compatibility, rendering a more proper model upgrading paradigm in large-scale retrieval systems.Code: https://github.com/TencentARC/OpenCompatible.","https://ojs.aaai.org/index.php/AAAI/article/view/25447/25219"
"25448","Mx2M: Masked Cross-Modality Modeling in Domain Adaptation for 3D Semantic Segmentation","['Boxiang Zhang', 'Zunran Wang', 'Yonggen Ling', 'Yuanyuan Guan', 'Shenghao Zhang', 'Wenhui Li']","['Jilin University', 'Tencent Robotics X', 'Tencent Robotics X', 'Jilin University', 'Tencent Robotics X', 'Jilin University']","['CV: Segmentation', 'CV: 3D Computer Vision', 'CV: Multi-modal Vision', 'CV: Representation Learning for Vision', 'CV: Scene Analysis & Understanding', 'CV: Vision for Robotics & Autonomous Driving', 'ML: Applications']","Zhang, B., Wang, Z., Ling, Y., Guan, Y., Zhang, S., & Li, W. (2023). Mx2M: Masked Cross-Modality Modeling in Domain Adaptation for 3D Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3401-3409. https://doi.org/10.1609/aaai.v37i3.25448","Abstract 					Existing methods of cross-modal domain adaptation for 3D semantic segmentation predict results only via 2D-3D complementarity that is obtained by cross-modal feature matching. However, as lacking supervision in the target domain, the complementarity is not always reliable. The results are not ideal when the domain gap is large. To solve the problem of lacking supervision, we introduce masked modeling into this task and propose a method Mx2M, which utilizes masked cross-modality modeling to reduce the large domain gap. Our Mx2M contains two components. One is the core solution, cross-modal removal and prediction (xMRP), which makes the Mx2M adapt to various scenarios and provides cross-modal self-supervision. The other is a new way of cross-modal feature matching, the dynamic cross-modal filter (DxMF) that ensures the whole method dynamically uses more suitable 2D-3D complementarity. Evaluation of the Mx2M on three DA scenarios, including Day/Night, USA/Singapore, and A2D2/SemanticKITTI, brings large improvements over previous methods on many metrics.","https://ojs.aaai.org/index.php/AAAI/article/view/25448/25220"
"25449","Few-Shot 3D Point Cloud Semantic Segmentation via Stratified Class-Specific Attention Based Transformer Network","['Canyu Zhang', 'Zhenyao Wu', 'Xinyi Wu', 'Ziyu Zhao', 'Song Wang']","['University of South Carolina', 'University of South Carolina', 'University of South Carolina', 'University of South Carolina', 'University of South Carolina']","['CV: 3D Computer Vision', 'CV: Segmentation', 'CV: Applications']","Zhang, C., Wu, Z., Wu, X., Zhao, Z., & Wang, S. (2023). Few-Shot 3D Point Cloud Semantic Segmentation via Stratified Class-Specific Attention Based Transformer Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3410-3417. https://doi.org/10.1609/aaai.v37i3.25449","Abstract 					3D point cloud semantic segmentation aims to group all points into different semantic categories, which benefits important applications such as point cloud scene reconstruction and understanding. Existing supervised point cloud semantic segmentation methods usually require large-scale annotated point clouds for training and cannot handle new categories. While a few-shot learning method was proposed recently to address these two problems, it suffers from high computational complexity caused by graph construction and inability to learn fine-grained relationships among points due to the use of pooling operations. In this paper, we further address these problems by developing a new multi-layer transformer network for few-shot point cloud semantic segmentation. In the proposed network, the query point cloud features are aggregated based on the class-specific support features in different scales. Without using pooling operations, our method makes full use of all pixel-level features from the support samples. By better leveraging the support features for few-shot learning, the proposed method achieves the new state-of-the-art performance, with 15% less inference time, over existing few-shot 3D point cloud segmentation models on the S3DIS dataset and the ScanNet dataset. Our code is available at https://github.com/czzhang179/SCAT.","https://ojs.aaai.org/index.php/AAAI/article/view/25449/25221"
"25450","PaRot: Patch-Wise Rotation-Invariant Network via Feature Disentanglement and Pose Restoration","['Dingxin Zhang', 'Jianhui Yu', 'Chaoyi Zhang', 'Weidong Cai']","['School of Computer Science, University of Sydney', 'School of Computer Science, University of Sydney', 'School of Computer Science, University of Sydney', 'School of Computer Science, University of Sydney']","['CV: 3D Computer Vision']","Zhang, D., Yu, J., Zhang, C., & Cai, W. (2023). PaRot: Patch-Wise Rotation-Invariant Network via Feature Disentanglement and Pose Restoration. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3418-3426. https://doi.org/10.1609/aaai.v37i3.25450","Abstract 					Recent interest in point cloud analysis has led rapid progress in designing deep learning methods for 3D models. However, state-of-the-art models are not robust to rotations, which remains an unknown prior to real applications and harms the model performance. In this work, we introduce a novel Patch-wise Rotation-invariant network (PaRot), which achieves rotation invariance via feature disentanglement and produces consistent predictions for samples with arbitrary rotations. Specifically, we design a siamese training module which disentangles rotation invariance and equivariance from patches defined over different scales, e.g., the local geometry and global shape, via a pair of rotations. However, our disentangled invariant feature loses the intrinsic pose information of each patch. To solve this problem, we propose a rotation-invariant geometric relation to restore the relative pose with equivariant information for patches defined over different scales. Utilising the pose information, we propose a hierarchical module which implements intra-scale and inter-scale feature aggregation for 3D shape learning. Moreover, we introduce a pose-aware feature propagation process with the rotation-invariant relative pose information embedded. Experiments show that our disentanglement module extracts high-quality rotation-robust features and the proposed lightweight model achieves competitive results in rotated 3D object classification and part segmentation tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25450/25222"
"25451","Hierarchical Consistent Contrastive Learning for Skeleton-Based Action Recognition with Growing Augmentations","['Jiahang Zhang', 'Lilang Lin', 'Jiaying Liu']","['Wangxuan Institute of Computer Technology, Peking University', 'Wangxuan Institute of Computer Technology, Peking University', 'Wangxuan Institute of Computer Technology, Peking University']","['CV: Video Understanding & Activity Analysis', 'CV: Representation Learning for Vision', 'ML: Unsupervised & Self-Supervised Learning']","Zhang, J., Lin, L., & Liu, J. (2023). Hierarchical Consistent Contrastive Learning for Skeleton-Based Action Recognition with Growing Augmentations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3427-3435. https://doi.org/10.1609/aaai.v37i3.25451","Abstract 					Contrastive learning has been proven beneficial for self-supervised skeleton-based action recognition. Most contrastive learning methods utilize carefully designed augmentations to generate different movement patterns of skeletons for the same semantics. However, it is still a pending issue to apply strong augmentations, which distort the images/skeletons’ structures and cause semantic loss, due to their resulting unstable training. In this paper, we investigate the potential of adopting strong augmentations and propose a general hierarchical consistent contrastive learning framework (HiCLR) for skeleton-based action recognition. Specifically, we first design a gradual growing augmentation policy to generate multiple ordered positive pairs, which guide to achieve the consistency of the learned representation from different views. Then, an asymmetric loss is proposed to enforce the hierarchical consistency via a directional clustering operation in the feature space, pulling the representations from strongly augmented views closer to those from weakly augmented views for better generalizability. Meanwhile, we propose and evaluate three kinds of strong augmentations for 3D skeletons to demonstrate the effectiveness of our method. Extensive experiments show that HiCLR outperforms the state-of-the-art methods notably on three large-scale datasets, i.e., NTU60, NTU120, and PKUMMD. Our project is publicly available at: https://jhang2020.github.io/Projects/HiCLR/HiCLR.html.","https://ojs.aaai.org/index.php/AAAI/article/view/25451/25223"
"25452","ImageNet Pre-training Also Transfers Non-robustness","['Jiaming Zhang', 'Jitao Sang', 'Qi Yi', 'Yunfan Yang', 'Huiwen Dong', 'Jian Yu']","['Beijing Jiaotong University', 'Beijing Jiaotong University\nPeng Cheng Lab', 'Beijing Jiaotong University', 'Beijing Jiaotong University', 'Beijing Normal University', 'Beijing Jiaotong University']","['CV: Adversarial Attacks & Robustness', 'ML: Adversarial Learning & Robustness', 'CV: Representation Learning for Vision', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Zhang, J., Sang, J., Yi, Q., Yang, Y., Dong, H., & Yu, J. (2023). ImageNet Pre-training Also Transfers Non-robustness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3436-3444. https://doi.org/10.1609/aaai.v37i3.25452","Abstract 					ImageNet pre-training has enabled state-of-the-art results on many tasks. In spite of its recognized contribution to generalization, we observed in this study that ImageNet pre-training also transfers adversarial non-robustness from pre-trained model into fine-tuned model in the downstream classification tasks. We first conducted experiments on various datasets and network backbones to uncover the adversarial non-robustness in fine-tuned model. Further analysis was conducted on examining the learned knowledge of fine-tuned model and standard model, and revealed that the reason leading to the non-robustness is the non-robust features transferred from ImageNet pre-trained model. Finally, we analyzed the preference for feature learning of the pre-trained model, explored the factors influencing robustness, and introduced a simple robust ImageNet pre-training solution. Our code is available at https://github.com/jiamingzhang94/ImageNet-Pretraining-transfers-non-robustness.","https://ojs.aaai.org/index.php/AAAI/article/view/25452/25224"
"25453","Language-Assisted 3D Feature Learning for Semantic Scene Understanding","['Junbo Zhang', 'Guofan Fan', 'Guanghan Wang', 'Zhengyuan Su', 'Kaisheng Ma', 'Li Yi']","['Tsinghua University', ""Xi'an Jiaotong University"", 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University\nShanghai Artificial Intelligence Laboratory\nShanghai Qi Zhi Institute']","['CV: 3D Computer Vision', 'CV: Scene Analysis & Understanding', 'CV: Language and Vision', 'CV: Representation Learning for Vision']","Zhang, J., Fan, G., Wang, G., Su, Z., Ma, K., & Yi, L. (2023). Language-Assisted 3D Feature Learning for Semantic Scene Understanding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3445-3453. https://doi.org/10.1609/aaai.v37i3.25453","Abstract 					Learning descriptive 3D features is crucial for understanding 3D scenes with diverse objects and complex structures. However, it is usually unknown whether important geometric attributes and scene context obtain enough emphasis in an end-to-end trained 3D scene understanding network. To guide 3D feature learning toward important geometric attributes and scene context, we explore the help of textual scene descriptions. Given some free-form descriptions paired with 3D scenes, we extract the knowledge regarding the object relationships and object attributes. We then inject the knowledge to 3D feature learning through three classification-based auxiliary tasks. This language-assisted training can be combined with modern object detection and instance segmentation methods to promote 3D semantic scene understanding, especially in a label-deficient regime. Moreover, the 3D feature learned with language assistance is better aligned with the language features, which can benefit various 3D-language multimodal tasks. Experiments on several benchmarks of 3D-only and 3D-language tasks demonstrate the effectiveness of our language-assisted 3D feature learning.  Code is available at https://github.com/Asterisci/Language-Assisted-3D.","https://ojs.aaai.org/index.php/AAAI/article/view/25453/25225"
"25454","IKOL: Inverse Kinematics Optimization Layer for 3D Human Pose and Shape Estimation via Gauss-Newton Differentiation","['Juze Zhang', 'Ye Shi', 'Yuexin Ma', 'Lan Xu', 'Jingyi Yu', 'Jingya Wang']","['ShanghaiTech University\nShanghai Advanced Research Institute, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences\nShanghai Engineering Research Center of Intelligent Vision and Imaging', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging', 'ShanghaiTech University\nShanghai Engineering Research Center of Intelligent Vision and Imaging']","['CV: 3D Computer Vision', 'CV: Biometrics', 'Face', 'Gesture & Pose']","Zhang, J., Shi, Y., Ma, Y., Xu, L., Yu, J., & Wang, J. (2023). IKOL: Inverse Kinematics Optimization Layer for 3D Human Pose and Shape Estimation via Gauss-Newton Differentiation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3454-3462. https://doi.org/10.1609/aaai.v37i3.25454","Abstract 					This paper presents an inverse kinematic optimization layer (IKOL) for 3D human pose and shape estimation that leverages the strength of both optimization- and regression-based methods within an end-to-end framework. IKOL involves a nonconvex optimization that establishes an implicit mapping from an image’s 3D keypoints and body shapes to the relative body-part rotations. The 3D keypoints and the body shapes are the inputs and the relative body-part rotations are the solutions. However, this procedure is implicit and hard to make differentiable. So, to overcome this issue, we designed a Gauss-Newton differentiation (GN-Diff) procedure to differentiate IKOL. GN-Diff iteratively linearizes the nonconvex objective function to obtain Gauss-Newton directions with closed form solutions. Then, an automatic differentiation procedure is directly applied to generate a Jacobian matrix for end-to-end training. Notably, the GN-Diff procedure works fast because it does not rely on a time-consuming implicit differentiation procedure. The twist rotation and shape parameters are learned from the neural networks and, as a result, IKOL has a much lower computational overhead than most existing optimization-based methods. Additionally, compared to existing regression-based methods, IKOL provides a more accurate mesh-image correspondence. This is because it iteratively reduces the distance between the keypoints and also enhances the reliability of the pose structures. Extensive experiments demonstrate the superiority of our proposed framework over a wide range of 3D human pose and shape estimation methods. Code is available at  https://github.com/Juzezhang/IKOL","https://ojs.aaai.org/index.php/AAAI/article/view/25454/25226"
"25455","Mind the Gap: Polishing Pseudo Labels for Accurate Semi-supervised Object Detection","['Lei Zhang', 'Yuxuan Sun', 'Wei Wei']","['Northwestern Polytechnical University', 'Northwestern Polytechnical University', 'Northwestern Polytechnical University']","['CV: Object Detection & Categorization', 'ML: Semi-Supervised Learning']","Zhang, L., Sun, Y., & Wei, W. (2023). Mind the Gap: Polishing Pseudo Labels for Accurate Semi-supervised Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3463-3471. https://doi.org/10.1609/aaai.v37i3.25455","Abstract 					Exploiting pseudo labels (e.g., categories and bounding boxes) of unannotated objects produced by a teacher detector have underpinned much of recent progress in semi-supervised object detection (SSOD). However, due to the limited generalization capacity of the teacher detector caused by the scarce annotations, the produced pseudo labels often deviate from ground truth, especially those with relatively low classification confidences, thus limiting the generalization performance of SSOD. To mitigate this problem, we propose a dual pseudo-label polishing framework for SSOD. Instead of directly exploiting the pseudo labels produced by the teacher detector, we take the first attempt at reducing their deviation from ground truth using dual polishing learning, where two differently structured polishing networks are elaborately developed and trained using synthesized paired pseudo labels and the corresponding ground truth for categories and bounding boxes on the given annotated objects, respectively. By doing this, both polishing networks can infer more accurate pseudo labels for unannotated objects through sufficiently exploiting their context knowledge based on the initially produced pseudo labels, and thus improve the generalization performance of SSOD. Moreover, such a scheme can be seamlessly plugged into the existing SSOD framework for joint end-to-end learning. In addition, we propose to disentangle the polished pseudo categories and bounding boxes of unannotated objects for separate category classification and bounding box regression in SSOD, which enables introducing more unannotated objects during model training and thus further improves the performance. Experiments on both PASCAL VOC and MS-COCO benchmarks demonstrate the superiority of the proposed method over existing state-of-the-art baselines. The code can be found at https://github.com/snowdusky/DualPolishLearning.","https://ojs.aaai.org/index.php/AAAI/article/view/25455/25227"
"25456","ConvMatch: Rethinking Network Design for Two-View Correspondence Learning","['Shihua Zhang', 'Jiayi Ma']","['Wuhan University', 'Wuhan University']","['CV: Motion & Tracking', 'CV: 3D Computer Vision', 'CV: Image and Video Retrieval']","Zhang, S., & Ma, J. (2023). ConvMatch: Rethinking Network Design for Two-View Correspondence Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3472-3479. https://doi.org/10.1609/aaai.v37i3.25456","Abstract 					Multilayer perceptron (MLP) has been widely used in two-view correspondence learning for only unordered correspondences provided, and it extracts deep features from individual correspondence effectively. However, the problem of lacking context information limits its performance and hence, many extra complex blocks are designed to capture such information in the follow-up studies. In this paper, from a novel perspective, we design a correspondence learning network called ConvMatch that for the first time can leverage convolutional neural network (CNN) as the backbone to capture better context, thus avoiding the complex design of extra blocks. Specifically, with the observation that sparse motion vectors and dense motion field can be converted into each other with interpolating and sampling, we regularize the putative motion vectors by estimating dense motion field implicitly, then rectify the errors caused by outliers in local areas with CNN, and finally obtain correct motion vectors from the rectified motion field. Extensive experiments reveal that ConvMatch with a simple CNN backbone consistently outperforms state-of-the-arts including MLP-based methods for relative pose estimation and homography estimation, and shows promising generalization ability to different datasets and descriptors. Our code is publicly available at https://github.com/SuhZhang/ConvMatch.","https://ojs.aaai.org/index.php/AAAI/article/view/25456/25228"
"25457","Cross-View Geo-Localization via Learning Disentangled Geometric Layout Correspondence","['Xiaohan Zhang', 'Xingyu Li', 'Waqas Sultani', 'Yi Zhou', 'Safwan Wshah']","['University of Vermont', 'Shanghai Center for Brain Science and Brain-Inspired Technology', 'Information Technology University', 'University of Science and Technology of China', 'University of Vermont']","['CV: Image and Video Retrieval', 'CV: Applications']","Zhang, X., Li, X., Sultani, W., Zhou, Y., & Wshah, S. (2023). Cross-View Geo-Localization via Learning Disentangled Geometric Layout Correspondence. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3480-3488. https://doi.org/10.1609/aaai.v37i3.25457","Abstract 					Cross-view geo-localization aims to estimate the location of a query ground image by matching it to a reference geo-tagged aerial images database. As an extremely challenging task, its difficulties root in the drastic view changes and different capturing time between two views. Despite these difficulties, recent works achieve outstanding progress on cross-view geo-localization benchmarks. However, existing methods still suffer from poor performance on the cross-area benchmarks, in which the training and testing data are captured from two different regions. We attribute this deficiency to the lack of ability to extract the spatial configuration of visual feature layouts and models' overfitting on low-level details from the training set. In this paper, we propose GeoDTR which explicitly disentangles geometric information from raw features and learns the spatial correlations among visual features from aerial and ground pairs with a novel geometric layout extractor module. This module generates a set of geometric layout descriptors, modulating the raw features and producing high-quality latent representations. In addition, we elaborate on two categories of data augmentations, (i) Layout simulation, which varies the spatial configuration while keeping the low-level details intact. (ii) Semantic augmentation, which alters the low-level details and encourages the model to capture spatial configurations. These augmentations help to improve the performance of the cross-view geo-localization models, especially on the cross-area benchmarks. Moreover, we propose a counterfactual-based learning process to benefit the geometric layout extractor in exploring spatial information. Extensive experiments show that GeoDTR not only achieves state-of-the-art results but also significantly boosts the performance on same-area and cross-area benchmarks. Our code can be found at https://gitlab.com/vail-uvm/geodtr.","https://ojs.aaai.org/index.php/AAAI/article/view/25457/25229"
"25458","Video Compression Artifact Reduction by Fusing Motion Compensation and Global Context in a Swin-CNN Based Parallel Architecture","['Xinjian Zhang', 'Su Yang', 'Wuyang Luo', 'Longwen Gao', 'Weishan Zhang']","['Fudan University\nShanghai Key Laboratory of Intelligent Information Processing', 'Fudan University\nShanghai Key Laboratory of Intelligent Information Processing', 'Fudan University\nShanghai Key Laboratory of Intelligent Information Processing', 'Bilibili', 'China University of Petroleum (East China)']","['CV: Low Level & Physics-Based Vision', 'CV: Applications']","Zhang, X., Yang, S., Luo, W., Gao, L., & Zhang, W. (2023). Video Compression Artifact Reduction by Fusing Motion Compensation and Global Context in a Swin-CNN Based Parallel Architecture. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3489-3497. https://doi.org/10.1609/aaai.v37i3.25458","Abstract 					Video Compression Artifact Reduction aims to reduce the artifacts caused by video compression algorithms and improve the quality of compressed video frames. The critical challenge in this task is to make use of the redundant high-quality information in compressed frames for compensation as much as possible. Two important possible compensations: Motion compensation and global context, are not comprehensively considered in previous works, leading to inferior results. The key idea of this paper is to fuse the motion compensation and global context together to gain more compensation information to improve the quality of compressed videos. Here, we propose a novel Spatio-Temporal Compensation Fusion (STCF) framework with the Parallel Swin-CNN Fusion (PSCF) block, which can simultaneously learn and merge the motion compensation and global context to reduce the video compression artifacts. Specifically, a temporal self-attention strategy based on shifted windows is developed to capture the global context in an efficient way, for which we use the Swin transformer layer in the PSCF block. Moreover, an additional Ada-CNN layer is applied in the PSCF block to extract the motion compensation. Experimental results demonstrate that our proposed STCF framework outperforms the state-of-the-art methods up to 0.23dB (27% improvement) on the MFQEv2 dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/25458/25230"
"25459","MRCN: A Novel Modality Restitution and Compensation Network for Visible-Infrared Person Re-identification","['Yukang Zhang', 'Yan Yan', 'Jie Li', 'Hanzi Wang']","['Fujian Key Laboratory of Sensing and Computing for Smart City, School of Informatics, Xiamen University, China', 'Fujian Key Laboratory of Sensing and Computing for Smart City, School of Informatics, Xiamen University, China', 'Video and Image Processing System Laboratory, School of Electronic Engineering, Xidian University, Xi’an, China', 'Fujian Key Laboratory of Sensing and Computing for Smart City, School of Informatics, Xiamen University, China\nShanghai Artificial Intelligence Laboratory, Shanghai, China']","['CV: Multi-modal Vision', 'CV: Image and Video Retrieval', 'ML: Multimodal Learning', 'CV: Applications', 'CV: Representation Learning for Vision']","Zhang, Y., Yan, Y., Li, J., & Wang, H. (2023). MRCN: A Novel Modality Restitution and Compensation Network for Visible-Infrared Person Re-identification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3498-3506. https://doi.org/10.1609/aaai.v37i3.25459","Abstract 					Visible-infrared person re-identification (VI-ReID), which aims to search identities across different spectra, is a challenging task due to large cross-modality discrepancy between visible and infrared images. The key to reduce the discrepancy is to filter out identity-irrelevant interference and effectively learn modality-invariant person representations. In this paper, we propose a novel Modality Restitution and Compensation Network (MRCN) to narrow the gap between the two modalities. Specifically, we first reduce the modality discrepancy by using two Instance Normalization (IN) layers. Next, to reduce the influence of IN layers on removing discriminative information and to reduce modality differences, we propose a Modality Restitution Module (MRM) and a Modality Compensation Module (MCM) to respectively distill modality-irrelevant and modality-relevant features from the removed information. Then, the modality-irrelevant features are used to restitute to the normalized visible and infrared features, while the modality-relevant features are used to compensate for the features of the other modality. Furthermore, to better disentangle the modality-relevant features and the modality-irrelevant features, we propose a novel Center-Quadruplet Causal (CQC) loss to encourage the network to effectively learn the modality-relevant features and the modality-irrelevant features. Extensive experiments are conducted to validate the superiority of our method on the challenging SYSU-MM01 and RegDB datasets. More remarkably, our method achieves 95.1% in terms of Rank-1 and 89.2% in terms of mAP on the RegDB dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/25459/25231"
"25460","A Simple Baseline for Multi-Camera 3D Object Detection","['Yunpeng Zhang', 'Wenzhao Zheng', 'Zheng Zhu', 'Guan Huang', 'Jiwen Lu', 'Jie Zhou']","['PhiGent Robotics', 'Department of Automation, Tsinghua University', 'PhiGent Robotics', 'PhiGent Robotics', 'Department of Automation, Tsinghua University', 'Department of Automation, Tsinghua University']","['CV: Object Detection & Categorization', 'CV: 3D Computer Vision', 'CV: Scene Analysis & Understanding']","Zhang, Y., Zheng, W., Zhu, Z., Huang, G., Lu, J., & Zhou, J. (2023). A Simple Baseline for Multi-Camera 3D Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3507-3515. https://doi.org/10.1609/aaai.v37i3.25460","Abstract 					3D object detection with surrounding cameras has been a promising direction for autonomous driving. In this paper, we present SimMOD, a Simple baseline for Multi-camera Object Detection, to solve the problem. To incorporate multiview information as well as build upon previous efforts on monocular 3D object detection, the framework is built on sample-wise object proposals and designed to work in a twostage manner. First, we extract multi-scale features and generate the perspective object proposals on each monocular image. Second, the multi-view proposals are aggregated and then iteratively refined with multi-view and multi-scale visual features in the DETR3D-style. The refined proposals are endto-end decoded into the detection results. To further boost the performance, we incorporate the auxiliary branches alongside the proposal generation to enhance the feature learning. Also, we design the methods of target filtering and teacher forcing to promote the consistency of two-stage training. We conduct extensive experiments on the 3D object detection benchmark of nuScenes to demonstrate the effectiveness of SimMOD and achieve competitive performance. Code will be available at https://github.com/zhangyp15/SimMOD.","https://ojs.aaai.org/index.php/AAAI/article/view/25460/25232"
"25461","Positional Label for Self-Supervised Vision Transformer","['Zhemin Zhang', 'Xun Gong']","['School of Computing and Artificial Intelligence, Southwest Jiaotong University, Chengdu, Sichuan, China', 'School of Computing and Artificial Intelligence, Southwest Jiaotong University, Chengdu, Sichuan, China\nEngineering Research Center of Sustainable Urban Intelligent Transportation, Ministry of Education, China\nManufacturing Industry Chains Collaboration and Information Support Technology Key Laboratory of Sichuan Province, Chengdu, Sichuan, China']","['CV: Object Detection & Categorization', 'CV: Representation Learning for Vision']","Zhang, Z., & Gong, X. (2023). Positional Label for Self-Supervised Vision Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3516-3524. https://doi.org/10.1609/aaai.v37i3.25461","Abstract 					Positional encoding is important for vision transformer (ViT) to capture the spatial structure of the input image. General effectiveness has been proven in ViT. In our work we propose to train ViT to recognize the positional label of patches of the input image, this apparently simple task actually yields a meaningful self-supervisory task. Based on previous work on ViT positional encoding, we propose two positional labels dedicated to 2D images including absolute position and relative position. Our positional labels can be easily plugged into various current ViT variants. It can work in two ways: (a) As an auxiliary training target for vanilla ViT for better performance. (b) Combine the self-supervised ViT to provide a more powerful self-supervised signal for semantic feature learning. Experiments demonstrate that with the proposed self-supervised methods, ViT-B and Swin-B gain improvements of 1.20% (top-1 Acc) and 0.74% (top-1 Acc) on ImageNet, respectively, and 6.15% and 1.14% improvement on Mini-ImageNet. The code is publicly available at: https://github.com/zhangzhemin/PositionalLabel.","https://ojs.aaai.org/index.php/AAAI/article/view/25461/25233"
"25462","Cross-Category Highlight Detection via Feature Decomposition and Modality Alignment","['Zhenduo Zhang']","['Tencent, China']","['CV: Video Understanding & Activity Analysis', 'CV: Representation Learning for Vision']","Zhang, Z. (2023). Cross-Category Highlight Detection via Feature Decomposition and Modality Alignment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3525-3533. https://doi.org/10.1609/aaai.v37i3.25462","Abstract 					Learning an autonomous highlight video detector with good transferability across video categories,  called Cross-Category Video Highlight Detection(CC-VHD),  is crucial for the practical application on video-based media platforms. To tackle this problem, we first propose a framework that treats the CC-VHD as learning category-independent highlight feature representation. Under this framework,  we propose a novel module, named Multi-task Feature Decomposition Branch which jointly conducts label prediction,  cyclic feature reconstruction, and adversarial feature reconstruction to decompose the video features into two independent components: highlight-related component and category-related component. Besides,  we propose to align the visual and audio modalities to one aligned feature space before conducting modality fusion, which has not been considered in previous works. Finally, the extensive experimental results on three challenging public benchmarks validate the efficacy of our paradigm and the superiority over the existing state-of-the-art approaches to video highlight detection.","https://ojs.aaai.org/index.php/AAAI/article/view/25462/25234"
"25463","TrEP: Transformer-Based Evidential Prediction for Pedestrian Intention with Uncertainty","['Zhengming Zhang', 'Renran Tian', 'Zhengming Ding']","['Purdue University', 'Indiana University-Purdue University Indianapolis', 'Tulane University']","['CV: Vision for Robotics & Autonomous Driving', 'HAI: Human Computation', 'ML: Deep Neural Network Algorithms', 'APP: Mobility', 'Driving & Flight']","Zhang, Z., Tian, R., & Ding, Z. (2023). TrEP: Transformer-Based Evidential Prediction for Pedestrian Intention with Uncertainty. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3534-3542. https://doi.org/10.1609/aaai.v37i3.25463","Abstract 					With rapid development in hardware (sensors and processors) and AI algorithms, automated driving techniques have entered the public’s daily life and achieved great success in supporting human driving performance. However, due to the high contextual variations and temporal dynamics in pedestrian behaviors, the interaction between autonomous-driving cars and pedestrians remains challenging, impeding the development of fully autonomous driving systems. This paper focuses on predicting pedestrian intention with a novel transformer-based evidential prediction (TrEP) algorithm. We develop a transformer module towards the temporal correlations among the input features within pedestrian video sequences and a deep evidential learning model to capture the AI uncertainty under scene complexities. Experimental results on three popular pedestrian intent benchmarks have verified the effectiveness of our proposed model over the state-of-the-art. The algorithm performance can be further boosted by controlling the uncertainty level. We systematically compare human disagreements with AI uncertainty to further evaluate AI performance in confusing scenes. The code is released at https://github.com/zzmonlyyou/TrEP.git.","https://ojs.aaai.org/index.php/AAAI/article/view/25463/25235"
"25464","DINet: Deformation Inpainting Network for Realistic Face Visually Dubbing on High Resolution Video","['Zhimeng Zhang', 'Zhipeng Hu', 'Wenjin Deng', 'Changjie Fan', 'Tangjie Lv', 'Yu Ding']","['Netease Fuxi AI Lab', 'NetEase Fuxi AI Lab\nZhejiang University', 'Xiamen University', 'NetEase Fuxi AI Lab', 'NetEase Fuxi AI Lab', 'Netease Fuxi AI Lab\nZhejiang University']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Applications', 'CV: Multi-modal Vision']","Zhang, Z., Hu, Z., Deng, W., Fan, C., Lv, T., & Ding, Y. (2023). DINet: Deformation Inpainting Network for Realistic Face Visually Dubbing on High Resolution Video. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3543-3551. https://doi.org/10.1609/aaai.v37i3.25464","Abstract 					For few-shot learning, it is still a critical challenge to realize photo-realistic face visually dubbing on high-resolution videos. Previous works fail to generate high-fidelity dubbing results. To address the above problem, this paper proposes a Deformation Inpainting Network (DINet) for high-resolution face visually dubbing. Different from previous works relying on multiple up-sample layers to directly generate pixels from latent embeddings, DINet performs spatial deformation on feature maps of reference images to better preserve high-frequency textural details. Specifically, DINet consists of one deformation part and one inpainting part. In the first part, five reference facial images adaptively perform spatial deformation to create deformed feature maps encoding mouth shapes at each frame, in order to align with input driving audio and also the head poses of input source images. In the second part, to produce face visually dubbing, a feature decoder is responsible for adaptively incorporating mouth movements from the deformed feature maps and other attributes (i.e., head pose and upper facial expression) from the source feature maps together. Finally, DINet achieves face visually dubbing with rich textural details. We conduct qualitative and quantitative comparisons to validate our DINet on high-resolution videos. The experimental results show that our method outperforms state-of-the-art works.","https://ojs.aaai.org/index.php/AAAI/article/view/25464/25236"
"25465","ShiftDDPMs: Exploring Conditional Diffusion Models by Shifting Diffusion Trajectories","['Zijian Zhang', 'Zhou Zhao', 'Jun Yu', 'Qi Tian']","['Zhejiang University', 'Zhejiang University', 'Hangzhou Dianzi University', 'Huawei Cloud & AI']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Representation Learning for Vision']","Zhang, Z., Zhao, Z., Yu, J., & Tian, Q. (2023). ShiftDDPMs: Exploring Conditional Diffusion Models by Shifting Diffusion Trajectories. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3552-3560. https://doi.org/10.1609/aaai.v37i3.25465","Abstract 					Diffusion models have recently exhibited remarkable abilities to synthesize striking image samples since the introduction of denoising diffusion probabilistic models (DDPMs). Their key idea is to disrupt images into noise through a fixed forward process and learn its reverse process to generate samples from noise in a denoising way. For conditional DDPMs, most existing practices relate conditions only to the reverse process and fit it to the reversal of unconditional forward process. We find this will limit the condition modeling and generation in a small time window. In this paper, we propose a novel and flexible conditional diffusion model by introducing conditions into the forward process. We utilize extra latent space to allocate an exclusive diffusion trajectory for each condition based on some shifting rules, which will disperse condition modeling to all timesteps and improve the learning capacity of model. We formulate our method, which we call ShiftDDPMs, and provide a unified point of view on existing related methods. Extensive qualitative and quantitative experiments on image synthesis demonstrate the feasibility and effectiveness of ShiftDDPMs.","https://ojs.aaai.org/index.php/AAAI/article/view/25465/25237"
"25466","Combating Unknown Bias with Effective Bias-Conflicting Scoring and Gradient Alignment","['Bowen Zhao', 'Chen Chen', 'Qian-Wei Wang', 'Anfeng He', 'Shu-Tao Xia']","['Tsinghua University', 'Tencent', 'Tsinghua University\nPeng Cheng Laboratory', 'Tencent', 'Tsinghua University\nPeng Cheng Laboratory']","['CV: Bias', 'Fairness & Privacy', 'CV: Object Detection & Categorization']","Zhao, B., Chen, C., Wang, Q.-W., He, A., & Xia, S.-T. (2023). Combating Unknown Bias with Effective Bias-Conflicting Scoring and Gradient Alignment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3561-3569. https://doi.org/10.1609/aaai.v37i3.25466","Abstract 					Models notoriously suffer from dataset biases which are detrimental to robustness and generalization. The identify-emphasize paradigm shows a promising effect in dealing with unknown biases. However, we find that it is still plagued by two challenges: A, the quality of the identified bias-conflicting samples is far from satisfactory; B, the emphasizing strategies just yield suboptimal performance. In this work, for challenge A, we propose an effective bias-conflicting scoring method to boost the identification accuracy with two practical strategies --- peer-picking and epoch-ensemble. For challenge B, we point out that the gradient contribution statistics can be a reliable indicator to inspect whether the optimization is dominated by bias-aligned samples. Then, we propose gradient alignment, which employs gradient statistics to balance the contributions of the mined bias-aligned and bias-conflicting samples dynamically throughout the learning process, forcing models to leverage intrinsic features to make fair decisions. Experiments are conducted on multiple datasets in various settings, demonstrating that the proposed solution can alleviate the impact of unknown biases and achieve state-of-the-art performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25466/25238"
"25467","RLogist: Fast Observation Strategy on Whole-Slide Images with Deep Reinforcement Learning","['Boxuan Zhao', 'Jun Zhang', 'Deheng Ye', 'Jian Cao', 'Xiao Han', 'Qiang Fu', 'Wei Yang']","['Tencent AI Lab\nShanghai Jiao Tong University', 'Tencent AI Lab', 'Tencent AI Lab', 'Shanghai Jiao Tong University', 'Tencent AI Lab', 'Tencent AI Lab', 'Tencent AI Lab']","['CV: Medical and Biological Imaging', 'APP: Healthcare', 'Medicine & Wellness', 'ML: Reinforcement Learning Algorithms', 'PRS: Routing']","Zhao, B., Zhang, J., Ye, D., Cao, J., Han, X., Fu, Q., & Yang, W. (2023). RLogist: Fast Observation Strategy on Whole-Slide Images with Deep Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3570-3578. https://doi.org/10.1609/aaai.v37i3.25467","Abstract 					Whole-slide images (WSI) in computational pathology have high resolution with gigapixel size, but are generally with sparse regions of interest, which leads to weak diagnostic relevance and data inefficiency for each area in the slide. Most of the existing methods rely on a multiple instance learning framework that requires densely sampling local patches at high magnification. The limitation is evident in the application stage as the heavy computation for extracting patch-level features is inevitable. In this paper, we develop RLogist, a benchmarking deep reinforcement learning (DRL) method for fast observation strategy on WSIs. Imitating the diagnostic logic of human pathologists, our RL agent learns how to find regions of observation value and obtain representative features across multiple resolution levels, without having to analyze each part of the WSI at the high magnification. We benchmark our method on two whole-slide level classification tasks, including detection of metastases in WSIs of lymph node sections, and subtyping of lung cancer. Experimental results demonstrate that RLogist achieves competitive classification performance compared to typical multiple instance learning algorithms, while having a significantly short observation path. In addition, the observation path given by RLogist provides good decision-making interpretability, and its ability of reading path navigation can potentially be used by pathologists for educational/assistive purposes. Our code is available at: https://github.com/tencent-ailab/RLogist.","https://ojs.aaai.org/index.php/AAAI/article/view/25467/25239"
"25468","Learning to Super-resolve Dynamic Scenes for Neuromorphic Spike Camera","['Jing Zhao', 'Ruiqin Xiong', 'Jian Zhang', 'Rui Zhao', 'Hangfan Liu', 'Tiejun Huang']","['Institute of Digital Media, School of Computer Science, Peking University\nNational Engineering Research Center of Visual Technology (NERCVT), Peking University', 'Institute of Digital Media, School of Computer Science, Peking University\nNational Engineering Research Center of Visual Technology (NERCVT), Peking University', 'National Engineering Research Center of Visual Technology (NERCVT), Peking University\nSchool of Electronic and Computer Engineering, Peking University Shenzhe', 'Institute of Digital Media, School of Computer Science, Peking University\nNational Engineering Research Center of Visual Technology (NERCVT), Peking University', 'Center for Biomedical Image Computing and Analytics, University', 'Institute of Digital Media, School of Computer Science, Peking University\nNational Engineering Research Center of Visual Technology (NERCVT), Peking University\nBeijing Academy of Artificial Intelligence']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Low Level & Physics-Based Vision']","Zhao, J., Xiong, R., Zhang, J., Zhao, R., Liu, H., & Huang, T. (2023). Learning to Super-resolve Dynamic Scenes for Neuromorphic Spike Camera. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3579-3587. https://doi.org/10.1609/aaai.v37i3.25468","Abstract 					Spike camera is a kind of neuromorphic sensor that uses a novel ``integrate-and-fire'' mechanism to generate a continuous spike stream to record the dynamic light intensity at extremely high temporal resolution. However, as a trade-off for high temporal resolution, its spatial resolution is limited, resulting in inferior reconstruction details. To address this issue, this paper develops a network (SpikeSR-Net) to super-resolve a high-resolution image sequence from the low-resolution binary spike streams. SpikeSR-Net is designed based on the observation model of spike camera and exploits both the merits of model-based and learning-based methods. To deal with the limited representation capacity of binary data, a pixel-adaptive spike encoder is proposed to convert spikes to latent representation to infer clues on intensity and motion. Then, a motion-aligned super resolver is employed to exploit long-term correlation, so that the dense sampling in temporal domain can be exploited to enhance the spatial resolution without introducing motion blur. Experimental results show that SpikeSR-Net is  promising in super-resolving higher-quality images for spike camera.","https://ojs.aaai.org/index.php/AAAI/article/view/25468/25240"
"25469","TinyNeRF: Towards 100 x Compression of Voxel Radiance Fields","['Tianli Zhao', 'Jiayuan Chen', 'Cong Leng', 'Jian Cheng']","['School of Artifcial Intelligence, University of Chinese Academy of Sciences. Beijing, China\nInstitute of Automation, Chinese Academy of Sciences, Beijing, China\nAIRIA. Nanjing, China\nMaicro.ai. Nanjing, China', 'AIRIA. Nanjing, China\nMaicro.ai. Nanjing, China\nSoutheast University. Nanjing, China', 'Institute of Automation, Chinese Academy of Sciences, Beijing, China\nAIRIA. Nanjing, China\nMaicro.ai. Nanjing, China', 'Institute of Automation, Chinese Academy of Sciences, Beijing, China\nAIRIA. Nanjing, China\nMaicro.ai. Nanjing, China']","['CV: 3D Computer Vision', 'CV: Computational Photography', 'Image & Video Synthesis', 'CV: Learning & Optimization for CV', 'ML: Learning on the Edge & Model Compression']","Zhao, T., Chen, J., Leng, C., & Cheng, J. (2023). TinyNeRF: Towards 100 x Compression of Voxel Radiance Fields. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3588-3596. https://doi.org/10.1609/aaai.v37i3.25469","Abstract 					Voxel grid representation of 3D scene properties has been widely used to improve the training or rendering speed of the Neural Radiance Fields (NeRF) while at the same time achieving high synthesis quality. However, these methods accelerate the original NeRF at the expense of extra storage demand, which hinders their applications in many scenarios. To solve this limitation, we present TinyNeRF, a three-stage pipeline: frequency domain transformation, pruning and quantization that work together to reduce the storage demand of the voxel grids with little to no effects on their speed and synthesis quality. Based on the prior knowledge of visual signals sparsity in the frequency domain, we convert the original voxel grids in the frequency domain via block-wise discrete cosine transformation (DCT). Next, we apply pruning and quantization to enforce the DCT coefficients to be sparse and low-bit. Our method can be optimized from scratch in an end-to-end manner, and can typically compress the original models by 2 orders of magnitude with minimal sacrifice on speed and synthesis quality.","https://ojs.aaai.org/index.php/AAAI/article/view/25469/25241"
"25470","BEST: BERT Pre-training for Sign Language Recognition with Coupling Tokenization","['Weichao Zhao', 'Hezhen Hu', 'Wengang Zhou', 'Jiaxin Shi', 'Houqiang Li']","['University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China\nInstitute of Artificial Intelligence, Hefei Comprehensive National Science Center', 'Huawei Cloud', 'University of Science and Technology of China\nInstitute of Artificial Intelligence, Hefei Comprehensive National Science Center']","['CV: Language and Vision', 'CV: Biometrics', 'Face', 'Gesture & Pose']","Zhao, W., Hu, H., Zhou, W., Shi, J., & Li, H. (2023). BEST: BERT Pre-training for Sign Language Recognition with Coupling Tokenization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3597-3605. https://doi.org/10.1609/aaai.v37i3.25470","Abstract 					In this work, we are dedicated to leveraging the BERT pre-training success and modeling the domain-specific statistics to fertilize the sign language recognition~(SLR) model. Considering the dominance of hand and body in sign language expression, we organize them as pose triplet units and feed them into the Transformer backbone in a frame-wise manner. Pre-training is performed via reconstructing the masked triplet unit from the corrupted input sequence, which learns the hierarchical correlation context cues among internal and external triplet units. Notably, different from the highly semantic word token in BERT, the pose unit is a low-level signal originally locating in continuous space, which prevents the direct adoption of the BERT cross entropy objective. To this end, we bridge this semantic gap via coupling tokenization of the triplet unit. It adaptively extracts the discrete pseudo label from the pose triplet unit, which represents the semantic gesture / body state. After pre-training, we fine-tune the pre-trained encoder on the downstream SLR task, jointly with the newly added task-specific layer. Extensive experiments are conducted to validate the effectiveness of our proposed method, achieving new state-of-the-art performance on all four benchmarks with a notable gain.","https://ojs.aaai.org/index.php/AAAI/article/view/25470/25242"
"25471","MulGT: Multi-Task Graph-Transformer with Task-Aware Knowledge Injection and Domain Knowledge-Driven Pooling for Whole Slide Image Analysis","['Weiqin Zhao', 'Shujun Wang', 'Maximus Yeung', 'Tianye Niu', 'Lequan Yu']","['The University of Hong Kong', 'University of Cambridge', 'The University of Hong Kong', 'Shenzhen Bay Laboratory', 'The University of Hong Kong']","['CV: Medical and Biological Imaging', 'ML: Applications', 'CV: Applications', 'APP: Healthcare', 'Medicine & Wellness']","Zhao, W., Wang, S., Yeung, M., Niu, T., & Yu, L. (2023). MulGT: Multi-Task Graph-Transformer with Task-Aware Knowledge Injection and Domain Knowledge-Driven Pooling for Whole Slide Image Analysis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3606-3614. https://doi.org/10.1609/aaai.v37i3.25471","Abstract 					Whole slide image (WSI) has been widely used to assist automated diagnosis under the deep learning fields. However, most previous works only discuss the SINGLE task setting which is not aligned with real clinical setting, where pathologists often conduct multiple diagnosis tasks simultaneously. Also, it is commonly recognized that the multi-task learning paradigm can improve learning efficiency by exploiting commonalities and differences across multiple tasks. To this end, we present a novel multi-task framework (i.e., MulGT) for WSI analysis by the specially designed Graph-Transformer equipped with Task-aware Knowledge Injection and Domain Knowledge-driven Graph Pooling modules. Basically, with the Graph Neural Network and Transformer as the building commons, our framework is able to learn task-agnostic low-level local information as well as task-specific high-level global representation. Considering that different tasks in WSI analysis depend on different features and properties, we also design a novel Task-aware Knowledge Injection module to transfer the task-shared graph embedding into task-specific feature spaces to learn more accurate representation for different tasks. Further, we elaborately design a novel Domain Knowledge-driven Graph Pooling module for each task to improve both the accuracy and robustness of different tasks by leveraging different diagnosis patterns of multiple tasks. We evaluated our method on two public WSI datasets from TCGA projects, i.e., esophageal carcinoma and kidney carcinoma. Experimental results show that our method outperforms single-task counterparts and the state-of-theart methods on both tumor typing and staging tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25471/25243"
"25472","Grouped Knowledge Distillation for Deep Face Recognition","['Weisong Zhao', 'Xiangyu Zhu', 'Kaiwen Guo', 'Xiao-Yu Zhang', 'Zhen Lei']","['Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China\nSchool of Cyber Security, University of Chinese Academy of Sciences, Beijing, China', 'CBSR&NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, China\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China', 'CBSR&NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China\nSchool of Cyber Security, University of Chinese Academy of Sciences, Beijing, China', 'CBSR&NLPR, Institute of Automation, Chinese Academy of Sciences, Beijing, China\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences, Beijing, China\nCentre for Artificial Intelligence and Robotics, Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences, Hong Kong, China']","['CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Representation Learning for Vision']","Zhao, W., Zhu, X., Guo, K., Zhang, X.-Y., & Lei, Z. (2023). Grouped Knowledge Distillation for Deep Face Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3615-3623. https://doi.org/10.1609/aaai.v37i3.25472","Abstract 					Compared with the feature-based distillation methods, logits distillation can liberalize the requirements of consistent feature dimension between teacher and student networks, while the performance is deemed inferior in face recognition. One major challenge is that the light-weight student network has difficulty fitting the target logits due to its low model capacity, which is attributed to the significant number of identities in face recognition. Therefore, we seek to probe the target logits to extract the primary knowledge related to face identity, and discard the others, to make the distillation more achievable for the student network. Specifically, there is a tail group with near-zero values in the prediction, containing minor knowledge for distillation. To provide a clear perspective of its impact, we first partition the logits into two groups, i.e., Primary Group and Secondary Group, according to the cumulative probability of the softened prediction. Then, we reorganize the Knowledge Distillation (KD) loss of grouped logits into three parts, i.e., Primary-KD, Secondary-KD, and Binary-KD. Primary-KD refers to distilling the primary knowledge from the teacher, Secondary-KD aims to refine minor knowledge but increases the difficulty of distillation, and Binary-KD ensures the consistency of knowledge distribution between teacher and student. We experimentally found that (1) Primary-KD and Binary-KD are indispensable for KD, and (2) Secondary-KD is the culprit restricting KD at the bottleneck. Therefore, we propose a Grouped Knowledge Distillation (GKD) that retains the Primary-KD and Binary-KD but omits Secondary-KD in the ultimate KD loss calculation. Extensive experimental results on popular face recognition benchmarks demonstrate the superiority of proposed GKD over state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25472/25244"
"25473","Style-Content Metric Learning for Multidomain Remote Sensing Object Recognition","['Wenda Zhao', 'Ruikai Yang', 'Yu Liu', 'You He']","['Dalian University of Technology', 'Dalian University of Technology', 'Tsinghua University', 'Tsinghua University']","['CV: Object Detection & Categorization']","Zhao, W., Yang, R., Liu, Y., & He, Y. (2023). Style-Content Metric Learning for Multidomain Remote Sensing Object Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3624-3632. https://doi.org/10.1609/aaai.v37i3.25473","Abstract 					Previous remote sensing recognition approaches predominantly perform well on the training-testing dataset. However, due to large style discrepancies not only among multidomain datasets but also within a single domain, they suffer from obvious performance degradation when applied to unseen domains. In this paper, we propose a style-content metric learning framework to address the generalizable remote sensing object recognition issue. Specifically, we firstly design an inter-class dispersion metric to encourage the model to make decision based on content rather than the style, which is achieved by dispersing predictions generated from the contents of both positive sample and negative sample and the style of input image. Secondly, we propose an intra-class compactness metric to force the model to be less style-biased by compacting classifier's predictions from the content of input image and the styles of positive sample and negative sample. Lastly, we design an intra-class interaction metric to improve model's recognition accuracy by pulling in classifier's predictions obtained from the input image and positive sample. Extensive experiments on four datasets show that our style-content metric learning achieves superior generalization performance against the state-of-the-art competitors. Code and model are available at: https://github.com/wdzhao123/TSCM.","https://ojs.aaai.org/index.php/AAAI/article/view/25473/25245"
"25474","Occupancy Planes for Single-View RGB-D Human Reconstruction","['Xiaoming Zhao', 'Yuan-Ting Hu', 'Zhongzheng Ren', 'Alexander G. Schwing']","['University of Illinois at Urbana-Champaign', 'University of Illinois at Urbana-Champaign', 'University of Illinois at Urbana-Champaign', 'University of Illinois at Urbana-Champaign']","['CV: 3D Computer Vision']","Zhao, X., Hu, Y.-T., Ren, Z., & Schwing, A. G. (2023). Occupancy Planes for Single-View RGB-D Human Reconstruction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3633-3641. https://doi.org/10.1609/aaai.v37i3.25474","Abstract 					Single-view RGB-D human reconstruction with implicit functions is often formulated as per-point classification. Specifically,  a set of 3D locations within the view-frustum of the camera are first projected independently onto the image and a corresponding feature is subsequently extracted for each 3D location. The feature of each 3D location is then used to classify independently whether the corresponding 3D point is inside or outside the observed object. This procedure leads to sub-optimal results because correlations between predictions for neighboring locations are only taken into account implicitly via the extracted features. For more accurate results we propose the occupancy planes (OPlanes) representation, which enables to formulate single-view RGB-D human reconstruction as occupancy prediction on planes which slice through the camera's view frustum. Such a representation provides more flexibility than voxel grids and enables to better leverage correlations than per-point classification. On the challenging S3D data we observe a simple classifier based on the OPlanes representation to yield compelling results, especially in difficult situations with partial occlusions due to other objects and partial visibility, which haven't been addressed by prior work.","https://ojs.aaai.org/index.php/AAAI/article/view/25474/25246"
"25475","Deep Equilibrium Models for Snapshot Compressive Imaging","['Yaping Zhao', 'Siming Zheng', 'Xin Yuan']","['Westlake University, Hangzhou, China\nThe University of Hong Kong, Pokfulam, Hong Kong SAR, China', 'Computer Network Information Center, Chinese Academy of Science, Beijing, China\nUniversity of Chinese Academy of Sciences, Beijing, China', 'Westlake University, Hangzhou, China']","['CV: Computational Photography', 'Image & Video Synthesis']","Zhao, Y., Zheng, S., & Yuan, X. (2023). Deep Equilibrium Models for Snapshot Compressive Imaging. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3642-3650. https://doi.org/10.1609/aaai.v37i3.25475","Abstract 					The ability of snapshot compressive imaging (SCI) systems to efficiently capture high-dimensional (HD) data has led to an inverse problem, which consists of recovering the HD signal from the compressed and noisy measurement. While reconstruction algorithms grow fast to solve it with the recent advances of deep learning, the fundamental issue of accurate and stable recovery remains. To this end, we propose deep equilibrium models (DEQ) for video SCI, fusing data-driven regularization and stable convergence in a theoretically sound manner. Each equilibrium model implicitly learns a nonexpansive operator and analytically computes the fixed point, thus enabling unlimited iterative steps and infinite network depth with only a constant memory requirement in training and testing. Specifically, we demonstrate how DEQ can be applied to two existing models for video SCI reconstruction: recurrent neural networks (RNN) and Plug-and-Play (PnP) algorithms. On a variety of datasets and real data, both quantitative and qualitative evaluations of our results demonstrate the effectiveness and stability of our proposed method. The code and models are available at: https://github.com/IndigoPurple/DEQSCI.","https://ojs.aaai.org/index.php/AAAI/article/view/25475/25247"
"25476","Unsupervised Deep Video Denoising with Untrained Network","['Huan Zheng', 'Tongyao Pang', 'Hui Ji']","['National University of Singapore', 'National University of Singapore', 'National University of Singapore']","['CV: Image and Video Retrieval', 'ML: Unsupervised & Self-Supervised Learning']","Zheng, H., Pang, T., & Ji, H. (2023). Unsupervised Deep Video Denoising with Untrained Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3651-3659. https://doi.org/10.1609/aaai.v37i3.25476","Abstract 					Deep learning has become a prominent tool for video denoising. However, most existing deep video denoising methods require supervised training using noise-free videos. Collecting noise-free videos can be costly and challenging in many applications. Therefore, this paper aims to develop an unsupervised deep learning method for video denoising that only uses a single test noisy video for training. To achieve this, an unsupervised loss function is presented that provides an unbiased estimator of its supervised counterpart defined on noise-free video. Additionally, a temporal attention mechanism is proposed to exploit redundancy among frames. The experiments on video denoising demonstrate that the proposed unsupervised method outperforms existing unsupervised methods and remains competitive against recent supervised deep learning methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25476/25248"
"25477","Attack Can Benefit: An Adversarial Approach to Recognizing Facial Expressions under Noisy Annotations","['Jiawen Zheng', 'Bo Li', 'Shengchuan Zhang', 'Shuang Wu', 'Liujuan Cao', 'Shouhong Ding']","['Xiamen University', 'Tencent', 'Xiamen University', 'Tencent', 'Xiamen University', 'Tencent']","['CV: Biometrics', 'Face', 'Gesture & Pose']","Zheng, J., Li, B., Zhang, S., Wu, S., Cao, L., & Ding, S. (2023). Attack Can Benefit: An Adversarial Approach to Recognizing Facial Expressions under Noisy Annotations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3660-3668. https://doi.org/10.1609/aaai.v37i3.25477","Abstract 					The real-world Facial Expression Recognition (FER) datasets usually exhibit complex scenarios with coupled noise annotations and imbalanced classes distribution, which undoubtedly impede the development of FER methods. To address the aforementioned issues, in this paper, we propose a novel and flexible method to spot noisy labels by leveraging adversarial attack, termed as Geometry Aware Adversarial Vulnerability Estimation (GAAVE). Different from existing state-of-the-art methods of noisy label learning (NLL), our method has no reliance on additional information and is thus easy to generalize to the large-scale real-world FER datasets. Besides, the combination of Dataset Splitting module and Subset Refactoring module mitigates the impact of class imbalance, and the Self-Annotator module facilitates the sufficient use of all training data. Extensive experiments on RAF-DB, FERPlus, AffectNet, and CIFAR-10 datasets validate the effectiveness of our method. The stabilized enhancement based on different methods demonstrates the flexibility of our proposed GAAVE.","https://ojs.aaai.org/index.php/AAAI/article/view/25477/25249"
"25478","Phrase-Level Temporal Relationship Mining for Temporal Sentence Localization","['Minghang Zheng', 'Sizhe Li', 'Qingchao Chen', 'Yuxin Peng', 'Yang Liu']","['Wangxuan Institute of Computer Technology, Peking University, Beijing, China', 'Wangxuan Institute of Computer Technology, Peking University, Beijing, China', 'National Institute of Health Data Science, Peking University, Beijing, China', 'Wangxuan Institute of Computer Technology, Peking University, Beijing, China\nPeng Cheng Laboratory, Shenzhen, China', 'Wangxuan Institute of Computer Technology, Peking University, Beijing, China\nNational Key Laboratory of General Artificial Intelligence, BIGAI, Beijing, China']","['CV: Language and Vision', 'CV: Multi-modal Vision', 'CV: Video Understanding & Activity Analysis']","Zheng, M., Li, S., Chen, Q., Peng, Y., & Liu, Y. (2023). Phrase-Level Temporal Relationship Mining for Temporal Sentence Localization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3669-3677. https://doi.org/10.1609/aaai.v37i3.25478","Abstract 					In this paper, we address the problem of video temporal sentence localization, which aims to localize a target moment from videos according to a given language query. We observe that existing models suffer from a sheer performance drop when dealing with simple phrases contained in the sentence. It reveals the limitation that existing models only capture the annotation bias of the datasets but lack sufficient understanding of the semantic phrases in the query. To address this problem, we propose a phrase-level Temporal Relationship Mining (TRM) framework employing the temporal relationship relevant to the phrase and the whole sentence to have a better understanding of each semantic entity in the sentence. Specifically, we use phrase-level predictions to refine the sentence-level prediction, and use Multiple Instance Learning to improve the quality of phrase-level predictions. We also exploit the consistency and exclusiveness constraints of phrase-level and sentence-level predictions to regularize the training process, thus alleviating the ambiguity of each phrase prediction. The proposed approach sheds light on how machines can understand detailed phrases in a sentence and their compositions in their generality rather than learning the annotation biases. Experiments on the ActivityNet Captions and Charades-STA datasets show the effectiveness of our method on both phrase and sentence temporal localization and enable better model interpretability and generalization when dealing with unseen compositions of seen concepts. Code can be found at https://github.com/minghangz/TRM.","https://ojs.aaai.org/index.php/AAAI/article/view/25478/25250"
"25479","Learning Semantic Degradation-Aware Guidance for Recognition-Driven Unsupervised Low-Light Image Enhancement","['Naishan Zheng', 'Jie Huang', 'Man Zhou', 'Zizheng Yang', 'Qi Zhu', 'Feng Zhao']","['University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China']","['CV: Low Level & Physics-Based Vision']","Zheng, N., Huang, J., Zhou, M., Yang, Z., Zhu, Q., & Zhao, F. (2023). Learning Semantic Degradation-Aware Guidance for Recognition-Driven Unsupervised Low-Light Image Enhancement. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3678-3686. https://doi.org/10.1609/aaai.v37i3.25479","Abstract 					Low-light images suffer severe degradation of low lightness and noise corruption, causing unsatisfactory visual quality and visual recognition performance.  To solve this problem while meeting the unavailability of paired datasets in wide-range scenarios, unsupervised low-light image enhancement (ULLIE) techniques have been developed.  However, these methods are primarily guided to alleviate the degradation effect on visual quality rather than semantic levels, hence limiting their performance in visual recognition tasks.  To this end, we propose to learn a Semantic Degradation-Aware Guidance (SDAG) that perceives the low-light degradation effect on semantic levels in a self-supervised manner, which is further utilized to guide the ULLIE methods. The proposed SDAG utilizes the low-light degradation factors as augmented signals to degrade the low-light images, and then capture their degradation effect on semantic levels.  Specifically, our SDAG employs the subsequent pre-trained recognition model extractor to extract semantic representations, and then learns to self-reconstruct the enhanced low-light image and its augmented degraded images.    By constraining the relative reconstruction effect between the original enhanced image and the augmented formats, our SDAG learns to be aware of the degradation effect on semantic levels in a relative comparison manner.  Moreover, our SDAG is general and can be plugged into the training paradigm of the existing ULLIE methods.   Extensive experiments demonstrate its effectiveness for improving the ULLIE approaches on the downstream recognition tasks while maintaining a competitive visual quality.  Code will be available at https://github.com/zheng980629/SDAG.","https://ojs.aaai.org/index.php/AAAI/article/view/25479/25251"
"25480","Memory-Aided Contrastive Consensus Learning for Co-salient Object Detection","['Peng Zheng', 'Jie Qin', 'Shuo Wang', 'Tian-Zhu Xiang', 'Huan Xiong']","['Nanjing University of Aeronautics and Astronautics', 'Nanjing University of Aeronautics and Astronautics', 'ETH Zurich', 'Inception Institute of Artificial Intelligence', 'Mohamed bin Zayed University of Artificial Intelligence']","['CV: Segmentation', 'CV: Image and Video Retrieval', 'CV: Scene Analysis & Understanding', 'CV: Object Detection & Categorization']","Zheng, P., Qin, J., Wang, S., Xiang, T.-Z., & Xiong, H. (2023). Memory-Aided Contrastive Consensus Learning for Co-salient Object Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3687-3695. https://doi.org/10.1609/aaai.v37i3.25480","Abstract 					Co-salient object detection (CoSOD) aims at detecting common salient objects within a group of relevant source images. Most of the latest works employ the attention mechanism for finding common objects. To achieve accurate CoSOD results with high-quality maps and high efficiency, we propose a novel Memory-aided Contrastive Consensus Learning (MCCL) framework, which is capable of effectively detecting co-salient objects in real time (∼150 fps). To learn better group consensus, we propose the Group Consensus Aggregation Module (GCAM) to abstract the common features of each image group; meanwhile, to make the consensus representation more discriminative, we introduce the Memory-based Contrastive Module (MCM), which saves and updates the consensus of images from different groups in a queue of memories. Finally, to improve the quality and integrity of the predicted maps, we develop an Adversarial Integrity Learning (AIL) strategy to make the segmented regions more likely composed of complete objects with less surrounding noise. Extensive experiments on all the latest CoSOD benchmarks demonstrate that our lite MCCL outperforms 13 cutting-edge models, achieving the new state of the art (∼5.9% and ∼6.2% improvement in S-measure on CoSOD3k and CoSal2015, respectively). Our source codes, saliency maps, and online demos are publicly available at https://github.com/ZhengPeng7/MCCL.","https://ojs.aaai.org/index.php/AAAI/article/view/25480/25252"
"25481","MaskBooster: End-to-End Self-Training for Sparsely Supervised Instance Segmentation","['Shida Zheng', 'Chenshu Chen', 'Xi Yang', 'Wenming Tan']","['Hikvision Research Institute', 'Hikvision Research Institute', 'Hikvision Research Institute', 'Hikvision Research Institute']","['CV: Segmentation', 'ML: Semi-Supervised Learning']","Zheng, S., Chen, C., Yang, X., & Tan, W. (2023). MaskBooster: End-to-End Self-Training for Sparsely Supervised Instance Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3696-3704. https://doi.org/10.1609/aaai.v37i3.25481","Abstract 					The present paper introduces sparsely supervised instance segmentation, with the datasets being fully annotated bounding boxes and sparsely annotated masks. A direct solution to this task is self-training, which is not fully explored for instance segmentation yet. In this paper, we propose MaskBooster for sparsely supervised instance segmentation (SpSIS) with comprehensive usage of pseudo masks. MaskBooster is featured with (1) dynamic and progressive pseudo masks from an online updating teacher model, (2) refining binary pseudo masks with the help of bounding box prior, (3) learning inter-class prediction distribution via knowledge distillation for soft pseudo masks. As an end-to-end and universal self-training framework, MaskBooster can empower fully supervised algorithms and boost their segmentation performance on SpSIS. Abundant experiments are conducted on COCO and BDD100K datasets and validate the effectiveness of MaskBooster. Specifically, on different COCO protocols and BDD100K, we surpass sparsely supervised baseline by a large margin for both Mask RCNN and ShapeProp. MaskBooster on SpSIS also outperforms weakly and semi-supervised instance segmentation state-of-the-art on the datasets with similar annotation budgets.","https://ojs.aaai.org/index.php/AAAI/article/view/25481/25253"
"25482","RSPT: Reconstruct Surroundings and Predict Trajectory for Generalizable Active Object Tracking","['Fangwei Zhong', 'Xiao Bi', 'Yudi Zhang', 'Wei Zhang', 'Yizhou Wang']","['Peking University\nBeijing Institute for General Artificial Intelligence (BIGAI)', 'Peking University', 'Shandong University', 'Shandong University', 'Peking University\nZhengzhou University']","['CV: Vision for Robotics & Autonomous Driving', 'CV: Motion & Tracking', 'CV: Multi-modal Vision']","Zhong, F., Bi, X., Zhang, Y., Zhang, W., & Wang, Y. (2023). RSPT: Reconstruct Surroundings and Predict Trajectory for Generalizable Active Object Tracking. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3705-3714. https://doi.org/10.1609/aaai.v37i3.25482","Abstract 					Active Object Tracking (AOT) aims to maintain a specific relation between the tracker and object(s) by autonomously controlling the motion system of a tracker given observations. It is widely used in various applications such as mobile robots and autonomous driving. However, Building a generalizable active tracker that works robustly across various scenarios remains a challenge, particularly in unstructured environments with cluttered obstacles and diverse layouts. To realize this, we argue that the key is to construct a state representation that can model the geometry structure of the surroundings and the dynamics of the target. To this end, we propose a framework called RSPT to form a structure-aware motion representation by Reconstructing Surroundings and Predicting the target Trajectory. Moreover, we further enhance the generalization of the policy network by training in the asymmetric dueling mechanism.  Empirical results show that RSPT outperforms existing methods in unseen environments, especially those with cluttered obstacles and diverse layouts. We also demonstrate good sim-to-real transfer when deploying RSPT in real-world scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/25482/25254"
"25483","STOA-VLP: Spatial-Temporal Modeling of Object and Action for Video-Language Pre-training","['Weihong Zhong', 'Mao Zheng', 'Duyu Tang', 'Xuan Luo', 'Heng Gong', 'Xiaocheng Feng', 'Bing Qin']","['Harbin Institute of Technology', 'Tencent MLPD', 'Independent Researcher', 'Tencent MLPD', 'Harbin Institute of Technology', 'Harbin Institute of Technology\nPeng Cheng Laboratory', 'Harbin Institute of Technology\nPeng Cheng Laboratory']","['CV: Language and Vision']","Zhong, W., Zheng, M., Tang, D., Luo, X., Gong, H., Feng, X., & Qin, B. (2023). STOA-VLP: Spatial-Temporal Modeling of Object and Action for Video-Language Pre-training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3715-3723. https://doi.org/10.1609/aaai.v37i3.25483","Abstract 					Although large-scale video-language pre-training models, which usually build a global alignment between the video and the text, have achieved remarkable progress on various downstream tasks, the idea of adopting fine-grained information during the pre-training stage is not well explored. In this work, we propose STOA-VLP, a pre-training framework that jointly models object and action information across spatial and temporal dimensions. More specifically, the model regards object trajectories across frames and multiple action features from the video as fine-grained features. Besides, We design two auxiliary tasks to better incorporate both kinds of information into the pre-training process of the video-language model. The first is the dynamic object-text alignment task, which builds a better connection between object trajectories and the relevant noun tokens. The second is the spatial-temporal action set prediction, which guides the model to generate consistent action features by predicting actions found in the text. Extensive experiments on three downstream tasks (video captioning, text-video retrieval, and video question answering) demonstrate the effectiveness of our proposed STOA-VLP (e.g. 3.7 Rouge-L improvements on MSR-VTT video captioning benchmark, 2.9% accuracy improvements on MSVD video question answering benchmark, compared to previous approaches).","https://ojs.aaai.org/index.php/AAAI/article/view/25483/25255"
"25484","Refined Semantic Enhancement towards Frequency Diffusion for Video Captioning","['Xian Zhong', 'Zipeng Li', 'Shuqin Chen', 'Kui Jiang', 'Chen Chen', 'Mang Ye']","['Wuhan University of Technology', 'Wuhan University of Technology', 'Hubei University of Education', 'Wuhan University', 'University of Central Florida', 'Wuhan University']","['CV: Video Understanding & Activity Analysis', 'CV: Language and Vision', 'CV: Multi-modal Vision', 'CV: Scene Analysis & Understanding']","Zhong, X., Li, Z., Chen, S., Jiang, K., Chen, C., & Ye, M. (2023). Refined Semantic Enhancement towards Frequency Diffusion for Video Captioning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3724-3732. https://doi.org/10.1609/aaai.v37i3.25484","Abstract 					Video captioning aims to generate natural language sentences that describe the given video accurately. Existing methods obtain favorable generation by exploring richer visual representations in encode phase or improving the decoding ability. However, the long-tailed problem hinders these attempts at low-frequency tokens, which rarely occur but carry critical semantics, playing a vital role in the detailed generation. In this paper, we introduce a novel Refined Semantic enhancement method towards Frequency Diffusion (RSFD), a captioning model that constantly perceives the linguistic representation of the infrequent tokens. Concretely, a Frequency-Aware Diffusion (FAD) module is proposed to comprehend the semantics of low-frequency tokens to break through generation limitations. In this way, the caption is refined by promoting the absorption of tokens with insufficient occurrence. Based on FAD, we design a Divergent Semantic Supervisor (DSS) module to compensate for the information loss of high-frequency tokens brought by the diffusion process, where the semantics of low-frequency tokens is further emphasized to alleviate the long-tailed problem. Extensive experiments indicate that RSFD outperforms the state-of-the-art methods on two benchmark datasets, i.e., MSR-VTT and MSVD, demonstrate that the enhancement of low-frequency tokens semantics can obtain a competitive generation effect. Code is available at https://github.com/lzp870/RSFD.","https://ojs.aaai.org/index.php/AAAI/article/view/25484/25256"
"25485","Aesthetically Relevant Image Captioning","['Zhipeng Zhong', 'Fei Zhou', 'Guoping Qiu']","['College of Electronics and Information Engineering, Shenzhen University, China\nGuangdong Key Laboratory of Intelligent Information Processing, Shenzhen, China\nShenzhen Institute for Artificial Intelligence and Robotics for Society, China\nGuangdong-Hong Kong Joint Laboratory for Big Data Imaging and Communication, Shenzhen, China', 'College of Electronics and Information Engineering, Shenzhen University, China\nPeng Cheng National Laboratory, Shenzhen, China\nGuangdong Key Laboratory of Intelligent Information Processing, Shenzhen, China\nShenzhen Institute for Artificial Intelligence and Robotics for Society, China\nGuangdong-Hong Kong Joint Laboratory for Big Data Imaging and Communication, Shenzhen, China', 'College of Electronics and Information Engineering, Shenzhen University, China\nPeng Cheng National Laboratory, Shenzhen, China\nGuangdong Key Laboratory of Intelligent Information Processing, Shenzhen, China\nShenzhen Institute for Artificial Intelligence and Robotics for Society, China\nGuangdong-Hong Kong Joint Laboratory for Big Data Imaging and Communication, Shenzhen, China']","['CV: Language and Vision', 'CV: Applications', 'CV: Multi-modal Vision']","Zhong, Z., Zhou, F., & Qiu, G. (2023). Aesthetically Relevant Image Captioning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3733-3741. https://doi.org/10.1609/aaai.v37i3.25485","Abstract 					Image aesthetic quality assessment (AQA) aims to assign numerical aesthetic ratings to images whilst image aesthetic captioning (IAC) aims to generate textual descriptions of the aesthetic aspects of images. In this paper, we study image AQA and IAC together and present a new IAC method termed Aesthetically Relevant Image Captioning (ARIC). Based on the observation that most textual comments of an image are about objects and their interactions rather than aspects of aesthetics, we first introduce the concept of Aesthetic Relevance Score (ARS) of a sentence and have developed a model to automatically label a sentence with its ARS. We then use the ARS to design the ARIC model which includes an ARS weighted IAC loss function and an ARS based diverse aesthetic caption selector (DACS). We present extensive experimental results to show the soundness of the ARS concept and the effectiveness of the ARIC model by demonstrating that texts with higher ARS’s can predict the aesthetic ratings more accurately and that the new ARIC model can generate more accurate, aesthetically more relevant and more diverse image captions. Furthermore, a large new research database containing 510K images with over 5 million comments and 350K aesthetic scores, and code for implementing ARIC, are available at https://github.com/PengZai/ARIC","https://ojs.aaai.org/index.php/AAAI/article/view/25485/25257"
"25486","Polarization-Aware Low-Light Image Enhancement","['Chu Zhou', 'Minggui Teng', 'Youwei Lyu', 'Si Li', 'Chao Xu', 'Boxin Shi']","['Peking University', 'Peking University', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Peking University', 'Peking University']","['CV: Computational Photography', 'Image & Video Synthesis']","Zhou, C., Teng, M., Lyu, Y., Li, S., Xu, C., & Shi, B. (2023). Polarization-Aware Low-Light Image Enhancement. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3742-3750. https://doi.org/10.1609/aaai.v37i3.25486","Abstract 					Polarization-based vision algorithms have found uses in various applications since polarization provides additional physical constraints. However, in low-light conditions, their performance would be severely degenerated since the captured polarized images could be noisy, leading to noticeable degradation in the degree of polarization (DoP) and the angle of polarization (AoP). Existing low-light image enhancement methods cannot handle the polarized images well since they operate in the intensity domain, without effectively exploiting the information provided by polarization. In this paper, we propose a Stokes-domain enhancement pipeline along with a dual-branch neural network to handle the problem in a polarization-aware manner. Two application scenarios (reflection removal and shape from polarization) are presented to show how our enhancement can improve their results.","https://ojs.aaai.org/index.php/AAAI/article/view/25486/25258"
"25487","Progressive Bayesian Inference for Scribble-Supervised Semantic Segmentation","['Chuanwei Zhou', 'Chunyan Xu', 'Zhen Cui']","['Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology']","['CV: Applications']","Zhou, C., Xu, C., & Cui, Z. (2023). Progressive Bayesian Inference for Scribble-Supervised Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3751-3759. https://doi.org/10.1609/aaai.v37i3.25487","Abstract 					The scribble-supervised semantic segmentation is an important yet challenging task in the field of computer vision. To deal with the pixel-wise sparse annotation problem, we propose a Progressive Bayesian Inference (PBI) framework to boost the performance of the scribble-supervised semantic segmentation, which can effectively infer the semantic distribution of these unlabeled pixels to guide the optimization of the segmentation network.  The PBI dynamically improves the model learning from two aspects: the Bayesian inference module (i.e., semantic distribution learning) and the pixel-wise segmenter (i.e., model updating). Specifically, we effectively infer the semantic probability distribution of these unlabeled pixels with our designed Bayesian inference module, where its guidance is estimated through the Bayesian expectation maximization under the situation of partially observed data. The segmenter can be progressively improved under the joint guidance of the original scribble information and the learned semantic distribution. The segmenter optimization and semantic distribution promotion are encapsulated into a unified architecture where they could improve each other with mutual evolution in a progressive fashion. Comprehensive evaluations of several benchmark datasets demonstrate the effectiveness and superiority of our proposed PBI when compared with other state-of-the-art methods applied to the scribble-supervised semantic segmentation task.","https://ojs.aaai.org/index.php/AAAI/article/view/25487/25259"
"25488","Exploratory Inference Learning for Scribble Supervised Semantic Segmentation","['Chuanwei Zhou', 'Zhen Cui', 'Chunyan Xu', 'Cao Han', 'Jian Yang']","['Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology']","['CV: Segmentation']","Zhou, C., Cui, Z., Xu, C., Han, C., & Yang, J. (2023). Exploratory Inference Learning for Scribble Supervised Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3760-3768. https://doi.org/10.1609/aaai.v37i3.25488","Abstract 					Scribble supervised semantic segmentation has achieved great advances in pseudo label exploitation, yet suffers insufficient label exploration for the mass of unannotated regions. In this work, we propose a novel exploratory inference learning (EIL) framework, which facilitates efficient probing on unlabeled pixels and promotes selecting confident candidates for boosting the evolved segmentation. The exploration of unannotated regions is formulated as an iterative decision-making process, where a policy searcher learns to infer in the unknown space and the reward to the exploratory policy is based on a contrastive measurement of candidates. In particular, we devise the contrastive reward with the intra-class attraction and the inter-class repulsion in the feature space w.r.t the pseudo labels. The unlabeled exploration and the labeled exploitation are jointly balanced to improve the segmentation, and framed in a close-looping end-to-end network. Comprehensive evaluations on the benchmark datasets (PASCAL VOC 2012 and PASCAL Context) demonstrate the superiority of our proposed EIL when compared with other state-of-the-art methods for the scribble-supervised semantic segmentation problem.","https://ojs.aaai.org/index.php/AAAI/article/view/25488/25260"
"25489","Dual Memory Units with Uncertainty Regulation for Weakly Supervised Video Anomaly Detection","['Hang Zhou', 'Junqing Yu', 'Wei Yang']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology']","['CV: Video Understanding & Activity Analysis', 'DMKM: Anomaly/Outlier Detection']","Zhou, H., Yu, J., & Yang, W. (2023). Dual Memory Units with Uncertainty Regulation for Weakly Supervised Video Anomaly Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3769-3777. https://doi.org/10.1609/aaai.v37i3.25489","Abstract 					Learning discriminative features for effectively separating abnormal events from normality is crucial for weakly supervised video anomaly detection (WS-VAD) tasks. Existing approaches, both video and segment level label oriented, mainly focus on extracting representations for anomaly data while neglecting the implication of normal data. We observe that such a scheme is sub-optimal, i.e., for better distinguishing anomaly one needs to understand what is a normal state, and may yield a higher false alarm rate. To address this issue, we propose an Uncertainty Regulated Dual Memory Units (UR-DMU) model to learn both the representations of normal data and discriminative features of abnormal data. To be specific, inspired by the traditional global and local structure on graph convolutional networks, we introduce a Global and Local Multi-Head Self Attention (GL-MHSA) module for the Transformer network to obtain more expressive embeddings for capturing associations in videos. Then, we use two memory banks, one additional abnormal memory for tackling hard samples, to store and separate abnormal and normal prototypes and maximize the margins between the two representations. Finally, we propose an uncertainty learning scheme to learn the normal data latent space, that is robust to noise from camera switching, object changing, scene transforming, etc. Extensive experiments on XD-Violence and UCF-Crime datasets demonstrate that our method outperforms the state-of-the-art methods by a sizable margin.","https://ojs.aaai.org/index.php/AAAI/article/view/25489/25261"
"25490","Unsupervised Hierarchical Domain Adaptation for Adverse Weather Optical Flow","['Hanyu Zhou', 'Yi Chang', 'Gang Chen', 'Luxin Yan']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Sun Yat-sen University', 'Huazhong University of Science and Technology']","['CV: Low Level & Physics-Based Vision', 'CV: Motion & Tracking']","Zhou, H., Chang, Y., Chen, G., & Yan, L. (2023). Unsupervised Hierarchical Domain Adaptation for Adverse Weather Optical Flow. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3778-3786. https://doi.org/10.1609/aaai.v37i3.25490","Abstract 					Optical flow estimation has made great progress, but usually suffers from degradation under adverse weather. Although semi/full-supervised methods have made good attempts, the domain shift between the synthetic and real adverse weather images would deteriorate their performance. To alleviate this issue, our start point is to unsupervisedly transfer the knowledge from source clean domain to target degraded domain. Our key insight is that adverse weather does not change the intrinsic optical flow of the scene, but causes a significant difference for the warp error between clean and degraded images. In this work, we propose the first unsupervised framework for adverse weather optical flow via hierarchical motion-boundary adaptation. Specifically, we first employ image translation to construct the transformation relationship between clean and degraded domains. In motion adaptation, we utilize the flow consistency knowledge to align the cross-domain optical flows into a motion-invariance common space, where the optical flow from clean weather is used as the guidance-knowledge to obtain a preliminary optical flow for adverse weather. Furthermore, we leverage the warp error inconsistency which measures the motion misalignment of the boundary between the clean and degraded domains, and propose a joint intra- and inter-scene boundary contrastive adaptation to refine the motion boundary. The hierarchical motion and boundary adaptation jointly promotes optical flow in a unified framework. Extensive quantitative and qualitative experiments have been performed to verify the superiority of the proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/25490/25262"
"25491","PASS: Patch Automatic Skip Scheme for Efficient Real-Time Video Perception on Edge Devices","['Qihua Zhou', 'Song Guo', 'Jun Pan', 'Jiacheng Liang', 'Zhenda Xu', 'Jingren Zhou']","['The Hong Kong Polytechnic University', 'The Hong Kong Polytechnic University', 'The Hong Kong Polytechnic University', 'Pennsylvania State University', 'Hong Kong Polytechnic University', 'Alibaba Group']","['CV: Image and Video Retrieval', 'CV: Motion & Tracking', 'CV: Representation Learning for Vision']","Zhou, Q., Guo, S., Pan, J., Liang, J., Xu, Z., & Zhou, J. (2023). PASS: Patch Automatic Skip Scheme for Efficient Real-Time Video Perception on Edge Devices. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3787-3795. https://doi.org/10.1609/aaai.v37i3.25491","Abstract 					Real-time video perception tasks are often challenging over the resource-constrained edge devices due to the concerns of accuracy drop and hardware overhead, where saving computations is the key to performance improvement. Existing methods either rely on domain-specific neural chips or priorly searched models, which require specialized optimization according to different task properties. In this work, we propose a general and task-independent Patch Automatic Skip Scheme (PASS), a novel end-to-end learning pipeline to support diverse video perception settings by decoupling acceleration and tasks. The gist is to capture the temporal similarity across video frames and skip the redundant computations at patch level, where the patch is a non-overlapping square block in visual. PASS equips each convolution layer with a learnable gate to selectively determine which patches could be safely skipped without degrading model accuracy. As to each layer, a desired gate needs to make flexible skip decisions based on intermediate features without any annotations, which cannot be achieved by conventional supervised learning paradigm. To address this challenge, we are the first to construct a tough self-supervisory procedure for optimizing these gates, which learns to extract contrastive representation, i.e., distinguishing similarity and difference, from frame sequence. These high-capacity gates can serve as a plug-and-play module for convolutional neural network (CNN) backbones to implement patch-skippable architectures, and automatically generate proper skip strategy to accelerate different video-based downstream tasks, e.g., outperforming the state-of-the-art MobileHumanPose (MHP) in 3D pose estimation and FairMOT in multiple object tracking, by up to 9.43 times and 12.19 times speedups, respectively. By directly processing the raw data of frames, PASS can generalize to real-time video streams on commodity edge devices, e.g., NVIDIA Jetson Nano, with efficient performance in realistic deployment.","https://ojs.aaai.org/index.php/AAAI/article/view/25491/25263"
"25492","Robust Feature Rectification of Pretrained Vision Models for Object Recognition","['Shengchao Zhou', 'Gaofeng Meng', 'Zhaoxiang Zhang', 'Richard Yi Da Xu', 'Shiming Xiang']","['NLPR, Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'NLPR, Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences\nCAIR, HK Institute of Science and Innovation, Chinese Academy of Sciences', 'NLPR, Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences\nCAIR, HK Institute of Science and Innovation, Chinese Academy of Sciences', 'FSC1209, Kowloon Tong Campus, Hong Kong Baptist University', 'NLPR, Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences']","['CV: Object Detection & Categorization', 'CV: Applications']","Zhou, S., Meng, G., Zhang, Z., Xu, R. Y. D., & Xiang, S. (2023). Robust Feature Rectification of Pretrained Vision Models for Object Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3796-3804. https://doi.org/10.1609/aaai.v37i3.25492","Abstract 					Pretrained vision models for object recognition often suffer a dramatic performance drop with degradations unseen during training. In this work, we propose a RObust FEature Rectification module (ROFER) to improve the performance of pretrained models against degradations. Specifically, ROFER first estimates the type and intensity of the degradation that corrupts the image features. Then, it leverages a Fully Convolutional Network (FCN) to rectify the features from the degradation by pulling them back to clear features. ROFER is a general-purpose module that can address various degradations simultaneously, including blur, noise, and low contrast. Besides, it can be plugged into pretrained models seamlessly to rectify the degraded features without retraining the whole model. Furthermore, ROFER can be easily extended to address composite degradations by adopting a beam search algorithm to find the composition order. Evaluations on CIFAR-10 and Tiny-ImageNet demonstrate that the accuracy of ROFER is 5% higher than that of SOTA methods on different degradations. With respect to composite degradations, ROFER improves the accuracy of a pretrained CNN by 10% and 6% on CIFAR-10 and Tiny-ImageNet respectively.","https://ojs.aaai.org/index.php/AAAI/article/view/25492/25264"
"25493","Video Object of Interest Segmentation","['Siyuan Zhou', 'Chunru Zhan', 'Biao Wang', 'Tiezheng Ge', 'Yuning Jiang', 'Li Niu']","['Shanghai Jiao Tong University', 'Alibaba Group', 'Alibaba Group', 'Alibaba Group', 'Alibaba Group', 'Shanghai Jiao Tong University']","['CV: Segmentation', 'CV: Video Understanding & Activity Analysis', 'CV: Multi-modal Vision']","Zhou, S., Zhan, C., Wang, B., Ge, T., Jiang, Y., & Niu, L. (2023). Video Object of Interest Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3805-3813. https://doi.org/10.1609/aaai.v37i3.25493","Abstract 					In this work, we present a new computer vision task named video object of interest segmentation (VOIS). Given a video and a target image of interest, our objective is to simultaneously segment and track all objects in the video that are relevant to the target image. This problem combines the traditional video object segmentation task with an additional image indicating the content that users are concerned with. Since no existing dataset is perfectly suitable for this new task, we specifically construct a large-scale dataset called LiveVideos, which contains 2418 pairs of target images and live videos with instance-level annotations. In addition, we propose a transformer-based method for this task. We revisit Swin Transformer and design a dual-path structure to fuse video and image features. Then, a transformer decoder is employed to generate object proposals for segmentation and tracking from the fused features. Extensive experiments on LiveVideos dataset show the superiority of our proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/25493/25265"
"25494","Tree-Structured Trajectory Encoding for Vision-and-Language Navigation","['Xinzhe Zhou', 'Yadong Mu']","['Peking University', 'Peking University, Peng Cheng Laboratory']","['CV: Language and Vision', 'CV: Multi-modal Vision']","Zhou, X., & Mu, Y. (2023). Tree-Structured Trajectory Encoding for Vision-and-Language Navigation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3814-3824. https://doi.org/10.1609/aaai.v37i3.25494","Abstract 					Over the past few years, the research on vision-and-language navigation (VLN) has made tremendous progress. Many previous works attempted to improve the performance from different aspects like training strategy, data augmentation, pre-training, etc. This work focuses on a rarely-explored aspect in VLN, namely the trajectory organization and encoding during the navigation. Most of existing state-of-the-art VLN models adopt a vanilla sequential strategy for encoding the trajectories. Such strategy takes the whole trajectory as a single sequence to estimate the current state,  no matter whether the agent moved smoothly or perhaps made mistakes and backtracked in the past. We show that the sequential encoding may largely lose this kind of fine-grained structure in the trajectory, which could hamper the later state estimation and decision making. In order to solve this problem, this work proposes a novel tree-structured trajectory encoding strategy. The whole trajectory is organized as a tree rooted from the starting position, and encoded using our Tree-Transformer module to fully extract the fine-grained historical information. Besides, as the spatial topology could be easily embedded in the trajectory tree, we further design a tree-based action space to allow the agent making long-range error-correction in one decision. We implement the holistic agent based on cross-modal transformer and train it with a newly-proposed Tree-nDTW reward. On the benchmark dataset R2R, our model achieves a surpassing success rate (SR) of 68% on val-unseen and 66% on test. We further conduct extensive ablation studies and analyses to provide more insights for the effectiveness our designs.","https://ojs.aaai.org/index.php/AAAI/article/view/25494/25266"
"25495","Self-Supervised Action Representation Learning from Partial Spatio-Temporal Skeleton Sequences","['Yujie Zhou', 'Haodong Duan', 'Anyi Rao', 'Bing Su', 'Jiaqi Wang']","['Gaoling School of Artificial Intelligence, Renmin University of China\nShanghai AI Laboratory', 'Chinese University of HongKong', 'Chinese University of Hong Kong', 'Gaoling School of Artificial Intelligence, Renmin University of China\nBeijing Key Laboratory of Big Data Management and Analysis Methods', 'Shanghai AI Laboratory']","['CV: Video Understanding & Activity Analysis', 'CV: Representation Learning for Vision']","Zhou, Y., Duan, H., Rao, A., Su, B., & Wang, J. (2023). Self-Supervised Action Representation Learning from Partial Spatio-Temporal Skeleton Sequences. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3825-3833. https://doi.org/10.1609/aaai.v37i3.25495","Abstract 					Self-supervised learning has demonstrated remarkable capability in representation learning for skeleton-based action recognition. Existing methods mainly focus on applying global data augmentation to generate different views of the skeleton sequence for contrastive learning. However, due to the rich action clues in the skeleton sequences, existing methods may only take a global perspective to learn to discriminate different skeletons without thoroughly leveraging the local relationship between different skeleton joints and video frames, which is essential for real-world applications. In this work, we propose a Partial Spatio-Temporal Learning (PSTL) framework to exploit the local relationship from a partial skeleton sequences built by a unique spatio-temporal masking strategy.  Specifically, we construct a negative-sample-free triplet steam structure that is composed of an anchor stream without any masking, a spatial masking stream with Central Spatial Masking (CSM), and a temporal masking stream with Motion Attention Temporal Masking (MATM). The feature cross-correlation matrix is measured between the anchor stream and the other two masking streams, respectively. (1) Central Spatial Masking discards selected joints from the feature calculation process, where the joints with a higher degree of centrality have a higher possibility of being selected.  (2) Motion Attention Temporal Masking leverages the motion of action and remove frames that move faster with a higher possibility. Our method achieves state-of-the-art performance on NTURGB+D 60, NTURGB+D 120 and PKU-MMD under various downstream tasks. Furthermore, to simulate the real-world scenarios, a practical evaluation is performed where some skeleton joints are lost in downstream tasks.In contrast to previous methods that suffer from large performance drops, our PSTL can still achieve remarkable results under this challenging setting, validating the robustness of our method.","https://ojs.aaai.org/index.php/AAAI/article/view/25495/25267"
"25496","Debiased Fine-Tuning for Vision-Language Models by Prompt Regularization","['Beier Zhu', 'Yulei Niu', 'Saeil Lee', 'Minhoe Hur', 'Hanwang Zhang']","['Nanyang Technological University', 'Columbia University', 'HMGICS AIR Center', 'AIRS Company, Hyundai Motor Group', 'Nanyang Technological University']","['CV: Bias', 'Fairness & Privacy', 'CV: Language and Vision', 'ML: Bias and Fairness', 'ML: Classification and Regression']","Zhu, B., Niu, Y., Lee, S., Hur, M., & Zhang, H. (2023). Debiased Fine-Tuning for Vision-Language Models by Prompt Regularization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3834-3842. https://doi.org/10.1609/aaai.v37i3.25496","Abstract 					We present a new paradigm for fine-tuning large-scale vision-language pre-trained models on downstream task, dubbed Prompt Regularization (ProReg). Different from traditional fine-tuning which easily overfits to the downstream task data, ProReg uses the prediction by prompting the pretrained model to regularize the fine-tuning. The motivation is: by prompting the large model “a photo of a [CLASS]”, the fill-in answer is only dependent on the pretraining encyclopedic knowledge while independent of the task data distribution, which is usually biased. Specifically, given a training sample prediction during fine-tuning, we first calculate its Kullback-Leibler loss of the prompt prediction and Cross-Entropy loss of the ground-truth label, and then combine them with a proposed sample-wise adaptive trade- off weight, which automatically adjusts the transfer between the pretrained and downstream domains. On various out-of-distribution benchmarks, we show the consistently strong performance of ProReg compared with conventional fine-tuning, zero-shot prompt, prompt tuning, and other state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25496/25268"
"25497","Improving Scene Text Image Super-resolution via Dual Prior Modulation Network","['Shipeng Zhu', 'Zuoyan Zhao', 'Pengfei Fang', 'Hui Xue']","['Southeast University', 'Southeast University', 'Southeast University', 'Southeast University']","['CV: Low Level & Physics-Based Vision', 'CV: Applications', 'CV: Multi-modal Vision', 'CV: Scene Analysis & Understanding', 'ML: Applications', 'ML: Deep Generative Models & Autoencoders', 'ML: Deep Neural Network Algorithms', 'ML: Multimodal Learning']","Zhu, S., Zhao, Z., Fang, P., & Xue, H. (2023). Improving Scene Text Image Super-resolution via Dual Prior Modulation Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3843-3851. https://doi.org/10.1609/aaai.v37i3.25497","Abstract 					Scene text image super-resolution (STISR) aims to simultaneously increase the resolution and legibility of the text images, and the resulting images will significantly affect the performance of downstream tasks. Although numerous progress has been made, existing approaches raise two crucial issues: (1) They neglect the global structure of the text, which bounds the semantic determinism of the scene text. (2) The priors, e.g., text prior or stroke prior, employed in existing works, are extracted from pre-trained text recognizers. That said, such priors suffer from the domain gap including low resolution and blurriness caused by poor imaging conditions, leading to incorrect guidance. Our work addresses these gaps and proposes a plug-and-play module dubbed Dual Prior Modulation Network (DPMN), which leverages dual image-level priors to bring performance gain over existing approaches. Specifically, two types of prior-guided refinement modules, each using the text mask or graphic recognition result of the low-quality SR image from the preceding layer, are designed to improve the structural clarity and semantic accuracy of the text, respectively. The following attention mechanism hence modulates two quality-enhanced images to attain a superior SR result. Extensive experiments validate that our method improves the image quality and boosts the performance of downstream tasks over five typical approaches on the benchmark. Substantial visualizations and ablation studies demonstrate the advantages of the proposed DPMN. Code is available at: https://github.com/jdfxzzy/DPMN.","https://ojs.aaai.org/index.php/AAAI/article/view/25497/25269"
"25498","SRoUDA: Meta Self-Training for Robust Unsupervised Domain Adaptation","['Wanqing Zhu', 'Jia-Li Yin', 'Bo-Hao Chen', 'Ximeng Liu']","['Fujian Province Key Laboratory of Information Security and Network Systems, Fuzhou 350108, China\nCollege of Computer Science and Big Data, Fuzhou University, Fuzhou 350108, China', 'Fujian Province Key Laboratory of Information Security and Network Systems, Fuzhou 350108, China\nCollege of Computer Science and Big Data, Fuzhou University, Fuzhou 350108, China', 'Department of Computer Science and Engineering, Yuan Ze University, Taiwan', 'Fujian Province Key Laboratory of Information Security and Network Systems, Fuzhou 350108, China\nCollege of Computer Science and Big Data, Fuzhou University, Fuzhou 350108, China']","['CV: Adversarial Attacks & Robustness', 'ML: Adversarial Learning & Robustness', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Zhu, W., Yin, J.-L., Chen, B.-H., & Liu, X. (2023). SRoUDA: Meta Self-Training for Robust Unsupervised Domain Adaptation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3852-3860. https://doi.org/10.1609/aaai.v37i3.25498","Abstract 					As acquiring manual labels on data could be costly, unsupervised domain adaptation (UDA), which transfers knowledge learned from a rich-label dataset to the unlabeled target dataset, is gaining increasingly more popularity. While extensive studies have been devoted to improving the model accuracy on target domain, an important issue of model robustness is neglected. To make things worse, conventional adversarial training (AT) methods for improving model robustness are inapplicable under UDA scenario since they train models on adversarial examples that are generated by supervised loss function. In this paper, we present a new meta self-training pipeline, named SRoUDA, for improving adversarial robustness of UDA models. Based on self-training paradigm, SRoUDA starts with pre-training a source model by applying UDA baseline on source labeled data and taraget unlabeled data with a developed random masked augmentation (RMA), and then alternates between adversarial target model training on pseudo-labeled target data and fine-tuning source model by a meta step. While self-training allows the direct incorporation of AT in UDA, the meta step in SRoUDA further helps in mitigating error propagation from noisy pseudo labels. Extensive experiments on various benchmark datasets demonstrate the state-of-the-art performance of SRoUDA where it achieves significant model robustness improvement without harming clean accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25498/25270"
"25499","Gradient-Based Graph Attention for Scene Text Image Super-resolution","['Xiangyuan Zhu', 'Kehua Guo', 'Hui Fang', 'Rui Ding', 'Zheng Wu', 'Gerald Schaefer']","['School of Computer Science and Engineering, Central South University', 'School of Computer Science and Engineering, Central South University', 'Loughborough University', 'School of Computer Science and Engineering, Central South University', 'School of Computer Science and Engineering, Central South University', 'Loughborough University']","['CV: Low Level & Physics-Based Vision', 'CV: Image and Video Retrieval', 'CV: Interpretability and Transparency', 'CV: Language and Vision', 'CV: Learning & Optimization for CV', 'CV: Applications']","Zhu, X., Guo, K., Fang, H., Ding, R., Wu, Z., & Schaefer, G. (2023). Gradient-Based Graph Attention for Scene Text Image Super-resolution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3861-3869. https://doi.org/10.1609/aaai.v37i3.25499","Abstract 					Scene text image super-resolution (STISR) in the wild has been shown to be beneficial to support improved vision-based text recognition from low-resolution imagery. An intuitive way to enhance STISR performance is to explore the well-structured and repetitive layout characteristics of text and exploit these as prior knowledge to guide model convergence. In this paper, we propose a novel gradient-based graph attention method to embed patch-wise text layout contexts into image feature representations for high-resolution text image reconstruction in an implicit and elegant manner. We introduce a non-local group-wise attention module to extract text features which are then enhanced by a cascaded channel attention module and a novel gradient-based graph attention module in order to obtain more effective representations by exploring correlations of regional and local patch-wise text layout properties. Extensive experiments on the benchmark TextZoom dataset convincingly demonstrate that our method supports excellent text recognition and outperforms the current state-of-the-art in STISR. The source code is available at https://github.com/xyzhu1/TSAN.","https://ojs.aaai.org/index.php/AAAI/article/view/25499/25271"
"25500","RGBD1K: A Large-Scale Dataset and Benchmark for RGB-D Object Tracking","['Xue-Feng Zhu', 'Tianyang Xu', 'Zhangyong Tang', 'Zucheng Wu', 'Haodong Liu', 'Xiao Yang', 'Xiao-Jun Wu', 'Josef Kittler']","['Jiangnan University', 'Jiangnan University', 'Jiangnan University', 'Jiangnan University', 'Jiangnan University', 'Jiangnan University', 'Jiangnan University', 'University of Surrey']","['CV: Motion & Tracking', 'CV: Multi-modal Vision']","Zhu, X.-F., Xu, T., Tang, Z., Wu, Z., Liu, H., Yang, X., Wu, X.-J., & Kittler, J. (2023). RGBD1K: A Large-Scale Dataset and Benchmark for RGB-D Object Tracking. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3870-3878. https://doi.org/10.1609/aaai.v37i3.25500","Abstract 					RGB-D object tracking has attracted considerable attention recently, achieving promising performance thanks to the symbiosis between visual and depth channels. However, given a limited amount of annotated RGB-D tracking data, most state-of-the-art RGB-D trackers are simple extensions of high-performance RGB-only trackers, without fully exploiting the underlying potential of the depth channel in the offline training stage. To address the dataset deficiency issue, a new RGB-D dataset named RGBD1K is released in this paper. The RGBD1K contains 1,050 sequences with about 2.5M frames in total. To demonstrate the benefits of training on a larger RGB-D data set in general, and RGBD1K in particular, we develop a transformer-based RGB-D tracker, named SPT, as a baseline for future visual object tracking studies using the new dataset. The results, of extensive experiments using the SPT tracker demonstrate the potential of the RGBD1K dataset to improve the performance of RGB-D tracking, inspiring future developments of effective tracker designs. The dataset and codes will be available on the project homepage: https://github.com/xuefeng-zhu5/RGBD1K.","https://ojs.aaai.org/index.php/AAAI/article/view/25500/25272"
"25501","Learn More for Food Recognition via Progressive Self-Distillation","['Yaohui Zhu', 'Linhu Liu', 'Jiang Tian']","['Beijing Normal University', 'Lenovo Research', 'Lenovo']","['CV: Object Detection & Categorization', 'CV: Representation Learning for Vision']","Zhu, Y., Liu, L., & Tian, J. (2023). Learn More for Food Recognition via Progressive Self-Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3879-3887. https://doi.org/10.1609/aaai.v37i3.25501","Abstract 					Food recognition has a wide range of applications, such as health-aware recommendation and self-service restaurants. Most previous methods of food recognition firstly locate informative regions in some weakly-supervised manners and then aggregate their features. However, location errors of informative regions limit the effectiveness of these methods to some extent. Instead of locating multiple regions, we propose a Progressive Self-Distillation (PSD) method, which progressively enhances the ability of network to mine more details for food recognition. The training of PSD simultaneously contains multiple self-distillations, in which a teacher network and a student network share the same embedding network. Since the student network receives a modified image from its teacher network by masking some informative regions, the teacher network outputs stronger semantic representations than the student network. Guided by such teacher network with stronger semantics, the student network is encouraged to mine more useful regions from the modified image by enhancing its own ability. The ability of the teacher network is also enhanced with the shared embedding network. By using progressive training, the teacher network incrementally improves its ability to mine more discriminative regions. In inference phase, only the teacher network is used without the help of the student network. Extensive experiments on three datasets demonstrate the effectiveness of our proposed method and state-of-the-art performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25501/25273"
"25502","Generative Image Inpainting with Segmentation Confusion Adversarial Training and Contrastive Learning","['Zhiwen Zuo', 'Lei Zhao', 'Ailin Li', 'Zhizhong Wang', 'Zhanjie Zhang', 'Jiafu Chen', 'Wei Xing', 'Dongming Lu']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University']","['CV: Computational Photography', 'Image & Video Synthesis', 'CV: Applications', 'ML: Deep Generative Models & Autoencoders']","Zuo, Z., Zhao, L., Li, A., Wang, Z., Zhang, Z., Chen, J., Xing, W., & Lu, D. (2023). Generative Image Inpainting with Segmentation Confusion Adversarial Training and Contrastive Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(3), 3888-3896. https://doi.org/10.1609/aaai.v37i3.25502","Abstract 					This paper presents a new adversarial training framework for image inpainting with segmentation confusion adversarial training (SCAT) and contrastive learning. SCAT plays an adversarial game between an inpainting generator and a segmentation network, which provides pixel-level local training signals and can adapt to images with free-form holes. By combining SCAT with standard global adversarial training, the new adversarial training framework exhibits the following three advantages simultaneously: (1) the global consistency of the repaired image, (2) the local fine texture details of the repaired image, and (3) the flexibility of handling images with free-form holes. Moreover, we propose the textural and semantic contrastive learning losses to stabilize and improve our inpainting model's training by exploiting the feature representation space of the discriminator, in which the inpainting images are pulled closer to the ground truth images but pushed farther from the corrupted images. The proposed contrastive losses better guide the repaired images to move from the corrupted image data points to the real image data points in the feature representation space, resulting in more realistic completed images. We conduct extensive experiments on two benchmark datasets, demonstrating our model's effectiveness and superiority both qualitatively and quantitatively.","https://ojs.aaai.org/index.php/AAAI/article/view/25502/25274"
"25503","Improved Algorithms for Maximum Satisfiability and Its Special Cases","['Kirill Brilliantov', 'Vasily Alferov', 'Ivan Bliznets']","['Constructor University', 'Independent Researcher', 'Utrecht University']","['CSO: Satisfiability', 'CSO: Constraint Satisfaction']","Brilliantov, K., Alferov, V., & Bliznets, I. (2023). Improved Algorithms for Maximum Satisfiability and Its Special Cases. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3898-3905. https://doi.org/10.1609/aaai.v37i4.25503","Abstract 					The Maximum Satisfiability (MAXSAT) problem is an optimization version of the Satisfiability problem (SAT) in which one is given a CNF formula with n variables and needs to find the maximum number of simultaneously satisfiable clauses. Recent works achieved significant progress in proving new upper bounds on the worst-case computational complexity of MAXSAT. All these works reduce general MAXSAT to a special case of MAXSAT where each variable appears a small number of times. So, it is important to design fast algorithms for (n,k)-MAXSAT to construct an efficient exact algorithm for MAXSAT. (n,k)-MAXSAT is a special case of MAXSAT where each variable appears at most k times in the input formula.   For the (n,3)-MAXSAT problem, we design a O*(1.1749^n) algorithm improving on the previous record running time of O*(1.191^n). For the (n,4)-MAXSAT problem, we construct a O*(1.3803^n) algorithm improving on the previous best running time of O*(1.4254^n). Using the results, we develop a O*(1.0911^L) algorithm for the MAXSAT where L is a length of the input formula which improves previous algorithm with O*(1.0927^L) running time.","https://ojs.aaai.org/index.php/AAAI/article/view/25503/25275"
"25504","Lifting (D)QBF Preprocessing and Solving Techniques to (D)SSAT","['Che Cheng', 'Jie-Hong R. Jiang']","['National Taiwan University', 'National Taiwan University']","['CSO: Solvers and Tools', 'CSO: Constraint Optimization', 'CSO: Constraint Satisfaction', 'CSO: Other Foundations of Constraint Satisfaction & Optimization', 'CSO: Satisfiability']","Cheng, C., & Jiang, J.-H. R. (2023). Lifting (D)QBF Preprocessing and Solving Techniques to (D)SSAT. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3906-3914. https://doi.org/10.1609/aaai.v37i4.25504","Abstract 					Dependency stochastic Boolean satisfiability (DSSAT) generalizes stochastic Boolean satisfiability (SSAT) in existential variables being Henkinized allowing their dependencies on randomized variables to be explicitly specified. It allows NEXPTIME problems of reasoning under uncertainty and partial information to be compactly encoded. To date, no decision procedure has been implemented for solving DSSAT formulas. This work provides the first such tool by converting DSSAT into SSAT with dependency elimination, similar to converting dependency quantified Boolean formula (DQBF) to quantified Boolean formula (QBF). Moreover, we extend (D)QBF preprocessing techniques and implement the first standalone (D)SSAT preprocessor. Experimental results show that solving DSSAT via dependency elimination is highly applicable and that existing SSAT solvers may benefit from preprocessing.","https://ojs.aaai.org/index.php/AAAI/article/view/25504/25276"
"25505","NuWLS: Improving Local Search for (Weighted) Partial MaxSAT by New Weighting Techniques","['Yi Chu', 'Shaowei Cai', 'Chuan Luo']","['Institute of Software, Chinese Academy of Sciences, China', 'State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences, China\nSchool of Computer Science and Technology, University of Chinese Academy of Sciences, China', 'School of Software, Beihang University, China']","['CSO: Constraint Optimization', 'CSO: Search', 'CSO: Solvers and Tools', 'SO: Heuristic Search', 'SO: Local Search']","Chu, Y., Cai, S., & Luo, C. (2023). NuWLS: Improving Local Search for (Weighted) Partial MaxSAT by New Weighting Techniques. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3915-3923. https://doi.org/10.1609/aaai.v37i4.25505","Abstract 					Maximum Satisfiability (MaxSAT) is a prototypical constraint optimization problem, and its generalized version is the (Weighted) Partial MaxSAT problem, denoted as (W)PMS, which deals with hard and soft clauses. Considerable progress has been made on stochastic local search (SLS) algorithms for solving (W)PMS, which mainly focus on clause weighting techniques. In this work, we identify two issues of existing clause weighting techniques for (W)PMS, and propose two ideas correspondingly. First, we observe that the initial values of soft clause weights have a big effect on the performance of the SLS solver for solving (W)PMS, and propose a weight initialization method. Second, we propose a new clause weighting scheme that for the first time employs different conditions for updating hard and soft clause weights. Based on these two ideas, we develop a new SLS solver for (W)PMS named NuWLS. Through extensive experiments, NuWLS performs much better than existing SLS solvers on all 6 benchmarks from the incomplete tracks of MaxSAT Evaluations (MSEs) 2019, 2020, and 2021. In terms of the number of winning instances, NuWLS outperforms state-of-the-art SAT-based incomplete solvers on all the 6 benchmarks. More encouragingly, a hybrid solver that combines NuWLS and an SAT-based solver won all four categories in the incomplete track of the MaxSAT Evaluation 2022.","https://ojs.aaai.org/index.php/AAAI/article/view/25505/25277"
"25506","Separate but Equal: Equality in Belief Propagation for Single Cycle Graphs","['Erel Cohen', 'Omer Lev', 'Roie Zivan']","['Ben-Gurion University', 'Ben-Gurion University', 'Ben-Gurion University']","['CSO: Constraint Optimization', 'CSO: Distributed CSP/Optimization']","Cohen, E., Lev, O., & Zivan, R. (2023). Separate but Equal: Equality in Belief Propagation for Single Cycle Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3924-3931. https://doi.org/10.1609/aaai.v37i4.25506","Abstract 					Belief propagation is a widely used incomplete optimization algorithm, whose main theoretical properties hold only under the assumptions that beliefs are not equal. Nevertheless, there is much evidence that equality between beliefs does occur. A method to overcome belief equality by using unary function-nodes is assumed to resolve the problem.  We focus on Min-sum, the belief propagation version for solving constraint optimization problems. We prove that on a single cycle graph, belief equality can be avoided only when the algorithm converges to the optimal solution. In any other case, the unary function methods will not prevent equality, rendering some existing results in need of reassessment. We differentiate between belief equality, which includes equal beliefs in a single message, and assignment equality, that prevents a coherent selection of assignments to variables. We show the necessary and satisfying conditions for both.","https://ojs.aaai.org/index.php/AAAI/article/view/25506/25278"
"25507","Complexity of Reasoning with Cardinality Minimality Conditions","['Nadia Creignou', 'Frédéric Olive', 'Johannes Schmidt']","['Aix-Marseille Université', 'Aix-Marseille Université', 'Jönköping University']","['CSO: Constraint Satisfaction', 'CSO: Satisfiability', 'KRR: Belief Change', 'KRR: Nonmonotonic Reasoning']","Creignou, N., Olive, F., & Schmidt, J. (2023). Complexity of Reasoning with Cardinality Minimality Conditions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3932-3940. https://doi.org/10.1609/aaai.v37i4.25507","Abstract 					Many AI-related reasoning problems are based on the problem of satisfiability of propositional formulas with some cardinality-minimality condition. While the complexity of the satisfiability problem (SAT) is well understood when considering systematically all fragments of propositional logic within Schaefer’s framework, this is not the case when such minimality condition is added. We consider the CardMinSat problem, which asks, given a formula φ and an atom x, whether x is true in some cardinality-minimal model of φ. We completely classify the computational complexity of the CardMinSat problem within Schaefer’s framework, thus paving the way for a better understanding of the tractability frontier of many AI-related reasoning problems. To this end we use advanced algebraic tools.","https://ojs.aaai.org/index.php/AAAI/article/view/25507/25279"
"25508","DASH: A Distributed and Parallelizable Algorithm for Size-Constrained Submodular Maximization","['Tonmoy Dey', 'Yixin Chen', 'Alan Kuhnle']","['Florida State University', 'Texas A&M University', 'Texas A&M University']","['CSO: Distributed CSP/Optimization', 'CSO: Constraint Optimization', 'CSO: Constraint Programming', 'CSO: Constraint Satisfaction', 'CSO: Other Foundations of Constraint Satisfaction & Optimization']","Dey, T., Chen, Y., & Kuhnle, A. (2023). DASH: A Distributed and Parallelizable Algorithm for Size-Constrained Submodular Maximization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3941-3948. https://doi.org/10.1609/aaai.v37i4.25508","Abstract 					MapReduce (MR) algorithms for maximizing monotone, submodular functions subject to a cardinality constraint (SMCC) are currently restricted to the use of the linear-adaptive (non-parallelizable) algorithm GREEDY. Low-adaptive algorithms do not satisfy the requirements of these distributed MR frameworks, thereby limiting their performance. We study the SMCC problem in a distributed setting and propose the first MR algorithms with sublinear adaptive complexity. Our algorithms, R-DASH, T-DASH and G-DASH provide 0.316 - ε, 3/8 - ε , and (1 - 1/e - ε)   approximation ratios, respectively, with nearly optimal adaptive complexity and nearly linear time complexity. Additionally, we provide a framework to increase, under some mild assumptions, the maximum permissible cardinality constraint from  O( n / ℓ^2) of prior MR algorithms to O( n / ℓ ), where n is the data size and ℓ is the number of machines; under a stronger condition on the objective function, we increase the maximum constraint value to n. Finally, we provide empirical evidence to demonstrate that our sublinear-adaptive, distributed algorithms provide orders of magnitude faster runtime compared to current state-of-the-art distributed algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/25508/25280"
"25509","SharpSSAT: A Witness-Generating Stochastic Boolean Satisfiability Solver","['Yu-Wei Fan', 'Jie-Hong R. Jiang']","['National Taiwan University', 'National Taiwan University']","['CSO: Satisfiability', 'CSO: Constraint Optimization', 'CSO: Constraint Satisfaction', 'CSO: Other Foundations of Constraint Satisfaction & Optimization', 'CSO: Search', 'CSO: Solvers and Tools', 'SO: Other Foundations of Search & Optimization']","Fan, Y.-W., & Jiang, J.-H. R. (2023). SharpSSAT: A Witness-Generating Stochastic Boolean Satisfiability Solver. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3949-3958. https://doi.org/10.1609/aaai.v37i4.25509","Abstract 					Stochastic Boolean satisfiability (SSAT) is a formalism allowing decision-making for optimization under quantitative constraints. Although SSAT solvers are under active development, existing solvers do not provide Skolem-function witnesses, which are crucial for practical applications. In this work, we develop a new witness-generating SSAT solver, SharpSSAT, which integrates techniques, including component caching, clause learning, and pure literal detection. It can generate a set of Skolem functions witnessing the attained satisfying probability of a given SSAT formula. We also equip the solver ClauSSat with witness generation capability for comparison. Experimental results show that SharpSSAT outperforms current state-of-the-art solvers and can effectively generate compact Skolem-function witnesses. The new witness-generating solver may broaden the applicability of SSAT to practical applications.","https://ojs.aaai.org/index.php/AAAI/article/view/25509/25281"
"25510","Submodular Maximization under the Intersection of Matroid and Knapsack Constraints","['Yu-Ran Gu', 'Chao Bian', 'Chao Qian']","['Nanjing University', 'Nanjing University', 'Nanjing University']","['CSO: Constraint Optimization', 'ML: Optimization']","Gu, Y.-R., Bian, C., & Qian, C. (2023). Submodular Maximization under the Intersection of Matroid and Knapsack Constraints. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3959-3967. https://doi.org/10.1609/aaai.v37i4.25510","Abstract 					Submodular maximization arises in many applications, and has attracted a lot of research attentions from various areas such as artificial intelligence, finance and operations research. Previous studies mainly consider only one kind of constraint, while many real-world problems often involve several constraints. In this paper, we consider the problem of submodular maximization under the intersection of two commonly used constraints, i.e., k-matroid constraint and m-knapsack constraint, and propose a new algorithm SPROUT by incorporating partial enumeration into the simultaneous greedy framework. We prove that SPROUT can achieve a polynomial-time approximation guarantee better than the state-of-the-art algorithms. Then, we introduce the random enumeration and smooth techniques into SPROUT to improve its efficiency, resulting in the SPROUT++ algorithm, which can keep a similar approximation guarantee. Experiments on the applications of movie recommendation and weighted max-cut demonstrate the superiority of SPROUT++ in practice.","https://ojs.aaai.org/index.php/AAAI/article/view/25510/25282"
"25511","A Framework to Design Approximation Algorithms for Finding Diverse Solutions in Combinatorial Problems","['Tesshu Hanaka', 'Masashi Kiyomi', 'Yasuaki Kobayashi', 'Yusuke Kobayashi', 'Kazuhiro Kurita', 'Yota Otachi']","['Kyushu University', 'Seikei University', 'Hokkaido University', 'Kyoto University', 'Nagoya University', 'Nagoya University']","['CSO: Other Foundations of Constraint Satisfaction & Optimization', 'SO: Other Foundations of Search & Optimization']","Hanaka, T., Kiyomi, M., Kobayashi, Y., Kobayashi, Y., Kurita, K., & Otachi, Y. (2023). A Framework to Design Approximation Algorithms for Finding Diverse Solutions in Combinatorial Problems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3968-3976. https://doi.org/10.1609/aaai.v37i4.25511","Abstract 					Finding a \emph{single} best solution is the most common objective in combinatorial optimization problems. However, such a single solution may not be applicable to real-world problems as objective functions and constraints are only ``approximately'' formulated for original real-world problems. To solve this issue, finding \emph{multiple} solutions is a natural direction, and diversity of solutions is an important concept in this context. Unfortunately, finding diverse solutions is much harder than finding a single solution. To cope with the difficulty, we investigate the approximability of finding diverse solutions. As a main result, we propose a framework to design approximation algorithms for finding diverse solutions, which yields several outcomes including constant-factor approximation algorithms for finding diverse matchings in graphs and diverse common bases in two matroids and PTASes for finding diverse minimum cuts and interval schedulings.","https://ojs.aaai.org/index.php/AAAI/article/view/25511/25283"
"25512","An Improved Approximation Algorithm for Wage Determination and Online Task Allocation in Crowd-Sourcing","['Yuya Hikima', 'Yasunori Akagi', 'Hideaki Kim', 'Taichi Asami']","['NTT Human Informatics Laboratories, NTT Corporation', 'NTT Human Informatics Laboratories, NTT Corporation', 'NTT Human Informatics Laboratories, NTT Corporation', 'NTT Human Informatics Laboratories, NTT Corporation']","['CSO: Mixed Discrete/Continuous Optimization', 'CSO: Applications', 'CSO: Constraint Optimization', 'HAI: Crowdsourcing']","Hikima, Y., Akagi, Y., Kim, H., & Asami, T. (2023). An Improved Approximation Algorithm for Wage Determination and Online Task Allocation in Crowd-Sourcing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3977-3986. https://doi.org/10.1609/aaai.v37i4.25512","Abstract 					Crowd-sourcing has attracted much attention due to its growing importance to society, and numerous studies have been conducted on task allocation and wage determination. Recent works have focused on optimizing task allocation and workers' wages, simultaneously. However, existing methods do not provide good solutions for real-world crowd-sourcing platforms due to the low approximation ratio or myopic problem settings. We tackle an optimization problem for wage determination and online task allocation in crowd-sourcing and propose a fast 1-1/(k+3)^(1/2)-approximation algorithm, where k is the minimum of tasks' budgets (numbers of possible assignments). This approximation ratio is greater than or equal to the existing method. The proposed method reduces the tackled problem to a non-convex multi-period continuous optimization problem by approximating the objective function. Then, the method transforms the reduced problem into a minimum convex cost flow problem, which is a well-known combinatorial optimization problem, and solves it by the capacity scaling algorithm. Synthetic experiments and simulation experiments using real crowd-sourcing data show that the proposed method solves the problem faster and outputs higher objective values than existing methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25512/25284"
"25513","Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints","['Xinyi Hu', 'Jasper C.H. Lee', 'Jimmy H.M. Lee']","['The Chinese University of Hong Kong', 'University of Wisconsin-Madison', 'The Chinese University of Hong Kong']","['CSO: Constraint Optimization', 'CSO: Constraint Programming', 'CSO: Other Foundations of Constraint Satisfaction & Optimization']","Hu, X., Lee, J. C., & Lee, J. H. (2023). Predict+Optimize for Packing and Covering LPs with Unknown Parameters in Constraints. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3987-3995. https://doi.org/10.1609/aaai.v37i4.25513","Abstract 					Predict+Optimize is a recently proposed framework which combines machine learning and constrained optimization, tackling optimization problems that contain parameters that are unknown at solving time. The goal is to predict the unknown parameters and use the estimates to solve for an estimated optimal solution to the optimization problem. However, all prior works have focused on the case where unknown parameters appear only in the optimization objective and not the constraints, for the simple reason that if the constraints were not known exactly, the estimated optimal solution might not even be feasible under the true parameters. The contributions of this paper are two-fold. First, we propose a novel and practically relevant framework for the Predict+Optimize setting, but with unknown parameters in both the objective and the constraints. We introduce the notion of a correction function, and an additional penalty term in the loss function, modelling practical scenarios where an estimated optimal solution can be modified into a feasible solution after the true parameters are revealed, but at an additional cost. Second, we propose a corresponding algorithmic approach for our framework, which handles all packing and covering linear programs. Our approach is inspired by the prior work of Mandi and Guns, though with crucial modifications and re-derivations for our very different setting. Experimentation demonstrates the superior empirical performance of our method over classical approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/25513/25285"
"25514","Solving Explainability Queries with Quantification: The Case of Feature Relevancy","['Xuanxiang Huang', 'Yacine Izza', 'Joao Marques-Silva']","['University of Toulouse', 'University of Toulouse\nNational University of Singapore', 'IRIT, CNRS']","['CSO: Satisfiability', 'CSO: Constraint Satisfaction', 'CSO: Solvers and Tools', 'ML: Transparent', 'Interpretable', 'Explainable ML']","Huang, X., Izza, Y., & Marques-Silva, J. (2023). Solving Explainability Queries with Quantification: The Case of Feature Relevancy. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 3996-4006. https://doi.org/10.1609/aaai.v37i4.25514","Abstract 					Trustable explanations of machine learning (ML) models are vital in high-risk uses of artificial intelligence (AI). Apart from the computation of trustable explanations, a number of explainability queries have been identified and studied in recent work. Some of these queries involve solving quantification problems, either in propositional or in more expressive logics. This paper investigates one of these quantification problems, namely the feature relevancy problem (FRP), i.e.\ to decide whether a (possibly sensitive) feature can occur in some explanation of a prediction. In contrast with earlier work, that studied FRP for specific classifiers, this paper proposes a novel algorithm for the \fprob quantification problem which is applicable to any ML classifier that meets minor requirements. Furthermore, the paper shows that the novel algorithm is efficient in practice. The experimental results, obtained using random forests (RFs) induced from well-known publicly available datasets, demonstrate that the proposed solution outperforms existing state-of-the-art solvers for Quantified Boolean Formulas (QBF) by orders of magnitude. Finally, the paper also identifies a novel family of formulas that are challenging for currently state-of-the-art QBF solvers.","https://ojs.aaai.org/index.php/AAAI/article/view/25514/25286"
"25515","Second-Order Quantified Boolean Logic","['Jie-Hong R. Jiang']","['National Taiwan University']","['CSO: Other Foundations of Constraint Satisfaction & Optimization', 'CSO: Constraint Satisfaction', 'CSO: Satisfiability', 'KRR: Automated Reasoning and Theorem Proving', 'KRR: Computational Complexity of Reasoning', 'KRR: Other Foundations of Knowledge Representation & Reasoning']","Jiang, J.-H. R. (2023). Second-Order Quantified Boolean Logic. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4007-4015. https://doi.org/10.1609/aaai.v37i4.25515","Abstract 					Second-order quantified Boolean formulas (SOQBFs) generalize quantified Boolean formulas (QBFs) by admitting second-order quantifiers on function variables in addition to first-order quantifiers on atomic variables. Recent endeavors establish that the complexity of SOQBF satisfiability corresponds to the exponential-time hierarchy (EXPH), similar to that of QBF satisfiability corresponding to the polynomial-time hierarchy (PH). This fact reveals the succinct expression power of SOQBFs in encoding decision problems not efficiently doable by QBFs. In this paper, we investigate the second-order quantified Boolean logic with the following main results: First, we present a procedure of quantifier elimination converting SOQBFs to QBFs and a game interpretation of SOQBF semantics. Second, we devise a sound and complete refutation-proof system for SOQBF. Third, we develop an algorithm for countermodel extraction from a refutation proof. Finally, we show potential applications of SOQBFs in system design and multi-agent planning. With these advances, we anticipate practical tools for development.","https://ojs.aaai.org/index.php/AAAI/article/view/25515/25287"
"25516","Learning Markov Random Fields for Combinatorial Structures via Sampling through Lovász Local Lemma","['Nan Jiang', 'Yi Gu', 'Yexiang Xue']","['Purdue University', 'Northwestern University', 'Purdue University']","['CSO: Constraint Satisfaction']","Jiang, N., Gu, Y., & Xue, Y. (2023). Learning Markov Random Fields for Combinatorial Structures via Sampling through Lovász Local Lemma. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4016-4024. https://doi.org/10.1609/aaai.v37i4.25516","Abstract 					Learning to generate complex combinatorial structures satisfying constraints will have transformative impacts in many application domains. However, it is beyond the capabilities of existing approaches due to the highly intractable nature of the embedded probabilistic inference. Prior works spend most of the training time learning to separate valid from invalid structures but do not learn the inductive biases of valid structures. We develop NEural Lovasz Sampler (NELSON), which embeds the sampler through Lovasz Local Lemma (LLL) as a fully differentiable neural network layer. Our NELSON-CD embeds this sampler into the contrastive divergence learning process of Markov random fields. NELSON allows us to obtain valid samples from the current model distribution. Contrastive divergence is then applied to separate these samples from those in the training set. NELSON is implemented as a fully differentiable neural net, taking advantage of the parallelism of GPUs. Experimental results on several real-world domains reveal that NELSON learns to generate 100% valid structures, while baselines either time out or cannot ensure validity. NELSON also outperforms other approaches in running time, log-likelihood, and MAP scores.","https://ojs.aaai.org/index.php/AAAI/article/view/25516/25288"
"25517","Fast Converging Anytime Model Counting","['Yong Lai', 'Kuldeep S. Meel', 'Roland H.C. Yap']","['Jilin University', 'National University of Singapore', 'National University of Singapore']","['CSO: Solvers and Tools', 'CSO: Satisfiability', 'KRR: Automated Reasoning and Theorem Proving', 'RU: Other Foundations of Reasoning Under Uncertainty', 'SO: Sampling/Simulation-Based Search']","Lai, Y., Meel, K. S., & Yap, R. H. (2023). Fast Converging Anytime Model Counting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4025-4034. https://doi.org/10.1609/aaai.v37i4.25517","Abstract 					Model counting is a fundamental problem which has been influential in many applications, from artificial intelligence to formal verification. Due to the intrinsic hardness of model counting, approximate techniques have been developed to solve real-world instances of model counting. This paper designs a new anytime approach called PartialKC for approximate model counting. The idea is a form of partial knowledge compilation to provide an unbiased estimate of the model count which can converge to the exact count. Our empirical analysis demonstrates that PartialKC achieves significant scalability and accuracy over prior state-of-the-art approximate counters, including satss and STS. Interestingly, the empirical results show that PartialKC reaches convergence for many instances and therefore provides exact model counting performance comparable to state-of-the-art exact counters.","https://ojs.aaai.org/index.php/AAAI/article/view/25517/25289"
"25518","Finding Good Partial Assignments during Restart-Based Branch and Bound Search","['Hongbo Li', 'Jimmy H.M. Lee']","['College of Information Science and Technology, Northeast Normal University', 'Department of Computer Science and Engineering, The Chinese University of Hong Kong']","['CSO: Constraint Satisfaction', 'CSO: Constraint Optimization']","Li, H., & Lee, J. H. (2023). Finding Good Partial Assignments during Restart-Based Branch and Bound Search. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4035-4043. https://doi.org/10.1609/aaai.v37i4.25518","Abstract 					Restart-based Branch-and-Bound Search (BBS) is a standard algorithm for solving Constraint Optimization Problems (COPs). In this paper, we propose an approach to find good partial assignments to jumpstart search at each restart for general COPs, which are identified by comparing different best solutions found in different restart runs. We consider information extracted from historical solutions to evaluate the quality of the partial assignments. Thus the good partial assignments are dynamically updated as the current best solution evolves.  Our approach makes restart-based BBS explore different promising sub-search-spaces to find high-quality solutions.  Experiments on the MiniZinc benchmark suite show how our approach brings significant improvements to a black-box COP solver equipped with the state of the art search techniques. Our method finds better solutions and proves optimality for more instances.","https://ojs.aaai.org/index.php/AAAI/article/view/25518/25290"
"25519","Hybrid Learning with New Value Function for the Maximum Common Induced Subgraph Problem","['Yanli Liu', 'Jiming Zhao', 'Chu-Min Li', 'Hua Jiang', 'Kun He']","['Wuhan university of science and technology', 'Wuhan University of Science and Technology', 'MIS, University of Picardie Jules Verne', 'Engineering Research Center of Cyberspace & School of Software, Yunnan University', 'Huazhong University of Science and Technology']","['CSO: Constraint Optimization', 'CSO: Constraint Satisfaction', 'CSO: Search', 'SO: Heuristic Search']","Liu, Y., Zhao, J., Li, C.-M., Jiang, H., & He, K. (2023). Hybrid Learning with New Value Function for the Maximum Common Induced Subgraph Problem. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4044-4051. https://doi.org/10.1609/aaai.v37i4.25519","Abstract 					Maximum Common Induced Subgraph (MCIS) is an important NP-hard problem with wide real-world applications. An efficient class of MCIS algorithms uses Branch-and-Bound (BnB), consisting in successively selecting vertices to match and pruning when it is discovered that a solution better than the best solution found so far does not exist. The method of selecting the vertices to match is essential for the performance of BnB. In this paper, we propose a new value function and a hybrid selection strategy used in reinforcement learning to define a new vertex selection method, and propose a new BnB algorithm, called McSplitDAL, for MCIS. Extensive experiments show that McSplitDAL significantly improves the current best BnB algorithms, McSplit+LL and McSplit+RL. An empirical analysis is also performed to illustrate why the new value function and the hybrid selection strategy are effective.","https://ojs.aaai.org/index.php/AAAI/article/view/25519/25291"
"25520","Self-Supervised Primal-Dual Learning for Constrained Optimization","['Seonho Park', 'Pascal Van Hentenryck']","['Georgia Institute of Technology', 'Georgia Institute of Technology']","['CSO: Constraint Optimization', 'CSO: Applications', 'CSO: Constraint Programming', 'CSO: Mixed Discrete/Continuous Optimization', 'APP: Energy', 'Environment & Sustainability', 'ML: Classification and Regression', 'ML: Optimization', 'ML: Unsupervised & Self-Supervised Learning', 'SO: Other Foundations of Search & Optimization']","Park, S., & Van Hentenryck, P. (2023). Self-Supervised Primal-Dual Learning for Constrained Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4052-4060. https://doi.org/10.1609/aaai.v37i4.25520","Abstract 					This paper studies how to train machine-learning models that directly approximate the optimal solutions of constrained optimization problems. This is an empirical risk minimization under constraints, which is challenging as training must balance optimality and feasibility conditions. Supervised learning methods often approach this challenge by training the model on a large collection of pre-solved instances. This paper takes a different route and proposes the idea of Primal-Dual Learning (PDL), a self-supervised training method that does not require a set of pre-solved instances or an optimization solver for training and inference. Instead, PDL mimics the trajectory of an Augmented Lagrangian Method (ALM) and jointly trains primal and dual neural networks. Being a primal-dual method, PDL uses instance-specific penalties of the constraint terms in the loss function used to train the primal network. Experiments show that, on a set of nonlinear optimization benchmarks, PDL typically exhibits negligible constraint violations and minor optimality gaps, and is remarkably close to the ALM optimization. PDL also demonstrated improved or similar performance in terms of the optimality gaps, constraint violations, and training times compared to existing approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/25520/25292"
"25521","Reinforcement Learning for Branch-and-Bound Optimisation Using Retrospective Trajectories","['Christopher W. F. Parsonson', 'Alexandre Laterre', 'Thomas D. Barrett']","['UCL', 'InstaDeep', 'InstaDeep']","['CSO: Solvers and Tools', 'CSO: Applications', 'CSO: Constraint Optimization', 'CSO: Constraint Programming', 'ML: Graph-based Machine Learning', 'ML: Reinforcement Learning Algorithms', 'ML: Reinforcement Learning Theory']","Parsonson, C. W. F., Laterre, A., & Barrett, T. D. (2023). Reinforcement Learning for Branch-and-Bound Optimisation Using Retrospective Trajectories. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4061-4069. https://doi.org/10.1609/aaai.v37i4.25521","Abstract 					Combinatorial optimisation problems framed as mixed integer linear programmes (MILPs) are ubiquitous across a range of real-world applications. The canonical branch-and-bound algorithm seeks to exactly solve MILPs by constructing a search tree of increasingly constrained sub-problems. In practice, its solving time performance is dependent on heuristics, such as the choice of the next variable to constrain ('branching'). Recently, machine learning (ML) has emerged as a promising paradigm for branching. However, prior works have struggled to apply reinforcement learning (RL), citing sparse rewards, difficult exploration, and partial observability as significant challenges. Instead, leading ML methodologies resort to approximating high quality handcrafted heuristics with imitation learning (IL), which precludes the discovery of novel policies and requires expensive data labelling. In this work, we propose retro branching; a simple yet effective approach to RL for branching. By retrospectively deconstructing the search tree into multiple paths each contained within a sub-tree, we enable the agent to learn from shorter trajectories with more predictable next states. In experiments on four combinatorial tasks, our approach enables learning-to-branch without any expert guidance or pre-training. We outperform the current state-of-the-art RL branching algorithm by 3-5x and come within 20% of the best IL method's performance on MILPs with 500 constraints and 1000 variables, with ablations verifying that our retrospectively constructed trajectories are essential to achieving these results.","https://ojs.aaai.org/index.php/AAAI/article/view/25521/25293"
"25522","Constraint Optimization over Semirings","['A. Pavan', 'Kuldeep S. Meel', 'N. V. Vinodchandran', 'Arnab Bhattacharyya']","['Iowa State University', 'National University of Singapore', 'University of Nebraska-Lincoln', 'National University of Singapore']","['CSO: Constraint Optimization', 'CSO: Constraint Satisfaction', 'CSO: Satisfiability']","Pavan, A., Meel, K. S., Vinodchandran, N. V., & Bhattacharyya, A. (2023). Constraint Optimization over Semirings. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4070-4077. https://doi.org/10.1609/aaai.v37i4.25522","Abstract 					Interpretations of logical formulas over semirings (other than the Boolean semiring) have applications in various areas of computer science including logic, AI, databases, and security.  Such interpretations provide richer information beyond the truth or falsity of a statement. Examples of such semirings include Viterbi semiring, min-max or access control semiring, tropical semiring, and fuzzy semiring.           The present work investigates the complexity of constraint optimization problems over semirings. The generic optimization problem we study is the following: Given a propositional formula phi over n variable and a semiring (K,+, . ,0,1), find the maximum value over all possible interpretations of phi over K. This can be seen as a generalization of the well-known satisfiability problem (a propositional formula is satisfiable if and only if the maximum value over all interpretations/assignments over the Boolean semiring is 1).  A related problem is to find an interpretation that achieves the maximum value. In this work, we first focus on these optimization problems over the Viterbi semiring, which we call optConfVal and optConf.           We first show that for general propositional formulas in negation normal form, optConfVal and optConf are in FP^NP. We then investigate optConf when the input formula phi is represented in the conjunctive normal form.  For CNF formulae, we first derive an upper bound on the value of optConf as a function of the number of maximum satisfiable clauses. In particular, we show that if r is the maximum number of satisfiable clauses in a CNF formula with m clauses, then its optConf value is at most 1/4^(m-r). Building on this we establish that optConf for CNF formulae is hard for the complexity class FP^NP[log]. We also design polynomial-time approximation algorithms and establish an inapproximability for optConfVal. We establish similar complexity results for these optimization problems over other semirings including tropical, fuzzy, and access control semirings.","https://ojs.aaai.org/index.php/AAAI/article/view/25522/25294"
"25523","Generalized Confidence Constraints","['Guillaume Perez', 'Steve Malalel', 'Gael Glorian', 'Victor Jung', 'Alexandre Papadopoulos', 'Marie Pelleau', 'Wijnand Suijlen', 'Jean-Charles Régin', 'Arnaud Lallouet']","['Huawei Technologies France', ""Université Côte d'Azur"", 'Huawei Technologies France', ""Université Côte d'Azur"", 'Huawei Technologies France', ""Université Côte d'Azur"", 'Huawei Technologies France', ""Université Côte d'Azur"", 'Huawei Technologies France']","['CSO: Constraint Programming', 'CSO: Constraint Optimization', 'CSO: Constraint Satisfaction', 'CSO: Mixed Discrete/Continuous Optimization', 'RU: Probabilistic Programming', 'RU: Stochastic Optimization']","Perez, G., Malalel, S., Glorian, G., Jung, V., Papadopoulos, A., Pelleau, M., Suijlen, W., Régin, J.-C., & Lallouet, A. (2023). Generalized Confidence Constraints. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4078-4086. https://doi.org/10.1609/aaai.v37i4.25523","Abstract 					In robust optimization, finding a solution that solely respects the constraints is not enough. Usually, the uncertainty and unknown parameters of the model are represented by random variables. In such conditions, a good solution is a solution robust to most-likely assignments of these random variables. Recently, the Confidence constraint has been introduced by Mercier-Aubin et al. in order to enforce this type of robustness in constraint programming. Unfortunately, it is restricted to a conjunction of binary inequalities In this paper, we generalize the Confidence constraint to any constraint and propose an implementation based on Multi-valued Decision Diagrams (MDDs).  The Confidence constraint is defined over a vector of random variables.  For a given constraint C, and given a threshold, the Confidence constraint ensures that the probability for C to be satisfied by a sample of the random variables is greater than the threshold. We propose to use MDDs to represent the constraints on the random variables. MDDs are an efficient tool for representing combinatorial constraints, thanks to their exponential compression power. Here, both random and decision variables are stored in the MDD,  and propagation rules are proposed for removing values of decision variables that cannot lead to robust solutions. Furthermore, for several constraints, we show that decision variables can be omitted from the MDD because lighter filtering algorithms are sufficient. This leads to gain an exponential factor in the MDD size. The experimental results obtained on a chemical deliveries problem in factories –  where the chemicals consumption are uncertain –  shows the efficiency of the proposed approach.","https://ojs.aaai.org/index.php/AAAI/article/view/25523/25295"
"25524","Circuit Minimization with QBF-Based Exact Synthesis","['Franz-Xaver Reichl', 'Friedrich Slivovsky', 'Stefan Szeider']","['TU Wien', 'TU Wien', 'TU Wien']","['CSO: Satisfiability', 'APP: Design']","Reichl, F.-X., Slivovsky, F., & Szeider, S. (2023). Circuit Minimization with QBF-Based Exact Synthesis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4087-4094. https://doi.org/10.1609/aaai.v37i4.25524","Abstract 					This paper presents a rewriting method for Boolean circuits that minimizes small subcircuits with exact synthesis. Individual synthesis tasks are encoded as Quantified Boolean Formulas (QBFs) that capture the full flexibility for implementing multi-output subcircuits. This is in contrast to SAT-based resynthesis, where ""don't cares"" are computed for an individual gate, and replacements are confined to the circuitry used exclusively by that gate. An implementation of our method achieved substantial size reductions compared to state-of-the-art methods across a wide range of benchmark circuits.","https://ojs.aaai.org/index.php/AAAI/article/view/25524/25296"
"25525","Probabilistic Generalization of Backdoor Trees with Application to SAT","['Alexander Semenov', 'Daniil Chivilikhin', 'Stepan Kochemazov', 'Ibragim Dzhiblavi']","['ITMO University', 'ITMO University', 'ITMO University', 'ITMO University']","['CSO: Satisfiability', 'CSO: Search', 'CSO: Solvers and Tools', 'SO: Evolutionary Computation', 'SO: Heuristic Search', 'SO: Metareasoning and Metaheuristics']","Semenov, A., Chivilikhin, D., Kochemazov, S., & Dzhiblavi, I. (2023). Probabilistic Generalization of Backdoor Trees with Application to SAT. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4095-4103. https://doi.org/10.1609/aaai.v37i4.25525","Abstract 					The concept of Strong Backdoor Sets (SBS) for Constraint Satisfaction Problems is well known as one of the attempts to exploit structural peculiarities in hard instances. However, in practice, finding an SBS for a particular instance is often harder than solving it. Recently, a probabilistic weakened variant of the SBS was introduced: in the SBS, all subproblems must be polynomially solvable, whereas in the probabilistic SBS only a large fraction ρ of them should have this property. This new variant of backdoors called ρ-backdoors makes it possible to use the Monte Carlo method and metaheuristic optimization to find ρ-backdoors with ρ very close to 1, and relatively fast. Despite the fact that in a ρ-backdoor-based decomposition a portion of hard subproblems remain, in practice the narrowing of the search space often allows solving the problem faster with such a backdoor than without it. In this paper, we significantly improve on the concept of ρ-backdoors by extending this concept to backdoor trees: we introduce ρ-backdoor trees, show the interconnections between SBS, ρ-backdoors, and the corresponding backdoor trees, and establish some new theoretical properties of backdoor trees. In the experimental part of the paper, we show that moving from the metaheuristic search for ρ-backdoors to that of ρ-backdoor trees allows drastically reducing the time required to construct the required decompositions without compromising their quality.","https://ojs.aaai.org/index.php/AAAI/article/view/25525/25297"
"25526","The Expressive Power of Ad-Hoc Constraints for Modelling CSPs","['Ruiwei Wang', 'Roland H.C. Yap']","['National University of Singapore', 'National University of Singapore']","['CSO: Constraint Satisfaction', 'CSO: Constraint Programming', 'CSO: Other Foundations of Constraint Satisfaction & Optimization']","Wang, R., & Yap, R. H. (2023). The Expressive Power of Ad-Hoc Constraints for Modelling CSPs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4104-4114. https://doi.org/10.1609/aaai.v37i4.25526","Abstract 					Ad-hoc constraints (also called generic constraints) are important for modelling Constraint Satisfaction Problems (CSPs). Many representations have been proposed to define ad-hoc constraints, such as tables, decision diagrams, binary constraint trees, automata and context-free grammars. However, prior works mainly focus on efficient Generalized Arc Consistency (GAC) propagators of ad-hoc constraints using the representations. In this paper, we ask a more fundamental question which bears on modelling constraints in a CSP as ad-hoc constraints, how the choice of constraints and operations affect tractability. Rather than ad-hoc constraints and their GAC propagators, our focus is on their expressive power in terms of succinctness (polysize) and cost of operations/queries (polytime). We use a large set of constraint families to investigate the expressive power of 14 existing ad-hoc constraints. We show a complete map of the succinctness of the ad-hoc constraints. We also present results on the tractability of applying various operations and queries on the ad-hoc constraints. Finally, we give case studies illustrating how our results can be useful for questions in the modelling of CSPs.","https://ojs.aaai.org/index.php/AAAI/article/view/25526/25298"
"25527","Graphs, Constraints, and Search for the Abstraction and Reasoning Corpus","['Yudong Xu', 'Elias B. Khalil', 'Scott Sanner']","['University of Toronto', 'University of Toronto', 'University of Toronto']","['CSO: Search', 'CSO: Constraint Learning and Acquisition', 'SO: Heuristic Search']","Xu, Y., Khalil, E. B., & Sanner, S. (2023). Graphs, Constraints, and Search for the Abstraction and Reasoning Corpus. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4115-4122. https://doi.org/10.1609/aaai.v37i4.25527","Abstract 					The Abstraction and Reasoning Corpus (ARC) aims at benchmarking the performance of general artificial intelligence algorithms. The ARC's focus on broad generalization and few-shot learning has made it difficult to solve using pure machine learning. A more promising approach has been to perform program synthesis within an appropriately designed Domain Specific Language (DSL). However, these too have seen limited success. We propose Abstract Reasoning with Graph Abstractions (ARGA), a new object-centric framework that first represents images using graphs and then performs a search for a correct program in a DSL that is based on the abstracted graph space. The complexity of this combinatorial search is tamed through the use of constraint acquisition, state hashing, and Tabu search. An extensive set of experiments demonstrates the promise of ARGA in tackling some of the complicated object-centric tasks of the ARC rather efficiently, producing programs that are correct and easy to understand.","https://ojs.aaai.org/index.php/AAAI/article/view/25527/25299"
"25528","Eliminating the Impossible, Whatever Remains Must Be True: On Extracting and Applying Background Knowledge in the Context of Formal Explanations","['Jinqiang Yu', 'Alexey Ignatiev', 'Peter J. Stuckey', 'Nina Narodytska', 'Joao Marques-Silva']","['Monash University\nARC Training Centre in OPTIMA', 'Monash University', 'Monash University\nARC Training Centre in OPTIMA', 'VMware Research', 'IRIT, CNRS']","['CSO: Satisfiability', 'CSO: Applications', 'DMKM: Applications', 'DMKM: Rule Mining & Pattern Mining', 'KRR: Applications', 'KRR: Automated Reasoning and Theorem Proving', 'ML: Transparent', 'Interpretable', 'Explainable ML']","Yu, J., Ignatiev, A., Stuckey, P. J., Narodytska, N., & Marques-Silva, J. (2023). Eliminating the Impossible, Whatever Remains Must Be True: On Extracting and Applying Background Knowledge in the Context of Formal Explanations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4123-4131. https://doi.org/10.1609/aaai.v37i4.25528","Abstract 					The rise of AI methods to make predictions and decisions has led to a pressing need for more explainable artificial intelligence (XAI) methods. One common approach for XAI is to produce a post-hoc explanation, explaining why a black box ML model made a certain prediction. Formal approaches to post-hoc explanations provide succinct reasons for why a prediction was made, as well as why not another prediction was made. But these approaches assume that features are independent and uniformly distributed. While this means that “why” explanations are correct, they may be longer than required. It also means the “why not” explanations may be suspect as the counterexamples they rely on may not be meaningful. In this paper, we show how one can apply background knowledge to give more succinct “why” formal explanations, that are presumably easier to interpret by humans, and give more accurate “why not” explanations.  In addition, we show how to use existing rule induction techniques to efficiently extract background information from a dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/25528/25300"
"25529","Farsighted Probabilistic Sampling: A General Strategy for Boosting Local Search MaxSAT Solvers","['Jiongzhi Zheng', 'Kun He', 'Jianrong Zhou']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology']","['CSO: Satisfiability', 'SO: Local Search']","Zheng, J., He, K., & Zhou, J. (2023). Farsighted Probabilistic Sampling: A General Strategy for Boosting Local Search MaxSAT Solvers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4132-4139. https://doi.org/10.1609/aaai.v37i4.25529","Abstract 					Local search has been demonstrated as an efficient approach for two practical generalizations of the MaxSAT problem, namely Partial MaxSAT (PMS) and Weighted PMS (WPMS). In this work, we observe that most local search (W)PMS solvers usually flip a single variable per iteration. Such a mechanism may lead to relatively low-quality local optimal solutions, and may limit the diversity of search directions to escape from local optima. To address this issue, we propose a general strategy, called farsighted probabilistic sampling (FPS), to replace the single flipping mechanism so as to boost the local search (W)PMS algorithms. FPS considers the benefit of continuously flipping a pair of variables in order to find higher-quality local optimal solutions. Moreover, FPS proposes an effective approach to escape from local optima by preferring the best to flip among the best sampled single variable and the best sampled variable pair. Extensive experiments demonstrate that our proposed FPS strategy significantly improves the state-of-the-art (W)PMS solvers, and FPS has an excellent generalization capability to various local search MaxSAT solvers.","https://ojs.aaai.org/index.php/AAAI/article/view/25529/25301"
"25530","LANCER: A Lifetime-Aware News Recommender System","['Hong-Kyun Bae', 'Jeewon Ahn', 'Dongwon Lee', 'Sang-Wook Kim']","['Hanyang University', 'Hanyang University', 'The Pennsylvania State University', 'Hanyang University']","['DMKM: Recommender Systems', 'DMKM: Web Search & Information Retrieval', 'APP: Web']","Bae, H.-K., Ahn, J., Lee, D., & Kim, S.-W. (2023). LANCER: A Lifetime-Aware News Recommender System. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4141-4148. https://doi.org/10.1609/aaai.v37i4.25530","Abstract 					From the observation that users reading news tend to not click outdated news, we propose the notion of 'lifetime' of news, with two hypotheses: (i) news has a shorter lifetime, compared to other types of items such as movies or e-commerce products; (ii) news only competes with other news whose lifetimes have not ended, and which has an overlapping lifetime (i.e., limited competitions). By further developing the characteristics of the lifetime of news, then we present a novel approach for news recommendation, namely, Lifetime-Aware News reCommEndeR System (LANCER) that carefully exploits the lifetime of news during training and recommendation. Using real-world news datasets (e.g., Adressa and MIND), we successfully demonstrate that state-of-the-art news recommendation models can get significantly benefited by integrating the notion of lifetime and LANCER, by up to about 40% increases in recommendation accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25530/25302"
"25531","Win-Win: A Privacy-Preserving Federated Framework for Dual-Target Cross-Domain Recommendation","['Gaode Chen', 'Xinghua Zhang', 'Yijun Su', 'Yantong Lai', 'Ji Xiang', 'Junbo Zhang', 'Yu Zheng']","['Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China\nSchool of Cyber Security, University of Chinese Academy of Sciences, Beijing, China\nJD iCity, JD Technology, Beijing, China\nJD Intelligent Cities Research, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China\nSchool of Cyber Security, University of Chinese Academy of Sciences, Beijing, China', 'JD iCity, JD Technology, Beijing, China\nJD Intelligent Cities Research, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China\nSchool of Cyber Security, University of Chinese Academy of Sciences, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China\nSchool of Cyber Security, University of Chinese Academy of Sciences, Beijing, China', 'JD iCity, JD Technology, Beijing, China\nJD Intelligent Cities Research, Beijing, China', 'JD iCity, JD Technology, Beijing, China\nJD Intelligent Cities Research, Beijing, China']","['DMKM: Recommender Systems', 'ML: Deep Neural Network Algorithms', 'ML: Distributed Machine Learning & Federated Learning']","Chen, G., Zhang, X., Su, Y., Lai, Y., Xiang, J., Zhang, J., & Zheng, Y. (2023). Win-Win: A Privacy-Preserving Federated Framework for Dual-Target Cross-Domain Recommendation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4149-4156. https://doi.org/10.1609/aaai.v37i4.25531","Abstract 					Cross-domain recommendation (CDR) aims to alleviate the data sparsity by transferring knowledge from an informative source domain to the target domain, which inevitably proposes stern challenges to data privacy and transferability during the transfer process. A small amount of recent CDR works have investigated privacy protection, while they still suffer from satisfying practical requirements (e.g., limited privacy-preserving ability) and preventing the potential risk of negative transfer. To address the above challenging problems, we propose a novel and unified privacy-preserving federated framework for dual-target CDR, namely P2FCDR. We design P2FCDR as peer-to-peer federated network architecture to ensure the local data storage and privacy protection of business partners. Specifically, for the special knowledge transfer process in CDR under federated settings, we initialize an optimizable orthogonal mapping matrix to learn the embedding transformation across domains and adopt the local differential privacy technique on the transformed embedding before exchanging across domains, which provides more reliable privacy protection. Furthermore, we exploit the similarity between in-domain and cross-domain embedding, and develop a gated selecting vector to refine the information fusion for more accurate dual transfer. Extensive experiments on three real-world datasets demonstrate that P2FCDR significantly outperforms the state-of-the-art methods and effectively protects data privacy.","https://ojs.aaai.org/index.php/AAAI/article/view/25531/25303"
"25532","Enhanced Multi-Relationships Integration Graph Convolutional Network for Inferring Substitutable and Complementary Items","['Huajie Chen', 'Jiyuan He', 'Weisheng Xu', 'Tao Feng', 'Ming Liu', 'Tianyu Song', 'Runfeng Yao', 'Yuanyuan Qiao']","['Meituan Group, Beijing, China', 'Meituan Group, Beijing, China', 'Meituan Group, Beijing, China\nBeijing University of Posts and Telecommunications, Beijing, China', 'Meituan Group, Beijing, China', 'Meituan Group, Beijing, China', 'Beijing University of Posts and Telecommunications, Beijing, China', 'Beijing University of Posts and Telecommunications, Beijing, China', 'Beijing University of Posts and Telecommunications, Beijing, China']","['DMKM: Recommender Systems', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Chen, H., He, J., Xu, W., Feng, T., Liu, M., Song, T., Yao, R., & Qiao, Y. (2023). Enhanced Multi-Relationships Integration Graph Convolutional Network for Inferring Substitutable and Complementary Items. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4157-4165. https://doi.org/10.1609/aaai.v37i4.25532","Abstract 					Understanding the relationships between items can improve the accuracy and interpretability of recommender systems. Among these relationships, the substitute and complement relationships attract the most attention in e-commerce platforms. The substitutable items are interchangeable and might be compared with each other before purchasing, while the complementary items are used in conjunction and are usually bought together with the query item. In this paper, we focus on two issues of inferring the substitutable and complementary items: 1) how to model their mutual influence to improve the performance of downstream tasks, 2) how to further discriminate them by considering the strength of relationship for different item pairs. We propose a novel multi-task learning framework named Enhanced Multi-Relationships Integration Graph Convolutional Network (EMRIGCN). We regard the relationship inference task as a link prediction task in heterogeneous graph with different types of edges between nodes (items). To model the mutual influence between substitute and complement, EMRIGCN adopts a two-level integration module, i.e., feature and structure integration, based on experts sharing mechanism during message passing. To obtain the strength of relationship for item pairs, we build an auxiliary loss function to further increase or decrease the distances between embeddings of items with weak or strong relation in latent space. Extensive experiments on both public and industrial datasets prove that EMRIGCN significantly outperforms the state-of-the-art solutions. We also conducted A/B tests on real world recommender systems of Meituan Maicai, an online supermarket platform in China, and obtained 15.3% improvement on VBR and 15.34% improvement on RPM.","https://ojs.aaai.org/index.php/AAAI/article/view/25532/25304"
"25533","PaTeCon: A Pattern-Based Temporal Constraint Mining Method for Conflict Detection on Knowledge Graphs","['Jianhao Chen', 'Junyang Ren', 'Wentao Ding', 'Yuzhong Qu']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University']","['DMKM: Semantic Web', 'DMKM: Rule Mining & Pattern Mining', 'KRR: Ontologies and Semantic Web']","Chen, J., Ren, J., Ding, W., & Qu, Y. (2023). PaTeCon: A Pattern-Based Temporal Constraint Mining Method for Conflict Detection on Knowledge Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4166-4172. https://doi.org/10.1609/aaai.v37i4.25533","Abstract 					Temporal facts, the facts for characterizing events that hold in specific time periods, are attracting rising attention in the knowledge graph (KG) research communities. In terms of quality management, the introduction of time restrictions brings new challenges to maintaining the temporal consistency of KGs and detecting potential temporal conflicts. Previous studies rely on manually enumerated temporal constraints to detect conflicts, which are labor-intensive and may have granularity issues. We start from the common pattern of temporal facts and constraints and propose a pattern-based temporal constraint mining method, PaTeCon. PaTeCon uses automatically determined graph patterns and their relevant statistical information over the given KG instead of human experts to generate time constraints. Specifically, PaTeCon dynamically attaches type restriction to candidate constraints according to their measuring scores. We evaluate PaTeCon on two large-scale datasets based on Wikidata and Freebase respectively, the experimental results show that pattern-based automatic constraint mining is powerful in generating valuable temporal constraints.","https://ojs.aaai.org/index.php/AAAI/article/view/25533/25305"
"25534","End-to-End Entity Linking with Hierarchical Reinforcement Learning","['Lihan Chen', 'Tinghui Zhu', 'Jingping Liu', 'Jiaqing Liang', 'Yanghua Xiao']","['Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University', 'Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University', 'East China University of Science and Technology, Shanghai, China', 'School of Data Science, Fudan University, China', 'Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\nFudan-Aishu Cognitive Intelligence Joint Research Center']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'ML: Reinforcement Learning Algorithms', 'SNLP: Learning & Optimization for SNLP']","Chen, L., Zhu, T., Liu, J., Liang, J., & Xiao, Y. (2023). End-to-End Entity Linking with Hierarchical Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4173-4181. https://doi.org/10.1609/aaai.v37i4.25534","Abstract 					Entity linking (EL) is the task of linking the text segments to the referring entities in the knowledge graph, typically decomposed into mention detection, and entity disambiguation. Compared to traditional methods treating the two tasks separately, recent end-to-end entity linking methods exploit the mutual dependency between mentions and entities to achieve better performance. However, existing end-to-end EL methods have problems utilizing the dependency of mentions and entities in the task. To this end, we propose to model the EL task as a hierarchical decision-making process and design a hierarchical reinforcement learning algorithm to solve the problem. We conduct extensive experiments to show that the proposed method achieves state-of-the-art performance in several EL benchmark datasets. Our code is publicly available at https://github.com/lhlclhl/he2eel.","https://ojs.aaai.org/index.php/AAAI/article/view/25534/25306"
"25535","Entity-Agnostic Representation Learning for Parameter-Efficient Knowledge Graph Embedding","['Mingyang Chen', 'Wen Zhang', 'Zhen Yao', 'Yushan Zhu', 'Yang Gao', 'Jeff Z. Pan', 'Huajun Chen']","['College of Computer Science and Technology, Zhejiang University', 'School of Software Technology, Zhejiang University', 'School of Software Technology, Zhejiang University', 'College of Computer Science and Technology, Zhejiang University', 'Huawei Technologies Co., Ltd.', 'School of Informatics, The University of Edinburgh', 'College of Computer Science and Technology, Zhejiang University\nDonghai Laboratory\nAlibaba-Zhejiang University Joint Institute of Frontier Technologies']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'DMKM: Semantic Web']","Chen, M., Zhang, W., Yao, Z., Zhu, Y., Gao, Y., Z. Pan, J., & Chen, H. (2023). Entity-Agnostic Representation Learning for Parameter-Efficient Knowledge Graph Embedding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4182-4190. https://doi.org/10.1609/aaai.v37i4.25535","Abstract 					We propose an entity-agnostic representation learning method for handling the problem of inefficient parameter storage costs brought by embedding knowledge graphs. Conventional knowledge graph embedding methods map elements in a knowledge graph, including entities and relations, into continuous vector spaces by assigning them one or multiple specific embeddings  (i.e., vector representations). Thus the number of embedding parameters increases linearly as the growth of knowledge graphs. In our proposed model, Entity-Agnostic Representation Learning (EARL), we only learn the embeddings for a small set of entities and refer to them as reserved entities. To obtain the embeddings for the full set of entities, we encode their distinguishable information from their connected relations, k-nearest reserved entities, and multi-hop neighbors. We learn universal and entity-agnostic encoders for transforming distinguishable information into entity embeddings. This approach allows our proposed EARL to have a static, efficient, and lower parameter count than conventional knowledge graph embedding methods. Experimental results show that EARL uses fewer parameters and performs better on link prediction tasks than baselines, reflecting its parameter efficiency.","https://ojs.aaai.org/index.php/AAAI/article/view/25535/25307"
"25536","Dual Low-Rank Graph Autoencoder for Semantic and Topological Networks","['Zhaoliang Chen', 'Zhihao Wu', 'Shiping Wang', 'Wenzhong Guo']","['College of Computer and Data Science, Fuzhou University, Fuzhou, China\nFujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China', 'College of Computer and Data Science, Fuzhou University, Fuzhou, China\nFujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China', 'College of Computer and Data Science, Fuzhou University, Fuzhou, China\nFujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China', 'College of Computer and Data Science, Fuzhou University, Fuzhou, China\nFujian Provincial Key Laboratory of Network Computing and Intelligent Information Processing, Fuzhou University, Fuzhou, China']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Classification and Regression', 'ML: Semi-Supervised Learning']","Chen, Z., Wu, Z., Wang, S., & Guo, W. (2023). Dual Low-Rank Graph Autoencoder for Semantic and Topological Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4191-4198. https://doi.org/10.1609/aaai.v37i4.25536","Abstract 					Due to the powerful capability to gather the information of neighborhood nodes, Graph Convolutional Network (GCN) has become a widely explored hotspot in recent years. As a well-established extension, Graph AutoEncoder (GAE) succeeds in mining underlying node representations via evaluating the quality of adjacency matrix reconstruction from learned features. However, limited works on GAE were devoted to leveraging both semantic and topological graphs, and they only indirectly extracted the relationships between graphs via weights shared by features. To better capture the connections between nodes from these two types of graphs, this paper proposes a graph neural network dubbed Dual Low-Rank Graph AutoEncoder (DLR-GAE), which takes both semantic and topological homophily into consideration. Differing from prior works that share common weights between GCNs, the presented DLR-GAE conducts sustained exploration of low-rank information between two distinct graphs, and reconstructs adjacency matrices from learned latent factors and embeddings. In order to obtain valid adjacency matrices that meet certain conditions, we design some surrogates and projections to restrict the learned factor matrix. We compare the proposed model with state-of-the-art methods on several datasets, which demonstrates the superior accuracy of DLR-GAE in semi-supervised classification.","https://ojs.aaai.org/index.php/AAAI/article/view/25536/25308"
"25537","Dynamic Multi-Behavior Sequence Modeling for Next Item Recommendation","['Junsu Cho', 'Dongmin Hyun', 'Dong won Lim', 'Hyeon jae Cheon', 'Hyoung-iel Park', 'Hwanjo Yu']","['POSTECH', 'POSTECH', 'GS Retail', 'GS Retail', 'GS Retail', 'POSTECH']","['DMKM: Recommender Systems', 'DMKM: Web Personalization & User Modeling']","Cho, J., Hyun, D., Lim, D. won, Cheon, H. jae, Park, H.- iel, & Yu, H. (2023). Dynamic Multi-Behavior Sequence Modeling for Next Item Recommendation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4199-4207. https://doi.org/10.1609/aaai.v37i4.25537","Abstract 					Sequential Recommender Systems (SRSs) aim to predict the next item that users will consume, by modeling the user interests within their item sequences. While most existing SRSs focus on a single type of user behavior, only a few pay attention to multi-behavior sequences, although they are very common in real-world scenarios. It is challenging to effectively capture the user interests within multi-behavior sequences, because the information about user interests is entangled throughout the sequences in complex relationships. To this end, we first address the characteristics of multi-behavior sequences that should be considered in SRSs, and then propose novel methods for Dynamic Multi-behavior Sequence modeling named DyMuS, which is a light version, and DyMuS+, which is an improved version, considering the characteristics. DyMuS first encodes each behavior sequence independently, and then combines the encoded sequences using dynamic routing, which dynamically integrates information required in the final result from among many candidates, based on correlations between the sequences. DyMuS+, furthermore, applies the dynamic routing even to encoding each behavior sequence to further capture the correlations at item-level. Moreover, we release a new, large and up-to-date dataset for multi-behavior recommendation. Our experiments on DyMuS and DyMuS+ show their superiority and the significance of capturing the characteristics of multi-behavior sequences.","https://ojs.aaai.org/index.php/AAAI/article/view/25537/25309"
"25538","Learning Representations of Bi-level Knowledge Graphs for Reasoning beyond Link Prediction","['Chanyoung Chung', 'Joyce Jiyoung Whang']","['KAIST', 'KAIST']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'ML: Representation Learning', 'ML: Graph-based Machine Learning']","Chung, C., & Whang, J. J. (2023). Learning Representations of Bi-level Knowledge Graphs for Reasoning beyond Link Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4208-4216. https://doi.org/10.1609/aaai.v37i4.25538","Abstract 					Knowledge graphs represent known facts using triplets. While existing knowledge graph embedding methods only consider the connections between entities, we propose considering the relationships between triplets. For example, let us consider two triplets T1 and T2 where T1 is (Academy_Awards, Nominates, Avatar) and T2 is (Avatar, Wins, Academy_Awards). Given these two base-level triplets, we see that T1 is a prerequisite for T2. In this paper, we define a higher-level triplet to represent a relationship between triplets, e.g.,  where PrerequisiteFor is a higher-level relation. We define a bi-level knowledge graph that consists of the base-level and the higher-level triplets. We also propose a data augmentation strategy based on the random walks on the bi-level knowledge graph to augment plausible triplets. Our model called BiVE learns embeddings by taking into account the structures of the base-level and the higher-level triplets, with additional consideration of the augmented triplets. We propose two new tasks: triplet prediction and conditional link prediction. Given a triplet T1 and a higher-level relation, the triplet prediction predicts a triplet that is likely to be connected to T1 by the higher-level relation, e.g., . The conditional link prediction predicts a missing entity in a triplet conditioned on another triplet, e.g., . Experimental results show that BiVE significantly outperforms all other methods in the two new tasks and the typical base-level link prediction in real-world bi-level knowledge graphs.","https://ojs.aaai.org/index.php/AAAI/article/view/25538/25310"
"25539","Lifelong Embedding Learning and Transfer for Growing Knowledge Graphs","['Yuanning Cui', 'Yuxin Wang', 'Zequn Sun', 'Wenqiang Liu', 'Yiqiao Jiang', 'Kexin Han', 'Wei Hu']","['Nanjing University', 'Nanjing Univerisity', 'Nanjing University', 'Tencent', 'Tencent', 'Tencent', 'Nanjing University']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion']","Cui, Y., Wang, Y., Sun, Z., Liu, W., Jiang, Y., Han, K., & Hu, W. (2023). Lifelong Embedding Learning and Transfer for Growing Knowledge Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4217-4224. https://doi.org/10.1609/aaai.v37i4.25539","Abstract 					Existing knowledge graph (KG) embedding models have primarily focused on static KGs. However, real-world KGs do not remain static, but rather evolve and grow in tandem with the development of KG applications. Consequently, new facts and previously unseen entities and relations continually emerge, necessitating an embedding model that can quickly learn and transfer new knowledge through growth. Motivated by this, we delve into an expanding field of KG embedding in this paper, i.e., lifelong KG embedding. We consider knowledge transfer and retention of the learning on growing snapshots of a KG without having to learn embeddings from scratch. The proposed model includes a masked KG autoencoder for embedding learning and update, with an embedding transfer strategy to inject the learned knowledge into the new entity and relation embeddings, and an embedding regularization method to avoid catastrophic forgetting. To investigate the impacts of different aspects of KG growth, we construct four datasets to evaluate the performance of lifelong KG embedding. Experimental results show that the proposed model outperforms the state-of-the-art inductive and lifelong embedding baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/25539/25311"
"25540","Uniform Sequence Better: Time Interval Aware Data Augmentation for Sequential Recommendation","['Yizhou Dang', 'Enneng Yang', 'Guibing Guo', 'Linying Jiang', 'Xingwei Wang', 'Xiaoxiao Xu', 'Qinghui Sun', 'Hong Liu']","['Software College, Northeastern University, China', 'Software College, Northeastern University, China', 'Software College, Northeastern University, China', 'Software College, Northeastern University, China', 'School of Computer Science and Engineering, Northeastern University, China', 'Alibaba Group', 'Alibaba Group', 'Alibaba Group']","['DMKM: Recommender Systems', 'DMKM: Web Personalization & User Modeling']","Dang, Y., Yang, E., Guo, G., Jiang, L., Wang, X., Xu, X., Sun, Q., & Liu, H. (2023). Uniform Sequence Better: Time Interval Aware Data Augmentation for Sequential Recommendation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4225-4232. https://doi.org/10.1609/aaai.v37i4.25540","Abstract 					Sequential recommendation is an important task to predict the next-item to access based on a sequence of interacted items. Most existing works learn user preference as the transition pattern from the previous item to the next one, ignoring the time interval between these two items. However, we observe that the time interval in a sequence may vary significantly different, and thus result in the ineffectiveness of user modeling due to the issue of preference drift. In fact, we conducted an empirical study to validate this observation, and found that a sequence with uniformly distributed time interval (denoted as uniform sequence) is more beneficial for performance improvement than that with greatly varying time interval. Therefore, we propose to augment sequence data from the perspective of time interval, which is not studied in the literature. Specifically, we design five operators (Ti-Crop, Ti-Reorder, Ti-Mask, Ti-Substitute, Ti-Insert) to transform the original non-uniform sequence to uniform sequence with the consideration of variance of time intervals. Then, we devise a control strategy to execute data augmentation on item sequences in different lengths. Finally, we implement these improvements on a state-of-the-art model CoSeRec and validate our approach on four real datasets. The experimental results show that our approach reaches significantly better performance than the other 9 competing methods.  Our implementation is available: https://github.com/KingGugu/TiCoSeRec.","https://ojs.aaai.org/index.php/AAAI/article/view/25540/25312"
"25541","Rule Induction in Knowledge Graphs Using Linear Programming","['Sanjeeb Dash', 'Joao Goncalves']","['IBM Research', 'IBM Research']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'DMKM: Rule Mining & Pattern Mining', 'KRR: Logic Programming', 'SO: Mixed Discrete/Continuous Search']","Dash, S., & Goncalves, J. (2023). Rule Induction in Knowledge Graphs Using Linear Programming. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4233-4241. https://doi.org/10.1609/aaai.v37i4.25541","Abstract 					We present a simple linear programming (LP) based method to learn compact and interpretable sets of rules encoding the facts in a knowledge graph (KG) and use these rules to solve the KG completion problem. Our LP model chooses a set of rules of bounded complexity from a list of candidate first-order logic rules and assigns weights to them. The complexity bound is enforced via explicit constraints. We combine simple rule generation heuristics with our rule selection LP to obtain predictions with accuracy comparable to state-of-the-art codes, even while generating much more compact rule sets. Furthermore, when we take as input rules generated by other codes, we often improve interpretability by reducing the number of chosen rules, while maintaining accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25541/25313"
"25542","Spatio-Temporal Neural Structural Causal Models for Bike Flow Prediction","['Pan Deng', 'Yu Zhao', 'Junting Liu', 'Xiaofeng Jia', 'Mulan Wang']","['Beihang University, Beijing, 100191, China', 'Beihang University, Beijing, 100191, China', 'Beihang University, Beijing, 100191, China', 'Beijing Big Data Centre, Beijing, 100024, China', 'Beihang University, Beijing, 100191, China']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'APP: Transportation', 'KRR: Action', 'Change', 'and Causality']","Deng, P., Zhao, Y., Liu, J., Jia, X., & Wang, M. (2023). Spatio-Temporal Neural Structural Causal Models for Bike Flow Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4242-4249. https://doi.org/10.1609/aaai.v37i4.25542","Abstract 					As a representative of public transportation, the fundamental issue of managing bike-sharing systems is bike flow prediction. Recent methods overemphasize the spatio-temporal correlations in the data, ignoring the effects of contextual conditions on the transportation system and the inter-regional time-varying causality. In addition, due to the disturbance of incomplete observations in the data, random contextual conditions lead to spurious correlations between data and features, making the prediction of the model ineffective in special scenarios. To overcome this issue, we propose a Spatio-temporal Neural Structure Causal Model(STNSCM) from the perspective of causality. First, we build a causal graph to describe the traffic prediction, and further analyze the causal relationship between the input data, contextual conditions, spatio-temporal states, and prediction results. Second, we propose to apply the frontdoor criterion to eliminate confounding biases in the feature extraction process. Finally, we propose a counterfactual representation reasoning module to extrapolate the spatio-temporal state under the factual scenario to future counterfactual scenarios to improve the prediction performance. Experiments on real-world datasets demonstrate the superior performance of our model, especially its resistance to fluctuations caused by the external environment. The source code and data will be released.","https://ojs.aaai.org/index.php/AAAI/article/view/25542/25314"
"25543","DAMix: Exploiting Deep Autoregressive Model Zoo for Improving Lossless Compression Generalization","['Qishi Dong', 'Fengwei Zhou', 'Ning Kang', 'Chuanlong Xie', 'Shifeng Zhang', 'Jiawei Li', 'Heng Peng', 'Zhenguo Li']","['Hong Kong Baptist University\nHuawei Noah’s Ark Lab', ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", 'Beijing Normal University\nHuawei Noah’s Ark Lab', ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", 'Hong Kong Baptist University', ""Huawei Noah's Ark Lab""]","['DMKM: Data Compression', 'ML: Bayesian Learning', 'ML: Ensemble Methods', 'ML: Probabilistic Methods']","Dong, Q., Zhou, F., Kang, N., Xie, C., Zhang, S., Li, J., Peng, H., & Li, Z. (2023). DAMix: Exploiting Deep Autoregressive Model Zoo for Improving Lossless Compression Generalization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4250-4258. https://doi.org/10.1609/aaai.v37i4.25543","Abstract 					Deep generative models have demonstrated superior performance in lossless compression on identically distributed data. However, in real-world scenarios, data to be compressed are of various distributions and usually cannot be known in advance. Thus, commercially expected neural compression must have strong Out-of-Distribution (OoD) generalization capabilities. Compared with traditional compression methods, deep learning methods have intrinsic flaws for OoD generalization. In this work, we make the attempt to tackle this challenge via exploiting a zoo of Deep Autoregressive models (DAMix). We build a model zoo consisting of autoregressive models trained on data from diverse distributions. In the test phase, we select useful expert models by a simple model evaluation score and adaptively aggregate the predictions of selected models. By assuming the outputs from each expert model are biased in favor of their training distributions, a von Mises-Fisher based filter is proposed to recover the value of unbiased predictions that provides more accurate density estimations than a single model. We derive the posterior of unbiased predictions as well as concentration parameters in the filter, and a novel temporal Stein variational gradient descent for sequential data is proposed to adaptively update the posterior distributions. We evaluate DAMix on 22 image datasets, including in-distribution and OoD data, and demonstrate that making use of unbiased predictions has up to 45.6% improvement over the single model trained on ImageNet.","https://ojs.aaai.org/index.php/AAAI/article/view/25543/25315"
"25544","Soft Target-Enhanced Matching Framework for Deep Entity Matching","['Wenzhou Dou', 'Derong Shen', 'Xiangmin Zhou', 'Tiezheng Nie', 'Yue Kou', 'Hang Cui', 'Ge Yu']","['Northeastern University', 'Northeastern University', 'RMIT University', 'Northeastern University', 'Northeastern University', 'University of Illinois at Urbana-Champaign', 'Northeastern University']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'DMKM: Applications', 'SNLP: Text Classification']","Dou, W., Shen, D., Zhou, X., Nie, T., Kou, Y., Cui, H., & Yu, G. (2023). Soft Target-Enhanced Matching Framework for Deep Entity Matching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4259-4266. https://doi.org/10.1609/aaai.v37i4.25544","Abstract 					Deep Entity Matching (EM) is one of the core research topics in data integration. Typical existing works construct EM models by training deep neural networks (DNNs) based on the training samples with onehot labels. However, these sharp supervision signals of onehot labels harm the generalization of EM models, causing them to overfit the training samples and perform badly in unseen datasets. To solve this problem, we first propose that the challenge of training a well-generalized EM model lies in achieving the compromise between fitting the training samples and imposing regularization, i.e., the bias-variance tradeoff. Then, we propose a novel Soft Target-EnhAnced Matching (Steam) framework, which exploits the automatically generated soft targets as label-wise regularizers to constrain the model training. Specifically, Steam regards the EM model trained in previous iteration as a virtual teacher and takes its softened output as the extra regularizer to train the EM model in the current iteration. As such, Steam effectively calibrates the obtained EM model, achieving the bias-variance tradeoff without any additional computational cost. We conduct extensive experiments over open datasets and the results show that our proposed Steam outperforms the state-of-the-art EM approaches in terms of effectiveness and label efficiency.","https://ojs.aaai.org/index.php/AAAI/article/view/25544/25316"
"25545","DropMessage: Unifying Random Dropping for Graph Neural Networks","['Taoran Fang', 'Zhiqing Xiao', 'Chunping Wang', 'Jiarong Xu', 'Xuan Yang', 'Yang Yang']","['Zhejiang University', 'Zhejiang University', 'FinVolution', 'Fudan University', 'Zhejiang University', 'Zhejiang University']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Fang, T., Xiao, Z., Wang, C., Xu, J., Yang, X., & Yang, Y. (2023). DropMessage: Unifying Random Dropping for Graph Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4267-4275. https://doi.org/10.1609/aaai.v37i4.25545","Abstract 					Graph Neural Networks (GNNs) are powerful tools for graph representation learning. Despite their rapid development, GNNs also face some challenges, such as over-fitting, over-smoothing, and non-robustness. Previous works indicate that these problems can be alleviated by random dropping methods, which integrate augmented data into models by randomly masking parts of the input. However, some open problems of random dropping on GNNs remain to be solved. First, it is challenging to find a universal method that are suitable for all cases considering the divergence of different datasets and models. Second, augmented data introduced to GNNs causes the incomplete coverage of parameters and unstable training process. Third, there is no theoretical analysis on the effectiveness of random dropping methods on GNNs. In this paper, we propose a novel random dropping method called DropMessage, which performs dropping operations directly on the propagated messages during the message-passing process. More importantly, we find that DropMessage provides a unified framework for most existing random dropping methods, based on which we give theoretical analysis of their effectiveness. Furthermore, we elaborate the superiority of DropMessage: it stabilizes the training process by reducing sample variance; it keeps information diversity from the perspective of information theory, enabling it become a theoretical upper bound of other methods. To evaluate our proposed method, we conduct experiments that aims for multiple tasks on five public datasets and two industrial datasets with various backbone models. The experimental results show that DropMessage has the advantages of both effectiveness and generalization, and can significantly alleviate the problems mentioned above. A detailed version with full appendix can be found on arXiv: https://arxiv.org/abs/2204.10037.","https://ojs.aaai.org/index.php/AAAI/article/view/25545/25317"
"25546","Contrastive Pre-training with Adversarial Perturbations for Check-In Sequence Representation Learning","['Letian Gong', 'Youfang Lin', 'Shengnan Guo', 'Yan Lin', 'Tianyi Wang', 'Erwen Zheng', 'Zeyu Zhou', 'Huaiyu Wan']","['Beijing Jiaotong University\nBeijing Key Laboratory of Traffic Data Analysis and Mining', 'Beijing Jiaotong University\nBeijing Key Laboratory of Traffic Data Analysis and Mining', 'Beijing Jiaotong University\nBeijing Key Laboratory of Traffic Data Analysis and Mining', 'Beijing Jiaotong University\nBeijing Key Laboratory of Traffic Data Analysis and Mining', 'Beijing Jiaotong University', 'Beijing Jiaotong University', 'Beijing Jiaotong University', 'Beijing Jiaotong University\nBeijing Key Laboratory of Traffic Data Analysis and Mining']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'ML: Representation Learning']","Gong, L., Lin, Y., Guo, S., Lin, Y., Wang, T., Zheng, E., Zhou, Z., & Wan, H. (2023). Contrastive Pre-training with Adversarial Perturbations for Check-In Sequence Representation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4276-4283. https://doi.org/10.1609/aaai.v37i4.25546","Abstract 					A core step of mining human mobility data is to learn accurate representations for user-generated check-in sequences. The learned representations should be able to fully describe the spatial-temporal mobility patterns of users and the high-level semantics of traveling. However, existing check-in sequence representation learning is usually implicitly achieved by end-to-end models designed for specific downstream tasks, resulting in unsatisfactory generalizable abilities and poor performance. Besides, although the sequence representation learning models that follow the contrastive learning pre-training paradigm have achieved breakthroughs in many fields like NLP, they fail to simultaneously consider the unique spatial-temporal characteristics of check-in sequences and need manual adjustments on the data augmentation strategies. So, directly applying them to check-in sequences cannot yield a meaningful pretext task. To this end, in this paper we propose a contrastive pre-training model with adversarial perturbations for check-in sequence representation learning (CACSR). Firstly, we design a novel spatial-temporal augmentation block for disturbing the spatial-temporal features of check-in sequences in the latent space to relieve the stress of designing manual data augmentation strategies. Secondly, to construct an effective contrastive pretext task, we generate “hard” positive and negative pairs for the check-in sequence by adversarial training. These two designs encourage the model to capture the high-level spatial-temporal patterns and semantics of check-in sequences while ignoring the noisy and unimportant details. We demonstrate the effectiveness and versatility of CACSR on two kinds of downstream tasks using three real-world datasets. The results show that our model outperforms both the state-of-the-art pre-training methods and the end-to-end models.","https://ojs.aaai.org/index.php/AAAI/article/view/25546/25318"
"25547","MA-GCL: Model Augmentation Tricks for Graph Contrastive Learning","['Xumeng Gong', 'Cheng Yang', 'Chuan Shi']","['Beijing University of Posts and Telecommunications', 'School of Computer Science, Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Graph-based Machine Learning']","Gong, X., Yang, C., & Shi, C. (2023). MA-GCL: Model Augmentation Tricks for Graph Contrastive Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4284-4292. https://doi.org/10.1609/aaai.v37i4.25547","Abstract 					Contrastive learning (CL), which can extract the information shared between different contrastive views, has become a popular paradigm for vision representation learning. Inspired by the success in computer vision, recent work introduces CL into graph modeling, dubbed as graph contrastive learning (GCL). However, generating contrastive views in graphs is more challenging than that in images, since we have little prior knowledge on how to significantly augment a graph without changing its labels. We argue that typical data augmentation techniques (e.g., edge dropping) in GCL cannot generate diverse enough contrastive views to filter out noises. Moreover, previous GCL methods employ two view encoders with exactly the same neural architecture and tied parameters, which further harms the diversity of augmented views. To address this limitation, we propose a novel paradigm named model augmented GCL (MA-GCL), which will focus on manipulating the architectures of view encoders instead of perturbing graph inputs. Specifically, we present three easy-to-implement model augmentation tricks for GCL, namely asymmetric, random and shuffling, which can respectively help alleviate high-frequency noises, enrich training instances and bring safer augmentations. All three tricks are compatible with typical data augmentations. Experimental results show that MA-GCL can achieve state-of-the-art performance on node classification benchmarks by applying the three tricks on a simple base model. Extensive studies also validate our motivation and the effectiveness of each trick. (Code, data and appendix are available at https://github.com/GXM1141/MA-GCL. )","https://ojs.aaai.org/index.php/AAAI/article/view/25547/25319"
"25548","Generic and Dynamic Graph Representation Learning for Crowd Flow Modeling","['Liangzhe Han', 'Ruixing Zhang', 'Leilei Sun', 'Bowen Du', 'Yanjie Fu', 'Tongyu Zhu']","['Beihang University', 'Beihang University', 'Beihang University', 'Beihang University', 'University of Central Florida', 'Beihang University']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'APP: Transportation']","Han, L., Zhang, R., Sun, L., Du, B., Fu, Y., & Zhu, T. (2023). Generic and Dynamic Graph Representation Learning for Crowd Flow Modeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4293-4301. https://doi.org/10.1609/aaai.v37i4.25548","Abstract 					Many deep spatio-temporal learning methods have been proposed for crowd flow modeling in recent years. However, most of them focus on designing a spatial and temporal convolution mechanism to aggregate information from nearby nodes and historical observations for a pre-defined prediction task. Different from the existing research, this paper aims to provide a generic and dynamic representation learning method for crowd flow modeling. The main idea of our method is to maintain a continuous-time representation for each node, and update the representations of all nodes continuously according to the streaming observed data. Along this line, a particular encoder-decoder architecture is proposed, where the encoder converts the newly happened transactions into a timestamped message, and then the representations of related nodes are updated according to the generated message. The role of the decoder is to guide the representation learning process by reconstructing the observed transactions based on the most recent node representations. Moreover, a number of virtual nodes are added to discover macro-level spatial patterns and also share the representations among spatially-interacted stations. Experiments have been conducted on two real-world datasets for four popular prediction tasks in crowd flow modeling. The result demonstrates that our method could achieve better prediction performance for all the tasks than baseline methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25548/25320"
"25549","Conditional Diffusion Based on Discrete Graph Structures for Molecular Graph Generation","['Han Huang', 'Leilei Sun', 'Bowen Du', 'Weifeng Lv']","['Beihang University', 'Beihang University', 'Beihang University', 'Beihang University']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'DMKM: Applications', 'ML: Graph-based Machine Learning']","Huang, H., Sun, L., Du, B., & Lv, W. (2023). Conditional Diffusion Based on Discrete Graph Structures for Molecular Graph Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4302-4311. https://doi.org/10.1609/aaai.v37i4.25549","Abstract 					Learning the underlying distribution of molecular graphs and generating high-fidelity samples is a fundamental research problem in drug discovery and material science. However, accurately modeling distribution and rapidly generating novel molecular graphs remain crucial and challenging goals. To accomplish these goals, we propose a novel Conditional Diffusion model based on discrete Graph Structures (CDGS) for molecular graph generation. Specifically, we construct a forward graph diffusion process on both graph structures and inherent features through stochastic differential equations (SDE) and derive discrete graph structures as the condition for reverse generative processes. We present a specialized hybrid graph noise prediction model that extracts the global context and the local node-edge dependency from intermediate graph states. We further utilize ordinary differential equation (ODE) solvers for efficient graph sampling, based on the semi-linear structure of the probability flow ODE. We also combine the solvers with gradient guidance from the molecule property predictor for similarity-constrained molecule optimization. Experiments on diverse datasets validate the effectiveness of our framework. Particularly, the proposed method still generates high-quality molecular graphs in a limited number of steps.","https://ojs.aaai.org/index.php/AAAI/article/view/25549/25321"
"25550","SAH: Shifting-Aware Asymmetric Hashing for Reverse k Maximum Inner Product Search","['Qiang Huang', 'Yanhao Wang', 'Anthony K. H. Tung']","['National University of Singapore', 'East China Normal University', 'National University of Singapore']","['DMKM: Web Search & Information Retrieval', 'ML: Probabilistic Methods']","Huang, Q., Wang, Y., & Tung, A. K. H. (2023). SAH: Shifting-Aware Asymmetric Hashing for Reverse k Maximum Inner Product Search. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4312-4321. https://doi.org/10.1609/aaai.v37i4.25550","Abstract 					This paper investigates a new yet challenging problem called Reverse k-Maximum Inner Product Search (RkMIPS). Given a query (item) vector, a set of item vectors, and a set of user vectors, the problem of RkMIPS aims to find a set of user vectors whose inner products with the query vector are one of the k largest among the query and item vectors. We propose the first subquadratic-time algorithm, i.e., Shifting-aware Asymmetric Hashing (SAH), to tackle the RkMIPS problem. To speed up the Maximum Inner Product Search (MIPS) on item vectors, we design a shifting-invariant asymmetric transformation and develop a novel sublinear-time Shifting-Aware Asymmetric Locality Sensitive Hashing (SA-ALSH) scheme. Furthermore, we devise a new blocking strategy based on the Cone-Tree to effectively prune user vectors (in a batch). We prove that SAH achieves a theoretical guarantee for solving the RMIPS problem. Experimental results on five real-world datasets show that SAH runs 4~8x faster than the state-of-the-art methods for RkMIPS while achieving F1-scores of over 90%. The code is available at https://github.com/HuangQiang/SAH.","https://ojs.aaai.org/index.php/AAAI/article/view/25550/25322"
"25551","Learned Distributed Image Compression with Multi-Scale Patch Matching in Feature Domain","['Yujun Huang', 'Bin Chen', 'Shiyu Qin', 'Jiawei Li', 'Yaowei Wang', 'Tao Dai', 'Shu-Tao Xia']","['Tsinghua University\nResearch Center of Artificial Intelligence, Peng Cheng Laboratory', 'Harbin Institute of Technology, Shenzhen\nResearch Center of Artificial Intelligence, Peng Cheng Laboratory\nGuangdong Provincial Key Laboratory of Novel Security Intelligence Technologies', 'Harbin Institute of Technology, ShenZhen', 'HUAWEI Machine Co., Ltd. DongGuan', 'Research Center of Artificial Intelligence, Peng Cheng Laboratory', 'Shenzhen University', 'Tsinghua Shenzhen International Graduate School, Tsinghua University\nResearch Center of Artificial Intelligence, Peng Cheng Laboratory']","['DMKM: Data Compression', 'ML: Other Foundations of Machine Learning']","Huang, Y., Chen, B., Qin, S., Li, J., Wang, Y., Dai, T., & Xia, S.-T. (2023). Learned Distributed Image Compression with Multi-Scale Patch Matching in Feature Domain. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4322-4329. https://doi.org/10.1609/aaai.v37i4.25551","Abstract 					Beyond achieving higher compression efficiency over classical image compression codecs, deep image compression is expected to be improved with additional side information, e.g., another image from a different perspective of the same scene. To better utilize the side information under the distributed compression scenario, the existing method only implements patch matching at the image domain to solve the parallax problem caused by the difference in viewing points. However, the patch matching at the image domain is not robust to the variance of scale, shape, and illumination caused by the different viewing angles, and can not make full use of the rich texture information of the side information image. To resolve this issue, we propose Multi-Scale Feature Domain Patch Matching (MSFDPM) to fully utilizes side information at the decoder of the distributed image compression model. Specifically, MSFDPM consists of a side information feature extractor, a multi-scale feature domain patch matching module, and a multi-scale feature fusion network. Furthermore, we reuse inter-patch correlation from the shallow layer to accelerate the patch matching of the deep layer. Finally, we find that our patch matching in a multi-scale feature domain further improves compression rate by about 20% compared with the patch matching method at image domain.","https://ojs.aaai.org/index.php/AAAI/article/view/25551/25323"
"25552","Constrained Market Share Maximization by Signal-Guided Optimization","['Bo Hui', 'Yuchen Fang', 'Tian Xia', 'Sarp Aykent', 'Wei-Shinn Ku']","['Auburn University', 'Beijing University of Posts and Telecommunications', 'Auburn University', 'Auburn University', 'Auburn University']","['DMKM: Applications', 'APP: Economic/Financial']","Hui, B., Fang, Y., Xia, T., Aykent, S., & Ku, W.-S. (2023). Constrained Market Share Maximization by Signal-Guided Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4330-4338. https://doi.org/10.1609/aaai.v37i4.25552","Abstract 					With the rapid development of the airline industry, maximizing the market share with a constrained budget is an urgent econometric problem for an airline. We investigate the problem by adjusting flight frequencies on different flight routes. Owing to the large search space of solutions and the difficulty of predicting the market, this problem is in general daunting to solve. This paper proposes a novel two-stage optimization method to address the challenges. On the higher level, we use a signal to guide the optimization process toward a constrained satisfying solution. On the lower level, we consider the consecutive itineraries in real scenarios and model the unseen correlations between routes in itineraries for market share prediction. In theory, we prove the convergence of our optimization approach. In the experiment, we empirically verify the superiority of both our prediction model and optimization approach over existing works with large-scale real-world data. Our code has been released at: https://github.com/codingAndBS/AirlineMarket.","https://ojs.aaai.org/index.php/AAAI/article/view/25552/25324"
"25553","T2-GNN: Graph Neural Networks for Graphs with Incomplete Features and Structure via Teacher-Student Distillation","['Cuiying Huo', 'Di Jin', 'Yawen Li', 'Dongxiao He', 'Yu-Bin Yang', 'Lingfei Wu']","['College of Intelligence and Computing, Tianjin University, Tianjin, P.R. China', 'College of Intelligence and Computing, Tianjin University, Tianjin, P.R. China\nState Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, P.R. China', 'School of Economics and Management, Beijing University of Posts and Telecommunications, Beijing, P.R. China', 'College of Intelligence and Computing, Tianjin University, Tianjin, P.R. China', 'State Key Laboratory for Novel Software Technology, Nanjing University, Nanjing, P.R. China', 'Pinterest, New York, USA']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Graph-based Machine Learning']","Huo, C., Jin, D., Li, Y., He, D., Yang, Y.-B., & Wu, L. (2023). T2-GNN: Graph Neural Networks for Graphs with Incomplete Features and Structure via Teacher-Student Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4339-4346. https://doi.org/10.1609/aaai.v37i4.25553","Abstract 					Graph Neural Networks (GNNs) have been a prevailing technique for tackling various analysis tasks on graph data. A key premise for the remarkable performance of GNNs relies on complete and trustworthy initial graph descriptions (i.e., node features and graph structure), which is often not satisfied since real-world graphs are often incomplete due to various unavoidable factors. In particular, GNNs face greater challenges when both node features and graph structure are incomplete at the same time. The existing methods either focus on feature completion or structure completion. They usually rely on the matching relationship between features and structure, or employ joint learning of node representation and feature (or structure) completion in the hope of achieving mutual benefit. However, recent studies confirm that the mutual interference between features and structure leads to the degradation of GNN performance. When both features and structure are incomplete, the mismatch between features and structure caused by the missing randomness exacerbates the interference between the two, which may trigger incorrect completions that negatively affect node representation. To this end, in this paper we propose a general GNN framework based on teacher-student distillation to improve the performance of GNNs on incomplete graphs, namely T2-GNN. To avoid the interference between features and structure, we separately design feature-level and structure-level teacher models to provide targeted guidance for student model (base GNNs, such as GCN) through distillation. Then we design two personalized methods to obtain well-trained feature and structure teachers. To ensure that the knowledge of the teacher model is comprehensively and effectively distilled to the student model, we further propose a dual distillation mode to enable the student to acquire as much expert knowledge as possible. Extensive experiments on eight benchmark datasets demonstrate the effectiveness and robustness of the new framework on graphs with incomplete features and structure.","https://ojs.aaai.org/index.php/AAAI/article/view/25553/25325"
"25554","Detecting Sources of Healthcare Associated Infections","['Hankyu Jang', 'Andrew Fu', 'Jiaming Cui', 'Methun Kamruzzaman', 'B. Aditya Prakash', 'Anil Vullikanti', 'Bijaya Adhikari', 'Sriram V. Pemmaraju']","['University of Iowa', 'University of Virginia', 'Georgia Institute of Technology', 'University of Virginia', 'Georgia Institute of Technology', 'University of Virginia', 'University of Iowa', 'University of Iowa']","['DMKM: Applications', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'APP: Healthcare', 'Medicine & Wellness']","Jang, H., Fu, A., Cui, J., Kamruzzaman, M., Prakash, B. A., Vullikanti, A., Adhikari, B., & Pemmaraju, S. V. (2023). Detecting Sources of Healthcare Associated Infections. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4347-4355. https://doi.org/10.1609/aaai.v37i4.25554","Abstract 					Healthcare acquired infections (HAIs) (e.g., Methicillin-resistant Staphylococcus aureus infection) have complex transmission pathways, spreading not just via direct person-to-person contacts, but also via contaminated surfaces. Prior work in mathematical epidemiology has led to a class of models – which we call load sharing models – that provide a discrete-time, stochastic formalization of HAI-spread on temporal contact networks. The focus of this paper is the source detection problem for the load sharing model. The source detection problem has been studied extensively in SEIR type models, but this prior work does not apply to load sharing models. We show that a natural formulation of the source detection problem for the load sharing model is computationally hard, even to approximate. We then present two alternate formulations that are much more tractable. The tractability of our problems depends crucially on the submodularity of the expected number of infections as a function of the source set. Prior techniques for showing submodularity, such as the ""live graph"" technique are not applicable for the load sharing model and our key technical contribution is to use a more sophisticated ""coupling"" technique to show the submodularity result. We propose algorithms for our two problem formulations by extending existing algorithmic results from submodular optimization and combining these with an expectation propagation heuristic for the load sharing model that leads to orders-of-magnitude speedup. We present experimental results on temporal contact networks based on fine-grained EMR data from three different hospitals. Our results on synthetic outbreaks on these networks show that our algorithms outperform baselines by up to 5.97 times. Furthermore, case studies based on hospital outbreaks of Clostridioides difficile infection show that our algorithms identify clinically meaningful sources.","https://ojs.aaai.org/index.php/AAAI/article/view/25554/25326"
"25555","Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction","['Jiahao Ji', 'Jingyuan Wang', 'Chao Huang', 'Junjie Wu', 'Boren Xu', 'Zhenhe Wu', 'Junbo Zhang', 'Yu Zheng']","['Beihang University', 'Beihang University', 'University of Hong Kong', 'Beihang University', 'Beihang University', 'Beihang University', 'JD Intelligent Cities Research\nJD Technology', 'JD Intelligent Cities Research\nJD Technology']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'APP: Internet of Things', 'Sensor Networks & Smart Cities', 'APP: Transportation']","Ji, J., Wang, J., Huang, C., Wu, J., Xu, B., Wu, Z., Zhang, J., & Zheng, Y. (2023). Spatio-Temporal Self-Supervised Learning for Traffic Flow Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4356-4364. https://doi.org/10.1609/aaai.v37i4.25555","Abstract 					Robust prediction of citywide traffic flows at different time periods plays a crucial role in intelligent transportation systems. While previous work has made great efforts to model spatio-temporal correlations, existing methods still suffer from two key limitations: i) Most models collectively predict all regions' flows without accounting for spatial heterogeneity, i.e., different regions may have skewed traffic flow distributions. ii) These models fail to capture the temporal heterogeneity induced by time-varying traffic patterns, as they typically model temporal correlations with a shared parameterized space for all time periods. To tackle these challenges, we propose a novel Spatio-Temporal Self-Supervised Learning (ST-SSL) traffic prediction framework which enhances the traffic pattern representations to be reflective of both spatial and temporal heterogeneity, with auxiliary self-supervised learning paradigms. Specifically, our ST-SSL is built over an integrated module with temporal and spatial convolutions for encoding the information across space and time. To achieve the adaptive spatio-temporal self-supervised learning, our ST-SSL first performs the adaptive augmentation over the traffic flow graph data at both attribute- and structure-levels. On top of the augmented traffic graph, two SSL auxiliary tasks are constructed to supplement the main traffic prediction task with spatial and temporal heterogeneity-aware augmentation. Experiments on four benchmark datasets demonstrate that ST-SSL consistently outperforms various state-of-the-art baselines. Since spatio-temporal heterogeneity widely exists in practical datasets, the proposed framework may also cast light on other spatial-temporal applications. Model implementation is available at https://github.com/Echo-Ji/ST-SSL.","https://ojs.aaai.org/index.php/AAAI/article/view/25555/25327"
"25556","PDFormer: Propagation Delay-Aware Dynamic Long-Range Transformer for Traffic Flow Prediction","['Jiawei Jiang', 'Chengkai Han', 'Wayne Xin Zhao', 'Jingyuan Wang']","['School of Computer Science and Engineering, Beihang University', 'School of Computer Science and Engineering, Beihang University', 'Gaoling School of Artificial Intelligence, Renmin University of China', 'School of Computer Science and Engineering, Beihang University\nPengcheng Laboratory\nSchool of Economics and Management, Beihang University']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'DMKM: Applications', 'APP: Transportation']","Jiang, J., Han, C., Zhao, W. X., & Wang, J. (2023). PDFormer: Propagation Delay-Aware Dynamic Long-Range Transformer for Traffic Flow Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4365-4373. https://doi.org/10.1609/aaai.v37i4.25556","Abstract 					As a core technology of Intelligent Transportation System, traffic flow prediction has a wide range of applications. The fundamental challenge in traffic flow prediction is to effectively model the complex spatial-temporal dependencies in traffic data. Spatial-temporal Graph Neural Network (GNN) models have emerged as one of the most promising methods to solve this problem. However, GNN-based models have three major limitations for traffic prediction: i) Most methods model spatial dependencies in a static manner, which limits the ability to learn dynamic urban traffic patterns; ii) Most methods only consider short-range spatial information and are unable to capture long-range spatial dependencies; iii) These methods ignore the fact that the propagation of traffic conditions between locations has a time delay in traffic systems. To this end, we propose a novel Propagation Delay-aware dynamic long-range transFormer, namely PDFormer, for accurate traffic flow prediction. Specifically, we design a spatial self-attention module to capture the dynamic spatial dependencies. Then, two graph masking matrices are introduced to highlight spatial dependencies from short- and long-range views. Moreover, a traffic delay-aware feature transformation module is proposed to empower PDFormer with the capability of explicitly modeling the time delay of spatial information propagation. Extensive experimental results on six real-world public traffic datasets show that our method can not only achieve state-of-the-art performance but also exhibit competitive computational efficiency. Moreover, we visualize the learned spatial-temporal attention map to make our model highly interpretable.","https://ojs.aaai.org/index.php/AAAI/article/view/25556/25328"
"25557","Continuous Trajectory Generation Based on Two-Stage GAN","['Wenjun Jiang', 'Wayne Xin Zhao', 'Jingyuan Wang', 'Jiawei Jiang']","['School of Computer Science and Engineering, Beihang University, Beijing, China', 'Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China', 'School of Computer Science and Engineering, Beihang University, Beijing, China\nPengcheng Laboratory, Shenzhen, China\nSchool of Economics and Management, Beihang University, Beijing, China', 'School of Computer Science and Engineering, Beihang University, Beijing, China']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'ML: Adversarial Learning & Robustness', 'ML: Deep Generative Models & Autoencoders']","Jiang, W., Zhao, W. X., Wang, J., & Jiang, J. (2023). Continuous Trajectory Generation Based on Two-Stage GAN. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4374-4382. https://doi.org/10.1609/aaai.v37i4.25557","Abstract 					Simulating the human mobility and generating large-scale trajectories are of great use in many real-world applications, such as urban planning, epidemic spreading analysis, and geographic privacy protect. Although many previous works have studied the problem of trajectory generation, the continuity of the generated trajectories has been neglected, which makes these methods useless for practical urban simulation scenarios. To solve this problem, we propose a novel two-stage generative adversarial framework to generate the continuous trajectory on the road network, namely TS-TrajGen, which efficiently integrates prior domain knowledge of human mobility with model-free learning paradigm. Specifically, we build the generator under the human mobility hypothesis of the A* algorithm to learn the human mobility behavior. For the discriminator, we combine the sequential reward with the mobility yaw reward to enhance the effectiveness of the generator. Finally, we propose a novel two-stage generation process to overcome the weak point of the existing stochastic generation process. Extensive experiments on two real-world datasets and two case studies demonstrate that our framework yields significant improvements over the state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25557/25329"
"25558","Let Graph Be the Go Board: Gradient-Free Node Injection Attack for Graph Neural Networks via Reinforcement Learning","['Mingxuan Ju', 'Yujie Fan', 'Chuxu Zhang', 'Yanfang Ye']","['University of Notre Dame', 'Case Western Reserve University', 'Brandeis University', 'University of Notre Dame']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Ju, M., Fan, Y., Zhang, C., & Ye, Y. (2023). Let Graph Be the Go Board: Gradient-Free Node Injection Attack for Graph Neural Networks via Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4383-4390. https://doi.org/10.1609/aaai.v37i4.25558","Abstract 					Graph Neural Networks (GNNs) have drawn significant attentions over the years and been broadly applied to essential applications requiring solid robustness or vigorous security standards, such as product recommendation and user behavior modeling. Under these scenarios, exploiting GNN's vulnerabilities and further downgrading its performance become extremely incentive for adversaries. Previous attackers mainly focus on structural perturbations or node injections to the existing graphs, guided by gradients from the surrogate models. Although they deliver promising results, several limitations still exist. For the structural perturbation attack, to launch a proposed attack, adversaries need to manipulate the existing graph topology, which is impractical in most circumstances. Whereas for the node injection attack, though being more practical, current approaches require training surrogate models to simulate a white-box setting, which results in significant performance downgrade when the surrogate architecture diverges from the actual victim model. To bridge these gaps, in this paper, we study the problem of black-box node injection attack, without training a potentially misleading surrogate model. Specifically, we model the node injection attack as a Markov decision process and propose Gradient-free Graph Advantage Actor Critic, namely G2A2C, a reinforcement learning framework in the fashion of advantage actor critic. By directly querying the victim model, G2A2C learns to inject highly malicious nodes with extremely limited attacking budgets, while maintaining a similar node feature distribution. Through our comprehensive experiments over eight acknowledged benchmark datasets with different characteristics, we demonstrate the superior performance of our proposed G2A2C over the existing state-of-the-art attackers. Source code is publicly available at: https://github.com/jumxglhf/G2A2C.","https://ojs.aaai.org/index.php/AAAI/article/view/25558/25330"
"25559","GLCC: A General Framework for Graph-Level Clustering","['Wei Ju', 'Yiyang Gu', 'Binqi Chen', 'Gongbo Sun', 'Yifang Qin', 'Xingyuming Liu', 'Xiao Luo', 'Ming Zhang']","['School of Computer Science, Peking University', 'School of Computer Science, Peking University', 'School of EECS, Peking University', 'Beijing National Day School', 'School of EECS, Peking University', 'School of EECS, Peking University', 'Department of Computer Science, University of California Los Angeles', 'School of Computer Science, Peking University']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Clustering']","Ju, W., Gu, Y., Chen, B., Sun, G., Qin, Y., Liu, X., Luo, X., & Zhang, M. (2023). GLCC: A General Framework for Graph-Level Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4391-4399. https://doi.org/10.1609/aaai.v37i4.25559","Abstract 					This paper studies the problem of graph-level clustering, which is a novel yet challenging task. This problem is critical in a variety of real-world applications such as protein clustering and genome analysis in bioinformatics. Recent years have witnessed the success of deep clustering coupled with graph neural networks (GNNs). However, existing methods focus on clustering among nodes given a single graph, while exploring clustering on multiple graphs is still under-explored. In this paper, we propose a general graph-level clustering framework named Graph-Level Contrastive Clustering (GLCC) given multiple graphs. Specifically, GLCC first constructs an adaptive affinity graph to explore instance- and cluster-level contrastive learning (CL). Instance-level CL leverages graph Laplacian based contrastive loss to learn clustering-friendly representations while cluster-level CL captures discriminative cluster representations incorporating neighbor information of each sample. Moreover, we utilize neighbor-aware pseudo-labels to reward the optimization of representation learning. The two steps can be alternatively trained to collaborate and benefit each other. Experiments on a range of well-known datasets demonstrate the superiority of our proposed GLCC over competitive baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/25559/25331"
"25560","Parameterized Algorithms for Colored Clustering","['Leon Kellerhals', 'Tomohiro Koana', 'Pascal Kunz', 'Rolf Niedermeier']","['Technische Universität Berlin', 'Technische Universität Berlin', 'Technische Universität Berlin\nHumboldt-Universität zu Berlin', 'Technische Universität Berlin']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'GTEP: Fair Division', 'ML: Clustering']","Kellerhals, L., Koana, T., Kunz, P., & Niedermeier, R. (2023). Parameterized Algorithms for Colored Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4400-4408. https://doi.org/10.1609/aaai.v37i4.25560","Abstract 					In the Colored Clustering problem, one is asked to cluster edge-colored (hyper-)graphs whose colors represent interaction types. More specifically, the goal is to select as many edges as possible without choosing two edges that share an endpoint and are colored differently. Equivalently, the goal can also be described as assigning colors to the vertices in a way that fits the edge-coloring as well as possible.  As this problem is NP-hard, we build on previous work by studying its parameterized complexity. We give a  2ᴼ⁽ᵏ⁾·nᴼ⁽¹⁾-time algorithm where k is the number of edges to be selected and n the number of vertices. We also prove the existence of a problem kernel of size O(k⁵ᐟ²), resolving an open problem posed in the literature. We consider parameters that are smaller than k, the number of edges to be selected, and r, the number of edges that can be deleted. Such smaller parameters are obtained by considering the difference between k or r and some lower bound on these values. We give both algorithms and lower bounds for Colored Clustering with such parameterizations. Finally, we settle the parameterized complexity of Colored Clustering with respect to structural graph parameters by showing that it is W[1]-hard with respect to both vertex cover number and tree-cut width, but fixed-parameter tractable with respect to local feedback edge number.","https://ojs.aaai.org/index.php/AAAI/article/view/25560/25332"
"25561","Towards Reliable Item Sampling for Recommendation Evaluation","['Dong Li', 'Ruoming Jin', 'Zhenming Liu', 'Bin Ren', 'Jing Gao', 'Zhi Liu']","['Kent State University', 'Kent State University', 'College of William & Mary', 'College of William & Mary', 'iLambda', 'iLambda']","['DMKM: Recommender Systems', 'ML: Evaluation and Analysis (Machine Learning)']","Li, D., Jin, R., Liu, Z., Ren, B., Gao, J., & Liu, Z. (2023). Towards Reliable Item Sampling for Recommendation Evaluation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4409-4416. https://doi.org/10.1609/aaai.v37i4.25561","Abstract 					Since Rendle and Krichene argued that commonly used sampling-based evaluation metrics are ``inconsistent'' with respect to the global metrics (even in expectation), there have been a few studies on the sampling-based recommender system evaluation. Existing methods try either mapping the sampling-based metrics to their global counterparts or more generally, learning the empirical rank distribution to estimate the top-K metrics.  However, despite existing efforts, there is still a lack of rigorous theoretical understanding of the proposed metric estimators, and the basic item sampling also suffers from the ``blind spot'' issue, i.e., estimation accuracy to recover the top-K metrics when K is small can still be rather substantial.  In this paper, we provide an in-depth investigation into these problems and make two innovative contributions. First, we propose a new item-sampling estimator that explicitly optimizes the error with respect to the ground truth, and theoretically highlights its subtle difference against prior work. Second, we propose a new adaptive sampling method that aims to deal with the ``blind spot'' problem and also demonstrate the expectation-maximization (EM) algorithm can be generalized for such a setting.  Our experimental results confirm our statistical analysis and the superiority of the proposed works.  This study helps lay the theoretical foundation for adopting item sampling metrics for recommendation evaluation and provides strong evidence for making item sampling a powerful and reliable tool for recommendation evaluation.","https://ojs.aaai.org/index.php/AAAI/article/view/25561/25333"
"25562","Multiple Robust Learning for Recommendation","['Haoxuan Li', 'Quanyu Dai', 'Yuru Li', 'Yan Lyu', 'Zhenhua Dong', 'Xiao-Hua Zhou', 'Peng Wu']","['Peking University', ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", 'Peking University', ""Huawei Noah's Ark Lab"", 'Peking University', 'Beijing Technology and Business University']","['DMKM: Recommender Systems', 'ML: Bias and Fairness', 'ML: Causal Learning']","Li, H., Dai, Q., Li, Y., Lyu, Y., Dong, Z., Zhou, X.-H., & Wu, P. (2023). Multiple Robust Learning for Recommendation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4417-4425. https://doi.org/10.1609/aaai.v37i4.25562","Abstract 					In recommender systems, a common problem is the presence of various biases in the collected data, which deteriorates the generalization ability of the recommendation models and leads to inaccurate predictions. Doubly robust (DR) learning has been studied in many tasks in RS, with the advantage that unbiased learning can be achieved when either a single imputation or a single propensity model is accurate. In this paper, we propose a multiple robust (MR) estimator that can take the advantage of multiple candidate imputation and propensity models to achieve unbiasedness. Specifically, the MR estimator is unbiased when any of the imputation or propensity models, or a linear combination of these models is accurate. Theoretical analysis shows that the proposed MR is an enhanced version of DR when only having a single imputation and propensity model, and has a smaller bias. Inspired by the generalization error bound of MR, we further propose a novel multiple robust learning approach with stabilization. We conduct extensive experiments on real-world and semi-synthetic datasets, which demonstrates the superiority of the proposed approach over state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25562/25334"
"25563","Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors","['Jingtao Li', 'Xinyu Wang', 'Hengwei Zhao', 'Shaoyu Wang', 'Yanfei Zhong']","['Wuhan university', 'Wuhan University', 'Wuhan University', 'Wuhan University', 'Wuhan University']","['DMKM: Anomaly/Outlier Detection', 'CV: Applications', 'CV: Representation Learning for Vision', 'CV: Segmentation']","Li, J., Wang, X., Zhao, H., Wang, S., & Zhong, Y. (2023). Anomaly Segmentation for High-Resolution Remote Sensing Images Based on Pixel Descriptors. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4426-4434. https://doi.org/10.1609/aaai.v37i4.25563","Abstract 					Anomaly segmentation in high spatial resolution (HSR) remote sensing imagery is aimed at segmenting anomaly patterns of the earth deviating from normal patterns, which plays an important role in various Earth vision applications. However, it is a challenging task due to the complex distribution and the irregular shapes of objects, and the lack of abnormal samples. To tackle these problems, an anomaly segmentation model based on pixel descriptors (ASD) is proposed for anomaly segmentation in HSR imagery. Specifically, deep one-class classification is introduced for anomaly segmentation in the feature space with discriminative pixel descriptors. The ASD model incorporates the data argument for generating virtual abnormal samples, which can force the pixel descriptors to be compact for normal data and meanwhile to be diverse to avoid the model collapse problems when only positive samples participated in the training. In addition, the ASD introduced a multi-level and multi-scale feature extraction strategy for learning the low-level and semantic information to make the pixel descriptors feature-rich.  The proposed ASD model was validated using four HSR datasets and compared with the recent state-of-the-art models, showing its potential value in Earth vision applications.","https://ojs.aaai.org/index.php/AAAI/article/view/25563/25335"
"25564","Adaptive Low-Precision Training for Embeddings in Click-Through Rate Prediction","['Shiwei Li', 'Huifeng Guo', 'Lu Hou', 'Wei Zhang', 'Xing Tang', 'Ruiming Tang', 'Rui Zhang', 'Ruixuan Li']","['Huazhong University of Science and Technology', ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", 'Tsinghua University', 'Huazhong University of Science and Technology']","['DMKM: Recommender Systems', 'DMKM: Data Compression']","Li, S., Guo, H., Hou, L., Zhang, W., Tang, X., Tang, R., Zhang, R., & Li, R. (2023). Adaptive Low-Precision Training for Embeddings in Click-Through Rate Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4435-4443. https://doi.org/10.1609/aaai.v37i4.25564","Abstract 					Embedding tables are usually huge in click-through rate (CTR) prediction models. To train and deploy the CTR models efficiently and economically, it is necessary to compress their embedding tables. To this end, we formulate a novel quantization training paradigm to compress the embeddings from the training stage, termed low-precision training (LPT). Also, we provide theoretical analysis on its convergence. The results show that stochastic weight quantization has a faster convergence rate and a smaller convergence error than deterministic weight quantization in LPT. Further, to reduce accuracy degradation, we propose adaptive low-precision training (ALPT) which learns the step size (i.e., the quantization resolution). Experiments on two real-world datasets confirm our analysis and show that ALPT can significantly improve the prediction accuracy, especially at extremely low bit width. For the first time in CTR models, we successfully train 8-bit embeddings without sacrificing prediction accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25564/25336"
"25565","Signed Laplacian Graph Neural Networks","['Yu Li', 'Meng Qu', 'Jian Tang', 'Yi Chang']","['College of Computer Science and Technology, Jilin University, China\nEngineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China', 'Mila - Québec AI Institute, Canada\nUnivesité de Montréal, Canada', 'Mila - Québec AI Institute, Canada\nHEC Montréal, Canada\nCIFAR AI Research Chair, Canada', 'School of Artificial Intelligence, Jilin University, China\nInternational Center of Future Science, Jilin University, China\nEngineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'DMKM: Rule Mining & Pattern Mining']","Li, Y., Qu, M., Tang, J., & Chang, Y. (2023). Signed Laplacian Graph Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4444-4452. https://doi.org/10.1609/aaai.v37i4.25565","Abstract 					This paper studies learning meaningful node representations for signed graphs, where both positive and negative links exist. This problem has been widely studied by meticulously designing expressive signed graph neural networks, as well as capturing the structural information of the signed graph through traditional structure decomposition methods, e.g., spectral graph theory. In this paper, we propose a novel signed graph representation learning framework, called Signed Laplacian Graph Neural Network (SLGNN), which combines the advantages of both. Specifically, based on spectral graph theory and graph signal processing, we first design different low-pass and high-pass graph convolution filters to extract low-frequency and high-frequency information on positive and negative links, respectively, and then combine them into a unified message passing framework. To effectively model signed graphs, we further propose a self-gating mechanism to estimate the impacts of low-frequency and high-frequency information during message passing. We mathematically establish the relationship between the aggregation process in SLGNN and signed Laplacian regularization in signed graphs, and theoretically analyze the expressiveness of SLGNN. Experimental results demonstrate that SLGNN outperforms various competitive baselines and achieves state-of-the-art performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25565/25337"
"25566","PPGenCDR: A Stable and Robust Framework for Privacy-Preserving Cross-Domain Recommendation","['Xinting Liao', 'Weiming Liu', 'Xiaolin Zheng', 'Binhui Yao', 'Chaochao Chen']","['Zhejiang University', 'Zhejiang university', 'Zhejiang University', 'Midea', 'Zhejiang University']","['DMKM: Recommender Systems']","Liao, X., Liu, W., Zheng, X., Yao, B., & Chen, C. (2023). PPGenCDR: A Stable and Robust Framework for Privacy-Preserving Cross-Domain Recommendation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4453-4461. https://doi.org/10.1609/aaai.v37i4.25566","Abstract 					Privacy-preserving cross-domain recommendation (PPCDR) refers to preserving the privacy of users when transferring the knowledge from source domain to target domain for better performance, which is vital for the long-term development of recommender systems. Existing work on cross-domain recommendation (CDR) reaches advanced and satisfying recommendation performance, but mostly neglects preserving privacy. To fill this gap, we propose a privacy-preserving generative cross-domain recommendation (PPGenCDR) framework for PPCDR. PPGenCDR includes two main modules, i.e., stable privacy-preserving generator module, and robust cross-domain recommendation module. Specifically, the former isolates data from different domains with a generative adversarial network (GAN) based model, which stably estimates the distribution of private data in the source domain with ́Renyi differential privacy (RDP) technique. Then the latter aims to robustly leverage the perturbed but effective knowledge from the source domain with the raw data in target domain to improve recommendation performance. Three key modules, i.e., (1) selective privacy preserver, (2) GAN stabilizer, and (3) robustness conductor, guarantee the cost-effective trade-off between utility and privacy, the stability of GAN when using RDP, and the robustness of leveraging transferable knowledge accordingly. The extensive empirical studies on Douban and Amazon datasets demonstrate that PPGenCDR significantly outperforms the state-of-the-art recommendation models while preserving privacy.","https://ojs.aaai.org/index.php/AAAI/article/view/25566/25338"
"25567","COLA: Improving Conversational Recommender Systems by Collaborative Augmentation","['Dongding Lin', 'Jian Wang', 'Wenjie Li']","['The Hong Kong Polytechnic University', 'The Hong Kong Polytechnic University', 'The Hong Kong Polytechnic University']","['DMKM: Recommender Systems', 'SNLP: Conversational AI/Dialogue Systems']","Lin, D., Wang, J., & Li, W. (2023). COLA: Improving Conversational Recommender Systems by Collaborative Augmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4462-4470. https://doi.org/10.1609/aaai.v37i4.25567","Abstract 					Conversational recommender systems (CRS) aim to employ natural language conversations to suggest suitable products to users. Understanding user preferences for prospective items and learning efficient item representations are crucial for CRS. Despite various attempts, earlier studies mostly learned item representations based on individual conversations, ignoring item popularity embodied among all others. Besides, they still need support in efficiently capturing user preferences since the information reflected in a single conversation is limited. Inspired by collaborative filtering, we propose a collaborative augmentation (COLA) method to simultaneously improve both item representation learning and user preference modeling to address these issues. We construct an interactive user-item graph from all conversations, which augments item representations with user-aware information, i.e., item popularity. To improve user preference modeling, we retrieve similar conversations from the training corpus, where the involved items and attributes that reflect the user's potential interests are used to augment the user representation through gate control. Extensive experiments on two benchmark datasets demonstrate the effectiveness of our method. Our code and data are available at https://github.com/DongdingLin/COLA.","https://ojs.aaai.org/index.php/AAAI/article/view/25567/25339"
"25568","Scalable and Effective Conductance-Based Graph Clustering","['Longlong Lin', 'Ronghua Li', 'Tao Jia']","['Southwest University', 'Beijing Institute of Technology', 'Southwest University']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Lin, L., Li, R., & Jia, T. (2023). Scalable and Effective Conductance-Based Graph Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4471-4478. https://doi.org/10.1609/aaai.v37i4.25568","Abstract 					Conductance-based graph clustering has been recognized as a fundamental operator in numerous graph analysis applications. Despite the significant success of conductance-based graph clustering, existing algorithms are either hard to obtain satisfactory clustering qualities, or have high time and space complexity to achieve provable clustering qualities. To overcome these limitations, we devise a powerful peeling-based graph clustering framework PCon. We show that many existing solutions can be reduced to our framework. Namely, they first define a score function for each vertex, then iteratively remove the vertex with the smallest score.  Finally, they output the result with the smallest conductance during the peeling process. Based on our framework, we propose two novel algorithms PCon_core and PCon_de with linear time and space complexity, which can efficiently and effectively identify clusters from massive graphs with more than a few billion edges. Surprisingly, we prove that PCon_de can identify clusters with near-constant approximation ratio, resulting in an important theoretical improvement over the well-known quadratic Cheeger bound. Empirical results on real-life and synthetic datasets show that our algorithms can achieve 5~42 times speedup with a high clustering accuracy, while using 1.4~7.8 times less memory than the baseline algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/25568/25340"
"25569","Multi-Domain Generalized Graph Meta Learning","['Mingkai Lin', 'Wenzhong Li', 'Ding Li', 'Yizhou Chen', 'Guohao Li', 'Sanglu Lu']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Graph-based Machine Learning', 'ML: Meta Learning']","Lin, M., Li, W., Li, D., Chen, Y., Li, G., & Lu, S. (2023). Multi-Domain Generalized Graph Meta Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4479-4487. https://doi.org/10.1609/aaai.v37i4.25569","Abstract 					Graph meta learning aims to learn historical knowledge from training graph neural networks (GNNs) models and adapt it to downstream learning tasks in a target graph, which has drawn increasing attention due to its ability of knowledge transfer and fast adaptation. While existing graph meta learning approaches assume the learning tasks are from the same graph domain but lack the solution for multi-domain adaptation. In this paper, we address the multi-domain generalized graph meta learning problem, which is challenging due to non-Euclidean data, inequivalent feature spaces, and heterogeneous distributions. To this end, we propose a novel solution called MD-Gram for multi-domain graph generalization. It introduces an empirical graph generalization method that uses empirical vectors to form a unified expression of non-Euclidean graph data. Then it proposes a multi-domain graphs transformation approach to transform the learning tasks from multiple source-domain graphs with inequivalent feature spaces into a common domain, where graph meta learning is conducted to learn generalized knowledge. It further adopts a domain-specific GNN enhancement method to learn a customized GNN model to achieve fast adaptation in the unseen target domain. Extensive experiments based on four real-world graph domain datasets show that the proposed method significantly outperforms the state-of-the-art in multi-domain graph meta learning tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25569/25341"
"25570","IterDE: An Iterative Knowledge Distillation Framework for Knowledge Graph Embeddings","['Jiajun Liu', 'Peng Wang', 'Ziyu Shang', 'Chenxiao Wu']","['Southeast University', 'Southeast University', 'Southeast university', 'Southeast University']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion']","Liu, J., Wang, P., Shang, Z., & Wu, C. (2023). IterDE: An Iterative Knowledge Distillation Framework for Knowledge Graph Embeddings. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4488-4496. https://doi.org/10.1609/aaai.v37i4.25570","Abstract 					Knowledge distillation for knowledge graph embedding (KGE) aims to reduce the KGE model size to address the challenges of storage limitations and knowledge reasoning efficiency. However, current work still suffers from the performance drops when compressing a high-dimensional original KGE model to a low-dimensional distillation KGE model. Moreover, most work focuses on the reduction of inference time but ignores the time-consuming training process of distilling KGE models. In this paper, we propose IterDE, a novel knowledge distillation framework for KGEs. First, IterDE introduces an iterative distillation way and enables a KGE model to alternately be a student model and a teacher model during the iterative distillation process. Consequently, knowledge can be transferred in a smooth manner between high-dimensional teacher models and low-dimensional student models, while preserving good KGE performances. Furthermore, in order to optimize the training process, we consider that different optimization objects between hard label loss and soft label loss can affect the efficiency of training, and then we propose a soft-label weighting dynamic adjustment mechanism that can balance the inconsistency of optimization direction between hard and soft label loss by gradually increasing the weighting of soft label loss. Our experimental results demonstrate that IterDE achieves a new state-of-the-art distillation performance for KGEs compared to strong baselines on the link prediction task. Significantly, IterDE can reduce the training time by 50% on average. Finally, more exploratory experiments show that the soft-label weighting dynamic adjustment mechanism and more fine-grained iterations can improve distillation performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25570/25342"
"25571","Learning by Applying: A General Framework for Mathematical Reasoning via Enhancing Explicit Knowledge Learning","['Jiayu Liu', 'Zhenya Huang', 'ChengXiang Zhai', 'Qi Liu']","['University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Illinois at Urbana-Champaign', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence']","['DMKM: Applications', 'KRR: Applications']","Liu, J., Huang, Z., Zhai, C., & Liu, Q. (2023). Learning by Applying: A General Framework for Mathematical Reasoning via Enhancing Explicit Knowledge Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4497-4506. https://doi.org/10.1609/aaai.v37i4.25571","Abstract 					Mathematical reasoning is one of the crucial abilities of general artificial intelligence, which requires machines to master mathematical logic and knowledge from solving problems. However, existing approaches are not transparent (thus not interpretable) in terms of what knowledge has been learned and applied in the reasoning process. In this paper, we propose a general Learning by Applying (LeAp) framework to enhance existing models (backbones) in a principled way by explicit knowledge learning. In LeAp, we perform knowledge learning in a novel problem-knowledge-expression paradigm, with a Knowledge Encoder to acquire knowledge from problem data and a Knowledge Decoder to apply knowledge for expression reasoning. The learned mathematical knowledge, including word-word relations and word-operator relations, forms an explicit knowledge graph, which bridges the knowledge “learning” and “applying” organically. Moreover, for problem solving, we design a semantics-enhanced module and a reasoning-enhanced module that apply knowledge to improve the problem comprehension and symbol reasoning abilities of any backbone, respectively. We theoretically prove the superiority of LeAp's autonomous learning mechanism. Experiments on three real-world datasets show that LeAp improves all backbones' performances, learns accurate knowledge, and achieves a more interpretable reasoning process.","https://ojs.aaai.org/index.php/AAAI/article/view/25571/25343"
"25572","Low-Resource Personal Attribute Prediction from Conversations","['Yinan Liu', 'Hu Chen', 'Wei Shen', 'Jiaoyan Chen']","['Nankai University', 'Nankai University', 'Nankai University', 'The University of Manchester']","['DMKM: Semantic Web']","Liu, Y., Chen, H., Shen, W., & Chen, J. (2023). Low-Resource Personal Attribute Prediction from Conversations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4507-4515. https://doi.org/10.1609/aaai.v37i4.25572","Abstract 					Personal knowledge bases (PKBs) are crucial for a broad range of applications such as personalized recommendation and Web-based chatbots. A critical challenge to build PKBs is extracting personal attribute knowledge from users' conversation data. Given some users of a conversational system, a personal attribute and these users' utterances, our goal is to predict the ranking of the given personal attribute values for each user. Previous studies often rely on a relative number of resources such as labeled utterances and external data, yet the attribute knowledge embedded in unlabeled utterances is underutilized and their performance of predicting some difficult personal attributes is still unsatisfactory. In addition, it is found that some text classification methods could be employed to resolve this task directly. However, they also perform not well over those difficult personal attributes. In this paper, we propose a novel framework PEARL to predict personal attributes from conversations by leveraging the abundant personal attribute knowledge from utterances under a low-resource setting in which no labeled utterances or external data are utilized. PEARL combines the biterm semantic information with the word co-occurrence information seamlessly via employing the updated prior attribute knowledge to refine the biterm topic model's Gibbs sampling process in an iterative manner. The extensive experimental results show that PEARL outperforms all the baseline methods not only on the task of personal attribute prediction from conversations over two data sets, but also on the more general weakly supervised text classification task over one data set.","https://ojs.aaai.org/index.php/AAAI/article/view/25572/25344"
"25573","Beyond Smoothing: Unsupervised Graph Representation Learning with Edge Heterophily Discriminating","['Yixin Liu', 'Yizhen Zheng', 'Daokun Zhang', 'Vincent CS Lee', 'Shirui Pan']","['Monash University', 'Monash University', 'Monash University', 'Monash University', 'Griffith University']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'ML: Graph-based Machine Learning']","Liu, Y., Zheng, Y., Zhang, D., Lee, V. C., & Pan, S. (2023). Beyond Smoothing: Unsupervised Graph Representation Learning with Edge Heterophily Discriminating. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4516-4524. https://doi.org/10.1609/aaai.v37i4.25573","Abstract 					Unsupervised graph representation learning (UGRL) has drawn increasing research attention and achieved promising results in several graph analytic tasks. Relying on the homophily assumption, existing UGRL methods tend to smooth the learned node representations along all edges, ignoring the existence of heterophilic edges that connect nodes with distinct attributes. As a result, current methods are hard to generalize to heterophilic graphs where dissimilar nodes are widely connected, and also vulnerable to adversarial attacks. To address this issue, we propose a novel unsupervised Graph Representation learning method with Edge hEterophily discriminaTing (GREET) which learns representations by discriminating and leveraging homophilic edges and heterophilic edges. To distinguish two types of edges, we build an edge discriminator that infers edge homophily/heterophily from feature and structure information. We train the edge discriminator in an unsupervised way through minimizing the crafted pivot-anchored ranking loss, with randomly sampled node pairs acting as pivots. Node representations are learned through contrasting the dual-channel encodings obtained from the discriminated homophilic and heterophilic edges. With an effective interplaying scheme, edge discriminating and representation learning can mutually boost each other during the training phase. We conducted extensive experiments on 14 benchmark datasets and multiple learning scenarios to demonstrate the superiority of GREET.","https://ojs.aaai.org/index.php/AAAI/article/view/25573/25345"
"25574","On Generalized Degree Fairness in Graph Neural Networks","['Zemin Liu', 'Trung-Kien Nguyen', 'Yuan Fang']","['National University of Singapore', 'Singapore Management University', 'Singapore Management University']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Bias and Fairness', 'ML: Graph-based Machine Learning']","Liu, Z., Nguyen, T.-K., & Fang, Y. (2023). On Generalized Degree Fairness in Graph Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4525-4533. https://doi.org/10.1609/aaai.v37i4.25574","Abstract 					Conventional graph neural networks (GNNs) are often confronted with fairness issues that may stem from their input, including node attributes and neighbors surrounding a node. While several recent approaches have been proposed to eliminate the bias rooted in sensitive attributes, they ignore the other key input of GNNs, namely the neighbors of a node, which can introduce bias since GNNs hinge on neighborhood structures to generate node representations. In particular, the varying neighborhood structures across nodes, manifesting themselves in drastically different node degrees, give rise to the diverse behaviors of nodes and biased outcomes. In this paper, we first define and generalize the degree bias using a generalized definition of node degree as a manifestation and quantification of different multi-hop structures around different nodes. To address the bias in the context of node classification, we propose a novel GNN framework called Generalized Degree Fairness-centric Graph Neural Network (DegFairGNN). Specifically, in each GNN layer, we employ a learnable debiasing function to generate debiasing contexts, which modulate the layer-wise neighborhood aggregation to eliminate the degree bias originating from the diverse degrees among nodes. Extensive experiments on three benchmark datasets demonstrate the effectiveness of our model on both accuracy and fairness metrics.","https://ojs.aaai.org/index.php/AAAI/article/view/25574/25346"
"25575","Time Series Contrastive Learning with Information-Aware Augmentations","['Dongsheng Luo', 'Wei Cheng', 'Yingheng Wang', 'Dongkuan Xu', 'Jingchao Ni', 'Wenchao Yu', 'Xuchao Zhang', 'Yanchi Liu', 'Yuncong Chen', 'Haifeng Chen', 'Xiang Zhang']","['Florida International University', 'NEC Laboratories America, Inc.', 'Cornell University', 'North Carolina State University', 'AWS AI Labs', 'NEC Laboratories America, Inc.', 'Microsoft', 'NEC Laboratories America, Inc.', 'NEC Laboratories America, Inc.', 'NEC Laboratories America, Inc.', 'The Pennsylvania State University']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data']","Luo, D., Cheng, W., Wang, Y., Xu, D., Ni, J., Yu, W., Zhang, X., Liu, Y., Chen, Y., Chen, H., & Zhang, X. (2023). Time Series Contrastive Learning with Information-Aware Augmentations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4534-4542. https://doi.org/10.1609/aaai.v37i4.25575","Abstract 					Various contrastive learning approaches have been proposed in recent years and achieve significant empirical success. While effective and prevalent, contrastive learning has been less explored for time series data. A key component of contrastive learning is to select appropriate augmentations imposing some priors to construct feasible positive samples, such that an encoder can be trained to learn robust and discriminative representations. Unlike image and language domains where ""desired'' augmented samples can be generated with the rule of thumb guided by prefabricated human priors, the ad-hoc manual selection of time series augmentations is hindered by their diverse and human-unrecognizable temporal structures. How to find the desired augmentations of time series data that are meaningful for given contrastive learning tasks and datasets remains an open question. In this work, we address the problem by encouraging both high fidelity and variety based on information theory. A theoretical analysis leads to the criteria for selecting feasible data augmentations. On top of that, we propose a new contrastive learning approach with information-aware augmentations, InfoTS, that adaptively selects optimal augmentations for time series representation learning. Experiments on various datasets show highly competitive performance with up to a 12.0% reduction in MSE on forecasting tasks and up to 3.7% relative improvement in accuracy on classification tasks over the leading baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/25575/25347"
"25576","NQE: N-ary Query Embedding for Complex Query Answering over Hyper-Relational Knowledge Graphs","['Haoran Luo', 'Haihong E', 'Yuhao Yang', 'Gengxian Zhou', 'Yikai Guo', 'Tianyu Yao', 'Zichen Tang', 'Xueyuan Lin', 'Kaiyang Wan']","['School of Computer Science, Beijing University of Posts and Telecommunications', 'School of Computer Science, Beijing University of Posts and Telecommunications', 'School of Automation Science and Electrical Engineering, Beihang University', 'School of Computer Science, Beijing University of Posts and Telecommunications', 'Beijing Institute of Computer Technology and Application', 'School of Computer Science, Beijing University of Posts and Telecommunications', 'School of Computer Science, Beijing University of Posts and Telecommunications', 'School of Computer Science, Beijing University of Posts and Telecommunications', 'School of Computer Science, Beijing University of Posts and Telecommunications']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'DMKM: Semantic Web', 'KRR: Automated Reasoning and Theorem Proving', 'KRR: Common-Sense Reasoning', 'KRR: Computational Complexity of Reasoning', 'KRR: Knowledge Engineering', 'KRR: Knowledge Representation Languages', 'KRR: Other Foundations of Knowledge Representation & Reasoning', 'SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Question Answering']","Luo, H., E, H., Yang, Y., Zhou, G., Guo, Y., Yao, T., Tang, Z., Lin, X., & Wan, K. (2023). NQE: N-ary Query Embedding for Complex Query Answering over Hyper-Relational Knowledge Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4543-4551. https://doi.org/10.1609/aaai.v37i4.25576","Abstract 					Complex query answering (CQA) is an essential task for multi-hop and logical reasoning on knowledge graphs (KGs). Currently, most approaches are limited to queries among binary relational facts and pay less attention to n-ary facts (n≥2) containing more than two entities, which are more prevalent in the real world. Moreover, previous CQA methods can only make predictions for a few given types of queries and cannot be flexibly extended to more complex logical queries, which significantly limits their applications. To overcome these challenges, in this work, we propose a novel N-ary Query Embedding (NQE) model for CQA over hyper-relational knowledge graphs (HKGs), which include massive n-ary facts. The NQE utilizes a dual-heterogeneous Transformer encoder and fuzzy logic theory to satisfy all n-ary FOL queries, including existential quantifiers (∃), conjunction (∧), disjunction (∨), and negation (¬). We also propose a parallel processing algorithm that can train or predict arbitrary n-ary FOL queries in a single batch, regardless of the kind of each query, with good flexibility and extensibility. In addition, we generate a new CQA dataset WD50K-NFOL, including diverse n-ary FOL queries over WD50K. Experimental results on WD50K-NFOL and other standard CQA datasets show that NQE is the state-of-the-art CQA method over HKGs with good generalization capability. Our code and dataset are publicly available.","https://ojs.aaai.org/index.php/AAAI/article/view/25576/25348"
"25577","FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction","['Kelong Mao', 'Jieming Zhu', 'Liangcai Su', 'Guohao Cai', 'Yuru Li', 'Zhenhua Dong']","['Gaoling School of Artificial Intelligence, Renmin University of China', ""Huawei Noah's Ark Lab"", 'Tsinghua University', ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab""]","['DMKM: Recommender Systems']","Mao, K., Zhu, J., Su, L., Cai, G., Li, Y., & Dong, Z. (2023). FinalMLP: An Enhanced Two-Stream MLP Model for CTR Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4552-4560. https://doi.org/10.1609/aaai.v37i4.25577","Abstract 					Click-through rate (CTR) prediction is one of the fundamental tasks in online advertising and recommendation. Multi-layer perceptron (MLP) serves as a core component in many deep CTR prediction models, but it has been widely shown that applying a vanilla MLP network alone is ineffective in learning complex feature interactions. As such, many two-stream models (e.g., Wide&Deep, DeepFM, and DCN) have recently been proposed, aiming to integrate two parallel sub-networks to learn feature interactions from two different views for enhanced CTR prediction. In addition to one MLP stream that learns feature interactions implicitly, most of the existing research focuses on designing another stream to complement the MLP stream with explicitly enhanced feature interactions. Instead, this paper presents a simple two-stream feature interaction model, namely FinalMLP, which employs only MLPs in both streams yet achieves surprisingly strong performance. In contrast to sophisticated network design in each stream, our work enhances CTR modeling through a feature selection module, which produces differentiated feature inputs to two streams, and a group-wise bilinear fusion module, which effectively captures stream-level interactions across two streams. We show that FinalMLP achieves competitive or even better performance against many existing two-stream CTR models on four open benchmark datasets and also brings significant CTR improvements during an online A/B test in our industrial news recommender system. We envision that the simple yet effective FinalMLP model could serve as a new strong baseline for future development of two-stream CTR models. Our source code will be available at MindSpore/models and FuxiCTR/model_zoo.","https://ojs.aaai.org/index.php/AAAI/article/view/25577/25349"
"25578","GMDNet: A Graph-Based Mixture Density Network for Estimating Packages’ Multimodal Travel Time Distribution","['Xiaowei Mao', 'Huaiyu Wan', 'Haomin Wen', 'Fan Wu', 'Jianbin Zheng', 'Yuting Qiang', 'Shengnan Guo', 'Lixia Wu', 'Haoyuan Hu', 'Youfang Lin']","['School of Computer and Information Technology, Beijing Jiaotong University\nArtificial Intelligence Department, Cainiao Network', 'School of Computer and Information Technology, Beijing Jiaotong University\nBeijing Key Laboratory of Traffic Data Analysis and Mining', 'School of Computer and Information Technology, Beijing Jiaotong University\nArtificial Intelligence Department, Cainiao Network', 'Artificial Intelligence Department, Cainiao Network', 'Artificial Intelligence Department, Cainiao Network', 'Artificial Intelligence Department, Cainiao Network', 'School of Computer and Information Technology, Beijing Jiaotong University\nBeijing Key Laboratory of Traffic Data Analysis and Mining', 'Artificial Intelligence Department, Cainiao Network', 'Artificial Intelligence Department, Cainiao Network', 'School of Computer and Information Technology, Beijing Jiaotong University\nBeijing Key Laboratory of Traffic Data Analysis and Mining']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'APP: Transportation']","Mao, X., Wan, H., Wen, H., Wu, F., Zheng, J., Qiang, Y., Guo, S., Wu, L., Hu, H., & Lin, Y. (2024). GMDNet: A Graph-Based Mixture Density Network for Estimating Packages’ Multimodal Travel Time Distribution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4561-4568. https://doi.org/10.1609/aaai.v37i4.25578 (Original work published June 26, 2023)","Abstract In the logistics network, accurately estimating packages' Travel Time Distribution (TTD) given the routes greatly benefits both consumers and platforms. Although recent works perform well in predicting an expected time or a time distribution in a road network, they could not be well applied to estimate TTD in logistics networks. Because TTD prediction in the logistics network requires modeling packages' multimodal TTD (MTTD, i.e., there can be more than one likely output with a given input) while leveraging the complex correlations in the logistics network. To this end, this work opens appealing research opportunities in studying MTTD learning conditioned on graph-structure data by investigating packages' travel time distribution in the logistics network. We propose a Graph-based Mixture Density Network, named GMDNet, which takes the benefits of both graph neural network and mixture density network for estimating MTTD conditioned on graph-structure data (i.e., the logistics network). Furthermore, we adopt the Expectation-Maximization (EM) framework in the training process to guarantee local convergence and thus obtain more stable results than gradient descent. Extensive experiments on two real-world datasets demonstrate the superiority of our proposed model. Corrigendum Notice In the initial publication of this article, the authors (Mao et al. 2023) acknowledged that although it referred to an earlier paper already presented and published in ICML-21 (Errica et al. 2021), it insufficiently acknowledged the extent to which it incorporated and made extensive use of techniques therein. We are providing a Corrigendum Note, ""PDF (2024-09-25),"" alongside the original published version. The Corrigendum Note summarizes the main novel contributions of this paper. Errica, F.; Bacciu, D.; and Micheli, A. 2021. Graph Mixture Density Networks. In Proceedings of the 38th International Conference on Machine Learning (PMLR-28), 3025–3035. PMLR.Mao, X.; Wan, H.; Wen, H.; Wu, F.; Zheng, J.; Qiang, Y.; Guo, S.; Wu, L.; Hu, H.; and Lin, Y. 2023. GMDNet: A Graph-Based Mixture Density Network for Estimating Packages’ Multimodal Travel Time Distribution. In Proceedings of the 37th AAAI Conference on Artificial Intelligence.","https://ojs.aaai.org/index.php/AAAI/article/view/25578/33778"
"25579","Logic and Commonsense-Guided Temporal Knowledge Graph Completion","['Guanglin Niu', 'Bo Li']","['Beihang University', 'Beihang University']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'SNLP: Applications', 'ML: Relational Learning']","Niu, G., & Li, B. (2023). Logic and Commonsense-Guided Temporal Knowledge Graph Completion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4569-4577. https://doi.org/10.1609/aaai.v37i4.25579","Abstract 					A temporal knowledge graph (TKG) stores the events derived from the data involving time. Predicting events is extremely challenging due to the time-sensitive property of events. Besides, the previous TKG completion (TKGC) approaches cannot represent both the timeliness and the causality properties of events, simultaneously. To address these challenges, we propose a Logic and Commonsense-Guided Embedding model (LCGE) to jointly learn the time-sensitive representation involving timeliness and causality of events, together with the time-independent representation of events from the perspective of commonsense. Specifically, we design a temporal rule learning algorithm to construct a rule-guided predicate embedding regularization strategy for learning the causality among events. Furthermore, we could accurately evaluate the plausibility of events via auxiliary commonsense knowledge. The experimental results of TKGC task illustrate the significant performance improvements of our model compared with the existing approaches. More interestingly, our model is able to provide the explainability of the predicted results in the view of causal inference. The appendix, source code and datasets of this paper are available at https://github.com/ngl567/LCGE.","https://ojs.aaai.org/index.php/AAAI/article/view/25579/25351"
"25580","Graph Structure Learning on User Mobility Data for Social Relationship Inference","['Guangming Qin', 'Lexue Song', 'Yanwei Yu', 'Chao Huang', 'Wenzhe Jia', 'Yuan Cao', 'Junyu Dong']","['Ocean University of China', 'Duke Kunshan University', 'Ocean University of China', 'University of Hong Kong', 'Ocean University of China', 'Ocean University of China', 'Ocean University of China']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data']","Qin, G., Song, L., Yu, Y., Huang, C., Jia, W., Cao, Y., & Dong, J. (2023). Graph Structure Learning on User Mobility Data for Social Relationship Inference. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4578-4586. https://doi.org/10.1609/aaai.v37i4.25580","Abstract 					With the prevalence of smart mobile devices and location-based services, uncovering social relationships from human mobility data is of great value in real-world spatio-temporal applications ranging from friend recommendation, advertisement targeting to transportation scheduling. While a handful of sophisticated graph embedding techniques are developed for social relationship inference, they are significantly limited to the sparse and noisy nature of user mobility data, as they all ignore the essential problem of the existence of a large amount of noisy data unrelated to social activities in such mobility data. In this work, we present Social Relationship Inference Network (SRINet), a novel Graph Neural Network (GNN) framework, to improve inference performance by learning to remove noisy data. Specifically, we first construct a multiplex user meeting graph to model the spatial-temporal interactions among users in different semantic contexts. Our proposed SRINet tactfully combines the representation learning ability of Graph Convolutional Networks (GCNs) with the power of removing noisy edges of graph structure learning, which can learn effective user embeddings on the multiplex user meeting graph in a semi-supervised manner. Extensive experiments on three real-world datasets demonstrate the superiority of SRINet against state-of-the-art techniques in inferring social relationships from user mobility data. The source code of our method is available at https://github.com/qinguangming1999/SRINet.","https://ojs.aaai.org/index.php/AAAI/article/view/25580/25352"
"25581","Online Random Feature Forests for Learning in Varying Feature Spaces","['Christian Schreckenberger', 'Yi He', 'Stefan Lüdtke', 'Christian Bartelt', 'Heiner Stuckenschmidt']","['University of Mannheim', 'Old Dominion University', 'University of Mannheim', 'University of Mannheim', 'University of Mannheim']","['DMKM: Data Stream Mining', 'ML: Classification and Regression', 'ML: Online Learning & Bandits', 'ML: Time-Series/Data Streams']","Schreckenberger, C., He, Y., Lüdtke, S., Bartelt, C., & Stuckenschmidt, H. (2023). Online Random Feature Forests for Learning in Varying Feature Spaces. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4587-4595. https://doi.org/10.1609/aaai.v37i4.25581","Abstract 					In this paper, we propose a new online learning algorithm tailored for data streams described by varying feature spaces (VFS), wherein new features constantly emerge and old features may stop to be observed over various time spans. Our proposed algorithm, named Online Random Feature Forests for Feature space Variabilities (ORF3V), provides a strategy to respect such feature dynamics by generating, updating, pruning, as well as online re-weighing an ensemble of what we call feature forests, which are generated and updated based on a compressed and storage efficient representation for each observed feature. We benchmark our algorithm on 12 datasets, including one novel real-world dataset of government COVID-19 responses collected through a crowd-sensing program in Spain. The empirical results substantiate the viability and effectiveness of our ORF3V algorithm and its superior accuracy performance over the state-of-the-art rival models.","https://ojs.aaai.org/index.php/AAAI/article/view/25581/25353"
"25582","Scaling Law for Recommendation Models: Towards General-Purpose User Representations","['Kyuyong Shin', 'Hanock Kwak', 'Su Young Kim', 'Max Nihlén Ramström', 'Jisu Jeong', 'Jung-Woo Ha', 'Kyung-Min Kim']","['NAVER, NAVER AI Lab', 'NAVER', 'NAVER', 'NAVER', 'NAVER, NAVER AI Lab', 'NAVER, NAVER AI Lab', 'NAVER, NAVER AI Lab']","['DMKM: Recommender Systems', 'DMKM: Applications', 'DMKM: Web Search & Information Retrieval']","Shin, K., Kwak, H., Kim, S. Y., Ramström, M. N., Jeong, J., Ha, J.-W., & Kim, K.-M. (2023). Scaling Law for Recommendation Models: Towards General-Purpose User Representations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4596-4604. https://doi.org/10.1609/aaai.v37i4.25582","Abstract 					Recent advancement of large-scale pretrained models such as BERT, GPT-3, CLIP, and Gopher, has shown astonishing achievements across various task domains. Unlike vision recognition and language models, studies on general-purpose user representation at scale still remain underexplored. Here we explore the possibility of general-purpose user representation learning by training a universal user encoder at large scales. We demonstrate that the scaling law is present in user representation learning areas, where the training error scales as a power-law with the amount of computation. Our Contrastive Learning User Encoder (CLUE), optimizes task-agnostic objectives, and the resulting user embeddings stretch our expectation of what is possible to do in various downstream tasks. CLUE also shows great transferability to other domains and companies, as performances on an online experiment shows significant improvements in Click-Through-Rate (CTR).  Furthermore, we also investigate how the model performance is influenced by the scale factors, such as training data size, model capacity, sequence length, and batch size. Finally, we discuss the broader impacts of CLUE in general.","https://ojs.aaai.org/index.php/AAAI/article/view/25582/25354"
"25583","Cross-Domain Adaptative Learning for Online Advertisement Customer Lifetime Value Prediction","['Hongzu Su', 'Zhekai Du', 'Jingjing Li', 'Lei Zhu', 'Ke Lu']","['University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China\nInstitute of Electronic and Information Engineering of UESTC in Guangdong', 'Shandong Normal Unversity', 'University of Electronic Science and Technology of China']","['DMKM: Recommender Systems', 'DMKM: Web Personalization & User Modeling']","Su, H., Du, Z., Li, J., Zhu, L., & Lu, K. (2023). Cross-Domain Adaptative Learning for Online Advertisement Customer Lifetime Value Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4605-4613. https://doi.org/10.1609/aaai.v37i4.25583","Abstract 					Accurate estimation of customer lifetime value (LTV), which reflects the potential consumption of a user over a period of time, is crucial for the revenue management of online advertising platforms. However, predicting LTV in real-world applications is not an easy task since the user consumption data is usually insufficient within a specific domain. To tackle this problem, we propose a novel cross-domain adaptative framework (CDAF) to leverage consumption data from different domains. The proposed method is able to simultaneously mitigate the data scarce problem and the distribution gap problem caused by data from different domains. To be specific, our method firstly learns a LTV prediction model from a different but related platform with sufficient data provision. Subsequently, we exploit domain-invariant information to mitigate data scarce problem by minimizing the Wasserstein discrepancy between the encoded user representations of two domains. In addition, we design a dual-predictor schema which not only enhances domain-invariant information in the semantic space but also preserves domain-specific information for accurate target prediction. The proposed framework is evaluated on five datasets collected from real historical data on the advertising platform of Tencent Games. Experimental results verify that the proposed framework is able to significantly improve the LTV prediction performance on this platform. For instance, our method can boost DCNv2 with the improvement of 13.7% in terms of AUC on dataset G2. Code: https://github.com/TL-UESTC/CDAF.","https://ojs.aaai.org/index.php/AAAI/article/view/25583/25355"
"25584","Self-Supervised Interest Transfer Network via Prototypical Contrastive Learning for Recommendation","['Guoqiang Sun', 'Yibin Shen', 'Sijin Zhou', 'Xiang Chen', 'Hongyan Liu', 'Chunming Wu', 'Chenyi Lei', 'Xianhui Wei', 'Fei Fang']","['Zhejiang University\nAlibaba Group', 'Alibaba Group', 'Alibaba Group', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Alibaba Group', 'Alibaba Group', 'Alibaba Group']","['DMKM: Recommender Systems', 'ML: Unsupervised & Self-Supervised Learning']","Sun, G., Shen, Y., Zhou, S., Chen, X., Liu, H., Wu, C., Lei, C., Wei, X., & Fang, F. (2023). Self-Supervised Interest Transfer Network via Prototypical Contrastive Learning for Recommendation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4614-4622. https://doi.org/10.1609/aaai.v37i4.25584","Abstract 					Cross-domain recommendation has attracted increasing attention from industry and academia recently. However, most existing methods do not exploit the interest invariance between domains, which would yield sub-optimal solutions. In this paper, we propose a cross-domain recommendation method: Self-supervised Interest Transfer Network (SITN), which can effectively transfer invariant knowledge between domains via prototypical contrastive learning. Specifically, we perform two levels of cross-domain contrastive learning: 1) instance-to-instance contrastive learning, 2) instance-to-cluster contrastive learning. Not only that, we also take into account users' multi-granularity and multi-view interests. With this paradigm, SITN can explicitly learn the invariant knowledge of interest clusters between domains and accurately capture users' intents and preferences. We conducted extensive experiments on a public dataset and a large-scale industrial dataset collected from one of the world's leading e-commerce corporations. The experimental results indicate that SITN achieves significant improvements over state-of-the-art recommendation methods. Additionally, SITN has been deployed on a micro-video recommendation platform, and the online A/B testing results further demonstrate its practical value. Supplement is available at: https://github.com/fanqieCoffee/SITN-Supplement.","https://ojs.aaai.org/index.php/AAAI/article/view/25584/25356"
"25585","Opinion Optimization in Directed Social Networks","['Haoxin Sun', 'Zhongzhi Zhang']","['Fudan University', 'Fudan University']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'CSO: Constraint Optimization', 'SO: Sampling/Simulation-Based Search']","Sun, H., & Zhang, Z. (2023). Opinion Optimization in Directed Social Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4623-4632. https://doi.org/10.1609/aaai.v37i4.25585","Abstract 					Shifting social opinions has far-reaching implications in various aspects, such as public health campaigns, product marketing, and political candidates. In this paper, we study a problem of opinion optimization based on the popular Friedkin-Johnsen (FJ) model  for opinion dynamics in an unweighted directed social network with n nodes and m edges. In the FJ model, the internal opinion of every node lies in the closed interval [0, 1], with 0 and 1 being polar opposites of opinions about a certain issue. Concretely, we focus on the problem of selecting a small number of k<","https://ojs.aaai.org/index.php/AAAI/article/view/25585/25357"
"25586","Self-Supervised Continual Graph Learning in Adaptive Riemannian Spaces","['Li Sun', 'Junda Ye', 'Hao Peng', 'Feiyang Wang', 'Philip S. Yu']","['North China Electric Power University', 'Beijing University of Posts and Telecommunications', 'Beihang University', 'Beijing University of Posts and Telecommunications', 'UIC']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Graph-based Machine Learning']","Sun, L., Ye, J., Peng, H., Wang, F., & Yu, P. S. (2023). Self-Supervised Continual Graph Learning in Adaptive Riemannian Spaces. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4633-4642. https://doi.org/10.1609/aaai.v37i4.25586","Abstract 					Continual graph learning routinely finds its role in a variety of real-world applications where the graph data with different tasks come sequentially. Despite the success of prior works, it still faces great challenges. On the one hand, existing methods work with the zero-curvature Euclidean space, and largely ignore the fact that curvature varies over the com- ing graph sequence. On the other hand, continual learners in the literature rely on abundant labels, but labeling graph in practice is particularly hard especially for the continuously emerging graphs on-the-fly. To address the aforementioned challenges, we propose to explore a challenging yet practical problem, the self-supervised continual graph learning in adaptive Riemannian spaces. In this paper, we propose a novel self-supervised Riemannian Graph Continual Learner (RieGrace). In RieGrace, we first design an Adaptive Riemannian GCN (AdaRGCN), a unified GCN coupled with a neural curvature adapter, so that Riemannian space is shaped by the learnt curvature adaptive to each graph. Then, we present a Label-free Lorentz Distillation approach, in which we create teacher-student AdaRGCN for the graph sequence. The student successively performs intra-distillation from itself and inter-distillation from the teacher so as to consolidate knowledge without catastrophic forgetting. In particular, we propose a theoretically grounded Generalized Lorentz Projection for the contrastive distillation in Riemannian space. Extensive experiments on the benchmark datasets show the superiority of RieGrace, and additionally, we investigate on how curvature changes over the graph sequence.","https://ojs.aaai.org/index.php/AAAI/article/view/25586/25358"
"25587","Self-Organization Preserved Graph Structure Learning with Principle of Relevant Information","['Qingyun Sun', 'Jianxin Li', 'Beining Yang', 'Xingcheng Fu', 'Hao Peng', 'Philip S. Yu']","['Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University\nSchool of Computer Science and Engineering, Beihang University', 'Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University\nSchool of Computer Science and Engineering, Beihang University', 'Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University\nSchool of Computer Science and Engineering, Beihang University', 'Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University\nSchool of Computer Science and Engineering, Beihang University', 'Beijing Advanced Innovation Center for Big Data and Brain Computing, Beihang University', 'Department of Computer Science, University of Illinois at Chicago']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Sun, Q., Li, J., Yang, B., Fu, X., Peng, H., & Yu, P. S. (2023). Self-Organization Preserved Graph Structure Learning with Principle of Relevant Information. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4643-4651. https://doi.org/10.1609/aaai.v37i4.25587","Abstract 					Most Graph Neural Networks follow the message-passing paradigm, assuming the observed structure depicts the ground-truth node relationships. However, this fundamental assumption cannot always be satisfied, as real-world graphs are always incomplete, noisy, or redundant. How to reveal the inherent graph structure in a unified way remains under-explored.  We proposed PRI-GSL, a Graph Structure Learning framework guided by the Principle of Relevant Information, providing a simple and unified framework for identifying the self-organization and revealing the hidden structure. PRI-GSL learns a structure that contains the most relevant yet least redundant information quantified by von Neumann entropy and Quantum Jensen Shannon divergence. PRI-GSL incorporates the evolution of quantum continuous walk with graph wavelets to encode node structural roles, showing in which way the nodes interplay and self-organize with the graph structure. Extensive experiments demonstrate the superior effectiveness and robustness of PRI-GSL.","https://ojs.aaai.org/index.php/AAAI/article/view/25587/25359"
"25588","Efficient Embeddings of Logical Variables for Query Answering over Incomplete Knowledge Graphs","['Dingmin Wang', 'Yeyuan Chen', 'Bernardo Cuenca Grau']","['University of Oxford', ""Xi'an Jiaotong University"", 'University of Oxford']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'DMKM: Applications', 'DMKM: Semantic Web']","Wang, D., Chen, Y., & Cuenca Grau, B. (2023). Efficient Embeddings of Logical Variables for Query Answering over Incomplete Knowledge Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4652-4659. https://doi.org/10.1609/aaai.v37i4.25588","Abstract 					The problem of answering complex First-order Logic queries over incomplete knowledge graphs  is receiving growing attention in the literature. A promising recent approach to this problem has been to exploit neural link predictors, which can be effective in identifying individual missing triples in the incomplete graph, in order to efficiently answer complex queries. A crucial advantage of this approach over other methods is that it does not require example answers to complex queries for training, as it relies only on the availability of a trained link  predictor for the knowledge graph at hand.  This approach, however, can be computationally expensive during inference,  and cannot deal with queries involving negation.   In this paper, we propose a novel approach that addresses all of these limitations. Experiments on established benchmark datasets demonstrate that our approach offers  superior performance while  significantly reducing inference times.","https://ojs.aaai.org/index.php/AAAI/article/view/25588/25360"
"25589","Human-Instructed Deep Hierarchical Generative Learning for Automated Urban Planning","['Dongjie Wang', 'Lingfei Wu', 'Denghui Zhang', 'Jingbo Zhou', 'Leilei Sun', 'Yanjie Fu']","['University of Central Florida', 'Pinterest', 'Rutgers University', 'Baidu Research', 'Beihang Univerisity', 'University of Central Florida']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'DMKM: Applications', 'APP: Internet of Things', 'Sensor Networks & Smart Cities']","Wang, D., Wu, L., Zhang, D., Zhou, J., Sun, L., & Fu, Y. (2023). Human-Instructed Deep Hierarchical Generative Learning for Automated Urban Planning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4660-4667. https://doi.org/10.1609/aaai.v37i4.25589","Abstract 					The essential task of urban planning is to generate the optimal land-use configuration of a target area. However, traditional urban planning is time-consuming and labor-intensive. Deep generative learning gives us hope that we can automate this planning process and come up with the ideal urban plans. While remarkable achievements have been obtained, they have exhibited limitations in lacking awareness of: 1) the hierarchical dependencies between functional zones and spatial grids; 2) the peer dependencies among functional zones; and 3) human regulations to ensure the usability of generated configurations. To address these limitations, we develop a novel human-instructed deep hierarchical generative model. We rethink the urban planning generative task from a unique functionality perspective, where we summarize planning requirements into different functionality projections for better urban plan generation. To this end, we develop a three-stage generation process from a target area to zones to grids. The first stage is to label the grids of a target area with latent functionalities to discover functional zones. The second stage is to perceive the planning requirements to form urban functionality projections. We propose a novel module: functionalizer to project the embedding of human instructions and geospatial contexts to the zone-level plan to obtain such projections. Each projection includes the information of land-use portfolios and the structural dependencies across spatial grids in terms of a specific urban function. The third stage is to leverage multi-attentions to model the zone-zone peer dependencies of the functionality projections to generate grid-level land-use configurations. Finally, we present extensive experiments to demonstrate the effectiveness of our framework.","https://ojs.aaai.org/index.php/AAAI/article/view/25589/25361"
"25590","Easy Begun Is Half Done: Spatial-Temporal Graph Modeling with ST-Curriculum Dropout","['Hongjun Wang', 'Jiyuan Chen', 'Tong Pan', 'Zipei Fan', 'Xuan Song', 'Renhe Jiang', 'Lingyu Zhang', 'Yi Xie', 'Zhongyi Wang', 'Boyuan Zhang']","['Southern University of Science and Technology', 'Southern University of Science and Technology', 'The Chinese University of Hong Kong', 'University of Tokyo', 'Southern University of Science and Technology', 'The University of Tokyo', 'Southern University of Science and Technology\nDidichuxing Inc.', 'Huawei Technologies CO.LTD', 'Huawei Technologies CO.LTD', 'Southern University of Science and Technology']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'DMKM: Applications', 'APP: Internet of Things', 'Sensor Networks & Smart Cities', 'APP: Transportation']","Wang, H., Chen, J., Pan, T., Fan, Z., Song, X., Jiang, R., Zhang, L., Xie, Y., Wang, Z., & Zhang, B. (2023). Easy Begun Is Half Done: Spatial-Temporal Graph Modeling with ST-Curriculum Dropout. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4668-4675. https://doi.org/10.1609/aaai.v37i4.25590","Abstract 					Spatial-temporal (ST) graph modeling, such as traffic speed forecasting and taxi demand prediction, is an important task in deep learning area. However, for the nodes in the graph, their ST patterns can vary greatly in difficulties for modeling, owning to the heterogeneous nature of ST data. We argue that unveiling the nodes to the model in a meaningful order, from easy to complex, can provide performance improvements over traditional training procedure. The idea has its root in Curriculum Learning, which suggests in the early stage of training models can be sensitive to noise and difficult samples. In this paper, we propose ST-Curriculum Dropout, a novel and easy-to-implement strategy for spatial-temporal graph modeling. Specifically, we evaluate the learning difficulty of each node in high-level feature space and drop those difficult ones out to ensure the model only needs to handle fundamental ST relations at the beginning, before gradually moving to hard ones. Our strategy can be applied to any canonical deep learning architecture without extra trainable parameters, and extensive experiments on a wide range of datasets are conducted to illustrate that, by controlling the difficulty level of ST relations as the training progresses, the model is able to capture better representation of the data and thus yields better generalization.","https://ojs.aaai.org/index.php/AAAI/article/view/25590/25362"
"25591","Cross-Domain Graph Anomaly Detection via Anomaly-Aware Contrastive Alignment","['Qizhou Wang', 'Guansong Pang', 'Mahsa Salehi', 'Wray Buntine', 'Christopher Leckie']","['Monash University', 'Singapore Management University', 'Monash University', 'VinUniversity\nMonash University', 'The University of Melbourne']","['DMKM: Anomaly/Outlier Detection', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Wang, Q., Pang, G., Salehi, M., Buntine, W., & Leckie, C. (2023). Cross-Domain Graph Anomaly Detection via Anomaly-Aware Contrastive Alignment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4676-4684. https://doi.org/10.1609/aaai.v37i4.25591","Abstract 					Cross-domain graph anomaly detection (CD-GAD) describes the problem of detecting anomalous nodes in an unlabelled target graph using auxiliary, related source graphs with labelled anomalous and normal nodes. Although it presents a promising approach to address the notoriously high false positive issue in anomaly detection, little work has been done in this line of research. There are numerous domain adaptation methods in the literature, but it is difficult to adapt them for GAD due to the unknown distributions of the anomalies and the complex node relations embedded in graph data. To this end, we introduce a novel domain adaptation approach, namely Anomaly-aware Contrastive alignmenT (ACT), for GAD. ACT is designed to jointly optimise: (i) unsupervised contrastive learning of normal representations of nodes in the target graph, and (ii) anomaly-aware one-class alignment that aligns these contrastive node representations and the representations of labelled normal nodes in the source graph, while enforcing significant deviation of the representations of the normal nodes from the labelled anomalous nodes in the source graph. In doing so, ACT effectively transfers anomaly-informed knowledge from the source graph to learn the complex node relations of the normal class for GAD on the target graph without any specification of the anomaly distributions. Extensive experiments on eight CD-GAD settings demonstrate that our approach ACT achieves substantially improved detection performance over 10 state-of-the-art GAD methods. Code is available at https://github.com/QZ-WANG/ACT.","https://ojs.aaai.org/index.php/AAAI/article/view/25591/25363"
"25592","WSiP: Wave Superposition Inspired Pooling for Dynamic Interactions-Aware Trajectory Prediction","['Renzhi Wang', 'Senzhang Wang', 'Hao Yan', 'Xiang Wang']","['Central South University', 'Central South University', 'Central south university', 'National University of Defense Technology']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'APP: Transportation']","Wang, R., Wang, S., Yan, H., & Wang, X. (2023). WSiP: Wave Superposition Inspired Pooling for Dynamic Interactions-Aware Trajectory Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4685-4692. https://doi.org/10.1609/aaai.v37i4.25592","Abstract 					Predicting motions of surrounding vehicles is critically important to help autonomous driving systems plan a safe path and avoid collisions. Although recent social pooling based LSTM models have achieved significant performance gains by considering the motion interactions between vehicles close to each other, vehicle trajectory prediction still remains as a challenging research issue due to the dynamic and high-order interactions in the real complex driving scenarios. To this end, we propose a wave superposition inspired social pooling (Wave-pooling for short) method for dynamically aggregating the high-order interactions from both local and global neighbor vehicles. Through modeling each vehicle as a wave with the amplitude and phase, Wave-pooling can more effectively represent the dynamic motion states of vehicles and capture their high-order dynamic interactions by wave superposition. By integrating Wave-pooling, an encoder-decoder based learning framework named WSiP is also proposed. Extensive experiments conducted on two public highway datasets NGSIM and highD verify the effectiveness of WSiP by comparison with current state-of-the-art baselines. More importantly, the result of WSiP is more interpretable as the interaction strength between vehicles can be intuitively reflected by their phase difference. The code of the work is publicly available at https://github.com/Chopin0123/WSiP.","https://ojs.aaai.org/index.php/AAAI/article/view/25592/25364"
"25593","Beyond Graph Convolutional Network: An Interpretable Regularizer-Centered Optimization Framework","['Shiping Wang', 'Zhihao Wu', 'Yuhong Chen', 'Yong Chen']","['College of Computer and Data Science, Fuzhou University', 'College of Computer and Data Science, Fuzhou University', 'College of Computer and Data Science, Fuzhou University', 'School of Computer Science, Beijing University of Posts and Telecommunications']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Deep Learning Theory', 'ML: Deep Neural Network Algorithms', 'ML: Graph-based Machine Learning']","Wang, S., Wu, Z., Chen, Y., & Chen, Y. (2023). Beyond Graph Convolutional Network: An Interpretable Regularizer-Centered Optimization Framework. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4693-4701. https://doi.org/10.1609/aaai.v37i4.25593","Abstract 					Graph convolutional networks (GCNs) have been attracting widespread attentions due to their encouraging performance and powerful generalizations. However, few work provide a general view to interpret various GCNs and guide GCNs' designs. In this paper, by revisiting the original GCN, we induce an interpretable regularizer-centerd optimization framework, in which by building appropriate regularizers we can interpret most GCNs, such as APPNP, JKNet, DAGNN, and GNN-LF/HF. Further, under the proposed framework, we devise a dual-regularizer graph convolutional network (dubbed tsGCN) to capture topological and semantic structures from graph data. Since the derived learning rule for tsGCN contains an inverse of a large matrix and thus is time-consuming, we leverage the Woodbury matrix identity and low-rank approximation tricks to successfully decrease the high computational complexity of computing infinite-order graph convolutions. Extensive experiments on eight public datasets demonstrate that tsGCN achieves superior performance against quite a few state-of-the-art competitors w.r.t. classification tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25593/25365"
"25594","Augmenting Affective Dependency Graph via Iterative Incongruity Graph Learning for Sarcasm Detection","['Xiaobao Wang', 'Yiqi Dong', 'Di Jin', 'Yawen Li', 'Longbiao Wang', 'Jianwu Dang']","['Tianjin Key Laboratory of Cognitive Computing and Application, College of Intelligence and Computing,Tianjin University, Tianjin, China', 'School of New Media and Communication, Tianjin University, Tianjin, China', 'Tianjin Key Laboratory of Cognitive Computing and Application, College of Intelligence and Computing,Tianjin University, Tianjin, China', 'School of Economics and Management, Beijing University of Posts and Telecommunications, Beijing, China', 'Tianjin Key Laboratory of Cognitive Computing and Application, College of Intelligence and Computing,Tianjin University, Tianjin, China\nHuiyan Technology (Tianjin) Co., Ltd, Tianjin, China', 'Peng Cheng Laboratory, Shenzhen, China\nTianjin Key Laboratory of Cognitive Computing and Application, College of Intelligence and Computing,Tianjin University, Tianjin, China']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Graph-based Machine Learning', 'SNLP: Sentiment Analysis and Stylistic Analysis', 'SNLP: Text Classification']","Wang, X., Dong, Y., Jin, D., Li, Y., Wang, L., & Dang, J. (2023). Augmenting Affective Dependency Graph via Iterative Incongruity Graph Learning for Sarcasm Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4702-4710. https://doi.org/10.1609/aaai.v37i4.25594","Abstract 					Recently, progress has been made towards improving automatic sarcasm detection in computer science. Among existing models, manually constructing static graphs for texts and then using graph neural networks (GNNs) is one of the most effective approaches for drawing long-range incongruity patterns. However, the manually constructed graph structure might be prone to errors (e.g., noisy or incomplete) and not optimal for the sarcasm detection task. Errors produced during the graph construction step cannot be remedied and may accrue to the following stages, resulting in poor performance. To surmount the above limitations, we explore a novel Iterative Augmenting Affective Graph and Dependency Graph (IAAD) framework to jointly and iteratively learn the incongruity graph structure. IAAD can alternatively update the incongruity graph structure and node representation until the learning graph structure is optimal for the metrics of sarcasm detection. More concretely, we begin with deriving an affective and a dependency graph for each instance, then an iterative incongruity graph learning module is employed to augment affective and dependency graphs for obtaining the optimal inconsistent semantic graph with the goal of optimizing the graph for the sarcasm detection task. Extensive experiments on three datasets demonstrate that the proposed model outperforms state-of-the-art baselines for sarcasm detection with significant margins.","https://ojs.aaai.org/index.php/AAAI/article/view/25594/25366"
"25595","Structure Aware Incremental Learning with Personalized Imitation Weights for Recommender Systems","['Yuening Wang', 'Yingxue Zhang', 'Antonios Valkanas', 'Ruiming Tang', 'Chen Ma', 'Jianye Hao', 'Mark Coates']","[""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", 'McGill University', ""Huawei Noah's Ark Lab"", 'City University of Hong Kong', ""Huawei Noah's Ark Lab\nTianjin University"", 'McGill University']","['DMKM: Recommender Systems', 'ML: Graph-based Machine Learning', 'ML: Lifelong and Continual Learning']","Wang, Y., Zhang, Y., Valkanas, A., Tang, R., Ma, C., Hao, J., & Coates, M. (2023). Structure Aware Incremental Learning with Personalized Imitation Weights for Recommender Systems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4711-4719. https://doi.org/10.1609/aaai.v37i4.25595","Abstract 					Recommender systems now consume large-scale data and play a significant role in improving user experience. Graph Neural Networks (GNNs) have emerged as one of the most effective recommender system models because they model the rich relational information. The ever-growing volume of data can make training GNNs prohibitively expensive. To address this, previous attempts propose to train the GNN models incrementally as new data blocks arrive.  Feature and structure knowledge distillation techniques have been explored to allow the GNN model to train in a fast incremental fashion while alleviating the catastrophic forgetting problem.  However, preserving the same amount of the historical information for all users is sub-optimal since it fails to take into account the dynamics of each user's change of preferences.  For the users whose interests shift substantially, retaining too much of the old knowledge can overly constrain the model, preventing it from quickly adapting to the users’ novel interests.  In contrast, for users who have static preferences, model performance can benefit greatly from preserving as much of the user's long-term preferences as possible. In this work, we propose a novel training strategy that adaptively learns personalized imitation weights for each user to balance the contribution from the recent data and the amount of knowledge to be distilled from previous time periods. We demonstrate the effectiveness of learning imitation weights via a comparison on five diverse datasets for three state-of-art structure distillation based recommender systems. The performance shows consistent improvement over competitive incremental learning techniques.","https://ojs.aaai.org/index.php/AAAI/article/view/25595/25367"
"25596","Online Semi-supervised Learning with Mix-Typed Streaming Features","['Di Wu', 'Shengda Zhuo', 'Yu Wang', 'Zhong Chen', 'Yi He']","['College of Computer and Information Science, Southwest University, Chongqing 400715, China', 'Institute of Artificial Intelligence and Blockchain, Guangzhou University, Guangzhou 510006, China', 'Institute of Artificial Intelligence and Blockchain, Guangzhou University, Guangzhou 510006, China', 'Department of Computer Science, Xavier University of Louisiana, New Orleans, LA 70125, USA', 'Department of Computer Science, Old Dominion University, Norfolk, VA 23529, USA']","['DMKM: Data Stream Mining', 'ML: Online Learning & Bandits', 'ML: Semi-Supervised Learning', 'ML: Time-Series/Data Streams']","Wu, D., Zhuo, S., Wang, Y., Chen, Z., & He, Y. (2023). Online Semi-supervised Learning with Mix-Typed Streaming Features. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4720-4728. https://doi.org/10.1609/aaai.v37i4.25596","Abstract 					Online learning with feature spaces that are not fixed but can vary over time renders a seemingly flexible learning paradigm thus has drawn much attention. Unfortunately, two restrictions prohibit a ubiquitous application of this learning paradigm in practice. First, whereas prior studies mainly assume a homogenous feature type, data streams generated from real applications can be heterogeneous in which Boolean, ordinal, and continuous co-exist. Existing methods that prescribe parametric distributions such as Gaussians would not suffice to model the correlation among such mixtyped features. Second, while full supervision seems to be a default setup, providing labels to all arriving data instances over a long time span is tangibly onerous, laborious, and economically unsustainable. Alas, a semi-supervised online learner that can deal with mix-typed, varying feature spaces is still missing. To fill the gap, this paper explores a novel problem, named Online Semi-supervised Learning with Mixtyped streaming Features (OSLMF), which strives to relax the restrictions on the feature type and supervision information. Our key idea to solve the new problem is to leverage copula model to align the data instances with different feature spaces so as to make their distance measurable. A geometric structure underlying data instances is then established in an online fashion based on their distances, through which the limited labeling information is propagated, from the scarce labeled instances to their close neighbors. Experimental results are documented to evidence the viability and effectiveness of our proposed approach. Code is released in https://github.com/wudi1989/OSLMF.","https://ojs.aaai.org/index.php/AAAI/article/view/25596/25368"
"25597","Few-Shot Composition Learning for Image Retrieval with Prompt Tuning","['Junda Wu', 'Rui Wang', 'Handong Zhao', 'Ruiyi Zhang', 'Chaochao Lu', 'Shuai Li', 'Ricardo Henao']","['New York University', 'Duke University', 'Adobe Research', 'Adobe Research', 'University of Cambridge', 'Shanghai Jiao Tong University', 'Duke University']","['DMKM: Recommender Systems', 'DMKM: Mining of Visual', 'Multimedia & Multimodal Data']","Wu, J., Wang, R., Zhao, H., Zhang, R., Lu, C., Li, S., & Henao, R. (2023). Few-Shot Composition Learning for Image Retrieval with Prompt Tuning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4729-4737. https://doi.org/10.1609/aaai.v37i4.25597","Abstract 					We study the problem of composition learning for image retrieval, for which we learn to retrieve target images with search queries in the form of a composition of a reference image and a modification text that describes desired modifications of the image. Existing models of composition learning for image retrieval are generally built with large-scale datasets, demanding extensive training samples, i.e., query-target pairs, as supervision, which restricts their application for the scenario of few-shot learning with only few query-target pairs available. Recently, prompt tuning with frozen pretrained language models has shown remarkable performance when the amount of training data is limited. Inspired by this, we propose a prompt tuning mechanism with the pretrained CLIP model for the task of few-shot composition learning for image retrieval. Specifically, we regard the representation of the reference image as a trainable visual prompt, prefixed to the embedding of the text sequence. One challenge is to efficiently train visual prompt with few-shot samples. To deal with this issue, we further propose a self-upervised auxiliary task via ensuring that the reference image can retrieve itself when no modification information is given from the text, which facilitates training for the visual prompt, while not requiring additional annotations for query-target pairs. Experiments on multiple benchmarks show that our proposed model can yield superior performance when trained with only few query-target pairs.","https://ojs.aaai.org/index.php/AAAI/article/view/25597/25369"
"25598","ConTextual Masked Auto-Encoder for Dense Passage Retrieval","['Xing Wu', 'Guangyuan Ma', 'Meng Lin', 'Zijia Lin', 'Zhongyuan Wang', 'Songlin Hu']","['Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences\nKuaishou Technology', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Kuaishou Technology', 'Kuaishou Technology', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences']","['DMKM: Web Search & Information Retrieval', 'SNLP: Language Models']","Wu, X., Ma, G., Lin, M., Lin, Z., Wang, Z., & Hu, S. (2023). ConTextual Masked Auto-Encoder for Dense Passage Retrieval. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4738-4746. https://doi.org/10.1609/aaai.v37i4.25598","Abstract 					Dense passage retrieval aims to retrieve the relevant passages of a query from a large corpus based on dense representations (i.e., vectors) of the query and the passages. Recent studies have explored improving pre-trained language models to boost dense retrieval performance. This paper proposes CoT-MAE (ConTextual Masked Auto-Encoder), a simple yet effective generative pre-training method for dense passage retrieval. CoT-MAE employs an asymmetric encoder-decoder architecture that learns to compress the sentence semantics into a dense vector through self-supervised and context-supervised masked auto-encoding. Precisely, self-supervised masked auto-encoding learns to model the semantics of the tokens inside a text span, and context-supervised masked auto-encoding learns to model the semantical correlation between the text spans. We conduct experiments on large-scale passage retrieval benchmarks and show considerable improvements over strong baselines, demonstrating the high efficiency of CoT-MAE. Our code is available at  https://github.com/caskcsg/ir/tree/main/cotmae.","https://ojs.aaai.org/index.php/AAAI/article/view/25598/25370"
"25599","Jointly Imputing Multi-View Data with Optimal Transport","['Yangyang Wu', 'Xiaoye Miao', 'Xinyu Huang', 'Jianwei Yin']","['Zhejiang University', 'Zhejiang University', 'Columbia University', 'Zhejiang University']","['DMKM: Mining of Visual', 'Multimedia & Multimodal Data']","Wu, Y., Miao, X., Huang, X., & Yin, J. (2023). Jointly Imputing Multi-View Data with Optimal Transport. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4747-4755. https://doi.org/10.1609/aaai.v37i4.25599","Abstract 					The multi-view data with incomplete information hinder the effective data analysis. Existing multi-view imputation methods that learn the mapping between complete view and completely missing view are not able to deal with the common multi-view data with missing feature information. In this paper, we propose a generative imputation model named Git with optimal transport theory to jointly impute the missing features/values, conditional on all observed values from the multi-view data. Git consists of two modules, i.e., a multi-view joint generator (MJG) and a masking energy discriminator (MED). The generator MJG incorporates a joint autoencoder with the multiple imputation rule to learn the data distribution from all observed multi-view data. The discriminator MED leverages a new masking energy divergence function to make Git differentiable for imputation enhancement. Extensive experiments on several real-world multi-view data sets demonstrate that, Git yields over 35% accuracy gain, compared to the state-of-the-art approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/25599/25371"
"25600","Knowledge Graph Embedding by Normalizing Flows","['Changyi Xiao', 'Xiangnan He', 'Yixin Cao']","['University of Science and Technology of China', 'University of Science and Technology of China', 'Singapore Management University']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'KRR: Knowledge Representation Languages', 'KRR: Other Foundations of Knowledge Representation & Reasoning', 'DMKM: Applications']","Xiao, C., He, X., & Cao, Y. (2023). Knowledge Graph Embedding by Normalizing Flows. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4756-4764. https://doi.org/10.1609/aaai.v37i4.25600","Abstract 					A key to knowledge graph embedding (KGE) is to choose a proper representation space, e.g., point-wise Euclidean space and complex vector space. In this paper, we propose a unified perspective of embedding and introduce uncertainty into KGE from the view of group theory. Our model can incorporate existing models (i.e., generality), ensure the computation is tractable (i.e., efficiency) and enjoy the expressive power of complex random variables (i.e., expressiveness). The core idea is that we embed entities/relations as elements of a symmetric group, i.e., permutations of a set. Permutations of different sets can reflect different properties of embedding. And the group operation of symmetric groups is easy to compute. In specific, we show that the embedding of many existing models, point vectors, can be seen as elements of a symmetric group. To reflect uncertainty, we first embed entities/relations as permutations of a set of random variables. A permutation can transform a simple random variable into a complex random variable for greater expressiveness, called a normalizing flow. We then define scoring functions by measuring the similarity of two normalizing flows, namely NFE. We construct several instantiating models and prove that they are able to learn logical rules. Experimental results demonstrate the effectiveness of introducing uncertainty and our model. The code is available at https://github.com/changyi7231/NFE.","https://ojs.aaai.org/index.php/AAAI/article/view/25600/25372"
"25601","Temporal Knowledge Graph Reasoning with Historical Contrastive Learning","['Yi Xu', 'Junjie Ou', 'Hui Xu', 'Luoyi Fu']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'shanghai jiao tong university', 'Shanghai Jiao Tong University']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'DMKM: Applications', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'DMKM: Web Search & Information Retrieval']","Xu, Y., Ou, J., Xu, H., & Fu, L. (2023). Temporal Knowledge Graph Reasoning with Historical Contrastive Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4765-4773. https://doi.org/10.1609/aaai.v37i4.25601","Abstract 					Temporal knowledge graph, serving as an effective way to store and model dynamic relations, shows promising prospects in event forecasting. However, most temporal knowledge graph reasoning methods are highly dependent on the recurrence or periodicity of events, which brings challenges to inferring future events related to entities that lack historical interaction. In fact, the current moment is often the combined effect of a small part of historical information and those unobserved underlying factors. To this end, we propose a new event forecasting model called Contrastive Event Network (CENET), based on a novel training framework of historical contrastive learning. CENET learns both the historical and non-historical dependency to distinguish the most potential entities that can best match the given query. Simultaneously, it trains representations of queries to investigate whether the current moment depends more on historical or non-historical events by launching contrastive learning. The representations further help train a binary classifier whose output is a boolean mask to indicate related entities in the search space. During the inference process, CENET employs a mask-based strategy to generate the final results. We evaluate our proposed model on five benchmark graphs. The results demonstrate that CENET significantly outperforms all existing methods in most metrics, achieving at least 8.3% relative improvement of Hits@1 over previous state-of-the-art baselines on event-based datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25601/25373"
"25602","SCI: A Spectrum Concentrated Implicit Neural Compression for Biomedical Data","['Runzhao Yang', 'Tingxiong Xiao', 'Yuxiao Cheng', 'Qianni Cao', 'Jinyuan Qu', 'Jinli Suo', 'Qionghai Dai']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University']","['DMKM: Data Compression', 'CV: Applications', 'CV: Medical and Biological Imaging', 'CV: Representation Learning for Vision', 'ML: Applications']","Yang, R., Xiao, T., Cheng, Y., Cao, Q., Qu, J., Suo, J., & Dai, Q. (2023). SCI: A Spectrum Concentrated Implicit Neural Compression for Biomedical Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4774-4782. https://doi.org/10.1609/aaai.v37i4.25602","Abstract 					Massive collection and explosive growth of biomedical data, demands effective compression for efficient storage, transmission and sharing. Readily available visual data compression techniques have been studied extensively but tailored for natural images/videos, and thus show limited performance on biomedical data which are of different features and larger diversity. Emerging implicit neural representation (INR) is gaining momentum and demonstrates high promise for fitting diverse visual data in target-data-specific manner, but a general compression scheme covering diverse biomedical data is so far absent. To address this issue, we firstly derive a mathematical explanation for INR's spectrum concentration property and an analytical insight on the design of INR based compressor. Further, we propose a Spectrum Concentrated Implicit neural compression (SCI) which adaptively partitions the complex biomedical data into blocks matching INR's concentrated spectrum envelop, and design a funnel shaped neural network capable of representing each block with a small number of parameters. Based on this design, we conduct compression via optimization under given budget and allocate the available parameters with high representation accuracy. The experiments show SCI's superior performance to state-of-the-art methods including commercial compressors, data-driven ones, and INR based counterparts on diverse biomedical data. The source code can be found at https://github.com/RichealYoung/ImplicitNeuralCompression.git.","https://ojs.aaai.org/index.php/AAAI/article/view/25602/25374"
"25603","Unsupervised Legal Evidence Retrieval via Contrastive Learning with Approximate Aggregated Positive","['Feng Yao', 'Jingyuan Zhang', 'Yating Zhang', 'Xiaozhong Liu', 'Changlong Sun', 'Yun Liu', 'Weixing Shen']","['Tsinghua University', 'Alibaba Group', 'Alibaba Group', 'Worcester Polytechnic Institute', 'Alibaba Group', 'Tsinghua University', 'Tsinghua University']","['DMKM: Applications', 'DMKM: Web Search & Information Retrieval', 'APP: Other Applications', 'SNLP: Applications']","Yao, F., Zhang, J., Zhang, Y., Liu, X., Sun, C., Liu, Y., & Shen, W. (2023). Unsupervised Legal Evidence Retrieval via Contrastive Learning with Approximate Aggregated Positive. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4783-4791. https://doi.org/10.1609/aaai.v37i4.25603","Abstract 					Verifying the facts alleged by the prosecutors before the trial requires the judges to retrieve evidence within the massive materials accompanied. Existing Legal AI applications often assume the facts are already determined and fail to notice the difficulty of reconstructing them. To build a practical Legal AI application and free the judges from the manually searching work, we introduce the task of Legal Evidence Retrieval, which aims at automatically retrieving the precise fact-related verbal evidence within a single case. We formulate the task in a dense retrieval paradigm, and jointly learn the constrastive representations and alignments between facts and evidence. To get rid of the tedious annotations, we construct an approximated positive vector for a given fact by aggregating a set of evidence from the same case. An entropy-based denoise technique is further applied to mitigate the impact of false positive samples. We train our models on tens of thousands of unlabeled cases and evaluate them on a labeled dataset containing 919 cases and 4,336 queries. Experimental results indicate that our approach is effective and outperforms other state-of-the-art representation and retrieval models. The dataset and code are available at https://github.com/yaof20/LER.","https://ojs.aaai.org/index.php/AAAI/article/view/25603/25375"
"25604","One-for-All: Proposal Masked Cross-Class Anomaly Detection","['Xincheng Yao', 'Chongyang Zhang', 'Ruoqi Li', 'Jun Sun', 'Zhenyu Liu']","['Shanghai Jiao Tong University, Shanghai, China', 'Shanghai Jiao Tong University, Shanghai, China', 'Shanghai Jiao Tong University, Shanghai, China', 'Shanghai Jiao Tong University, Shanghai, China', 'Ningbo HTVision Digital Technology Co.,Ltd, Ningbo, China']","['DMKM: Anomaly/Outlier Detection', 'CV: Applications', 'CV: Object Detection & Categorization', 'CV: Other Foundations of Computer Vision']","Yao, X., Zhang, C., Li, R., Sun, J., & Liu, Z. (2023). One-for-All: Proposal Masked Cross-Class Anomaly Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4792-4800. https://doi.org/10.1609/aaai.v37i4.25604","Abstract 					One of the most challenges for anomaly detection (AD) is how to learn one unified and generalizable model to adapt to multi-class especially cross-class settings: the model is trained with normal samples from seen classes with the objective to detect anomalies from both seen and unseen classes. In this work, we propose a novel Proposal Masked Anomaly Detection (PMAD) approach for such challenging multi- and cross-class anomaly detection. The proposed PMAD can be adapted to seen and unseen classes by two key designs: MAE-based patch-level reconstruction and prototype-guided proposal masking. First, motivated by MAE (Masked AutoEncoder), we develop a patch-level reconstruction model rather than the image-level reconstruction adopted in most AD methods for this reason: the masked patches in unseen classes can be reconstructed well by using the visible patches and the adaptive reconstruction capability of MAE. Moreover, we improve MAE by ViT encoder-decoder architecture, combinational masking, and visual tokens as reconstruction objectives to make it more suitable for anomaly detection. Second, we develop a two-stage anomaly detection manner during inference. In the proposal masking stage, the prototype-guided proposal masking module is utilized to generate proposals for suspicious anomalies as much as possible, then masked patches can be generated from the proposal regions. By masking most likely anomalous patches, the “shortcut reconstruction” issue (i.e., anomalous regions can be well reconstructed) can be mostly avoided. In the reconstruction stage, these masked patches are then reconstructed by the trained patch-level reconstruction model to determine if they are anomalies. Extensive experiments show that the proposed PMAD can outperform current state-of-the-art models significantly under the multi- and especially cross-class settings. Code will be publicly available at https://github.com/xcyao00/PMAD.","https://ojs.aaai.org/index.php/AAAI/article/view/25604/25376"
"25605","Analogical Inference Enhanced Knowledge Graph Embedding","['Zhen Yao', 'Wen Zhang', 'Mingyang Chen', 'Yufeng Huang', 'Yi Yang', 'Huajun Chen']","['School of Software Technology, Zhejiang University', 'School of Software Technology, Zhejiang University', 'College of Computer Science and Technology, Zhejiang University', 'School of Software Technology, Zhejiang University', 'HUAWEI TECHNOLOGIES CO., LTD.', 'College of Computer Science and Technology, Zhejiang University\nDonghai Laboratory, Zhoushan 316021, China\nAlibaba-Zhejiang University Joint Institute of Frontier Technologies']","['DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion', 'DMKM: Semantic Web']","Yao, Z., Zhang, W., Chen, M., Huang, Y., Yang, Y., & Chen, H. (2023). Analogical Inference Enhanced Knowledge Graph Embedding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4801-4808. https://doi.org/10.1609/aaai.v37i4.25605","Abstract 					Knowledge graph embedding (KGE), which maps entities and relations in a knowledge graph into continuous vector spaces, has achieved great success in predicting missing links in knowledge graphs. However, knowledge graphs often contain incomplete triples that are difficult to inductively infer by KGEs. To address this challenge, we resort to analogical inference and propose a novel and general self-supervised framework AnKGE to enhance KGE models with analogical inference capability. We propose an analogical object retriever that retrieves appropriate analogical objects from entity-level, relation-level, and triple-level. And in AnKGE, we train an analogy function for each level of analogical inference with the original element embedding from a well-trained KGE model as input, which outputs the analogical object embedding. In order to combine inductive inference capability from the original KGE model and analogical inference capability enhanced by AnKGE, we interpolate the analogy score with the base model score and introduce the adaptive weights in the score function for prediction. Through extensive experiments on FB15k-237 and WN18RR datasets, we show that AnKGE achieves competitive results on link prediction task and well performs analogical inference.","https://ojs.aaai.org/index.php/AAAI/article/view/25605/25377"
"25606","A Noise-Tolerant Differentiable Learning Approach for Single Occurrence Regular Expression with Interleaving","['Rongzhen Ye', 'Tianqu Zhuang', 'Hai Wan', 'Jianfeng Du', 'Weilin Luo', 'Pingjia Liang']","['School of Computer Science and Engineering, Sun Yat-sen University', 'School of Computer Science and Engineering, Sun Yat-sen University', 'School of Computer Science and Engineering, Sun Yat-sen University', 'Guangzhou Key Laboratory of Multilingual Intelligent Processing, Guangdong University of Foreign Studies', 'School of Computer Science and Engineering, Sun Yat-sen University', 'School of Computer Science and Engineering, Sun Yat-sen University']","['DMKM: Rule Mining & Pattern Mining']","Ye, R., Zhuang, T., Wan, H., Du, J., Luo, W., & Liang, P. (2023). A Noise-Tolerant Differentiable Learning Approach for Single Occurrence Regular Expression with Interleaving. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4809-4817. https://doi.org/10.1609/aaai.v37i4.25606","Abstract 					We study the problem of learning a single occurrence regular expression with interleaving (SOIRE) from a set of text strings possibly with noise. SOIRE fully supports interleaving and covers a large portion of regular expressions used in practice. Learning SOIREs is challenging because it requires heavy computation and text strings usually contain noise in practice. Most of the previous studies only learn restricted SOIREs and are not robust on noisy data. To tackle these issues, we propose a noise-tolerant differentiable learning approach SOIREDL for SOIRE. We design a neural network to simulate SOIRE matching and theoretically prove that certain assignments of the set of parameters learnt by the neural network, called faithful encodings, are one-to-one corresponding to SOIREs for a bounded size. Based on this correspondence, we interpret the target SOIRE from an assignment of the set of parameters of the neural network by exploring the nearest faithful encodings. Experimental results show that SOIREDL outperforms the state-of-the-art approaches, especially on noisy data.","https://ojs.aaai.org/index.php/AAAI/article/view/25606/25378"
"25607","Learning from the Wisdom of Crowds: Exploiting Similar Sessions for Session Search","['Yuhang Ye', 'Zhonghua Li', 'Zhicheng Dou', 'Yutao Zhu', 'Changwang Zhang', 'Shangquan Wu', 'Zhao Cao']","['Huawei Poisson Lab', 'Huawei Poisson Lab', 'Renmin University of China', 'University of Montreal', 'Huawei Poisson Lab', 'Huawei Poisson Lab', 'Huawei Poisson Lab']","['DMKM: Web Search & Information Retrieval', 'ML: Deep Neural Architectures', 'ML: Learning Preferences or Rankings']","Ye, Y., Li, Z., Dou, Z., Zhu, Y., Zhang, C., Wu, S., & Cao, Z. (2023). Learning from the Wisdom of Crowds: Exploiting Similar Sessions for Session Search. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4818-4826. https://doi.org/10.1609/aaai.v37i4.25607","Abstract 					Search engines are essential internet services, enabling users to efficiently find the information they need. Session search employs users’ session logs of queries to solve complex retrieval tasks, in which users search multiple times until interested documents are found. Most existing session search models focus on the contextual information within the current search, ignoring the evidence from historical search sessions. Considering the fact that many ongoing retrieval tasks should have already been carried out by other users with a similar intent, we argue that historical sessions with similar intents can help improve the accuracy of the current search task. We propose a novel Similar Session-enhanced Ranking (SSR) model to improve the session search performance using historical sessions with similar intents. Specifically, the candidate historical sessions are matched by query-level and session-level semantic similarity, and then query-level neighbor behaviors are aggregated by a Query-guided GNN (QGNN) while session-level neighbor behaviors are aggregated using the attention mechanism. Finally, we integrate the refined and aggregated historical neighbor information into the current search session. Experimental results on AOL and Tiangong-ST datasets show that our SSR model significantly outperforms the state-of-the-art models.","https://ojs.aaai.org/index.php/AAAI/article/view/25607/25379"
"25608","Next POI Recommendation with Dynamic Graph and Explicit Dependency","['Feiyu Yin', 'Yong Liu', 'Zhiqi Shen', 'Lisi Chen', 'Shuo Shang', 'Peng Han']","['University of Electronic Science and Technology of China', 'Nanyang Technological University', 'Nanyang Technological University', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China\nSichuan Artificial Intelligence Research Institute, Yibin, China', 'University of Electronic Science and Technology of China']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data']","Yin, F., Liu, Y., Shen, Z., Chen, L., Shang, S., & Han, P. (2023). Next POI Recommendation with Dynamic Graph and Explicit Dependency. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4827-4834. https://doi.org/10.1609/aaai.v37i4.25608","Abstract 					Next Point-Of-Interest (POI) recommendation plays an important role in various location-based services. Its main objective is to predict the user's next interested POI based on her previous check-in information. Most existing methods directly use users' historical check-in trajectories to construct various graphs to assist sequential models to complete this task. However, as users' check-in data is extremely sparse, it is difficult to capture the potential relations between POIs by directly using these check-in data. To this end, we propose the Sequence-based Neighbour search and Prediction Model (SNPM) for next POI recommendation. In SNPM, the RotatE knowledge graph embedding and Eigenmap methods are used to extract POI relationships implied in check-in data, and build the POI similarity graph. Then, we enhance the model's generalized representations of POIs' general features by aggregating similar POIs. As the context is typically rich and valuable when making Next POI predictions, the sequence model selects which POIs to aggregate not only depends on the current state, but also needs to consider the previous POI sequence. Therefore, we construct a Sequence-based, Dynamic Neighbor Graph (SDNG) to find the similarity neighbourhood and develop a Multi-Step Dependency Prediction model (MSDP) inspired by RotatE, which explicitly leverage information from previous states. We evaluate the proposed model on two real-world datasets, and the experimental results show that the proposed method significantly outperforms existing state-of-the-art POI recommendation methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25608/25380"
"25609","Predicting Temporal Sets with Simplified Fully Connected Networks","['Le Yu', 'Zihang Liu', 'Tongyu Zhu', 'Leilei Sun', 'Bowen Du', 'Weifeng Lv']","['Beihang University', 'Beihang University', 'Beihang University', 'Beihang University', 'Beihang University', 'Beihang University']","['DMKM: Web Personalization & User Modeling', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data']","Yu, L., Liu, Z., Zhu, T., Sun, L., Du, B., & Lv, W. (2023). Predicting Temporal Sets with Simplified Fully Connected Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4835-4844. https://doi.org/10.1609/aaai.v37i4.25609","Abstract 					Given a sequence of sets, where each set contains an arbitrary number of elements, temporal sets prediction aims to predict which elements will appear in the subsequent set. Existing methods for temporal sets prediction are developed on sophisticated components (e.g., recurrent neural networks, attention or gating mechanisms, and graph neural networks), which inevitably increase the model complexity due to more trainable parameters and higher computational costs. Moreover, the involved nonlinear activation may contribute little or even degrade the performance. In this paper, we present a succinct architecture that is solely built on the Simplified Fully Connected Networks (SFCNs) for temporal sets prediction to bring both effectiveness and efficiency together. In particular, given a user's sequence of sets, we employ SFCNs to derive representations of the user by learning inter-set temporal dependencies, intra-set element relationships, and intra-embedding channel correlations. Two families of general functions are introduced to preserve the permutation-invariant property of each set and the permutation-equivariant property of elements in each set. Moreover, we design a user representations adaptive fusing module to aggregate user representations according to each element for improving the prediction performance. Experiments on four benchmarks show the superiority of our approach over the state-of-the-art under both transductive and inductive settings. We also theoretically and empirically demonstrate that our model has lower space and time complexity than baselines. Codes and datasets are available at https://github.com/yule-BUAA/SFCNTSP.","https://ojs.aaai.org/index.php/AAAI/article/view/25609/25381"
"25610","Learning to Count Isomorphisms with Graph Neural Networks","['Xingtong Yu', 'Zemin Liu', 'Yuan Fang', 'Xinming Zhang']","['University of Science and Technology of China', 'National University of Singapore', 'Singapore Management University', 'University of Science and Technology of China']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Graph-based Machine Learning']","Yu, X., Liu, Z., Fang, Y., & Zhang, X. (2023). Learning to Count Isomorphisms with Graph Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4845-4853. https://doi.org/10.1609/aaai.v37i4.25610","Abstract 					Subgraph isomorphism counting is an important problem on graphs, as many graph-based tasks exploit recurring subgraph patterns. Classical methods usually boil down to a backtracking framework that needs to navigate a huge search space with prohibitive computational cost. Some recent studies resort to graph neural networks (GNNs) to learn a low-dimensional representation for both the query and input graphs, in order to predict the number of subgraph isomorphisms on the input graph. However, typical GNNs employ a node-centric message passing scheme that receives and aggregates messages on nodes, which is inadequate in complex structure matching for isomorphism counting. Moreover, on an input graph, the space of possible query graphs is enormous, and different parts of the input graph will be triggered to match different queries. Thus, expecting a fixed representation of the input graph to match diversely structured query graphs is unrealistic. In this paper, we propose a novel GNN called Count-GNN for subgraph isomorphism counting, to deal with the above challenges. At the edge level, given that an edge is an atomic unit of encoding graph structures, we propose an edge-centric message passing scheme, where messages on edges are propagated and aggregated based on the edge adjacency to preserve fine-grained structural information. At the graph level, we modulate the input graph representation conditioned on the query, so that the input graph can be adapted to each query individually to improve their matching. Finally, we conduct extensive experiments on a number of benchmark datasets to demonstrate the superior performance of Count-GNN.","https://ojs.aaai.org/index.php/AAAI/article/view/25610/25382"
"25611","Untargeted Attack against Federated Recommendation Systems via Poisonous Item Embeddings and the Defense","['Yang Yu', 'Qi Liu', 'Likang Wu', 'Runlong Yu', 'Sanshi Lei Yu', 'Zaixi Zhang']","['University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence']","['DMKM: Recommender Systems', 'ML: Distributed Machine Learning & Federated Learning']","Yu, Y., Liu, Q., Wu, L., Yu, R., Yu, S. L., & Zhang, Z. (2023). Untargeted Attack against Federated Recommendation Systems via Poisonous Item Embeddings and the Defense. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4854-4863. https://doi.org/10.1609/aaai.v37i4.25611","Abstract 					Federated recommendation (FedRec) can train personalized recommenders without collecting user data, but the decentralized nature makes it susceptible to poisoning attacks. Most previous studies focus on the targeted attack to promote certain items, while the untargeted attack that aims to degrade the overall performance of the FedRec system remains less explored. In fact, untargeted attacks can disrupt the user experience and bring severe ﬁnancial loss to the service provider. However, existing untargeted attack methods are either inapplicable or ineffective against FedRec systems. In this paper, we delve into the untargeted attack and its defense for FedRec systems. (i) We propose ClusterAttack, a novel untargeted attack method. It uploads poisonous gradients that converge the item embeddings into several dense clusters, which make the recommender generate similar scores for these items in the same cluster and perturb the ranking order. (ii) We propose a uniformity-based defense mechanism (UNION) to protect FedRec systems from such attacks. We design a contrastive learning task that regularizes the item embeddings toward a uniform distribution. Then the server ﬁlters out these malicious gradients by estimating the uniformity of updated item embeddings. Experiments on two public datasets show that ClusterAttack can effectively degrade the performance of FedRec systems while circumventing many defense methods, and UNION can improve the resistance of the system against various untargeted attacks, including our ClusterAttack.","https://ojs.aaai.org/index.php/AAAI/article/view/25611/25383"
"25612","Practical Cross-System Shilling Attacks with Limited Access to Data","['Meifang Zeng', 'Ke Li', 'Bingchuan Jiang', 'Liujuan Cao', 'Hui Li']","['School of Informatics, Xiamen University', 'PLA Strategic Support Force Information Engineering University', 'PLA Strategic Support Force Information Engineering University', 'School of Informatics, Xiamen University', 'School of Informatics, Xiamen University']","['DMKM: Recommender Systems', 'APP: Security']","Zeng, M., Li, K., Jiang, B., Cao, L., & Li, H. (2023). Practical Cross-System Shilling Attacks with Limited Access to Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4864-4874. https://doi.org/10.1609/aaai.v37i4.25612","Abstract 					In shilling attacks, an adversarial party injects a few fake user profiles into a Recommender System (RS) so that the target item can be promoted or demoted. Although much effort has been devoted to developing shilling attack methods, we find that existing approaches are still far from practical. In this paper, we analyze the properties a practical shilling attack method should have and propose a new concept of Cross-system Attack. With the idea of Cross-system Attack, we design a Practical Cross-system Shilling Attack (PC-Attack) framework that requires little information about the victim RS model and the target RS data for conducting attacks. PC-Attack is trained to capture graph topology knowledge from public RS data in a self-supervised manner. Then, it is fine-tuned on a small portion of target data that is easy to access to construct fake profiles. Extensive experiments have demonstrated the superiority of PC-Attack over state-of-the-art baselines. Our implementation of PC-Attack is available at https://github.com/KDEGroup/PC-Attack.","https://ojs.aaai.org/index.php/AAAI/article/view/25612/25384"
"25613","Query-Aware Quantization for Maximum Inner Product Search","['Jin Zhang', 'Defu Lian', 'Haodi Zhang', 'Baoyun Wang', 'Enhong Chen']","['University of Science and Technology of China', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence, Hefei, China', 'Shenzhen University', 'Hisense', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence, Hefei, China']","['DMKM: Web Search & Information Retrieval', 'DMKM: Web Personalization & User Modeling']","Zhang, J., Lian, D., Zhang, H., Wang, B., & Chen, E. (2023). Query-Aware Quantization for Maximum Inner Product Search. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4875-4883. https://doi.org/10.1609/aaai.v37i4.25613","Abstract 					Maximum Inner Product Search (MIPS) plays an essential role in many applications ranging from information retrieval, recommender systems to natural language processing. However, exhaustive MIPS is often expensive and impractical when there are a large number of candidate items.  The state-of-the-art quantization method of approximated MIPS is product quantization with a score-aware loss, developed by assuming that queries are uniformly distributed in the unit sphere. However, in real-world datasets, the above assumption about queries does not necessarily hold.  To this end, we propose a quantization method based on the distribution of queries combined with sampled softmax. Further, we introduce a general framework encompassing the proposed method and multiple quantization methods, and we develop an effective optimization for the proposed general framework. The proposed method is evaluated on three real-world datasets. The experimental results show that it outperforms the state-of-the-art baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/25613/25385"
"25614","TOT：Topology-Aware Optimal Transport for Multimodal Hate Detection","['Linhao Zhang', 'Li Jin', 'Xian Sun', 'Guangluan Xu', 'Zequn Zhang', 'Xiaoyu Li', 'Nayu Liu', 'Qing Liu', 'Shiyao Yan']","['Aerospace Information Research Institute, Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences', 'Aerospace Information Research Institute, Chinese Academy of Sciences']","['DMKM: Mining of Visual', 'Multimedia & Multimodal Data', 'CMS: Affective Computing', 'CV: Language and Vision', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Multimodal Learning', 'SNLP: Speech and Multimodality']","Zhang, L., Jin, L., Sun, X., Xu, G., Zhang, Z., Li, X., Liu, N., Liu, Q., & Yan, S. (2023). TOT：Topology-Aware Optimal Transport for Multimodal Hate Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4884-4892. https://doi.org/10.1609/aaai.v37i4.25614","Abstract 					Multimodal hate detection, which aims to identify the harmful content online such as memes, is crucial for building a wholesome internet environment. Previous work has made enlightening exploration in detecting explicit hate remarks. However, most of their approaches neglect the analysis of implicit harm, which is particularly challenging as explicit text markers and demographic visual cues are often twisted or missing. The leveraged cross-modal attention mechanisms also suffer from the distributional modality gap and lack logical interpretability. To address these  semantic gap issues, we propose TOT: a topology-aware optimal transport framework to decipher the implicit harm in memes scenario, which formulates the cross-modal aligning problem as solutions for optimal transportation plans. Specifically, we leverage an optimal transport kernel method to capture complementary information from multiple modalities. The kernel embedding provides a non-linear transformation ability to reproduce a kernel Hilbert space (RKHS), which reflects significance for eliminating the distributional modality gap. Moreover, we perceive the topology information based on aligned representations to conduct bipartite graph path reasoning. The newly achieved state-of-the-art performance on two publicly available benchmark datasets, together with  further visual analysis, demonstrate the superiority of TOT in capturing implicit cross-modal alignment.","https://ojs.aaai.org/index.php/AAAI/article/view/25614/25386"
"25615","Cross-Domain Few-Shot Graph Classification with a Reinforced Task Coordinator","['Qiannan Zhang', 'Shichao Pei', 'Qiang Yang', 'Chuxu Zhang', 'Nitesh V. Chawla', 'Xiangliang Zhang']","['King Abdullah University of Science and Technology', 'University of Notre Dame', 'King Abdullah University of Science and Technology', 'Brandeis University', 'University of Notre Dame', 'University of Notre Dame']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Graph-based Machine Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Zhang, Q., Pei, S., Yang, Q., Zhang, C., Chawla, N. V., & Zhang, X. (2023). Cross-Domain Few-Shot Graph Classification with a Reinforced Task Coordinator. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4893-4901. https://doi.org/10.1609/aaai.v37i4.25615","Abstract 					Cross-domain graph few-shot learning attempts to address the prevalent data scarcity issue in graph mining problems. However, the utilization of cross-domain data induces another intractable domain shift issue which severely degrades the generalization ability of cross-domain graph few-shot learning models. The combat with the domain shift issue is hindered due to the coarse utilization of source domains and the ignorance of accessible prompts. To address these challenges, in this paper, we design a novel Cross-domain Task Coordinator to leverage a small set of labeled target domain data as prompt tasks, then model the association and discover the relevance between meta-tasks from the source domain and the prompt tasks. Based on the discovered relevance, our model achieves adaptive task selection and enables the optimization of a graph learner using the selected fine-grained meta-tasks. Extensive experiments conducted on molecular property prediction benchmarks validate the effectiveness of our proposed method by comparing it with state-of-the-art baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/25615/25387"
"25616","AutoSTL: Automated Spatio-Temporal Multi-Task Learning","['Zijian Zhang', 'Xiangyu Zhao', 'Hao Miao', 'Chunxu Zhang', 'Hongwei Zhao', 'Junbo Zhang']","['College of Computer Science and Technology, Jilin University, China\nSchool of Data Science, City University of Hong Kong, Hong Kong\nKey Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, China\nHong Kong Institute for Data Science, City University of Hong Kong, Hong Kong', 'School of Data Science, City University of Hong Kong, Hong Kong\nHong Kong Institute for Data Science, City University of Hong Kong, Hong Kong', 'Department of Computer Science, Aalborg University, Denmark', 'College of Computer Science and Technology, Jilin University, China\nKey Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, China', 'College of Computer Science and Technology, Jilin University, China\nKey Laboratory of Symbolic Computation and Knowledge Engineering of Ministry of Education, Jilin University, China', 'JD Intelligent Cities Research, China\nJD iCity, JD Technology, China']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'ML: Auto ML and Hyperparameter Tuning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Zhang, Z., Zhao, X., Miao, H., Zhang, C., Zhao, H., & Zhang, J. (2023). AutoSTL: Automated Spatio-Temporal Multi-Task Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4902-4910. https://doi.org/10.1609/aaai.v37i4.25616","Abstract 					Spatio-temporal prediction plays a critical role in smart city construction. Jointly modeling multiple spatio-temporal tasks can further promote an intelligent city life by integrating their inseparable relationship. However, existing studies fail to address this joint learning problem well, which generally solve tasks individually or a fixed task combination. The challenges lie in the tangled relation between different properties, the demand for supporting flexible combinations of tasks and the complex spatio-temporal dependency. To cope with the problems above, we propose an Automated Spatio-Temporal multi-task Learning (AutoSTL) method to handle multiple spatio-temporal tasks jointly. Firstly, we propose a scalable architecture consisting of advanced spatio-temporal operations to exploit the complicated dependency. Shared modules and feature fusion mechanism are incorporated to further capture the intrinsic relationship between tasks. Furthermore, our model automatically allocates the operations and fusion weight. Extensive experiments on benchmark datasets verified that our model achieves state-of-the-art performance. As we can know, AutoSTL is the first automated spatio-temporal multi-task learning method.","https://ojs.aaai.org/index.php/AAAI/article/view/25616/25388"
"25617","Fair Representation Learning for Recommendation: A Mutual Information Perspective","['Chen Zhao', 'Le Wu', 'Pengyang Shao', 'Kun Zhang', 'Richang Hong', 'Meng Wang']","['Hefei University of Technology', 'Hefei University of Technology\nHefei Comprehensive National Science Center', 'Hefei University of Technology', 'Hefei University of Technology', 'Hefei University of Technology\nHefei Comprehensive National Science Center', 'Hefei University of Technology\nHefei Comprehensive National Science Center']","['DMKM: Recommender Systems', 'DMKM: Web Personalization & User Modeling']","Zhao, C., Wu, L., Shao, P., Zhang, K., Hong, R., & Wang, M. (2023). Fair Representation Learning for Recommendation: A Mutual Information Perspective. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4911-4919. https://doi.org/10.1609/aaai.v37i4.25617","Abstract 					Recommender systems have been widely used in recent years. By exploiting historical user-item interactions, recommender systems can model personalized potential interests of users and have been widely applied to a wide range of scenarios. Despite their impressive performance, most of them may be subject to unwanted biases related to sensitive attributes (e.g., race and gender), leading to unfairness. An intuitive idea to alleviate this problem is to ensure that there is no mutual information between recommendation results and sensitive attributes. However, keeping independence conditions solely achieves fairness improvement while causing an obvious degradation of recommendation accuracy, which is not a desired result. To this end, in this paper, we re-define recommendation fairness with a novel two-fold mutual information objective. In concerned details, we define fairness as mutual information minimization between embeddings and sensitive information, and mutual information maximization between embeddings and non-sensitive information. Then, a flexible Fair Mutual Information (FairMI) framework is designed to achieve this goal. FairMI first employs a sensitive attribute encoder to capture sensitive information in the data. Then, based on results from the sensitive attribute encoder, an interest encoder is developed to generate sensitive-free embeddings, which are expected to contain rich non-sensitive information of input data. Moreover, we propose novel mutual information (upper/lower) bounds with contrastive information estimation for model optimization. Extensive experiments over two real-world datasets demonstrate the effectiveness of our proposed FairMI in reducing unfairness and improving recommendation accuracy simultaneously.","https://ojs.aaai.org/index.php/AAAI/article/view/25617/25389"
"25618","Deep Graph Structural Infomax","['Wenting Zhao', 'Gongping Xu', 'Zhen Cui', 'Siqiang Luo', 'Cheng Long', 'Tong Zhang']","['Nanjing University of Science and Technology, Nanjing, China.', 'Nanjing University of Science and Technology, Nanjing, China.', 'Nanjing University of Science and Technology, Nanjing, China.', 'Nanyang Technological University, Singapore.', 'Nanyang Technological University, Singapore.', 'Nanjing University of Science and Technology, Nanjing, China.']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Classification and Regression', 'ML: Graph-based Machine Learning']","Zhao, W., Xu, G., Cui, Z., Luo, S., Long, C., & Zhang, T. (2023). Deep Graph Structural Infomax. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4920-4928. https://doi.org/10.1609/aaai.v37i4.25618","Abstract 					In the scene of self-supervised graph learning, Mutual Information (MI) was recently introduced for graph encoding to generate robust node embeddings. A successful representative is Deep Graph Infomax (DGI), which essentially operates on the space of node features but ignores topological structures, and just considers global graph summary. In this paper, we present an effective model called Deep Graph Structural Infomax (DGSI) to learn node representation. We explore to derive the structural mutual information from the perspective of Information Bottleneck (IB), which defines a trade-off between the sufficiency and minimality of representation on the condition of the topological structure preservation. Intuitively, the derived constraints formally maximize the structural mutual information both edge-wise and local neighborhood-wise. Besides, we develop a general framework that incorporates the global representational mutual information, local representational mutual information, and sufficient structural information into the node representation. Essentially, our DGSI extends DGI and could capture more fine-grained semantic information as well as beneficial structural information in a self-supervised manner, thereby improving node representation and further boosting the learning performance. Extensive experiments on different types of datasets demonstrate the effectiveness and superiority of the proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/25618/25390"
"25619","Causal Conditional Hidden Markov Model for Multimodal Traffic Prediction","['Yu Zhao', 'Pan Deng', 'Junting Liu', 'Xiaofeng Jia', 'Mulan Wang']","['Beihang University, Beijing, 100191, China', 'Beihang University, Beijing, 100191, China', 'Beihang University, Beijing, 100191, China', 'Beijing Big Data Centre, Beijing, 100024, China', 'Beihang University, Beijing, 100191, China']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'APP: Transportation', 'KRR: Action', 'Change', 'and Causality']","Zhao, Y., Deng, P., Liu, J., Jia, X., & Wang, M. (2023). Causal Conditional Hidden Markov Model for Multimodal Traffic Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4929-4936. https://doi.org/10.1609/aaai.v37i4.25619","Abstract 					Multimodal traffic flow can reflect the health of the transportation system, and its prediction is crucial to urban traffic management. Recent works overemphasize spatio-temporal correlations of traffic flow, ignoring the physical concepts that lead to the generation of observations and their causal relationship. Spatio-temporal correlations are considered unstable under the influence of different conditions, and spurious correlations may exist in observations. In this paper, we analyze the physical concepts affecting the generation of multimode traffic flow from the perspective of the observation generation principle and propose a Causal Conditional Hidden Markov Model (CCHMM) to predict multimodal traffic flow. In the latent variables inference stage, a posterior network disentangles the causal representations of the concepts of interest from conditional information and observations, and a causal propagation module mines their causal relationship. In the data generation stage, a prior network samples the causal latent variables from the prior distribution and feeds them into the generator to generate multimodal traffic flow. We use a mutually supervised training method for the prior and posterior to enhance the identifiability of the model. Experiments on real-world datasets show that CCHMM can effectively disentangle causal representations of concepts of interest and identify causality, and accurately predict multimodal traffic flow.","https://ojs.aaai.org/index.php/AAAI/article/view/25619/25391"
"25620","ADMoE: Anomaly Detection with Mixture-of-Experts from Noisy Labels","['Yue Zhao', 'Guoqing Zheng', 'Subhabrata Mukherjee', 'Robert McCann', 'Ahmed Awadallah']","['Carnegie Mellon University', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft']","['DMKM: Anomaly/Outlier Detection', 'ML: Applications']","Zhao, Y., Zheng, G., Mukherjee, S., McCann, R., & Awadallah, A. (2023). ADMoE: Anomaly Detection with Mixture-of-Experts from Noisy Labels. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4937-4945. https://doi.org/10.1609/aaai.v37i4.25620","Abstract 					Existing works on anomaly detection (AD) rely on clean labels from human annotators that are expensive to acquire in practice.  In this work, we propose a method to leverage weak/noisy labels (e.g., risk scores generated by machine rules for detecting malware) that are cheaper to obtain for anomaly detection. Specifically, we propose ADMoE, the first framework for anomaly detection algorithms to learn from noisy labels. In a nutshell, ADMoE leverages mixture-of-experts (MoE) architecture to encourage specialized and scalable learning from multiple noisy sources. It captures the similarities among noisy labels by sharing most model parameters, while encouraging specialization by building ""expert"" sub-networks. To further juice out the signals from noisy labels, ADMoE uses them as input features to facilitate expert learning. Extensive results on eight datasets (including a proprietary enterprise security dataset) demonstrate the effectiveness of ADMoE, where it brings up to 34% performance improvement over not using it. Also, it outperforms a total of 13 leading baselines with equivalent network parameters and FLOPS. Notably, ADMoE is model-agnostic to enable any neural network-based detection methods to handle noisy labels, where we showcase its results on both multiple-layer perceptron (MLP) and the leading AD method DeepSAD.","https://ojs.aaai.org/index.php/AAAI/article/view/25620/25392"
"25621","A Provable Framework of Learning Graph Embeddings via Summarization","['Houquan Zhou', 'Shenghua Liu', 'Danai Koutra', 'Huawei Shen', 'Xueqi Cheng']","['Institute of Computing Technology, Chinese Academy of Science', 'Institute of Computing Technology, CAS, China', 'U Michigan', 'Institute of Computing Technology, Chinese Academy of Sciences', 'Institute of Computing Technology, Chinese Academy of Sciences']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'DMKM: Data Visualization & Summarization', 'ML: Graph-based Machine Learning', 'ML: Representation Learning']","Zhou, H., Liu, S., Koutra, D., Shen, H., & Cheng, X. (2023). A Provable Framework of Learning Graph Embeddings via Summarization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4946-4953. https://doi.org/10.1609/aaai.v37i4.25621","Abstract 					Given a large graph, can we learn its node embeddings from a smaller summary graph? What is the relationship between embeddings learned from original graphs and their summary graphs? Graph representation learning plays an important role in many graph mining applications, but learning em-beddings of large-scale graphs remains a challenge. Recent works try to alleviate it via graph summarization, which typ-ically includes the three steps: reducing the graph size by combining nodes and edges into supernodes and superedges,learning the supernode embedding on the summary graph and then restoring the embeddings of the original nodes. How-ever, the justification behind those steps is still unknown. In this work, we propose GELSUMM, a well-formulated graph embedding learning framework based on graph sum-marization, in which we show the theoretical ground of learn-ing from summary graphs and the restoration with the three well-known graph embedding approaches in a closed form.Through extensive experiments on real-world datasets, we demonstrate that our methods can learn graph embeddings with matching or better performance on downstream tasks.This work provides theoretical analysis for learning node em-beddings via summarization and helps explain and under-stand the mechanism of the existing works.","https://ojs.aaai.org/index.php/AAAI/article/view/25621/25393"
"25622","GraphSR: A Data Augmentation Algorithm for Imbalanced Node Classification","['Mengting Zhou', 'Zhiguo Gong']","['State Key Laboratory of Internet of Things for Smart City, University of Macau, Macao\nGuangdong-Macau Joint Laboratory for Advanced and Intelligent Computing', 'State Key Laboratory of Internet of Things for Smart City, University of Macau, Macao\nGuangdong-Macau Joint Laboratory for Advanced and Intelligent Computing']","['DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Graph-based Machine Learning', 'ML: Representation Learning']","Zhou, M., & Gong, Z. (2023). GraphSR: A Data Augmentation Algorithm for Imbalanced Node Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4954-4962. https://doi.org/10.1609/aaai.v37i4.25622","Abstract 					Graph neural networks (GNNs) have achieved great success in node classification tasks. However, existing GNNs naturally bias towards the majority classes with more labelled data and ignore those minority classes with relatively few labelled ones. The traditional techniques often resort over-sampling methods, but they may cause overfitting problem. More recently, some works propose to synthesize additional nodes for minority classes from the labelled nodes, however, there is no any guarantee if those generated nodes really stand for the the corresponding minority classes.  In fact, improperly synthesized nodes may result in insufficient generalization of the algorithm. To resolve the problem, in this paper we seek to automatically augment the minority classes from the massive unlabelled nodes of the graph. Specifically, we propose \textit{GraphSR}, a novel self-training strategy to augment the minority classes with significant diversity of unlabelled nodes, which is based on a Similarity-based selection module and a Reinforcement Learning(RL) selection module. The first module finds a subset of unlabelled nodes which are most similar to those labelled minority nodes, and the second one further determines the representative and reliable nodes from the subset via RL technique.   Furthermore, the RL-based module can adaptively determine the sampling scale according to current training data. This strategy is general and can be easily combined with different GNNs models. Our experiments demonstrate the proposed approach outperforms the state-of-the-art baselines on various class-imbalanced datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25622/25394"
"25623","Detecting Multivariate Time Series Anomalies with Zero Known Label","['Qihang Zhou', 'Jiming Chen', 'Haoyu Liu', 'Shibo He', 'Wenchao Meng']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University\nNetEase Fuxi AI Lab, Hangzhou, China', 'Zhejiang University\nKey Laboratory of Collaborative Sensing and Autonomous Unmanned Systems of Zhejiang Province, Hangzhou, China', 'Zhejiang University']","['DMKM: Anomaly/Outlier Detection', 'DMKM: Applications']","Zhou, Q., Chen, J., Liu, H., He, S., & Meng, W. (2023). Detecting Multivariate Time Series Anomalies with Zero Known Label. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4963-4971. https://doi.org/10.1609/aaai.v37i4.25623","Abstract 					Multivariate time series anomaly detection has been extensively studied under the one-class classification setting, where a training dataset with all normal instances is required. However, preparing such a dataset is very laborious since each single data instance should be fully guaranteed to be normal. It is, therefore, desired to explore multivariate time series anomaly detection methods based on the dataset without any label knowledge. In this paper, we propose MTGFlow, an unsupervised anomaly detection approach forMultivariate Time series anomaly detection via dynamic Graph and entityaware normalizing Flow, leaning only on a widely accepted hypothesis that abnormal instances exhibit sparse densities than the normal. However, the complex interdependencies among entities and the diverse inherent characteristics of each entity pose significant challenges to density estimation, let alone to detect anomalies based on the estimated possibility distribution. To tackle these problems, we propose to learn the mutual and dynamic relations among entities via a graph structure learning model, which helps to model the accurate distribution of multivariate time series. Moreover, taking account of distinct characteristics of the individual entities, an entity-aware normalizing flow is developed to describe each entity into a parameterized normal distribution, thereby producing fine-grained density estimation. Incorporating these two strategies, MTGFlow achieves superior anomaly detection performance. Experiments on five public datasets with seven baselines are conducted, MTGFlow outperforms the SOTA methods by up to 5.0 AUROC%.","https://ojs.aaai.org/index.php/AAAI/article/view/25623/25395"
"25624","GRLSTM: Trajectory Similarity Computation with Graph-Based Residual LSTM","['Silin Zhou', 'Jing Li', 'Hao Wang', 'Shuo Shang', 'Peng Han']","['University of Electronic Science and Technology of China', 'Harbin Institute of Technology, Shenzhen, China', 'Wuhan University, China', 'University of Electronic Science and Technology of China\nSichuan Artificial Intelligence Research Institute, Yibin, 644000, China', 'University of Electronic Science and Technology of China']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data']","Zhou, S., Li, J., Wang, H., Shang, S., & Han, P. (2023). GRLSTM: Trajectory Similarity Computation with Graph-Based Residual LSTM. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4972-4980. https://doi.org/10.1609/aaai.v37i4.25624","Abstract 					The computation of trajectory similarity is a crucial task in many spatial data analysis applications. However, existing methods have been designed primarily for trajectories in Euclidean space, which overlooks the fact that real-world trajectories are often generated on road networks. This paper addresses this gap by proposing a novel framework, called GRLSTM (Graph-based Residual LSTM). To jointly capture the properties of trajectories and road networks, the proposed framework incorporates knowledge graph embedding (KGE), graph neural network (GNN), and the residual network into the multi-layer LSTM (Residual-LSTM). Specifically, the framework constructs a point knowledge graph to study the multi-relation of points, as points may belong to both the trajectory and the road network. KGE is introduced to learn point embeddings and relation embeddings to build the point fusion graph, while GNN is used to capture the topology structure information of the point fusion graph. Finally, Residual-LSTM is used to learn the trajectory embeddings.To further enhance the accuracy and robustness of the final trajectory embeddings, we introduce two new neighbor-based point loss functions, namely, graph-based point loss function and trajectory-based point loss function. The GRLSTM is evaluated using two real-world trajectory datasets, and the experimental results demonstrate that GRLSTM outperforms all the state-of-the-art methods significantly.","https://ojs.aaai.org/index.php/AAAI/article/view/25624/25396"
"25625","Heterogeneous Region Embedding with Prompt Learning","['Silin Zhou', 'Dan He', 'Lisi Chen', 'Shuo Shang', 'Peng Han']","['University of Electronic Science and Technology of China', 'The University of Queensland, Australia', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China']","['DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data']","Zhou, S., He, D., Chen, L., Shang, S., & Han, P. (2023). Heterogeneous Region Embedding with Prompt Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4981-4989. https://doi.org/10.1609/aaai.v37i4.25625","Abstract 					The prevalence of region-based urban data has opened new possibilities for exploring correlations among regions to improve urban planning and smart-city solutions. Region embedding, which plays a critical role in this endeavor, faces significant challenges related to the varying nature of city data and the effectiveness of downstream applications. In this paper, we propose a novel framework, HREP (Heterogeneous Region Embedding with Prompt learning), which addresses both intra-region and inter-region correlations through two key modules: Heterogeneous Region Embedding (HRE) and prompt learning for different downstream tasks. The HRE module constructs a heterogeneous region graph based on three categories of data, capturing inter-region contexts such as human mobility and geographic neighbors, and intraregion contexts such as POI (Point-of-Interest) information. We use relation-aware graph embedding to learn region and relation embeddings of edge types, and introduce selfattention to capture global correlations among regions. Additionally, we develop an attention-based fusion module to integrate shared information among different types of correlations. To enhance the effectiveness of region embedding in downstream tasks, we incorporate prompt learning, specifically prefix-tuning, which guides the learning of downstream tasks and results in better prediction performance. Our experiment results on real-world datasets demonstrate that our proposed model outperforms state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25625/25397"
"25626","Show Me the Way! Bilevel Search for Synthesizing Programmatic Strategies","['David S. Aleixo', 'Levi H.S. Lelis']","['Universidade Federal de Viçosa', 'University of Alberta']","['APP: Games', 'SO: Local Search', 'MAS: Adversarial Agents']","Aleixo, D. S., & Lelis, L. H. (2023). Show Me the Way! Bilevel Search for Synthesizing Programmatic Strategies. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4991-4998. https://doi.org/10.1609/aaai.v37i4.25626","Abstract 					The synthesis of programmatic strategies requires one to search in large non-differentiable spaces of computer programs. Current search algorithms use self-play approaches to guide this search. The issue with these approaches is that the guiding function often provides a weak search signal. This is because self-play functions only measure how well a program performs against other programs. Thus, while small changes to a losing program might not transform it into a winning one, such changes might represent steps in the direction of a winning program. In this paper we introduce a bilevel search algorithm that searches concurrently in the space of programs and in a space of state features. Each iteration of the search in the space of features defines a set of target features that the search in the program space attempts to achieve (i.e., features one observes while following the strategy encoded in a program). We hypothesize the combination of a self-play function and a feature-based one provides a stronger search signal for synthesis. While both functions are used to guide the search in the program space, the self-play function is used to guide the search in the feature space, to allow for the selection of target features that are more likely to lead to winning programs. We evaluated our bilevel algorithm in MicroRTS, a real-time strategy game. Our results show that the bilevel search synthesizes stronger strategies than methods that search only in the program space. Also, the strategies our method synthesizes obtained the highest winning rate in a simulated tournament with several baseline agents, including the best agents from the two latest MicroRTS competitions.","https://ojs.aaai.org/index.php/AAAI/article/view/25626/25398"
"25627","Anytime User Engagement Prediction in Information Cascades for Arbitrary Observation Periods","['Akshay Aravamudan', 'Xi Zhang', 'Georgios C. Anagnostopoulos']","['Florida Institute of Technology', 'Florida Institute of Technology', 'Florida Institute of Technology']","['APP: Social Networks', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'ML: Applications', 'ML: Probabilistic Methods', 'ML: Time-Series/Data Streams']","Aravamudan, A., Zhang, X., & Anagnostopoulos, G. C. (2023). Anytime User Engagement Prediction in Information Cascades for Arbitrary Observation Periods. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 4999-5009. https://doi.org/10.1609/aaai.v37i4.25627","Abstract 					Predicting user engagement -- whether a user will engage in a given information cascade -- is an important problem in the context of social media, as it is useful to online marketing and misinformation mitigation just to name a couple major applications. Based on split population multi-variate survival processes, we develop a discriminative approach that, unlike prior works, leads to a single model for predicting whether individual users of an information network will engage a given cascade for arbitrary forecast horizons and observation periods. Being probabilistic in nature, this model retains the interpretability of its generative counterpart and renders count prediction intervals in a disciplined manner. Our results indicate that our model is highly competitive, if not superior, to current approaches, when compared over varying observed cascade histories and forecast horizons.","https://ojs.aaai.org/index.php/AAAI/article/view/25627/25399"
"25628","Principled Data-Driven Decision Support for Cyber-Forensic Investigations","['Soodeh Atefi', 'Sakshyam Panda', 'Emmanouil Panaousis', 'Aron Laszka']","['University of Houston', 'University of Greenwich', 'University of Greenwich', 'Pennsylvania State University']","['APP: Security', 'RU: Sequential Decision Making', 'ML: Optimization', 'RU: Applications', 'ML: Applications']","Atefi, S., Panda, S., Panaousis, E., & Laszka, A. (2023). Principled Data-Driven Decision Support for Cyber-Forensic Investigations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5010-5017. https://doi.org/10.1609/aaai.v37i4.25628","Abstract 					In the wake of a cybersecurity incident, it is crucial to promptly discover how the threat actors breached security in order to assess the impact of the incident and to develop and deploy countermeasures that can protect against further attacks. To this end, defenders can launch a cyber-forensic investigation, which discovers the techniques that the threat actors used in the incident. A fundamental challenge in such an investigation is prioritizing the investigation of particular techniques since the investigation of each technique requires time and effort, but forensic analysts cannot know which ones were actually used before investigating them. To ensure prompt discovery, it is imperative to provide decision support that can help forensic analysts with this prioritization. A recent study demonstrated that data-driven decision support, based on a dataset of prior incidents, can provide state-of-the-art prioritization. However, this data-driven approach, called DISCLOSE, is based on a heuristic that utilizes only a subset of the available information and does not approximate optimal decisions. To improve upon this heuristic, we introduce a principled approach for data-driven decision support for cyber-forensic investigations. We formulate the decision-support problem using a Markov decision process, whose states represent the states of a forensic investigation. To solve the decision problem, we propose a Monte Carlo tree search based method, which relies on a k-NN regression over prior incidents to estimate state-transition probabilities. We evaluate our proposed approach on multiple versions of the MITRE ATT&CK dataset, which is a knowledge base of adversarial techniques and tactics based on real-world cyber incidents, and demonstrate that our approach outperforms DISCLOSE in terms of techniques discovered per effort spent.","https://ojs.aaai.org/index.php/AAAI/article/view/25628/25400"
"25629","BETA-CD: A Bayesian Meta-Learned Cognitive Diagnosis Framework for Personalized Learning","['Haoyang Bi', 'Enhong Chen', 'Weidong He', 'Han Wu', 'Weihao Zhao', 'Shijin Wang', 'Jinze Wu']","['University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'State Key Laboratory of Cognitive Intelligence\niFLYTEK AI Research, iFLYTEK CO., LTD.', 'iFLYTEK AI Research, iFLYTEK CO., LTD.']","['APP: Education', 'ML: Meta Learning']","Bi, H., Chen, E., He, W., Wu, H., Zhao, W., Wang, S., & Wu, J. (2023). BETA-CD: A Bayesian Meta-Learned Cognitive Diagnosis Framework for Personalized Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5018-5026. https://doi.org/10.1609/aaai.v37i4.25629","Abstract 					Personalized learning is a promising educational approach that aims to provide high-quality personalized services for each student with minimum demands for practice data. The key to achieving that lies in the cognitive diagnosis task, which estimates the cognitive state of the student through his/her logged data of doing practice quizzes. Nevertheless, in the personalized learning scenario, existing cognitive diagnosis models suffer from the inability to (1) quickly adapt to new students using a small amount of data, and (2) measure the reliability of the diagnosis result to avoid improper services that mismatch the student's actual state. In this paper, we propose a general Bayesian mETA-learned Cognitive Diagnosis framework (BETA-CD), which addresses the two challenges by prior knowledge exploitation and model uncertainty quantification, respectively. Specifically, we firstly introduce Bayesian hierarchical modeling to associate each student's cognitive state with a shared prior distribution encoding prior knowledge and a personal posterior distribution indicating model uncertainty. Furthermore, we formulate a meta-learning objective to automatically exploit prior knowledge from historical students, and efficiently solve it with a gradient-based variational inference method. The code will be publicly available at https://github.com/AyiStar/pyat.","https://ojs.aaai.org/index.php/AAAI/article/view/25629/25401"
"25630","Set-to-Sequence Ranking-Based Concept-Aware Learning Path Recommendation","['Xianyu Chen', 'Jian Shen', 'Wei Xia', 'Jiarui Jin', 'Yakun Song', 'Weinan Zhang', 'Weiwen Liu', 'Menghui Zhu', 'Ruiming Tang', 'Kai Dong', 'Dingyin Xia', 'Yong Yu']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', ""Huawei Noah's Ark Lab"", 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', ""Huawei Noah's Ark Lab"", 'Shanghai Jiao Tong University', ""Huawei Noah's Ark Lab"", 'Huawei', 'Huawei', 'Shanghai Jiao Tong University']","['APP: Education', 'DMKM: Recommender Systems']","Chen, X., Shen, J., Xia, W., Jin, J., Song, Y., Zhang, W., Liu, W., Zhu, M., Tang, R., Dong, K., Xia, D., & Yu, Y. (2023). Set-to-Sequence Ranking-Based Concept-Aware Learning Path Recommendation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5027-5035. https://doi.org/10.1609/aaai.v37i4.25630","Abstract 					With the development of the online education system, personalized education recommendation has played an essential role. In this paper, we focus on developing path recommendation systems that aim to generating and recommending an entire learning path to the given user in each session. Noticing that existing approaches fail to consider the correlations of concepts in the path, we propose a novel framework named Set-to-Sequence Ranking-based Concept-aware Learning Path Recommendation (SRC), which formulates the recommendation task under a set-to-sequence paradigm. Specifically, we first design a concept-aware encoder module which can capture the correlations among the input learning concepts. The outputs are then fed into a decoder module that sequentially generates a path through an attention mechanism that handles correlations between the learning and target concepts. Our recommendation policy is optimized by policy gradient. In addition, we also introduce an auxiliary module based on knowledge tracing to enhance the model’s stability by evaluating students’ learning effects on learning concepts. We conduct extensive experiments on two real-world public datasets and one industrial dataset, and the experimental results demonstrate the superiority and effectiveness of SRC. Code now is available at https://gitee.com/mindspore/models/tree/master/research/recommend/SRC.","https://ojs.aaai.org/index.php/AAAI/article/view/25630/25402"
"25631","Unsupervised Deep Embedded Fusion Representation of Single-Cell Transcriptomics","['Yue Cheng', 'Yanchi Su', 'Zhuohan Yu', 'Yanchun Liang', 'Ka-Chun Wong', 'Xiangtao Li']","['Jilin University', 'Jilin University', 'Jilin University', 'Zhuhai College of Science and Technology', 'City University of Hong Kong', 'Jilin University']","['APP: Bioinformatics']","Cheng, Y., Su, Y., Yu, Z., Liang, Y., Wong, K.-C., & Li, X. (2023). Unsupervised Deep Embedded Fusion Representation of Single-Cell Transcriptomics. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5036-5044. https://doi.org/10.1609/aaai.v37i4.25631","Abstract 					Cell clustering is a critical step in analyzing single-cell RNA sequencing (scRNA-seq) data, which allows us to characterize the cellular heterogeneity of transcriptional profiling at the single-cell level. Single-cell deep embedded representation models have recently become popular since they can learn feature representation and clustering simultaneously. However, the model still suffers from a variety of significant challenges, including the massive amount of data, pervasive dropout events, and complicated noise patterns in transcriptional profiling. Here, we propose a Single-Cell Deep Embedding Fusion Representation (scDEFR) model, which develop a deep embedded fusion representation to learn fused heterogeneous latent embedding that contains both the transcriptome gene-level information and the cell topology information. We first fuse them layer by layer to obtain compressed representations of intercellular relationships and transcriptome information. After that, the zero-inflated negative binomial model (ZINB)-based decoder is proposed to capture the global probabilistic structure of the data and reconstruct the final gene expression information and cell graph. Finally, by simultaneously integrating the clustering loss, crossentropy loss, ZINB loss, and the cell graph reconstruction loss, scDEFR can optimize clustering performance and learn the latent representation in fused information under a joint mutual supervised strategy. We conducted extensive and comprehensive experiments on 15 single-cell RNA-seq datasets from different sequencing platforms to demonstrate the superiority of scDEFR over a variety of state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25631/25403"
"25632","Constrained Submodular Optimization for Vaccine Design","['Zheng Dai', 'David K. Gifford']","['Massachusetts Institute of Technology', 'MIT CSAIL']","['APP: Bioinformatics', 'APP: Healthcare', 'Medicine & Wellness', 'CSO: Constraint Optimization']","Dai, Z., & Gifford, D. K. (2023). Constrained Submodular Optimization for Vaccine Design. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5045-5053. https://doi.org/10.1609/aaai.v37i4.25632","Abstract 					Advances in machine learning have enabled the prediction of immune system responses to prophylactic and therapeutic vaccines. However, the engineering task of designing vaccines remains a challenge. In particular, the genetic variability of the human immune system makes it difficult to design peptide vaccines that provide widespread immunity in vaccinated populations.  We introduce a framework for evaluating and designing peptide vaccines that uses probabilistic machine learning models, and demonstrate its ability to produce designs for a SARS-CoV-2 vaccine that outperform previous designs.  We provide a theoretical analysis of the approximability, scalability, and complexity of our framework.","https://ojs.aaai.org/index.php/AAAI/article/view/25632/25404"
"25633","Flow-Based Robust Watermarking with Invertible Noise Layer for Black-Box Distortions","['Han Fang', 'Yupeng Qiu', 'Kejiang Chen', 'Jiyi Zhang', 'Weiming Zhang', 'Ee-Chien Chang']","['National University of Singapore', 'National University of Singapore', 'University of Science and Technology of China', 'National University of Singapore', 'University of Science and Technology of China', 'National University of Singapore']","['APP: Security', 'ML: Applications']","Fang, H., Qiu, Y., Chen, K., Zhang, J., Zhang, W., & Chang, E.-C. (2023). Flow-Based Robust Watermarking with Invertible Noise Layer for Black-Box Distortions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5054-5061. https://doi.org/10.1609/aaai.v37i4.25633","Abstract 					Deep learning-based digital watermarking frameworks have been widely studied recently. Most existing methods adopt an ``encoder-noise layer-decoder''-based architecture where the embedding and extraction processes are accomplished separately by the encoder and the decoder. However, one potential drawback of such a framework is that the encoder and the decoder may not be well coupled, resulting in the fact that the encoder may embed some redundant features into the host image thus influencing the invisibility and robustness of the whole algorithm. To address this limitation, this paper proposes a flow-based robust watermarking framework. The basic component of such framework is an invertible up-down-sampling neural block that can realize the embedding and extraction simultaneously. As a consequence, the encoded feature could keep high consistency with the feature that the decoder needed, which effectively avoids the embedding of redundant features. In addition, to ensure the robustness of black-box distortion, an invertible noise layer (INL) is designed to simulate the distortion and is served as a noise layer in the training stage. Benefiting from its reversibility, INL is also applied as a preprocessing before extraction to eliminate the distortion, which further improves the robustness of the algorithm. Extensive experiments demonstrate the superiority of the proposed framework in terms of visual quality and robustness. Compared with the state-of-the-art architecture, the visual quality (measured by PSNR) of the proposed framework improves by 2dB and the extraction accuracy after JPEG compression (QF=50) improves by more than 4%. Besides, the robustness against black-box distortions can be greatly achieved with more than 95% extraction accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25633/25405"
"25634","Identifying and Eliminating Majority Illusion in Social Networks","['Umberto Grandi', 'Lawqueen Kanesh', 'Grzegorz Lisowski', 'Ramanujan Sridharan', 'Paolo Turrini']","['University of Toulouse, France', 'IIT Jodhpur, India', 'University of Warwick, UK', 'University of Warwick, UK', 'University of Warwick, UK']","['APP: Social Networks', 'GTEP: Social Choice / Voting', 'KRR: Computational Complexity of Reasoning']","Grandi, U., Kanesh, L., Lisowski, G., Sridharan, R., & Turrini, P. (2023). Identifying and Eliminating Majority Illusion in Social Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5062-5069. https://doi.org/10.1609/aaai.v37i4.25634","Abstract 					Majority illusion occurs in a social network when the majority of the network vertices belong to a certain type but the majority of each vertex's neighbours belong to a different type, therefore creating the wrong perception, i.e., the illusion, that the majority type is different from the actual one. From a system engineering point of view, this motivates the search for algorithms to detect and, where possible, correct this undesirable phenomenon. In this paper we initiate the computational study of majority illusion in social networks, providing NP-hardness and parametrised complexity results for its occurrence and elimination.","https://ojs.aaai.org/index.php/AAAI/article/view/25634/25406"
"25635","A Domain-Knowledge-Inspired Music Embedding Space and a Novel Attention Mechanism for Symbolic Music Modeling","['Zixun Guo', 'Jaeyong Kang', 'Dorien Herremans']","['Singapore University of Technology and Design', 'Singapore University of Technology and Design', 'Singapore University of Technology and Design']","['APP: Art/Music/Creativity', 'CMS: Computational Creativity']","Guo, Z., Kang, J., & Herremans, D. (2023). A Domain-Knowledge-Inspired Music Embedding Space and a Novel Attention Mechanism for Symbolic Music Modeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5070-5077. https://doi.org/10.1609/aaai.v37i4.25635","Abstract 					Following the success of the transformer architecture in the natural language domain, transformer-like architectures have been widely applied to the domain of symbolic music recently. Symbolic music and text, however, are two different modalities. Symbolic music contains multiple attributes, both absolute attributes (e.g., pitch) and relative attributes (e.g., pitch interval). These relative attributes shape human perception of musical motifs. These important relative attributes, however, are mostly ignored in existing symbolic music modelling methods with the main reason being the lack of a musically-meaningful embedding space where both the absolute and relative embeddings of the symbolic music tokens can be efficiently represented. In this paper, we propose the Fundamental Music Embedding (FME) for symbolic music based on a bias-adjusted sinusoidal encoding within which both the absolute and the relative attributes can be embedded and the fundamental musical properties (e.g., translational invariance) are explicitly preserved. Taking advantage of the proposed FME, we further propose a novel attention mechanism based on the relative index, pitch and onset embeddings (RIPO attention) such that the musical domain knowledge can be fully utilized for symbolic music modelling. Experiment results show that our proposed model: RIPO transformer which utilizes FME and RIPO attention outperforms the state-of-the-art transformers (i.e., music transformer, linear transformer) in a melody completion task. Moreover, using the RIPO transformer in a downstream music generation task, we notice that the notorious degeneration phenomenon no longer exists and the music generated by the RIPO transformer outperforms the music generated by state-of-the-art transformer models in both subjective and objective evaluations. The code of the proposed method is available online: github.com/guozixunnicolas/FundamentalMusicEmbedding.","https://ojs.aaai.org/index.php/AAAI/article/view/25635/25407"
"25636","MSDC: Exploiting Multi-State Power Consumption in Non-intrusive Load Monitoring Based on a Dual-CNN Model","['Jialing He', 'Jiamou Liu', 'Zijian Zhang', 'Yang Chen', 'Yiwei Liu', 'Bakh Khoussainov', 'Liehuang Zhu']","['College of Computer Science, Chongqing University, Chongqing, China, 400044.\nSchool of Cyberspace Science and Technology, Beijing Institute of Technology, Beijing, China, 100081.', 'School of Computer Science, The University of Auckland, Auckland 1142, New Zealand.', 'School of Cyberspace Science and Technology, Beijing Institute of Technology, Beijing, China, 100081.\nSoutheast Institute of Information Technology, Beijing Institute of Technology, Fujian China, 351100.', 'Strong AI Lab, The University of Auckland, Auckland 1142, New Zealand.', 'Defence Industry Secrecy Examination and Certification Center, Beijing, China, 100089.', 'School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China, 611731.', 'School of Cyberspace Science and Technology, Beijing Institute of Technology, Beijing, China, 100081.']","['APP: Energy', 'Environment & Sustainability', 'DMKM: Data Stream Mining', 'KRR: Knowledge Acquisition', 'ML: Applications']","He, J., Liu, J., Zhang, Z., Chen, Y., Liu, Y., Khoussainov, B., & Zhu, L. (2023). MSDC: Exploiting Multi-State Power Consumption in Non-intrusive Load Monitoring Based on a Dual-CNN Model. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5078-5086. https://doi.org/10.1609/aaai.v37i4.25636","Abstract 					Non-intrusive load monitoring (NILM) aims to decompose aggregated electrical usage signal into appliance-specific power consumption and it amounts to a classical example of blind source separation tasks. Leveraging recent progress on deep learning techniques, we design a new neural NILM model {\em Multi-State Dual CNN} (MSDC). Different from previous models, MSDC explicitly extracts information about the appliance's multiple states and state transitions, which in turn regulates the prediction of signals for appliances. More specifically, we employ a dual-CNN architecture: one CNN for outputting state distributions and the other for predicting the power of each state. A new technique is invented that utilizes conditional random fields (CRF) to capture state transitions. Experiments on two real-world datasets REDD and UK-DALE demonstrate that our model significantly outperform state-of-the-art models  while having good generalization capacity, achieving 6%-10% MAE gain and 33%-51% SAE gain to unseen appliances.","https://ojs.aaai.org/index.php/AAAI/article/view/25636/25408"
"25637","Integrating Reward Maximization and Population Estimation: Sequential Decision-Making for Internal Revenue Service Audit Selection","['Peter Henderson', 'Ben Chugg', 'Brandon Anderson', 'Kristen Altenburger', 'Alex Turk', 'John Guyton', 'Jacob Goldin', 'Daniel E. Ho']","['Stanford University', 'Carnegie Mellon University', 'Internal Revenue Service', 'Stanford University', 'Internal Revenue Service', 'Internal Revenue Service', 'University of Chicago', 'Stanford University']","['APP: Economic/Financial', 'APP: Humanities & Computational Social Science']","Henderson, P., Chugg, B., Anderson, B., Altenburger, K., Turk, A., Guyton, J., Goldin, J., & Ho, D. E. (2023). Integrating Reward Maximization and Population Estimation: Sequential Decision-Making for Internal Revenue Service Audit Selection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5087-5095. https://doi.org/10.1609/aaai.v37i4.25637","Abstract 					We introduce a new setting, optimize-and-estimate structured bandits. Here, a policy must select a batch of arms, each characterized by its own context, that would allow it to both maximize reward and maintain an accurate (ideally unbiased) population estimate of the reward. This setting is inherent to many public and private sector applications and often requires handling delayed feedback, small data, and distribution shifts. We demonstrate its importance on real data from the United States Internal Revenue Service (IRS). The IRS performs yearly audits of the tax base. Two of its most important objectives are to identify suspected misreporting and to estimate the ""tax gap"" -- the global difference between the amount paid and true amount owed. Based on a unique collaboration with the IRS, we cast these two processes as a unified optimize-and-estimate structured bandit. We analyze optimize-and-estimate approaches to the IRS problem and propose a novel mechanism for unbiased population estimation that achieves rewards comparable to baseline approaches. This approach has the potential to improve audit efficacy, while maintaining policy-relevant estimates of the tax gap. This has important social consequences given that the current tax gap is estimated at nearly half a trillion dollars. We suggest that this problem setting is fertile ground for further research and we highlight its interesting challenges. The results of this and related research are currently being incorporated into the continual improvement of the IRS audit selection methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25637/25409"
"25638","MGTCF: Multi-Generator Tropical Cyclone Forecasting with Heterogeneous Meteorological Data","['Cheng Huang', 'Cong Bai', 'Sixian Chan', 'Jinglin Zhang', 'YuQuan Wu']","['College of Computer Science, Zhejiang University of Technology', 'College of Computer Science, Zhejiang University of Technology\nKey Laboratory of Visual Media Intelligent Processing Technology of Zhejiang Province', 'College of Computer Science, Zhejiang University of Technology\nKLME, CIC-FEMD, Nanjing University of Information Science & Technology', 'School of Control Science and Engineering, Shangdong University', 'Institute of Software Chinese Academy of Sciences']","['APP: Natural Sciences', 'APP: Energy', 'Environment & Sustainability']","Huang, C., Bai, C., Chan, S., Zhang, J., & Wu, Y. (2023). MGTCF: Multi-Generator Tropical Cyclone Forecasting with Heterogeneous Meteorological Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5096-5104. https://doi.org/10.1609/aaai.v37i4.25638","Abstract 					Accurate forecasting of tropical cyclone (TC) plays a critical role in the prevention and defense of TC disasters. We must explore a more accurate method for TC prediction. Deep learning methods are increasingly being implemented to make TC prediction more accurate. However, most existing methods lack a generic framework for adapting heterogeneous meteorological data and do not focus on the importance of the environment. Therefore, we propose a Multi-Generator Tropical Cyclone Forecasting model (MGTCF), a generic, extensible, multi-modal TC prediction model with the key modules of Generator Chooser Network (GC-Net) and Environment Net (Env-Net). The proposed method can utilize heterogeneous meteorologic data efficiently and mine environmental factors. In addition, the Multi-generator with Generator Chooser Net is proposed to tackle the drawbacks of single-generator TC prediction methods: the prediction of undesired out-of-distribution samples and the problems stemming from insufficient learning ability. To prove the effectiveness of MGTCF, we conduct extensive experiments on the China Meteorological Administration Tropical Cyclone Best Track Dataset. MGTCF obtains better performance compared with other deep learning methods and outperforms the official prediction method of the China Central Meteorological Observatory in most indexes.","https://ojs.aaai.org/index.php/AAAI/article/view/25638/25410"
"25639","MDM: Molecular Diffusion Model for 3D Molecule Generation","['Lei Huang', 'Hengtong Zhang', 'Tingyang Xu', 'Ka-Chun Wong']","['City University of Hong Kong\nTencent AI Lab', 'Tencent AI Lab', 'Tencent AI Lab', 'City University of Hong Kong']","['APP: Healthcare', 'Medicine & Wellness', 'APP: Bioinformatics', 'ML: Deep Generative Models & Autoencoders']","Huang, L., Zhang, H., Xu, T., & Wong, K.-C. (2023). MDM: Molecular Diffusion Model for 3D Molecule Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5105-5112. https://doi.org/10.1609/aaai.v37i4.25639","Abstract 					Molecule generation, especially generating 3D molecular geometries from scratch (i.e., 3D de novo generation), has become a fundamental task in drug design. Existing diffusion based 3D molecule generation methods could suffer from unsatisfactory performances, especially when generating large molecules. At the same time, the generated molecules lack enough diversity. This paper proposes a novel diffusion model to address those two challenges.   First, interatomic relations are not included in molecules' 3D point cloud representations. Thus, it is difficult for existing generative models to capture the potential interatomic forces and abundant local constraints.  To tackle this challenge, we propose to augment the potential interatomic forces and further involve dual equivariant encoders to encode interatomic forces of different strengths. Second, existing diffusion-based models essentially shift elements in geometry along the gradient of data density. Such a process lacks enough exploration in the intermediate steps of the Langevin dynamics. To address this issue, we introduce a distributional controlling variable in each diffusion/reverse step to enforce thorough explorations and further improve generation diversity.  Extensive experiments on multiple benchmarks demonstrate that the proposed model significantly outperforms existing methods for both unconditional and conditional generation tasks. We also conduct case studies to help understand the physicochemical properties of the generated molecules. The codes are available at https://github.com/tencent-ailab/MDM.","https://ojs.aaai.org/index.php/AAAI/article/view/25639/25411"
"25640","Learning Chemical Rules of Retrosynthesis with Pre-training","['Yinjie Jiang', 'Ying WEI', 'Fei Wu', 'Zhengxing Huang', 'Kun Kuang', 'Zhihua Wang']","['Zhejiang University', 'City University of Hong Kong', 'Zhejiang University\nShanghai Institute for Advanced Study of Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Shanghai Institute for Advanced Study of Zhejiang University']","['APP: Healthcare', 'Medicine & Wellness']","Jiang, Y., WEI, Y., Wu, F., Huang, Z., Kuang, K., & Wang, Z. (2023). Learning Chemical Rules of Retrosynthesis with Pre-training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5113-5121. https://doi.org/10.1609/aaai.v37i4.25640","Abstract 					Retrosynthesis aided by artificial intelligence has been a very active and bourgeoning area of research, for its critical role in drug discovery as well as material science. Three categories of solutions, i.e., template-based, template-free, and semi-template methods, constitute mainstream solutions to this problem. In this paper, we focus on template-free methods which are known to be less bothered by the template generalization issue and the atom mapping challenge. Among several remaining problems regarding template-free methods, failing to conform to chemical rules is pronounced. To address the issue, we seek for a pre-training solution to empower the pre-trained model with chemical rules encoded. Concretely, we enforce the atom conservation rule via a molecule reconstruction pre-training task, and the reaction rule that dictates reaction centers via a reaction type guided contrastive pre-training task. In our empirical evaluation, the proposed pre-training solution substantially improves the single-step retrosynthesis accuracies in three downstream datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25640/25412"
"25641","Online Symbolic Regression with Informative Query","['Pengwei Jin', 'Di Huang', 'Rui Zhang', 'Xing Hu', 'Ziyuan Nan', 'Zidong Du', 'Qi Guo', 'Yunji Chen']","['State Key Lab of Processors, Institute of Computing Technology, CAS\nUniversity of Chinese Academy of Sciences\nCambricon Technologies', 'State Key Lab of Processors, Institute of Computing Technology, CAS\nUniversity of Chinese Academy of Sciences\nCambricon Technologies', 'State Key Lab of Processors, Institute of Computing Technology, CAS\nCambricon Technologies', 'State Key Lab of Processors, Institute of Computing Technology, CAS', 'State Key Lab of Processors, Institute of Computing Technology, CAS\nUniversity of Chinese Academy of Sciences\nCambricon Technologies', 'State Key Lab of Processors, Institute of Computing Technology, CAS', 'State Key Lab of Processors, Institute of Computing Technology, CAS', 'State Key Lab of Processors, Institute of Computing Technology, CAS\nUniversity of Chinese Academy of Sciences']","['APP: Other Applications', 'ML: Applications', 'ML: Representation Learning']","Jin, P., Huang, D., Zhang, R., Hu, X., Nan, Z., Du, Z., Guo, Q., & Chen, Y. (2023). Online Symbolic Regression with Informative Query. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5122-5130. https://doi.org/10.1609/aaai.v37i4.25641","Abstract 					Symbolic regression, the task of extracting mathematical expressions from the observed data, plays a crucial role in scientific discovery. Despite the promising performance of existing methods, most of them conduct symbolic regression in an offline setting. That is, they treat the observed data points as given ones that are simply sampled from uniform distributions without exploring the expressive potential of data. However, for real-world scientific problems, the data used for symbolic regression are usually actively obtained by doing experiments, which is an online setting. Thus, how to obtain informative data that can facilitate the symbolic regression process is an important problem that remains challenging.   In this paper, we propose QUOSR, a query-based framework for online symbolic regression that can automatically obtain informative data in an iterative manner. Specifically, at each step, QUOSR receives historical data points, generates new x, and then queries the symbolic expression to get the corresponding y, where the (x, y) serves as new data points. This process repeats until the maximum number of query steps is reached. To make the generated data points informative, we implement the framework with a neural network and train it by maximizing the mutual information between generated data points and the target expression. Through comprehensive experiments, we show that QUOSR can facilitate modern symbolic regression methods by generating informative data.","https://ojs.aaai.org/index.php/AAAI/article/view/25641/25413"
"25642","Repair Is Nearly Generation: Multilingual Program Repair with LLMs","['Harshit Joshi', 'José Cambronero Sanchez', 'Sumit Gulwani', 'Vu Le', 'Gust Verbruggen', 'Ivan Radiček']","['Microsoft, India', 'Microsoft, USA', 'Microsoft, USA', 'Microsoft, USA', 'Microsoft, Belgium', 'Microsoft, Croatia']","['APP: Software Engineering', 'SNLP: Applications', 'SNLP: Language Models']","Joshi, H., Cambronero Sanchez, J., Gulwani, S., Le, V., Verbruggen, G., & Radiček, I. (2023). Repair Is Nearly Generation: Multilingual Program Repair with LLMs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5131-5140. https://doi.org/10.1609/aaai.v37i4.25642","Abstract 					Most programmers make mistakes when writing code. Some of these mistakes are small and require few edits to the original program – a class of errors recently termed last mile mistakes. These errors break the flow for experienced developers and can stump novice programmers. Existing automated repair techniques targeting this class of errors are language-specific and do not easily carry over to new languages. Transferring symbolic approaches requires substantial engineering and neural approaches require data and retraining. We introduce RING, a multilingual repair engine powered by a large language model trained on code (LLMC) such as Codex. Such a multilingual engine enables a flipped model for programming assistance, one where the programmer writes code and the AI assistance suggests fixes, compared to traditional code suggestion technology. Taking inspiration from the way programmers manually fix bugs, we show that a prompt-based strategy that conceptualizes repair as localization, transformation, and candidate ranking, can successfully repair programs in multiple languages with minimal effort. We present the first results for such a multilingual repair engine by evaluating on 6 different languages and comparing performance to language-specific repair engines. We show that RING can outperform language-specific repair engines for three of these languages.","https://ojs.aaai.org/index.php/AAAI/article/view/25642/25414"
"25643","Heterogeneous Graph Learning for Multi-Modal Medical Data Analysis","['Sein Kim', 'Namkyeong Lee', 'Junseok Lee', 'Dongmin Hyun', 'Chanyoung Park']","['KAIST', 'KAIST', 'KAIST', 'POSTECH', 'KAIST']","['APP: Healthcare', 'Medicine & Wellness', 'CV: Medical and Biological Imaging']","Kim, S., Lee, N., Lee, J., Hyun, D., & Park, C. (2023). Heterogeneous Graph Learning for Multi-Modal Medical Data Analysis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5141-5150. https://doi.org/10.1609/aaai.v37i4.25643","Abstract 					Routine clinical visits of a patient produce not only image data, but also non-image data containing clinical information regarding the patient, i.e., medical data is multi-modal in nature. Such heterogeneous modalities offer different and complementary perspectives on the same patient, resulting in more accurate clinical decisions when they are properly combined. However, despite its significance, how to effectively fuse the multi-modal medical data into a unified framework has received relatively little attention. In this paper, we propose an effective graph-based framework called HetMed (Heterogeneous Graph Learning for Multi-modal Medical Data Analysis) for fusing the multi-modal medical data. Specifically, we construct a multiplex network that incorporates multiple types of non-image features of patients to capture the complex relationship between patients in a systematic way, which leads to more accurate clinical decisions. Extensive experiments on various real-world datasets demonstrate the superiority and practicality of HetMed. The source code for HetMed is available at https://github.com/Sein-Kim/Multimodal-Medical.","https://ojs.aaai.org/index.php/AAAI/article/view/25643/25415"
"25644","Rolling Horizon Based Temporal Decomposition for the Offline Pickup and Delivery Problem with Time Windows","['Youngseo Kim', 'Danushka Edirimanna', 'Michael Wilbur', 'Philip Pugliese', 'Aron Laszka', 'Abhishek Dubey', 'Samitha Samaranayake']","['Cornell University', 'Cornell University', 'Vanderbilt University', 'Chattanooga Area Regional Transportation Authority', 'Pennsylvania State University', 'Vanderbilt University', 'Cornell University']","['APP: Transportation', 'PRS: Temporal Planning', 'PRS: Applications', 'PRS: Optimization of Spatio-Temporal Systems', 'PRS: Scheduling', 'APP: Mobility', 'Driving & Flight', 'SO: Applications']","Kim, Y., Edirimanna, D., Wilbur, M., Pugliese, P., Laszka, A., Dubey, A., & Samaranayake, S. (2023). Rolling Horizon Based Temporal Decomposition for the Offline Pickup and Delivery Problem with Time Windows. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5151-5159. https://doi.org/10.1609/aaai.v37i4.25644","Abstract 					The offline pickup and delivery problem with time windows (PDPTW) is a classical combinatorial optimization problem in the transportation community, which has proven to be very challenging computationally. Due to the complexity of the problem, practical problem instances can be solved only via heuristics, which trade-off solution quality for computational tractability. Among the various heuristics, a common strategy is problem decomposition, that is, the reduction of a large-scale problem into a collection of smaller sub-problems, with spatial and temporal decompositions being two natural approaches. While spatial decomposition has been successful in certain settings, effective temporal decomposition has been challenging due to the difficulty of stitching together the sub-problem solutions across the decomposition boundaries. In this work, we introduce a novel temporal decomposition scheme for solving a class of PDPTWs that have narrow time windows, for which it is able to provide both fast and high-quality solutions. We utilize techniques that have been popularized recently in the context of online dial-a-ride problems along with the general idea of rolling horizon optimization. To the best of our knowledge, this is the first attempt to solve offline PDPTWs using such an approach. To show the performance and scalability of our framework, we use the optimization of paratransit services as a motivating example. Due to the lack of benchmark solvers similar to ours (i.e., temporal decomposition with an online solver), we compare our results with an offline heuristic algorithm using Google OR-Tools. In smaller problem instances (with an average of 129 requests per instance), the baseline approach is as competitive as our framework. However, in larger problem instances (approximately 2,500 requests per instance), our framework is more scalable and can provide good solutions to problem instances of varying degrees of difficulty, while the baseline algorithm often fails to find a feasible solution within comparable compute times.","https://ojs.aaai.org/index.php/AAAI/article/view/25644/25416"
"25645","GRIP: Graph Representation of Immune Repertoire Using Graph Neural Network and Transformer","['Yongju Lee', 'Hyunho Lee', 'Kyoungseob Shin', 'Sunghoon Kwon']","['Seoul National University', 'Seoul National University', 'Seoul National University', 'Seoul National University']","['APP: Bioinformatics', 'ML: Graph-based Machine Learning', 'ML: Multi-Instance/Multi-View Learning']","Lee, Y., Lee, H., Shin, K., & Kwon, S. (2023). GRIP: Graph Representation of Immune Repertoire Using Graph Neural Network and Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5160-5168. https://doi.org/10.1609/aaai.v37i4.25645","Abstract 					The immune repertoire is a collection of immune recep-tors that has emerged as an important biomarker for both diagnostic and therapeutic of cancer patients. In terms of deep learning, analyzing immune repertoire is a challeng-ing multiple-instance learning problem in which the im-mune repertoire of an individual is a bag, and the immune receptor is an instance. Although several deep learning methods for immune repertoire analysis are introduced, they consider the immune repertoire as a set-like struc-ture that doesn’t take account of the nature of the im-mune response. When the immune response occurs, mu-tations are introduced to the immune receptor sequence sequentially to optimize the immune response against the pathogens that enter our body. As a result, immune receptors for the specific pathogen have the lineage of evolution; thus, immune repertoire is better represented as a graph-like structure. In this work, we present our novel method graph representation of immune repertoire (GRIP), which analyzes the immune repertoire as a hier-archical graph structure and utilize the collection of graph neural network followed by graph pooling and transformer to efficiently represents the immune reper-toire as an embedding vector. We show that GRIP predict the survival probability of cancer patients better than the set-based methods and graph-based structure is critical for performance. Also, GRIP provides interpretable re-sults, which prove that GRIP adequately use the progno-sis-related immune receptor and give further possibility to use the GRIP as the novel biomarker searching tool","https://ojs.aaai.org/index.php/AAAI/article/view/25645/25417"
"25646","LagNet: Deep Lagrangian Mechanics for Plug-and-Play Molecular Representation Learning","['Chunyan Li', 'Junfeng Yao', 'Jinsong Su', 'Zhaoyang Liu', 'Xiangxiang Zeng', 'Chenxi Huang']","['Xiamen University\nYunnan Normal University', 'Xiamen University', 'Xiamen University', 'China University of Mining and Technology', 'Hunan University', 'Xiamen University']","['APP: Bioinformatics', 'APP: Healthcare', 'Medicine & Wellness', 'ML: Representation Learning']","Li, C., Yao, J., Su, J., Liu, Z., Zeng, X., & Huang, C. (2023). LagNet: Deep Lagrangian Mechanics for Plug-and-Play Molecular Representation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5169-5177. https://doi.org/10.1609/aaai.v37i4.25646","Abstract 					Molecular representation learning is a fundamental problem in the field of drug discovery and molecular science. Whereas incorporating molecular 3D information in the representations of molecule seems beneficial, which is related to computational chemistry with the basic task of predicting stable 3D structures (conformations) of molecules. Existing machine learning methods either rely on 1D and 2D molecular properties or simulate molecular force field to use additional 3D structure information via Hamiltonian network. The former has the disadvantage of ignoring important 3D structure features, while the latter has the disadvantage that existing Hamiltonian neural network must satisfy the “canonial” constraint, which is difficult to be obeyed in many cases. In this paper, we propose a novel plug-and-play architecture LagNet by simulating molecular force field only with parameterized position coordinates, which implements Lagrangian mechanics to learn molecular representation by preserving 3D conformation without obeying any additional restrictions. LagNet is designed to generate known conformations and generalize for unknown ones from molecular SMILES. Implicit positions in LagNet are learned iteratively using discrete-time Lagrangian equations. Experimental results show that LagNet can well learn 3D molecular structure features, and outperforms previous state-of-the-art baselines related molecular representation by a significant margin.","https://ojs.aaai.org/index.php/AAAI/article/view/25646/25418"
"25647","Steganography of Steganographic Networks","['Guobiao Li', 'Sheng Li', 'Meiling Li', 'Xinpeng Zhang', 'Zhenxing Qian']","['Fudan University', 'Fudan University', 'Fudan University', 'Fudan University', 'Fudan University']","['APP: Security']","Li, G., Li, S., Li, M., Zhang, X., & Qian, Z. (2023). Steganography of Steganographic Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5178-5186. https://doi.org/10.1609/aaai.v37i4.25647","Abstract 					Steganography is a technique for covert communication between two parties. With the rapid development of deep neural networks (DNN), more and more steganographic networks are proposed recently, which are shown to be promising to achieve good performance. Unlike the traditional handcrafted steganographic tools, a steganographic network is relatively large in size. It raises concerns on how to covertly transmit the steganographic network in public channels, which is a crucial stage in the pipeline of steganography in real world applications. To address such an issue, we propose a novel scheme for steganography of steganographic networks in this paper. Unlike the existing steganographic schemes which focus on the subtle modification of the cover data to accommodate the secrets. We propose to disguise a steganographic network (termed as the secret DNN model) into a stego DNN model which performs an ordinary machine learning task (termed as the stego task). During the model disguising, we select and tune a subset of filters in the secret DNN model to preserve its function on the secret task, where the remaining filters are reactivated according to a partial optimization strategy to disguise the whole secret DNN model into a stego DNN model. The secret DNN model can be recovered from the stego DNN model when needed. Various experiments have been conducted to demonstrate the advantage of our proposed method for covert communication of steganographic networks as well as general DNN models.","https://ojs.aaai.org/index.php/AAAI/article/view/25647/25419"
"25648","PEN: Prediction-Explanation Network to Forecast Stock Price Movement with Better Explainability","['Shuqi Li', 'Weiheng Liao', 'Yuhan Chen', 'Rui Yan']","['Gaoling School of Artificial Intelligence, Renmin University of China', 'Made by Data', 'Gaoling School of Artificial Intelligence, Renmin University of China', 'Gaoling School of Artificial Intelligence, Renmin University of China\nEngineering Research Center of Next-Generation Intelligent Search and Recommendation, Ministry of Education']","['APP: Economic/Financial', 'ML: Classification and Regression', 'ML: Deep Generative Models & Autoencoders', 'ML: Representation Learning']","Li, S., Liao, W., Chen, Y., & Yan, R. (2023). PEN: Prediction-Explanation Network to Forecast Stock Price Movement with Better Explainability. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5187-5194. https://doi.org/10.1609/aaai.v37i4.25648","Abstract 					Nowadays explainability in stock price movement prediction is attracting increasing attention in banks, hedge funds and asset managers, primarily due to audit or regulatory reasons. Text data such as financial news and social media posts can be part of the reasons for stock price movement. To this end, we propose a novel framework of Prediction-Explanation Network (PEN) jointly modeling text streams and price streams with alignment. The key component of the PEN model is an shared representation learning module that learns which texts are possibly associated with the stock price movement by modeling the interaction between the text data and stock price data with a salient vector characterizing their correlation. In this way, the PEN model is able to predict the stock price movement by identifying and utilizing abundant messages while on the other hand, the selected text messages also explain the stock price movement. Experiments on real-world datasets demonstrate that we are able to kill two birds with one stone: in terms of accuracy, the proposed PEN model outperforms the state-of-art baseline; on explainability, the PEN model are demonstrated to be far superior to attention mechanism, capable of picking out the crucial texts with a very high confidence.","https://ojs.aaai.org/index.php/AAAI/article/view/25648/25420"
"25649","Decision-Making Context Interaction Network for Click-Through Rate Prediction","['Xiang Li', 'Shuwei Chen', 'Jian Dong', 'Jin Zhang', 'Yongkang Wang', 'Xingxing Wang', 'Dong Wang']","['Meituan', 'Meituan', 'Meituan', 'Meituan', 'Meituan', 'Meituan', 'Meituan']","['APP: Business/Marketing/Advertising/E-Commerce', 'DMKM: Applications', 'DMKM: Recommender Systems', 'DMKM: Web Personalization & User Modeling', 'ML: Deep Neural Network Algorithms']","Li, X., Chen, S., Dong, J., Zhang, J., Wang, Y., Wang, X., & Wang, D. (2023). Decision-Making Context Interaction Network for Click-Through Rate Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5195-5202. https://doi.org/10.1609/aaai.v37i4.25649","Abstract 					Click-through rate (CTR) prediction is crucial in recommendation and online advertising systems. Existing methods usually model user behaviors, while ignoring the informative context which influences the user to make a click decision, e.g., click pages and pre-ranking candidates that inform inferences about user interests, leading to suboptimal performance. In this paper, we propose a Decision-Making Context Interaction Network (DCIN), which deploys a carefully designed Context Interaction Unit (CIU) to learn decision-making contexts and thus benefits CTR prediction. In addition, the relationship between different decision-making context sources is explored by the proposed Adaptive Interest Aggregation Unit (AIAU) to improve CTR prediction further. In the experiments on public and industrial datasets, DCIN significantly outperforms the state-of-the-art methods. Notably, the model has obtained the improvement of CTR+2.9%/CPM+2.1%/GMV+1.5% for online A/B testing and served the main traffic of Meituan Waimai advertising system.","https://ojs.aaai.org/index.php/AAAI/article/view/25649/25421"
"25650","Fine-Grained Position Helps Memorizing More, a Novel Music Compound Transformer Model with Feature Interaction Fusion","['Zuchao Li', 'Ruhan Gong', 'Yineng Chen', 'Kehua Su']","['Shool of Computer Science, Wuhan University', 'School of Computer Science, Wuhan University', 'Shool of Computer Science, Wuhan University', 'Shool of Computer Science, Wuhan University']","['APP: Art/Music/Creativity', 'SNLP: Applications', 'SNLP: Text Classification']","Li, Z., Gong, R., Chen, Y., & Su, K. (2023). Fine-Grained Position Helps Memorizing More, a Novel Music Compound Transformer Model with Feature Interaction Fusion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5203-5212. https://doi.org/10.1609/aaai.v37i4.25650","Abstract 					Due to the particularity of the simultaneous occurrence of multiple events in music sequences, compound Transformer is proposed to deal with the challenge of long sequences. However, there are two deficiencies in the compound Transformer. First, since the order of events is more important for music than natural language, the information provided by the original absolute position embedding is not precise enough. Second, there is an important correlation between the tokens in the compound word, which is ignored by the current compound Transformer. Therefore, in this work, we propose an improved compound Transformer model for music understanding. Specifically, we propose an attribute embedding fusion module  and a novel position encoding scheme with absolute-relative consideration. In the attribute embedding fusion module, different attributes are fused through feature permutation by using a multi-head self-attention mechanism in order to capture rich interactions between attributes. In the novel position encoding scheme, we propose RoAR position encoding, which realizes rotational absolute position encoding, relative position encoding, and absolute-relative position interactive encoding, providing clear and rich orders for musical events.  Empirical study on four typical music understanding tasks shows that our attribute fusion approach and RoAR position encoding brings large performance gains. In addition, we further investigate the impact of masked language modeling and casual language modeling  pre-training on music understanding.","https://ojs.aaai.org/index.php/AAAI/article/view/25650/25422"
"25651","Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning","['Hongzhan Lin', 'Pengyao Yi', 'Jing Ma', 'Haiyun Jiang', 'Ziyang Luo', 'Shuming Shi', 'Ruifang Liu']","['Hong Kong Baptist University', 'Beijing University of Posts and Telecommunications', 'Hong Kong Baptist Univesity', 'Fudan University', 'Hong Kong Baptist University', 'Tsinghua University', 'Beijing University of Posts and Telecommunications']","['APP: Misinformation & Fake News']","Lin, H., Yi, P., Ma, J., Jiang, H., Luo, Z., Shi, S., & Liu, R. (2023). Zero-Shot Rumor Detection with Propagation Structure via Prompt Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5213-5221. https://doi.org/10.1609/aaai.v37i4.25651","Abstract 					The spread of rumors along with breaking events seriously hinders the truth in the era of social media. Previous studies reveal that due to the lack of annotated resources, rumors presented in minority languages are hard to be detected. Furthermore, the unforeseen breaking events not involved in yesterday's news exacerbate the scarcity of data resources. In this work, we propose a novel zero-shot framework based on prompt learning to detect rumors falling in different domains or presented in different languages. More specifically, we firstly represent rumor circulated on social media as diverse propagation threads, then design a hierarchical prompt encoding mechanism to learn language-agnostic contextual representations for both prompts and rumor data. To further enhance domain adaptation, we model the domain-invariant structural features from the propagation threads, to incorporate structural position representations of influential community response. In addition, a new virtual response augmentation method is used to improve model training. Extensive experiments conducted on three real-world datasets demonstrate that our proposed model achieves much better performance than state-of-the-art methods and exhibits a superior capacity for detecting rumors at early stages.","https://ojs.aaai.org/index.php/AAAI/article/view/25651/25423"
"25652","On Manipulating Weight Predictions in Signed Weighted Networks","['Tomasz Lizurej', 'Tomasz Michalak', 'Stefan Dziembowski']","['University of Warsaw\nIDEAS NCBR', 'University of Warsaw\nIDEAS NCBR', 'University of Warsaw\nIDEAS NCBR']","['APP: Security', 'APP: Social Networks']","Lizurej, T., Michalak, T., & Dziembowski, S. (2023). On Manipulating Weight Predictions in Signed Weighted Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5222-5229. https://doi.org/10.1609/aaai.v37i4.25652","Abstract 					Adversarial social network analysis studies how graphs can be rewired or otherwise manipulated to evade social network analysis tools. While there is ample literature on manipulating simple networks, more sophisticated network types are much less understood in this respect. In this paper, we focus on the problem of evading FGA---an edge weight prediction method for signed weighted networks by Kumar et al. 2016. Among others, this method can be used for trust prediction in reputation systems. We study the theoretical underpinnings of FGA and its computational properties in terms of manipulability. Our positive finding is that, unlike many other tools, this measure is not only difficult to manipulate optimally, but also it can be difficult to manipulate in practice.","https://ojs.aaai.org/index.php/AAAI/article/view/25652/25424"
"25653","Better Context Makes Better Code Language Models: A Case Study on Function Call Argument Completion","['Hengzhi Pei', 'Jinman Zhao', 'Leonard Lausen', 'Sheng Zha', 'George Karypis']","['University of Illinois Urbana-Champaign', 'Amazon Web Services', 'Amazon Web Services', 'Amazon Web Services', 'Amazon Web Services']","['APP: Software Engineering', 'SNLP: Language Models']","Pei, H., Zhao, J., Lausen, L., Zha, S., & Karypis, G. (2023). Better Context Makes Better Code Language Models: A Case Study on Function Call Argument Completion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5230-5238. https://doi.org/10.1609/aaai.v37i4.25653","Abstract 					Pretrained code language models have enabled great progress towards program synthesis. However, common approaches only consider in-file local context and thus miss information and constraints imposed by other parts of the codebase and its external dependencies. Existing code completion benchmarks also lack such context. To resolve these restrictions we curate a new dataset of permissively licensed Python packages that includes full projects and their dependencies and provide tools to extract non-local information with the help of program analyzers. We then focus on the task of function call argument completion which requires predicting the arguments to function calls. We show that existing code completion models do not yield good results on our completion task. To better solve this task, we query a program analyzer for information relevant to a given function call, and consider ways to provide the analyzer results to different code completion models during inference and training. Our experiments show that providing access to the function implementation and function usages greatly improves the argument completion performance. Our ablation study provides further insights on how different types of information available from the program analyzer and different ways of incorporating the information affect the model performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25653/25425"
"25654","MetaTPTrans: A Meta Learning Approach for Multilingual Code Representation Learning","['Weiguo Pian', 'Hanyu Peng', 'Xunzhu Tang', 'Tiezhu Sun', 'Haoye Tian', 'Andrew Habib', 'Jacques Klein', 'Tegawendé F. Bissyandé']","['University of Luxembourg', 'Baidu Inc.', 'University of Luxembourg', 'University of Luxembourg', 'University of Luxembourg', 'University of Luxembourg', 'University of Luxembourg', 'University of Luxembourg\nUniversité Virtuelle du Burkina Faso']","['APP: Software Engineering', 'ML: Applications']","Pian, W., Peng, H., Tang, X., Sun, T., Tian, H., Habib, A., Klein, J., & Bissyandé, T. F. (2023). MetaTPTrans: A Meta Learning Approach for Multilingual Code Representation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5239-5247. https://doi.org/10.1609/aaai.v37i4.25654","Abstract 					Representation learning of source code is essential for applying machine learning to software engineering tasks. Learning code representation from a multilingual source code dataset has been shown to be more effective than learning from single-language datasets separately, since more training data from multilingual dataset improves the model's ability to extract language-agnostic information from source code. However, existing multilingual training overlooks the language-specific information which is crucial for modeling source code across different programming languages, while only focusing on learning a unified model with shared parameters among different languages for language-agnostic information modeling. To address this problem, we propose MetaTPTrans, a meta learning approach for multilingual code representation learning. MetaTPTrans generates different parameters for the feature extractor according to the specific programming language type of the input code snippet, enabling the model to learn both language-agnostic and language-specific information with dynamic parameters in the feature extractor. We conduct experiments on the code summarization and code completion tasks to verify the effectiveness of our approach. The results demonstrate the superiority of our approach with significant improvements on state-of-the-art baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/25654/25426"
"25655","HG-SL: Jointly Learning of Global and Local User Spreading Behavior for Fake News Early Detection","['Ling Sun', 'Yuan Rao', 'Yuqian Lan', 'Bingcan Xia', 'Yangyang Li']","[""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", 'Xi’an Jiaotong University', ""Xi'an Jiaotong University"", 'National Engineering Laboratory for Risk Perception and Prevention']","['APP: Misinformation & Fake News', 'DMKM: Applications', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'DMKM: Web Personalization & User Modeling', 'APP: Social Networks', 'KRR: Applications', 'ML: Graph-based Machine Learning']","Sun, L., Rao, Y., Lan, Y., Xia, B., & Li, Y. (2023). HG-SL: Jointly Learning of Global and Local User Spreading Behavior for Fake News Early Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5248-5256. https://doi.org/10.1609/aaai.v37i4.25655","Abstract 					Recently, fake news forgery technology has become more and more sophisticated, and even the profiles of participants may be faked, which challenges the robustness and effectiveness of traditional detection methods involving text or user identity. Most propagation-only approaches mainly rely on neural networks to learn the diffusion pattern of individual news, which is insufficient to describe the differences in news spread ability, and also ignores the valuable global connections of news and users, limiting the performance of detection. Therefore, we propose a joint learning model named HG-SL, which is blind to news content and user identities, but capable of catching the differences between true and fake news in the early stages of propagation through global and local user spreading behavior. Specifically, we innovatively design a Hypergraph-based Global interaction learning module to capture the global preferences of users from their co-spreading relationships, and introduce node centrality encoding to complement user influence in hypergraph learning. Moreover, the designed Self-attention-based Local context learning module first introduce spread status to highlight the propagation ability of news and users, thus providing additional signals for verifying news authenticity. Experiments on real-world datasets indicate that our HG-SL, which solely relies on user behavior, outperforms SOTA baselines utilizing multidimensional features in both fake news detection and early detection task.","https://ojs.aaai.org/index.php/AAAI/article/view/25655/25427"
"25656","Defending against Backdoor Attacks in Natural Language Generation","['Xiaofei Sun', 'Xiaoya Li', 'Yuxian Meng', 'Xiang Ao', 'Lingjuan Lyu', 'Jiwei Li', 'Tianwei Zhang']","['Zhejiang University', 'Shannon.AI', 'Shannon.AI', 'Chinese Academy of Sciences', 'Sony AI', 'Shannon.AI\nZhejiang University', 'Nanyang Technological University']","['APP: Security', 'SNLP: Bias', 'Fairness', 'Transparency & Privacy', 'SNLP: Adversarial Attacks & Robustness', 'SNLP: Generation']","Sun, X., Li, X., Meng, Y., Ao, X., Lyu, L., Li, J., & Zhang, T. (2023). Defending against Backdoor Attacks in Natural Language Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5257-5265. https://doi.org/10.1609/aaai.v37i4.25656","Abstract 					The frustratingly fragile nature of neural network models make current natural  language generation (NLG) systems prone to backdoor attacks and generate malicious sequences that could be sexist or offensive. Unfortunately, little effort has been invested to how backdoor attacks can affect current NLG models and how to defend against these attacks. In this work, by giving a formal definition of backdoor attack and defense, we investigate this problem on two important NLG tasks, machine translation and dialog generation. Tailored to the inherent nature of NLG models (e.g., producing a sequence of coherent words given contexts), we design defending strategies against attacks.  We find that testing the backward probability of generating sources given targets yields  effective defense performance against all different types of attacks, and is able to handle the one-to-many issue in many NLG tasks such as dialog generation. We hope that this work can raise the awareness of backdoor risks concealed in deep NLG systems and inspire more future work (both attack and defense) towards this direction.","https://ojs.aaai.org/index.php/AAAI/article/view/25656/25428"
"25657","GenéLive! Generating Rhythm Actions in Love Live!","['Atsushi Takada', 'Daichi Yamazaki', 'Yudai Yoshida', 'Nyamkhuu Ganbat', 'Takayuki Shimotomai', 'Naoki Hamada', 'Likun Liu', 'Taiga Yamamoto', 'Daisuke Sakurai']","['KLab Inc.', 'KLab Inc.', 'KLab Inc.', 'KLab Inc.', 'KLab Inc.', 'KLab Inc.', 'Kyushu University', 'Kyushu University', 'Kyushu University']","['APP: Art/Music/Creativity', 'APP: Entertainment', 'APP: Games', 'ML: Deep Generative Models & Autoencoders']","Takada, A., Yamazaki, D., Yoshida, Y., Ganbat, N., Shimotomai, T., Hamada, N., Liu, L., Yamamoto, T., & Sakurai, D. (2023). GenéLive! Generating Rhythm Actions in Love Live!. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5266-5275. https://doi.org/10.1609/aaai.v37i4.25657","Abstract 					This article presents our generative model for rhythm action games together with applications in business operation. Rhythm action games are video games in which the player is challenged to issue commands at the right timings during a music session. The timings are rendered in the chart, which consists of visual symbols, called notes, flying through the screen. We introduce our deep generative model, GenéLive!, which outperforms the state-of-the-art model by taking into account musical structures through beats and temporal scales. Thanks to its favorable performance, GenéLive! was put into operation at KLab Inc., a Japan-based video game developer, and reduced the business cost of chart generation by as much as half. The application target included the phenomenal ""Love Live!"", which has more than 10 million users across Asia and beyond, and is one of the few rhythm action franchises that has led the online era of the genre. In this article, we evaluate the generative performance of GenéLive! using production datasets at KLab as well as open datasets for reproducibility, while the model continues to operate in their business. Our code and the model, tuned and trained using a supercomputer, are publicly available.","https://ojs.aaai.org/index.php/AAAI/article/view/25657/25429"
"25658","Deepfake Video Detection via Facial Action Dependencies Estimation","['Lingfeng Tan', 'Yunhong Wang', 'Junfu Wang', 'Liang Yang', 'Xunxun Chen', 'Yuanfang Guo']","['School of Computer Science and Engineering, Beihang University, China', 'School of Computer Science and Engineering, Beihang University, China', 'School of Computer Science and Engineering, Beihang University, China', 'School of Artificial Intelligence, Hebei University of Technology, China', 'CNCERT/CC, Beijing, China', 'School of Computer Science and Engineering, Beihang University, China\nZhongguancun Laboratory, Beijing, China']","['APP: Security']","Tan, L., Wang, Y., Wang, J., Yang, L., Chen, X., & Guo, Y. (2023). Deepfake Video Detection via Facial Action Dependencies Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5276-5284. https://doi.org/10.1609/aaai.v37i4.25658","Abstract 					Deepfake video detection has drawn significant attention from researchers due to the security issues induced by deepfake videos. Unfortunately, most of the existing deepfake detection approaches have not competently modeled the natural structures and movements of human faces. In this paper, we formulate the deepfake video detection problem into a graph classification task, and propose a novel paradigm named Facial Action Dependencies Estimation (FADE) for deepfake video detection. We propose a Multi-Dependency Graph Module (MDGM) to capture abundant dependencies among facial action units, and extracts subtle clues in these dependencies. MDGM can be easily integrated into the existing frame-level detection schemes to provide significant performance gains. Extensive experiments demonstrate the superiority of our method against the state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25658/25430"
"25659","Contrastive Attention Networks for Attribution of Early Modern Print","['Nikolai Vogler', 'Kartik Goyal', 'Kishore PV Reddy', 'Elizaveta Pertseva', 'Samuel V. Lemley', 'Christopher N. Warren', ""Max G'Sell"", 'Taylor Berg-Kirkpatrick']","['UC San Diego', 'Toyota Technological Institute at Chicago', 'UC San Diego', 'UC San Diego', 'Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University', 'UC San Diego']","['APP: Humanities & Computational Social Science', 'CV: Image and Video Retrieval', 'ML: Applications']","Vogler, N., Goyal, K., Reddy, K. P., Pertseva, E., Lemley, S. V., Warren, C. N., G’Sell, M., & Berg-Kirkpatrick, T. (2023). Contrastive Attention Networks for Attribution of Early Modern Print. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5285-5293. https://doi.org/10.1609/aaai.v37i4.25659","Abstract 					In this paper, we develop machine learning techniques to identify unknown printers in early modern (c.~1500--1800) English printed books. Specifically, we focus on matching uniquely damaged character type-imprints in anonymously printed books to works with known printers in order to provide evidence of their origins. Until now, this work has been limited to manual investigations by analytical bibliographers. We present a Contrastive Attention-based Metric Learning approach to identify similar damage across character image pairs, which is sensitive to very subtle differences in glyph shapes, yet robust to various confounding sources of noise associated with digitized historical books.  To overcome the scarce amount of supervised data, we design a random data synthesis procedure that aims to simulate bends, fractures, and inking variations induced by the early printing process. Our method successfully improves downstream damaged type-imprint matching among printed works from this period, as validated by in-domain human experts. The results of our approach on two important philosophical works from the Early Modern period demonstrate potential to extend the extant historical research about the origins and content of these books.","https://ojs.aaai.org/index.php/AAAI/article/view/25659/25431"
"25660","AdapSafe: Adaptive and Safe-Certified Deep Reinforcement Learning-Based Frequency Control for Carbon-Neutral Power Systems","['Xu Wan', 'Mingyang Sun', 'Boli Chen', 'Zhongda Chu', 'Fei Teng']","['Zhejiang University\nAlibaba-Zhejiang University Joint Research Institute of Frontier Technologies', 'Zhejiang University\nAlibaba-Zhejiang University Joint Research Institute of Frontier Technologies', 'University College London', 'Imperial College London', 'Imperial College London']","['APP: Energy', 'Environment & Sustainability', 'ML: Applications', 'ML: Reinforcement Learning Algorithms', 'PEAI: Safety', 'Robustness & Trustworthiness']","Wan, X., Sun, M., Chen, B., Chu, Z., & Teng, F. (2023). AdapSafe: Adaptive and Safe-Certified Deep Reinforcement Learning-Based Frequency Control for Carbon-Neutral Power Systems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5294-5302. https://doi.org/10.1609/aaai.v37i4.25660","Abstract 					With the increasing penetration of inverter-based renewable energy resources, deep reinforcement learning (DRL) has been proposed as one of the most promising solutions to realize real-time and autonomous control for future carbon-neutral power systems. In particular, DRL-based frequency control approaches have been extensively investigated to overcome the limitations of model-based approaches, such as the computational cost and scalability for large-scale systems. Nevertheless, the real-world implementation of DRLbased frequency control methods is facing the following fundamental challenges: 1) safety guarantee during the learning and decision-making processes; 2) adaptability against the dynamic system operating conditions. To this end, this is the first work that proposes an Adaptive and Safe-Certified DRL (AdapSafe) algorithm for frequency control to simultaneously address the aforementioned challenges. In particular, a novel self-tuning control barrier function is designed to actively compensate the unsafe frequency control strategies under variational safety constraints and thus achieve guaranteed safety. Furthermore, the concept of meta-reinforcement learning is integrated to significantly enhance its adaptiveness in non-stationary power system environments without sacrificing the safety cost. Experiments are conducted based on GB 2030 power system, and the results demonstrate that the proposed AdapSafe exhibits superior performance in terms of its guaranteed safety in both training and test phases, as well as its considerable adaptability against the dynamics changes of system parameters.","https://ojs.aaai.org/index.php/AAAI/article/view/25660/25432"
"25661","Don’t Predict Counterfactual Values, Predict Expected Values Instead","['Jeremiasz Wołosiuk', 'Maciej Świechowski', 'Jacek Mańdziuk']","['Deepsolver', 'QED Software\nWarsaw University of Technology', 'Warsaw University of Technology']","['APP: Games', 'GTEP: Imperfect Information']","Wołosiuk, J., Świechowski, M., & Mańdziuk, J. (2023). Don’t Predict Counterfactual Values, Predict Expected Values Instead. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5303-5311. https://doi.org/10.1609/aaai.v37i4.25661","Abstract 					Counterfactual Regret Minimization algorithms are the most popular way of estimating the Nash Equilibrium in imperfect-information zero-sum games. In particular, DeepStack -- the state-of-the-art Poker bot -- employs the so-called Deep Counterfactual Value Network (DCVN) to learn the Counterfactual Values (CFVs) associated with various states in the game. Each CFV is a multiplication of two factors: (1) the probability that the opponent would reach a given state in a game, which can be explicitly calculated from the input data, and (2) the expected value (EV) of a payoff in that state, which is a complex function of the input data, hard to calculate. In this paper, we propose a simple yet powerful modification to the CFVs estimation process, which consists in utilizing a deep neural network to estimate only the EV factor of CFV. This new target setting significantly simplifies the learning problem and leads to much more accurate CFVs estimation.  A direct comparison, in terms of CFVs prediction losses, shows a significant prediction accuracy improvement of the proposed approach (DEVN) over the original DCVN formulation (relatively by 9.18-15.70% when using card abstraction, and by 3.37-8.39% without card abstraction, depending on a particular setting).  Furthermore, the application of DEVN improves the theoretical lower bound of the error by 29.05-31.83% compared to the DCVN pipeline when card abstraction is applied. Additionally, DEVN is able to achieve the goal using significantly smaller, and faster to infer, networks. While the proposed modification may seem to be of a rather technical nature, it, in fact, presents a fundamentally different approach to the overall process of learning and estimating CFVs, since the distributions of the training signals differ significantly between DCVN and DEVN. The former estimates CFVs, which are biased by the probability of reaching a given game state, while training the latter relies on a direct EV estimation, regardless of the state probability. In effect, the learning signal of DEVN presents a better estimation of the true value of a given state, thus allowing more accurate CFVs estimation.","https://ojs.aaai.org/index.php/AAAI/article/view/25661/25433"
"25662","Molformer: Motif-Based Transformer on 3D Heterogeneous Molecular Graphs","['Fang Wu', 'Dragomir Radev', 'Stan Z. Li']","['School of Engineering, Westlake University\nInstitute of AI Industry Research, Tsinghua University', 'Department of Computer Science, Yale University', 'School of Engineering, Westlake University']","['APP: Natural Sciences', 'APP: Bioinformatics']","Wu, F., Radev, D., & Li, S. Z. (2023). Molformer: Motif-Based Transformer on 3D Heterogeneous Molecular Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5312-5320. https://doi.org/10.1609/aaai.v37i4.25662","Abstract 					Procuring expressive molecular representations underpins AI-driven molecule design and scientific discovery. The research mainly focuses on atom-level homogeneous molecular graphs, ignoring the rich information in subgraphs or motifs. However, it has been widely accepted that substructures play a dominant role in identifying and determining molecular properties. To address such issues, we formulate heterogeneous molecular graphs (HMGs) and introduce a novel architecture to exploit both molecular motifs and 3D geometry. Precisely, we extract functional groups as motifs for small molecules and employ reinforcement learning to adaptively select quaternary amino acids as motif candidates for proteins. Then HMGs are constructed with both atom-level and motif-level nodes. To better accommodate those HMGs, we introduce a variant of the Transformer named Molformer, which adopts a heterogeneous self-attention layer to distinguish the interactions between multi-level nodes. Besides, it is also coupled with a multi-scale mechanism to capture fine-grained local patterns with increasing contextual scales. An attentive farthest point sampling algorithm is also proposed to obtain the molecular representations. We validate Molformer across a broad range of domains, including quantum chemistry, physiology, and biophysics. Extensive experiments show that Molformer outperforms or achieves the comparable performance of several state-of-the-art baselines. Our work provides a promising way to utilize informative motifs from the perspective of multi-level graph construction. The code is available at https://github.com/smiles724/Molformer.","https://ojs.aaai.org/index.php/AAAI/article/view/25662/25434"
"25663","DiffMD: A Geometric Diffusion Model for Molecular Dynamics Simulations","['Fang Wu', 'Stan Z. Li']","['AI Research and Innovation Laboratory, School of Engineering, Westlake University\nInstitute of AI Industry Research, Tsinghua University', 'AI Research and Innovation Laboratory, School of Engineering, Westlake University']","['APP: Natural Sciences', 'APP: Bioinformatics']","Wu, F., & Li, S. Z. (2023). DiffMD: A Geometric Diffusion Model for Molecular Dynamics Simulations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5321-5329. https://doi.org/10.1609/aaai.v37i4.25663","Abstract 					Molecular dynamics (MD) has long been the de facto choice for simulating complex atomistic systems from first principles. Recently deep learning models become a popular way to accelerate MD. Notwithstanding, existing models depend on intermediate variables such as the potential energy or force fields to update atomic positions, which requires additional computations to perform back-propagation. To waive this requirement, we propose a novel model called DiffMD by directly estimating the gradient of the log density of molecular conformations. DiffMD relies on a score-based denoising diffusion generative model that perturbs the molecular structure with a conditional noise depending on atomic accelerations and treats conformations at previous timeframes as the prior distribution for sampling. Another challenge of modeling such a conformation generation process is that a molecule is kinetic instead of static, which no prior works have strictly studied. To solve this challenge, we propose an equivariant geometric Transformer as the score function in the diffusion process to calculate corresponding gradients. It incorporates the directions and velocities of atomic motions via 3D spherical Fourier-Bessel representations. With multiple architectural improvements, we outperform state-of-the-art baselines on MD17 and isomers of C7O2H10 datasets. This work contributes to accelerating material and drug discovery.","https://ojs.aaai.org/index.php/AAAI/article/view/25663/25435"
"25664","Retrosynthesis Prediction with Local Template Retrieval","['Shufang Xie', 'Rui Yan', 'Junliang Guo', 'Yingce Xia', 'Lijun Wu', 'Tao Qin']","['Gaoling School of Artificial Intelligence, Renmin University of China', 'Gaoling School of Artificial Intelligence, Renmin University of China', 'Microsoft Research Asia', 'Microsoft Research AI4Science', 'Microsoft Research AI4Science', 'Microsoft Research AI4Science']","['APP: Healthcare', 'Medicine & Wellness', 'APP: Bioinformatics']","Xie, S., Yan, R., Guo, J., Xia, Y., Wu, L., & Qin, T. (2023). Retrosynthesis Prediction with Local Template Retrieval. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5330-5338. https://doi.org/10.1609/aaai.v37i4.25664","Abstract 					Retrosynthesis, which predicts the reactants of a given target molecule, is an essential task for drug discovery. In recent years, the machine learing based retrosynthesis methods have achieved promising results. In this work, we introduce RetroKNN, a local reaction template retrieval method to further boost the performance of template-based systems with non-parametric retrieval. We first build an atom-template store and a bond-template store that contains the local templates in the training data, then retrieve from these templates with a k-nearest-neighbor (KNN) search during inference. The retrieved templates are combined with neural network predictions as the final output. Furthermore, we propose a lightweight adapter to adjust the weights when combing neural network and KNN predictions conditioned on the hidden representation and the retrieved templates. We conduct comprehensive experiments on two widely used benchmarks, the USPTO-50K and USPTO-MIT. Especially for the top-1 accuracy, we improved 7.1% on the USPTO-50K dataset and 12.0% on the USPTO-MIT dataset.These results demonstrate the effectiveness of our method.","https://ojs.aaai.org/index.php/AAAI/article/view/25664/25436"
"25665","Multi-Relational Contrastive Learning Graph Neural Network for Drug-Drug Interaction Event Prediction","['Zhankun Xiong', 'Shichao Liu', 'Feng Huang', 'Ziyan Wang', 'Xuan Liu', 'Zhongfei Zhang', 'Wen Zhang']","['Huazhong Agricultural University', 'Huazhong Agricultural University', 'Huazhong Agricultural University', 'Huazhong Agriculture University', 'Huazhong Agricultural University', 'Binghamton University, SUNY', 'Huazhong Agricultural University']","['APP: Bioinformatics', 'APP: Healthcare', 'Medicine & Wellness']","Xiong, Z., Liu, S., Huang, F., Wang, Z., Liu, X., Zhang, Z., & Zhang, W. (2023). Multi-Relational Contrastive Learning Graph Neural Network for Drug-Drug Interaction Event Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5339-5347. https://doi.org/10.1609/aaai.v37i4.25665","Abstract 					Drug-drug interactions (DDIs) could lead to various unexpected adverse consequences, so-called DDI events. Predicting DDI events can reduce the potential risk of combinatorial therapy and improve the safety of medication use, and has attracted much attention in the deep learning community. Recently, graph neural network (GNN)-based models have aroused broad interest and achieved satisfactory results in the DDI event prediction. Most existing GNN-based models ignore either drug structural information or drug interactive information, but both aspects of information are important for DDI event prediction. Furthermore, accurately predicting rare DDI events is hindered by their inadequate labeled instances. In this paper, we propose a new method, Multi-Relational Contrastive learning Graph Neural Network, MRCGNN for brevity, to predict DDI events. Specifically, MRCGNN integrates the two aspects of information by deploying a GNN on the multi-relational DDI event graph attributed with the drug features extracted from drug molecular graphs. Moreover, we implement a multi-relational graph contrastive learning with a designed dual-view negative counterpart augmentation strategy, to capture implicit information about rare DDI events. Extensive experiments on two datasets show that MRCGNN outperforms the state-of-the-art methods. Besides, we observe that MRCGNN achieves satisfactory performance when predicting rare DDI events.","https://ojs.aaai.org/index.php/AAAI/article/view/25665/25437"
"25666","Tighter Robust Upper Bounds for Options via No-Regret Learning","['Shan Xue', 'Ye Du', 'Liang Xu']","['Southwestern University of Finance and Economics', 'Southwestern University of Finance and Economics', 'Southwestern University of Finance and Economics']","['APP: Economic/Financial', 'ML: Online Learning & Bandits']","Xue, S., Du, Y., & Xu, L. (2023). Tighter Robust Upper Bounds for Options via No-Regret Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5348-5356. https://doi.org/10.1609/aaai.v37i4.25666","Abstract 					Classic option pricing models, such as the Black-Scholes formula, often depend on some rigid assumptions on the dynamics of the underlying asset prices. These assumptions are inevitably violated in practice and thus induce the model risk. To mitigate this, robust option pricing that only requires the no-arbitrage principle has attracted a great deal of attention among researchers. In this paper, we give new robust upper bounds for option prices based on a novel η-momentum trading strategy. Our bounds for European options are tighter for most common moneyness, volatility, and expiration date setups than those presented in the existing literature. Our bounds for average strike Asian options are the first closed-form robust upper bounds for those options. Numerical simulations demonstrate that our bounds significantly outperform the benchmarks for both European and Asian options.","https://ojs.aaai.org/index.php/AAAI/article/view/25666/25438"
"25667","KerPrint: Local-Global Knowledge Graph Enhanced Diagnosis Prediction for Retrospective and Prospective Interpretations","['Kai Yang', 'Yongxin Xu', 'Peinie Zou', 'Hongxin Ding', 'Junfeng Zhao', 'Yasha Wang', 'Bing Xie']","['Zhongguancun Laboratory', 'Key Laboratory of High Confidence Software Technologies, Ministry of Education\nSchool of Computer Science, Peking University', 'Key Laboratory of High Confidence Software Technologies, Ministry of Education\nSchool of Computer Science, Peking University', 'Key Laboratory of High Confidence Software Technologies, Ministry of Education\nSchool of Computer Science, Peking University', 'Key Laboratory of High Confidence Software Technologies, Ministry of Education\nSchool of Computer Science, Peking University\nPeking University Information Technology Institute (Tianjin Binhai)', 'National Engineering Research Center For Software Engineering, Peking University\nKey Laboratory of High Confidence Software Technologies, Ministry of Education\nPeking University Information Technology Institute (Tianjin Binhai)', 'Key Laboratory of High Confidence Software Technologies, Ministry of Education\nSchool of Computer Science, Peking University\nPeking University Information Technology Institute (Tianjin Binhai)']","['APP: Healthcare', 'Medicine & Wellness', 'KRR: Applications', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'PEAI: Interpretability and Explainability']","Yang, K., Xu, Y., Zou, P., Ding, H., Zhao, J., Wang, Y., & Xie, B. (2023). KerPrint: Local-Global Knowledge Graph Enhanced Diagnosis Prediction for Retrospective and Prospective Interpretations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5357-5365. https://doi.org/10.1609/aaai.v37i4.25667","Abstract 					While recent developments of deep learning models have led to record-breaking achievements in many areas, the lack of sufficient interpretation remains a problem for many specific applications, such as the diagnosis prediction task in healthcare. The previous knowledge graph(KG) enhanced approaches mainly focus on learning clinically meaningful representations, the importance of medical concepts, and even the knowledge paths from inputs to labels. However, it is infeasible to interpret the diagnosis prediction, which needs to consider different medical concepts, various medical relationships, and the time-effectiveness of knowledge triples in different patient contexts. More importantly, the retrospective and prospective interpretations of disease processes are valuable to clinicians for the patients' confounding diseases. We propose KerPrint, a novel KG enhanced approach for retrospective and prospective interpretations to tackle these problems. Specifically, we propose a time-aware KG attention method to solve the problem of knowledge decay over time for trustworthy retrospective interpretation. We also propose a novel element-wise attention method to select candidate global knowledge using comprehensive representations from the local KG for prospective interpretation. We validate the effectiveness of our KerPrint through an extensive experimental study on a real-world dataset and a public dataset. The results show that our proposed approach not only achieves significant improvement over knowledge-enhanced methods but also gives the interpretability of diagnosis prediction in both retrospective and prospective views.","https://ojs.aaai.org/index.php/AAAI/article/view/25667/25439"
"25668","Multi-Label Few-Shot ICD Coding as Autoregressive Generation with Prompt","['Zhichao Yang', 'Sunjae Kwon', 'Zonghai Yao', 'Hong Yu']","['College of Information and Computer Sciences, University of Massachusetts Amherst', 'College of Information and Computer Sciences, University of Massachusetts Amherst', 'College of Information and Computer Sciences, University of Massachusetts Amherst', 'College of Information and Computer Sciences, University of Massachusetts Amherst\nDepartment of Computer Science, University of Massachusetts Lowell\nCenter for Healthcare Organization and Implementation Research, Veterans Affairs Bedford Healthcare System']","['APP: Healthcare', 'Medicine & Wellness', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'SNLP: Applications', 'SNLP: Generation', 'SNLP: Language Models', 'SNLP: Text Classification']","Yang, Z., Kwon, S., Yao, Z., & Yu, H. (2023). Multi-Label Few-Shot ICD Coding as Autoregressive Generation with Prompt. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5366-5374. https://doi.org/10.1609/aaai.v37i4.25668","Abstract 					Automatic International Classification of Diseases (ICD) coding aims to assign multiple ICD codes to a medical note with an average of 3,000+ tokens. This task is challenging due to the high-dimensional space of multi-label assignment (155,000+ ICD code candidates) and the long-tail challenge - Many ICD codes are infrequently assigned yet infrequent ICD codes are important clinically. This study addresses the long-tail challenge by transforming this multi-label classification task into an autoregressive generation task. Specifically, we first introduce a novel pretraining objective to generate free text diagnosis and procedure descriptions using the SOAP structure, the medical logic physicians use for note documentation. Second, instead of directly predicting the high dimensional space of ICD codes, our model generates the lower dimension of text descriptions, which then infer ICD codes. Third, we designed a novel prompt template for multi-label classification. We evaluate our Generation with Prompt (GP) model with the benchmark of all code assignment (MIMIC-III-full) and few shot ICD code assignment evaluation benchmark (MIMIC-III-few). Experiments on MIMIC-III-few show that our model performs with a marco F1 30.2, which substantially outperforms the previous MIMIC-III-full SOTA model (marco F1 4.3) and the model specifically designed for few/zero shot setting (marco F1 18.7). Finally, we design a novel ensemble learner, a cross attention reranker with prompts, to integrate previous SOTA and our best few-shot coding predictions. Experiments on MIMIC-III-full show that our ensemble learner substantially improves both macro and micro F1, from 10.4 to 14.6 and from 58.2 to 59.1, respectively.","https://ojs.aaai.org/index.php/AAAI/article/view/25668/25440"
"25669","DMIS: Dynamic Mesh-Based Importance Sampling for Training Physics-Informed Neural Networks","['Zijiang Yang', 'Zhongwei Qiu', 'Dongmei Fu']","['School of Automation and Electrical Engineering, University of Science and Technology Beijing\nBeijing Engineering Research Center of Industrial Spectrum Imaging', 'School of Automation and Electrical Engineering, University of Science and Technology Beijing\nBeijing Engineering Research Center of Industrial Spectrum Imaging\nThe University of Sydney', 'School of Automation and Electrical Engineering, University of Science and Technology Beijing\nBeijing Engineering Research Center of Industrial Spectrum Imaging\nShunde Innovation School, University of Science and Technology Beijing']","['APP: Natural Sciences', 'ML: Applications', 'ML: Optimization', 'SO: Applications', 'SO: Sampling/Simulation-Based Search']","Yang, Z., Qiu, Z., & Fu, D. (2023). DMIS: Dynamic Mesh-Based Importance Sampling for Training Physics-Informed Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5375-5383. https://doi.org/10.1609/aaai.v37i4.25669","Abstract 					Modeling dynamics in the form of partial differential equations (PDEs) is an effectual way to understand real-world physics processes. For complex physics systems, analytical solutions are not available and numerical solutions are widely-used. However, traditional numerical algorithms are computationally expensive and challenging in handling multiphysics systems. Recently, using neural networks to solve PDEs has made significant progress, called physics-informed neural networks (PINNs). PINNs encode physical laws into neural networks and learn the continuous solutions of PDEs. For the training of PINNs, existing methods suffer from the problems of inefficiency and unstable convergence, since the PDE residuals require calculating automatic differentiation. In this paper, we propose Dynamic Mesh-based Importance Sampling (DMIS) to tackle these problems. DMIS is a novel sampling scheme based on importance sampling, which constructs a dynamic triangular mesh to estimate sample weights efficiently. DMIS has broad applicability and can be easily integrated into existing methods. The evaluation of DMIS on three widely-used benchmarks shows that DMIS improves the convergence speed and accuracy in the meantime. Especially in solving the highly nonlinear Schrödinger Equation, compared with state-of-the-art methods, DMIS shows up to 46% smaller root mean square error and five times faster convergence speed. Code is available at https://github.com/MatrixBrain/DMIS.","https://ojs.aaai.org/index.php/AAAI/article/view/25669/25441"
"25670","Bootstrapping Multi-View Representations for Fake News Detection","['Qichao Ying', 'Xiaoxiao Hu', 'Yangming Zhou', 'Zhenxing Qian', 'Dan Zeng', 'Shiming Ge']","['School of Computer Science, Fudan University', 'School of Computer Science, Fudan University', 'School of Computer Science, Fudan University', 'School of Computer Science, Fudan University', 'Shanghai University', 'Chinese Academy of Sciences']","['APP: Misinformation & Fake News', 'CV: Multi-modal Vision', 'ML: Multimodal Learning']","Ying, Q., Hu, X., Zhou, Y., Qian, Z., Zeng, D., & Ge, S. (2023). Bootstrapping Multi-View Representations for Fake News Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5384-5392. https://doi.org/10.1609/aaai.v37i4.25670","Abstract 					Previous researches on multimedia fake news detection include a series of complex feature extraction and fusion networks to gather useful information from the news. However, how cross-modal consistency relates to the fidelity of news and how features from different modalities affect the decision-making are still open questions. This paper presents a novel scheme of Bootstrapping Multi-view Representations (BMR) for fake news detection. Given a multi-modal news, we extract representations respectively from the views of the text, the image pattern and the image semantics. Improved Multi-gate Mixture-of-Expert networks (iMMoE) are proposed for feature refinement and fusion. Representations from each view are separately used to coarsely predict the fidelity of the whole news, and the multimodal representations are able to predict the cross-modal consistency. With the prediction scores, we reweigh each view of the representations and bootstrap them for fake news detection. Extensive experiments conducted on typical fake news detection datasets prove that BMR outperforms state-of-the-art schemes.","https://ojs.aaai.org/index.php/AAAI/article/view/25670/25442"
"25671","Overcoming Forgetting in Fine-Grained Urban Flow Inference via Adaptive Knowledge Replay","['Haoyang Yu', 'Xovee Xu', 'Ting Zhong', 'Fan Zhou']","['University of Electronic Science and Technology of China, Chengdu, Sichuan, China', 'University of Electronic Science and Technology of China, Chengdu, Sichuan, China', 'University of Electronic Science and Technology of China, Chengdu, Sichuan, China', 'University of Electronic Science and Technology of China, Chengdu, Sichuan, China']","['APP: Internet of Things', 'Sensor Networks & Smart Cities', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'APP: Transportation']","Yu, H., Xu, X., Zhong, T., & Zhou, F. (2023). Overcoming Forgetting in Fine-Grained Urban Flow Inference via Adaptive Knowledge Replay. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5393-5401. https://doi.org/10.1609/aaai.v37i4.25671","Abstract 					Fine-grained urban flow inference (FUFI) problem aims at inferring the high-resolution flow maps from the coarse-grained ones, which plays an important role in sustainable and economic urban computing and traffic management. Previous models addressed the FUFI problem from spatial constraint, external factors, and memory cost. However, utilizing the new urban flow maps to calibrate the learned model is very challenging due to the ""catastrophic forgetting"" problem and is still under-explored. In this paper, we make the first step in FUFI and present CUFAR -- Continual Urban Flow inference with Adaptive knowledge Replay -- a novel framework for inferring the fine-grained citywide traffic flows. Specifically, (1) we design a spatial-temporal inference network that can extract better flow map features from both local and global levels; (2) then we present an adaptive knowledge replay (AKR) training algorithm to selectively replay the learned knowledge to facilitate the learning process of the model on new knowledge without forgetting. In addition, we also propose a knowledge discriminator to avoid ""negative replaying"" issue introduced by noisy urban flow maps. Extensive experiments on four large-scale real-world FUFI datasets demonstrate that our proposed model consistently outperforms strong baselines and effectively mitigates the forgetting problem. Source code is available at: https://github.com/PattonYu/CUFAR.","https://ojs.aaai.org/index.php/AAAI/article/view/25671/25443"
"25672","Generalized Cell Type Annotation and Discovery for Single-Cell RNA-Seq Data","['Yuyao Zhai', 'Liang Chen', 'Minghua Deng']","['Peking University', 'Huawei Technologies Co., Ltd.', 'Peking University']","['APP: Bioinformatics', 'ML: Applications']","Zhai, Y., Chen, L., & Deng, M. (2023). Generalized Cell Type Annotation and Discovery for Single-Cell RNA-Seq Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5402-5410. https://doi.org/10.1609/aaai.v37i4.25672","Abstract 					The rapid development of single-cell RNA sequencing (scRNA-seq) technology allows us to study gene expression heterogeneity at the cellular level. Cell annotation is the basis for subsequent downstream analysis in single-cell data mining. Existing methods rarely explore the fine-grained semantic knowledge of novel cell types absent from the reference data and usually susceptible to batch effects on the classification of seen cell types. Taking into consideration these limitations, this paper proposes a new and practical task called generalized cell type annotation and discovery for scRNA-seq data. In this task, cells of seen cell types are given class labels, while cells of novel cell types are given cluster labels instead of a unified “unassigned” label. To address this problem, we carefully design a comprehensive evaluation benchmark and propose a novel end-to-end algorithm framework called scGAD. Specifically, scGAD first builds the intrinsic correspondence across the reference and target data by retrieving the geometrically and semantically mutual nearest neighbors as anchor pairs. Then we introduce an anchor-based self-supervised learning module with a connectivity-aware attention mechanism to facilitate model prediction capability on unlabeled target data. To enhance the inter-type separation and intra-type compactness, we further propose a confidential prototypical self-supervised learning module to uncover the consensus category structure of the reference and target data. Extensive results on massive real datasets demonstrate the superiority of scGAD over various state-of-the-art clustering and annotation methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25672/25444"
"25673","Mining and Applying Composition Knowledge of Dance Moves for Style-Concentrated Dance Generation","['Xinjian Zhang', 'Su Yang', 'Yi Xu', 'Weishan Zhang', 'Longwen Gao']","['Fudan University\nShanghai Key Laboratory of Intelligent Information Processing', 'Fudan University\nShanghai Key Laboratory of Intelligent Information Processing', 'Fudan University\nShanghai Key Laboratory of Intelligent Information Processing', 'China University of Petroleum (East China)', 'Bilibili']","['APP: Art/Music/Creativity', 'CV: Applications', 'DMKM: Mining of Visual', 'Multimedia & Multimodal Data', 'ML: Applications']","Zhang, X., Yang, S., Xu, Y., Zhang, W., & Gao, L. (2023). Mining and Applying Composition Knowledge of Dance Moves for Style-Concentrated Dance Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5411-5419. https://doi.org/10.1609/aaai.v37i4.25673","Abstract 					Choreography refers to creation of dance motions according to both music and dance knowledge, where the created dances should be style-specific and consistent. However, most of the existing methods generate dances using the given music as the only reference, lacking the stylized dancing knowledge, namely, the flag motion patterns contained in different styles. Without the stylized prior knowledge, these approaches are not promising to generate controllable style or diverse moves for each dance style, nor new dances complying with stylized knowledge. To address this issue, we propose a novel music-to-dance generation framework guided by style embedding, considering both input music and stylized dancing knowledge. These style embeddings are learnt representations of style-consistent kinematic abstraction of reference dance videos, which can act as controllable factors to impose style constraints on dance generation in a latent manner. Hence, we can make the style embedding fit into any given style while allowing the flexibility to generate new compatible dance moves by modifying the style embedding according to the learnt representations of a certain style. We are the first to achieve knowledge-driven style control in dance generation tasks. To support this study, we build a large multi-style music-to-dance dataset referred to as I-Dance. The qualitative and quantitative evaluations demonstrate the advantage of the proposed framework, as well as the ability to synthesize diverse moves under a dance style directed by style embedding.","https://ojs.aaai.org/index.php/AAAI/article/view/25673/25445"
"25674","Yet Another Traffic Classifier: A Masked Autoencoder Based Traffic Transformer with Multi-Level Flow Representation","['Ruijie Zhao', 'Mingwei Zhan', 'Xianwen Deng', 'Yanhao Wang', 'Yijun Wang', 'Guan Gui', 'Zhi Xue']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'QI-ANXIN', 'Shanghai Jiao Tong University', 'Nanjing University of Posts and Telecommunications', 'Shanghai Jiao Tong University']","['APP: Security', 'APP: Internet of Things', 'Sensor Networks & Smart Cities', 'APP: Web']","Zhao, R., Zhan, M., Deng, X., Wang, Y., Wang, Y., Gui, G., & Xue, Z. (2023). Yet Another Traffic Classifier: A Masked Autoencoder Based Traffic Transformer with Multi-Level Flow Representation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5420-5427. https://doi.org/10.1609/aaai.v37i4.25674","Abstract 					Traffic classification is a critical task in network security and management. Recent research has demonstrated the effectiveness of the deep learning-based traffic classification method. However, the following limitations remain: (1) the traffic representation is simply generated from raw packet bytes, resulting in the absence of important information; (2) the model structure of directly applying deep learning algorithms does not take traffic characteristics into account; and (3) scenario-specific classifier training usually requires a labor-intensive and time-consuming process to label data. In this paper, we introduce a masked autoencoder (MAE) based traffic transformer with multi-level flow representation to tackle these problems. To model raw traffic data, we design a formatted traffic representation matrix with hierarchical flow information. After that, we develop an efficient Traffic Transformer, in which packet-level and flow-level attention mechanisms implement more efficient feature extraction with lower complexity. At last, we utilize the MAE paradigm to pre-train our classifier with a large amount of unlabeled data, and perform fine-tuning with a few labeled data for a series of traffic classification tasks. Experiment findings reveal that our method outperforms state-of-the-art methods on five real-world traffic datasets by a large margin. The code is available at https://github.com/NSSL-SJTU/YaTC.","https://ojs.aaai.org/index.php/AAAI/article/view/25674/25446"
"25675","Loan Fraud Users Detection in Online Lending Leveraging Multiple Data Views","['Sha Zhao', 'Yongrui Huang', 'Ling Chen', 'Chunping Wang', 'Shijian Li', 'Lei Chen', 'Gang Pan']","['Zhejiang University', 'Zhejiang University', 'FinVolution Group (FINV)', 'FinVolution Group (FINV)', 'Zhejiang University', 'FinVolution Group (FINV)', 'Zhejiang University']","['APP: Economic/Financial', 'DMKM: Applications']","Zhao, S., Huang, Y., Chen, L., Wang, C., Li, S., Chen, L., & Pan, G. (2023). Loan Fraud Users Detection in Online Lending Leveraging Multiple Data Views. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5428-5436. https://doi.org/10.1609/aaai.v37i4.25675","Abstract 					In recent years, online lending platforms have been becoming attractive for micro-financing and popular in financial industries. However, such online lending platforms face a high risk of failure due to the lack of expertise on borrowers' creditworthness. Thus, risk forecasting is important to avoid economic loss. Detecting loan fraud users in advance is at the heart of risk forecasting. The purpose of fraud user (borrower) detection is to predict whether one user will fail to make required payments in the future. Detecting fraud users depend on historical loan records. However, a large proportion of users lack such information, especially for new users. In this paper, we attempt to detect loan fraud users from cross domain heterogeneous data views, including user attributes, installed app lists, app installation behaviors, and app-in logs, which compensate for the lack of historical loan records. However, it is difficult to effectively fuse the multiple heterogeneous data views. Moreover, some samples miss one or even more data views, increasing the difficulty in fusion. To address the challenges, we propose a novel end-to-end deep multiview learning approach, which encodes heterogeneous data views into homogeneous ones, generates the missing views based on the learned relationship among all the views, and then fuses all the views together to a comprehensive view for identifying fraud users. Our model is evaluated on a real-world large-scale dataset consisting of 401,978 loan records of 228,117 users from January 1, 2019, to September 30, 2019, achieving the state-of-the-art performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25675/25447"
"25676","Sparse Maximum Margin Learning from Multimodal Human Behavioral Patterns","['Ervine Zheng', 'Qi Yu', 'Zhi Zheng']","['Rochester Institute of Technology', 'Rochester Institute of Technology', 'Rochester Institute of Technology']","['APP: Healthcare', 'Medicine & Wellness', 'ML: Bayesian Learning']","Zheng, E., Yu, Q., & Zheng, Z. (2023). Sparse Maximum Margin Learning from Multimodal Human Behavioral Patterns. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5437-5445. https://doi.org/10.1609/aaai.v37i4.25676","Abstract 					We propose a multimodal data fusion framework to systematically analyze human behavioral data from specialized domains that are inherently dynamic, sparse, and heterogeneous. We develop a two-tier architecture of probabilistic mixtures, where the lower tier leverages parametric distributions from the exponential family to extract significant behavioral patterns from each data modality. These patterns are then organized into a dynamic latent state space at the higher tier to fuse patterns from different modalities. In addition, our framework jointly performs pattern discovery and maximum-margin learning for downstream classification tasks by using a group-wise sparse prior that regularizes the coefficients of the maximum-margin classifier. Therefore, the discovered patterns are highly interpretable and discriminative to support downstream classification tasks. Experiments on real-world behavioral data from medical and psychological domains demonstrate that our framework discovers meaningful multimodal behavioral patterns with improved interpretability and prediction performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25676/25448"
"25677","Direct Heterogeneous Causal Learning for Resource Allocation Problems in Marketing","['Hao Zhou', 'Shaoming Li', 'Guibin Jiang', 'Jiaqi Zheng', 'Dong Wang']","['Meituan', 'Meituan', 'Meituan', 'Nanjing University', 'Meituan']","['APP: Business/Marketing/Advertising/E-Commerce', 'ML: Causal Learning']","Zhou, H., Li, S., Jiang, G., Zheng, J., & Wang, D. (2023). Direct Heterogeneous Causal Learning for Resource Allocation Problems in Marketing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(4), 5446-5454. https://doi.org/10.1609/aaai.v37i4.25677","Abstract 					Marketing is an important mechanism to increase user engagement and improve platform revenue, and heterogeneous causal learning can help develop more effective strategies. Most decision-making problems in marketing can be formulated as resource allocation problems and have been studied for decades. Existing works usually divide the solution procedure into two fully decoupled stages, i.e., machine learning (ML) and operation research (OR) --- the first stage predicts the model parameters and they are fed to the optimization in the second stage. However, the error of the predicted parameters in ML cannot be respected and a series of complex mathematical operations in OR lead to the increased accumulative errors. Essentially, the improved precision on the prediction parameters may not have a positive correlation on the final solution due to the side-effect from the decoupled design.  In this paper, we propose a novel approach for solving resource allocation problems to mitigate the side-effects. Our key intuition is that we introduce the decision factor to establish a bridge between ML and OR such that the solution can be directly obtained in OR by only performing the sorting or comparison operations on the decision factor. Furthermore, we design a customized loss function that can conduct direct heterogeneous causal learning on the decision factor, an unbiased estimation of which can be guaranteed when the loss convergences.  As a case study, we apply our approach to two crucial problems in marketing: the binary treatment assignment problem and the budget allocation problem with multiple treatments. Both large-scale simulations and online A/B Tests demonstrate that our approach achieves significant improvement compared with state-of-the-art.","https://ojs.aaai.org/index.php/AAAI/article/view/25677/25449"
"25678","Mediated Cheap Talk Design","['Itai Arieli', 'Ivan Geffner', 'Moshe Tennenholtz']","['Technion – Israel Institute of Technology', 'Technion – Israel Institute of Technology', 'Technion – Israel Institute of Technology']","['GTEP: Game Theory', 'GTEP: Equilibrium', 'GTEP: Mechanism Design', 'RU: Decision/Utility Theory']","Arieli, I., Geffner, I., & Tennenholtz, M. (2023). Mediated Cheap Talk Design. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5456-5463. https://doi.org/10.1609/aaai.v37i5.25678","Abstract 					We study an information design problem with two informed senders and a receiver in which, in contrast to traditional Bayesian persuasion settings, senders do not have commitment power. In our setting, a trusted mediator/platform gathers data from the senders and recommends the receiver which action to play. We characterize the set of feasible action distributions that can be obtained in equilibrium, and provide an O(n log n) algorithm (where n is the number of states) that computes the optimal equilibrium for the senders.  Additionally, we show that the optimal equilibrium for the receiver can be obtained by a simple revelation mechanism.","https://ojs.aaai.org/index.php/AAAI/article/view/25678/25450"
"25679","Bidding Graph Games with Partially-Observable Budgets","['Guy Avni', 'Ismael Jecker', 'Đorđe Žikelić']","['University of Haifa', 'University of Warsaw', 'Institute of Science and Technology Austria (ISTA)']","['GTEP: Game Theory', 'GTEP: Other Foundations of Game Theory & Economic Paradigms']","Avni, G., Jecker, I., & Žikelić, Đorđe. (2023). Bidding Graph Games with Partially-Observable Budgets. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5464-5471. https://doi.org/10.1609/aaai.v37i5.25679","Abstract 					Two-player zero-sum ""graph games"" are central in logic, verification, and multi-agent systems. The game proceeds by placing a token on a vertex of a graph, and allowing the players to move it to produce an infinite path, which determines the winner or payoff of the game. Traditionally, the players alternate turns in moving the token. In ""bidding games"", however, the players have budgets and in each turn, an auction (bidding) determines which player moves the token. So far, bidding games have only been studied as full-information games.  In this work we initiate the study of partial-information bidding games: we study bidding games in which a player's initial budget is drawn from a known probability distribution.  We show that while for some bidding mechanisms and objectives, it is straightforward to adapt the results from the full-information setting to the partial-information setting, for others, the analysis is significantly more challenging, requires new techniques, and gives rise to interesting results.  Specifically, we study games with ""mean-payoff"" objectives in combination with ""poorman"" bidding. We construct optimal strategies for a partially-informed player who plays against a fully-informed adversary. We show that, somewhat surprisingly, the ""value"" under pure strategies does not necessarily exist in such games.","https://ojs.aaai.org/index.php/AAAI/article/view/25679/25451"
"25680","Fairness Concepts for Indivisible Items with Externalities","['Haris Aziz', 'Warut Suksompong', 'Zhaohong Sun', 'Toby Walsh']","['University of New South Wales', 'National University of Singapore', 'CyberAgent', 'University of New South Wales']","['GTEP: Fair Division']","Aziz, H., Suksompong, W., Sun, Z., & Walsh, T. (2023). Fairness Concepts for Indivisible Items with Externalities. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5472-5480. https://doi.org/10.1609/aaai.v37i5.25680","Abstract 					We study a fair allocation problem of indivisible items under additive externalities in which each agent also receives utility from items that are assigned to other agents. This allows us to capture scenarios in which agents benefit from or compete against one another. We extend the well-studied properties of envy-freeness up to one item (EF1) and envy-freeness up to any item (EFX) to this setting, and we propose a new fairness concept called general fair share (GFS), which applies to a more general public decision making model. We undertake a detailed study and present algorithms for finding fair allocations.","https://ojs.aaai.org/index.php/AAAI/article/view/25680/25452"
"25681","Finding Fair Allocations under Budget Constraints","['Siddharth Barman', 'Arindam Khan', 'Sudarshan Shyam', 'K. V. N. Sreenivas']","['Indian Institute of Science', 'Indian Institute of Science', 'Aarhus University\nIndian Institute of Science', 'Indian Institute of Science']","['GTEP: Fair Division', 'GTEP: Social Choice / Voting']","Barman, S., Khan, A., Shyam, S., & Sreenivas, K. V. N. (2023). Finding Fair Allocations under Budget Constraints. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5481-5489. https://doi.org/10.1609/aaai.v37i5.25681","Abstract 					We study the fair allocation of indivisible goods among agents with identical, additive valuations but individual budget constraints. Here, the indivisible goods--each with a specific size and value--need to be allocated such that the bundle assigned to each agent is of total size at most the agent's budget. Since envy-free allocations do not necessarily exist in the indivisible goods context, compelling relaxations--in particular, the notion of envy-freeness up to k goods (EFk)--have received significant attention in recent years. In an EFk allocation, each agent prefers its own bundle over that of any other agent, up to the removal of k goods, and the agents have similarly bounded envy against the charity (which corresponds to the set of all unallocated goods). It has been shown in prior work that an allocation that satisfies the budget constraints and maximizes the Nash social welfare is 1/4-approximately EF1. However, the computation (or even existence) of exact EFk allocations remained an intriguing open problem.  We make notable progress towards this by proposing a simple, greedy, polynomial-time algorithm that computes EF2 allocations under budget constraints. Our algorithmic result  implies the universal existence of EF2 allocations in this fair division context. The analysis of the algorithm exploits intricate structural properties of envy-freeness. Interestingly, the same algorithm also provides EF1 guarantees for important special cases. Specifically, we settle the existence of EF1 allocations for instances in which: (i) the value of each good is proportional to its size, (ii) all the goods have the same size, or (iii) all the goods have the same value. Our EF2 result even extends to the setting wherein the goods' sizes are agent specific.","https://ojs.aaai.org/index.php/AAAI/article/view/25681/25453"
"25682","Now We’re Talking: Better Deliberation Groups through Submodular Optimization","['Jake Barrett', 'Kobi Gal', 'Paul Gölz', 'Rose M. Hong', 'Ariel D. Procaccia']","['University of Edinburgh', 'University of Edinburgh\nBen-Gurion University of the Negev', 'Harvard University', 'Harvard University', 'Harvard University']","['GTEP: Social Choice / Voting', 'SO: Applications']","Barrett, J., Gal, K., Gölz, P., Hong, R. M., & Procaccia, A. D. (2023). Now We’re Talking: Better Deliberation Groups through Submodular Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5490-5498. https://doi.org/10.1609/aaai.v37i5.25682","Abstract 					Citizens’ assemblies are groups of randomly selected constituents who are tasked with providing recommendations on policy questions. Assembly members form their recommendations through a sequence of discussions in small groups (deliberation), in which group members exchange arguments and experiences. We seek to support this process through optimization, by studying how to assign participants to discussion groups over multiple sessions, in a way that maximizes interaction between participants and satisfies diversity constraints within each group. Since repeated meetings between a given pair of participants have diminishing marginal returns, we capture interaction through a submodular function, which is approximately optimized by a greedy algorithm making calls to an ILP solver. This framework supports different submodular objective functions, and we identify sensible options, but we also show it is not necessary to commit to a particular choice: Our main theoretical result is a (practically efficient) algorithm that simultaneously approximates every possible objective function of the form we are interested in. Experiments with data from real citizens' assemblies demonstrate that our approach substantially outperforms the heuristic algorithm currently used by practitioners.","https://ojs.aaai.org/index.php/AAAI/article/view/25682/25454"
"25683","Causes of Stability in Dynamic Coalition Formation","['Niclas Boehmer', 'Martin Bullinger', 'Anna Maria Kerkmann']","['Technische Universität Berlin', 'Technische Universität München', 'Heinrich-Heine-Universität Düsseldorf']","['GTEP: Cooperative Game Theory', 'GTEP: Coordination and Collaboration', 'GTEP: Social Choice / Voting']","Boehmer, N., Bullinger, M., & Kerkmann, A. M. (2023). Causes of Stability in Dynamic Coalition Formation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5499-5506. https://doi.org/10.1609/aaai.v37i5.25683","Abstract 					We study the formation of stable outcomes via simple dynamics in cardinal hedonic games, where the utilities of agents change over time depending on the history of the coalition formation process. Specifically, we analyze situations where members of a coalition decrease their utility for a leaving agent (resent) or increase their utility for a joining agent (appreciation). We show that in contrast to classical dynamics, for resentful or appreciative agents, dynamics are guaranteed to converge under mild conditions for various stability concepts. Thereby, we establish that both resent and appreciation are strong stability-driving forces.","https://ojs.aaai.org/index.php/AAAI/article/view/25683/25455"
"25684","Properties of Position Matrices and Their Elections","['Niclas Boehmer', 'Jin-Yi Cai', 'Piotr Faliszewski', 'Austen Z. Fan', 'Łukasz Janeczko', 'Andrzej Kaczmarczyk', 'Tomasz Wąs']","['Algorithmics and Computational Complexity, Technische Universität Berlin', 'University of Wisconsin-Madison', 'AGH University', 'University of Wisconsin-Madison', 'AGH University', 'AGH University', 'AGH University\nPennsylvania State University']","['GTEP: Social Choice / Voting']","Boehmer, N., Cai, J.-Y., Faliszewski, P., Fan, A. Z., Janeczko, Łukasz, Kaczmarczyk, A., & Wąs, T. (2023). Properties of Position Matrices and Their Elections. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5507-5514. https://doi.org/10.1609/aaai.v37i5.25684","Abstract 					We study the properties of elections that have a given position matrix (in such elections each candidate is ranked on each position by a number of voters specified in the matrix).  We show that counting elections that generate a given position matrix is #P-complete. Consequently, sampling such elections uniformly at random seems challenging and we propose a simpler algorithm, without hard guarantees. Next, we consider the problem of testing if a given matrix can be implemented by an election with a certain structure (such as single-peakedness or group-separability). Finally, we consider the problem of checking if a given position matrix can be implemented by an election with a Condorcet winner.  We complement our theoretical findings with experiments.","https://ojs.aaai.org/index.php/AAAI/article/view/25684/25456"
"25685","Rank Aggregation Using Scoring Rules","['Niclas Boehmer', 'Robert Bredereck', 'Dominik Peters']","['Algorithmics and Computational Complexity, Technische Universität Berlin', 'Institut für Informatik, TU Clausthal', 'LAMSADE, Université Paris Dauphine-PSL']","['GTEP: Social Choice / Voting']","Boehmer, N., Bredereck, R., & Peters, D. (2023). Rank Aggregation Using Scoring Rules. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5515-5523. https://doi.org/10.1609/aaai.v37i5.25685","Abstract 					To aggregate rankings into a social ranking, one can use scoring systems such as Plurality, Veto, and Borda. We distinguish three types of methods: ranking by score, ranking by repeatedly choosing a winner that we delete and rank at the top, and ranking by repeatedly choosing a loser that we delete and rank at the bottom. The latter method captures the frequently studied voting rules Single Transferable Vote (aka Instant Runoff Voting), Coombs, and Baldwin. In an experimental analysis, we show that the three types of methods produce different rankings in practice. We also provide evidence that sequentially selecting winners is most suitable to detect the ""true"" ranking of candidates. For different rules in our classes, we then study the (parameterized) computational complexity of deciding in which positions a given candidate can appear in the chosen ranking. As part of our analysis, we also consider the Winner Determination problem for STV, Coombs, and Baldwin and determine their complexity when there are few voters or candidates.","https://ojs.aaai.org/index.php/AAAI/article/view/25685/25457"
"25686","Proportionality in Approval-Based Participatory Budgeting","['Markus Brill', 'Stefan Forster', 'Martin Lackner', 'Jan Maly', 'Jannik Peters']","['University of Warwick\nTU Berlin', 'TU Wien', 'TU Wien', 'University of Amsterdam', 'TU Berlin']","['GTEP: Social Choice / Voting']","Brill, M., Forster, S., Lackner, M., Maly, J., & Peters, J. (2023). Proportionality in Approval-Based Participatory Budgeting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5524-5531. https://doi.org/10.1609/aaai.v37i5.25686","Abstract 					The ability to measure the satisfaction of (groups of) voters is a crucial prerequisite for formulating proportionality axioms in approval-based participatory budgeting elections. Two common -- but very different -- ways to measure the satisfaction of a voter consider (i) the number of approved projects and (ii) the total cost of approved projects, respectively. In general, it is difficult to decide which measure of satisfaction best reflects the voters' true utilities. In this paper, we study proportionality axioms with respect to large classes of approval-based satisfaction functions. We establish logical implications among our axioms and related notions from the literature, and we ask whether outcomes can be achieved that are proportional with respect to more than one satisfaction function. We show that this is impossible for the two commonly used satisfaction functions when considering proportionality notions based on extended justified representation, but achievable for a notion based on proportional justified representation. For the latter result, we introduce a strengthening of priceability and show that it is satisfied by several polynomial-time computable rules, including the Method of Equal Shares and Phragmén's sequential rule.","https://ojs.aaai.org/index.php/AAAI/article/view/25686/25458"
"25687","Multiwinner Voting with Possibly Unavailable Candidates","['Markus Brill', 'Hayrullah Dindar', 'Jonas Israel', 'Jérôme Lang', 'Jannik Peters', 'Ulrike Schmidt-Kraepelin']","['University of Warwick\nTechnische Universität Berlin', 'Technische Universität Berlin', 'Technische Universität Berlin', 'CNRS', 'Technische Universität Berlin', 'Technische Universität Berlin']","['GTEP: Social Choice / Voting', 'GTEP: Game Theory', 'GTEP: Other Foundations of Game Theory & Economic Paradigms']","Brill, M., Dindar, H., Israel, J., Lang, J., Peters, J., & Schmidt-Kraepelin, U. (2023). Multiwinner Voting with Possibly Unavailable Candidates. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5532-5539. https://doi.org/10.1609/aaai.v37i5.25687","Abstract 					Selecting a committee that meets diversity and proportionality criteria is a challenging endeavor that has been studied extensively in recent years. This task becomes even more challenging when some of the selected candidates decline the invitation to join the committee. Since the unavailability of one candidate may impact the rest of the selection, inviting all candidates at the same time may lead to a suboptimal committee. Instead, invitations should be sequential and conditional on which candidates invited so far accepted the invitation: the solution to the committee selection problem is a query policy. If invitation queries are binding, they should be safe: one should not query a candidate without being sure that whatever the set of available candidates possible at that stage, her inclusion will not jeopardize committee optimality. Assuming approval-based inputs, we characterize the set of rules for which a safe query exists at every stage. In order to parallelize the invitation process, we investigate the computation of safe parallel queries, and show that it is often hard. We also study the existence of safe parallel queries with respect to proportionality axioms such as extended justified representation.","https://ojs.aaai.org/index.php/AAAI/article/view/25687/25459"
"25688","Fair Division with Prioritized Agents","['Xiaolin Bu', 'Zihao Li', 'Shengxin Liu', 'Jiaxin Song', 'Biaoshuai Tao']","['Shanghai Jiao Tong University', 'Nanyang Technological University', 'Harbin Institute of Technology, Shenzhen', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['GTEP: Fair Division']","Bu, X., Li, Z., Liu, S., Song, J., & Tao, B. (2023). Fair Division with Prioritized Agents. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5540-5548. https://doi.org/10.1609/aaai.v37i5.25688","Abstract 					We consider the fair division problem of indivisible items. It is well-known that an envy-free allocation may not exist, and a relaxed version of envy-freeness, envy-freeness up to one item (EF1), has been widely considered. In an EF1 allocation, an agent may envy others' allocated shares, but only up to one item. In many applications, we may wish to specify a subset of prioritized agents where strict envy-freeness needs to be guaranteed from these agents to the remaining agents, while ensuring the whole allocation is still EF1. Prioritized agents may be those agents who are envious in a previous EF1 allocation, those agents who belong to underrepresented groups, etc. Motivated by this, we propose a new fairness notion named envy-freeness with prioritized agents EFprior, and study the existence and the algorithmic aspects for the problem of computing an EFprior allocation. With additive valuations, the simple round-robin algorithm is able to compute an EFprior allocation. In this paper, we mainly focus on general valuations. In particular, we present a polynomial-time algorithm that outputs an EFprior allocation with most of the items allocated. When all the items need to be allocated, we also present polynomial-time algorithms for some well-motivated special cases.","https://ojs.aaai.org/index.php/AAAI/article/view/25688/25460"
"25689","Topological Distance Games","['Martin Bullinger', 'Warut Suksompong']","['Technical University of Munich', 'National University of Singapore']","['GTEP: Cooperative Game Theory']","Bullinger, M., & Suksompong, W. (2023). Topological Distance Games. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5549-5556. https://doi.org/10.1609/aaai.v37i5.25689","Abstract 					We introduce a class of strategic games in which agents are assigned to nodes of a topology graph and the utility of an agent depends on both the agent's inherent utilities for other agents as well as her distance from these agents on the topology graph. This model of topological distance games (TDGs) offers an appealing combination of important aspects of several prominent settings in coalition formation, including (additively separable) hedonic games, social distance games, and Schelling games. We study the existence and complexity of stable outcomes in TDGs—for instance, while a jump stable assignment may not exist in general, we show that the existence is guaranteed in several special cases. We also investigate the dynamics induced by performing beneficial jumps.","https://ojs.aaai.org/index.php/AAAI/article/view/25689/25461"
"25690","Game Implementation: What Are the Obstructions?","['Jiehua Chen', 'Seyedeh Negar Layegh Khavidaki', 'Sebastian Vincent Haydn', 'Sofia Simola', 'Manuel Sorge']","['TU Wien', 'TU Wien', 'TU Wien', 'TU Wien', 'TU Wien']","['GTEP: Game Theory', 'CSO: Applications', 'GTEP: Mechanism Design', 'MAS: Applications', 'SO: Applications']","Chen, J., Layegh Khavidaki, S. N., Haydn, S. V., Simola, S., & Sorge, M. (2023). Game Implementation: What Are the Obstructions?. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5557-5564. https://doi.org/10.1609/aaai.v37i5.25690","Abstract 					In many applications, we want to influence the decisions of independent agents by designing incentives for their actions. We revisit a fundamental problem in this area, called GAME IMPLEMENTATION: Given a game in standard form and a set of desired strategies, can we design a set of payment promises such that if the players take the payment promises into account, then all undominated strategies are desired? Furthermore, we aim to minimize the cost, that is, the worst-case amount of payments.  We study the tractability of computing such payment promises and determine more closely what obstructions we may have to overcome in doing so. We show that GAME IMPLEMENTATION is NP-hard even for two players, solving in particular a long-standing open question and suggesting more restrictions are necessary to obtain tractability results. We thus study the regime in which players have only a small constant number of strategies and obtain the following. First, this case remains NP-hard even if each player’s utility depends only on three others. Second, we repair a flawed efficient algorithm for the case of both small number of strategies and small number of players. Among further results, we characterize sets of desired strategies that can be implemented at zero cost as a generalization of Nash equilibria.","https://ojs.aaai.org/index.php/AAAI/article/view/25690/25462"
"25691","A Pair-Approximation Method for Modelling the Dynamics of Multi-Agent Stochastic Games","['Chen Chu', 'Zheng Yuan', 'Shuyue Hu', 'Chunjiang Mu', 'Zhen Wang']","['School of Statistics and Mathematics, Yunnan University of Finance and Economics\nSchool of Artificial Intelligence, Optics and Electronics (iOPEN), Northwestern Polytechnical University', 'School of Statistics and Mathematics, Yunnan University of Finance and Economics', 'Shanghai Artificial Intelligence Laboratory', 'Northwestern Polytechnical University', 'Northwestern Polytechnical University']","['GTEP: Game Theory', 'MAS: Agent-Based Simulation and Emergent Behavior']","Chu, C., Yuan, Z., Hu, S., Mu, C., & Wang, Z. (2023). A Pair-Approximation Method for Modelling the Dynamics of Multi-Agent Stochastic Games. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5565-5572. https://doi.org/10.1609/aaai.v37i5.25691","Abstract 					Developing a dynamical model for learning in games has attracted much recent interest. In stochastic games, agents need to make decisions in multiple states, and transitions between states, in turn, influence the dynamics of strategies. While previous works typically focus either on 2-agent stochastic games or on normal form games under an infinite-agent setting, we aim at formally modelling the learning dynamics in stochastic games under the infinite-agent setting. With a novel use of pair-approximation method, we develop a formal model for myopic Q-learning in stochastic games with symmetric state transition. We verify the descriptive power of our model (a partial differential equation) across various games through comparisons with agent-based simulation results. Based on our proposed model, we can gain qualitative and quantitative insights into the influence of transition probabilities on the dynamics of strategies. In particular, we illustrate that a careful design of transition probabilities can help players overcome the social dilemmas and promote cooperation, even if agents are myopic learners.","https://ojs.aaai.org/index.php/AAAI/article/view/25691/25463"
"25692","Complexity of Probabilistic Inference in Random Dichotomous Hedonic Games","['Saar Cohen', 'Noa Agmon']","['Department of Computer Science, Bar-Ilan University, Israel', 'Department of Computer Science, Bar-Ilan University, Israel']","['GTEP: Cooperative Game Theory', 'GTEP: Coordination and Collaboration', 'GTEP: Social Choice / Voting', 'MAS: Coordination and Collaboration', 'MAS: Multiagent Systems Under Uncertainty', 'RU: Stochastic Models & Probabilistic Inference']","Cohen, S., & Agmon, N. (2023). Complexity of Probabilistic Inference in Random Dichotomous Hedonic Games. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5573-5581. https://doi.org/10.1609/aaai.v37i5.25692","Abstract 					Hedonic games model cooperative games where agents desire to form coalitions, and only care about the composition of the coalitions of which they are members. Focusing on various classes of dichotomous hedonic games, where each agent either approves or disapproves a given coalition, we propose the random extension, where players have an independent participation probability. We initiate the research on the computational complexity of computing the probability that coalitions and partitions are optimal or stable. While some cases admit efficient algorithms (e.g., agents approve only few coalitions), they become computationally hard (#P-hard) in their complementary scenario. We then investigate the distribution of coalitions in perfect partitions and their performance in majority games, where an agent approves coalitions in which the agent is friends with the majority of its members. When friendships independently form with a constant probability, we prove that the number of coalitions of size 3 converges in distribution to a Poisson random variable.","https://ojs.aaai.org/index.php/AAAI/article/view/25692/25464"
"25693","Combinatorial Civic Crowdfunding with Budgeted Agents: Welfare Optimality at Equilibrium and Optimal Deviation","['Sankarshan Damle', 'Manisha Padala', 'Sujit Gujar']","['Machine Learning Lab, International Institute of Information Technology, Hyderabad', 'Machine Learning Lab, International Institute of Information Technology, Hyderabad', 'Machine Learning Laboratory, International Institute of Information Technology, Hyderabad']","['GTEP: Applications', 'GTEP: Other Foundations of Game Theory & Economic Paradigms']","Damle, S., Padala, M., & Gujar, S. (2023). Combinatorial Civic Crowdfunding with Budgeted Agents: Welfare Optimality at Equilibrium and Optimal Deviation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5582-5590. https://doi.org/10.1609/aaai.v37i5.25693","Abstract 					Civic Crowdfunding (CC) uses the ``power of the crowd"" to garner contributions towards public projects. As these projects are non-excludable, agents may prefer to ``free-ride,""  resulting in the project not being funded. Researchers introduce refunds for single project CC to incentivize agents to contribute, guaranteeing the project's funding. These funding guarantees are applicable only when agents have an unlimited budget. This paper focuses on a combinatorial setting, where multiple projects are available for CC and agents have a limited budget. We study specific conditions where funding can be guaranteed. Naturally, funding the optimal social welfare subset of projects is desirable when every available project cannot be funded due to budget restrictions. We prove the impossibility of achieving optimal welfare at equilibrium for any monotone refund scheme. Further, given the contributions of other agents, we prove that it is NP-Hard for an agent to determine its optimal strategy. That is, while profitable deviations may exist for agents instead of funding the optimal welfare subset, it is computationally hard for an agent to find its optimal deviation. Consequently, we study different heuristics agents can use to contribute to the projects in practice. We demonstrate the heuristics' performance as the average-case trade-off between the welfare obtained and an agent's utility through simulations.","https://ojs.aaai.org/index.php/AAAI/article/view/25693/25465"
"25694","Strategyproofness and Proportionality in Party-Approval Multiwinner Elections","['Théo Delemazure', 'Tom Demeulemeester', 'Manuel Eberl', 'Jonas Israel', 'Patrick Lederer']","['Paris Dauphine University', 'KU Leuven', 'University of Innsbruck', 'Technische Universität Berlin', 'Technische Universität München']","['GTEP: Social Choice / Voting']","Delemazure, T., Demeulemeester, T., Eberl, M., Israel, J., & Lederer, P. (2023). Strategyproofness and Proportionality in Party-Approval Multiwinner Elections. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5591-5599. https://doi.org/10.1609/aaai.v37i5.25694","Abstract 					In party-approval multiwinner elections the goal is to allocate the seats of a fixed-size committee to parties based on the approval ballots of the voters over the parties. In particular, each voter can approve multiple parties and each party can be assigned multiple seats. Two central requirements in this setting are proportional representation and strategyproofness. Intuitively, proportional representation requires that every sufficiently large group of voters with similar preferences is represented in the committee. Strategyproofness demands that no voter can benefit by misreporting her true preferences. We show that these two axioms are incompatible for anonymous party-approval multiwinner voting rules, thus proving a far-reaching impossibility theorem. The proof of this result is obtained by formulating the problem in propositional logic and then letting a SAT solver show that the formula is unsatisfiable. Additionally, we demonstrate how to circumvent this impossibility by considering a weakening of strategyproofness which requires that only voters who do not approve any elected party cannot manipulate. While most common voting rules fail even this weak notion of strategyproofness, we characterize Chamberlin-Courant approval voting within the class of Thiele rules based on this strategyproofness notion.","https://ojs.aaai.org/index.php/AAAI/article/view/25694/25466"
"25695","Tight Inapproximability for Graphical Games","['Argyrios Deligkas', 'John Fearnley', 'Alexandros Hollender', 'Themistoklis Melissourgos']","['Royal Holloway University of London', 'University of Liverpool', 'EPFL', 'University of Essex']","['GTEP: Game Theory', 'GTEP: Equilibrium']","Deligkas, A., Fearnley, J., Hollender, A., & Melissourgos, T. (2023). Tight Inapproximability for Graphical Games. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5600-5607. https://doi.org/10.1609/aaai.v37i5.25695","Abstract 					We provide a complete characterization for the computational complexity of finding approximate equilibria in two-action graphical games. We consider the two most well-studied approximation notions: ε-Nash equilibria (ε-NE) and ε-well-supported Nash equilibria (ε-WSNE), where ε is in [0,1]. We prove that computing an ε-NE is PPAD-complete for any constant ε smaller than 1/2, while a very simple algorithm (namely, letting all players mix uniformly between their two actions) yields a 1/2-NE. On the other hand, we show that computing an ε-WSNE is PPAD-complete for any constant ε smaller than 1, while a 1-WSNE is trivial to achieve, because any strategy profile is a 1-WSNE. All of our lower bounds immediately also apply to graphical games with more than two actions per player.","https://ojs.aaai.org/index.php/AAAI/article/view/25695/25467"
"25696","From Monopoly to Competition: Optimal Contests Prevail","['Xiaotie Deng', 'Yotam Gafni', 'Ron Lavi', 'Tao Lin', 'Hongyi Ling']","['Peking University', 'Technion - Israel Institute of Technology', 'University of Bath, UK', 'Harvard University', 'ETH Zurich']","['GTEP: Auctions and Market-Based Systems', 'GTEP: Mechanism Design']","Deng, X., Gafni, Y., Lavi, R., Lin, T., & Ling, H. (2023). From Monopoly to Competition: Optimal Contests Prevail. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5608-5615. https://doi.org/10.1609/aaai.v37i5.25696","Abstract 					We study competition among contests in a general model that allows for an arbitrary and heterogeneous space of contest design and symmetric contestants. The goal of the contest designers is to maximize the contestants' sum of efforts. Our main result shows that optimal contests in the monopolistic setting (i.e., those that maximize the sum of efforts in a model with a single contest) form an equilibrium in the model with competition among contests. Under a very natural assumption these contests are in fact dominant, and the equilibria that they form are unique. Moreover, equilibria with the optimal contests are Pareto-optimal even in cases where other equilibria emerge. In many natural cases, they also maximize the social welfare.","https://ojs.aaai.org/index.php/AAAI/article/view/25696/25468"
"25697","Commitment Games with Conditional Information Disclosure","['Anthony DiGiovanni', 'Jesse Clifton']","['Center on Long-Term Risk', 'Center on Long-Term Risk']","['GTEP: Game Theory', 'GTEP: Equilibrium']","DiGiovanni, A., & Clifton, J. (2023). Commitment Games with Conditional Information Disclosure. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5616-5623. https://doi.org/10.1609/aaai.v37i5.25697","Abstract 					The conditional commitment abilities of mutually transparent computer agents have been studied in previous work on commitment games and program equilibrium. This literature has shown how these abilities can help resolve Prisoner’s Dilemmas and other failures of cooperation in complete information settings. But inefficiencies due to private information have been neglected thus far in this literature, despite the fact that these problems are pervasive and might also be addressed by greater mutual transparency. In this work, we introduce a framework for commitment games with a new kind of conditional commitment device, which agents can use to conditionally disclose private information. We prove a folk theorem for this setting that provides sufficient conditions for ex post efficiency, and thus represents a model of ideal cooperation between agents without a third-party mediator. Further, extending previous work on program equilibrium, we develop an implementation of conditional information disclosure. We show that this implementation forms program ε-Bayesian Nash equilibria corresponding to the Bayesian Nash equilibria of these commitment games.","https://ojs.aaai.org/index.php/AAAI/article/view/25697/25469"
"25698","Rawlsian Fairness in Online Bipartite Matching: Two-Sided, Group, and Individual","['Seyed Esmaeili', 'Sharmila Duppala', 'Davidson Cheng', 'Vedant Nanda', 'Aravind Srinivasan', 'John P. Dickerson']","['University of Maryland, College Park', 'University of Maryland, College Park', 'Colorado College', 'University of Maryland, College Park', 'University of Maryland College Park', 'University of Maryland']","['GTEP: Auctions and Market-Based Systems', 'ML: Bias and Fairness', 'MAS: Applications']","Esmaeili, S., Duppala, S., Cheng, D., Nanda, V., Srinivasan, A., & Dickerson, J. P. (2023). Rawlsian Fairness in Online Bipartite Matching: Two-Sided, Group, and Individual. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5624-5632. https://doi.org/10.1609/aaai.v37i5.25698","Abstract 					Online bipartite-matching platforms are ubiquitous and find applications in important areas such as crowdsourcing and ridesharing. In the most general form, the platform consists of three entities: two sides to be matched and a platform operator that decides the matching. The design of algorithms for such platforms has traditionally focused on the operator’s (expected) profit. Since fairness has become an important consideration that was ignored in the existing algorithms a collection of online matching algorithms have been developed that give a fair treatment guarantee for one side of the market at the expense of a drop in the operator’s profit. In this paper, we generalize the existing work to offer fair treatment guarantees to both sides of the market simultaneously, at a calculated worst case drop to operator profit. We consider group and individual Rawlsian fairness criteria. Moreover, our algorithms have theoretical guarantees and have adjustable parameters that can be tuned as desired to balance the trade-off between the utilities of the three sides. We also derive hardness results that give clear upper bounds over the performance of any algorithm.","https://ojs.aaai.org/index.php/AAAI/article/view/25698/25470"
"25699","Participatory Budgeting Designs for the Real World","['Roy Fairstein', 'Gerdus Benadè', 'Kobi Gal']","['Ben-Gurion University of the Negev, Israel', 'Boston University, USA', 'Ben-Gurion University of the Negev, Israel\nUniversity of Edinburgh, UK']","['GTEP: Social Choice / Voting', 'APP: Energy', 'Environment & Sustainability', 'HAI: Human-Computer Interaction']","Fairstein, R., Benadè, G., & Gal, K. (2023). Participatory Budgeting Designs for the Real World. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5633-5640. https://doi.org/10.1609/aaai.v37i5.25699","Abstract 					Participatory budgeting engages the public in the process of allocating public money to different types of projects. PB designs differ in how voters are asked to express their preferences over candidate projects and how these preferences are aggregated to determine which projects to fund. This paper studies two fundamental questions in PB design. Which voting format and aggregation method to use, and how to evaluate the outcomes of these design decisions? We conduct an extensive empirical study in which 1 800 participants vote in four participatory budgeting elections in a controlled setting to evaluate the practical effects of the choice of voting format and aggregation rule.We find that k-approval leads to the best user experience. With respect to the aggregation rule, greedy aggregation leads to outcomes that are highly sensitive to the input format used and the fraction of the population that participates. The method of equal shares, in contrast, leads to outcomes that are not sensitive to the type of voting format used, and these outcomes are remarkably stable even when the majority of the population does not participate in the election. These results carry valuable insights for PB practitioners and social choice researchers.","https://ojs.aaai.org/index.php/AAAI/article/view/25699/25471"
"25700","PAC Learning and Stabilizing Hedonic Games: Towards a Unifying Approach.","['Simone Fioravanti', 'Michele Flammini', 'Bojana Kodric', 'Giovanna Varricchio']","[""Gran Sasso Science Institute (GSSI), L'Aquila, Italy"", ""Gran Sasso Science Institute (GSSI), L'Aquila, Italy\nUniversity of Calabria, Rende, Italy"", ""Ca’ Foscari University of Venice, Venice, Italy\nGran Sasso Science Institute (GSSI), L'Aquila, Italy"", 'Goethe-Universität, Frankfurt am Main, Germany']","['GTEP: Game Theory', 'GTEP: Social Choice / Voting', 'ML: Learning Theory', 'MAS: Multiagent Learning']","Fioravanti, S., Flammini, M., Kodric, B., & Varricchio, G. (2023). PAC Learning and Stabilizing Hedonic Games: Towards a Unifying Approach. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5641-5648. https://doi.org/10.1609/aaai.v37i5.25700","Abstract 					We study PAC learnability and PAC stabilizability of Hedonic Games (HGs), i.e., efficiently inferring preferences or core-stable partitions from samples. We first expand the known learnability/stabilizability landscape for some of the most prominent HGs classes, providing results for Friends and Enemies Games, Bottom Responsive, and Anonymous HGs. Then, having a broader view in mind, we attempt to shed light on the structural properties leading to learnability/stabilizability, or lack thereof, for specific HGs classes. Along this path, we focus on the fully expressive Hedonic Coalition Nets representation of HGs. We identify two sets of conditions that lead to efficient learnability, and which encompass all of the known positive learnability results. On the side of stability, we reveal that, while the freedom of choosing an ad hoc adversarial distribution is the most obvious hurdle to achieving PAC stability, it is not the only one. First, we show a distribution independent necessary condition for PAC stability. Then, we focus on W-games, where players have individual preferences over other players and evaluate coalitions based on the least preferred member. We prove that these games are PAC stabilizable under the class of bounded distributions, which assign positive probability mass to all coalitions. Finally, we discuss why such a result is not easily extendable to other HGs classes even in this promising scenario. Namely, we establish a purely computational property necessary for achieving PAC stability.","https://ojs.aaai.org/index.php/AAAI/article/view/25700/25472"
"25701","Scalable Edge Blocking Algorithms for Defending Active Directory Style Attack Graphs","['Mingyu Guo', 'Max Ward', 'Aneta Neumann', 'Frank Neumann', 'Hung Nguyen']","['University of Adelaide', 'University of Western Australia\nHarvard University', 'University of Adelaide', 'University of Adelaide', 'University of Adelaide']","['GTEP: Applications', 'APP: Security', 'MAS: Applications', 'ML: Optimization']","Guo, M., Ward, M., Neumann, A., Neumann, F., & Nguyen, H. (2023). Scalable Edge Blocking Algorithms for Defending Active Directory Style Attack Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5649-5656. https://doi.org/10.1609/aaai.v37i5.25701","Abstract 					Active Directory (AD) is the default security management system for Windows domain networks.  An AD environment naturally describes an attack graph where nodes represent computers/accounts/security groups, and edges represent existing accesses/known exploits that allow the attacker to gain access from one node to another.  Motivated by practical AD use cases, we study a Stackelberg game between one attacker and one defender.  There are multiple entry nodes for the attacker to choose from and there is a single target (Domain Admin).  Every edge has a failure rate.  The attacker chooses the attack path with the maximum success rate.  The defender can block a limited number of edges (i.e., revoke accesses) from a set of blockable edges, limited by budget. The defender's aim is to minimize the attacker's success rate.  We exploit the tree-likeness of practical AD graphs to design scalable algorithms.  We propose two novel methods that combine theoretical fixed parameter analysis and practical optimisation techniques.  For graphs with small tree widths, we propose a tree decomposition based dynamic program.  We then propose a general method for converting tree decomposition based dynamic programs to reinforcement learning environments, which leads to an anytime algorithm that scales better, but loses the optimality guarantee.  For graphs with small numbers of non-splitting paths (a parameter we invent specifically for AD graphs), we propose a kernelization technique that significantly downsizes the model, which is then solved via mixed-integer programming.  Experimentally, our algorithms scale to handle synthetic AD graphs with tens of thousands of nodes.","https://ojs.aaai.org/index.php/AAAI/article/view/25701/25473"
"25702","Representation with Incomplete Votes","['Daniel Halpern', 'Gregory Kehne', 'Ariel D. Procaccia', 'Jamie Tucker-Foltz', 'Manuel Wüthrich']","['Harvard University', 'Harvard University', 'Harvard', 'Harvard University', 'Harvard University']","['GTEP: Social Choice / Voting']","Halpern, D., Kehne, G., Procaccia, A. D., Tucker-Foltz, J., & Wüthrich, M. (2023). Representation with Incomplete Votes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5657-5664. https://doi.org/10.1609/aaai.v37i5.25702","Abstract 					Platforms for online civic participation rely heavily on methods for condensing thousands of comments into a relevant handful, based on whether participants agree or disagree with them. These methods should guarantee fair representation of the participants, as their outcomes may affect the health of the conversation and inform impactful downstream decisions. To that end, we draw on the literature on approval-based committee elections. Our setting is novel in that the approval votes are incomplete since participants will typically not vote on all comments. We prove that this complication renders non-adaptive algorithms impractical in terms of the amount of information they must gather. Therefore, we develop an adaptive algorithm that uses information more efficiently by presenting incoming participants with statements that appear promising based on votes by previous participants. We prove that this method satisfies commonly used notions of fair representation, even when participants only vote on a small fraction of comments. Finally, an empirical evaluation using real data shows that the proposed algorithm provides representative outcomes in practice.","https://ojs.aaai.org/index.php/AAAI/article/view/25702/25474"
"25703","Optimizing Multiple Simultaneous Objectives for Voting and Facility Location","['Yue Han', 'Christopher Jerrett', 'Elliot Anshelevich']","['Rensselaer Polytechnic Institute', 'Rensselaer Polytechnic Institute', 'Rensselaer Polytechnic Institute']","['GTEP: Social Choice / Voting']","Han, Y., Jerrett, C., & Anshelevich, E. (2023). Optimizing Multiple Simultaneous Objectives for Voting and Facility Location. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5665-5672. https://doi.org/10.1609/aaai.v37i5.25703","Abstract 					We study the classic facility location setting, where we are given n clients and m possible facility locations in some arbitrary metric space, and want to choose a location to build a facility. The exact same setting also arises in spatial social choice, where voters are the clients and the goal is to choose a candidate or outcome, with the distance from a voter to an outcome representing the cost of this outcome for the voter (e.g., based on their ideological differences). Unlike most previous work, we do not focus on a single objective to optimize (e.g., the total distance from clients to the facility, or the maximum distance, etc.), but instead attempt to optimize several different objectives simultaneously. More specifically, we consider the l-centrum family of objectives, which includes the total distance, max distance, and many others. We present tight bounds on how well any pair of such objectives (e.g., max and sum) can be simultaneously approximated compared to their optimum outcomes. In particular, we show that for any such pair of objectives, it is always possible to choose an outcome which simultaneously approximates both objectives within a factor of 1 plus square root of 2, and give a precise characterization of how this factor improves as the two objectives being optimized become more similar. For q>2 different centrum objectives, we show that it is always possible to approximate all q of these objectives within a small constant, and that this constant approaches 3 as q increases. Our results show that when optimizing only a few simultaneous objectives, it is always possible to form an outcome which is a significantly better than 3 approximation for all of these objectives.","https://ojs.aaai.org/index.php/AAAI/article/view/25703/25475"
"25704","Class Fairness in Online Matching","['Hadi Hosseini', 'Zhiyi Huang', 'Ayumi Igarashi', 'Nisarg Shah']","['Pennsylvania State University', 'University of Hong Kong', 'University of Tokyo', 'University of Toronto']","['GTEP: Fair Division', 'GTEP: Mechanism Design', 'GTEP: Social Choice / Voting']","Hosseini, H., Huang, Z., Igarashi, A., & Shah, N. (2023). Class Fairness in Online Matching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5673-5680. https://doi.org/10.1609/aaai.v37i5.25704","Abstract 					We initiate the study of fairness among classes of agents in online bipartite matching where there is a given set of offline vertices (aka agents) and another set of vertices (aka items) that arrive online and must be matched irrevocably upon arrival. In this setting, agents are partitioned into a set of classes and the matching is required to be fair with respect to the classes. We adopt popular fairness notions (e.g. envy-freeness, proportionality, and maximin share) and their relaxations to this setting and study deterministic and randomized algorithms for matching indivisible items (leading to integral matchings) and for matching divisible items (leading to fractional matchings). For matching indivisible items, we propose an adaptive-priority-based algorithm, MATCH-AND-SHIFT, prove that it achieves (1/2)-approximation of both class envy-freeness up to one item and class maximin share fairness, and show that each guarantee is tight. For matching divisible items, we design a water-filling-based algorithm, EQUAL-FILLING, that achieves (1-1/e)-approximation of class envy-freeness and class proportionality; we prove (1-1/e) to be tight for class proportionality and establish a 3/4 upper bound on class envy-freeness.","https://ojs.aaai.org/index.php/AAAI/article/view/25704/25476"
"25705","How to Cut a Discrete Cake Fairly","['Ayumi Igarashi']","['The University of Tokyo']","['GTEP: Fair Division', 'GTEP: Social Choice / Voting']","Igarashi, A. (2023). How to Cut a Discrete Cake Fairly. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5681-5688. https://doi.org/10.1609/aaai.v37i5.25705","Abstract 					Cake-cutting is a fundamental model of dividing a heterogeneous resource, such as land, broadcast time, and advertisement space. In this study, we consider the problem of dividing indivisible goods fairly under the connectivity constraints of a path. We prove that a connected division of indivisible items satisfying a discrete counterpart of envy-freeness, called envy-freeness up to one good (EF1), always exists for any number of agents n with monotone valuations. Our result settles an open question raised by Bilò et al. (2019), who proved that an EF1 connected division always exists for four agents with monotone valuations. Moreover, the proof can be extended to show the following (1) ``secretive"" and (2) ``extra"" versions: (1) for n agents with monotone valuations, the path can be divided into n connected bundles such that an EF1 assignment of the remaining bundles can be made to the other agents for any selection made by the “secretive agent”; (2) for n+1 agents with monotone valuations, the path can be divided into n connected bundles such that when any ``extra agent” leaves, an EF1 assignment of the bundles can be made to the remaining agents.","https://ojs.aaai.org/index.php/AAAI/article/view/25705/25477"
"25706","Competition, Alignment, and Equilibria in Digital Marketplaces","['Meena Jagadeesan', 'Michael I. Jordan', 'Nika Haghtalab']","['UC Berkeley', 'UC Berkeley', 'UC Berkeley']","['GTEP: Other Foundations of Game Theory & Economic Paradigms', 'GTEP: Auctions and Market-Based Systems', 'GTEP: Game Theory', 'ML: Online Learning & Bandits']","Jagadeesan, M., Jordan, M. I., & Haghtalab, N. (2023). Competition, Alignment, and Equilibria in Digital Marketplaces. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5689-5696. https://doi.org/10.1609/aaai.v37i5.25706","Abstract 					Competition between traditional platforms is known to improve user utility by aligning the platform's actions with user preferences. But to what extent is alignment exhibited in data-driven marketplaces? To study this question from a theoretical perspective, we introduce a duopoly market where platform actions are bandit algorithms and the two platforms compete for user participation. A salient feature of this market is that the quality of recommendations depends on both the bandit algorithm and the amount of data provided by interactions from users. This interdependency between the algorithm performance and the actions of users complicates the structure of market equilibria and their quality in terms of user utility. Our main finding is that competition in this market does not perfectly align market outcomes with user utility. Interestingly, market outcomes exhibit misalignment not only when the platforms have separate data repositories, but also when the platforms have a shared data repository. Nonetheless, the data sharing assumptions impact what mechanism drives misalignment and also affect the specific form of misalignment (e.g. the quality of the best-case and worst-case market outcomes). More broadly, our work illustrates that competition in digital marketplaces has subtle consequences for user utility that merit further investigation.","https://ojs.aaai.org/index.php/AAAI/article/view/25706/25478"
"25707","Voting with Preference Intensities","['Anson Kahng', 'Mohamad Latifian', 'Nisarg Shah']","['University of Rochester', 'University of Toronto', 'University of Toronto']","['GTEP: Social Choice / Voting']","Kahng, A., Latifian, M., & Shah, N. (2023). Voting with Preference Intensities. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5697-5704. https://doi.org/10.1609/aaai.v37i5.25707","Abstract 					When an agent votes, she typically ranks the set of available alternatives. Occasionally, she may also wish to report the intensity of her preferences by indicating adjacent pairs of alternatives in her ranking between which her preference is acutely decisive; for instance, she may suggest that she likes alternative a more than b, but b much more than c. We design near-optimal voting rules which aggregate such preference rankings with intensities using the recently-popular distortion framework. We also show that traditional voting rules, which aggregate preference rankings while ignoring (or not eliciting) intensities, can incur significant welfare loss.","https://ojs.aaai.org/index.php/AAAI/article/view/25707/25479"
"25708","Approximations for Indivisible Concave Allocations with Applications to Nash Welfare Maximization","['Nathaniel Kell', 'Kevin Sun']","['Denison University', 'Elon University']","['GTEP: Fair Division', 'GTEP: Auctions and Market-Based Systems', 'GTEP: Other Foundations of Game Theory & Economic Paradigms', 'SO: Local Search', 'SO: Other Foundations of Search & Optimization']","Kell, N., & Sun, K. (2023). Approximations for Indivisible Concave Allocations with Applications to Nash Welfare Maximization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5705-5713. https://doi.org/10.1609/aaai.v37i5.25708","Abstract 					We study a general allocation setting where agent valuations are concave additive. In this model, a collection of items must be uniquely distributed among a set of agents, where each agent-item pair has a specified utility. The objective is to maximize the sum of agent valuations, each of which is an arbitrary non-decreasing concave function of the agent's total additive utility. This setting was studied by Devanur and Jain (STOC 2012) in the online setting for divisible items. In this paper, we obtain both multiplicative and additive approximations in the offline setting for indivisible items. Our approximations depend on novel parameters that measure the local multiplicative/additive curvatures of each agent valuation, which we show correspond directly to the integrality gap of the natural assignment convex program of the problem. Furthermore, we extend our additive guarantees to obtain constant multiplicative approximations for Asymmetric Nash Welfare Maximization when agents have smooth valuations. This algorithm also yields an interesting tatonnement-style interpretation, where agents adjust uniform prices and items are assigned according to maximum weighted bang-per-buck ratios.","https://ojs.aaai.org/index.php/AAAI/article/view/25708/25480"
"25709","Strategic Facility Location with Clients That Minimize Total Waiting Time","['Simon Krogmann', 'Pascal Lenzner', 'Alexander Skopalik']","['Hasso Plattner Institute, University of Potsdam', 'Hasso Plattner Institute, University of Potsdam', 'Department of Applied Mathematics, University of Twente']","['GTEP: Game Theory', 'GTEP: Equilibrium']","Krogmann, S., Lenzner, P., & Skopalik, A. (2023). Strategic Facility Location with Clients That Minimize Total Waiting Time. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5714-5721. https://doi.org/10.1609/aaai.v37i5.25709","Abstract 					We study a non-cooperative two-sided facility location game in which facilities and clients behave strategically. This is in contrast to many other facility location games in which clients simply visit their closest facility. Facility agents select a location on a graph to open a facility to attract as much purchasing power as possible, while client agents choose which facilities to patronize by strategically distributing their purchasing power in order to minimize their total waiting time. Here, the waiting time of a facility depends on its received total purchasing power.     We show that our client stage is an atomic splittable congestion game, which implies existence, uniqueness and efficient computation of a client equilibrium. Therefore, facility agents can efficiently predict client behavior and make strategic decisions accordingly. Despite that, we prove that subgame perfect equilibria do not exist in all instances of this game and that their existence is NP-hard to decide. On the positive side, we provide a simple and efficient algorithm to compute 3-approximate subgame perfect equilibria.","https://ojs.aaai.org/index.php/AAAI/article/view/25709/25481"
"25710","Proportional Decisions in Perpetual Voting","['Martin Lackner', 'Jan Maly']","['TU Wien', 'University of Amsterdam']","['GTEP: Social Choice / Voting']","Lackner, M., & Maly, J. (2023). Proportional Decisions in Perpetual Voting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5722-5729. https://doi.org/10.1609/aaai.v37i5.25710","Abstract 					Perpetual voting is a framework for long-term collective decision making. In this framework, we consider a sequence of subsequent approval-based elections and try to achieve a fair overall outcome. To achieve fairness over time, perpetual voting rules take the history of previous decisions into account and identify voters that were dissatisfied with previous decisions. In this paper, we look at perpetual voting rules from an axiomatic perspective. First, we define two classes of perpetual voting rules that are particularly easy to explain to voters and explore the bounds imposed by this simplicity. Second, we study proportionality in the perpetual setting and identify two rules with strong proportionality guarantees. However, both rules yield different guarantees and we prove them to be incompatible with each other.","https://ojs.aaai.org/index.php/AAAI/article/view/25710/25482"
"25711","Multiagent MST Cover: Pleasing All Optimally via a Simple Voting Rule","['Bo Li', 'Xiaowei Wu', 'Chenyang Xu', 'Ruilong Zhang']","['Department of Computing, The Hong Kong Polytechnic University', 'IOTSC, University of Macau', 'Software Engineering Institute, East China Normal University\nCollege of Computer Science, Zhejiang University', 'Department of Computer Science, City University of Hong Kong']","['GTEP: Social Choice / Voting', 'GTEP: Game Theory', 'GTEP: Other Foundations of Game Theory & Economic Paradigms']","Li, B., Wu, X., Xu, C., & Zhang, R. (2023). Multiagent MST Cover: Pleasing All Optimally via a Simple Voting Rule. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5730-5738. https://doi.org/10.1609/aaai.v37i5.25711","Abstract 					Given a connected graph on whose edges we can build roads to connect the nodes, a number of agents hold possibly different perspectives on which edges should be selected by assigning different edge weights. Our task is to build a minimum number of roads so that every agent has a spanning tree in the built subgraph whose weight is the same as a minimum spanning tree in the original graph. We first show that this problem is NP-hard and does not admit better than ((1-o(1)) ln k)-approximation polynomial-time algorithms unless P = NP, where k is the number of agents. We then give a simple voting algorithm with an optimal approximation ratio. Moreover, our algorithm only needs to access the agents' rankings on the edges. Finally, we extend our problem to submodular objective functions and Matroid rank constraints.","https://ojs.aaai.org/index.php/AAAI/article/view/25711/25483"
"25712","When Congestion Games Meet Mobile Crowdsourcing: Selective Information Disclosure","['Hongbo Li', 'Lingjie Duan']","['Singapore University of Technology and Design', 'Singapore University of Technology and Design']","['GTEP: Game Theory', 'GTEP: Mechanism Design', 'GTEP: Social Choice / Voting']","Li, H., & Duan, L. (2023). When Congestion Games Meet Mobile Crowdsourcing: Selective Information Disclosure. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5739-5746. https://doi.org/10.1609/aaai.v37i5.25712","Abstract 					In congestion games, users make myopic routing decisions to jam each other, and the social planner with the full information designs mechanisms on information or payment side to regulate. However, it is difficult to obtain time-varying traffic conditions, and emerging crowdsourcing platforms (e.g., Waze and Google Maps) provide a convenient way for mobile users travelling on the paths to learn and share the traffic conditions over time. When congestion games meet mobile crowdsourcing, it is critical to incentive selfish users to change their myopic routing policy and reach the best exploitation-exploration trade-off. By considering a simple but fundamental parallel routing network with one deterministic path and multiple stochastic paths for atomic users, we prove that the myopic routing policy's price of anarchy (PoA) can be arbitrarily large as the discount factor approaches 1. To remedy such huge efficiency loss, we propose a selective information disclosure (SID) mechanism: we only reveal the latest traffic information to users when they intend to over-explore the stochastic paths, while hiding such information when they want to under-explore. We prove that our mechanism reduces PoA to less than 2. Besides the worst-case performance, we further examine our mechanism's average-case performance by using extensive simulations.","https://ojs.aaai.org/index.php/AAAI/article/view/25712/25484"
"25713","Partitioning Friends Fairly","['Lily Li', 'Evi Micha', 'Aleksandar Nikolov', 'Nisarg Shah']","['University of Toronto', 'University of Toronto', 'University of Toronto', 'University of Toronto']","['GTEP: Social Choice / Voting', 'GTEP: Cooperative Game Theory', 'GTEP: Fair Division']","Li, L., Micha, E., Nikolov, A., & Shah, N. (2023). Partitioning Friends Fairly. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5747-5754. https://doi.org/10.1609/aaai.v37i5.25713","Abstract 					We consider the problem of partitioning n agents in an undirected social network into k almost equal in size (differing by at most one) groups, where the utility of an agent for a group is the number of her neighbors in the group. The core and envy-freeness are two compelling axiomatic fairness guarantees in such settings. The former demands that there be no coalition of agents such that each agent in the coalition has more utility for that coalition than for her own group, while the latter demands that no agent envy another agent for the group they are in. We provide (often tight) approximations to both fairness guarantees, and many of our positive results are obtained via efficient algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/25713/25485"
"25714","Differentially Private Condorcet Voting","['Zhechen Li', 'Ao Liu', 'Lirong Xia', 'Yongzhi Cao', 'Hanpin Wang']","['Peking University', 'Rensselaer Polytechnic Institute', 'Rensselaer Polytechnic Institute', 'Peking University', 'Guangzhou University\nPeking University']","['GTEP: Social Choice / Voting']","Li, Z., Liu, A., Xia, L., Cao, Y., & Wang, H. (2023). Differentially Private Condorcet Voting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5755-5763. https://doi.org/10.1609/aaai.v37i5.25714","Abstract 					Designing private voting rules is an important and pressing problem for trustworthy democracy. In this paper, under the framework of differential privacy, we propose a novel famliy of randomized voting rules based on the well-known Condorcet method, and focus on three classes of voting rules in this family: Laplacian Condorcet method (CMLAP), exponential Condorcet method (CMEXP), and randomized response Condorcet method (CMRR), where λ represents the level of noise. We prove that all of our rules satisfy absolute monotonicity, lexi-participation, probabilistic Pareto efficiency, approximate probabilistic Condorcet criterion, and approximate SD-strategyproofness. In addition, CMRR satisfies (non-approximate) probabilistic Condorcet criterion, while CMLAP and CMEXP satisfy strong lexi-participation. Finally, we regard differential privacy as a voting axiom, and discuss its relations to other axioms.","https://ojs.aaai.org/index.php/AAAI/article/view/25714/25486"
"25715","Function Approximation for Solving Stackelberg Equilibrium in Large Perfect Information Games","['Chun Kai Ling', 'J. Zico Kolter', 'Fei Fang']","['Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University']","['GTEP: Game Theory', 'GTEP: Equilibrium']","Ling, C. K., Kolter, J. Z., & Fang, F. (2023). Function Approximation for Solving Stackelberg Equilibrium in Large Perfect Information Games. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5764-5772. https://doi.org/10.1609/aaai.v37i5.25715","Abstract 					Function approximation (FA) has been a critical component in solving large zero-sum games. Yet, little attention has been given towards FA in solving general-sum extensive-form games, despite them being widely regarded as being computationally more challenging than their fully competitive  or cooperative counterparts. A key challenge is that for many equilibria in general-sum games, no simple analogue to the state value function used in Markov Decision Processes and zero-sum games exists. In this paper, we propose learning the Enforceable Payoff Frontier (EPF)---a generalization of the state value function for general-sum games. We approximate the optimal Stackelberg extensive-form correlated equilibrium by representing EPFs with neural networks and training them by using appropriate backup operations and loss functions. This is the first method that applies FA to the Stackelberg setting, allowing us to scale to much larger games while still enjoying performance guarantees based on FA error. Additionally, our proposed method guarantees incentive compatibility and is easy to evaluate without having to depend on self-play or approximate best-response oracles.","https://ojs.aaai.org/index.php/AAAI/article/view/25715/25487"
"25716","Optimal Pricing Schemes for Identical Items with Time-Sensitive Buyers","['Zhengyang Liu', 'Liang Shan', 'Zihe Wang']","['Beijing Institute of Technology', 'Renmin University of China', 'Renmin University of China']","['GTEP: Mechanism Design']","Liu, Z., Shan, L., & Wang, Z. (2023). Optimal Pricing Schemes for Identical Items with Time-Sensitive Buyers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5773-5780. https://doi.org/10.1609/aaai.v37i5.25716","Abstract 					Time or money? That is a question! In this paper, we consider this dilemma in the pricing regime, in which we try to find the optimal pricing scheme for identical items with heterogenous time-sensitive buyers. We characterize the revenue-optimal solution and propose an efficient algorithm to find it in a Bayesian setting. Our results also demonstrate the tight ratio between the value of wasted time and the seller's revenue, as well as that of two common-used pricing schemes, the k-step function and the fixed pricing. To explore the nature of the optimal scheme in the general setting, we present the closed forms over the product distribution and show by examples that positive correlation between the valuation of the item and the cost per unit time could help increase revenue. To the best of our knowledge, it is the first step towards understanding the impact of the time factor as a part of the buyer cost in pricing problems, in the computational view.","https://ojs.aaai.org/index.php/AAAI/article/view/25716/25488"
"25717","Approval-Based Voting with Mixed Goods","['Xinhang Lu', 'Jannik Peters', 'Haris Aziz', 'Xiaohui Bei', 'Warut Suksompong']","['University of New South Wales', 'Technische Universität Berlin', 'University of New South Wales', 'Nanyang Technological University', 'National University of Singapore']","['GTEP: Social Choice / Voting']","Lu, X., Peters, J., Aziz, H., Bei, X., & Suksompong, W. (2023). Approval-Based Voting with Mixed Goods. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5781-5788. https://doi.org/10.1609/aaai.v37i5.25717","Abstract 					We consider a voting scenario in which the resource to be voted upon may consist of both indivisible and divisible goods. This generalizes both the well-studied model of multiwinner voting and the recently introduced model of cake sharing. Under approval votes, we propose two variants of the extended justified representation (EJR) notion from multiwinner voting, a stronger one called EJR for mixed goods (EJR-M) and a weaker one called EJR up to 1 (EJR-1). We extend three multiwinner voting rules to our setting—GreedyEJR, the method of equal shares (MES), and proportional approval voting (PAV)—and show that while all three generalizations satisfy EJR-1, only the first one provides EJR-M. In addition, we derive tight bounds on the proportionality degree implied by EJR-M and EJR-1, and investigate the proportionality degree of our proposed rules.","https://ojs.aaai.org/index.php/AAAI/article/view/25717/25489"
"25718","Utility Maximizer or Value Maximizer: Mechanism Design for Mixed Bidders in Online Advertising","['Hongtao Lv', 'Zhilin Zhang', 'Zhenzhe Zheng', 'Jinghan Liu', 'Chuan Yu', 'Lei Liu', 'Lizhen Cui', 'Fan Wu']","['Shandong University\nShanghai Jiao Tong University', 'Alibaba Group', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Alibaba Group', 'Shandong University', 'Shandong University', 'Shanghai Jiao Tong University']","['GTEP: Mechanism Design', 'APP: Business/Marketing/Advertising/E-Commerce', 'GTEP: Game Theory']","Lv, H., Zhang, Z., Zheng, Z., Liu, J., Yu, C., Liu, L., Cui, L., & Wu, F. (2023). Utility Maximizer or Value Maximizer: Mechanism Design for Mixed Bidders in Online Advertising. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5789-5796. https://doi.org/10.1609/aaai.v37i5.25718","Abstract 					Digital advertising constitutes one of the main revenue sources for online platforms. In recent years, some advertisers tend to adopt auto-bidding tools to facilitate advertising performance optimization, making the classical utility maximizer model in auction theory not fit well. Some recent studies proposed a new model, called value maximizer, for auto-bidding advertisers with return-on-investment (ROI) constraints. However, the model of either utility maximizer or value maximizer could only characterize partial advertisers in real-world advertising platforms. In a mixed environment where utility maximizers and value maximizers coexist, the truthful ad auction design would be challenging since bidders could manipulate both their values and affiliated classes, leading to a multi-parameter mechanism design problem. In this work, we address this issue by proposing a payment rule which combines the corresponding ones in classical VCG and GSP mechanisms in a novel way. Based on this payment rule, we propose a truthful auction mechanism with an approximation ratio of 2 on social welfare, which is close to the lower bound of at least 5/4 that we also prove. The designed auction mechanism is a generalization of VCG for utility maximizers and GSP for value maximizers.","https://ojs.aaai.org/index.php/AAAI/article/view/25718/25490"
"25719","Facility Location Games with Entrance Fees","['Mengfan Ma', 'Mingyu Xiao', 'Tian Bai', 'Bakh Khoussainov']","['University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China']","['GTEP: Mechanism Design', 'GTEP: Game Theory', 'GTEP: Social Choice / Voting']","Ma, M., Xiao, M., Bai, T., & Khoussainov, B. (2023). Facility Location Games with Entrance Fees. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5797-5804. https://doi.org/10.1609/aaai.v37i5.25719","Abstract 					The facility location game is an extensively studied problem in mechanism design. In the classical model, the cost of each agent is her distance to the nearest facility. In this paper, we consider a novel model where each facility charges an entrance fee, which is a function of the facility's location. Thus, in our model, the cost of each agent is the sum of the distance to the facility and the entrance fee of the facility. The generalized model captures more real-life scenarios. In our model, the entrance fee function can be an arbitrary function, and the corresponding preferences of agents may not be single-peaked anymore: this makes the problem complex and requires new techniques in the analysis. We systematically study the model and design strategyproof mechanisms with nice approximation ratios and also complement these with nearly-tight impossibility results. Specifically, for one-facility and two-facility games, we provide upper and lower bounds for the approximation ratios given by deterministic and randomized mechanisms, with respect to the utilitarian and egalitarian objectives. Most of our bounds are tight, and these bounds are independent of the entrance fee functions. Our results also match the results of the classical model.","https://ojs.aaai.org/index.php/AAAI/article/view/25719/25491"
"25720","Securing Lifelines: Safe Delivery of Critical Services in Areas with Volatile Security Situation via a Stackelberg Game Approach","['Tien Mai', 'Arunesh Sinha']","['Singapore Management University', 'Rutgers University']","['GTEP: Equilibrium', 'CSO: Mixed Discrete/Continuous Optimization']","Mai, T., & Sinha, A. (2023). Securing Lifelines: Safe Delivery of Critical Services in Areas with Volatile Security Situation via a Stackelberg Game Approach. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5805-5813. https://doi.org/10.1609/aaai.v37i5.25720","Abstract 					Vaccine delivery in under-resourced locations with security risks is not just challenging but also life threatening. The COVID pandemic and the need to vaccinate added even more urgency to this issue. Motivated by this problem, we propose a general framework to set-up limited temporary (vaccination) centers that balance physical security and desired (vaccine) service coverage with limited resources. We set-up the problem as a Stackelberg game between the centers operator (defender) and an adversary, where the set of centers is not fixed a priori but is part of the decision output. This results in a mixed combinatorial and continuous optimization problem. As part of our scalable approximation solution, we provide a fundamental contribution by identifying general duality conditions of switching max and min when both discrete and continuous variables are involved. Via detailed experiments, we show that the solution proposed is scalable in practice.","https://ojs.aaai.org/index.php/AAAI/article/view/25720/25492"
"25721","Differentially Private Fair Division","['Pasin Manurangsi', 'Warut Suksompong']","['Google Research', 'National University of Singapore']","['GTEP: Fair Division', 'ML: Privacy-Aware ML', 'GTEP: Game Theory']","Manurangsi, P., & Suksompong, W. (2023). Differentially Private Fair Division. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5814-5822. https://doi.org/10.1609/aaai.v37i5.25721","Abstract 					Fairness and privacy are two important concerns in social decision-making processes such as resource allocation. We study privacy in the fair allocation of indivisible resources using the well-established framework of differential privacy. We present algorithms for approximate envy-freeness and proportionality when two instances are considered to be adjacent if they differ only on the utility of a single agent for a single item. On the other hand, we provide strong negative results for both fairness criteria when the adjacency notion allows the entire utility function of a single agent to change.","https://ojs.aaai.org/index.php/AAAI/article/view/25721/25493"
"25722","An Efficient Deep Reinforcement Learning Algorithm for Solving Imperfect Information Extensive-Form Games","['Linjian Meng', 'Zhenxing Ge', 'Pinzhuo Tian', 'Bo An', 'Yang Gao']","['Nanjing University', 'Nanjing University', 'Shanghai University', 'Nanyang Technological University', 'Nanjing University']","['GTEP: Imperfect Information']","Meng, L., Ge, Z., Tian, P., An, B., & Gao, Y. (2023). An Efficient Deep Reinforcement Learning Algorithm for Solving Imperfect Information Extensive-Form Games. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5823-5831. https://doi.org/10.1609/aaai.v37i5.25722","Abstract 					One of the most popular methods for learning Nash equilibrium (NE) in large-scale imperfect information extensive-form games (IIEFGs) is the neural variants of counterfactual regret minimization (CFR). CFR is a special case of Follow-The-Regularized-Leader (FTRL). At each iteration, the neural variants of CFR update the agent's strategy via the estimated counterfactual regrets. Then, they use neural networks to approximate the new strategy, which incurs an approximation error. These approximation errors will accumulate since the counterfactual regrets at iteration t are estimated using the agent's past approximated strategies. Such accumulated approximation error causes poor performance. To address this accumulated approximation error, we propose a novel FTRL algorithm called FTRL-ORW, which does not utilize the agent's past strategies to pick the next iteration strategy. More importantly, FTRL-ORW can update its strategy via the trajectories sampled from the game, which is suitable to solve large-scale IIEFGs since sampling multiple actions for each information set is too expensive in such games. However, it remains unclear which algorithm to use to compute the next iteration strategy for FTRL-ORW when only such sampled trajectories are revealed at iteration t. To address this problem and scale FTRL-ORW to large-scale games, we provide a model-free method called Deep FTRL-ORW, which computes the next iteration strategy using model-free Maximum Entropy Deep Reinforcement Learning. Experimental results on two-player zero-sum IIEFGs show that Deep FTRL-ORW significantly outperforms existing model-free neural methods and OS-MCCFR.","https://ojs.aaai.org/index.php/AAAI/article/view/25722/25494"
"25723","Fast and Interpretable Dynamics for Fisher Markets via Block-Coordinate Updates","['Tianlong Nan', 'Yuan Gao', 'Christian Kroer']","['Columbia University', 'Columbia University', 'Columbia University']","['GTEP: Equilibrium', 'GTEP: Fair Division', 'MAS: Agent/AI Theories and Architectures']","Nan, T., Gao, Y., & Kroer, C. (2023). Fast and Interpretable Dynamics for Fisher Markets via Block-Coordinate Updates. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5832-5840. https://doi.org/10.1609/aaai.v37i5.25723","Abstract 					We consider the problem of large-scale Fisher market equilibrium computation through scalable first-order optimization methods. It is well-known that market equilibria can be captured using structured convex programs such as the Eisenberg-Gale and Shmyrev convex programs. Highly performant deterministic full-gradient first-order methods have been developed for these programs. In this paper, we develop new block-coordinate first-order methods for computing Fisher market equilibria, and show that these methods have interpretations as tâtonnement-style or proportional response-style dynamics where either buyers or items show up one at a time. We reformulate these convex programs and solve them using proximal block coordinate descent methods, a class of methods that update only a small number of coordinates of the decision variable in each iteration. Leveraging recent advances in the convergence analysis of these methods and structures of the equilibrium-capturing convex programs, we establish fast convergence rates of these methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25723/25495"
"25724","Ballot Length in Instant Runoff Voting","['Kiran Tomlinson', 'Johan Ugander', 'Jon Kleinberg']","['Cornell University', 'Stanford University', 'Cornell University']","['GTEP: Social Choice / Voting', 'GTEP: Mechanism Design', 'MAS: Mechanism Design']","Tomlinson, K., Ugander, J., & Kleinberg, J. (2023). Ballot Length in Instant Runoff Voting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5841-5849. https://doi.org/10.1609/aaai.v37i5.25724","Abstract 					Instant runoff voting (IRV) is an increasingly-popular alternative to traditional plurality voting in which voters submit rankings over the candidates rather than single votes. In practice, elections using IRV often restrict the ballot length, the number of candidates a voter is allowed to rank on their ballot. We theoretically and empirically analyze how ballot length can influence the outcome of an election, given fixed voter preferences. We show that there exist preference profiles over k candidates such that up to k-1 different candidates win at different ballot lengths. We derive exact lower bounds on the number of voters required for such profiles and provide a construction matching the lower bound for unrestricted voter preferences. Additionally, we characterize which sequences of winners are possible over ballot lengths and provide explicit profile constructions achieving any feasible winner sequence. We also examine how classic preference restrictions influence our results—for instance, single-peakedness makes k-1 different winners impossible but still allows at least Ω(√k). Finally, we analyze a collection of 168 real-world elections, where we truncate rankings to simulate shorter ballots. We find that shorter ballots could have changed the outcome in one quarter of these elections. Our results highlight ballot length as a consequential degree of freedom in the design of IRV elections.","https://ojs.aaai.org/index.php/AAAI/article/view/25724/25496"
"25725","Multi-Stage Facility Location Problems with Transient Agents","['Xuezhen Wang', 'Vincent Chau', 'Hau Chan', 'Ken C.K. Fong', 'Minming Li']","['City University of Hong Kong', 'Southeast University', 'University of Nebraska-Lincoln', 'Lingnan University', 'City University of Hong Kong']","['GTEP: Social Choice / Voting', 'GTEP: Game Theory', 'GTEP: Mechanism Design', 'MAS: Mechanism Design']","Wang, X., Chau, V., Chan, H., Fong, K. C., & Li, M. (2023). Multi-Stage Facility Location Problems with Transient Agents. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5850-5857. https://doi.org/10.1609/aaai.v37i5.25725","Abstract 					We study various models for the one-dimensional multi-stage facility location problems with transient agents, where a transient agent arrives in some stage and stays for a number of consecutive stages. In the problems, we need to serve each agent in one of their stages by determining the location of the facility at each stage. In the first model, we assume there is no cost for moving the facility across the stages. We focus on optimal algorithms to minimize both the social cost objective, defined as the total distance of all agents to the facility over all stages, and the maximum cost objective, defined as the max distance of any agent to the facility over all stages. For each objective, we give a slice-wise polynomial (XP) algorithm (i.e., solvable in m^f(k) for some fixed parameter k and computable function f, where m is the input size) and show that there is a polynomial-time algorithm when a natural first-come-first-serve (FCFS) order of agent serving is enforced. We then consider the mechanism design problem, where the agents' locations and arrival stages are private, and design a group strategy-proof mechanism that achieves good approximation ratios for both objectives and settings with and without FCFS ordering. In the second model, we consider the facility's moving cost between adjacent stages under the social cost objective, which accounts for the total moving distance of the facility. Correspondingly, we design XP (and polynomial time) algorithms and a group strategy-proof mechanism for settings with or without the FCFS ordering.","https://ojs.aaai.org/index.php/AAAI/article/view/25725/25497"
"25726","Bayesian Optimization-Based Combinatorial Assignment","['Jakob Weissteiner', 'Jakob Heiss', 'Julien Siems', 'Sven Seuken']","['University of Zurich\nETH AI Center', 'ETH Zurich\nETH AI Center', 'University of Zurich', 'University of Zurich\nETH AI Center']","['GTEP: Auctions and Market-Based Systems', 'ML: Learning Preferences or Rankings', 'ML: Active Learning']","Weissteiner, J., Heiss, J., Siems, J., & Seuken, S. (2023). Bayesian Optimization-Based Combinatorial Assignment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5858-5866. https://doi.org/10.1609/aaai.v37i5.25726","Abstract 					We study the combinatorial assignment domain, which includes combinatorial auctions and course allocation. The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning-based preference elicitation algorithms that aim to elicit only the most important information from agents. However, the main shortcoming of this prior work is that it does not model a mechanism's uncertainty over values for not yet elicited bundles. In this paper, we address this shortcoming by presenting a Bayesian optimization-based combinatorial assignment (BOCA) mechanism. Our key technical contribution is to integrate a method for capturing model uncertainty into an iterative combinatorial auction mechanism. Concretely, we design a new method for estimating an upper uncertainty bound that can be used to define an acquisition function to determine the next query to the agents. This enables the mechanism to properly explore (and not just exploit) the bundle space during its preference elicitation phase. We run computational experiments in several spectrum auction domains to evaluate BOCA's performance. Our results show that BOCA achieves higher allocative efficiency than state-of-the-art approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/25726/25498"
"25727","Semi-random Impossibilities of Condorcet Criterion","['Lirong Xia']","['RPI']","['GTEP: Social Choice / Voting']","Xia, L. (2023). Semi-random Impossibilities of Condorcet Criterion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5867-5875. https://doi.org/10.1609/aaai.v37i5.25727","Abstract 					The Condorcet criterion (CC) is a classical and well-accepted criterion for voting. Unfortunately, it is incompatible with many other desiderata including participation (PAR), half-way monotonicity (HM), Maskin monotonicity (MM), and strategy-proofness (SP). Such incompatibilities are often known as impossibility theorems, and are proved by worst-case analysis. Previous work has investigated the likelihood for these impossibilities to occur under certain models, which are often criticized of being unrealistic.  We strengthen previous work by proving the first set of semi-random impossibilities for voting rules to satisfy CC and the more general, group versions of the four desiderata: for any sufficiently large number of voters n, any size of the group 1<= B<= \sqrt n, any voting rule r, and under a large class of semi-random models that include Impartial Culture, the likelihood for r to satisfy CC and PAR, CC and HM, CC and MM, or CC and SP  is 1-\Omega(B/\sqrt n). This matches existing lower bounds for CC&PAR (B=1) and CC&SP and CC&HM (B<=\sqrt n), showing that many commonly-studied voting rules  are already asymptotically optimal in such cases.","https://ojs.aaai.org/index.php/AAAI/article/view/25727/25499"
"25728","Tournament Fixing Parameterized by Feedback Vertex Set Number Is FPT","['Meirav Zehavi']","['Ben-Gurion University of the Negev, Beersheba']","['GTEP: Social Choice / Voting']","Zehavi, M. (2023). Tournament Fixing Parameterized by Feedback Vertex Set Number Is FPT. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5876-5883. https://doi.org/10.1609/aaai.v37i5.25728","Abstract 					A knockout (or single-elimination) tournament is a format of a competition that is very popular in practice (particularly in sports, elections and decision making), and which has been extensively and intensively studied from a theoretical point of view for more than a decade. Particular attention has been devoted to the Tournament Fixing problem, where, roughly speaking, the objective is to determine whether we can conduct the knockout tournament in a way that makes our favorite player win. Here, part of the input is a tournament graph D that encodes the winner of each possible match. A sequence of papers has studied the parameterized complexity of  Tournament Fixing with respect to the feedback arc set number (fas) of D Given that this parameter yielded tractability, it has been asked explicitly and repeatedly whether Tournament Fixing is FPT also with respect to the  feedback vertex set number (fvs) of D. We answer this question positively. In fact, although fvs can be arbitrarily smaller than fas, we attain the same dependency on the parameter in the time complexity. So, additionally, our work subsumes the best known algorithm for Tournament Fixing with respect to as.","https://ojs.aaai.org/index.php/AAAI/article/view/25728/25500"
"25729","Truthful Mechanisms for Steiner Tree Problems","['Jinshan Zhang', 'Zhengyang Liu', 'Xiaotie Deng', 'Jianwei Yin']","['Zhejiang University', 'Beijing Institute of Technology', 'Peking University', 'Zhejiang University']","['GTEP: Mechanism Design']","Zhang, J., Liu, Z., Deng, X., & Yin, J. (2023). Truthful Mechanisms for Steiner Tree Problems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5884-5891. https://doi.org/10.1609/aaai.v37i5.25729","Abstract 					Consider an undirected graph G=(V,E) model for a communication network, where  each edge is owned by a selfish agent, who reports the cost for offering the use of her edge. Note that each edge agent may misreport her own cost for the use of the edge for her own benefit. In such a non-cooperative setting, we aim at designing an approximately truthful mechanism for establishing a Steiner tree, a minimum cost tree spanning over all the terminals. We present a truthful-in-expectation mechanism that achieves the approximation ratio ln 4 + ε ≈ 1.39, which matches the current best algorithmic ratio for STP.","https://ojs.aaai.org/index.php/AAAI/article/view/25729/25501"
"25730","Collusion-Proof and Sybil-Proof Reward Mechanisms for Query Incentive Networks","['Youjia Zhang', 'Pingzhong Tang']","['Tsinghua University', 'Tsinghua University']","['GTEP: Mechanism Design', 'GTEP: Cooperative Game Theory', 'GTEP: Game Theory']","Zhang, Y., & Tang, P. (2023). Collusion-Proof and Sybil-Proof Reward Mechanisms for Query Incentive Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5892-5899. https://doi.org/10.1609/aaai.v37i5.25730","Abstract 					This paper explores reward mechanisms for a query incentive network in which agents seek information from social networks. In a query tree issued by the task owner, each agent is rewarded by the owner for contributing to the solution, for instance, solving the task or inviting others to solve it. The reward mechanism determines the reward for each agent and motivates all agents to propagate and report their information truthfully. In particular, the reward cannot exceed the budget set by the task owner. However, our impossibility results demonstrate that a reward mechanism cannot simultaneously achieve Sybil-proof (agents benefit from manipulating multiple fake identities), collusion-proof (multiple agents pretend as a single agent to improve the reward), and other essential properties. In order to address these issues, we propose two novel reward mechanisms. The first mechanism achieves Sybil-proof and collusion-proof, respectively; the second mechanism sacrifices Sybil-proof to achieve the approximate versions of Sybil-proof and collusion-proof. Additionally, we show experimentally that our second reward mechanism outperforms the existing ones.","https://ojs.aaai.org/index.php/AAAI/article/view/25730/25502"
"25731","Fisher Markets with Social Influence","['Jiayi Zhao', 'Denizalp Goktas', 'Amy Greenwald']","['Pomona College', 'Brown University', 'Brown University']","['GTEP: Auctions and Market-Based Systems', 'GTEP: Equilibrium', 'GTEP: Game Theory']","Zhao, J., Goktas, D., & Greenwald, A. (2023). Fisher Markets with Social Influence. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5900-5909. https://doi.org/10.1609/aaai.v37i5.25731","Abstract 					A Fisher market is an economic model of buyer and seller interactions in which each buyer’s utility depends only on the bundle of goods she obtains. Many people’s interests, however, are affected by their social interactions with others. In this paper, we introduce a generalization of Fisher markets, namely influence Fisher markets, which captures the impact of social influence on buyers’ utilities. We show that competitive equilibria in influence Fisher markets correspond to generalized Nash equilibria in an associated pseudo-game, which implies the existence of competitive equilibria in all influence Fisher markets with continuous and concave utility functions. We then construct a monotone pseudo-game, whose variational equilibria and their duals together characterize competitive equilibria in influence Fisher markets with continuous, jointly concave, and homogeneous utility functions. This observation implies that competitive equilibria in these markets can be computed in polynomial time under standard smoothness assumptions on the utility functions. The dual of this second pseudo-game enables us to interpret the competitive equilibria of influence CCH Fisher markets as the solutions to a system of simultaneous Stackelberg games. Finally, we derive a novel first-order method that solves this Stackelberg system in polynomial time, prove that it is equivalent to computing competitive equilibrium prices via tâtonnement, and run experiments that confirm our theoretical results.","https://ojs.aaai.org/index.php/AAAI/article/view/25731/25503"
"25732","Probably Approximate Shapley Fairness with Applications in Machine Learning","['Zijian Zhou', 'Xinyi Xu', 'Rachael Hwee Ling Sim', 'Chuan Sheng Foo', 'Bryan Kian Hsiang Low']","['National University of Singapore', 'National University of Singapore\nInstitute for Infocomm Research, A*STAR', 'National University of Singapore', 'Institute for Infocomm Research, A*STAR\nCentre for Frontier AI Research, A*STAR', 'National University of Singapore']","['GTEP: Applications', 'ML: Evaluation and Analysis (Machine Learning)']","Zhou, Z., Xu, X., Sim, R. H. L., Foo, C. S., & Low, B. K. H. (2023). Probably Approximate Shapley Fairness with Applications in Machine Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5910-5918. https://doi.org/10.1609/aaai.v37i5.25732","Abstract 					The Shapley value (SV) is adopted in various scenarios in machine learning (ML), including data valuation, agent valuation, and feature attribution, as it satisfies their fairness requirements. However, as exact SVs are infeasible to compute in practice, SV estimates are approximated instead. This approximation step raises an important question: do the SV estimates preserve the fairness guarantees of exact SVs? We observe that the fairness guarantees of exact SVs are too restrictive for SV estimates. Thus, we generalise Shapley fairness to probably approximate Shapley fairness and propose fidelity score, a metric to measure the variation of SV estimates, that determines how probable the fairness guarantees hold. Our last theoretical contribution is a novel greedy active estimation (GAE) algorithm that will maximise the lowest fidelity score and achieve a better fairness guarantee than the de facto Monte-Carlo estimation. We empirically verify GAE outperforms several existing methods in guaranteeing fairness while remaining competitive in estimation accuracy in various ML scenarios using real-world datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25732/25504"
"25733","The Perils of Trial-and-Error Reward Design: Misdesign through Overfitting and Invalid Task Specifications","['Serena Booth', 'W. Bradley Knox', 'Julie Shah', 'Scott Niekum', 'Peter Stone', 'Alessandro Allievi']","['Bosch\nThe University of Texas at Austin\nMIT CSAIL', 'Bosch\nThe University of Texas at Austin\nGoogle Research', 'MIT CSAIL', 'The University of Texas at Austin\nThe University of Massachusetts at Amherst', 'The University of Texas at Austin\nSony AI', 'Bosch\nThe University of Texas at Austin']","['HAI: Learning Human Values and Preferences', 'HAI: Human-in-the-Loop Machine Learning', 'HAI: Other Foundations of Humans & AI', 'ML: Auto ML and Hyperparameter Tuning', 'ML: Reinforcement Learning Algorithms']","Booth, S., Knox, W. B., Shah, J., Niekum, S., Stone, P., & Allievi, A. (2023). The Perils of Trial-and-Error Reward Design: Misdesign through Overfitting and Invalid Task Specifications. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5920-5929. https://doi.org/10.1609/aaai.v37i5.25733","Abstract 					In reinforcement learning (RL), a reward function that aligns exactly with a task's true performance metric is often necessarily sparse. For example, a true task metric might encode a reward of 1 upon success and 0 otherwise. The sparsity of these true task metrics can make them hard to learn from, so in practice they are often replaced with alternative dense reward functions. These dense reward functions are typically designed by experts through an ad hoc process of trial and error. In this process, experts manually search for a reward function that improves performance with respect to the task metric while also enabling an RL algorithm to learn faster. This process raises the question of whether the same reward function is optimal for all algorithms, i.e., whether the reward function can be overfit to a particular algorithm. In this paper, we study the consequences of this wide yet unexamined practice of trial-and-error reward design. We first conduct computational experiments that confirm that reward functions can be overfit to learning algorithms and their hyperparameters. We then conduct a controlled observation study which emulates expert practitioners' typical experiences of reward design, in which we similarly find evidence of reward function overfitting. We also find that experts' typical approach to reward design---of adopting a myopic strategy and weighing the relative goodness of each state-action pair---leads to misdesign through invalid task specifications, since RL algorithms use cumulative reward rather than rewards for individual state-action pairs as an optimization target.  Code, data: github.com/serenabooth/reward-design-perils","https://ojs.aaai.org/index.php/AAAI/article/view/25733/25505"
"25734","The Value of AI Guidance in Human Examination of Synthetically-Generated Faces","['Aidan Boyd', 'Patrick Tinsley', 'Kevin Bowyer', 'Adam Czajka']","['University of Notre Dame', 'University of Notre Dame', 'University of Notre Dame', 'University of Notre Dame']","['HAI: Human-Machine Teams', 'CV: Adversarial Attacks & Robustness', 'CV: Biometrics', 'Face', 'Gesture & Pose', 'HAI: Human-in-the-Loop Machine Learning', 'HAI: Learning Human Values and Preferences']","Boyd, A., Tinsley, P., Bowyer, K., & Czajka, A. (2023). The Value of AI Guidance in Human Examination of Synthetically-Generated Faces. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5930-5938. https://doi.org/10.1609/aaai.v37i5.25734","Abstract 					Face image synthesis has progressed beyond the point at which humans can effectively distinguish authentic faces from synthetically-generated ones. Recently developed synthetic face image detectors boast ``better-than-human'' discriminative ability, especially those guided by human perceptual intelligence during the model's training process. In this paper, we investigate whether these human-guided synthetic face detectors can assist non-expert human operators in the task of synthetic image detection when compared to models trained without human-guidance. We conducted a large-scale experiment with more than 1,560 subjects classifying whether an image shows an authentic or synthetically-generated face, and annotating regions supporting their decisions. In total, 56,015 annotations across 3,780 unique face images were collected. All subjects first examined samples without any AI support, followed by samples given (a) the AI's decision (``synthetic'' or ``authentic''), (b) class activation maps illustrating where the model deems salient for its decision,  or (c) both the AI's decision and AI's saliency map. Synthetic faces were generated with six modern Generative Adversarial Networks. Interesting observations from this experiment include: (1) models trained with human-guidance, which are also more accurate in our experiments, offer better support to human examination of face images when compared to models trained traditionally using cross-entropy loss, (2) binary decisions presented to humans results in their better performance than when saliency maps are presented, (3) understanding the AI's accuracy helps humans to increase trust in a given model and thus increase their overall accuracy. This work demonstrates that although humans supported by machines achieve better-than-random accuracy of synthetic face detection, the approaches of supplying humans with AI support and of building trust are key factors determining high effectiveness of the human-AI tandem.","https://ojs.aaai.org/index.php/AAAI/article/view/25734/25506"
"25735","Teaching to Learn: Sequential Teaching of Learners with Internal States","['Mustafa Mert Çelikok', 'Pierre-Alexandre Murena', 'Samuel Kaski']","['Aalto University', 'Aalto University', 'Aalto University\nThe University of Manchester']","['HAI: Human-Machine Teams', 'HAI: Human-in-the-Loop Machine Learning', 'ML: Probabilistic Methods', 'MAS: Modeling Other Agents', 'MAS: Multiagent Learning', 'PRS: Planning With Markov Models (MDPs', 'POMDPs)']","Çelikok, M. M., Murena, P.-A., & Kaski, S. (2023). Teaching to Learn: Sequential Teaching of Learners with Internal States. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5939-5947. https://doi.org/10.1609/aaai.v37i5.25735","Abstract 					In sequential machine teaching, a teacher’s objective is to provide the optimal sequence of inputs to sequential learners in order to guide them towards the best model. However, this teaching objective considers a restricted class of learners with fixed inductive biases. In this paper, we extend the machine teaching framework to learners that can improve their inductive biases, represented as latent internal states, in order to generalize to new datasets. We introduce a novel framework in which learners’ inductive biases may change with the teaching interaction, which affects the learning performance in future tasks. In order to teach such learners, we propose a multi-objective control approach that takes the future performance of the learner after teaching into account. This framework provides tools for modelling learners with internal states, humans and meta-learning algorithms alike. Furthermore, we distinguish manipulative teaching, which can be done by effectively hiding data and also used for indoctrination, from teaching to learn which aims to help the learner become better at learning from new datasets in the absence of a teacher. Our empirical results demonstrate that our framework is able to reduce the number of required tasks for online meta-learning, and increases independent learning performance of simulated human users in future tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25735/25507"
"25736","Interactive Concept Bottleneck Models","['Kushal Chauhan', 'Rishabh Tiwari', 'Jan Freyberg', 'Pradeep Shenoy', 'Krishnamurthy Dvijotham']","['Google Research India', 'Google Research India', 'Google Health India', 'Google Research India', 'Google Research India']","['HAI: Human-Machine Teams', 'CV: Applications', 'CV: Interpretability and Transparency', 'HAI: Human-Computer Interaction', 'ML: Calibration & Uncertainty Quantification', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'RU: Applications']","Chauhan, K., Tiwari, R., Freyberg, J., Shenoy, P., & Dvijotham, K. (2023). Interactive Concept Bottleneck Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5948-5955. https://doi.org/10.1609/aaai.v37i5.25736","Abstract 					Concept bottleneck models (CBMs) are interpretable neural networks that first predict labels for human-interpretable concepts relevant to the prediction task, and then predict the final label based on the concept label predictions. We extend CBMs to interactive prediction settings where the model can query a human collaborator for the label to some concepts. We develop an interaction policy that, at prediction time, chooses which concepts to request a label for so as to maximally improve the final prediction. We demonstrate that a simple policy combining concept prediction uncertainty and influence of the concept on the final prediction achieves strong performance and outperforms static approaches as well as active feature acquisition methods proposed in the literature. We show that the interactive CBM can achieve accuracy gains of 5-10% with only 5 interactions over competitive baselines on the Caltech-UCSD Birds, CheXpert and OAI datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25736/25508"
"25737","Local Justice and Machine Learning: Modeling and Inferring Dynamic Ethical Preferences toward Allocations","['Violet (Xinying) Chen', 'Joshua Williams', 'Derek Leben', 'Hoda Heidari']","['Stevens Institute of Technology', 'Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University']","['HAI: Learning Human Values and Preferences', 'PEAI: Bias', 'Fairness & Equity']","Chen, V. (Xinying), Williams, J., Leben, D., & Heidari, H. (2023). Local Justice and Machine Learning: Modeling and Inferring Dynamic Ethical Preferences toward Allocations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5956-5964. https://doi.org/10.1609/aaai.v37i5.25737","Abstract 					We consider a setting in which a social planner has to make a sequence of decisions to allocate scarce resources in a high-stakes domain. Our goal is to understand stakeholders' dynamic moral preferences toward such allocational policies. In particular, we evaluate the sensitivity of moral preferences to the history of allocations and their perceived future impact on various socially salient groups.  We propose a mathematical model to capture and infer such dynamic moral preferences. We illustrate our model through small-scale human-subject experiments focused on the allocation of scarce medical resource distributions during a hypothetical viral epidemic. We observe that participants' preferences are indeed history- and impact-dependent. Additionally, our preliminary experimental results reveal intriguing patterns specific to medical resources---a topic that is particularly salient against the backdrop of the global covid-19 pandemic.","https://ojs.aaai.org/index.php/AAAI/article/view/25737/25509"
"25738","Extracting Semantic-Dynamic Features for Long-Term Stable Brain Computer Interface","['Tao Fang', 'Qian Zheng', 'Yu Qi', 'Gang Pan']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University']","['HAI: Brain-Sensing and Analysis', 'HAI: Applications']","Fang, T., Zheng, Q., Qi, Y., & Pan, G. (2023). Extracting Semantic-Dynamic Features for Long-Term Stable Brain Computer Interface. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5965-5973. https://doi.org/10.1609/aaai.v37i5.25738","Abstract 					Brain-computer Interface (BCI) builds a neural signal to the motor command pathway, which is a prerequisite for the realization of neural prosthetics. However, a long-term stable BCI suffers from the neural data drift across days while retraining the BCI decoder is expensive and restricts its application scenarios. Recent solutions of neural signal recalibration treat the continuous neural signals as discrete, which is less effective in temporal feature extraction. Inspired by the observation from biologists that low-dimensional dynamics could describe high-dimensional neural signals, we model the underlying neural dynamics and propose a semantic-dynamic feature that represents the semantics and dynamics in a shared feature space facilitating the BCI recalibration. Besides, we present the joint distribution alignment instead of the common used marginal alignment strategy, dealing with the various complex changes in neural data distribution. Our recalibration approach achieves state-of-the-art performance on the real neural data of two monkeys in both classification and regression tasks. Our approach is also evaluated on a simulated dataset, which indicates its robustness in dealing with various common causes of neural signal instability.","https://ojs.aaai.org/index.php/AAAI/article/view/25738/25510"
"25739","Moral Machine or Tyranny of the Majority?","['Michael Feffer', 'Hoda Heidari', 'Zachary C. Lipton']","['Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University']","['HAI: Learning Human Values and Preferences', 'PEAI: Bias', 'Fairness & Equity', 'PEAI: Morality and Value-Based AI']","Feffer, M., Heidari, H., & Lipton, Z. C. (2023). Moral Machine or Tyranny of the Majority?. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5974-5982. https://doi.org/10.1609/aaai.v37i5.25739","Abstract 					With artificial intelligence systems increasingly applied in consequential domains, researchers have begun to ask how AI systems ought to act in ethically charged situations where even humans lack consensus. In the Moral Machine project, researchers crowdsourced answers to ""Trolley Problems"" concerning autonomous vehicles. Subsequently, Noothigattu et al. (2018) proposed inferring linear functions that approximate each individual's preferences and aggregating these linear models by averaging parameters across the population. In this paper, we examine this averaging mechanism, focusing on fairness concerns and strategic effects. We investigate a simple setting where the population consists of two groups, the minority constitutes an α < 0.5 share of the population, and within-group preferences are homogeneous. Focusing on the fraction of contested cases where the minority group prevails, we make the following observations: (a) even when all parties report their preferences truthfully, the fraction of disputes where the minority prevails is less than proportionate in α; (b) the degree of sub-proportionality grows more severe as the level of disagreement between the groups increases; (c) when parties report preferences strategically, pure strategy equilibria do not always exist; and (d) whenever a pure strategy equilibrium exists, the majority group prevails 100% of the time. These findings raise concerns about stability and fairness of averaging as a mechanism for aggregating diverging voices. Finally, we discuss alternatives, including randomized dictatorship and median-based mechanisms.","https://ojs.aaai.org/index.php/AAAI/article/view/25739/25511"
"25740","The Effect of Modeling Human Rationality Level on Learning Rewards from Multiple Feedback Types","['Gaurav R. Ghosal', 'Matthew Zurek', 'Daniel S. Brown', 'Anca D. Dragan']","['EECS Department, University of California, Berkeley', 'UW-Madison', 'University of Utah', 'EECS Department, University of California, Berkeley']","['HAI: Learning Human Values and Preferences', 'HAI: Human-in-the-Loop Machine Learning', 'ML: Imitation Learning & Inverse Reinforcement Learning']","Ghosal, G. R., Zurek, M., Brown, D. S., & Dragan, A. D. (2023). The Effect of Modeling Human Rationality Level on Learning Rewards from Multiple Feedback Types. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5983-5992. https://doi.org/10.1609/aaai.v37i5.25740","Abstract 					When inferring reward functions from human behavior (be it demonstrations, comparisons, physical corrections, or e-stops), it has proven useful to model the human as making noisy-rational choices, with a ""rationality coefficient"" capturing how much noise or entropy we expect to see in the human behavior. Prior work typically sets the rationality level to a constant value, regardless of the type, or quality, of human feedback. However, in many settings, giving one type of feedback (e.g. a demonstration) may be much more difficult than a different type of feedback (e.g. answering a comparison query). Thus, we expect to see more or less noise depending on the type of human feedback. In this work, we advocate that grounding the rationality coefficient in real data for each feedback type, rather than assuming a default value, has a significant positive effect on reward learning. We test this in both simulated experiments and in a user study with real human feedback. We find that overestimating human rationality can have dire effects on reward learning accuracy and regret. We also find that fitting the rationality coefficient to human data enables better reward learning, even when the human deviates significantly from the noisy-rational choice model due to systematic biases. Further, we find that the rationality level affects the informativeness of each feedback type: surprisingly, demonstrations are not always the most informative---when the human acts very suboptimally, comparisons actually become more informative, even when the rationality level is the same for both.  Ultimately, our results emphasize the importance and advantage of paying attention to the assumed human-rationality-level, especially when agents actively learn from multiple types of human feedback.","https://ojs.aaai.org/index.php/AAAI/article/view/25740/25512"
"25741","The Role of Heuristics and Biases during Complex Choices with an AI Teammate","['Nikolos Gurney', 'John H. Miller', 'David V. Pynadath']","['Institute for Creative Technologies, University of Southern California', 'Carnegie Mellon University\nSanta Fe Institute', 'Institute for Creative Technologies, University of Southern California']","['HAI: Human-Computer Interaction', 'HAI: Human-Aware Planning and Behavior Prediction', 'HAI: Human-Machine Teams', 'HAI: Learning Human Values and Preferences', 'HAI: Other Foundations of Humans & AI', 'ROB: Human-Robot Interaction']","Gurney, N., Miller, J. H., & Pynadath, D. V. (2023). The Role of Heuristics and Biases during Complex Choices with an AI Teammate. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 5993-6001. https://doi.org/10.1609/aaai.v37i5.25741","Abstract 					Behavioral scientists have classically documented aversion to algorithmic decision aids, from simple linear models to AI. Sentiment, however, is changing and possibly accelerating AI helper usage. AI assistance is, arguably, most valuable when humans must make complex choices. We argue that classic experimental methods used to study heuristics and biases are insufficient for studying complex choices made with AI helpers. We adapted an experimental paradigm designed for studying complex choices in such contexts. We show that framing and anchoring effects impact how people work with an AI helper and are predictive of choice outcomes. The evidence suggests that some participants, particularly those in a loss frame, put too much faith in the AI helper and experienced worse choice outcomes by doing so. The paradigm also generates computational modeling-friendly data allowing future studies of human-AI decision making.","https://ojs.aaai.org/index.php/AAAI/article/view/25741/25513"
"25742","Learning to Defer with Limited Expert Predictions","['Patrick Hemmer', 'Lukas Thede', 'Michael Vössing', 'Johannes Jakubik', 'Niklas Kühl']","['Karlsruhe Institute of Technology', 'Karlsruhe Institute of Technology', 'Karlsruhe Institute of Technology', 'Karlsruhe Institute of Technology', 'Karlsruhe Institute of Technology']","['HAI: Human-Machine Teams']","Hemmer, P., Thede, L., Vössing, M., Jakubik, J., & Kühl, N. (2023). Learning to Defer with Limited Expert Predictions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6002-6011. https://doi.org/10.1609/aaai.v37i5.25742","Abstract 					Recent research suggests that combining AI models with a human expert can exceed the performance of either alone. The combination of their capabilities is often realized by learning to defer algorithms that enable the AI to learn to decide whether to make a prediction for a particular instance or defer it to the human expert. However, to accurately learn which instances should be deferred to the human expert, a large number of expert predictions that accurately reflect the expert's capabilities are required—in addition to the ground truth labels needed to train the AI. This requirement shared by many learning to defer algorithms hinders their adoption in scenarios where the responsible expert regularly changes or where acquiring a sufficient number of expert predictions is costly. In this paper, we propose a three-step approach to reduce the number of expert predictions required to train learning to defer algorithms. It encompasses (1) the training of an embedding model with ground truth labels to generate feature representations that serve as a basis for (2) the training of an expertise predictor model to approximate the expert's capabilities. (3) The expertise predictor generates artificial expert predictions for instances not yet labeled by the expert, which are required by the learning to defer algorithms. We evaluate our approach on two public datasets. One with ""synthetically"" generated human experts and another from the medical domain containing real-world radiologists' predictions. Our experiments show that the approach allows the training of various learning to defer algorithms with a minimal number of human expert predictions. Furthermore, we demonstrate that even a small number of expert predictions per class is sufficient for these algorithms to exceed the performance the AI and the human expert can achieve individually.","https://ojs.aaai.org/index.php/AAAI/article/view/25742/25514"
"25743","SWL-Adapt: An Unsupervised Domain Adaptation Model with Sample Weight Learning for Cross-User Wearable Human Activity Recognition","['Rong Hu', 'Ling Chen', 'Shenghuan Miao', 'Xing Tang']","['College of Computer Science and Technology, Zhejiang University', 'College of Computer Science and Technology, Zhejiang University\nAlibaba-Zhejiang University Joint Research Institute of Frontier Technologies', 'College of Computer Science and Technology, Zhejiang University', 'College of Computer Science and Technology, Zhejiang University']","['HAI: Human-Computer Interaction', 'APP: Internet of Things', 'Sensor Networks & Smart Cities', 'ML: Time-Series/Data Streams', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Unsupervised & Self-Supervised Learning']","Hu, R., Chen, L., Miao, S., & Tang, X. (2023). SWL-Adapt: An Unsupervised Domain Adaptation Model with Sample Weight Learning for Cross-User Wearable Human Activity Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6012-6020. https://doi.org/10.1609/aaai.v37i5.25743","Abstract 					In practice, Wearable Human Activity Recognition (WHAR) models usually face performance degradation on the new user due to user variance. Unsupervised domain adaptation (UDA) becomes the natural solution to cross-user WHAR under annotation scarcity. Existing UDA models usually align samples across domains without differentiation, which ignores the difference among samples. In this paper, we propose an unsupervised domain adaptation model with sample weight learning (SWL-Adapt) for cross-user WHAR. SWL-Adapt calculates sample weights according to the classification loss and domain discrimination loss of each sample with a parameterized network. We introduce the meta-optimization based update rule to learn this network end-to-end, which is guided by meta-classification loss on the selected pseudo-labeled target samples. Therefore, this network can fit a weighting function according to the cross-user WHAR task at hand, which is superior to existing sample differentiation rules fixed for special scenarios. Extensive experiments on three public WHAR datasets demonstrate that SWL-Adapt achieves the state-of-the-art performance on the cross-user WHAR task, outperforming the best baseline by an average of 3.1% and 5.3% in accuracy and macro F1 score, respectively.","https://ojs.aaai.org/index.php/AAAI/article/view/25743/25515"
"25744","Incentive-Boosted Federated Crowdsourcing","['Xiangping Kang', 'Guoxian Yu', 'Jun Wang', 'Wei Guo', 'Carlotta Domeniconi', 'Jinglin Zhang']","['Shandong University', 'Shandong University', 'Shandong University', 'Shandong University', 'George Mason University', 'Shandong University']","['HAI: Crowdsourcing', 'HAI: Human-in-the-Loop Machine Learning', 'ML: Distributed Machine Learning & Federated Learning', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Multi-Instance/Multi-View Learning']","Kang, X., Yu, G., Wang, J., Guo, W., Domeniconi, C., & Zhang, J. (2023). Incentive-Boosted Federated Crowdsourcing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6021-6029. https://doi.org/10.1609/aaai.v37i5.25744","Abstract 					Crowdsourcing is a favorable computing paradigm for processing computer-hard tasks by harnessing human intelligence. However, generic crowdsourcing systems may lead to privacy-leakage through the sharing of worker data. To tackle this problem, we propose a novel approach, called iFedCrowd (incentive-boosted Federated Crowdsourcing), to manage the privacy and quality of crowdsourcing projects. iFedCrowd allows participants to locally process sensitive data and only upload encrypted training models, and then aggregates the model parameters to build a shared server model to protect data privacy. To motivate workers to build a high-quality global model in an efficacy way, we introduce an incentive mechanism that encourages workers to constantly collect fresh data to train accurate client models and boosts the global model training. We model the incentive-based interaction between the crowdsourcing platform and participating workers as a Stackelberg game, in which each side maximizes its own profit. We derive the Nash Equilibrium of the game to find the optimal solutions for the two sides. Experimental results confirm that iFedCrowd can complete secure crowdsourcing projects with high quality and efficiency.","https://ojs.aaai.org/index.php/AAAI/article/view/25744/25516"
"25745","Towards Voice Reconstruction from EEG during Imagined Speech","['Young-Eun Lee', 'Seo-Hyun Lee', 'Sang-Ho Kim', 'Seong-Whan Lee']","['Korea University, Seoul, Republic of Korea', 'Korea University, Seoul, Republic of Korea', 'Korea University, Seoul, Republic of Korea', 'Korea University, Seoul, Republic of Korea']","['HAI: Brain-Sensing and Analysis', 'CMS: Brain Modeling', 'HAI: Communication Protocols']","Lee, Y.-E., Lee, S.-H., Kim, S.-H., & Lee, S.-W. (2023). Towards Voice Reconstruction from EEG during Imagined Speech. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6030-6038. https://doi.org/10.1609/aaai.v37i5.25745","Abstract 					Translating imagined speech from human brain activity into voice is a challenging and absorbing research issue that can provide new means of human communication via brain signals. Efforts to reconstruct speech from brain activity have shown their potential using invasive measures of spoken speech data, but have faced challenges in reconstructing imagined speech. In this paper, we propose NeuroTalk, which converts non-invasive brain signals of imagined speech into the user's own voice. Our model was trained with spoken speech EEG which was generalized to adapt to the domain of imagined speech, thus allowing natural correspondence between the imagined speech and the voice as a ground truth. In our framework, an automatic speech recognition decoder contributed to decomposing the phonemes of the generated speech, demonstrating the potential of voice reconstruction from unseen words. Our results imply the potential of speech synthesis from human EEG signals, not only from spoken speech but also from the brain signals of imagined speech.","https://ojs.aaai.org/index.php/AAAI/article/view/25745/25517"
"25746","Evaluating and Improving Interactions with Hazy Oracles","['Stephan J. Lemmer', 'Jason J. Corso']","['University of Michigan, Ann Arbor, MI', 'University of Michigan, Ann Arbor, MI']","['HAI: Human-Computer Interaction', 'ML: Evaluation and Analysis (Machine Learning)']","Lemmer, S. J., & Corso, J. J. (2023). Evaluating and Improving Interactions with Hazy Oracles. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6039-6047. https://doi.org/10.1609/aaai.v37i5.25746","Abstract 					Many AI systems integrate sensor inputs, world knowledge, and human-provided information to perform inference. While such systems often treat the human input as flawless, humans are better thought of as hazy oracles whose input may be ambiguous or outside of the AI system's understanding. In such situations it makes sense for the AI system to defer its inference while it disambiguates the human-provided information by, for example, asking the human to rephrase the query. Though this approach has been considered in the past, current work is typically limited to application-specific methods and non-standardized human experiments. We instead introduce and formalize a general notion of deferred inference. Using this formulation, we then propose a novel evaluation centered around the Deferred Error Volume (DEV) metric, which explicitly considers the tradeoff between error reduction and the additional human effort required to achieve it. We demonstrate this new formalization and an innovative deferred inference method on the disparate tasks of Single-Target Video Object Tracking and Referring Expression Comprehension, ultimately reducing error by up to 48% without any change to the underlying model or its parameters.","https://ojs.aaai.org/index.php/AAAI/article/view/25746/25518"
"25747","Human-in-the-Loop Vehicle ReID","['Zepeng Li', 'Dongxiang Zhang', 'Yanyan Shen', 'Gang Chen']","['Zhejiang University', 'Zhejiang University', 'Shanghai Jiao Tong University', 'Zhejiang University']","['HAI: Human-in-the-Loop Machine Learning', 'CV: Applications', 'CV: Image and Video Retrieval']","Li, Z., Zhang, D., Shen, Y., & Chen, G. (2023). Human-in-the-Loop Vehicle ReID. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6048-6055. https://doi.org/10.1609/aaai.v37i5.25747","Abstract 					Vehicle ReID has been an active topic in computer vision, with a substantial number of deep neural models proposed as end-to-end solutions. In this paper, we solve the problem from a new perspective and present an interesting variant called human-in-the-loop vehicle ReID to leverage interactive (and possibly wrong) human feedback signal for performance enhancement. Such human-machine cooperation mode is orthogonal to existing ReID models. To avoid incremental training overhead, we propose an Interaction ReID Network (IRIN) that can directly accept the feedback signal as an input and adjust the embedding of query image in an online fashion. IRIN is offline trained by simulating the human interaction process, with multiple optimization strategies to fully exploit the feedback signal. Experimental results show that even by interacting  with flawed feedback generated by non-experts, IRIN still outperforms state-of-the-art ReID models by a considerable margin. If the feedback contains no false positive, IRIN boosts the mAP in Veri776 from 81.6% to 95.2% with only 5 rounds of interaction per query image.","https://ojs.aaai.org/index.php/AAAI/article/view/25747/25519"
"25748","Modeling Human Trust and Reliance in AI-Assisted Decision Making: A Markovian Approach","['Zhuoyan Li', 'Zhuoran Lu', 'Ming Yin']","['Purdue University', 'Purdue University', 'Purdue University']","['HAI: Human-Computer Interaction', 'CMS: Simulating Humans', 'HAI: Human-Machine Teams']","Li, Z., Lu, Z., & Yin, M. (2023). Modeling Human Trust and Reliance in AI-Assisted Decision Making: A Markovian Approach. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6056-6064. https://doi.org/10.1609/aaai.v37i5.25748","Abstract 					The increased integration of artificial intelligence (AI) technologies in human workflows has resulted in a new paradigm of AI-assisted decision making, in which an AI model provides decision recommendations while humans make the final decisions. To best support humans in decision making, it is critical to obtain a quantitative understanding of how humans interact with and rely on AI. Previous studies often model humans' reliance on AI as an analytical process, i.e., reliance decisions are made based on cost-benefit analysis. However, theoretical models in psychology suggest that the reliance decisions can often be driven by emotions like humans' trust in AI models. In this paper, we propose a hidden Markov model to capture the affective process underlying the human-AI interaction in AI-assisted decision making, by characterizing how decision makers adjust their trust in AI over time and make reliance decisions based on their trust. Evaluations on real human behavior data collected from human-subject experiments show that the proposed model outperforms various baselines in accurately predicting humans' reliance behavior in AI-assisted decision making. Based on the proposed model, we further provide insights into how humans' trust and reliance dynamics in AI-assisted decision making is influenced by contextual factors like decision stakes and their interaction experiences.","https://ojs.aaai.org/index.php/AAAI/article/view/25748/25520"
"25749","Learning Deep Hierarchical Features with Spatial Regularization for One-Class Facial Expression Recognition","['Bingjun Luo', 'Junjie Zhu', 'Tianyu Yang', 'Sicheng Zhao', 'Chao Hu', 'Xibin Zhao', 'Yue Gao']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Central South University', 'Tsinghua University', 'Tsinghua University']","['HAI: Human-Computer Interaction', 'HAI: Emotional Intelligence', 'DMKM: Anomaly/Outlier Detection', 'APP: Humanities & Computational Social Science', 'CMS: Social Cognition and Interaction', 'ML: Other Foundations of Machine Learning']","Luo, B., Zhu, J., Yang, T., Zhao, S., Hu, C., Zhao, X., & Gao, Y. (2023). Learning Deep Hierarchical Features with Spatial Regularization for One-Class Facial Expression Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6065-6073. https://doi.org/10.1609/aaai.v37i5.25749","Abstract 					Existing methods on facial expression recognition (FER) are mainly trained in the setting when multi-class data is available. However, to detect the alien expressions that are absent during training, this type of methods cannot work. To address this problem, we develop a Hierarchical Spatial One Class Facial Expression Recognition Network (HS-OCFER) which can construct the decision boundary of a given expression class (called normal class) by training on only one-class data. Specifically, HS-OCFER consists of three novel components. First, hierarchical bottleneck modules are proposed to enrich the representation power of the model and extract detailed feature hierarchy from different levels. Second, multi-scale spatial regularization with facial geometric information is employed to guide the feature extraction towards emotional facial representations and prevent the model from overfitting extraneous disturbing factors. Third, compact intra-class variation is adopted to separate the normal class from alien classes in the decision space. Extensive evaluations on 4 typical FER datasets from both laboratory and wild scenarios show that our method consistently outperforms state-of-the-art One-Class Classification (OCC) approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/25749/25521"
"25750","Frustratingly Easy Truth Discovery","['Reshef Meir', 'Ofra Amir', 'Omer Ben-Porat', 'Tsviel Ben Shabat', 'Gal Cohensius', 'Lirong Xia']","['Technion – Israel Institute of Technology', 'Technion – Israel Institute of Technology', 'Technion – Israel Institute of Technology', 'Technion – Israel Institute of Technology', 'Technion – Israel Institute of Technology', 'RPI']","['HAI: Crowdsourcing', 'GTEP: Social Choice / Voting', 'HAI: Human Computation', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'ML: Unsupervised & Self-Supervised Learning']","Meir, R., Amir, O., Ben-Porat, O., Ben Shabat, T., Cohensius, G., & Xia, L. (2023). Frustratingly Easy Truth Discovery. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6074-6083. https://doi.org/10.1609/aaai.v37i5.25750","Abstract 					Truth discovery is a general name for a broad range of statistical methods aimed to extract the correct answers to questions, based on multiple answers coming from noisy sources. For example, workers in a crowdsourcing platform. In this paper, we consider an extremely simple heuristic for estimating workers' competence using  average proximity to other workers. We prove that this  estimates well the actual competence level and enables separating high and low quality workers in a wide spectrum of domains and statistical models. Under Gaussian noise,  this simple estimate is the unique solution to the MLE with a constant regularization factor.    Finally,  weighing workers according to their average proximity in a crowdsourcing setting, results in  substantial improvement over unweighted aggregation and other truth discovery algorithms in practice.","https://ojs.aaai.org/index.php/AAAI/article/view/25750/25522"
"25751","Beam Search Optimized Batch Bayesian Active Learning","['Jingyu Sun', 'Hongjie Zhai', 'Osamu Saisho', 'Susumu Takeuchi']","['NTT Computer and Data Science Laboratories', 'NTT Software Innovation Center', 'NTT Social Informatics Laboratories', 'NTT Computer and Data Science Laboratories']","['HAI: Human-in-the-Loop Machine Learning', 'HAI: Applications', 'ML: Active Learning', 'ML: Applications', 'ML: Deep Neural Architectures', 'ML: Evaluation and Analysis (Machine Learning)']","Sun, J., Zhai, H., Saisho, O., & Takeuchi, S. (2023). Beam Search Optimized Batch Bayesian Active Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6084-6091. https://doi.org/10.1609/aaai.v37i5.25751","Abstract 					Active Learning is an essential method for label-efficient deep learning. As a Bayesian active learning method, Bayesian Active Learning by Disagreement (BALD) successfully selects the most representative samples by maximizing the mutual information between the model prediction and model parameters. However, when applied to a batch acquisition mode, like batch construction with greedy search, BALD suffers from poor performance, especially with noises of near-duplicate data. To address this shortcoming, we propose a diverse beam search optimized batch active learning method, which explores a graph for every batch construction by expanding the highest-scored samples of a predetermined number. To avoid near duplicate beam branches (very similar beams generated from the same root and similar samples), which is undesirable for lacking diverse representations in the feature space, we design a self-adapted constraint within candidate beams. The proposed method is able to acquire data that can better represent the distribution of the unlabeled pool, and at the same time, be significantly different from existing beams. We observe that the proposed method achieves higher batch performance than the baseline methods on three benchmark datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25751/25523"
"25752","Multi-Scale Control Signal-Aware Transformer for Motion Synthesis without Phase","['Lintao Wang', 'Kun Hu', 'Lei Bai', 'Yu Ding', 'Wanli Ouyang', 'Zhiyong Wang']","['The University of Sydney', 'The Univeristy of Sydney', 'Shanghai AI Laboratory', 'Netease Fuxi AI Lab', 'The University of Sydney', 'The University of Sydney']","['HAI: Games', 'Virtual Humans', 'and Autonomous Characters', 'APP: Games']","Wang, L., Hu, K., Bai, L., Ding, Y., Ouyang, W., & Wang, Z. (2023). Multi-Scale Control Signal-Aware Transformer for Motion Synthesis without Phase. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6092-6100. https://doi.org/10.1609/aaai.v37i5.25752","Abstract 					Synthesizing controllable motion for a character using deep learning has been a promising approach due to its potential to learn a compact model without laborious feature engineering. To produce dynamic motion from weak control signals such as desired paths, existing methods often require auxiliary information such as phases for alleviating motion ambiguity, which limits their generalisation capability. As past poses often contain useful auxiliary hints, in this paper, we propose a task-agnostic deep learning method, namely Multi-scale Control Signal-aware Transformer (MCS-T), with an attention based encoder-decoder architecture to discover the auxiliary information implicitly for synthesizing controllable motion without explicitly requiring auxiliary information such as phase. Specifically, an encoder is devised to adaptively formulate the motion patterns of a character's past poses with multi-scale skeletons, and  a decoder driven by control signals to further synthesize and predict the character's state by paying context-specialised attention to the encoded past motion patterns. As a result, it helps alleviate the issues of low responsiveness and slow transition which often happen in conventional methods not using auxiliary information. Both qualitative and quantitative experimental results on an existing biped locomotion dataset, which involves diverse types of motion transitions, demonstrate the effectiveness of our method. In particular, MCS-T is able to successfully generate motions comparable to those generated by the methods using auxiliary information.","https://ojs.aaai.org/index.php/AAAI/article/view/25752/25524"
"25753","SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines","['Shizun Wang', 'Weihong Zeng', 'Xu Wang', 'Hao Yang', 'Li Chen', 'Chuang Zhang', 'Ming Wu', 'Yi Yuan', 'Yunzhao Zeng', 'Min Zheng', 'Jing Liu']","['Beijing University of Posts and Telecommunications', 'Douyin Vision', 'Douyin Vision', 'Douyin Vision', 'Douyin Vision', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Douyin Vision', 'Douyin Vision', 'Douyin Vision', 'Douyin Vision']","['HAI: Games', 'Virtual Humans', 'and Autonomous Characters', 'CV: Applications', 'ML: Deep Generative Models & Autoencoders', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Unsupervised & Self-Supervised Learning']","Wang, S., Zeng, W., Wang, X., Yang, H., Chen, L., Zhang, C., Wu, M., Yuan, Y., Zeng, Y., Zheng, M., & Liu, J. (2023). SwiftAvatar: Efficient Auto-Creation of Parameterized Stylized Character on Arbitrary Avatar Engines. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6101-6109. https://doi.org/10.1609/aaai.v37i5.25753","Abstract 					The creation of a parameterized stylized character involves careful selection of numerous parameters, also known as the ""avatar vectors"" that can be interpreted by the avatar engine. Existing unsupervised avatar vector estimation methods that auto-create avatars for users, however, often fail to work because of the domain gap between realistic faces and stylized avatar images. To this end, we propose SwiftAvatar, a novel avatar auto-creation framework that is evidently superior to previous works. SwiftAvatar introduces dual-domain generators to create pairs of realistic faces and avatar images using shared latent codes. The latent codes can then be bridged with the avatar vectors as pairs, by performing GAN inversion on the avatar images rendered from the engine using avatar vectors. Through this way, we are able to synthesize paired data in high-quality as many as possible, consisting of avatar vectors and their corresponding realistic faces. We also propose semantic augmentation to improve the diversity of synthesis. Finally, a light-weight avatar vector estimator is trained on the synthetic pairs to implement efficient auto-creation. Our experiments demonstrate the effectiveness and efficiency of SwiftAvatar on two different avatar engines. The superiority and advantageous flexibility of SwiftAvatar are also verified in both subjective and objective evaluations.","https://ojs.aaai.org/index.php/AAAI/article/view/25753/25525"
"25754","Human Joint Kinematics Diffusion-Refinement for Stochastic Motion Prediction","['Dong Wei', 'Huaijiang Sun', 'Bin Li', 'Jianfeng Lu', 'Weiqing Li', 'Xiaoning Sun', 'Shengxiang Hu']","['Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Tianjin AiForward Science and Technology Co., Ltd.', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology']","['HAI: Human-Aware Planning and Behavior Prediction', 'CV: Motion & Tracking', 'ML: Deep Generative Models & Autoencoders']","Wei, D., Sun, H., Li, B., Lu, J., Li, W., Sun, X., & Hu, S. (2023). Human Joint Kinematics Diffusion-Refinement for Stochastic Motion Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6110-6118. https://doi.org/10.1609/aaai.v37i5.25754","Abstract 					Stochastic human motion prediction aims to forecast multiple plausible future motions given a single pose sequence from the past. Most previous works focus on designing elaborate losses to improve the accuracy, while the diversity is typically characterized by randomly sampling a set of latent variables from the latent prior, which is then decoded into possible motions. This joint training of sampling and decoding, however, suffers from posterior collapse as the learned latent variables tend to be ignored by a strong decoder, leading to limited diversity. Alternatively, inspired by the diffusion process in nonequilibrium thermodynamics, we propose MotionDiff, a diffusion probabilistic model to treat the kinematics of human joints as heated particles, which will diffuse from original states to a noise distribution. This process not only offers a natural way to obtain the ""whitened'' latents without any trainable parameters, but also introduces a new noise in each diffusion step, both of which facilitate more diverse motions. Human motion prediction is then regarded as the reverse diffusion process that converts the noise distribution into realistic future motions conditioned on the observed sequence. Specifically, MotionDiff consists of two parts: a spatial-temporal transformer-based diffusion network to generate diverse yet plausible motions, and a flexible refinement network to further enable geometric losses and align with the ground truth. Experimental results on two datasets demonstrate that our model yields the competitive performance in terms of both diversity and accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25754/25526"
"25755","Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach","['Samuel Westby', 'Christoph Riedl']","['Northeastern University', 'Northeastern University']","['HAI: Human-Machine Teams', 'CMS: Bayesian Learning', 'CMS: Simulating Humans', 'HAI: Learning Human Values and Preferences']","Westby, S., & Riedl, C. (2023). Collective Intelligence in Human-AI Teams: A Bayesian Theory of Mind Approach. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6119-6127. https://doi.org/10.1609/aaai.v37i5.25755","Abstract 					We develop a network of Bayesian agents that collectively model the mental states of teammates from the observed communication. Using a generative computational approach to cognition, we make two contributions. First, we show that our agent could generate interventions that improve the collective intelligence of a human-AI team beyond what humans alone would achieve. Second, we develop a real-time measure of human's theory of mind ability and test theories about human cognition. We use data collected from an online experiment in which 145 individuals in 29 human-only teams of five communicate through a chat-based system to solve a cognitive task. We find that humans (a) struggle to fully integrate information from teammates into their decisions, especially when communication load is high, and (b) have cognitive biases which lead them to underweight certain useful, but ambiguous, information. Our theory of mind ability measure predicts both individual- and team-level performance. Observing teams' first 25% of messages explains about 8% of the variation in final team performance, a 170% improvement compared to the current state of the art.","https://ojs.aaai.org/index.php/AAAI/article/view/25755/25527"
"25756","Learning to Select Pivotal Samples for Meta Re-weighting","['Yinjun Wu', 'Adam Stein', 'Jacob Gardner', 'Mayur Naik']","['University of Pennsylvania', 'University of Pennsylvania', 'University of Pennsylvania', 'University of Pennsylvania']","['HAI: Human-in-the-Loop Machine Learning', 'HAI: Applications', 'HAI: Crowdsourcing']","Wu, Y., Stein, A., Gardner, J., & Naik, M. (2023). Learning to Select Pivotal Samples for Meta Re-weighting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6128-6136. https://doi.org/10.1609/aaai.v37i5.25756","Abstract 					Sample re-weighting strategies provide a promising mechanism to deal with imperfect training data in machine learning, such as noisily labeled or class-imbalanced data. One such strategy involves formulating a bi-level optimization problem called the meta re-weighting problem, whose goal is to optimize performance on a small set of perfect pivotal samples, called meta samples. Many approaches have been proposed to efficiently solve this problem. However, all of them assume that a perfect meta sample set is already provided while we observe that the selections of meta sample set is performance-critical. In this paper, we study how to learn to identify such a meta sample set from a large, imperfect training set, that is subsequently cleaned and used to optimize performance in the meta re-weighting setting. We propose a learning framework which reduces the meta samples selection problem to a weighted K-means clustering problem through rigorously theoretical analysis. We propose two clustering methods within our learning framework, Representation-based clustering method (RBC) and Gradient-based clustering method (GBC), for balancing performance and computational efficiency. Empirical studies demonstrate the performance advantage of our methods over various baseline methods","https://ojs.aaai.org/index.php/AAAI/article/view/25756/25528"
"25757","Better Peer Grading through Bayesian Inference","['Hedayat Zarkoob', ""Greg d'Eon"", 'Lena Podina', 'Kevin Leyton-Brown']","['University of British Columbia', 'University of British Columbia', 'University of Waterloo\nUniversity of British Columbia', 'University of British Columbia']","['HAI: Crowdsourcing', 'APP: Education', 'GTEP: Applications', 'GTEP: Mechanism Design']","Zarkoob, H., d’Eon, G., Podina, L., & Leyton-Brown, K. (2023). Better Peer Grading through Bayesian Inference. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6137-6144. https://doi.org/10.1609/aaai.v37i5.25757","Abstract 					Peer grading systems aggregate noisy reports from multiple students to approximate a ""true"" grade as closely as possible. Most current systems either take the mean or median of reported grades; others aim to estimate students’ grading accuracy under a probabilistic model. This paper extends the state of the art in the latter approach in three key ways:  (1) recognizing that students can behave strategically (e.g., reporting grades close to the class average without doing the work); (2) appropriately handling censored data that arises from discrete-valued grading rubrics; and (3) using mixed integer programming to improve the interpretability of the grades assigned to students. We demonstrate how to make Bayesian inference practical in this model and evaluate our approach on both synthetic and real-world data obtained by using our implemented system in four large classes. These extensive experiments show that grade aggregation using our model accurately estimates true grades, students' likelihood of submitting uninformative grades, and the variation in their inherent grading error; we also characterize our models' robustness.","https://ojs.aaai.org/index.php/AAAI/article/view/25757/25529"
"25758","Maximum Entropy Population-Based Training for Zero-Shot Human-AI Coordination","['Rui Zhao', 'Jinming Song', 'Yufeng Yuan', 'Haifeng Hu', 'Yang Gao', 'Yi Wu', 'Zhongqian Sun', 'Wei Yang']","['Tencent AI Lab', 'Tencent AI Lab', 'Tencent AI Lab', 'Tencent AI Lab', 'Tsinghua University', 'Tsinghua University', 'Tencent AI Lab', 'Tencent AI Lab']","['HAI: Games', 'Virtual Humans', 'and Autonomous Characters', 'ML: Reinforcement Learning Algorithms', 'MAS: Coordination and Collaboration']","Zhao, R., Song, J., Yuan, Y., Hu, H., Gao, Y., Wu, Y., Sun, Z., & Yang, W. (2023). Maximum Entropy Population-Based Training for Zero-Shot Human-AI Coordination. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6145-6153. https://doi.org/10.1609/aaai.v37i5.25758","Abstract 					We study the problem of training a Reinforcement Learning (RL) agent that is collaborative with humans without using human data. Although such agents can be obtained through self-play training, they can suffer significantly from the distributional shift when paired with unencountered partners, such as humans. In this paper, we propose Maximum Entropy Population-based training (MEP) to mitigate such distributional shift. In MEP, agents in the population are trained with our derived Population Entropy bonus to promote the pairwise diversity between agents and the individual diversity of agents themselves. After obtaining this diversified population, a common best agent is trained by paring with agents in this population via prioritized sampling, where the prioritization is dynamically adjusted based on the training progress. We demonstrate the effectiveness of our method MEP, with comparison to Self-Play PPO (SP), Population-Based Training (PBT), Trajectory Diversity (TrajeDi), and Fictitious Co-Play (FCP) in both matrix game and Overcooked game environments, with partners being human proxy models and real humans. A supplementary video showing experimental results is available at https://youtu.be/Xh-FKD0AAKE.","https://ojs.aaai.org/index.php/AAAI/article/view/25758/25530"
"25759","A Set of Control Points Conditioned Pedestrian Trajectory Prediction","['Inhwan Bae', 'Hae-Gon Jeon']","['Gwangju Institute of Science and Technology', 'Gwangju Institute of Science and Technology']","['ROB: Motion and Path Planning', 'ROB: Behavior Learning & Control', 'ROB: Multi-Robot Systems', 'CV: Motion & Tracking']","Bae, I., & Jeon, H.-G. (2023). A Set of Control Points Conditioned Pedestrian Trajectory Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6155-6165. https://doi.org/10.1609/aaai.v37i5.25759","Abstract 					Predicting the trajectories of pedestrians in crowded conditions is an important task for applications like autonomous navigation systems. Previous studies have tackled this problem using two strategies. They (1) infer all future steps recursively, or (2) predict the potential destinations of pedestrians at once and interpolate the intermediate steps to arrive there. However, these strategies often suffer from the accumulated errors of the recursive inference, or restrictive assumptions about social relations in the intermediate path. In this paper, we present a graph convolutional network-based trajectory prediction. Firstly, we propose a control point prediction that divides the future path into three sections and infers the intermediate destinations of pedestrians to reduce the accumulated error. To do this, we construct multi-relational weighted graphs to account for their physical and complex social relations. We then introduce a trajectory refinement step based on a spatio-temporal and multi-relational graph. By considering the social interactions between neighbors, better prediction results are achievable. In experiments, the proposed network achieves state-of-the-art performance on various real-world trajectory prediction benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25759/25531"
"25760","Meta-Auxiliary Learning for Adaptive Human Pose Prediction","['Qiongjie Cui', 'Huaijiang Sun', 'Jianfeng Lu', 'Bin Li', 'Weiqing Li']","['Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Tianjin AiForward Science and Technology Co., Ltd., China', 'Nanjing University of Science and Technology']","['ROB: Human-Robot Interaction', 'CV: 3D Computer Vision', 'HAI: Human-Aware Planning and Behavior Prediction']","Cui, Q., Sun, H., Lu, J., Li, B., & Li, W. (2023). Meta-Auxiliary Learning for Adaptive Human Pose Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6166-6174. https://doi.org/10.1609/aaai.v37i5.25760","Abstract 					Predicting high-fidelity future human poses, from a historically observed sequence, is crucial for intelligent robots to interact with humans. Deep end-to-end learning approaches, which typically train a generic pre-trained model on external datasets and then directly apply it to all test samples, emerge as the dominant solution to solve this issue. Despite encouraging progress, they remain non-optimal, as the unique properties (e.g., motion style, rhythm) of a specific sequence cannot be adapted. More generally, once encountering out-of-distributions, the predicted poses tend to be unreliable. Motivated by this observation, we propose a novel test-time adaptation framework that leverages two self-supervised auxiliary tasks to help the primary forecasting network adapt to the test sequence. In the testing phase, our model can adjust the model parameters by several gradient updates to improve the generation quality. However, due to catastrophic forgetting, both auxiliary tasks typically have a low ability to automatically present the desired positive incentives for the final prediction performance. For this reason, we also propose a meta-auxiliary learning scheme for better adaptation. Extensive experiments show that the proposed approach achieves higher accuracy and more realistic visualization.","https://ojs.aaai.org/index.php/AAAI/article/view/25760/25532"
"25761","Moving-Landmark Assisted Distributed Learning Based Decentralized Cooperative Localization (DL-DCL) with Fault Tolerance","['Shubhankar Gupta', 'Suresh Sundaram']","['Indian Institute of Science, Bengaluru', 'Indian Institute of Science, Bengaluru']","['ROB: Localization', 'Mapping', 'and Navigation', 'ROB: Multi-Robot Systems', 'ROB: State Estimation', 'MAS: Multiagent Learning', 'MAS: Multiagent Systems Under Uncertainty']","Gupta, S., & Sundaram, S. (2023). Moving-Landmark Assisted Distributed Learning Based Decentralized Cooperative Localization (DL-DCL) with Fault Tolerance. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6175-6182. https://doi.org/10.1609/aaai.v37i5.25761","Abstract 					This paper considers the problem of cooperative localization of multiple robots under uncertainty, communicating over a partially connected, dynamic communication network and assisted by an agile landmark. Each robot owns an IMU and a relative pose sensing suite, which can get faulty due to system or environmental uncertainty, and therefore exhibit large bias in their estimation output. For the robots to localize accurately under sensor failure and system or environmental uncertainty, a novel Distributed Learning based Decentralized Cooperative Localization (DL-DCL) algorithm is proposed that involves real-time learning of an information fusion strategy by each robot for combining pose estimates from its own sensors as well as from those of its neighboring robots, and utilizing the moving landmark's pose information as a feedback to the learning process. Convergence analysis shows that the learning process converges exponentially under certain reasonable assumptions. Simulations involving sensor failures inducing around 40-60 times increase in the nominal bias show DL-DCL's estimation performance to be approximately 40% better than the well-known covariance-based estimate fusion methods. For the evaluation of DL-DCL's implementability and fault-tolerance capability in practice, a high-fidelity simulation is carried out in Gazebo with ROS2.","https://ojs.aaai.org/index.php/AAAI/article/view/25761/25533"
"25762","Periodic Multi-Agent Path Planning","['Kazumi Kasaura', 'Ryo Yonetani', 'Mai Nishimura']","['OMRON SINIC X Corporation', 'OMRON SINIC X Corporation', 'OMRON SINIC X Corporation']","['ROB: Motion and Path Planning', 'ROB: Multi-Robot Systems']","Kasaura, K., Yonetani, R., & Nishimura, M. (2023). Periodic Multi-Agent Path Planning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6183-6191. https://doi.org/10.1609/aaai.v37i5.25762","Abstract 					Multi-agent path planning (MAPP) is the problem of planning collision-free trajectories from start to goal locations for a team of agents. This work explores a relatively unexplored setting of MAPP where streams of agents have to go through the starts and goals with high throughput. We tackle this problem by formulating a new variant of MAPP called periodic MAPP in which the timing of agent appearances is periodic. The objective with periodic MAPP is to find a periodic plan, a set of collision-free trajectories that the agent streams can use repeatedly over periods, with periods that are as small as possible. To meet this objective, we propose a solution method that is based on constraint relaxation and optimization. We show that the periodic plans once found can be used for a more practical case in which agents in a stream can appear at random times. We confirm the effectiveness of our method compared with baseline methods in terms of throughput in several scenarios that abstract autonomous intersection management tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25762/25534"
"25763","Improving Robotic Tactile Localization Super-resolution via Spatiotemporal Continuity Learning and Overlapping Air Chambers","['Xuyang Li', 'Yipu Zhang', 'Xuemei Xie', 'Jiawei Li', 'Guangming Shi']","['Xidian University', 'Xidian University', 'Xidian University\nPazhou Lab, Huangpu', 'Xidian University', 'Xidian University\nPeng Cheng Laboratory']","['ROB: Multimodal Perception & Sensor Fusion', 'ROB: Human-Robot Interaction', 'ROB: Other Foundations of Intelligent Robots', 'ML: Causal Learning']","Li, X., Zhang, Y., Xie, X., Li, J., & Shi, G. (2023). Improving Robotic Tactile Localization Super-resolution via Spatiotemporal Continuity Learning and Overlapping Air Chambers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6192-6199. https://doi.org/10.1609/aaai.v37i5.25763","Abstract 					Human hand has amazing super-resolution ability in sensing the force and position of contact and this ability can be strengthened by practice. Inspired by this, we propose a method for robotic tactile super-resolution enhancement by learning spatiotemporal continuity of contact position and a tactile sensor composed of overlapping air chambers. Each overlapping air chamber is constructed of soft material and seals the barometer inside to mimic adapting receptors of human skin. Each barometer obtains the global receptive field of the contact surface with the pressure propagation in the hyperelastic seal overlapping air chambers.  Neural networks with causal convolution are employed to resolve the pressure data sampled by barometers and to predict the contact position. The temporal consistency of spatial position contributes to the accuracy and stability of positioning. We obtain an average super-resolution (SR) factor of over 2500 with only four physical sensing nodes on the rubber surface (0.1 mm in the best case on 38 × 26 mm²), which outperforms the state-of-the-art. The effect of time series length on the location prediction accuracy of causal convolution is quantitatively analyzed in this article.  We show that robots can accomplish challenging tasks such as haptic trajectory following, adaptive grasping, and human-robot interaction with the tactile sensor. This research provides new insight into tactile super-resolution sensing and could be beneficial to various applications in the robotics field.","https://ojs.aaai.org/index.php/AAAI/article/view/25763/25535"
"25764","Co-imitation: Learning Design and Behaviour by Imitation","['Chang Rajani', 'Karol Arndt', 'David Blanco-Mulero', 'Kevin Sebastian Luck', 'Ville Kyrki']","['University of Helsinki\nAalto University', 'Aalto University', 'Aalto University', 'Aalto University\nFinnish Center for Artificial Intelligence', 'Aalto University']","['ROB: Learning & Optimization for ROB', 'ROB: Behavior Learning & Control', 'ML: Evolutionary Learning', 'ML: Imitation Learning & Inverse Reinforcement Learning']","Rajani, C., Arndt, K., Blanco-Mulero, D., Luck, K. S., & Kyrki, V. (2023). Co-imitation: Learning Design and Behaviour by Imitation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6200-6208. https://doi.org/10.1609/aaai.v37i5.25764","Abstract 					The co-adaptation of robots has been a long-standing research endeavour with the goal of adapting both body and behaviour of a robot for a given task, inspired by the natural evolution of animals. Co-adaptation has the potential to eliminate costly manual hardware engineering as well as improve the performance of systems. The standard approach to co-adaptation is to use a reward function for optimizing behaviour and morphology. However, defining and constructing such reward functions is notoriously difficult and often a significant engineering effort. This paper introduces a new viewpoint on the co-adaptation problem, which we call co-imitation: finding a morphology and a policy that allow an imitator to closely match the behaviour of a demonstrator. To this end we propose a co-imitation methodology for adapting behaviour and morphology by matching state-distributions of the demonstrator. Specifically, we focus on the challenging scenario with mismatched state- and action-spaces between both agents. We find that co-imitation increases behaviour similarity across a variety of tasks and settings, and demonstrate co-imitation by transferring human walking, jogging and kicking skills onto a simulated humanoid.","https://ojs.aaai.org/index.php/AAAI/article/view/25764/25536"
"25765","RobustLoc: Robust Camera Pose Regression in Challenging Driving Environments","['Sijie Wang', 'Qiyu Kang', 'Rui She', 'Wee Peng Tay', 'Andreas Hartmannsgruber', 'Diego Navarro Navarro']","['Nanyang Technological University', 'Nanyang Technological University', 'Nanyang Technological University', 'Nanyang Technological University', 'Continental Automotive', 'Continental Automotive']","['ROB: Localization', 'Mapping', 'and Navigation', 'CV: Vision for Robotics & Autonomous Driving']","Wang, S., Kang, Q., She, R., Tay, W. P., Hartmannsgruber, A., & Navarro Navarro, D. (2023). RobustLoc: Robust Camera Pose Regression in Challenging Driving Environments. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6209-6216. https://doi.org/10.1609/aaai.v37i5.25765","Abstract 					Camera relocalization has various applications in autonomous driving. Previous camera pose regression models consider only ideal scenarios where there is little environmental perturbation. To deal with challenging driving environments that may have changing seasons, weather, illumination, and the presence of unstable objects, we propose RobustLoc, which derives its robustness against perturbations from neural differential equations. Our model uses a convolutional neural network to extract feature maps from multi-view images, a robust neural differential equation diffusion block module to diffuse information interactively, and a branched pose decoder with multi-layer training to estimate the vehicle poses. Experiments demonstrate that RobustLoc surpasses current state-of-the-art camera pose regression models and achieves robust performance in various environments. Our code is released at: https://github.com/sijieaaa/RobustLoc","https://ojs.aaai.org/index.php/AAAI/article/view/25765/25537"
"25766","Abstract Argumentation Framework with Conditional Preferences","['Gianvincenzo Alfano', 'Sergio Greco', 'Francesco Parisi', 'Irina Trubitsyna']","['University of Calabria', 'University of Calabria', 'University of Calabria', 'University of Calabria']","['KRR: Argumentation']","Alfano, G., Greco, S., Parisi, F., & Trubitsyna, I. (2023). Abstract Argumentation Framework with Conditional Preferences. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6218-6227. https://doi.org/10.1609/aaai.v37i5.25766","Abstract 					Dung's abstract Argumentation Framework (AF) has emerged as a central formalism in the area of knowledge representation and reasoning. Preferences in AF allow to represent the comparative strength of arguments in a simple yet expressive way.  Preference-based AF (PAF) has been proposed to extend AF with preferences of the form a > b, whose intuitive meaning is that argument a is better than b.  In this paper we generalize PAF by introducing conditional preferences of the form a > b \leftarrow body that informally state that a is better than b whenever the condition expressed by body is true. The resulting framework, namely Conditional Preference-based AF (CPAF), extends the PAF semantics under three well-known preference criteria, i.e. democratic, elitist, and KTV.   After introducing CPAF, we study the complexity of the verification problem (deciding whether a set of arguments is a ``best'' extension) as well as of the credulous and skeptical acceptance problems (deciding whether a given argument belongs to any or all ``best'' extensions, respectively) under multiple-status semantics (that is, complete, preferred, stable, and semi-stable semantics) for the above-mentioned preference criteria.","https://ojs.aaai.org/index.php/AAAI/article/view/25766/25538"
"25767","Reactive Synthesis of Dominant Strategies","['Benjamin Aminof', 'Giuseppe De Giacomo', 'Sasha Rubin']","['TU Wien\nUniversità degli Studi di Roma “La Sapienza""', 'University of Oxford\nUniversità degli Studi di Roma “La Sapienza""', 'University of Sydney']","['KRR: Action', 'Change', 'and Causality']","Aminof, B., De Giacomo, G., & Rubin, S. (2023). Reactive Synthesis of Dominant Strategies. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6228-6235. https://doi.org/10.1609/aaai.v37i5.25767","Abstract 					We study the synthesis under environment specifications problem for LTL/LTLf which, in particular, generalizes FOND (strong) planning with these temporal goals. We consider the case where the agent cannot enforce its goal --- for which the argument for using best-effort strategies has been made  --- and study the intermediate ground, between enforcing and best-effort strategies, of dominant strategies. Intuitively, such strategies achieve the goal against any environment for which it is achievable.    We show that dominant strategies may exist when enforcing ones do not, while still sharing with the latter many desirable properties such as being interchangeable with each other, and being monotone with respect to tightening of environment specifications. We give necessary and sufficient conditions for the existence of dominant strategies, and show that deciding if they exist is 2EXPTIME-complete --- the same as for enforcing strategies. Finally, we give a uniform, optimal, game-theoretic algorithm for simultaneously solving the three synthesis problems of enforcing, dominant, and best-effort strategies.","https://ojs.aaai.org/index.php/AAAI/article/view/25767/25539"
"25768","Complexity of Safety and coSafety Fragments of Linear Temporal Logic","['Alessandro Artale', 'Luca Geatti', 'Nicola Gigante', 'Andrea Mazzullo', 'Angelo Montanari']","['Free University of Bozen-Bolzano', 'University of Udine', 'Free University of Bozen-Bolzano', 'Free University of Bozen-Bolzano', 'University of Udine']","['KRR: Computational Complexity of Reasoning', 'KRR: Geometric', 'Spatial', 'and Temporal Reasoning', 'KRR: Other Foundations of Knowledge Representation & Reasoning']","Artale, A., Geatti, L., Gigante, N., Mazzullo, A., & Montanari, A. (2023). Complexity of Safety and coSafety Fragments of Linear Temporal Logic. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6236-6244. https://doi.org/10.1609/aaai.v37i5.25768","Abstract 					Linear Temporal Logic (LTL) is the de-facto standard temporal logic for system specification, whose foundational properties have been studied for over five decades. Safety and cosafety properties of LTL define notable fragments of LTL, where a prefix of a trace suffices to establish whether a formula is true or not over that trace. In this paper, we study the complexity of the problems of satisfiability, validity, and realizability over infinite and finite traces for the safety and cosafety fragments of LTL. As for satisfiability and validity over infinite traces, we prove that the majority of the fragments have the same complexity as full LTL, that is, they are PSPACE-complete. The picture is radically different for realizability: we find fragments with the same expressive power whose complexity varies from 2EXPTIME-complete (as full LTL) to EXPTIME-complete. Notably, for all cosafety fragments, the complexity of the three problems does not change passing from infinite to finite traces, while for all safety fragments the complexity of satisfiability (resp., realizability) over finite traces drops to NP-complete (resp., Πᴾ₂- complete).","https://ojs.aaai.org/index.php/AAAI/article/view/25768/25540"
"25769","Automatically Verifying Expressive Epistemic Properties of Programs","['Francesco Belardinelli', 'Ioana Boureanu', 'Vadim Malvone', 'Fortunat Rajaona']","['Imperial College London', 'University of Surrey', 'Telecom Paris', 'University of Surrey']","['KRR: Knowledge Representation Languages']","Belardinelli, F., Boureanu, I., Malvone, V., & Rajaona, F. (2023). Automatically Verifying Expressive Epistemic Properties of Programs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6245-6252. https://doi.org/10.1609/aaai.v37i5.25769","Abstract 					We propose a new approach to the verification of epistemic properties of programmes. First, we introduce the new ``program-epistemic'' logic L_PK, which is strictly richer and more general than similar formalisms appearing in the literature. To solve the verification problem in an efficient way, we introduce a translation from our language L_PK into first-order logic. Then, we show and prove correct a reduction from the model checking problem for program-epistemic formulas to the satisfiability of their first-order translation. Both our logic and our translation can handle richer specification w.r.t. the state of the art, allowing us to express the knowledge of agents about facts pertaining to programs (i.e., agents' knowledge before a program is executed as well as after is has been executed). Furthermore, we implement our translation in Haskell in a general way (i.e., independently of the programs in the logical statements), and we use existing SMT-solvers to check satisfaction of L_PK formulas on a benchmark example in the AI/agency field.","https://ojs.aaai.org/index.php/AAAI/article/view/25769/25541"
"25770","The Effect of Preferences in Abstract Argumentation under a Claim-Centric View","['Michael Bernreiter', 'Wolfgang Dvorak', 'Anna Rapberger', 'Stefan Woltran']","['TU Wien', 'TU Wien', 'TU Wien', 'TU Wien']","['KRR: Argumentation', 'KRR: Computational Complexity of Reasoning', 'KRR: Nonmonotonic Reasoning', 'KRR: Preferences']","Bernreiter, M., Dvorak, W., Rapberger, A., & Woltran, S. (2023). The Effect of Preferences in Abstract Argumentation under a Claim-Centric View. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6253-6261. https://doi.org/10.1609/aaai.v37i5.25770","Abstract 					In this paper, we study the effect of preferences in abstract argumentation under a claim-centric perspective. Recent work has revealed that semantical and computational properties can change when reasoning is performed on    claim-level rather than on the argument-level, while under certain    natural restrictions (arguments with the same claims have the    same outgoing attacks) these properties are conserved. We now investigate   these effects when, in addition, preferences have to be taken into account and consider four prominent reductions to handle preferences between arguments.   As we shall see, these reductions give rise to    different classes of claim-augmented argumentation frameworks, and behave    differently in terms of semantic properties and computational complexity.   This strengthens the view that the actual choice for handling preferences    has to be taken with care.","https://ojs.aaai.org/index.php/AAAI/article/view/25770/25542"
"25771","The Parameterized Complexity of Network Microaggregation","['Václav Blažej', 'Robert Ganian', 'Dušan Knop', 'Jan Pokorný', 'Šimon Schierreich', 'Kirill Simonov']","['Faculty of Information Technology, Czech Technical University in Prague, Prague, Czechia', 'Algorithms and Complexity Group, Technische Universität Wien, Vienna, Austria', 'Faculty of Information Technology, Czech Technical University in Prague, Prague, Czechia', 'Faculty of Information Technology, Czech Technical University in Prague, Prague, Czechia', 'Faculty of Information Technology, Czech Technical University in Prague, Prague, Czechia', 'Hasso Plattner Institute, University of Potsdam, Postdam, Germany']","['KRR: Computational Complexity of Reasoning', 'CSO: Other Foundations of Constraint Satisfaction & Optimization', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'GTEP: Other Foundations of Game Theory & Economic Paradigms', 'ML: Clustering']","Blažej, V., Ganian, R., Knop, D., Pokorný, J., Schierreich, Šimon, & Simonov, K. (2023). The Parameterized Complexity of Network Microaggregation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6262-6270. https://doi.org/10.1609/aaai.v37i5.25771","Abstract 					Microaggregation is a classical statistical disclosure control technique which requires the input data to be partitioned into clusters while adhering to specified size constraints. We provide novel exact algorithms and lower bounds for the task of microaggregating a given network while considering both unrestricted and connected clusterings, and analyze these from the perspective of the parameterized complexity paradigm. Altogether, our results assemble a complete complexity-theoretic picture for the network microaggregation problem with respect to the most natural parameterizations of the problem, including input-specified parameters capturing the size and homogeneity of the clusters as well as the treewidth and vertex cover number of the network.","https://ojs.aaai.org/index.php/AAAI/article/view/25771/25543"
"25772","SMT Safety Verification of Ontology-Based Processes","['Diego Calvanese', 'Alessandro Gianola', 'Andrea Mazzullo', 'Marco Montali']","['Faculty of Engineering, Free University of Bozen-Bolzano, Italy\nComputing Science Department, Umeå University, Sweden', 'Faculty of Engineering, Free University of Bozen-Bolzano, Italy', 'Faculty of Engineering, Free University of Bozen-Bolzano, Italy', 'Faculty of Engineering, Free University of Bozen-Bolzano, Italy']","['KRR: Action', 'Change', 'and Causality', 'KRR: Description Logics', 'KRR: Automated Reasoning and Theorem Proving']","Calvanese, D., Gianola, A., Mazzullo, A., & Montali, M. (2023). SMT Safety Verification of Ontology-Based Processes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6271-6279. https://doi.org/10.1609/aaai.v37i5.25772","Abstract 					In the context of verification of data-aware processes, a formal approach based on satisfiability modulo theories (SMT) has been considered to verify parameterised safety properties. This approach requires a combination of model-theoretic notions and algorithmic techniques based on backward reachability. We introduce here Ontology-Based Processes, which are a variant of one of the most investigated models in this spectrum, namely simple artifact systems (SASs), where, instead of managing a database, we operate over a description logic (DL) ontology.  We prove that when the DL is expressed in (a slight extension of) RDFS, it enjoys suitable model-theoretic properties, and that by relying on such DL we can define Ontology-Based Processes to which backward reachability can still be applied.  Relying on these results we are able to show that in this novel setting, verification of safety properties is decidable in PSPACE.","https://ojs.aaai.org/index.php/AAAI/article/view/25772/25544"
"25773","Epistemic Disjunctive Datalog for Querying Knowledge Bases","['Gianluca Cima', 'Marco Console', 'Maurizio Lenzerini', 'Antonella Poggi']","['Sapienza University of Rome', 'Sapienza University of Rome', 'Sapienza University of Rome', 'Sapienza University of Rome']","['KRR: Description Logics', 'KRR: Computational Complexity of Reasoning', 'KRR: Logic Programming', 'KRR: Ontologies and Semantic Web']","Cima, G., Console, M., Lenzerini, M., & Poggi, A. (2023). Epistemic Disjunctive Datalog for Querying Knowledge Bases. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6280-6288. https://doi.org/10.1609/aaai.v37i5.25773","Abstract 					The Datalog query language can express several powerful recursive properties, often crucial in real-world scenarios. While answering such queries is feasible over relational databases, the picture changes dramatically when data is enriched with intensional knowledge. It is indeed well-known that answering Datalog queries is undecidable already over lightweight knowledge bases (KBs) of the DL-Lite family. To overcome this issue, we propose a new query language based on Disjunctive Datalog rules combined with a modal epistemic operator. Rules in this language interact with the queried KB exclusively via the epistemic operator, thus extracting only the information true in every model of the KB. This form of interaction is crucial for not falling into undecidability. The contribution provided by this paper is threefold. First, we illustrate the syntax and the semantics of the novel query language. Second, we study the expressive power of different fragments of our new language and compare it with Disjunctive Datalog and its variants. Third, we outline the precise data complexity of answering queries in our new language over KBs expressed in various well-known formalisms.","https://ojs.aaai.org/index.php/AAAI/article/view/25773/25545"
"25774","Learning Logic Programs by Discovering Where Not to Search","['Andrew Cropper', 'Céline Hocquette']","['University of Oxford', 'University of Oxford']","['KRR: Logic Programming', 'ML: Relational Learning']","Cropper, A., & Hocquette, C. (2023). Learning Logic Programs by Discovering Where Not to Search. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6289-6296. https://doi.org/10.1609/aaai.v37i5.25774","Abstract 					The goal of inductive logic programming (ILP) is to search for a hypothesis that generalises training examples and background knowledge (BK). To improve performance, we introduce an approach that, before searching for a hypothesis, first discovers ""where not to search"". We use given BK to discover constraints on hypotheses, such as that a number cannot be both even and odd. We use the constraints to bootstrap a constraint-driven ILP system. Our experiments on multiple domains (including program synthesis and inductive general game playing) show that our approach can (i) substantially reduce learning times by up to 97%, and (ii) can scale to domains with millions of facts.","https://ojs.aaai.org/index.php/AAAI/article/view/25774/25546"
"25775","From Width-Based Model Checking to Width-Based Automated Theorem Proving","['Mateus de Oliveira Oliveira', 'Farhad Vadiee']","['Stockholm University\nUniversity of Bergen', 'University of Bergen']","['KRR: Computational Complexity of Reasoning', 'KRR: Automated Reasoning and Theorem Proving']","de Oliveira Oliveira, M., & Vadiee, F. (2023). From Width-Based Model Checking to Width-Based Automated Theorem Proving. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6297-6304. https://doi.org/10.1609/aaai.v37i5.25775","Abstract 					In the field of parameterized complexity theory, the study of graph width measures has been intimately connected with the development of width-based model checking algorithms for combinatorial properties on graphs. In this work, we introduce a general framework to convert a large class of width-based model-checking algorithms into algorithms that can be used to test the validity of graph-theoretic conjectures on classes of graphs of bounded width. Our framework is modular and can be applied with respect to several well-studied width measures for graphs, including treewidth and cliquewidth.  As a quantitative application of our framework, we prove analytically that for several long-standing graph-theoretic conjectures, there exists an algorithm that takes a number k as input and correctly determines in time double-exponential in a polynomial of k whether the conjecture is valid on all graphs of treewidth at most k. These upper bounds, which may be regarded as upper-bounds on the size of proofs/disproofs for these conjectures on the class of graphs of treewidth at most k, improve significantly on theoretical upper bounds obtained using previously available techniques.","https://ojs.aaai.org/index.php/AAAI/article/view/25775/25547"
"25776","Model-Checking for Ability-Based Logics with Constrained Plans","['Stéphane Demri', 'Raul Fervari']","['CNRS, LMF, ENS Paris-Saclay, France', 'Universidad Nacional de Córdoba and CONICET, Argentina\nGTIIT, China']","['KRR: Computational Complexity of Reasoning', 'KRR: Action', 'Change', 'and Causality', 'KRR: Knowledge Representation Languages', 'KRR: Other Foundations of Knowledge Representation & Reasoning', 'KRR: Reasoning with Beliefs']","Demri, S., & Fervari, R. (2023). Model-Checking for Ability-Based Logics with Constrained Plans. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6305-6312. https://doi.org/10.1609/aaai.v37i5.25776","Abstract 					We investigate the complexity of the model-checking problem for a family of modal logics capturing the notion of “knowing how”. We consider the most standard ability-based knowing how logic, for which we show that model-checking is PSpace-complete. By contrast, a multi-agent variant based on an uncertainty relation between plans in which uncertainty is encoded by a regular language, is shown to admit a PTime model-checking problem. We extend with budgets the above-mentioned ability-logics, as done for ATL-like logics. We show that for the former logic enriched with budgets, the complexity increases to at least ExpSpace-hardness, whereas for the latter, the PTime bound is preserved. Other variant logics are discussed along the paper.","https://ojs.aaai.org/index.php/AAAI/article/view/25776/25548"
"25777","A Structural Complexity Analysis of Synchronous Dynamical Systems","['Eduard Eiben', 'Robert Ganian', 'Thekla Hamm', 'Viktoriia Korchemna']","['Royal Holloway, University of London', 'TU Wien', 'Utrecht University', 'TU Wien']","['KRR: Computational Complexity of Reasoning', 'GTEP: Other Foundations of Game Theory & Economic Paradigms', 'MAS: Other Foundations of Multiagent Systems']","Eiben, E., Ganian, R., Hamm, T., & Korchemna, V. (2023). A Structural Complexity Analysis of Synchronous Dynamical Systems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6313-6321. https://doi.org/10.1609/aaai.v37i5.25777","Abstract 					Synchronous dynamical systems are well-established models that have been used to capture a range of phenomena in networks, including opinion diffusion, spread of disease and product adoption. We study the three most notable problems in synchronous dynamical systems: whether the system will transition to a target configuration from a starting configuration, whether the system will reach convergence from a starting configuration, and whether the system is guaranteed to converge from every possible starting configuration. While all three problems were known to be intractable in the classical sense, we initiate the study of their exact boundaries of tractability from the perspective of structural parameters of the network by making use of the more fine-grained parameterized complexity paradigm.   As our first result, we consider treewidth - as the most prominent and ubiquitous structural parameter - and show that all three problems remain intractable even on instances of constant treewidth. We complement this negative finding with fixed-parameter algorithms for the former two problems parameterized by treedepth, a well-studied restriction of treewidth. While it is possible to rule out a similar algorithm for convergence guarantee under treedepth, we conclude with a fixed-parameter algorithm for this last problem when parameterized by treedepth and the maximum in-degree.","https://ojs.aaai.org/index.php/AAAI/article/view/25777/25549"
"25778","Evaluating Epistemic Logic Programs via Answer Set Programming with Quantifiers","['Wolfgang Faber', 'Michael Morak']","['University of Klagenfurt, Austria', 'University of Klagenfurt, Austria']","['KRR: Logic Programming', 'KRR: Knowledge Representation Languages', 'KRR: Nonmonotonic Reasoning']","Faber, W., & Morak, M. (2023). Evaluating Epistemic Logic Programs via Answer Set Programming with Quantifiers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6322-6329. https://doi.org/10.1609/aaai.v37i5.25778","Abstract 					In this paper we introduce a simple way to evaluate epistemic logic programs by means of answer set programming with quantifiers, a recently proposed extension of answer set programming. The method can easily be adapted for most of the many semantics that were proposed for epistemic logic programs. We evaluate the proposed transformation on existing benchmarks using a recently proposed solver for answer set programming with quantifiers, which relies on QBF solvers.","https://ojs.aaai.org/index.php/AAAI/article/view/25778/25550"
"25779","Reachability Games Modulo Theories with a Bounded Safety Player","['Marco Faella', 'Gennaro Parlato']","['University of Naples Federico II', 'University of Molise']","['KRR: Automated Reasoning and Theorem Proving', 'MAS: Adversarial Agents', 'RU: Sequential Decision Making']","Faella, M., & Parlato, G. (2023). Reachability Games Modulo Theories with a Bounded Safety Player. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6330-6337. https://doi.org/10.1609/aaai.v37i5.25779","Abstract 					Solving reachability games is a fundamental problem for the analysis, verification, and synthesis of reactive systems. We consider logical reachability games modulo theories (in short, GMTs), i.e., infinite-state games whose rules are defined by logical formulas over a multi-sorted first-order theory.  Our games have an asymmetric constraint: the safety player has at most k possible moves from each game configuration, whereas the reachability player has no such limitation. Even though determining the winner of such a GMT is undecidable, it can be reduced to the well-studied problem of checking the satisfiability of a system of  constrained Horn clauses (CHCs), for which many off-the-shelf solvers have been developed. Winning strategies for GMTs can also be computed by resorting to suitable CHC queries.  We demonstrate that GMTs can model various relevant real-world games, and that our approach can effectively solve several problems from different domains, using Z3 as the backend CHC solver.","https://ojs.aaai.org/index.php/AAAI/article/view/25779/25551"
"25780","Splitting Answer Set Programs with Respect to Intensionality Statements","['Jorge Fandinno', 'Yuliya Lierler']","['University of Nebraska at Omaha', 'University of Nebraska Omaha']","['KRR: Logic Programming', 'KRR: Nonmonotonic Reasoning']","Fandinno, J., & Lierler, Y. (2023). Splitting Answer Set Programs with Respect to Intensionality Statements. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6338-6345. https://doi.org/10.1609/aaai.v37i5.25780","Abstract 					Splitting a logic program allows us to reduce the task of computing its stable models to similar tasks for its subprograms. This can be used to increase solving performance and to prove the correctness of programs. We generalize the conditions under which this technique is applicable, by considering not only dependencies between predicates but also their arguments and context. This allows splitting  programs commonly used in practice to which previous results were not applicable.","https://ojs.aaai.org/index.php/AAAI/article/view/25780/25552"
"25781","Monitoring Arithmetic Temporal Properties on Finite Traces","['Paolo Felli', 'Marco Montali', 'Fabio Patrizi', 'Sarah Winkler']","['University of Bologna', 'Free University of Bozen-Bolzano', 'Sapienza University of Rome', 'Free University of Bozen-Bolzano']","['KRR: Action', 'Change', 'and Causality', 'KRR: Geometric', 'Spatial', 'and Temporal Reasoning']","Felli, P., Montali, M., Patrizi, F., & Winkler, S. (2023). Monitoring Arithmetic Temporal Properties on Finite Traces. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6346-6354. https://doi.org/10.1609/aaai.v37i5.25781","Abstract 					We study monitoring of linear-time arithmetic properties against finite traces generated by an unknown dynamic system. The monitoring state is determined by considering at once the trace prefix seen so far, and all its possible finite-length, future continuations. This makes monitoring at least as hard as satisfiability and validity. Traces consist of finite sequences of assignments of a fixed set of variables to numerical values. Properties are specified in a logic we call ALTLf, combining LTLf (LTL on finite traces) with linear arithmetic constraints that may carry lookahead, i.e., variables may be compared over multiple instants of the trace. While the monitoring problem for this setting is undecidable in general, we show decidability for (a) properties without lookahead, and (b) properties with lookahead that satisfy the abstract, semantic condition of finite summary, studied before in the context of model checking. We then single out concrete, practically relevant classes of constraints guaranteeing finite summary. Feasibility is witnessed by a prototype implementation.","https://ojs.aaai.org/index.php/AAAI/article/view/25781/25553"
"25782","Untangled: A Complete Dynamic Topological Logic","['David Fernández-Duque', 'Yoàv Montacute']","['Ghent University\nICS of the Czech Academy of Sciences', 'University of Cambridge']","['KRR: Geometric', 'Spatial', 'and Temporal Reasoning', 'KRR: Action', 'Change', 'and Causality', 'GTEP: Coordination and Collaboration', 'MAS: Agent-Based Simulation and Emergent Behavior', 'MAS: Coordination and Collaboration', 'PRS: Model-Based Reasoning', 'PRS: Optimization of Spatio-Temporal Systems']","Fernández-Duque, D., & Montacute, Y. (2023). Untangled: A Complete Dynamic Topological Logic. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6355-6362. https://doi.org/10.1609/aaai.v37i5.25782","Abstract 					Dynamical systems are general models of change or movement over time with a broad area of applicability to many branches of science, including computer science and AI. Dynamic topological logic (DTL) is a formal framework for symbolic reasoning about dynamical systems. DTL can express various liveness and reachability conditions on such systems, but has the drawback that the only known axiomatisation requires an extended language. In this paper, we consider dynamic topological logic restricted to the class of scattered spaces. Scattered spaces appear in the context of computational logic as they provide semantics for provability and enjoy definable fixed points. We exhibit the first sound and complete dynamic topological logic in the original language of DTL. In particular, we show that the version of DTL based on the class of scattered spaces is finitely axiomatisable, and that the natural axiomatisation is sound and complete.","https://ojs.aaai.org/index.php/AAAI/article/view/25782/25554"
"25783","Inconsistent Cores for ASP: The Perks and Perils of Non-monotonicity","['Johannes K. Fichte', 'Markus Hecher', 'Stefan Szeider']","['TU Wien, Research Unit Databases and AI, Vienna, Austria', 'Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology, Cambridge, MA, United States', 'TU Wien, Research Unit Algorithms and Complexity, Vienna, Austria']","['KRR: Computational Complexity of Reasoning', 'CSO: Constraint Optimization', 'KRR: Logic Programming', 'KRR: Nonmonotonic Reasoning', 'KRR: Other Foundations of Knowledge Representation & Reasoning']","Fichte, J. K., Hecher, M., & Szeider, S. (2023). Inconsistent Cores for ASP: The Perks and Perils of Non-monotonicity. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6363-6371. https://doi.org/10.1609/aaai.v37i5.25783","Abstract 					Answer Set Programming (ASP) is a prominent modeling and solving framework. An inconsistent core (IC) of an ASP program is an inconsistent subset of rules. In the case of inconsistent programs, a smallest or subset-minimal IC contains crucial rules for the inconsistency. In this work, we study fnding minimal ICs of ASP programs and key fragments from a complexity-theoretic perspective. Interestingly, due to ASP’s non-monotonic behavior, also consistent programs admit ICs. It turns out that there is an entire landscape of problems involving ICs with a diverse range of complexities up to the fourth level of the Polynomial Hierarchy. Deciding the existence of an IC is, already for tight programs, on the second level of the Polynomial Hierarchy. Furthermore, we give encodings for IC-related problems on the fragment of tight programs and illustrate feasibility on small instance sets.","https://ojs.aaai.org/index.php/AAAI/article/view/25783/25555"
"25784","General Acyclicity and Cyclicity Notions for the Disjunctive Skolem Chase","['Lukas Gerlach', 'David Carral']","['Knowledge-Based Systems Group, TU Dresden, Dresden, Germany', 'LIRMM, Inria, University of Montpellier, CNRS, Montpellier, France']","['KRR: Other Foundations of Knowledge Representation & Reasoning', 'KRR: Knowledge Representation Languages', 'KRR: Automated Reasoning and Theorem Proving', 'KRR: Logic Programming', 'KRR: Computational Complexity of Reasoning', 'KRR: Description Logics', 'KRR: Ontologies and Semantic Web']","Gerlach, L., & Carral, D. (2023). General Acyclicity and Cyclicity Notions for the Disjunctive Skolem Chase. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6372-6379. https://doi.org/10.1609/aaai.v37i5.25784","Abstract 					The disjunctive skolem chase is a sound, complete, and potentially non-terminating procedure for solving boolean conjunctive query entailment over knowledge bases of disjunctive existential rules. We develop novel acyclicity and cyclicity notions for this procedure; that is, we develop sufficient conditions to determine chase termination and non-termination. Our empirical evaluation shows that our novel notions are significantly more general than existing criteria.","https://ojs.aaai.org/index.php/AAAI/article/view/25784/25556"
"25785","GANTEE: Generative Adversarial Network for Taxonomy Enterance Evaluation","['Zhouhong Gu', 'Sihang Jiang', 'Jingping Liu', 'Yanghua Xiao', 'Hongwei Feng', 'Zhixu Li', 'Jiaqing Liang', 'Zhong Jian']","['Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, China\nSchool of Data Science, Fudan University', 'Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, China', 'School of Information Science and Engineering, East China University of Science and Technology', 'Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, China\nFudan-Aishu Cognitive Intelligence Joint Research Center', 'Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, China', 'Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University, China', 'School of Data Science, Fudan University', 'HUAWEI CBG Edu AI Lab']","['KRR: Knowledge Acquisition', 'DMKM: Semantic Web', 'KRR: Applications', 'KRR: Knowledge Engineering']","Gu, Z., Jiang, S., Liu, J., Xiao, Y., Feng, H., Li, Z., Liang, J., & Jian, Z. (2023). GANTEE: Generative Adversarial Network for Taxonomy Enterance Evaluation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6380-6388. https://doi.org/10.1609/aaai.v37i5.25785","Abstract 					Taxonomy is formulated as directed acyclic graphs or trees of concepts that support many downstream tasks. Many new coming concepts need to be added to an existing taxonomy. The traditional taxonomy expansion task aims only at finding the best position for new coming concepts in the existing taxonomy.  However, they have two drawbacks when being applied to the real-scenarios. The previous methods suffer from low-efficiency since they waste much time when most of the new coming concepts are indeed noisy concepts. They also suffer from low-effectiveness since they collect training samples only from the existing taxonomy, which limits the ability of the model to mine more hypernym-hyponym relationships among real concepts. This paper proposes a pluggable framework called Generative Adversarial Network for Taxonomy Entering Evaluation (GANTEE) to alleviate these drawbacks. A generative adversarial network is designed in this framework by discriminative models to alleviate the first drawback and the generative model to alleviate the second drawback. Two discriminators are used in GANTEE to provide long-term and short-term rewards, respectively. Moreover, to further improve the efficiency, pre-trained language models are used to retrieve the representation of the concepts quickly. The experiments on three real-world large-scale datasets with two different languages show that GANTEE improves the performance of the existing taxonomy expansion methods in both effectiveness and efficiency.","https://ojs.aaai.org/index.php/AAAI/article/view/25785/25557"
"25786","Finite Based Contraction and Expansion via Models","['Ricardo Guimarães', 'Ana Ozaki', 'Jandson S. Ribeiro']","['University of Bergen', 'University of Bergen', 'University of Hagen']","['KRR: Belief Change', 'KRR: Description Logics', 'KRR: Reasoning with Beliefs']","Guimarães, R., Ozaki, A., & Ribeiro, J. S. (2023). Finite Based Contraction and Expansion via Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6389-6397. https://doi.org/10.1609/aaai.v37i5.25786","Abstract 					We propose a new paradigm for Belief Change in which the new information is represented as sets of models, while the agent's body of knowledge is represented as a finite set of formulae, that is, a finite base. The focus on finiteness is crucial when we consider limited agents and reasoning algorithms. Moreover, having the input as arbitrary set of models is more general than the usual treatment of formulas as input. In this setting, we define new Belief Change operations akin to traditional expansion and contraction, and we identify the rationality postulates that emerge due to the finite representability requirement. We also analyse different logics concerning compatibility with our framework.","https://ojs.aaai.org/index.php/AAAI/article/view/25786/25558"
"25787","MAPS-KB: A Million-Scale Probabilistic Simile Knowledge Base","['Qianyu He', 'Xintao Wang', 'Jiaqing Liang', 'Yanghua Xiao']","['Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University', 'Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University', 'School of Data Science, Fudan University', 'Shanghai Key Laboratory of Data Science, School of Computer Science, Fudan University\nFudan-Aishu Cognitive Intelligence Joint Research Center, Shanghai, China']","['KRR: Knowledge Acquisition', 'KRR: Knowledge Engineering', 'SNLP: Language Models']","He, Q., Wang, X., Liang, J., & Xiao, Y. (2023). MAPS-KB: A Million-Scale Probabilistic Simile Knowledge Base. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6398-6406. https://doi.org/10.1609/aaai.v37i5.25787","Abstract 					The ability to understand and generate similes is an imperative step to realize human-level AI. However, there is still a considerable gap between machine intelligence and human cognition in similes, since deep models based on statistical distribution tend to favour high-frequency similes. Hence, a large-scale symbolic knowledge base of similes is required, as it contributes to the modeling of diverse yet unpopular similes while facilitating additional evaluation and reasoning. To bridge the gap, we propose a novel framework for large-scale simile knowledge base construction, as well as two probabilistic metrics which enable an improved understanding of simile phenomena in natural language. Overall, we construct MAPS-KB, a million-scale probabilistic simile knowledge base, covering 4.3 million triplets over 0.4 million terms from 70 GB corpora. We conduct sufficient experiments to justify the effectiveness and necessity of the methods of our framework. We also apply MAPS-KB on three downstream tasks to achieve state-of-the-art performance, further demonstrating the value of MAPS-KB. Resources of MAPS-KB are publicly available at https://github.com/Abbey4799/MAPS-KB.","https://ojs.aaai.org/index.php/AAAI/article/view/25787/25559"
"25788","Characterizing Structural Hardness of Logic Programs: What Makes Cycles and Reachability Hard for Treewidth?","['Markus Hecher']","['Computer Science and Artificial Intelligence Lab, Massachusetts Institute of Technology, Cambridge, MA, United States']","['KRR: Logic Programming', 'KRR: Computational Complexity of Reasoning', 'KRR: Nonmonotonic Reasoning', 'KRR: Other Foundations of Knowledge Representation & Reasoning']","Hecher, M. (2023). Characterizing Structural Hardness of Logic Programs: What Makes Cycles and Reachability Hard for Treewidth?. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6407-6415. https://doi.org/10.1609/aaai.v37i5.25788","Abstract 					Answer Set Programming (ASP) is a problem modeling and solving framework for several problems in KR with growing industrial applications. Also for studies of computational complexity and deeper insights into the hardness and its sources, ASP has been attracting researchers for many years. These studies resulted in fruitful characterizations in terms of complexity classes, fine-grained insights in form of dichotomy-style results, as well as detailed parameterized complexity landscapes. Recently, this lead to a novel result establishing that for the measure treewidth, which captures structural density of a program, the evaluation of the well-known class of normal programs is expected to be slightly harder than deciding satisfiability (SAT). However, it is unclear how to utilize this structural power of ASP. This paper deals with a novel reduction from SAT to normal ASP that goes beyond well-known encodings: We explicitly utilize the structural power of ASP, whereby we sublinearly decrease the treewidth, which probably cannot be significantly improved. Then, compared to existing results, this characterizes hardness in a fine-grained way by establishing the required functional dependency of the dependency graph’s cycle length (SCC size) on the treewidth.","https://ojs.aaai.org/index.php/AAAI/article/view/25788/25560"
"25789","Conditional Syntax Splitting for Non-monotonic Inference Operators","['Jesse Heyninck', 'Gabriele Kern-Isberner', 'Thomas Meyer', 'Jonas Philipp Haldimann', 'Christoph Beierle']","['Open Universiteit, the Netherlands', 'TU Dortmund University, Germany', 'University of Cape Town, South-Africa\nCentre for Artificial Intelligence Research (CAIR), South-Africa', 'FernUniversität in Hagen, Germany', 'FernUniversität in Hagen, Germany']","['KRR: Nonmonotonic Reasoning']","Heyninck, J., Kern-Isberner, G., Meyer, T., Haldimann, J. P., & Beierle, C. (2023). Conditional Syntax Splitting for Non-monotonic Inference Operators. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6416-6424. https://doi.org/10.1609/aaai.v37i5.25789","Abstract 					Syntax splitting is a property of inductive inference operators that ensures we can restrict our attention to parts of the conditional belief base that share atoms with a given query. To apply syntax splitting, a conditional belief base needs to consist of syntactically disjoint conditionals. This requirement is often too strong in practice, as conditionals might share atoms. In this paper we introduce the concept of conditional syntax splitting, inspired by the notion of conditional independence as known from probability theory. We show that lexicographic inference and system W satisfy conditional syntax splitting, and connect conditional syntax splitting to several known properties from the literature on non-monotonic reasoning, including the drowning effect.","https://ojs.aaai.org/index.php/AAAI/article/view/25789/25561"
"25790","Relational Program Synthesis with Numerical Reasoning","['Céline Hocquette', 'Andrew Cropper']","['University of Oxford', 'University of Oxford']","['KRR: Logic Programming', 'CSO: Constraint Programming', 'ML: Relational Learning']","Hocquette, C., & Cropper, A. (2023). Relational Program Synthesis with Numerical Reasoning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6425-6433. https://doi.org/10.1609/aaai.v37i5.25790","Abstract 					Learning programs with numerical values is fundamental to many AI applications, including bio-informatics and drug design. However, current program synthesis approaches struggle to learn programs with numerical values. An especially difficult problem is learning continuous values from multiple examples, such as intervals. To overcome this limitation, we introduce an inductive logic programming approach which combines relational learning with numerical reasoning. Our approach, which we call NumSynth, uses satisfiability modulo theories solvers to efficiently learn programs with numerical values. Our approach can identify numerical values in linear arithmetic fragments, such as real difference logic, and from infinite domains, such as real numbers or integers. Our experiments on four diverse domains, including game playing and program synthesis, show that our approach can (i) learn programs with numerical values from linear arithmetical reasoning, and (ii) outperform existing approaches in terms of predictive accuracies and learning times.","https://ojs.aaai.org/index.php/AAAI/article/view/25790/25562"
"25791","Common Knowledge of Abstract Groups","['Merlin Humml', 'Lutz Schröder']","['Friedrich Alexander Universität Erlangen-Nürnberg', 'Friedrich-Alexander-University Erlangen-Nürnberg, Department of Computer Science']","['KRR: Knowledge Representation Languages', 'KRR: Description Logics', 'KRR: Ontologies and Semantic Web', 'KRR: Reasoning with Beliefs']","Humml, M., & Schröder, L. (2023). Common Knowledge of Abstract Groups. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6434-6441. https://doi.org/10.1609/aaai.v37i5.25791","Abstract 					Epistemic logics typically talk about knowledge of individual agents or groups of explicitly listed agents. Often, however, one wishes to express knowledge of groups of agents specified by a given property, as in ‘it is common knowledge among economists’. We introduce such a logic of common knowledge, which we term abstract-group epistemic logic (AGEL). That is, AGEL features a common knowledge operator for groups of agents given by concepts in a separate agent logic that we keep generic, with one possible agent logic being ALC. We show that AGEL is EXPTIME-complete, with the lower bound established by reduction from standard group epistemic logic, and the upper bound by a satisfiability-preserving embedding into the full µ-calculus. Further main results include a finite model property (not enjoyed by the full µ-calculus) and a complete axiomatization.","https://ojs.aaai.org/index.php/AAAI/article/view/25791/25563"
"25792","FASTDIAGP: An Algorithm for Parallelized Direct Diagnosis","['Viet-Man Le', 'Cristian Vidal Silva', 'Alexander Felfernig', 'David Benavides', 'José Galindo', 'Thi Ngoc Trang Tran']","['Graz University of Technology, Graz, Austria', 'Universidad de Talca, Talca, Chile', 'Graz University of Technology, Graz, Austria', 'University of Sevilla, Seville, Spain', 'University of Sevilla, Seville, Spain', 'Graz University of Technology, Graz, Austria']","['KRR: Diagnosis and Abductive Reasoning', 'CSO: Applications', 'KRR: Applications', 'KRR: Knowledge Engineering']","Le, V.-M., Vidal Silva, C., Felfernig, A., Benavides, D., Galindo, J., & Tran, T. N. T. (2023). FASTDIAGP: An Algorithm for Parallelized Direct Diagnosis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6442-6449. https://doi.org/10.1609/aaai.v37i5.25792","Abstract 					Constraint-based applications attempt to identify a solution that meets all defined user requirements. If the requirements are inconsistent with the underlying constraint set, algorithms that compute diagnoses for inconsistent constraints should be implemented to help users resolve the “no solution could be found” dilemma. FastDiag is a typical direct diagnosis algorithm that supports diagnosis calculation without pre-determining conflicts. However, this approach faces runtime performance issues, especially when analyzing complex and large-scale knowledge bases. In this paper, we propose a novel algorithm, so-called FastDiagP, which is based on the idea of speculative programming. This algorithm extends FastDiag by integrating a parallelization mechanism that anticipates and pre-calculates consistency checks requested by FastDiag. This mechanism helps to provide consistency checks with fast answers and boosts the algorithm’s runtime performance. The performance improvements of our proposed algorithm have been shown through empirical results using the Linux-2.6.3.33 configuration knowledge base.","https://ojs.aaai.org/index.php/AAAI/article/view/25792/25564"
"25793","Two Views of Constrained Differential Privacy: Belief Revision and Update","['Likang Liu', 'Keke Sun', 'Chunlai Zhou', 'Yuan Feng']","['Renmin University of China', 'Renmin University of China', 'Renmin University of China', 'University of Technology Sydney']","['KRR: Reasoning with Beliefs', 'KRR: Belief Change', 'PEAI: Privacy and Security']","Liu, L., Sun, K., Zhou, C., & Feng, Y. (2023). Two Views of Constrained Differential Privacy: Belief Revision and Update. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6450-6457. https://doi.org/10.1609/aaai.v37i5.25793","Abstract 					In this paper, we provide two views of constrained differential private (DP) mechanisms. The first one is as belief revision.  A constrained DP mechanism is obtained by standard probabilistic conditioning, and hence can be naturally implemented by Monte Carlo algorithms.  The other is as belief update.  A constrained DP is defined according to l2-distance minimization postprocessing or projection and hence can be naturally implemented by optimization algorithms.  The main advantage of these two perspectives is that we can make full use of the machinery of belief revision and update to show basic properties for constrained differential privacy especially some important new composition properties.  Within the framework established in this paper, constrained DP algorithms in the literature can be classified either as belief revision or belief update.  At the end of the paper, we demonstrate their differences especially in utility on a couple of scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/25793/25565"
"25794","Copyright-Certified Distillation Dataset: Distilling One Million Coins into One Bitcoin with Your Private Key","['Tengjun Liu', 'Ying Chen', 'Wanxuan Gu']","['Fudan University', 'Fudan University', 'NVIDIA']","['KRR: Knowledge Engineering', 'DMKM: Data Compression', 'DMKM: Scalability', 'Parallel & Distributed Systems', 'ML: Classification and Regression', 'ML: Scalability of ML Systems', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'PEAI: Privacy and Security']","Liu, T., Chen, Y., & Gu, W. (2023). Copyright-Certified Distillation Dataset: Distilling One Million Coins into One Bitcoin with Your Private Key. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6458-6466. https://doi.org/10.1609/aaai.v37i5.25794","Abstract 					The rapid development of neural network dataset distillation in recent years has provided new ideas in many areas such as continuous learning, neural network architecture search and privacy preservation. Dataset distillation is a very effective method to distill large training datasets into small data, thus ensuring that the test accuracy of models trained on their synthesized small datasets matches that of models trained on the full dataset. Thus, dataset distillation itself is commercially valuable, not only for reducing training costs, but also for compressing storage costs and significantly reducing the training costs of deep learning. However, copyright protection for dataset distillation has not been proposed yet, so we propose the first method to protect intellectual property by embedding watermarks in the dataset distillation process. Our approach not only popularizes the dataset distillation technique, but also authenticates the ownership of the distilled dataset by the models trained on that distilled dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/25794/25566"
"25795","DHGE: Dual-View Hyper-Relational Knowledge Graph Embedding for Link Prediction and Entity Typing","['Haoran Luo', 'Haihong E', 'Ling Tan', 'Gengxian Zhou', 'Tianyu Yao', 'Kaiyang Wan']","['School of Computer Science, Beijing University of Posts and Telecommunications', 'School of Computer Science, Beijing University of Posts and Telecommunications', 'School of Computer Science, Beijing University of Posts and Telecommunications', 'School of Computer Science, Beijing University of Posts and Telecommunications', 'School of Computer Science, Beijing University of Posts and Telecommunications', 'School of Computer Science, Beijing University of Posts and Telecommunications']","['KRR: Ontologies and Semantic Web', 'DMKM: Other Foundations of Data Mining & Knowledge Management', 'DMKM: Semantic Web', 'APP: Healthcare', 'Medicine & Wellness', 'KRR: Knowledge Acquisition', 'KRR: Knowledge Engineering', 'KRR: Knowledge Representation Languages', 'SNLP: Information Extraction', 'SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Ontology Induction From Text', 'SNLP: Sentence-Level Semantics and Textual Inference']","Luo, H., E, H., Tan, L., Zhou, G., Yao, T., & Wan, K. (2023). DHGE: Dual-View Hyper-Relational Knowledge Graph Embedding for Link Prediction and Entity Typing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6467-6474. https://doi.org/10.1609/aaai.v37i5.25795","Abstract 					In the field of representation learning on knowledge graphs (KGs), a hyper-relational fact consists of a main triple and several auxiliary attribute-value descriptions, which is considered more comprehensive and specific than a triple-based fact. However, currently available hyper-relational KG embedding methods in a single view are limited in application because they weaken the hierarchical structure that represents the affiliation between entities. To overcome this limitation, we propose a dual-view hyper-relational KG structure (DH-KG) that contains a hyper-relational instance view for entities and a hyper-relational ontology view for concepts that are abstracted hierarchically from the entities. This paper defines link prediction and entity typing tasks on DH-KG for the first time and constructs two DH-KG datasets, JW44K-6K, extracted from Wikidata, and HTDM based on medical data. Furthermore, we propose DHGE, a DH-KG embedding model based on GRAN encoders, HGNNs, and joint learning. DHGE outperforms baseline models on DH-KG, according to experimental results. Finally, we provide an example of how this technology can be used to treat hypertension. Our model and new datasets are publicly available.","https://ojs.aaai.org/index.php/AAAI/article/view/25795/25567"
"25796","Automated Verification of Propositional Agent Abstraction for Classical Planning via CTLK Model Checking","['Kailun Luo']","['Dongguan University of Technology']","['KRR: Action', 'Change', 'and Causality', 'PRS: Other Foundations of Planning', 'Routing & Scheduling']","Luo, K. (2023). Automated Verification of Propositional Agent Abstraction for Classical Planning via CTLK Model Checking. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6475-6482. https://doi.org/10.1609/aaai.v37i5.25796","Abstract 					Abstraction has long been an effective mechanism to help find a solution in classical planning. Agent abstraction, based on the situation calculus, is a promising explainable framework for agent planning, yet its automation is still far from being tackled. In this paper, we focus on a propositional version of agent abstraction designed for finite-state systems. We investigate the automated verification of the existence of propositional agent abstraction, given a finite-state system and a mapping indicating an abstraction for it. By formalizing sound, complete and deterministic properties of abstractions in a general framework, we show that the verification task can be reduced to the task of model checking against CTLK specifications. We implemented a prototype system, and validated the viability of our approach through experimentation on several domains from classical planning.","https://ojs.aaai.org/index.php/AAAI/article/view/25796/25568"
"25797","Efficient Answer Enumeration in Description Logics with Functional Roles","['Carsten Lutz', 'Marcin Przybyłko']","['Leipzig University', 'Leipzig University']","['KRR: Description Logics']","Lutz, C., & Przybyłko, M. (2023). Efficient Answer Enumeration in Description Logics with Functional Roles. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6483-6490. https://doi.org/10.1609/aaai.v37i5.25797","Abstract 					We study the enumeration of answers to ontology-mediated queries when the ontology is formulated in a description logic that supports functional roles and the query is a CQ. In particular, we show that enumeration is possible with linear preprocessing and constant delay when a certain extension of the CQ (pertaining to functional roles) is acyclic and free-connex acyclic. This holds both for complete answers and for partial answers. We provide matching lower bounds for the case where the query is self-join free.","https://ojs.aaai.org/index.php/AAAI/article/view/25797/25569"
"25798","Distributed Spectrum-Based Fault Localization","['Avraham Natan', 'Roni Stern', 'Meir Kalech']","['Ben Gurion University', 'Ben Gurion University', 'Ben Gurion University']","['KRR: Diagnosis and Abductive Reasoning', 'MAS: Coordination and Collaboration', 'MAS: Distributed Problem Solving']","Natan, A., Stern, R., & Kalech, M. (2023). Distributed Spectrum-Based Fault Localization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6491-6498. https://doi.org/10.1609/aaai.v37i5.25798","Abstract 					Spectrum-Based Fault Localization (SFL) is a popular approach for diagnosing faulty systems. SFL algorithms are inherently centralized, where observations are collected and analyzed by a single diagnoser. Applying SFL to diagnose distributed systems is challenging, especially when communication is costly and there are privacy concerns. We propose two SFL-based algorithms that are designed for distributed systems: one for diagnosing a single faulty component and one for diagnosing multiple faults. We analyze these algorithms theoretically and empirically. Our analysis shows that the distributed SFL algorithms we developed output identical diagnoses to centralized SFL while preserving privacy.","https://ojs.aaai.org/index.php/AAAI/article/view/25798/25570"
"25799","Multi-Level Wavelet Mapping Correlation for Statistical Dependence Measurement: Methodology and Performance","['Yixin Ren', 'Hao Zhang', 'Yewei Xia', 'Jihong Guan', 'Shuigeng Zhou']","['Fudan University', 'Fudan University', 'Fudan University', 'Tongji University', 'Fudan University']","['KRR: Other Foundations of Knowledge Representation & Reasoning', 'RU: Other Foundations of Reasoning Under Uncertainty']","Ren, Y., Zhang, H., Xia, Y., Guan, J., & Zhou, S. (2023). Multi-Level Wavelet Mapping Correlation for Statistical Dependence Measurement: Methodology and Performance. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6499-6506. https://doi.org/10.1609/aaai.v37i5.25799","Abstract 					We propose a new criterion for measuring dependence between two real variables, namely, Multi-level Wavelet Mapping Correlation (MWMC). MWMC can capture the nonlinear dependencies between variables by measuring their correlation under different levels of wavelet mappings. We show that the empirical estimate of MWMC converges exponentially to its population quantity. To support independence test better with MWMC, we further design a permutation test based on MWMC and prove that our test can not only control the type I error rate (the rate of false positives) well but also ensure that the type II error rate (the rate of false negatives) is upper bounded by O(1/n) (n is the sample size) with finite permutations. By extensive experiments on (conditional) independence tests and causal discovery, we show that our method outperforms existing independence test methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25799/25571"
"25800","Learning Interpretable Temporal Properties from Positive Examples Only","['Rajarshi Roy', 'Jean-Raphaël Gaglione', 'Nasim Baharisangari', 'Daniel Neider', 'Zhe Xu', 'Ufuk Topcu']","['Max Planck Institute for Software Systems, Kaiserslautern, Germany', 'University of Texas at Austin, Texas, USA', 'Arizona State University, Arizona, USA', 'TU Dortmund University, Dortmund, Germany\nCenter for Trustworthy Data Science and Security, University Alliance Ruhr, Germany', 'Arizona State University, Arizona, USA', 'University of Texas at Austin, Texas, USA']","['KRR: Knowledge Representation Languages', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'CSO: Constraint Satisfaction']","Roy, R., Gaglione, J.-R., Baharisangari, N., Neider, D., Xu, Z., & Topcu, U. (2023). Learning Interpretable Temporal Properties from Positive Examples Only. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6507-6515. https://doi.org/10.1609/aaai.v37i5.25800","Abstract 					We consider the problem of explaining the temporal behavior of black-box systems using human-interpretable models. Following recent research trends, we rely on the fundamental yet interpretable models of deterministic finite automata (DFAs) and linear temporal logic (LTL_f) formulas. In contrast to most existing works for learning DFAs and LTL_f formulas, we consider learning from only positive examples. Our motivation is that negative examples are generally difficult to observe, in particular, from black-box systems. To learn meaningful models from positive examples only, we design algorithms that rely on conciseness and language minimality of models as regularizers. Our learning algorithms are based on two approaches: a symbolic and a counterexample-guided one. The symbolic approach exploits an efficient encoding of language minimality as a constraint satisfaction problem, whereas the counterexample-guided one relies on generating suitable negative examples to guide the learning. Both approaches provide us with effective algorithms with minimality guarantees on the learned models. To assess the effectiveness of our algorithms, we evaluate them on a few practical case studies.","https://ojs.aaai.org/index.php/AAAI/article/view/25800/25572"
"25801","Editing Boolean Classifiers: A Belief Change Perspective","['Nicolas Schwind', 'Katsumi Inoue', 'Pierre Marquis']","['National Institute of Advanced Industrial Science and Technology, Tokyo, Japan', 'National Institute of Informatics, Tokyo, Japan\nThe Graduate University for Advanced Studies, SOKENDAI, Tokyo, Japan', 'Univ. Artois, CNRS, CRIL, F-62300 Lens, France\nInstitut Universitaire de France']","['KRR: Belief Change']","Schwind, N., Inoue, K., & Marquis, P. (2023). Editing Boolean Classifiers: A Belief Change Perspective. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6516-6524. https://doi.org/10.1609/aaai.v37i5.25801","Abstract 					This paper is about editing Boolean classifiers, i.e., determining how a Boolean classifier should be modified when new pieces of evidence must be incorporated. Our main goal is to delineate what are the rational ways of making such edits. This goes through a number of rationality postulates inspired from those considered so far for belief revision. We give a representation theorem and present some families of edit operators satisfying the postulates.","https://ojs.aaai.org/index.php/AAAI/article/view/25801/25573"
"25802","Implementing Bounded Revision via Lexicographic Revision and C-revision","['Meliha Sezgin', 'Gabriele Kern-Isberner']","['TU Dortmund University', 'TU Dortmund University']","['KRR: Belief Change', 'KRR: Nonmonotonic Reasoning', 'KRR: Preferences', 'KRR: Qualitative Reasoning', 'KRR: Reasoning with Beliefs']","Sezgin, M., & Kern-Isberner, G. (2023). Implementing Bounded Revision via Lexicographic Revision and C-revision. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6525-6532. https://doi.org/10.1609/aaai.v37i5.25802","Abstract 					New information in the context of real life settings usually is accompanied by some kind of supplementary information that indicates context, reliability, or expertise of the information's source. Bounded Revision (BR) displays an iterated belief revision mechanism that takes as input a new information accompanied by a reference sentence acting as supplementary information, which specifies the depth with which the new input shall be integrated in the posterior belief state. The reference sentence specifies which worlds in the prior belief state are affected by the change mechanism. We show that Bounded Revision can be characterized by three simple, yet elegant postulates and corresponds to a special case of a lexicographic revision, which inherits all relevant features of BR. Furthermore, we present methodological implementations of BR including conditional revision with c-revisions, making it directly usable for conditional revision tools.","https://ojs.aaai.org/index.php/AAAI/article/view/25802/25574"
"25803","Multi-Aspect Explainable Inductive Relation Prediction by Sentence Transformer","['Zhixiang Su', 'Di Wang', 'Chunyan Miao', 'Lizhen Cui']","['Nanyang Technological University, Singapore\nShandong University, China', 'Nanyang Technological University, Singapore', 'Nanyang Technological University, Singapore\nShandong University, China', 'Shandong University, China']","['KRR: Knowledge Acquisition']","Su, Z., Wang, D., Miao, C., & Cui, L. (2023). Multi-Aspect Explainable Inductive Relation Prediction by Sentence Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6533-6540. https://doi.org/10.1609/aaai.v37i5.25803","Abstract 					Recent studies on knowledge graphs (KGs) show that path-based methods empowered by pre-trained language models perform well in the provision of inductive and explainable relation predictions. In this paper, we introduce the concepts of relation path coverage and relation path confidence to filter out unreliable paths prior to model training to elevate the model performance. Moreover, we propose Knowledge Reasoning Sentence Transformer (KRST) to predict inductive relations in KGs. KRST is designed to encode the extracted reliable paths in KGs, allowing us to properly cluster paths and provide multi-aspect explanations. We conduct extensive experiments on three real-world datasets. The experimental results show that compared to SOTA models, KRST achieves the best performance in most transductive and inductive test cases (4 of 6), and in 11 of 12 few-shot test cases.","https://ojs.aaai.org/index.php/AAAI/article/view/25803/25575"
"25804","Learning to Break Symmetries for Efficient Optimization in Answer Set Programming","['Alice Tarzariol', 'Martin Gebser', 'Konstantin Schekotihin', 'Mark Law']","['University of Klagenfurt', 'University of Klagenfurt\nGraz University of Technology', 'University of Klagenfurt', 'ILASP Limited']","['KRR: Logic Programming', 'KRR: Knowledge Acquisition', 'KRR: Nonmonotonic Reasoning']","Tarzariol, A., Gebser, M., Schekotihin, K., & Law, M. (2023). Learning to Break Symmetries for Efficient Optimization in Answer Set Programming. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6541-6549. https://doi.org/10.1609/aaai.v37i5.25804","Abstract 					The ability to efficiently solve hard combinatorial optimization problems is a key prerequisite to various applications of declarative programming paradigms. Symmetries in solution candidates pose a significant challenge to modern optimization algorithms since the enumeration of such candidates might substantially reduce their performance.  This paper proposes a novel approach using Inductive Logic Programming (ILP) to lift symmetry-breaking constraints for optimization problems modeled in Answer Set Programming (ASP). Given an ASP encoding with optimization statements and a set of small representative instances, our method augments ground ASP programs with auxiliary normal rules enabling the identification of symmetries using existing tools, like SBASS. Then, the obtained symmetries are lifted to first-order constraints with ILP.  We prove the correctness of our method and evaluate it on real-world optimization problems from the domain of automated configuration. Our experiments show significant improvements of optimization performance due to the learned first-order constraints.","https://ojs.aaai.org/index.php/AAAI/article/view/25804/25576"
"25805","On Undisputed Sets in Abstract Argumentation","['Matthias Thimm']","['University of Hagen']","['KRR: Argumentation', 'KRR: Computational Complexity of Reasoning', 'MAS: Agreement', 'Argumentation & Negotiation']","Thimm, M. (2023). On Undisputed Sets in Abstract Argumentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6550-6557. https://doi.org/10.1609/aaai.v37i5.25805","Abstract 					We introduce the notion of an undisputed set for abstract argumentation frameworks, which is a conflict-free set of arguments, such that its reduct contains no non-empty admissible set. We show that undisputed sets, and the stronger notion of strongly undisputed sets, provide a meaningful approach to weaken admissibility and deal with the problem of attacks from self-attacking arguments, in a similar manner as the recently introduced notion of weak admissibility. We investigate the properties of our new semantical notions and show certain relationships to classical semantics, in particular that undisputed sets are a generalisation of preferred extensions and strongly undisputed sets are a generalisation of stable extensions. We also investigate the computational complexity of standard reasoning tasks with these new notions and show that they lie on the second and third level of the polynomial hierarchy, respectively.","https://ojs.aaai.org/index.php/AAAI/article/view/25805/25577"
"25806","Neurosymbolic Reasoning and Learning with Restricted Boltzmann Machines","['Son N. Tran', ""Artur d'Avila Garcez""]","['The University of Tasmania', 'City University of London']","['KRR: Other Foundations of Knowledge Representation & Reasoning', 'KRR: Applications', 'ML: Deep Neural Architectures', 'ML: Relational Learning', 'ML: Transparent', 'Interpretable', 'Explainable ML']","Tran, S. N., & Garcez, A. d’Avila. (2023). Neurosymbolic Reasoning and Learning with Restricted Boltzmann Machines. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6558-6565. https://doi.org/10.1609/aaai.v37i5.25806","Abstract 					Knowledge representation and reasoning in neural networks has been a long-standing endeavour which has attracted much attention recently. The principled integration of reasoning and learning in neural networks is a main objective of the area of neurosymbolic Artificial Intelligence. In this paper, a neurosymbolic system is introduced that can represent any propositional logic formula. A proof of equivalence is presented showing that energy minimization in restricted Boltzmann machines corresponds to logical reasoning. We demonstrate the application of our approach empirically on logical reasoning and learning from data and knowledge. Experimental results show that reasoning can be performed effectively for a class of logical formulae. Learning from data and knowledge is also evaluated in comparison with learning of logic programs using neural networks. The results show that our approach can improve on state-of-the-art neurosymbolic systems. The theorems and empirical results presented in this paper are expected to reignite the research on the use of neural networks as massively-parallel models for logical reasoning and promote the principled integration of reasoning and learning in deep networks.","https://ojs.aaai.org/index.php/AAAI/article/view/25806/25578"
"25807","Materialisation-Based Reasoning in DatalogMTL with Bounded Intervals","['Przemysław A. Wałęga', 'Michał Zawidzki', 'Dingmin Wang', 'Bernardo Cuenca Grau']","['University of Oxford', 'University of Oxford', 'University of Oxford', 'University of Oxford']","['KRR: Geometric', 'Spatial', 'and Temporal Reasoning', 'KRR: Automated Reasoning and Theorem Proving']","Wałęga, P. A., Zawidzki, M., Wang, D., & Cuenca Grau, B. (2023). Materialisation-Based Reasoning in DatalogMTL with Bounded Intervals. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6566-6574. https://doi.org/10.1609/aaai.v37i5.25807","Abstract 					DatalogMTL is a powerful extension of Datalog with operators from metric temporal logic (MTL), which has received significant attention in recent years. In this paper, we investigate materialisation-based reasoning (a.k.a. forward chaining) in the context of DatalogMTL programs and datasets with bounded intervals, where partial representations of the canonical model are obtained through successive rounds of rule applications. Although materialisation does not naturally terminate in this setting, it is known that the structure of canonical models is ultimately periodic. Our first contribution in this paper is a detailed analysis of the periodic structure of canonical models; in particular, we formulate saturation conditions whose satisfaction by a partial materialisation implies an ability to recover the full canonical model via unfolding; this allows us to compute the actual periods describing the repeating parts of the canonical model as well as to establish concrete bounds on the number of rounds of rule applications required to achieve saturation. Based on these theoretical results, we propose a practical reasoning algorithm where saturation can be efficiently detected as materialisation progresses, and where the relevant periods used to evaluate entailment of queries via unfolding are efficiently computed. We have implemented our algorithm  and our experiments suggest that  our approach is both scalable and robust.","https://ojs.aaai.org/index.php/AAAI/article/view/25807/25579"
"25808","Efficient Extraction of EL-Ontology Deductive Modules","['Hui Yang', 'Yue Ma', 'Nicole Bidoit']","['Laboratoire Interdisciplinaire des Sciences du Numérique, University of Paris-Saclay', 'Laboratoire Interdisciplinaire des Sciences du Numérique, University of Paris-Saclay', 'Laboratoire Interdisciplinaire des Sciences du Numérique, University of Paris-Saclay']","['KRR: Description Logics', 'KRR: Ontologies and Semantic Web']","Yang, H., Ma, Y., & Bidoit, N. (2023). Efficient Extraction of EL-Ontology Deductive Modules. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6575-6582. https://doi.org/10.1609/aaai.v37i5.25808","Abstract 					Because widely used real-world ontologies are often complex and large, one important challenge has emerged: designing tools for users to focus on sub-ontologies corresponding to their specific interests. To this end, various modules have been introduced to provide concise ontology views. This work concentrates on extracting deductive modules that preserve logical entailment over a given vocabulary. Existing deductive module proposals are either inefficient from a computing point of view or unsatisfactory from a quality point of view because the modules extracted are not concise enough. For example, minimal modules guarantee the most concise results, but their computation is highly time-consuming, while ⊥⊤∗-modules are easy to compute but usually contain many redundant items. To overcome computation cost and lack of quality, we propose to compute two kinds of deductive modules called pseudo-minimal modules and complete modules for EL-ontology. Our deductive module definitions rely on associating a tree representation with an ontology, and their computation is based on SAT encoding. Our experiments on real-world ontologies show that our pseudo-minimal modules are indeed minimal modules in almost all cases (98.9%), and computing pseudo-minimal modules is more efficient (99.79 times faster on average) than the state-of-the-art method Zoom for computing minimal modules. Also, our complete modules are more compact than ⊥⊤∗-modules, but their computation time remains comparable. Finally, note that our proposal applies to EL-ontologies while Zoom only works for EL-terminologies.","https://ojs.aaai.org/index.php/AAAI/article/view/25808/25580"
"25809","Visually Grounded Commonsense Knowledge Acquisition","['Yuan Yao', 'Tianyu Yu', 'Ao Zhang', 'Mengdi Li', 'Ruobing Xie', 'Cornelius Weber', 'Zhiyuan Liu', 'Hai-Tao Zheng', 'Stefan Wermter', 'Tat-Seng Chua', 'Maosong Sun']","['Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China', 'Tsinghua Shenzhen International Graduate School, Tsinghua University', 'School of Computing, National University of Singapore, Singapore', 'Department of Informatics, University of Hamburg, Hamburg, Germany', 'WeChat AI, Tencent', 'Department of Informatics, University of Hamburg, Hamburg, Germany', 'Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China', 'Shenzhen International Graduate School, Tsinghua University\nPeng Cheng Laboratory', 'Department of Informatics, University of Hamburg, Hamburg, Germany', 'School of Computing, National University of Singapore, Singapore', 'Dept. of Comp. Sci. & Tech., Institute for AI, Tsinghua University, Beijing, China']","['KRR: Knowledge Acquisition', 'KRR: Common-Sense Reasoning']","Yao, Y., Yu, T., Zhang, A., Li, M., Xie, R., Weber, C., Liu, Z., Zheng, H.-T., Wermter, S., Chua, T.-S., & Sun, M. (2023). Visually Grounded Commonsense Knowledge Acquisition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6583-6592. https://doi.org/10.1609/aaai.v37i5.25809","Abstract 					Large-scale commonsense knowledge bases empower a broad range of AI applications, where the automatic extraction of commonsense knowledge (CKE) is a fundamental and challenging problem. CKE from text is known for suffering from the inherent sparsity and reporting bias of commonsense in text. Visual perception, on the other hand, contains rich commonsense knowledge about real-world entities, e.g., (person, can_hold, bottle), which can serve as promising sources for acquiring grounded commonsense knowledge. In this work, we present CLEVER, which formulates CKE as a distantly supervised multi-instance learning problem, where models learn to summarize commonsense relations from a bag of images about an entity pair without any human annotation on image instances. To address the problem, CLEVER leverages vision-language pre-training models for deep understanding of each image in the bag, and selects informative instances from the bag to summarize commonsense entity relations via a novel contrastive attention mechanism. Comprehensive experimental results in held-out and human evaluation show that CLEVER can extract commonsense knowledge in promising quality, outperforming pre-trained language model-based methods by 3.9 AUC and 6.4 mAUC points. The predicted commonsense scores show strong correlation with human judgment with a 0.78 Spearman coefficient. Moreover, the extracted commonsense can also be grounded into images with reasonable interpretability. The data and codes can be obtained at https://github.com/thunlp/CLEVER.","https://ojs.aaai.org/index.php/AAAI/article/view/25809/25581"
"25810","DNG: Taxonomy Expansion by Exploring the Intrinsic Directed Structure on Non-gaussian Space","['Songlin Zhai', 'Weiqing Wang', 'Yuanfang Li', 'Yuan Meng']","['School of Computer Science and Engineering, Southeast University, China', 'Faculty of Information Technology, Monash University, Australia', 'Faculty of Information Technology, Monash University, Australia', 'School of Computer Science and Engineering, Southeast University, China']","['KRR: Ontologies and Semantic Web', 'SNLP: Ontology Induction From Text']","Zhai, S., Wang, W., Li, Y., & Meng, Y. (2023). DNG: Taxonomy Expansion by Exploring the Intrinsic Directed Structure on Non-gaussian Space. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6593-6601. https://doi.org/10.1609/aaai.v37i5.25810","Abstract 					Taxonomy expansion is the process of incorporating a large number of additional nodes (i.e., ''queries'') into an existing taxonomy (i.e., ''seed''), with the most important step being the selection of appropriate positions for each query. Enormous efforts have been made by exploring the seed's structure. However, existing approaches are deficient in their mining of structural information in two ways: poor modeling of the hierarchical semantics and failure to capture directionality of the is-a relation. This paper seeks to address these issues by explicitly denoting each node as the combination of inherited feature (i.e., structural part) and incremental feature (i.e., supplementary part). Specifically, the inherited feature originates from ''parent'' nodes and is weighted by an inheritance factor. With this node representation, the hierarchy of semantics in taxonomies (i.e., the inheritance and accumulation of features from ''parent'' to ''child'') could be embodied. Additionally, based on this representation, the directionality of the is-a relation could be easily translated into the irreversible inheritance of features. Inspired by the Darmois-Skitovich Theorem, we implement this irreversibility by a non-Gaussian constraint on the supplementary feature. A log-likelihood learning objective is further utilized to optimize the proposed model (dubbed DNG), whereby the required non-Gaussianity is also theoretically ensured. Extensive experimental results on two real-world datasets verify the superiority of DNG relative to several strong baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/25810/25582"
"25811","Quality-Aware Self-Training on Differentiable Synthesis of Rare Relational Data","['Chongsheng Zhang', 'Yaxin Hou', 'Ke Chen', 'Shuang Cao', 'Gaojuan Fan', 'Ji Liu']","['Henan University', 'Henan University', 'South China University of Technology\nPeng Cheng Laboratory', 'Henan University', 'Henan University', 'Baidu Research']","['KRR: Knowledge Engineering', 'ML: Deep Neural Network Algorithms', 'ML: Relational Learning', 'ML: Classification and Regression']","Zhang, C., Hou, Y., Chen, K., Cao, S., Fan, G., & Liu, J. (2023). Quality-Aware Self-Training on Differentiable Synthesis of Rare Relational Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6602-6611. https://doi.org/10.1609/aaai.v37i5.25811","Abstract 					Data scarcity is a very common real-world problem that poses a major  challenge to data-driven analytics. Although a lot of data-balancing approaches have been proposed to mitigate this problem, they may drop some useful information or fall into the overfitting problem. Generative Adversarial Network (GAN) based data synthesis methods can alleviate such a problem but lack of quality control over the generated samples. Moreover, the latent associations between the attribute set and the class labels in a relational data cannot be easily captured by a vanilla GAN. In light of this, we introduce an end-to-end self-training scheme (namely, Quality-Aware Self-Training) for rare relational data synthesis, which generates labeled synthetic data via pseudo labeling on GAN-based synthesis. We design a semantic pseudo labeling module to first control the quality of the generated features/samples, then calibrate their semantic labels via a classifier committee consisting of multiple pre-trained shallow classifiers. The high-confident generated samples with calibrated pseudo labels are then fed into a semantic classification network as augmented samples for self-training. We conduct extensive experiments on 20 benchmark datasets of different domains, including 14 industrial datasets. The results show that our method significantly outperforms state-of-the-art methods, including two recent GAN-based data synthesis schemes. Codes are available at https://github.com/yaxinhou/QAST.","https://ojs.aaai.org/index.php/AAAI/article/view/25811/25583"
"25812","Learning to Select Prototypical Parts for Interpretable Sequential Data Modeling","['Yifei Zhang', 'Neng Gao', 'Cunqing Ma']","['Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China', 'Institute of Information Engineering, Chinese Academy of Sciences, Beijing, China']","['KRR: Case-Based Reasoning', 'ML: Time-Series/Data Streams', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'PEAI: Interpretability and Explainability']","Zhang, Y., Gao, N., & Ma, C. (2023). Learning to Select Prototypical Parts for Interpretable Sequential Data Modeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6612-6620. https://doi.org/10.1609/aaai.v37i5.25812","Abstract 					Prototype-based interpretability methods provide intuitive explanations of model prediction by comparing samples to a reference set of memorized exemplars or typical representatives in terms of similarity. In the field of sequential data modeling, similarity calculations of prototypes are usually based on encoded representation vectors. However, due to highly recursive functions, there is usually a non-negligible disparity between the prototype-based explanations and the original input. In this work, we propose a Self-Explaining Selective Model (SESM) that uses a linear combination of prototypical concepts to explain its own predictions. The model employs the idea of case-based reasoning by selecting sub-sequences of the input that mostly activate different concepts as prototypical parts, which users can compare to sub-sequences selected from different example inputs to understand model decisions. For better interpretability, we design multiple constraints including diversity, stability, and locality as training objectives. Extensive experiments in different domains demonstrate that our method exhibits promising interpretability and competitive accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25812/25584"
"25813","RETRACTED: McOmet: Multimodal Fusion Transformer for Physical Audiovisual Commonsense Reasoning","['Daoming Zong', 'Shiliang Sun']","['East China Normal University', 'East China Normal University']","['KRR: Common-Sense Reasoning', 'KRR: Geometric', 'Spatial', 'and Temporal Reasoning', 'KRR: Other Foundations of Knowledge Representation & Reasoning', 'ML: Multimodal Learning']","Zong, D., & Sun, S. (2023). RETRACTED: McOmet: Multimodal Fusion Transformer for Physical Audiovisual Commonsense Reasoning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(5), 6621-6629. https://doi.org/10.1609/aaai.v37i5.25813","Abstract Referred to by: Retraction Note to: McOmet: Multimodal Fusion Transformer for Physical Audiovisual Commonsense Reasoning. This article, which was published in Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence (AAAI 2023), has been retracted by agreement between the authors and the journal.","https://ojs.aaai.org/index.php/AAAI/article/view/25813/25585"
"25814","Approximating Full Conformal Prediction at Scale via Influence Functions","['Javier Abad Martinez', 'Umang Bhatt', 'Adrian Weller', 'Giovanni Cherubin']","['ETH Zurich, Switzerland', 'University of Cambridge, UK\nThe Alan Turing Institute, London, UK', 'University of Cambridge, UK\nThe Alan Turing Institute, London, UK', 'Microsoft Research, Cambridge, UK']","['ML: Calibration & Uncertainty Quantification', 'PEAI: Safety', 'Robustness & Trustworthiness']","Abad Martinez, J., Bhatt, U., Weller, A., & Cherubin, G. (2023). Approximating Full Conformal Prediction at Scale via Influence Functions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6631-6639. https://doi.org/10.1609/aaai.v37i6.25814","Abstract 					Conformal prediction (CP) is a wrapper around traditional machine learning models, giving coverage guarantees under the sole assumption of exchangeability; in classification problems, a CP guarantees that the error rate is at most a chosen significance level, irrespective of whether the underlying model is misspecified. However, the prohibitive computational costs of full CP led researchers to design scalable alternatives, which alas do not attain the same guarantees or statistical power of full CP. In this paper, we use influence functions to efficiently approximate full CP. We prove that our method is a consistent approximation of full CP, and empirically show that the approximation error becomes smaller as the training set increases; e.g., for 1,000 training points the two methods output p-values that are <0.001 apart: a negligible error for any practical application. Our methods enable scaling full CP to large real-world datasets. We compare our full CP approximation (ACP) to mainstream CP alternatives, and observe that our method is computationally competitive whilst enjoying the statistical predictive power of full CP.","https://ojs.aaai.org/index.php/AAAI/article/view/25814/25586"
"25815","Efficient Distributed Inference of Deep Neural Networks via Restructuring and Pruning","['Afshin Abdi', 'Saeed Rashidi', 'Faramarz Fekri', 'Tushar Krishna']","['Georgia Institute of Technology', 'Georgia Institute of Technology', 'Georgia Institute of Technology', 'Georgia Institute of Technology']","['ML: Learning on the Edge & Model Compression', 'ML: Distributed Machine Learning & Federated Learning']","Abdi, A., Rashidi, S., Fekri, F., & Krishna, T. (2023). Efficient Distributed Inference of Deep Neural Networks via Restructuring and Pruning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6640-6648. https://doi.org/10.1609/aaai.v37i6.25815","Abstract 					In this paper, we consider the parallel implementation of an already-trained deep model on multiple processing nodes (a.k.a. workers). Specifically, we investigate as to how a deep model should be divided into several parallel sub-models, each of which is executed efficiently by a worker. Since latency due to synchronization and data transfer among workers negatively impacts the performance of the parallel implementation, it is desirable to have minimum interdependency among parallel sub-models. To achieve this goal, we propose to rearrange the neurons in the neural network, partition them (without changing the general topology of the neural network), and modify the weights such that the interdependency among sub-models is minimized under the computations and communications constraints of the workers while minimizing its impact on the performance of the model. We propose RePurpose, a layer-wise model restructuring and pruning technique that guarantees the performance of the overall parallelized model. To efficiently apply RePurpose, we propose an approach based on L0 optimization and the Munkres assignment algorithm. We show that, compared to the existing methods, RePurpose significantly improves the efficiency of the distributed inference via parallel implementation, both in terms of communication and computational complexity.","https://ojs.aaai.org/index.php/AAAI/article/view/25815/25587"
"25816","Symbolic Metamodels for Interpreting Black-Boxes Using Primitive Functions","['Mahed Abroshan', 'Saumitra Mishra', 'Mohammad Mahdi Khalili']","['The Alan Turing Institute, London, UK', 'JP Morgan AI Research, London, UK', 'Yahoo! Research, NYC, NY, USA\nCSE Department, The Ohio State University, Columbus, Ohio, USA']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'PEAI: Interpretability and Explainability', 'SO: Evolutionary Computation']","Abroshan, M., Mishra, S., & Khalili, M. M. (2023). Symbolic Metamodels for Interpreting Black-Boxes Using Primitive Functions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6649-6657. https://doi.org/10.1609/aaai.v37i6.25816","Abstract 					One approach for interpreting black-box machine learning models is to find a global approximation of the model using simple interpretable functions, which is called a metamodel (a model of the model). Approximating the black-box with a metamodel can be used to 1) estimate instance-wise feature importance; 2) understand the functional form of the model; 3) analyze feature interactions. In this work, we propose a new method for finding interpretable metamodels. Our approach utilizes Kolmogorov superposition theorem, which expresses multivariate functions as a composition of univariate functions (our primitive parameterized functions). This composition can be represented in the form of a tree. Inspired by symbolic regression, we use a modified form of genetic programming to search over different tree configurations. Gradient descent (GD) is used to optimize the parameters of a given configuration. Our method is a novel memetic algorithm that uses GD  not only for training numerical constants but also for the training of building blocks. Using several experiments, we show that our method outperforms recent metamodeling approaches suggested for interpreting black-boxes.","https://ojs.aaai.org/index.php/AAAI/article/view/25816/25588"
"25817","Utilizing Prior Solutions for Reward Shaping and Composition in Entropy-Regularized Reinforcement Learning","['Jacob Adamczyk', 'Argenis Arriojas', 'Stas Tiomkin', 'Rahul V. Kulkarni']","['University of Massachusetts Boston', 'University of Massachusetts Boston', 'San Jose State University', 'University of Massachusetts Boston']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms', 'ML: Lifelong and Continual Learning']","Adamczyk, J., Arriojas, A., Tiomkin, S., & Kulkarni, R. V. (2023). Utilizing Prior Solutions for Reward Shaping and Composition in Entropy-Regularized Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6658-6665. https://doi.org/10.1609/aaai.v37i6.25817","Abstract 					In reinforcement learning (RL), the ability to utilize prior knowledge from previously solved tasks can allow agents to quickly solve new problems. In some cases, these new problems may be approximately solved by composing the solutions of previously solved primitive tasks (task composition). Otherwise, prior knowledge can be used to adjust the reward function for a new problem, in a way that leaves the optimal policy unchanged but enables quicker learning (reward shaping). In this work, we develop a general framework for reward shaping and task composition in entropy-regularized RL. To do so, we derive an exact relation connecting the optimal soft value functions for two entropy-regularized RL problems with different reward functions and dynamics. We show how the derived relation leads to a general result for reward shaping in entropy-regularized RL. We then generalize this approach to derive an exact relation connecting optimal value functions for the composition of multiple tasks in entropy-regularized RL. We validate these theoretical contributions with experiments showing that reward shaping and task composition lead to faster learning in various settings.","https://ojs.aaai.org/index.php/AAAI/article/view/25817/25589"
"25818","Clustering What Matters: Optimal Approximation for Clustering with Outliers","['Akanksha Agrawal', 'Tanmay Inamdar', 'Saket Saurabh', 'Jie Xue']","['Indian Institute of Technology Madras', 'University of Bergen', 'The Institute of Mathematical Sciences, HBNI\nUniversity of Bergen', 'New York University Shanghai']","['ML: Clustering']","Agrawal, A., Inamdar, T., Saurabh, S., & Xue, J. (2023). Clustering What Matters: Optimal Approximation for Clustering with Outliers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6666-6674. https://doi.org/10.1609/aaai.v37i6.25818","Abstract 					Clustering with outliers is one of the most fundamental problems in Computer Science.  Given a set X of n points and two numbers k and m, the clustering with outliers aims to exclude m points from X, and partition the remaining points into k clusters that minimizes a certain cost function. In this paper, we give a general approach for solving clustering with outliers, which results in a fixed-parameter tractable (FPT) algorithm in k and m (i.e., an algorithm with running time of the form f(k, m) * poly(n) for some function f), that almost matches the approximation ratio for its outlier-free counterpart.  As a corollary, we obtain FPT approximation algorithms with optimal approximation ratios for k-Median and k-Means with outliers in general and Euclidean metrics. We also exhibit more applications of our approach to other variants of the problem that impose additional constraints on the clustering, such as fairness or matroid constraints.","https://ojs.aaai.org/index.php/AAAI/article/view/25818/25590"
"25819","Contrastive Classification and Representation Learning with Probabilistic Interpretation","['Rahaf Aljundi', 'Yash Patel', 'Milan Sulc', 'Nikolay Chumerin', 'Daniel Olmeda Reino']","['Toyota Motor Europe', 'Czech Technical University in Prague', 'Czech Technical University, Prague', 'Toyota Motor Europe', 'Toyota Motor Europe']","['ML: Classification and Regression', 'ML: Representation Learning']","Aljundi, R., Patel, Y., Sulc, M., Chumerin, N., & Olmeda Reino, D. (2023). Contrastive Classification and Representation Learning with Probabilistic Interpretation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6675-6683. https://doi.org/10.1609/aaai.v37i6.25819","Abstract 					Cross entropy loss has served as the main objective function for classification-based tasks. Widely deployed for learning neural network classifiers, it shows both effectiveness and a probabilistic interpretation.  Recently, after the success of self supervised contrastive representation learning methods, supervised contrastive methods have been proposed to learn representations and have shown superior and more robust performance, compared to solely training with cross entropy loss. However, cross entropy loss is still needed to train the final classification layer. In this work, we investigate the possibility of learning both the representation and the classifier using one objective function that combines the robustness of contrastive learning and the probabilistic interpretation of  cross entropy loss. First,  we revisit a previously proposed contrastive-based objective function that approximates cross entropy loss and present a simple extension to learn  the classifier jointly. Second, we propose a new version of the supervised contrastive training that learns jointly the parameters of the classifier and the backbone of the network. We empirically show that these proposed objective functions demonstrate state-of-the-art performance and show a significant improvement over the standard cross entropy loss with more training stability and robustness in various challenging settings.","https://ojs.aaai.org/index.php/AAAI/article/view/25819/25591"
"25820","Simulating Network Paths with Recurrent Buffering Units","['Divyam Anshumaan', 'Sriram Balasubramanian', 'Shubham Tiwari', 'Nagarajan Natarajan', 'Sundararajan Sellamanickam', 'Venkat N. Padmanabhan']","['Microsoft Research India', 'University of Maryland, College Park\nMicrosoft Research India', 'Microsoft Research India', 'Microsoft Research India', 'Microsoft Research India', 'Microsoft Research India']","['ML: Applications', 'APP: Communication', 'APP: Web', 'ML: Deep Generative Models & Autoencoders', 'ML: Time-Series/Data Streams']","Anshumaan, D., Balasubramanian, S., Tiwari, S., Natarajan, N., Sellamanickam, S., & Padmanabhan, V. N. (2023). Simulating Network Paths with Recurrent Buffering Units. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6684-6692. https://doi.org/10.1609/aaai.v37i6.25820","Abstract 					Simulating physical network paths (e.g., Internet) is a cornerstone research problem in the emerging sub-field of AI-for-networking. We seek a model that generates end-to-end packet delay values in response to the time-varying load offered by a sender, which is typically a function of the previously output delays. The problem setting is unique, and renders the state-of-the-art text and time-series generative models inapplicable or ineffective. We formulate an ML problem at the intersection of dynamical systems, sequential decision making, and time-series modeling. We propose a novel grey-box approach to network simulation that embeds the semantics of physical network path in a new RNN-style model called Recurrent Buffering Unit, providing the interpretability of standard network simulator tools, the power of neural models, the efficiency of SGD-based techniques for learning, and yielding promising results on synthetic and real-world network traces.","https://ojs.aaai.org/index.php/AAAI/article/view/25820/25592"
"25821","Fully Dynamic Online Selection through Online Contention Resolution Schemes","['Vashist Avadhanula', 'Andrea Celli', 'Riccardo Colini-Baldeschi', 'Stefano Leonardi', 'Matteo Russo']","['Meta', 'Bocconi University', 'Meta', 'Sapienza University of Rome', 'Sapienza University Rome']","['ML: Online Learning & Bandits', 'ML: Other Foundations of Machine Learning']","Avadhanula, V., Celli, A., Colini-Baldeschi, R., Leonardi, S., & Russo, M. (2023). Fully Dynamic Online Selection through Online Contention Resolution Schemes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6693-6700. https://doi.org/10.1609/aaai.v37i6.25821","Abstract 					We study fully dynamic online selection problems in an adversarial/stochastic setting that includes Bayesian online selection, prophet inequalities, posted price mechanisms, and stochastic probing problems subject to combinatorial constraints.   In the classical ``incremental'' version of the problem, selected elements remain active until the end of the input sequence. On the other hand, in the fully dynamic version of the problem, elements stay active for a limited time interval, and then leave. This models, for example, the online matching of tasks to workers with task/worker-dependent working times, and sequential posted pricing of perishable goods. A successful approach to online selection problems in the adversarial setting is given by the notion of  Online Contention Resolution Scheme (OCRS), that uses  a priori information to formulate a linear relaxation of the underlying optimization problem, whose optimal fractional solution is rounded online for any adversarial order of the input sequence. Our main contribution is providing a general method for constructing an OCRS for fully dynamic online selection problems. Then, we show how to employ such OCRS to construct no-regret algorithms in a partial information model with semi-bandit feedback and adversarial inputs.","https://ojs.aaai.org/index.php/AAAI/article/view/25821/25593"
"25822","Tree Learning: Optimal Sample Complexity and Algorithms","['Dmitrii Avdiukhin', 'Grigory Yaroslavtsev', 'Danny Vainstein', 'Orr Fischer', 'Sauman Das', 'Faraz Mirza']","['Indiana University, Bloomington', 'George Mason University', 'Tel-Aviv University', 'Weizmann Institute of Science', 'Thomas Jefferson High School for Science and Technology', 'Thomas Jefferson High School for Science and Technology']","['ML: Clustering', 'ML: Learning Theory', 'ML: Relational Learning']","Avdiukhin, D., Yaroslavtsev, G., Vainstein, D., Fischer, O., Das, S., & Mirza, F. (2023). Tree Learning: Optimal Sample Complexity and Algorithms. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6701-6708. https://doi.org/10.1609/aaai.v37i6.25822","Abstract 					We study the problem of learning a hierarchical tree representation of data from labeled samples, taken from an arbitrary (and possibly adversarial) distribution. Consider a collection of data tuples labeled according to their hierarchical structure. The smallest number of such tuples required in order to be able to accurately label subsequent tuples is of interest for data collection in machine learning. We present optimal sample complexity bounds for this problem in several learning settings, including (agnostic) PAC learning and online learning. Our results are based on tight bounds of the Natarajan and Littlestone dimensions of the associated problem. The corresponding tree classifiers can be constructed efficiently in near-linear time.","https://ojs.aaai.org/index.php/AAAI/article/view/25822/25594"
"25823","Meta-Learning for Simple Regret Minimization","['Javad Azizi', 'Branislav Kveton', 'Mohammad Ghavamzadeh', 'Sumeet Katariya']","['University of Southern California', 'Amazon', 'Google Research', 'Amazon']","['ML: Online Learning & Bandits', 'ML: Meta Learning']","Azizi, J., Kveton, B., Ghavamzadeh, M., & Katariya, S. (2023). Meta-Learning for Simple Regret Minimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6709-6717. https://doi.org/10.1609/aaai.v37i6.25823","Abstract 					We develop a meta-learning framework for simple regret minimization in bandits. In this framework, a learning agent interacts with a sequence of bandit tasks, which are sampled i.i.d. from an unknown prior distribution, and learns its meta-parameters to perform better on future tasks. We propose the first Bayesian and frequentist meta-learning algorithms for this setting. The Bayesian algorithm has access to a prior distribution over the meta-parameters and its meta simple regret over m bandit tasks with horizon n is mere O(m / √n). On the other hand, the meta simple regret of the frequentist algorithm is O(n√m + m/ √n). While its regret is worse, the frequentist algorithm is more general because it does not need a prior distribution over the meta-parameters. It can also be analyzed in more settings. We instantiate our algorithms for several classes of bandit problems. Our algorithms are general and we complement our theory by evaluating them empirically in several environments.","https://ojs.aaai.org/index.php/AAAI/article/view/25823/25595"
"25824","Generalizing Downsampling from Regular Data to Graphs","['Davide Bacciu', 'Alessio Conte', 'Francesco Landolfi']","['Università di Pisa', 'Università di Pisa', 'Università di Pisa']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Bacciu, D., Conte, A., & Landolfi, F. (2023). Generalizing Downsampling from Regular Data to Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6718-6727. https://doi.org/10.1609/aaai.v37i6.25824","Abstract 					Downsampling produces coarsened, multi-resolution representations of data and it is used, for example, to produce lossy compression and visualization of large images, reduce computational costs, and boost deep neural representation learning.  Unfortunately, due to their lack of a regular structure, there is still no consensus on how downsampling should apply to graphs and linked data. Indeed reductions in graph data are still needed for the goals described above, but reduction mechanisms do not have the same focus on preserving topological structures and properties, while allowing for resolution-tuning, as is the case in regular data downsampling. In this paper, we take a step in this direction, introducing a unifying interpretation of downsampling in regular and graph data. In particular, we define a graph coarsening mechanism which is a graph-structured counterpart of controllable equispaced coarsening mechanisms in regular data. We prove theoretical guarantees for distortion bounds on path lengths, as well as the ability to preserve key topological properties in the coarsened graphs. We leverage these concepts to define a graph pooling mechanism that we empirically assess in graph classification tasks, providing a greedy algorithm that allows efficient parallel implementation on GPUs, and showing that it compares favorably against pooling methods in literature.","https://ojs.aaai.org/index.php/AAAI/article/view/25824/25596"
"25825","PiCor: Multi-Task Deep Reinforcement Learning with Policy Correction","['Fengshuo Bai', 'Hongming Zhang', 'Tianyang Tao', 'Zhiheng Wu', 'Yanna Wang', 'Bo Xu']","['School of Artificial Intelligence, University of Chinese Academy of Sciences\nInstitute of Automation, Chinese Academy of Sciences (CASIA)', 'University of Alberta', 'Université Paris-Saclay', 'School of Artificial Intelligence, University of Chinese Academy of Sciences\nInstitute of Automation, Chinese Academy of Sciences (CASIA)', 'Institute of Automation, Chinese Academy of Sciences (CASIA)', 'Institute of Automation Chinese Academy of Sciences (CASIA)\nNanjing Artificial Intelligence Research of IA']","['ML: Reinforcement Learning Algorithms', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Bai, F., Zhang, H., Tao, T., Wu, Z., Wang, Y., & Xu, B. (2023). PiCor: Multi-Task Deep Reinforcement Learning with Policy Correction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6728-6736. https://doi.org/10.1609/aaai.v37i6.25825","Abstract 					Multi-task deep reinforcement learning (DRL) ambitiously aims to train a general agent that masters multiple tasks simultaneously. However, varying learning speeds of different tasks compounding with negative gradients interference makes policy learning inefficient. In this work, we propose PiCor, an efficient multi-task DRL framework that splits learning into policy optimization and policy correction phases. The policy optimization phase improves the policy by any DRL algothrim on the sampled single task without considering other tasks. The policy correction phase first constructs an adaptive adjusted performance constraint set. Then the intermediate policy learned by the first phase is constrained to the set, which controls the negative interference and balances the learning speeds across tasks. Empirically, we demonstrate that PiCor outperforms previous methods and significantly improves sample efficiency on simulated robotic manipulation and continuous control tasks. We additionally show that adaptive weight adjusting can further improve data efficiency and performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25825/25597"
"25826","Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Conservative Natural Policy Gradient Primal-Dual Algorithm","['Qinbo Bai', 'Amrit Singh Bedi', 'Vaneet Aggarwal']","['Purdue University', 'University of Maryland', 'Purdue University']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms']","Bai, Q., Singh Bedi, A., & Aggarwal, V. (2023). Achieving Zero Constraint Violation for Constrained Reinforcement Learning via Conservative Natural Policy Gradient Primal-Dual Algorithm. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6737-6744. https://doi.org/10.1609/aaai.v37i6.25826","Abstract 					We consider the problem of constrained Markov decision process (CMDP) in continuous state actions spaces where the goal is to maximize the expected cumulative reward subject to some constraints. We propose a novel Conservative Natural Policy Gradient Primal Dual Algorithm (CNPGPD) to achieve zero constraint violation while achieving state of the art convergence results for the objective value function. For general policy parametrization, we prove convergence of value function to global optimal upto an approximation error due to restricted policy class. We improve the sample complexity of existing constrained NPGPD algorithm. To the best of our knowledge, this is the first work to establish zero constraint violation with Natural policy gradient style algorithms for infinite horizon discounted CMDPs. We demonstrate the merits of proposed algorithm via experimental evaluations.","https://ojs.aaai.org/index.php/AAAI/article/view/25826/25598"
"25827","Optimal Sparse Recovery with Decision Stumps","['Kiarash Banihashem', 'Mohammad Hajiaghayi', 'Max Springer']","['University of Maryland', 'University of Maryland', 'University of Maryland']","['ML: Dimensionality Reduction/Feature Selection', 'ML: Classification and Regression']","Banihashem, K., Hajiaghayi, M., & Springer, M. (2023). Optimal Sparse Recovery with Decision Stumps. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6745-6752. https://doi.org/10.1609/aaai.v37i6.25827","Abstract 					Decision trees are widely used for their low computational cost, good   predictive performance, and ability to assess the importance of features.   Though often used in practice for feature selection, the theoretical   guarantees of these methods are not well understood. We here obtain a tight   finite sample bound for the feature selection problem in linear regression   using single-depth decision trees. We examine the statistical properties of   these ""decision stumps"" for the recovery of the s active features from p   total features, where s << p. Our analysis provides tight sample performance guarantees on   high-dimensional sparse systems which align with the finite sample bound of   O(s log p) as obtained by Lasso, improving upon previous bounds for both   the median and optimal splitting criteria. Our results extend to the   non-linear regime as well as arbitrary sub-Gaussian distributions,   demonstrating that tree based methods attain strong feature selection   properties under a wide variety of settings and further shedding light on the   success of these methods in practice. As a byproduct of our analysis, we show   that we can provably guarantee recovery even when the number of active   features s is unknown.   We further validate our theoretical results and proof methodology   using computational experiments.","https://ojs.aaai.org/index.php/AAAI/article/view/25827/25599"
"25828","Towards Efficient and Domain-Agnostic Evasion Attack with High-Dimensional Categorical Inputs","['Hongyan Bao', 'Yufei Han', 'Yujun Zhou', 'Xin Gao', 'Xiangliang Zhang']","['King Abdullah University of Science and Technology', 'INRIA', 'King Abdullah University of Science and Technology', 'King Abdullah University of Science and Technology', 'University of Notre Dame,\nKing Abdullah University of Science and Technology']","['ML: Adversarial Learning & Robustness', 'ML: Classification and Regression']","Bao, H., Han, Y., Zhou, Y., Gao, X., & Zhang, X. (2023). Towards Efficient and Domain-Agnostic Evasion Attack with High-Dimensional Categorical Inputs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6753-6761. https://doi.org/10.1609/aaai.v37i6.25828","Abstract 					Our work targets at searching feasible adversarial perturbation to attack a classifier with  high-dimensional categorical inputs in a domain-agnostic setting. This is intrinsically a NP-hard knapsack problem where the exploration space becomes explosively larger as the feature dimension increases. Without the help of domain knowledge, solving this problem via heuristic method, such as Branch-and-Bound, suffers from exponential complexity, yet can bring arbitrarily bad attack results. We address the challenge via the lens of multi-armed bandit based combinatorial search. Our proposed method, namely FEAT, treats modifying each categorical feature as pulling an arm in multi-armed bandit programming. Our objective is to achieve highly efficient and effective attack using an Orthogonal Matching Pursuit (OMP)-enhanced Upper Confidence Bound (UCB) exploration strategy. Our theoretical analysis bounding the regret gap of FEAT guarantees its practical attack performance. In empirical analysis, we compare FEAT with other state-of-the-art domain-agnostic attack methods over various real-world categorical data sets of different applications. Substantial experimental observations confirm the expected efficiency and attack effectiveness of FEAT applied in different application scenarios. Our work further hints the applicability of FEAT for assessing the adversarial vulnerability of classification systems with high-dimensional categorical inputs.","https://ojs.aaai.org/index.php/AAAI/article/view/25828/25600"
"25829","Fairness and Welfare Quantification for Regret in Multi-Armed Bandits","['Siddharth Barman', 'Arindam Khan', 'Arnab Maiti', 'Ayush Sawarni']","['Indian Institute of Science', 'Indian Institute of Science', 'University of Washington', 'Indian Institute of Science']","['ML: Online Learning & Bandits', 'GTEP: Fair Division']","Barman, S., Khan, A., Maiti, A., & Sawarni, A. (2023). Fairness and Welfare Quantification for Regret in Multi-Armed Bandits. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6762-6769. https://doi.org/10.1609/aaai.v37i6.25829","Abstract 					We extend the notion of regret with a welfarist perspective. Focussing on the classic multi-armed bandit (MAB) framework, the current work quantifies the performance of bandit algorithms by applying a fundamental welfare function, namely the Nash social welfare (NSW) function. This corresponds to equating algorithm's performance to the geometric mean of its expected rewards and leads us to the study of   Nash regret, defined as the difference between the - a priori unknown - optimal mean (among the arms) and the algorithm's performance. Since NSW is known to satisfy fairness axioms, our approach complements the utilitarian considerations of average (cumulative) regret, wherein the algorithm is evaluated via the arithmetic mean of its expected rewards.   This work develops an algorithm that, given the horizon of play T, achieves a Nash regret of O ( sqrt{(k log T)/T} ), here k denotes the number of arms in the MAB instance. Since, for any algorithm, the Nash regret is at least as much as its average regret (the AM-GM inequality), the known lower bound on average regret holds for Nash regret as well. Therefore, our Nash regret guarantee is essentially tight. In addition, we develop an anytime algorithm with a Nash regret guarantee of O( sqrt{(k log T)/T} log T ).","https://ojs.aaai.org/index.php/AAAI/article/view/25829/25601"
"25830","Alternating Layered Variational Quantum Circuits Can Be Classically Optimized Efficiently Using Classical Shadows","['Afrad Basheer', 'Yuan Feng', 'Christopher Ferrie', 'Sanjiang Li']","['University of Technology, Sydney', 'University of Technology Sydney', 'University of Technology Sydney', 'University of Technology Sydney']","['ML: Quantum Machine Learning']","Basheer, A., Feng, Y., Ferrie, C., & Li, S. (2023). Alternating Layered Variational Quantum Circuits Can Be Classically Optimized Efficiently Using Classical Shadows. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6770-6778. https://doi.org/10.1609/aaai.v37i6.25830","Abstract 					Variational quantum algorithms (VQAs) are the quantum analog of classical neural networks (NNs). A VQA consists of a parameterized quantum circuit (PQC) which is composed of multiple layers of ansatzes (simpler PQCs, which are an analogy of NN layers) that differ only in selections of parameters. Previous work has identified the alternating layered ansatz as potentially a new standard ansatz in near-term quantum computing. Indeed, shallow alternating layered VQAs are easy to implement and have been shown to be both trainable and expressive. In this work, we introduce a training algorithm with an exponential reduction in training cost of such VQAs. Moreover, our algorithm uses classical shadows of quantum input data, and can hence be run on a classical computer with rigorous performance guarantees. We demonstrate 2-3 orders of magnitude improvement in the training cost using our algorithm for the example problems of finding state preparation circuits and the quantum autoencoder.","https://ojs.aaai.org/index.php/AAAI/article/view/25830/25602"
"25831","Learnable Spectral Wavelets on Dynamic Graphs to Capture Global Interactions","['Anson Bastos', 'Abhishek Nadgeri', 'Kuldeep Singh', 'Toyotaro Suzumura', 'Manish Singh']","['Indian Institute of Technology Hyderabad', 'RWTH Aachen', 'Cerence GmbH', 'IBM T.J. Watson Research Center', 'Indian Institute of Technology, Hyderabad']","['ML: Graph-based Machine Learning']","Bastos, A., Nadgeri, A., Singh, K., Suzumura, T., & Singh, M. (2023). Learnable Spectral Wavelets on Dynamic Graphs to Capture Global Interactions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6779-6787. https://doi.org/10.1609/aaai.v37i6.25831","Abstract 					Learning on evolving(dynamic) graphs has caught the attention of researchers as static methods exhibit limited performance in this setting. The existing methods for dynamic graphs learn spatial features by local neighborhood aggregation, which essentially only captures the low pass signals and local interactions. In this work, we go beyond current approaches to incorporate global features for effectively learning representations of a dynamically evolving graph.  We propose to do so by capturing the spectrum of the dynamic graph. Since static methods to learn the graph spectrum would not consider the history of the evolution of the spectrum as the graph evolves with time, we propose an approach to learn the graph wavelets to capture this evolving spectra. Further, we propose a framework that integrates the dynamically captured spectra in the form of these learnable wavelets into spatial features for incorporating local and global interactions. Experiments on eight standard datasets show that our method significantly outperforms related methods on various tasks for dynamic graphs.","https://ojs.aaai.org/index.php/AAAI/article/view/25831/25603"
"25832","Equi-Tuning: Group Equivariant Fine-Tuning of Pretrained Models","['Sourya Basu', 'Prasanna Sattigeri', 'Karthikeyan Natesan Ramamurthy', 'Vijil Chenthamarakshan', 'Kush R. Varshney', 'Lav R. Varshney', 'Payel Das']","['University of Illinois at Urbana-Champaign', 'IBM Research', 'IBM Research', 'IBM Research', 'IBM Research', 'University of Illinois at Urbana-Champaign', 'IBM Research']","['ML: Deep Neural Architectures', 'CV: Representation Learning for Vision', 'ML: Bias and Fairness', 'SNLP: Bias', 'Fairness', 'Transparency & Privacy', 'SNLP: Generation']","Basu, S., Sattigeri, P., Natesan Ramamurthy, K., Chenthamarakshan, V., Varshney, K. R., Varshney, L. R., & Das, P. (2023). Equi-Tuning: Group Equivariant Fine-Tuning of Pretrained Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6788-6796. https://doi.org/10.1609/aaai.v37i6.25832","Abstract 					We introduce equi-tuning, a novel fine-tuning method that transforms (potentially non-equivariant) pretrained models into group equivariant models while incurring minimum L_2 loss between the feature representations of the pretrained and the equivariant models. Large pretrained models can be equi-tuned for different groups to satisfy the needs of various downstream tasks. Equi-tuned models benefit from both group equivariance as an inductive bias and semantic priors from pretrained models. We provide applications of equi-tuning on three different tasks: image classification, compositional generalization in language, and fairness in natural language generation (NLG). We also provide a novel group-theoretic definition for fairness in NLG. The effectiveness of this definition is shown by testing it against a standard empirical method of fairness in NLG. We provide experimental results for equi-tuning using a variety of pretrained models: Alexnet, Resnet, VGG, and Densenet for image classification; RNNs, GRUs, and LSTMs for compositional generalization; and GPT2 for fairness in NLG. We test these models on benchmark datasets across all considered tasks to show the generality and effectiveness of the proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/25832/25604"
"25833","Sustaining Fairness via Incremental Learning","['Somnath Basu Roy Chowdhury', 'Snigdha Chaturvedi']","['UNC Chapel Hill', 'University of North Carolina, Chapel Hill']","['ML: Bias and Fairness', 'SNLP: Bias', 'Fairness', 'Transparency & Privacy']","Basu Roy Chowdhury, S., & Chaturvedi, S. (2023). Sustaining Fairness via Incremental Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6797-6805. https://doi.org/10.1609/aaai.v37i6.25833","Abstract 					Machine learning systems are often deployed for making critical decisions like credit lending, hiring, etc. While making decisions, such systems often encode the user's demographic information (like gender, age) in their intermediate representations. This can lead to decisions that are biased towards specific demographics. Prior work has focused on  debiasing intermediate representations to ensure fair decisions. However, these approaches fail to remain fair with changes in the task or demographic distribution. To ensure fairness in the wild, it is important for a system to adapt to such changes as it accesses new data in an incremental fashion.  In this work, we propose to address this issue by introducing the problem of learning fair representations in an incremental learning setting. To this end, we present Fairness-aware Incremental Representation Learning (FaIRL), a representation learning system that can sustain fairness while incrementally learning new tasks. FaIRL is able to achieve fairness and learn new tasks by controlling the rate-distortion function of the learned representations. Our empirical evaluations show that FaIRL is able to make fair decisions while achieving high performance on the target task, outperforming several baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/25833/25605"
"25834","Normalizing Flow Ensembles for Rich Aleatoric and Epistemic Uncertainty Modeling","['Lucas Berry', 'David Meger']","['McGill University', 'McGill University']","['ML: Calibration & Uncertainty Quantification', 'ML: Active Learning', 'ML: Ensemble Methods', 'ML: Multimodal Learning', 'ML: Probabilistic Methods']","Berry, L., & Meger, D. (2023). Normalizing Flow Ensembles for Rich Aleatoric and Epistemic Uncertainty Modeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6806-6814. https://doi.org/10.1609/aaai.v37i6.25834","Abstract 					In this work, we demonstrate how to reliably estimate epistemic uncertainty while maintaining the flexibility needed to capture complicated aleatoric distributions. To this end, we propose an ensemble of Normalizing Flows (NF), which are state-of-the-art in modeling aleatoric uncertainty. The ensembles are created via sets of fixed dropout masks, making them less expensive than creating separate NF models. We demonstrate how to leverage the unique structure of NFs, base distributions, to estimate aleatoric uncertainty without relying on samples, provide a comprehensive set of baselines, and derive unbiased estimates for differential entropy. The methods were applied to a variety of experiments, commonly used to benchmark aleatoric and epistemic uncertainty estimation: 1D sinusoidal data, 2D windy grid-world (Wet Chicken), Pendulum, and Hopper. In these experiments, we setup an active learning framework and evaluate each model's capability at measuring aleatoric and epistemic uncertainty. The results show the advantages of using NF ensembles in capturing complicated aleatoric while maintaining accurate epistemic uncertainty estimates.","https://ojs.aaai.org/index.php/AAAI/article/view/25834/25606"
"25835","An Improved Algorithm for Online Min-Sum Set Cover","['Marcin Bienkowski', 'Marcin Mucha']","['University of Wroclaw', 'University of Warsaw']","['ML: Learning Preferences or Rankings', 'ML: Online Learning & Bandits', 'RU: Other Foundations of Reasoning Under Uncertainty']","Bienkowski, M., & Mucha, M. (2023). An Improved Algorithm for Online Min-Sum Set Cover. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6815-6822. https://doi.org/10.1609/aaai.v37i6.25835","Abstract 					We study a fundamental model of online preference aggregation, where an algorithm maintains an ordered list of n elements. An input is a stream of preferred sets R_1, R_2, ..., R_t, ... Upon seeing R_t and without knowledge of any future sets, an algorithm has to rerank elements (change the list ordering), so that at least one element of R_t is found near the list front. The incurred cost is a sum of the list update costs (the number of swaps of neighboring list elements) and access cost (the position of the first element of R_t on the list). This scenario occurs naturally in applications such as ordering items in an online shop using aggregated preferences of shop customers. The theoretical underpinning of this problem is known as Min-Sum Set Cover.  Unlike previous work that mostly studied the performance of an online algorithm ALG in comparison to the static optimal solution (a single optimal list ordering), in this paper, we study an arguably harder variant where the benchmark is the provably stronger optimal dynamic solution OPT (that may also modify the list ordering). In terms of an online shop, this means that the aggregated preferences of its user base evolve with time. We construct a computationally efficient randomized algorithm whose competitive ratio (ALG-to-OPT cost ratio) is O(r^2) and prove the existence of a deterministic O(r^4)-competitive algorithm. Here, r is the maximum cardinality of sets R_t. This is the first algorithm whose ratio does not depend on n: the previously best algorithm for this problem was O(r^(3/2) * n^(1/2))-competitive and Ω(r) is a lower bound on the performance of any deterministic online algorithm.","https://ojs.aaai.org/index.php/AAAI/article/view/25835/25607"
"25836","AutoInit: Analytic Signal-Preserving Weight Initialization for Neural Networks","['Garrett Bingham', 'Risto Miikkulainen']","['The University of Texas at Austin\nCognizant AI Labs', 'The University of Texas at Austin\nCognizant AI Labs']","['ML: Deep Neural Network Algorithms', 'ML: Applications', 'ML: Auto ML and Hyperparameter Tuning', 'ML: Deep Learning Theory', 'ML: Evolutionary Learning', 'ML: Optimization']","Bingham, G., & Miikkulainen, R. (2023). AutoInit: Analytic Signal-Preserving Weight Initialization for Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6823-6833. https://doi.org/10.1609/aaai.v37i6.25836","Abstract 					Neural networks require careful weight initialization to prevent signals from exploding or vanishing.  Existing initialization schemes solve this problem in specific cases by assuming that the network has a certain activation function or topology.  It is difficult to derive such weight initialization strategies, and modern architectures therefore often use these same initialization schemes even though their assumptions do not hold. This paper introduces AutoInit, a weight initialization algorithm that automatically adapts to different neural network architectures.  By analytically tracking the mean and variance of signals as they propagate through the network, AutoInit appropriately scales the weights at each layer to avoid exploding or vanishing signals.  Experiments demonstrate that AutoInit improves performance of convolutional, residual, and transformer networks across a range of activation function, dropout, weight decay, learning rate, and normalizer settings, and does so more reliably than data-dependent initialization methods.  This flexibility allows AutoInit to initialize models for everything from small tabular tasks to large datasets such as ImageNet.  Such generality turns out particularly useful in neural architecture search and in activation function discovery.  In these settings, AutoInit initializes each candidate appropriately, making performance evaluations more accurate. AutoInit thus serves as an automatic configuration tool that makes design of new neural network architectures more robust. The AutoInit package provides a wrapper around TensorFlow models and is available at https://github.com/cognizant-ai-labs/autoinit.","https://ojs.aaai.org/index.php/AAAI/article/view/25836/25608"
"25837","A Parameterized Theory of PAC Learning","['Cornelius Brand', 'Robert Ganian', 'Kirill Simonov']","['TU Wien', 'TU Wien', 'Hasso Plattner Institute']","['ML: Learning Theory', 'KRR: Computational Complexity of Reasoning', 'ML: Reinforcement Learning Theory']","Brand, C., Ganian, R., & Simonov, K. (2023). A Parameterized Theory of PAC Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6834-6841. https://doi.org/10.1609/aaai.v37i6.25837","Abstract 					Probably Approximately Correct (i.e., PAC) learning is a core concept of sample complexity theory, and efficient PAC learnability is often seen as a natural counterpart to the class P in classical computational complexity. But while the nascent theory of parameterized complexity has allowed us to push beyond the P-NP ""dichotomy"" in classical computational complexity and identify the exact boundaries of tractability for numerous problems, there is no analogue in the domain of sample complexity that could push beyond efficient PAC learnability.  As our core contribution, we fill this gap by developing a theory of parameterized PAC learning  which allows us to shed new light on several recent PAC learning results that incorporated elements of parameterized complexity. Within the theory, we identify not one but two notions of fixed-parameter learnability that both form distinct counterparts to the class FPT - the core concept at the center of the parameterized complexity paradigm - and develop the machinery required to exclude fixed-parameter learnability. We then showcase the applications of this theory to identify refined boundaries of tractability for CNF and DNF learning as well as for a range of learning problems on graphs.","https://ojs.aaai.org/index.php/AAAI/article/view/25837/25609"
"25838","Fully-Dynamic Decision Trees","['Marco Bressan', 'Gabriel Damay', 'Mauro Sozio']","['University of Milan', 'Institut Polytechnique de Paris, Télécom Paris', 'Institut Polytechnique de Paris, Télécom Paris']","['ML: Classification and Regression', 'DMKM: Data Stream Mining', 'ML: Scalability of ML Systems']","Bressan, M., Damay, G., & Sozio, M. (2023). Fully-Dynamic Decision Trees. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6842-6849. https://doi.org/10.1609/aaai.v37i6.25838","Abstract 					We develop the first fully dynamic algorithm that maintains a decision tree over an arbitrary sequence of insertions and deletions of labeled examples. Given ε>0 our algorithm guarantees that, at every point in time, every node of the decision tree uses a split with Gini gain within an additive ε of the optimum. For real-valued features the algorithm has an amortized running time per insertion/deletion of O((d·log³n)/ε²), which improves to O((d·log²n)/ε) for binary or categorical features, while it uses space O(n·d), where n is the maximum number of examples at any point in time and d is the number of features. Our algorithm is nearly optimal, as we show that any algorithm with similar guarantees requires amortized running time Ω(d) and space Ω(n·d/polylog(nd)). We complement our theoretical results with an extensive experimental evaluation on real-world data, showing the effectiveness of our algorithm.","https://ojs.aaai.org/index.php/AAAI/article/view/25838/25610"
"25839","Scalable Theory-Driven Regularization of Scene Graph Generation Models","['Davide Buffelli', 'Efthymia Tsamoura']","['University of Padova', 'Samsung AI']","['ML: Deep Neural Network Algorithms', 'CV: Scene Analysis & Understanding', 'CV: Visual Reasoning & Symbolic Representations', 'KRR: Common-Sense Reasoning', 'ML: Semi-Supervised Learning']","Buffelli, D., & Tsamoura, E. (2023). Scalable Theory-Driven Regularization of Scene Graph Generation Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6850-6859. https://doi.org/10.1609/aaai.v37i6.25839","Abstract 					Several techniques have recently aimed to improve the performance of deep learning models for Scene Graph Generation (SGG) by incorporating background knowledge. State-of-the-art techniques can be divided into two families: one where the background knowledge is incorporated into the model in a subsymbolic fashion, and another in which the background knowledge is maintained in symbolic form. Despite promising results, both families of techniques face several shortcomings: the first one requires ad-hoc, more complex neural architectures increasing the training or inference cost; the second one suffers from limited scalability w.r.t. the size of the background knowledge. Our work introduces a regularization technique for injecting symbolic background knowledge into neural SGG models that overcomes the limitations of prior art. Our technique is model-agnostic, does not incur any cost at inference time, and scales to previously unmanageable background knowledge sizes. We demonstrate that our technique can improve the accuracy of state-of-the-art SGG models, by up to 33%.","https://ojs.aaai.org/index.php/AAAI/article/view/25839/25611"
"25840","Toward a Perspectivist Turn in Ground Truthing for Predictive Computing","['Federico Cabitza', 'Andrea Campagner', 'Valerio Basile']","['University of Milano-Bicocca', 'IRCCS Istituto Ortopedico Galeazzi', 'University of Turin']","['ML: Other Foundations of Machine Learning', 'HAI: Crowdsourcing', 'HAI: Other Foundations of Humans & AI', 'ML: Classification and Regression', 'ML: Transparent', 'Interpretable', 'Explainable ML']","Cabitza, F., Campagner, A., & Basile, V. (2023). Toward a Perspectivist Turn in Ground Truthing for Predictive Computing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6860-6868. https://doi.org/10.1609/aaai.v37i6.25840","Abstract 					Most current Artificial Intelligence applications are based on supervised Machine Learning (ML), which ultimately grounds on data annotated by small teams of experts or large ensemble of volunteers. The annotation process is often performed in terms of a majority vote, however this has been proved to be often problematic by recent evaluation studies. In this article, we describe and advocate for a different paradigm, which we call perspectivism: this counters the removal of disagreement and, consequently, the assumption of correctness of traditionally aggregated gold-standard datasets, and proposes the adoption of methods that preserve divergence of opinions and integrate multiple perspectives in the ground truthing process of ML development. Drawing on previous works which inspired it, mainly from the crowdsourcing and multi-rater labeling settings, we survey the state-of-the-art and describe the potential of our proposal for not only the more subjective tasks (e.g. those related to human language) but also those tasks commonly understood as objective (e.g. medical decision making). We present the main benefits of adopting a perspectivist stance in ML, as well as possible disadvantages, and various ways in which such a stance can be implemented in practice. Finally, we share a set of recommendations and outline a research agenda to advance the perspectivist stance in ML.","https://ojs.aaai.org/index.php/AAAI/article/view/25840/25612"
"25841","Semantic-Enhanced Image Clustering","['Shaotian Cai', 'Liping Qiu', 'Xiaojun Chen', 'Qin Zhang', 'Longteng Chen']","['Shenzhen University', 'Shenzhen University', 'Shenzhen University', 'Shenzhen University', 'Shenzhen University']","['ML: Clustering', 'ML: Applications']","Cai, S., Qiu, L., Chen, X., Zhang, Q., & Chen, L. (2023). Semantic-Enhanced Image Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6869-6878. https://doi.org/10.1609/aaai.v37i6.25841","Abstract 					Image clustering is an important and open challenging task in computer vision. Although many methods have been proposed to solve the image clustering task, they only explore images and uncover clusters according to the image features, thus being unable to distinguish visually similar but semantically different images. In this paper, we propose to investigate the task of image clustering with the help of visual-language pre-training model. Different from the zero-shot setting, in which the class names are known, we only know the number of clusters in this setting. Therefore, how to map images to a proper semantic space and how to cluster images from both image and semantic spaces are two key problems. To solve the above problems, we propose a novel image clustering method guided by the visual-language pre-training model CLIP, named Semantic-Enhanced Image Clustering (SIC). In this new method, we propose a method to map the given images to a proper semantic space first and efficient methods to generate pseudo-labels according to the relationships between images and semantics. Finally, we propose to perform clustering with consistency learning in both image space and semantic space, in a self-supervised learning fashion. The theoretical result of convergence analysis shows that our proposed method can converge at a sublinear speed. Theoretical analysis of expectation risk also shows that we can reduce the expectation risk by improving neighborhood consistency, increasing prediction confidence, or reducing neighborhood imbalance. Experimental results on five benchmark datasets clearly show the superiority of our new method.","https://ojs.aaai.org/index.php/AAAI/article/view/25841/25613"
"25842","RePreM: Representation Pre-training with Masked Model for Reinforcement Learning","['Yuanying Cai', 'Chuheng Zhang', 'Wei Shen', 'Xuyun Zhang', 'Wenjie Ruan', 'Longbo Huang']","['IIIS, Tsinghua Univeristy', 'Microsoft Research', 'Hulu', 'Macquarie University', 'Macquarie University\nUniversity of Exeter', 'IIIS, Tsinghua Univeristy']","['ML: Reinforcement Learning Algorithms', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Unsupervised & Self-Supervised Learning']","Cai, Y., Zhang, C., Shen, W., Zhang, X., Ruan, W., & Huang, L. (2023). RePreM: Representation Pre-training with Masked Model for Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6879-6887. https://doi.org/10.1609/aaai.v37i6.25842","Abstract 					Inspired by the recent success of sequence modeling in RL and the use of   masked language model for pre-training, we propose a masked model for pre-training in RL, RePreM (Representation Pre-training with Masked Model), which trains the encoder combined with transformer blocks to predict the masked states or actions in a trajectory. RePreM is simple but effective compared to existing representation pre-training methods in RL. It avoids algorithmic sophistication (such as data augmentation or estimating multiple models) with sequence modeling and generates a representation that captures long-term dynamics well. Empirically, we demonstrate the effectiveness of RePreM in various tasks, including dynamic prediction, transfer learning, and sample-efficient RL with both value-based and actor-critic methods. Moreover, we show that RePreM scales well with dataset size, dataset quality, and the scale of the encoder, which indicates its potential towards big RL models.","https://ojs.aaai.org/index.php/AAAI/article/view/25842/25614"
"25843","FTM: A Frame-Level Timeline Modeling Method for Temporal Graph Representation Learning","['Bowen Cao', 'Qichen Ye', 'Weiyuan Xu', 'Yuexian Zou']","['Peking University', 'Peking University', 'Peking University', 'Peking University\nPeng Cheng Laboratory']","['ML: Graph-based Machine Learning', 'ML: Representation Learning']","Cao, B., Ye, Q., Xu, W., & Zou, Y. (2023). FTM: A Frame-Level Timeline Modeling Method for Temporal Graph Representation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6888-6896. https://doi.org/10.1609/aaai.v37i6.25843","Abstract 					Learning representations for graph-structured data is essential for graph analytical tasks. While remarkable progress has been made on static graphs, researches on temporal graphs are still in its beginning stage. The bottleneck of the temporal graph representation learning approach is the neighborhood aggregation strategy, based on which graph attributes share and gather information explicitly. Existing neighborhood aggregation strategies fail to capture either the short-term features or the long-term features of temporal graph attributes, leading to unsatisfactory model performance and even poor robustness and domain generality of the representation learning method. To address this problem, we propose a Frame-level Timeline Modeling (FTM) method that helps to capture both short-term and long-term features and thus learns more informative representations on temporal graphs. In particular, we present a novel link-based framing technique to preserve the short-term features and then incorporate a timeline aggregator module to capture the intrinsic dynamics of graph evolution as long-term features. Our method can be easily assembled with most temporal GNNs. Extensive experiments on common datasets show that our method brings great improvements to the capability, robustness, and domain generality of backbone methods in downstream tasks. Our code can be found at https://github.com/yeeeqichen/FTM.","https://ojs.aaai.org/index.php/AAAI/article/view/25843/25615"
"25844","Estimating Treatment Effects from Irregular Time Series Observations with Hidden Confounders","['Defu Cao', 'James Enouen', 'Yujing Wang', 'Xiangchen Song', 'Chuizheng Meng', 'Hao Niu', 'Yan Liu']","['University of Southern California', 'University of Southern California', 'Peking University', 'Carnegie Mellon University', 'University of Southern California', 'KDDI Research, Inc.', 'University of Southern California']","['ML: Applications', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'ML: Causal Learning', 'ML: Time-Series/Data Streams']","Cao, D., Enouen, J., Wang, Y., Song, X., Meng, C., Niu, H., & Liu, Y. (2023). Estimating Treatment Effects from Irregular Time Series Observations with Hidden Confounders. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6897-6905. https://doi.org/10.1609/aaai.v37i6.25844","Abstract 					Causal analysis for time series data, in particular estimating individualized treatment effect (ITE), is a key task in many real world applications, such as finance, retail, healthcare,  etc. Real world time series, i.e., large-scale irregular or sparse and intermittent time series, raise significant challenges to existing work attempting to estimate treatment effects. Specifically, the existence of hidden confounders can lead to  biased treatment estimates and complicate the causal inference process. In particular, anomaly hidden confounders which exceed the typical range can lead to high variance estimates. Moreover,  in continuous time settings with irregular samples, it is challenging to directly handle the dynamics of causality. In this paper, we leverage recent advances in Lipschitz regularization and neural controlled differential equations (CDE)  to develop an effective and scalable solution, namely LipCDE, to address the above challenges. LipCDE can directly model the dynamic causal relationships between historical data and outcomes with irregular samples by considering the boundary of hidden confounders given by Lipschitz constrained neural networks. Furthermore, we conduct extensive experiments on both synthetic and real world datasets to demonstrate the effectiveness and scalability of LipCDE.","https://ojs.aaai.org/index.php/AAAI/article/view/25844/25616"
"25845","InParformer: Evolutionary Decomposition Transformers with Interactive Parallel Attention for Long-Term Time Series Forecasting","['Haizhou Cao', 'Zhenhao Huang', 'Tiechui Yao', 'Jue Wang', 'Hui He', 'Yangang Wang']","['Computer Network Information Center, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'North China Electric Power University', 'Computer Network Information Center, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Computer Network Information Center, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'North China Electric Power University', 'Computer Network Information Center, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences']","['ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms', 'ML: Time-Series/Data Streams']","Cao, H., Huang, Z., Yao, T., Wang, J., He, H., & Wang, Y. (2023). InParformer: Evolutionary Decomposition Transformers with Interactive Parallel Attention for Long-Term Time Series Forecasting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6906-6915. https://doi.org/10.1609/aaai.v37i6.25845","Abstract 					Long-term time series forecasting (LTSF) provides substantial benefits for numerous real-world applications, whereas places essential demands on the model capacity to capture long-range dependencies. Recent Transformer-based models have significantly improved LTSF performance. It is worth noting that Transformer with the self-attention mechanism was originally proposed to model language sequences whose tokens (i.e., words) are discrete and highly semantic. However, unlike language sequences, most time series are sequential and continuous numeric points. Time steps with temporal redundancy are weakly semantic, and only leveraging time-domain tokens is hard to depict the overall properties of time series (e.g., the overall trend and periodic variations). To address these problems, we propose a novel Transformer-based forecasting model named InParformer with an Interactive Parallel Attention (InPar Attention) mechanism. The InPar Attention is proposed to learn long-range dependencies comprehensively in both frequency and time domains. To improve its learning capacity and efficiency, we further design several mechanisms, including query selection, key-value pair compression, and recombination. Moreover, InParformer is constructed with evolutionary seasonal-trend decomposition modules to enhance intricate temporal pattern extraction. Extensive experiments on six real-world benchmarks show that InParformer outperforms the state-of-the-art forecasting Transformers.","https://ojs.aaai.org/index.php/AAAI/article/view/25845/25617"
"25846","Meta-Sketch: A Neural Data Structure for Estimating Item Frequencies of Data Streams","['Yukun Cao', 'Yuan Feng', 'Xike Xie']","['University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China']","['ML: Meta Learning', 'ML: Applications', 'ML: Transparent', 'Interpretable', 'Explainable ML']","Cao, Y., Feng, Y., & Xie, X. (2023). Meta-Sketch: A Neural Data Structure for Estimating Item Frequencies of Data Streams. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6916-6924. https://doi.org/10.1609/aaai.v37i6.25846","Abstract 					To estimate item frequencies of data streams with limited space, sketches are widely used in real applications, including real-time web analytics, network monitoring, and self-driving. Sketches can be viewed as a model which maps the identifier of a stream item to the corresponding frequency domain. Starting from the premise, we envision a neural data structure, which we term the meta-sketch, to go beyond the basic structure of conventional sketches. The meta-sketch learns basic sketching abilities from meta-tasks constituted with synthetic datasets following Zipf distributions in the pre-training phase, and can be fast adapted to real (skewed) distributions in the adaption phase. Extensive experiments demonstrate the performance gains of the meta-sketch and offer insights into our proposals.","https://ojs.aaai.org/index.php/AAAI/article/view/25846/25618"
"25847","Unfooling Perturbation-Based Post Hoc Explainers","['Zachariah Carmichael', 'Walter J. Scheirer']","['University of Notre Dame', 'University of Notre Dame']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'DMKM: Anomaly/Outlier Detection', 'ML: Adversarial Learning & Robustness', 'ML: Bias and Fairness', 'PEAI: Accountability', 'PEAI: AI and Law', 'Justice', 'Regulation & Governance', 'PEAI: Bias', 'Fairness & Equity']","Carmichael, Z., & Scheirer, W. J. (2023). Unfooling Perturbation-Based Post Hoc Explainers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6925-6934. https://doi.org/10.1609/aaai.v37i6.25847","Abstract 					Monumental advancements in artificial intelligence (AI) have lured the interest of doctors, lenders, judges, and other professionals. While these high-stakes decision-makers are optimistic about the technology, those familiar with AI systems are wary about the lack of transparency of its decision-making processes. Perturbation-based post hoc explainers offer a model agnostic means of interpreting these systems while only requiring query-level access. However, recent work demonstrates that these explainers can be fooled adversarially. This discovery has adverse implications for auditors, regulators, and other sentinels. With this in mind, several natural questions arise - how can we audit these black box systems? And how can we ascertain that the auditee is complying with the audit in good faith? In this work, we rigorously formalize this problem and devise a defense against adversarial attacks on perturbation-based explainers. We propose algorithms for the detection (CAD-Detect) and defense (CAD-Defend) of these attacks, which are aided by our novel conditional anomaly detection approach, KNN-CAD. We demonstrate that our approach successfully detects whether a black box system adversarially conceals its decision-making process and mitigates the adversarial attack on real-world data for the prevalent explainers, LIME and SHAP. The code for this work is available at https://github.com/craymichael/unfooling.","https://ojs.aaai.org/index.php/AAAI/article/view/25847/25619"
"25848","Very Fast, Approximate Counterfactual Explanations for Decision Forests","['Miguel Á. Carreira-Perpinan', 'Suryabhan Singh Hada']","['UC Merced', 'UC Merced']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'ML: Bias and Fairness', 'ML: Ensemble Methods', 'PEAI: Interpretability and Explainability']","Carreira-Perpinan, M. Á., & Hada, S. S. (2023). Very Fast, Approximate Counterfactual Explanations for Decision Forests. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6935-6943. https://doi.org/10.1609/aaai.v37i6.25848","Abstract 					We consider finding a counterfactual explanation for a classification or regression forest, such as a random forest. This requires solving an optimization problem to find the closest input instance to a given instance for which the forest outputs a desired value. Finding an exact solution has a cost that is exponential on the number of leaves in the forest. We propose a simple but very effective approach: we constrain the optimization to input space regions populated by actual data points. The problem reduces to a form of nearest-neighbor search using a certain distance on a certain dataset. This has two advantages: first, the solution can be found very quickly, scaling to large forests and high-dimensional data, and enabling interactive use. Second, the solution found is more likely to be realistic in that it is guided towards high-density areas of input space.","https://ojs.aaai.org/index.php/AAAI/article/view/25848/25620"
"25849","An Equivalence Analysis of Binary Quantification Methods","['Alberto Castaño', 'Jaime Alonso', 'Pablo González', 'Juan José del Coz']","['Artificial Intelligence Center, University of Oviedo at Gijón', 'Artificial Intelligence Center, University of Oviedo at Gijón', 'Artificial Intelligence Center, University of Oviedo at Gijón', 'Artificial Intelligence Center, University of Oviedo at Gijón']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Causal Learning', 'ML: Classification and Regression', 'ML: Multi-Instance/Multi-View Learning']","Castaño, A., Alonso, J., González, P., & del Coz, J. J. (2023). An Equivalence Analysis of Binary Quantification Methods. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6944-6952. https://doi.org/10.1609/aaai.v37i6.25849","Abstract 					Quantification (or prevalence estimation) algorithms aim at predicting the class distribution of unseen sets (or bags) of examples. These methods are useful for two main tasks: 1) quantification applications, for instance when we need to track the proportions of several groups of interest over time, and 2) domain adaptation problems, in which we usually need to adapt a previously trained classifier to a different --albeit related-- target distribution according to the estimated prevalences. This paper analyzes several binary quantification algorithms showing that not only do they share a common framework but are, in fact, equivalent. Inspired by this study, we propose a new method that extends one of the approaches analyzed. After an empirical evaluation of all these methods using synthetic and benchmark datasets, the paper concludes recommending three of them due to their precision, efficiency, and diversity.","https://ojs.aaai.org/index.php/AAAI/article/view/25849/25621"
"25850","Soft Action Priors: Towards Robust Policy Transfer","['Matheus Centa', 'Philippe Preux']","['Univ. Lille\nCNRS, UMR 9189 – CRIStAL, F-59000 Lille, France\nInria\nCentrale Lille', 'Univ. Lille\nCNRS, UMR 9189 – CRIStAL, F-59000 Lille, France\nInria\nCentrale Lille']","['ML: Reinforcement Learning Algorithms', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Centa, M., & Preux, P. (2023). Soft Action Priors: Towards Robust Policy Transfer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6953-6961. https://doi.org/10.1609/aaai.v37i6.25850","Abstract 					Despite success in many challenging problems, reinforcement learning (RL) is still confronted with sample inefficiency, which can be mitigated by introducing prior knowledge to agents. However, many transfer techniques in reinforcement learning make the limiting assumption that the teacher is an expert. In this paper, we use the action prior from the Reinforcement Learning as Inference framework - that is, a distribution over actions at each state which resembles a teacher policy, rather than a Bayesian prior - to recover state-of-the-art policy distillation techniques. Then, we propose a class of adaptive methods that can robustly exploit action priors by combining reward shaping and auxiliary regularization losses. In contrast to prior work, we develop algorithms for leveraging suboptimal action priors that may nevertheless impart valuable knowledge - which we call soft action priors. The proposed algorithms adapt by adjusting the strength of teacher feedback according to an estimate of the teacher's usefulness in each state. We perform tabular experiments, which show that the proposed methods achieve state-of-the-art performance, surpassing it when learning from suboptimal priors. Finally, we demonstrate the robustness of the adaptive algorithms in continuous action deep RL problems, in which adaptive algorithms considerably improved stability when compared to existing policy distillation methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25850/25622"
"25851","Invariant Representations with Stochastically Quantized Neural Networks","['Mattia Cerrato', 'Marius Köppel', 'Roberto Esposito', 'Stefan Kramer']","['Johannes Gutenberg University Mainz', 'Johannes Gutenberg University Mainz', 'Università degli Studi di Torino', 'Johannes Gutenberg University Mainz']","['ML: Bias and Fairness', 'ML: Classification and Regression', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms', 'ML: Representation Learning', 'PEAI: Bias', 'Fairness & Equity', 'PEAI: Societal Impact of AI']","Cerrato, M., Köppel, M., Esposito, R., & Kramer, S. (2023). Invariant Representations with Stochastically Quantized Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6962-6970. https://doi.org/10.1609/aaai.v37i6.25851","Abstract 					Representation learning algorithms offer the opportunity to learn invariant representations of the input data with regard to nuisance factors. Many authors have leveraged such strategies to learn fair representations, i.e., vectors where information about sensitive attributes is removed. These methods are attractive as they may be interpreted as minimizing the mutual information between a neural layer's activations and a sensitive attribute. However, the theoretical grounding of such methods relies either on the computation of infinitely accurate adversaries or on minimizing a variational upper bound of a mutual information estimate. In this paper, we propose a methodology for direct computation of the mutual information between neurons in a layer and a sensitive attribute. We employ stochastically-activated binary neural networks, which lets us treat neurons as random variables. Our method is therefore able to minimize an upper bound on the mutual information between the neural representations and a sensitive attribute. We show that this method compares favorably with the state of the art in fair representation learning and that the learned representations display a higher level of invariance compared to full-precision neural networks.","https://ojs.aaai.org/index.php/AAAI/article/view/25851/25623"
"25852","Learning Pessimism for Reinforcement Learning","['Edoardo Cetin', 'Oya Celiktutan']","[""King's College London"", ""King's College London""]","['ML: Reinforcement Learning Algorithms', 'ROB: Behavior Learning & Control', 'ML: Auto ML and Hyperparameter Tuning']","Cetin, E., & Celiktutan, O. (2023). Learning Pessimism for Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6971-6979. https://doi.org/10.1609/aaai.v37i6.25852","Abstract 					Off-policy deep reinforcement learning algorithms commonly compensate for overestimation bias during temporal-difference learning by utilizing pessimistic estimates of the expected target returns. In this work, we propose Generalized Pessimism Learning (GPL), a strategy employing a novel learnable penalty to enact such pessimism. In particular, we propose to learn this penalty alongside the critic with dual TD-learning, a new procedure to estimate and minimize the magnitude of the target returns bias with trivial computational cost. GPL enables us to accurately counteract overestimation bias throughout training without incurring the downsides of overly pessimistic targets. By integrating GPL with popular off-policy algorithms, we achieve state-of-the-art results in both competitive proprioceptive and pixel-based benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25852/25624"
"25853","Posterior Coreset Construction with Kernelized Stein Discrepancy for Model-Based Reinforcement Learning","['Souradip Chakraborty', 'Amrit Singh Bedi', 'Pratap Tokekar', 'Alec Koppel', 'Brian Sadler', 'Furong Huang', 'Dinesh Manocha']","['University of Maryland, College Park, USA', 'University of Maryland, College Park, USA', 'University of Maryland, College Park, USA', 'JP Morgan AI Research, NY, USA', 'DEVCOM Army Research Laboratory, USA', 'University of Maryland, College Park, USA', 'University of Maryland, College Park, USA']","['ML: Reinforcement Learning Theory', 'ML: Bayesian Learning', 'ML: Kernel Methods', 'ML: Reinforcement Learning Algorithms', 'ML: Scalability of ML Systems', 'RU: Sequential Decision Making']","Chakraborty, S., Bedi, A. S., Tokekar, P., Koppel, A., Sadler, B., Huang, F., & Manocha, D. (2023). Posterior Coreset Construction with Kernelized Stein Discrepancy for Model-Based Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6980-6988. https://doi.org/10.1609/aaai.v37i6.25853","Abstract 					Model-based approaches to reinforcement learning (MBRL) exhibit favorable performance in practice, but their theoretical guarantees in large spaces are mostly restricted to the setting when transition model is Gaussian or Lipschitz, and demands a posterior estimate whose representational complexity grows unbounded with time. In this work, we develop a novel MBRL method (i) which relaxes the assumptions on the target transition model to belong to a generic family of mixture models; (ii) is applicable to large-scale training by incorporating a compression step such that the posterior estimate consists of a Bayesian coreset of only statistically significant past state-action pairs; and (iii) exhibits a sublinear Bayesian regret. To achieve these results, we adopt an approach based upon Stein's method, which, under a smoothness condition on the constructed posterior and target, allows distributional distance to be evaluated in closed form as the kernelized Stein discrepancy (KSD). The aforementioned compression step is then computed in terms of greedily retaining only those samples which are more than a certain KSD away from the previous model estimate. Experimentally, we observe that this approach is competitive with several state-of-the-art RL methodologies, and can achieve up-to 50 percent reduction in wall clock time in some continuous control environments.","https://ojs.aaai.org/index.php/AAAI/article/view/25853/25625"
"25854","NHITS: Neural Hierarchical Interpolation for Time Series Forecasting","['Cristian Challu', 'Kin G. Olivares', 'Boris N. Oreshkin', 'Federico Garza Ramirez', 'Max Mergenthaler Canseco', 'Artur Dubrawski']","['Carnegie Mellon University', 'Carnegie Mellon University', 'Unity Technologies', 'Nixtla', 'Nixtla', 'Carnegie Mellon University']","['ML: Time-Series/Data Streams', 'ML: Deep Neural Architectures']","Challu, C., Olivares, K. G., Oreshkin, B. N., Garza Ramirez, F., Mergenthaler Canseco, M., & Dubrawski, A. (2023). NHITS: Neural Hierarchical Interpolation for Time Series Forecasting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6989-6997. https://doi.org/10.1609/aaai.v37i6.25854","Abstract 					Recent progress in neural forecasting accelerated improvements in the performance of large-scale forecasting systems. Yet, long-horizon forecasting remains a very difficult task. Two common challenges afflicting the task are the volatility of the predictions and their computational complexity. We introduce NHITS, a model which addresses both challenges by incorporating novel hierarchical interpolation and multi-rate data sampling techniques. These techniques enable the proposed method to assemble its predictions sequentially, emphasizing components with different frequencies and scales while decomposing the input signal and synthesizing the forecast. We prove that the hierarchical interpolation technique can efficiently approximate arbitrarily long horizons in the presence of smoothness. Additionally, we conduct extensive large-scale dataset experiments from the long-horizon forecasting literature, demonstrating the advantages of our method over the state-of-the-art methods, where NHITS provides an average accuracy improvement of almost 20% over the latest Transformer architectures while reducing the computation time by an order of magnitude (50 times). Our code is available at https://github.com/Nixtla/neuralforecast.","https://ojs.aaai.org/index.php/AAAI/article/view/25854/25626"
"25855","Where Will Players Move Next? Dynamic Graphs and Hierarchical Fusion for Movement Forecasting in Badminton","['Kai-Shiang Chang', 'Wei-Yao Wang', 'Wen-Chih Peng']","['National Yang Ming Chiao Tung University', 'National Yang Ming Chiao Tung University', 'National Yang Ming Chiao Tung University']","['ML: Applications', 'DMKM: Applications', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'DMKM: Other Foundations of Data Mining & Knowledge Management', 'APP: Other Applications', 'ML: Graph-based Machine Learning']","Chang, K.-S., Wang, W.-Y., & Peng, W.-C. (2023). Where Will Players Move Next? Dynamic Graphs and Hierarchical Fusion for Movement Forecasting in Badminton. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 6998-7005. https://doi.org/10.1609/aaai.v37i6.25855","Abstract 					Sports analytics has captured increasing attention since analysis of the various data enables insights for training strategies, player evaluation, etc. In this paper, we focus on predicting what types of returning strokes will be made, and where players will move to based on previous strokes. As this problem has not been addressed to date, movement forecasting can be tackled through sequence-based and graph-based models by formulating as a sequence prediction task. However, existing sequence-based models neglect the effects of interactions between players, and graph-based models still suffer from multifaceted perspectives on the next movement. Moreover, there is no existing work on representing strategic relations among players' shot types and movements. To address these challenges, we first introduce the procedure of the Player Movements (PM) graph to exploit the structural movements of players with strategic relations. Based on the PM graph, we propose a novel Dynamic Graphs and Hierarchical Fusion for Movement Forecasting model (DyMF) with interaction style extractors to capture the mutual interactions of players themselves and between both players within a rally, and dynamic players' tactics across time. In addition, hierarchical fusion modules are designed to incorporate the style influence of both players and rally interactions. Extensive experiments show that our model empirically outperforms both sequence- and graph-based methods and demonstrate the practical usage of movement forecasting. Code is available at https://github.com/wywyWang/CoachAI-Projects/tree/main/Movement%20Forecasting.","https://ojs.aaai.org/index.php/AAAI/article/view/25855/25627"
"25856","Graph Ordering Attention Networks","['Michail Chatzianastasis', 'Johannes Lutzeyer', 'George Dasoulas', 'Michalis Vazirgiannis']","['École Polytechnique', 'Ecole Polytechnique', 'Ecole Polytechnique\nHarvard University', 'École Polytechnique']","['ML: Graph-based Machine Learning', 'ML: Deep Neural Architectures']","Chatzianastasis, M., Lutzeyer, J., Dasoulas, G., & Vazirgiannis, M. (2023). Graph Ordering Attention Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7006-7014. https://doi.org/10.1609/aaai.v37i6.25856","Abstract 					Graph Neural Networks (GNNs) have been successfully used in many problems involving graph-structured data, achieving state-of-the-art performance.  GNNs typically employ a message-passing scheme, in which every node aggregates information from its neighbors using a permutation-invariant aggregation function. Standard well-examined choices such as the mean or sum aggregation functions have limited capabilities, as they are not able to capture interactions among neighbors.  In this work, we formalize these interactions using an information-theoretic framework that notably includes synergistic information.  Driven by this definition, we introduce the Graph Ordering Attention (GOAT) layer, a novel GNN component that captures interactions between nodes in a neighborhood.  This is achieved by learning local node orderings via an attention mechanism and processing the ordered representations using a recurrent neural network aggregator.  This design allows us to make use of a permutation-sensitive aggregator while maintaining the permutation-equivariance of the proposed GOAT layer.  The GOAT model demonstrates its increased performance in modeling graph metrics that capture complex information, such as the betweenness centrality and the effective size of a node. In practical use-cases, its superior modeling capability is confirmed through its success in several real-world node classification benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25856/25628"
"25857","Scalable and Globally Optimal Generalized L₁ K-center Clustering via Constraint Generation in Mixed Integer Linear Programming","['Aravinth Chembu', 'Scott Sanner', 'Hassan Khurram', 'Akshat Kumar']","['University of Toronto, Toronto', 'University of Toronto, Toronto', 'University of Toronto, Toronto', 'Singapore Management University, Singapore']","['ML: Clustering', 'CSO: Constraint Optimization', 'CSO: Mixed Discrete/Continuous Optimization']","Chembu, A., Sanner, S., Khurram, H., & Kumar, A. (2023). Scalable and Globally Optimal Generalized L₁ K-center Clustering via Constraint Generation in Mixed Integer Linear Programming. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7015-7023. https://doi.org/10.1609/aaai.v37i6.25857","Abstract 					The k-center clustering algorithm, introduced over 35 years ago, is known to be robust to class imbalance prevalent in many clustering problems and has various applications such as data summarization, document clustering, and facility location determination. Unfortunately, existing k-center algorithms provide highly suboptimal solutions that can limit their practical application, reproducibility, and clustering quality. In this paper, we provide a novel scalable and globally optimal solution to a popular variant of the k-center problem known as generalized L_1 k-center clustering that uses L_1 distance and allows the selection of arbitrary vectors as cluster centers.  We show that this clustering objective can be reduced to a mixed-integer linear program (MILP) that facilitates globally optimal clustering solutions. However, solving such a MILP may be intractable for large datasets; to remedy this, we present a scalable algorithm that leverages constraint generation to efficiently and provably converge to its global optimum. We further enhance outlier handling through a simple but elegant extension to our MILP objective. We first evaluate our algorithm on a variety of synthetic datasets to better understand its properties and then validate on 20 real benchmark datasets where we compare its performance to both traditional L_1 distance k-center and k-medians baselines. Our results demonstrate significant suboptimality of existing algorithms in comparison to our approach and further demonstrate that we can find optimal generalized L_1 k-center clustering solutions up to an unprecedented 1,000,000 data points.","https://ojs.aaai.org/index.php/AAAI/article/view/25857/25629"
"25858","Attribute and Structure Preserving Graph Contrastive Learning","['Jialu Chen', 'Gang Kou']","['Southwestern University of Finance and Economics', 'Southwestern University of Finance and Economics']","['ML: Graph-based Machine Learning', 'ML: Unsupervised & Self-Supervised Learning', 'ML: Representation Learning', 'ML: Deep Neural Network Algorithms', 'ML: Classification and Regression']","Chen, J., & Kou, G. (2023). Attribute and Structure Preserving Graph Contrastive Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7024-7032. https://doi.org/10.1609/aaai.v37i6.25858","Abstract 					Graph Contrastive Learning (GCL) has drawn much research interest due to its strong ability to capture both graph structure and node attribute information in a self-supervised manner. Current GCL methods usually adopt Graph Neural Networks (GNNs) as the base encoder, which typically relies on the homophily assumption of networks and overlooks node similarity in the attribute space. There are many scenarios where such assumption cannot be satisfied, or node similarity plays a crucial role. In order to design a more robust mechanism, we develop a novel attribute and structure preserving graph contrastive learning framework, named ASP, which comprehensively and efficiently preserves node attributes while exploiting graph structure. Specifically, we consider three different graph views in our framework, i.e., original view, attribute view, and global structure view. Then, we perform contrastive learning across three views in a joint fashion, mining comprehensive graph information. We validate the effectiveness of the proposed framework on various real-world networks with different levels of homophily. The results demonstrate the superior performance of our model over the representative baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/25858/25630"
"25859","On the Stability and Generalization of Triplet Learning","['Jun Chen', 'Hong Chen', 'Xue Jiang', 'Bin Gu', 'Weifu Li', 'Tieliang Gong', 'Feng Zheng']","['Huazhong Agricultural University', 'Huazhong Agricultural University\nEngineering Research Center of Intelligent Technology for Agriculture, Ministry of Education\nKey Laboratory of Smart Farming for Agricultural Animals', 'Southern University of Science and Technology', 'Mohamed bin Zayed University of Artificial Intelligence', 'Huazhong Agricultural University\nEngineering Research Center of Intelligent Technology for Agriculture, Ministry of Education\nKey Laboratory of Smart Farming for Agricultural Animals', ""Xi'an Jiaotong University\nShaanxi Provincial Key Laboratory of Big Data Knowledge Engineering, Ministry of Education"", 'Southern University of Science and Technology']","['ML: Learning Theory']","Chen, J., Chen, H., Jiang, X., Gu, B., Li, W., Gong, T., & Zheng, F. (2023). On the Stability and Generalization of Triplet Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7033-7041. https://doi.org/10.1609/aaai.v37i6.25859","Abstract 					Triplet learning, i.e. learning from triplet data, has attracted much attention in computer vision tasks with an extremely large number of categories, e.g., face recognition and person re-identification. Albeit with rapid progress in designing and applying triplet learning algorithms, there is a lacking study on the theoretical understanding of their generalization performance. To fill this gap, this paper investigates the generalization guarantees of triplet learning by leveraging the stability analysis.  Specifically, we establish the first general high-probability generalization bound for the triplet learning algorithm satisfying the uniform stability, and then obtain the excess risk bounds of the order O(log(n)/(√n) ) for both stochastic gradient descent (SGD) and regularized risk minimization (RRM), where 2n is approximately equal to the number of training samples. Moreover, an optimistic generalization bound in expectation as fast as O(1/n) is derived for RRM in a low noise case via the on-average stability analysis. Finally, our results are applied to triplet metric learning to characterize its theoretical underpinning.","https://ojs.aaai.org/index.php/AAAI/article/view/25859/25631"
"25860","CF-ViT: A General Coarse-to-Fine Method for Vision Transformer","['Mengzhao Chen', 'Mingbao Lin', 'Ke Li', 'Yunhang Shen', 'Yongjian Wu', 'Fei Chao', 'Rongrong Ji']","['MAC Lab, Department of Artificial Intelligence, Xiamen University', 'Tencent Youtu Lab', 'Tencent Youtu Lab', 'Tencent Youtu Lab', 'Tencent Youtu Lab', 'MAC Lab, Department of Artificial Intelligence, Xiamen University', 'MAC Lab, Department of Artificial Intelligence, Xiamen University\nInstitute of Artificial Intelligence, Xiamen University']","['ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms']","Chen, M., Lin, M., Li, K., Shen, Y., Wu, Y., Chao, F., & Ji, R. (2023). CF-ViT: A General Coarse-to-Fine Method for Vision Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7042-7052. https://doi.org/10.1609/aaai.v37i6.25860","Abstract 					Vision Transformers (ViT) have made many breakthroughs in computer vision tasks. However, considerable redundancy arises in the spatial dimension of an input image, leading to massive computational costs. Therefore, We propose a coarse-to-fine vision transformer (CF-ViT) to relieve computational burden while retaining performance in this paper. Our proposed CF-ViT is motivated by two important observations in modern ViT models: (1) The coarse-grained patch splitting can locate informative regions of an input image. (2) Most images can be well recognized by a ViT model in a small-length token sequence.  Therefore, our CF-ViT implements network inference in a two-stage manner. At coarse inference stage, an input image is split into a small-length patch sequence for a computationally economical classification. If not well recognized, the informative patches are identified and further re-split in a fine-grained granularity.  Extensive experiments demonstrate the efficacy of our CF-ViT. For example, without any compromise on performance, CF-ViT reduces 53% FLOPs of LV-ViT, and also achieves 2.01x throughput. Code of this project is at https://github.com/ChenMnZ/CF-V","https://ojs.aaai.org/index.php/AAAI/article/view/25860/25632"
"25861","Context-Aware Safe Medication Recommendations with Molecular Graph and DDI Graph Embedding","['Qianyu Chen', 'Xin Li', 'Kunnan Geng', 'Mingzhong Wang']","['Beijing Institute of Technology', 'Beijing Institute of Technology', 'Beijing Institute of Technology', 'The University of the Sunshine Coast']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'APP: Healthcare', 'Medicine & Wellness']","Chen, Q., Li, X., Geng, K., & Wang, M. (2023). Context-Aware Safe Medication Recommendations with Molecular Graph and DDI Graph Embedding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7053-7060. https://doi.org/10.1609/aaai.v37i6.25861","Abstract 					Molecular structures and Drug-Drug Interactions (DDI) are recognized as important knowledge to guide medication recommendation (MR) tasks, and medical concept embedding has been applied to boost their performance. Though promising performance has been achieved by leveraging Graph Neural Network (GNN) models to encode the molecular structures of medications or/and DDI, we observe that existing models are still defective: 1) to differentiate medications with similar molecules but different functionality; or/and 2) to properly capture the unintended reactions between drugs in the embedding space. To alleviate this limitation, we propose Carmen, a cautiously designed graph embedding-based MR framework. Carmen consists of four components, including patient representation learning, context information extraction, a context-aware GNN, and DDI encoding. Carmen incorporates the visit history into the representation learning of molecular graphs to distinguish molecules with similar topology but dissimilar activity. Its DDI encoding module is specially devised for the non-transitive interaction DDI graphs. The experiments on real-world datasets demonstrate that Carmen achieves remarkable performance improvement over state-of-the-art models and can improve the safety of recommended drugs with a proper DDI graph encoding.","https://ojs.aaai.org/index.php/AAAI/article/view/25861/25633"
"25862","Min-Max Submodular Ranking for Multiple Agents","['Qingyun Chen', 'Sungjin Im', 'Benjamin Moseley', 'Chenyang Xu', 'Ruilong Zhang']","['University of California, Merced', 'University of California at Merced', 'Carnegie Mellon University', 'East China Normal University\nZhejiang University', 'City University of Hong Kong']","['ML: Optimization', 'GTEP: Social Choice / Voting', 'RU: Sequential Decision Making']","Chen, Q., Im, S., Moseley, B., Xu, C., & Zhang, R. (2023). Min-Max Submodular Ranking for Multiple Agents. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7061-7068. https://doi.org/10.1609/aaai.v37i6.25862","Abstract 					In the submodular ranking (SR) problem, the input consists of a set of submodular functions defined on a ground set of elements. The goal is to order elements for all the functions to have value above a certain threshold as soon on average as possible, assuming we choose one element per time. The problem is flexible enough to capture various applications in machine learning, including decision trees.   This paper considers the min-max version of SR where multiple instances share the ground set. With the view of each instance being associated with an agent, the min-max problem is to order the common elements to minimize the maximum objective of all agents---thus, finding a fair solution for all agents. We give approximation algorithms for this problem and demonstrate their effectiveness in the application of finding a decision tree for multiple agents.","https://ojs.aaai.org/index.php/AAAI/article/view/25862/25634"
"25863","Supervised Contrastive Few-Shot Learning for High-Frequency Time Series","['Xi Chen', 'Cheng Ge', 'Ming Wang', 'Jin Wang']","['Alibaba Group', 'Alibaba Group', 'Alibaba Group', 'Alibaba Group']","['ML: Representation Learning', 'APP: Internet of Things', 'Sensor Networks & Smart Cities', 'ML: Applications', 'ML: Classification and Regression', 'ML: Deep Neural Architectures', 'ML: Time-Series/Data Streams']","Chen, X., Ge, C., Wang, M., & Wang, J. (2023). Supervised Contrastive Few-Shot Learning for High-Frequency Time Series. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7069-7077. https://doi.org/10.1609/aaai.v37i6.25863","Abstract 					Significant progress has been made in representation learning, especially with recent success on self-supervised contrastive learning. However, for time series with less intuitive or semantic meaning, sampling bias may be inevitably encountered in unsupervised approaches. Although supervised contrastive learning has shown superior performance by leveraging label information, it may also suffer from class collapse. In this study, we consider a realistic scenario in industry with limited annotation information available. A supervised contrastive framework is developed for high-frequency time series representation and classification, wherein a novel variant of supervised contrastive loss is proposed to include multiple augmentations while induce spread within each class. Experiments on four mainstream public datasets as well as a series of sensitivity and ablation analyses demonstrate that the learned representations are effective and robust compared with the direct supervised learning and self-supervised learning, notably under the minimal few-shot situation.","https://ojs.aaai.org/index.php/AAAI/article/view/25863/25635"
"25864","The Sufficiency of Off-Policyness and Soft Clipping: PPO Is Still Insufficient according to an Off-Policy Measure","['Xing Chen', 'Dongcui Diao', 'Hechang Chen', 'Hengshuai Yao', 'Haiyin Piao', 'Zhixiao Sun', 'Zhiwei Yang', 'Randy Goebel', 'Bei Jiang', 'Yi Chang']","['School of Artificial Intelligence, Jilin University, Changchun, China\nEngineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China', 'Department of Mathematical and Statistical Sciences, University of Alberta, Edmonton, Canada', 'School of Artificial Intelligence, Jilin University, Changchun, China\nEngineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China', 'Department of Computing Science, University of Alberta, Edmonton, Canada', 'School of Electronics and Information, Northwestern Polytechnical University, Xian, China', 'School of Electronics and Information, Northwestern Polytechnical University, Xian, China', 'School of Artificial Intelligence, Jilin University, Changchun, China\nEngineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China', 'Department of Computing Science, University of Alberta, Edmonton, Canada\nAlberta Machine Intelligence Institute, University of Alberta, Edmonton, Canada', 'Alberta Machine Intelligence Institute, University of Alberta, Edmonton, Canada\nDepartment of Mathematical and Statistical Sciences, University of Alberta, Edmonton, Canada', 'School of Artificial Intelligence, Jilin University, Changchun, China\nEngineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China']","['ML: Reinforcement Learning Algorithms', 'ML: Optimization']","Chen, X., Diao, D., Chen, H., Yao, H., Piao, H., Sun, Z., Yang, Z., Goebel, R., Jiang, B., & Chang, Y. (2023). The Sufficiency of Off-Policyness and Soft Clipping: PPO Is Still Insufficient according to an Off-Policy Measure. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7078-7086. https://doi.org/10.1609/aaai.v37i6.25864","Abstract 					The popular Proximal Policy Optimization (PPO) algorithm approximates the solution in a clipped policy space. Does there exist better policies outside of this space? By using a novel surrogate objective that employs the sigmoid function (which provides an interesting way of exploration), we found that the answer is ""YES"", and the better policies are in fact located very far from the clipped space. We show that PPO is insufficient in ""off-policyness"", according to an off-policy metric called DEON. Our algorithm explores in a much larger policy space than PPO, and it maximizes the Conservative Policy Iteration (CPI) objective better than PPO during training. To the best of our knowledge, all current PPO methods have the clipping operation and optimize in the clipped policy space. Our method is the first of this kind, which advances the understanding of CPI optimization and policy gradient methods. Code is available at https://github.com/raincchio/P3O.","https://ojs.aaai.org/index.php/AAAI/article/view/25864/25636"
"25865","Global Convergence of Two-Timescale Actor-Critic for Solving Linear Quadratic Regulator","['Xuyang Chen', 'Jingliang Duan', 'Yingbin Liang', 'Lin Zhao']","['National University of Singapore', 'University of Science and Technology Beijing', 'The Ohio State University', 'National University of Singapore']","['ML: Learning Theory', 'ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms']","Chen, X., Duan, J., Liang, Y., & Zhao, L. (2023). Global Convergence of Two-Timescale Actor-Critic for Solving Linear Quadratic Regulator. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7087-7095. https://doi.org/10.1609/aaai.v37i6.25865","Abstract 					The actor-critic (AC) reinforcement learning algorithms have been the powerhouse behind many challenging applications. Nevertheless, its convergence is fragile in general. To study its instability, existing works mostly consider the uncommon double-loop variant or basic models with finite state and action space. We investigate the more practical single-sample two-timescale AC for solving the canonical linear quadratic regulator (LQR) problem, where the actor and the critic update only once with a single sample in each iteration on an unbounded continuous state and action space. Existing analysis cannot conclude the convergence for such a challenging case. We develop a new analysis framework that allows establishing the global convergence to an epsilon-optimal solution with at most an order of epsilon to -2.5 sample complexity. To our knowledge, this is the first finite-time convergence analysis for the single sample two-timescale AC for solving LQR with global optimality. The sample complexity improves those of other variants by orders, which sheds light on the practical wisdom of single sample algorithms. We also further validate our theoretical findings via comprehensive simulation comparisons.","https://ojs.aaai.org/index.php/AAAI/article/view/25865/25637"
"25866","Topological Pooling on Graphs","['Yuzhou Chen', 'Yulia R. Gel']","['Temple University', 'The University of Texas at Dallas, National Science Foundation']","['ML: Representation Learning', 'ML: Graph-based Machine Learning']","Chen, Y., & Gel, Y. R. (2023). Topological Pooling on Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7096-7103. https://doi.org/10.1609/aaai.v37i6.25866","Abstract 					Graph neural networks (GNNs) have demonstrated a significant success in various graph learning tasks, from graph classification to anomaly detection. There recently has emerged a number of approaches adopting a graph pooling operation within GNNs, with a goal to preserve graph attributive and structural features during the graph representation learning. However, most existing graph pooling operations suffer from the limitations of relying on node-wise neighbor weighting and embedding, which leads to insufficient encoding of rich topological structures and node attributes exhibited by real-world networks. By invoking the machinery of persistent homology and the concept of landmarks, we propose a novel topological pooling layer and witness complex-based topological embedding mechanism that allow us to systematically integrate hidden topological information at both local and global levels. Specifically, we design new learnable local and global topological representations Wit-TopoPool which allow us to simultaneously extract rich discriminative topological information from graphs. Experiments on 11 diverse benchmark datasets against 18 baseline models in conjunction with graph classification tasks indicate that Wit-TopoPool significantly outperforms all competitors across all datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25866/25638"
"25867","Riemannian Local Mechanism for SPD Neural Networks","['Ziheng Chen', 'Tianyang Xu', 'Xiao-Jun Wu', 'Rui Wang', 'Zhiwu Huang', 'Josef Kittler']","['Jiangnan University', 'Jiangnan University', 'Jiangnan University', 'Jiangnan University', 'Singapore Management University', 'University of Surrey']","['ML: Deep Neural Network Algorithms', 'CV: Representation Learning for Vision', 'ML: Deep Learning Theory', 'ML: Matrix & Tensor Methods']","Chen, Z., Xu, T., Wu, X.-J., Wang, R., Huang, Z., & Kittler, J. (2023). Riemannian Local Mechanism for SPD Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7104-7112. https://doi.org/10.1609/aaai.v37i6.25867","Abstract 					The Symmetric Positive Definite (SPD) matrices have received wide attention for data representation in many scientific areas. Although there are many different attempts to develop effective deep architectures for data processing on the Riemannian manifold of SPD matrices, very few solutions explicitly mine the local geometrical information in deep SPD feature representations. Given the great success of local mechanisms in Euclidean methods, we argue that it is of utmost importance to ensure the preservation of local geometric information in the SPD networks. We first analyse the convolution operator commonly used for capturing local information in Euclidean deep networks from the perspective of a higher level of abstraction afforded by category theory. Based on this analysis, we define the local information in the SPD manifold and design a multi-scale submanifold block for mining local geometry. Experiments involving multiple visual tasks validate the effectiveness of our approach.","https://ojs.aaai.org/index.php/AAAI/article/view/25867/25639"
"25868","TC-DWA:Text Clustering with Dual Word-Level Augmentation","['Bo Cheng', 'Ximing Li', 'Yi Chang']","['School of Artificial Intelligence, Jilin University, China\nInternational Center of Future Science, Jilin University, China\nEngineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China', 'College of Computer Science and Technology, Jilin University, China\nKey Laboratory of Symbolic Computation and Knowledge Engineering of MOE, Jilin University, China', 'School of Artificial Intelligence, Jilin University, China\nInternational Center of Future Science, Jilin University, China\nEngineering Research Center of Knowledge-Driven Human-Machine Intelligence, Ministry of Education, China']","['ML: Clustering', 'DMKM: Applications', 'ML: Unsupervised & Self-Supervised Learning', 'SNLP: Language Models']","Cheng, B., Li, X., & Chang, Y. (2023). TC-DWA:Text Clustering with Dual Word-Level Augmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7113-7121. https://doi.org/10.1609/aaai.v37i6.25868","Abstract 					The pre-trained language models, e.g., ELMo and BERT, have recently achieved promising performance improvement in a wide range of NLP tasks, because they can output strong contextualized embedded features of words. Inspired by their great success, in this paper we target at fine-tuning them to effectively handle the text clustering task, i.e., a classic and fundamental challenge in machine learning. Accordingly, we propose a novel BERT-based method, namely Text Clustering with Dual Word-level Augmentation (TCDWA). To be specific, we formulate a self-training objective and enhance it with a dual word-level augmentation technique. First, we suppose that each text contains several most informative words, called anchor words, supporting the full text semantics. We use the embedded features of anchor words as augmented data, which are selected by ranking the norm-based attention weights of words. Second, we formulate an expectation form of word augmentation, which is equivalent to generating infinite augmented features, and further suggest a tractable approximation of Taylor expansion for efficient optimization. To evaluate the effectiveness of TCDWA, we conduct extensive experiments on several benchmark text datasets. The results demonstrate that TCDWA consistently outperforms the state-of-the-art baseline methods. Code available: https://github.com/BoCheng-96/TC-DWA.","https://ojs.aaai.org/index.php/AAAI/article/view/25868/25640"
"25869","Causal Inference with Conditional Instruments Using Deep Generative Models","['Debo Cheng', 'Ziqi Xu', 'Jiuyong Li', 'Lin Liu', 'Jixue Liu', 'Thuc Duy Le']","['School of Computer Science and Engineering, Guangxi Normal University\nUniSA STEM, University of South Australia', 'UniSA STEM, University of South Australia', 'UniSA STEM, University of South Australia', 'UniSA STEM, University of South Australia', 'UniSA STEM, University of South Australia', 'UniSA STEM, University of South Australia']","['ML: Deep Generative Models & Autoencoders', 'ML: Causal Learning', 'RU: Causality']","Cheng, D., Xu, Z., Li, J., Liu, L., Liu, J., & Le, T. D. (2023). Causal Inference with Conditional Instruments Using Deep Generative Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7122-7130. https://doi.org/10.1609/aaai.v37i6.25869","Abstract 					The instrumental variable (IV) approach is a widely used way to estimate the causal effects of a treatment on an outcome of interest from observational data with latent confounders. A standard IV is expected to be related to the treatment variable and independent of all other variables in the system. However, it is challenging to search for a standard IV from data directly due to the strict conditions. The conditional IV (CIV) method has been proposed to allow a variable to be an instrument conditioning on a set of variables, allowing a wider choice of possible IVs and enabling broader practical applications of the IV approach. Nevertheless, there is not a data-driven method to discover a CIV and its conditioning set directly from data. To fill this gap, in this paper, we propose to learn the representations of the information of a CIV and its conditioning set from data with latent confounders for average causal effect estimation. By taking advantage of deep generative models, we develop a novel data-driven approach for simultaneously learning the representation of a CIV from measured variables and generating the representation of its conditioning set given measured variables. Extensive experiments on synthetic and real-world datasets show that our method outperforms the existing IV methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25869/25641"
"25870","Wiener Graph Deconvolutional Network Improves Graph Self-Supervised Learning","['Jiashun Cheng', 'Man Li', 'Jia Li', 'Fugee Tsung']","['The Hong Kong University of Science and Technology', 'The Hong Kong University of Science and Technology', 'The Hong Kong University of Science and Technology (Guangzhou)\nThe Hong Kong University of Science and Technology', 'The Hong Kong University of Science and Technology (Guangzhou)\nThe Hong Kong University of Science and Technology']","['ML: Graph-based Machine Learning', 'ML: Unsupervised & Self-Supervised Learning']","Cheng, J., Li, M., Li, J., & Tsung, F. (2023). Wiener Graph Deconvolutional Network Improves Graph Self-Supervised Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7131-7139. https://doi.org/10.1609/aaai.v37i6.25870","Abstract 					Graph self-supervised learning (SSL) has been vastly employed to learn representations from unlabeled graphs. Existing methods can be roughly divided into predictive learning and contrastive learning, where the latter one attracts more research attention with better empirical performance. We argue that, however, predictive models weaponed with powerful decoder could achieve comparable or even better representation power than contrastive models. In this work, we propose a Wiener Graph Deconvolutional Network (WGDN), an augmentation-adaptive decoder empowered by graph wiener filter to perform information reconstruction. Theoretical analysis proves the superior reconstruction ability of graph wiener filter. Extensive experimental results on various datasets demonstrate the effectiveness of our approach.","https://ojs.aaai.org/index.php/AAAI/article/view/25870/25642"
"25871","Partial-Label Regression","['Xin Cheng', 'Deng-Bao Wang', 'Lei Feng', 'Min-Ling Zhang', 'Bo An']","['Chongqing University', 'Southeast University', 'Chongqing University', 'Southeast University', 'Nanyang Technological University']","['ML: Classification and Regression', 'ML: Semi-Supervised Learning']","Cheng, X., Wang, D.-B., Feng, L., Zhang, M.-L., & An, B. (2023). Partial-Label Regression. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7140-7147. https://doi.org/10.1609/aaai.v37i6.25871","Abstract 					Partial-label learning is a popular weakly supervised learning setting that allows each training example to be annotated with a set of candidate labels. Previous studies on partial-label learning only focused on the classification setting where candidate labels are all discrete, which cannot handle continuous labels with real values. In this paper, we provide the first attempt to investigate partial-label regression, where each training example is annotated with a set of real-valued candidate labels. To solve this problem, we first propose a simple baseline method that takes the average loss incurred by candidate labels as the predictive loss. The drawback of this method lies in that the loss incurred by the true label may be overwhelmed by other false labels. To overcome this drawback, we propose an identification method that takes the least loss incurred by candidate labels as the predictive loss. We further improve it by proposing a progressive identification method to differentiate candidate labels using progressively updated weights for incurred losses. We prove that the latter two methods are model-consistent and provide convergence analysis showing the optimal parametric convergence rate. Our proposed methods are theoretically grounded and can be compatible with any models, optimizers, and losses. Experiments validate the effectiveness of our proposed methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25871/25643"
"25872","Offline Quantum Reinforcement Learning in a Conservative Manner","['Zhihao Cheng', 'Kaining Zhang', 'Li Shen', 'Dacheng Tao']","['The University of Sydney', 'The University of Sydney', 'JD Explore Academy', 'JD Explore Academy\nThe University of Sydney']","['ML: Quantum Machine Learning', 'ML: Reinforcement Learning Algorithms']","Cheng, Z., Zhang, K., Shen, L., & Tao, D. (2023). Offline Quantum Reinforcement Learning in a Conservative Manner. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7148-7156. https://doi.org/10.1609/aaai.v37i6.25872","Abstract 					Recently, to reap the quantum advantage, empowering reinforcement learning (RL) with quantum computing has attracted much attention, which is dubbed as quantum RL (QRL). However, current QRL algorithms employ an online learning scheme, i.e., the policy that is run on a quantum computer needs to interact with the environment to collect experiences, which could be expensive and dangerous for practical applications. In this paper, we aim to solve this problem in an offline learning manner. To be more specific, we develop the first offline quantum RL (offline QRL) algorithm named CQ2L (Conservative Quantum Q-learning), which learns from offline samples and does not require any interaction with the environment. CQ2L utilizes variational quantum circuits (VQCs), which are improved with data re-uploading and scaling parameters, to represent Q-value functions of agents. To suppress the overestimation of Q-values resulting from offline data, we first employ a double Q-learning framework to reduce the overestimation bias; then a penalty term that encourages generating conservative Q-values is designed. We conduct abundant experiments to demonstrate that the proposed method CQ2L can successfully solve offline QRL tasks that the online counterpart could not.","https://ojs.aaai.org/index.php/AAAI/article/view/25872/25644"
"25873","Variational Wasserstein Barycenters with C-cyclical Monotonicity Regularization","['Jinjin Chi', 'Zhiyao Yang', 'Ximing Li', 'Jihong Ouyang', 'Renchu Guan']","['Jilin university', 'Jilin university', 'Jilin University', 'Jilin University', 'The Key Laboratory for Symbol Computation and Knowledge Engineering of the Ministry of Education\nCollege of Computer Science and Technology, Jilin University']","['ML: Probabilistic Methods']","Chi, J., Yang, Z., Li, X., Ouyang, J., & Guan, R. (2023). Variational Wasserstein Barycenters with C-cyclical Monotonicity Regularization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7157-7165. https://doi.org/10.1609/aaai.v37i6.25873","Abstract 					Wasserstein barycenter, built on the theory of Optimal Transport (OT), provides a powerful framework to aggregate probability distributions, and it has increasingly attracted great attention within the machine learning community. However, it is often intractable to precisely compute, especially for high dimensional and continuous settings. To alleviate this problem, we develop a novel regularization by using the fact that c-cyclical monotonicity is often necessary and sufficient conditions for optimality in OT problems, and incorporate it into the dual formulation of Wasserstein barycenters. For efficient computations, we adopt a variational distribution as the approximation of the true continuous barycenter, so as to frame the Wasserstein barycenters problem as an optimization problem with respect to variational parameters. Upon those ideas, we propose a novel end-to-end continuous approximation method, namely Variational Wasserstein Barycenters with c-Cyclical Monotonicity Regularization (VWB-CMR), given sample access to the input distributions. We show theoretical convergence analysis and demonstrate the superior performance of VWB-CMR on synthetic data and real applications of subset posterior aggregation.","https://ojs.aaai.org/index.php/AAAI/article/view/25873/25645"
"25874","MobileTL: On-Device Transfer Learning with Inverted Residual Blocks","['Hung-Yueh Chiang', 'Natalia Frumkin', 'Feng Liang', 'Diana Marculescu']","['The University of Texas at Austin', 'The University of Texas at Austin', 'The University of Texas at Austin', 'The University of Texas at Austin']","['ML: Learning on the Edge & Model Compression', 'ML: Distributed Machine Learning & Federated Learning']","Chiang, H.-Y., Frumkin, N., Liang, F., & Marculescu, D. (2023). MobileTL: On-Device Transfer Learning with Inverted Residual Blocks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7166-7174. https://doi.org/10.1609/aaai.v37i6.25874","Abstract 					Transfer learning on edge is challenging due to on-device limited resources. Existing work addresses this issue by training a subset of parameters or adding model patches. Developed with inference in mind, Inverted Residual Blocks (IRBs) split a convolutional layer into depthwise and pointwise convolutions, leading to more stacking layers, e.g., convolution, normalization, and activation layers. Though they are efficient for inference, IRBs require that additional activation maps are stored in memory for training weights for convolution layers and scales for normalization layers. As a result, their high memory cost prohibits training IRBs on resource-limited edge devices, and making them unsuitable in the context of transfer learning. To address this issue, we present MobileTL, a memory and computationally efficient on-device transfer learning method for models built with IRBs. MobileTL trains the shifts for internal normalization layers to avoid storing activation maps for the backward pass. Also, MobileTL approximates the backward computation of the activation layer (e.g., Hard-Swish and ReLU6) as a signed function which enables storing a binary mask instead of activation maps for the backward pass. MobileTL fine-tunes a few top blocks (close to output) rather than propagating the gradient through the whole network to reduce the computation cost. Our method reduces memory usage by 46% and 53% for MobileNetV2 and V3 IRBs, respectively. For MobileNetV3, we observe a 36% reduction in floating-point operations (FLOPs) when fine-tuning 5 blocks, while only incurring a 0.6% accuracy reduction on CIFAR10. Extensive experiments on multiple datasets demonstrate that our method is Pareto-optimal (best accuracy under given hardware constraints) compared to prior work in transfer learning for edge devices.","https://ojs.aaai.org/index.php/AAAI/article/view/25874/25646"
"25875","Learning Optimal Features via Partial Invariance","['Moulik Choraria', 'Ibtihal Ferwana', 'Ankur Mani', 'Lav R. Varshney']","['University of Illinois at Urbana-Champaign', 'University of Illinois Urbana Champaign', 'University of Minnesota - Twin Cities', 'University of Illinois at Urbana-Champaign']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Bayesian Learning', 'ML: Classification and Regression']","Choraria, M., Ferwana, I., Mani, A., & Varshney, L. R. (2023). Learning Optimal Features via Partial Invariance. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7175-7183. https://doi.org/10.1609/aaai.v37i6.25875","Abstract 					Learning models that are robust to distribution shifts is a key concern in the context of their real-life applicability. Invariant Risk Minimization (IRM) is a popular framework that aims to learn robust models from multiple environments. The success of IRM requires an important assumption: the underlying causal mechanisms/features remain invariant across environments. When not satisfied, we show that IRM can over-constrain the predictor and to remedy this, we propose a relaxation via partial invariance. In this work, we theoretically highlight the sub-optimality of IRM and then demonstrate how learning from a partition of training domains can help improve invariant models. Several experiments, conducted both in linear settings as well as with deep neural networks on tasks over both language and image data, allow us to verify our conclusions.","https://ojs.aaai.org/index.php/AAAI/article/view/25875/25647"
"25876","PrimeNet: Pre-training for Irregular Multivariate Time Series","['Ranak Roy Chowdhury', 'Jiacheng Li', 'Xiyuan Zhang', 'Dezhi Hong', 'Rajesh K. Gupta', 'Jingbo Shang']","['University of California, San Diego', 'University of California, San Diego', 'University of California, San Diego', 'Amazon', 'University of California, San Diego', 'University of California, San Diego']","['ML: Time-Series/Data Streams']","Chowdhury, R. R., Li, J., Zhang, X., Hong, D., Gupta, R. K., & Shang, J. (2023). PrimeNet: Pre-training for Irregular Multivariate Time Series. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7184-7192. https://doi.org/10.1609/aaai.v37i6.25876","Abstract 					Real-world applications often involve irregular time series, for which the time intervals between successive observations are non-uniform. Irregularity across multiple features in a multi-variate time series further results in a different subset of features at any given time (i.e., asynchronicity). Existing pre-training schemes for time-series, however, often assume regularity of time series and make no special treatment of irregularity. We argue that such irregularity offers insight about domain property of the data—for example, frequency of hospital visits may signal patient health condition—that can guide representation learning. In this work, we propose PrimeNet to learn a self-supervised representation for irregular multivariate time-series. Specifically, we design a time sensitive contrastive learning and data reconstruction task to pre-train a model. Irregular time-series exhibits considerable variations in sampling density over time. Hence, our triplet generation strategy follows the density of the original data points, preserving its native irregularity. Moreover, the sampling density variation over time makes data reconstruction difficult for different regions. Therefore, we design a data masking technique that always masks a constant time duration to accommodate reconstruction for regions of different sampling density. We learn with these tasks using unlabeled data to build a pre-trained model and fine-tune on a downstream task with limited labeled data, in contrast with existing fully supervised approach for irregular time-series, requiring large amounts of labeled data. Experiment results show that PrimeNet significantly outperforms state-of-the-art methods on naturally irregular and asynchronous data from Healthcare and IoT applications for several downstream tasks, including classification, interpolation, and regression.","https://ojs.aaai.org/index.php/AAAI/article/view/25876/25648"
"25877","Structured BFGS Method for Optimal Doubly Stochastic Matrix Approximation","['Dejun Chu', 'Changshui Zhang', 'Shiliang Sun', 'Qing Tao']","['Hefei University of Technology', 'Tsinghua University', 'East China Normal University', 'Army Academy of Artillery and Air Defense']","['ML: Optimization', 'CSO: Constraint Optimization', 'CSO: Constraint Programming']","Chu, D., Zhang, C., Sun, S., & Tao, Q. (2023). Structured BFGS Method for Optimal Doubly Stochastic Matrix Approximation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7193-7201. https://doi.org/10.1609/aaai.v37i6.25877","Abstract 					Doubly stochastic matrix plays an essential role in several areas such as statistics and machine learning. In this paper we consider the optimal approximation of a square matrix in the set of doubly stochastic matrices. A structured BFGS method is proposed to solve the dual of the primal problem. The resulting algorithm builds curvature information into the diagonal components of the true Hessian, so that it takes only additional linear cost to obtain the descent direction based on the gradient information without having to explicitly store the inverse Hessian approximation. The cost is substantially fewer than quadratic complexity of the classical BFGS algorithm. Meanwhile, a Newton-based line search method is presented for finding a suitable step size, which in practice uses the existing knowledge and takes only one iteration. The global convergence of our algorithm is established. We verify the advantages of our approach on both synthetic data and real data sets. The experimental results demonstrate that our algorithm outperforms the state-of-the-art solvers and enjoys outstanding scalability.","https://ojs.aaai.org/index.php/AAAI/article/view/25877/25649"
"25878","On the Complexity of PAC Learning in Hilbert Spaces","['Sergei Chubanov']","['Bosch Center for Artificial Intelligence']","['ML: Learning Theory', 'CSO: Other Foundations of Constraint Satisfaction & Optimization', 'ML: Kernel Methods', 'ML: Optimization', 'ML: Other Foundations of Machine Learning']","Chubanov, S. (2023). On the Complexity of PAC Learning in Hilbert Spaces. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7202-7209. https://doi.org/10.1609/aaai.v37i6.25878","Abstract 					We study the problem of binary classification from the point of view of learning convex polyhedra in Hilbert spaces, to which one can reduce any binary classification problem. The problem of learning convex polyhedra in finite-dimensional spaces is sufficiently well studied in the literature. We generalize this problem to that in a Hilbert space and propose an algorithm for learning a polyhedron which correctly classifies at least 1 − ε of the distribution, with a probability of at least 1 − δ, where ε and δ are given parameters. Also, as a corollary, we improve some previous bounds for polyhedral classification in finite-dimensional spaces.","https://ojs.aaai.org/index.php/AAAI/article/view/25878/25650"
"25879","Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks Using an Incompetent Teacher","['Vikram S Chundawat', 'Ayush K Tarun', 'Murari Mandal', 'Mohan Kankanhalli']","['Mavvex Labs, India', 'Mavvex Labs, India', 'Kalinga Institute of Industrial Technology, Bhubaneswar, India', 'National University of Singapore, Singapore']","['ML: Privacy-Aware ML', 'ML: Classification and Regression', 'ML: Evaluation and Analysis (Machine Learning)', 'PEAI: Privacy and Security']","Chundawat, V. S., Tarun, A. K., Mandal, M., & Kankanhalli, M. (2023). Can Bad Teaching Induce Forgetting? Unlearning in Deep Networks Using an Incompetent Teacher. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7210-7217. https://doi.org/10.1609/aaai.v37i6.25879","Abstract 					Machine unlearning has become an important area of research due to an increasing need for machine learning (ML) applications to comply with the emerging data privacy regulations. It facilitates the provision for removal of certain set or class of data from an already trained ML model without requiring retraining from scratch. Recently, several efforts have been put in to make unlearning to be effective and efficient. We propose a novel machine unlearning method by exploring the utility of competent and incompetent teachers in a student-teacher framework to induce forgetfulness. The knowledge from the competent and incompetent teachers is selectively transferred to the student to obtain a model that doesn't contain any information about the forget data. We experimentally show that this method generalizes well, is fast and effective. Furthermore, we introduce the zero retrain forgetting (ZRF) metric to evaluate any unlearning method. Unlike the existing unlearning metrics, the ZRF score does not depend on the availability of the expensive retrained model. This makes it useful for analysis of the unlearned model after deployment as well. We present results of experiments conducted for random subset forgetting and class forgetting on various deep networks and across different application domains. Code is at: https://github.com/vikram2000b/bad-teaching- unlearning","https://ojs.aaai.org/index.php/AAAI/article/view/25879/25651"
"25880","Scalable Spatiotemporal Graph Neural Networks","['Andrea Cini', 'Ivan Marisca', 'Filippo Maria Bianchi', 'Cesare Alippi']","['The Swiss AI Lab IDSIA, Università della Svizzera italiana', 'The Swiss AI Lab IDSIA, Università della Svizzera italiana', 'UiT the Arctic University of Norway\nNORCE Norwegian Research Centre', 'The Swiss AI Lab IDSIA, Università della Svizzera italiana\nPolitecnico di Milano']","['ML: Graph-based Machine Learning', 'ML: Time-Series/Data Streams', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'ML: Scalability of ML Systems', 'ML: Deep Neural Architectures']","Cini, A., Marisca, I., Bianchi, F. M., & Alippi, C. (2023). Scalable Spatiotemporal Graph Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7218-7226. https://doi.org/10.1609/aaai.v37i6.25880","Abstract 					Neural forecasting of spatiotemporal time series drives both research and industrial innovation in several relevant application domains. Graph neural networks (GNNs) are often the core component of the forecasting architecture. However, in most spatiotemporal GNNs, the computational complexity scales up to a quadratic factor with the length of the sequence times the number of links in the graph, hence hindering the application of these models to large graphs and long temporal sequences. While methods to improve scalability have been proposed in the context of static graphs, few research efforts have been devoted to the spatiotemporal case. To fill this gap, we propose a scalable architecture that exploits an efficient encoding of both temporal and spatial dynamics. In particular, we use a randomized recurrent neural network to embed the history of the input time series into high-dimensional state representations encompassing multi-scale temporal dynamics. Such representations are then propagated along the spatial dimension using different powers of the graph adjacency matrix to generate node embeddings characterized by a rich pool of spatiotemporal features. The resulting node embeddings can be efficiently pre-computed in an unsupervised manner, before being fed to a feed-forward decoder that learns to map the multi-scale spatiotemporal representations to predictions. The training procedure can then be parallelized node-wise by sampling the node embeddings without breaking any dependency, thus enabling scalability to large networks. Empirical results on relevant datasets show that our approach achieves results competitive with the state of the art, while dramatically reducing the computational burden.","https://ojs.aaai.org/index.php/AAAI/article/view/25880/25652"
"25881","Exploiting Multiple Abstractions in Episodic RL via Reward Shaping","['Roberto Cipollone', 'Giuseppe De Giacomo', 'Marco Favorito', 'Luca Iocchi', 'Fabio Patrizi']","['Università di Roma La Sapienza', 'Università di Roma La Sapienza\nUniversity of Oxford', 'Banca d’Italia', 'Università di Roma La Sapienza', 'Università di Roma La Sapienza']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms']","Cipollone, R., De Giacomo, G., Favorito, M., Iocchi, L., & Patrizi, F. (2023). Exploiting Multiple Abstractions in Episodic RL via Reward Shaping. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7227-7234. https://doi.org/10.1609/aaai.v37i6.25881","Abstract 					One major limitation to the applicability of Reinforcement Learning (RL) to many practical domains is the large number of samples required to learn an optimal policy. To address this problem and improve learning efficiency, we consider a linear hierarchy of abstraction layers of the Markov Decision Process (MDP) underlying the target domain. Each layer is an MDP representing a coarser model of the one immediately below in the hierarchy. In this work, we propose a novel form of Reward Shaping where the solution obtained at the abstract level is used to offer rewards to the more concrete MDP, in such a way that the abstract solution guides the learning in the more complex domain. In contrast with other works in Hierarchical RL, our technique has few requirements in the design of the abstract models and it is also tolerant to modeling errors, thus making the proposed approach practical. We formally analyze the relationship between the abstract models and the exploration heuristic induced in the lower-level domain. Moreover, we prove that the method guarantees optimal convergence and we demonstrate its effectiveness experimentally.","https://ojs.aaai.org/index.php/AAAI/article/view/25881/25653"
"25882","Tricking the Hashing Trick: A Tight Lower Bound on the Robustness of CountSketch to Adaptive Inputs","['Edith Cohen', 'Jelani Nelson', 'Tamas Sarlos', 'Uri Stemmer']","['Google Research\nTel Aviv University', 'UC Berkeley\nGoogle Research', 'Google Research', 'Tel Aviv University\nGoogle Research']","['ML: Dimensionality Reduction/Feature Selection', 'DMKM: Data Stream Mining', 'ML: Adversarial Learning & Robustness']","Cohen, E., Nelson, J., Sarlos, T., & Stemmer, U. (2023). Tricking the Hashing Trick: A Tight Lower Bound on the Robustness of CountSketch to Adaptive Inputs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7235-7243. https://doi.org/10.1609/aaai.v37i6.25882","Abstract 					CountSketch and Feature Hashing  (the ``hashing trick'')  are popular randomized dimensionality reduction methods that support recovery of l2 -heavy hitters and approximate inner products. When the inputs are not adaptive (do not depend on prior outputs), classic estimators applied to a sketch of size O(l / epsilon) are accurate for a number of queries that is exponential in l.  When inputs are adaptive, however, an adversarial input can be constructed after O(l) queries with the classic estimator and the best known robust estimator only supports ~O(l^2) queries.  In this work we show that this quadratic dependence is in a sense inherent: We design an attack that after O(l^2) queries produces an adversarial input vector whose sketch is highly biased. Our attack uses ``natural'' non-adaptive inputs (only the final adversarial input is chosen adaptively) and universally applies  with any correct estimator, including one that is unknown to the attacker. In that, we expose inherent vulnerability of this fundamental method.","https://ojs.aaai.org/index.php/AAAI/article/view/25882/25654"
"25883","Continuous Mixtures of Tractable Probabilistic Models","['Alvaro H.C. Correia', 'Gennaro Gala', 'Erik Quaeghebeur', 'Cassio de Campos', 'Robert Peharz']","['Eindhoven University of Technology', 'Eindhoven University of Technology', 'Eindhoven University of Technology', 'Eindhoven University of Technology', 'Eindhoven University of Technology\nGraz University of Technology']","['ML: Probabilistic Methods', 'RU: Graphical Model']","Correia, A. H., Gala, G., Quaeghebeur, E., de Campos, C., & Peharz, R. (2023). Continuous Mixtures of Tractable Probabilistic Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7244-7252. https://doi.org/10.1609/aaai.v37i6.25883","Abstract 					Probabilistic models based on continuous latent spaces, such as variational autoencoders, can be understood as uncountable mixture models where components depend continuously on the latent code. They have proven to be expressive tools for generative and probabilistic modelling, but are at odds with tractable probabilistic inference, that is, computing marginals and conditionals of the represented probability distribution. Meanwhile, tractable probabilistic models such as probabilistic circuits (PCs) can be understood as hierarchical discrete mixture models, and thus are capable of performing exact inference efficiently but often show subpar performance in comparison to continuous latent-space models. In this paper, we investigate a hybrid approach, namely continuous mixtures of tractable models with a small latent dimension. While these models are analytically intractable, they are well amenable to numerical integration schemes based on a finite set of integration points. With a large enough number of integration points the approximation becomes de-facto exact. Moreover, for a finite set of integration points, the integration method effectively compiles the continuous mixture into a standard PC. In experiments, we show that this simple scheme proves remarkably effective, as PCs learnt this way set new state of the art for tractable models on many standard density estimation benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25883/25655"
"25884","End-to-End Learning for Optimization via Constraint-Enforcing Approximators","['Rares Cristian', 'Pavithra Harsha', 'Georgia Perakis', 'Brian L Quanz', 'Ioannis Spantidakis']","['Massachusetts Institute of Technology', 'IBM Research', 'Massachusetts Institute of Technology', 'IBM Research', 'Massachusetts Institute of Technology']","['ML: Optimization', 'RU: Stochastic Optimization']","Cristian, R., Harsha, P., Perakis, G., Quanz, B. L., & Spantidakis, I. (2023). End-to-End Learning for Optimization via Constraint-Enforcing Approximators. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7253-7260. https://doi.org/10.1609/aaai.v37i6.25884","Abstract 					In many real-world applications, predictive methods are used to provide inputs for downstream optimization problems. It has been shown that using the downstream task-based objective to learn the intermediate predictive model is often better than using only intermediate task objectives, such as prediction error. The learning task in the former approach is referred to as end-to-end learning. The difficulty in end-to-end learning lies in differentiating through the optimization problem. Therefore, we propose a neural network architecture that can learn to approximately solve these optimization problems, particularly ensuring its output satisfies the feasibility constraints via alternate projections. We show these projections converge at a geometric rate to the exact projection. Our approach is more computationally efficient than existing methods as we do not need to solve the original optimization problem at each iteration. Furthermore, our approach can be applied to a wider range of optimization problems. We apply this to a shortest path problem for which the first stage forecasting problem is a computer vision task of predicting edge costs from terrain maps, a capacitated multi-product newsvendor problem, and a maximum matching problem. We show that this method out-performs existing approaches in terms of final task-based loss and training time.","https://ojs.aaai.org/index.php/AAAI/article/view/25884/25656"
"25885","Practical Parallel Algorithms for Submodular Maximization Subject to a Knapsack Constraint with Nearly Optimal Adaptivity","['Shuang Cui', 'Kai Han', 'Jing Tang', 'He Huang', 'Xueying Li', 'Aakas Zhiyuli']","['School of Computer Science and Technology / Suzhou Research Institute, University of Science and Technology of China', 'School of Computer Science and Technology, Soochow University', 'The Hong Kong University of Science and Technology (Guangzhou)\nThe Hong Kong University of Science and Technology', 'School of Computer Science and Technology, Soochow University', 'Alibaba Group', 'Alibaba Group']","['ML: Optimization']","Cui, S., Han, K., Tang, J., Huang, H., Li, X., & Zhiyuli, A. (2023). Practical Parallel Algorithms for Submodular Maximization Subject to a Knapsack Constraint with Nearly Optimal Adaptivity. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7261-7269. https://doi.org/10.1609/aaai.v37i6.25885","Abstract 					Submodular maximization has wide applications in machine learning and data mining, where massive datasets have brought the great need for designing efficient and parallelizable algorithms. One measure of the parallelizability of a submodular maximization algorithm is its adaptivity complexity, which indicates the number of sequential rounds where a polynomial number of queries to the objective function can be executed in parallel. In this paper, we study the problem of non-monotone submodular maximization subject to a knapsack constraint, and propose the first combinatorial algorithm achieving an (8+epsilon)-approximation under O(log n) adaptive complexity, which is optimal up to a factor of O(loglog n). Moreover, under slightly larger adaptivity, we also propose approximation algorithms with nearly optimal query complexity of O(n), while achieving better approximation ratios. We show that our algorithms can also be applied to the special case of submodular maximization subject to a cardinality constraint, and achieve performance bounds comparable with those of state-of-the-art algorithms. Finally, the effectiveness of our approach is demonstrated by extensive experiments on real-world applications.","https://ojs.aaai.org/index.php/AAAI/article/view/25885/25657"
"25886","Opposite Online Learning via Sequentially Integrated Stochastic Gradient Descent Estimators","['Wenhai Cui', 'Xiaoting Ji', 'Linglong Kong', 'Xiaodong Yan']","['Zhongtai Securities Institute for Financial Studies, Shandong University', 'Zhongtai Securities Institute for Financial Studies, Shandong University', 'Department of Mathematical and Statistical Sciences, University of Alberta', 'Zhongtai Securities Institute for Financial Studies, Shandong University\nShandong Province Key Laboratory of Financial Risk\nShandong National Center for Applied Mathematics']","['ML: Time-Series/Data Streams', 'ML: Optimization']","Cui, W., Ji, X., Kong, L., & Yan, X. (2023). Opposite Online Learning via Sequentially Integrated Stochastic Gradient Descent Estimators. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7270-7278. https://doi.org/10.1609/aaai.v37i6.25886","Abstract 					Stochastic gradient descent  algorithm  (SGD)  has been popular in various fields of artificial intelligence as well as a prototype of online learning algorithms. This article proposes a novel and general framework of one-sided testing for streaming data based on SGD, which  determines whether the unknown parameter is greater than a certain positive constant. We construct the online-updated test statistic sequentially by integrating the selected batch-specific estimator or its opposite, which is referred to opposite online learning. The batch-specific online estimators are chosen strategically according to the proposed sequential tactics designed by two-armed bandit process. Theoretical results prove the advantage of the strategy ensuring the distribution of test statistic to be optimal under the null hypothesis and also supply the theoretical evidence of power enhancement compared with classical test statistic. In application, the proposed method is appealing for statistical inference of one-sided testing because it is scalable for any model. Finally, the superior finite-sample performance is evaluated by simulation studies.","https://ojs.aaai.org/index.php/AAAI/article/view/25886/25658"
"25887","Contrastive Learning with the Feature Reconstruction Amplifier","['Wentao Cui', 'Liang Bai']","['Key Laboratory of Computational Intelligence and Chinese Information Processing of Ministry of Education, School of Computer and Information Technology, Shanxi University, Taiyuan, Shanxi, China', 'Key Laboratory of Computational Intelligence and Chinese Information Processing of Ministry of Education, School of Computer and Information Technology, Shanxi University, Taiyuan, Shanxi, China\nInstitute of Intelligent Information Processing, Shanxi University, Taiyuan, 030006, Shanxi, China']","['ML: Unsupervised & Self-Supervised Learning']","Cui, W., & Bai, L. (2023). Contrastive Learning with the Feature Reconstruction Amplifier. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7279-7287. https://doi.org/10.1609/aaai.v37i6.25887","Abstract 					Contrastive learning has emerged as one of the most promising self-supervised methods. It can efficiently learn the transferable representations of samples through the instance-level discrimination task. In general, the performance of the contrastive learning method can be further improved by projecting the transferable high-dimensional representations into the low-dimensional feature space. This is because the model can learn more abstract discriminative information. However, when low-dimensional features cannot provide sufficient discriminative information to the model (e.g., the samples are very similar to each other), the existing contrastive learning method will be limited to a great extent. Therefore, in this paper, we propose a general module called the Feature Reconstruction Amplifier (FRA) for adding additional high-dimensional feature information to the model. Specifically, FRA reconstructs the low-dimensional feature embeddings with Gaussian noise vectors and projects them to a high-dimensional reconstruction space. In this reconstruction space, we can add additional feature information through the designed loss. We have verified the effectiveness of the module itself through exhaustive ablation experiments. In addition, we perform linear evaluation and transfer learning on five common visual datasets, the experimental results demonstrate that our method is superior to recent advanced contrastive learning methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25887/25659"
"25888","Augmented Proximal Policy Optimization for Safe Reinforcement Learning","['Juntao Dai', 'Jiaming Ji', 'Long Yang', 'Qian Zheng', 'Gang Pan']","['Zhejiang University', 'Zhejiang University', 'Peking University', 'Zhejiang University', 'Zhejiang University']","['ML: Reinforcement Learning Algorithms', 'PEAI: Safety', 'Robustness & Trustworthiness', 'PRS: Control of High-Dimensional Systems', 'PRS: Planning Under Uncertainty', 'PRS: Planning With Markov Models (MDPs', 'POMDPs)', 'RU: Decision/Utility Theory']","Dai, J., Ji, J., Yang, L., Zheng, Q., & Pan, G. (2023). Augmented Proximal Policy Optimization for Safe Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7288-7295. https://doi.org/10.1609/aaai.v37i6.25888","Abstract 					Safe reinforcement learning considers practical scenarios that maximize the return while satisfying safety constraints. Current algorithms, which suffer from training oscillations or approximation errors, still struggle to update the policy efficiently with precise constraint satisfaction. In this article, we propose Augmented Proximal Policy Optimization (APPO), which augments the Lagrangian function of the primal constrained problem via attaching a quadratic deviation term. The constructed multiplier-penalty function dampens cost oscillation for stable convergence while being equivalent to the primal constrained problem to precisely control safety costs. APPO alternately updates the policy and the Lagrangian multiplier via solving the constructed augmented primal-dual problem, which can be easily implemented by any first-order optimizer. We apply our APPO methods in diverse safety-constrained tasks, setting a new state of the art compared with a comprehensive list of safe RL baselines. Extensive experiments verify the merits of our method in easy implementation, stable convergence, and precise cost control.","https://ojs.aaai.org/index.php/AAAI/article/view/25888/25660"
"25889","GradPU: Positive-Unlabeled Learning via Gradient Penalty and Positive Upweighting","['Songmin Dai', 'Xiaoqiang Li', 'Yue Zhou', 'Xichen Ye', 'Tong Liu']","['Shanghai University', 'Shanghai University', 'Shanghai University', 'Shanghai University', 'Shanghai University']","['ML: Classification and Regression', 'CV: Object Detection & Categorization', 'ML: Semi-Supervised Learning', 'ML: Unsupervised & Self-Supervised Learning']","Dai, S., Li, X., Zhou, Y., Ye, X., & Liu, T. (2023). GradPU: Positive-Unlabeled Learning via Gradient Penalty and Positive Upweighting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7296-7303. https://doi.org/10.1609/aaai.v37i6.25889","Abstract 					Positive-unlabeled learning is an essential problem in many real-world applications with only labeled positive and unlabeled data, especially when the negative samples are difficult to identify. Most existing positive-unlabeled learning methods will inevitably overfit the positive class to some extent due to the existence of unidentified positive samples. This paper first analyzes the overfitting problem and proposes to bound the generalization errors via Wasserstein distances. Based on that, we develop a simple yet effective positive-unlabeled learning method, GradPU, which consists of two key ingredients: A gradient-based regularizer that penalizes the gradient norms in the interpolated data region, which improves the generalization of positive class; An unnormalized upweighting mechanism that assigns larger weights to those positive samples that are hard, not-well-fitted and less frequently labeled. It enforces the training error of each positive sample to be small and increases the robustness to the labeling bias. We evaluate our proposed GradPU on three datasets: MNIST, FashionMNIST, and CIFAR10. The results demonstrate that GradPU achieves state-of-the-art performance on both unbiased and biased positive labeling scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/25889/25661"
"25890","Semi-Supervised Deep Regression with Uncertainty Consistency and Variational Model Ensembling via Bayesian Neural Networks","['Weihang Dai', 'Xiaomeng Li', 'Kwang-Ting Cheng']","['The Hong Kong University of Science and Technology', 'The Hong Kong University of Science and Technology', 'The Hong Kong University of Science and Technology']","['ML: Semi-Supervised Learning', 'CV: Learning & Optimization for CV', 'CV: Medical and Biological Imaging', 'APP: Healthcare', 'Medicine & Wellness', 'ML: Bayesian Learning', 'ML: Classification and Regression', 'ML: Deep Neural Network Algorithms', 'RU: Bayesian Networks']","Dai, W., Li, X., & Cheng, K.-T. (2023). Semi-Supervised Deep Regression with Uncertainty Consistency and Variational Model Ensembling via Bayesian Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7304-7313. https://doi.org/10.1609/aaai.v37i6.25890","Abstract 					Deep regression is an important problem with numerous applications. These range from computer vision tasks such as age estimation from photographs, to medical tasks such as ejection fraction estimation from echocardiograms for disease tracking. Semi-supervised approaches for deep regression are notably under-explored compared to classification and segmentation tasks, however.  Unlike classification tasks, which rely on thresholding functions for generating class pseudo-labels, regression tasks use real number target predictions directly as pseudo-labels, making them more sensitive to prediction quality. In this work, we propose a novel approach to semi-supervised regression, namely Uncertainty-Consistent Variational Model Ensembling (UCVME), which improves training by generating high-quality pseudo-labels and uncertainty estimates for heteroscedastic regression. Given that aleatoric uncertainty is only dependent on input data by definition and should be equal for the same inputs, we present a novel uncertainty consistency loss for co-trained models. Our consistency loss significantly improves uncertainty estimates and allows higher quality pseudo-labels to be assigned greater importance under heteroscedastic regression.  Furthermore, we introduce a novel variational model ensembling approach to reduce prediction noise and generate more robust pseudo-labels. We analytically show our method generates higher quality targets for unlabeled data and further improves training.  Experiments show that our method outperforms state-of-the-art alternatives on different tasks and can be competitive with supervised methods that use full labels. Code is available at https://github.com/xmed-lab/UCVME.","https://ojs.aaai.org/index.php/AAAI/article/view/25890/25662"
"25891","Tackling Data Heterogeneity in Federated Learning with Class Prototypes","['Yutong Dai', 'Zeyuan Chen', 'Junnan Li', 'Shelby Heinecke', 'Lichao Sun', 'Ran Xu']","['Lehigh University', 'Salesforce Research', 'Salesforce Research', 'Salesforce Research', 'Lehigh University', 'Salesforce Research']","['ML: Distributed Machine Learning & Federated Learning', 'CV: Representation Learning for Vision', 'ML: Classification and Regression']","Dai, Y., Chen, Z., Li, J., Heinecke, S., Sun, L., & Xu, R. (2023). Tackling Data Heterogeneity in Federated Learning with Class Prototypes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7314-7322. https://doi.org/10.1609/aaai.v37i6.25891","Abstract 					Data heterogeneity across clients in federated learning (FL) settings is a widely acknowledged challenge. In response, personalized federated learning (PFL) emerged as a framework to curate local models for clients' tasks. In PFL, a common strategy is to develop local and global models jointly - the global model (for generalization) informs the local models, and the local models (for personalization) are aggregated to update the global model. A key observation is that if we can improve the generalization ability of local models, then we can improve the generalization of global models, which in turn builds better personalized models. In this work, we consider class imbalance, an overlooked type of data heterogeneity, in the classification setting. We propose FedNH, a novel method that improves the local models' performance for both personalization and generalization by combining the uniformity and semantics of class prototypes. FedNH initially distributes class prototypes uniformly in the latent space and smoothly infuses the class semantics into class prototypes. We show that imposing uniformity helps to combat prototype collapse while infusing class semantics improves local models. Extensive experiments were conducted on popular classification datasets under the cross-device setting. Our results demonstrate the effectiveness and stability of our method over recent works.","https://ojs.aaai.org/index.php/AAAI/article/view/25891/25663"
"25892","CrysGNN: Distilling Pre-trained Knowledge to Enhance Property Prediction for Crystalline Materials","['Kishalay Das', 'Bidisha Samanta', 'Pawan Goyal', 'Seung-Cheol Lee', 'Satadeep Bhattacharjee', 'Niloy Ganguly']","['Indian Institute of Technology Kharagpur', 'Indian Institute of Technology Kharagpur', 'Indian Institute of Technology Kharagpur', 'Indo Korea Institute of Science and Technology', 'Indo Korea Science and Technology Center', 'Indian Institute of Technology Kharagpur\nL3S, Leibniz University of Hannover, Germany']","['ML: Graph-based Machine Learning', 'APP: Natural Sciences', 'ML: Unsupervised & Self-Supervised Learning']","Das, K., Samanta, B., Goyal, P., Lee, S.-C., Bhattacharjee, S., & Ganguly, N. (2023). CrysGNN: Distilling Pre-trained Knowledge to Enhance Property Prediction for Crystalline Materials. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7323-7331. https://doi.org/10.1609/aaai.v37i6.25892","Abstract 					In recent years, graph neural network (GNN) based approaches have emerged as a powerful technique to encode complex topological structure of crystal materials in an enriched repre- sentation space. These models are often supervised in nature and using the property-specific training data, learn relation- ship between crystal structure and different properties like formation energy, bandgap, bulk modulus, etc. Most of these methods require a huge amount of property-tagged data to train the system which may not be available for different prop- erties. However, there is an availability of a huge amount of crystal data with its chemical composition and structural bonds. To leverage these untapped data, this paper presents CrysGNN, a new pre-trained GNN framework for crystalline materials, which captures both node and graph level structural information of crystal graphs using a huge amount of unla- belled material data. Further, we extract distilled knowledge from CrysGNN and inject into different state of the art prop- erty predictors to enhance their property prediction accuracy. We conduct extensive experiments to show that with distilled knowledge from the pre-trained model, all the SOTA algo- rithms are able to outperform their own vanilla version with good margins. We also observe that the distillation process provides significant improvement over the conventional ap- proach of finetuning the pre-trained model. We will release the pre-trained model along with the large dataset of 800K crys- tal graph which we carefully curated; so that the pre-trained model can be plugged into any existing and upcoming models to enhance their prediction accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25892/25664"
"25893","Non-reversible Parallel Tempering for Deep Posterior Approximation","['Wei Deng', 'Qian Zhang', 'Qi Feng', 'Faming Liang', 'Guang Lin']","['Purdue University\nMorgan Stanley', 'Purdue University', 'University of Michigan, Ann Arbor', 'Purdue University', 'Purdue University']","['ML: Bayesian Learning', 'ML: Probabilistic Methods', 'RU: Stochastic Models & Probabilistic Inference', 'RU: Stochastic Optimization', 'RU: Uncertainty Representations']","Deng, W., Zhang, Q., Feng, Q., Liang, F., & Lin, G. (2023). Non-reversible Parallel Tempering for Deep Posterior Approximation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7332-7339. https://doi.org/10.1609/aaai.v37i6.25893","Abstract 					Parallel tempering (PT), also known as replica exchange, is the go-to workhorse for simulations of multi-modal distributions. The key to the success of PT is to adopt efficient swap schemes. The popular deterministic even-odd (DEO) scheme exploits the non-reversibility property and has successfully reduced the communication cost from quadratic to linear given the sufficiently many chains. However, such an innovation largely disappears in big data due to the limited chains and few bias-corrected swaps. To handle this issue, we generalize the DEO scheme to promote non-reversibility and propose a few solutions to tackle the underlying bias caused by the geometric stopping time. Notably, in big data scenarios, we obtain a nearly linear communication cost based on the optimal window size. In addition, we also adopt stochastic gradient descent (SGD) with large and constant learning rates as exploration kernels. Such a user-friendly nature enables us to conduct approximation tasks for complex posteriors without much tuning costs.","https://ojs.aaai.org/index.php/AAAI/article/view/25893/25665"
"25894","Stability-Based Generalization Analysis of the Asynchronous Decentralized SGD","['Xiaoge Deng', 'Tao Sun', 'Shengwei Li', 'Dongsheng Li']","['National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology']","['ML: Learning Theory', 'ML: Deep Learning Theory', 'ML: Distributed Machine Learning & Federated Learning', 'ML: Optimization']","Deng, X., Sun, T., Li, S., & Li, D. (2023). Stability-Based Generalization Analysis of the Asynchronous Decentralized SGD. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7340-7348. https://doi.org/10.1609/aaai.v37i6.25894","Abstract 					The generalization ability often determines the success of machine learning algorithms in practice. Therefore, it is of great theoretical and practical importance to understand and bound the generalization error of machine learning algorithms. In this paper, we provide the first generalization results of the popular stochastic gradient descent (SGD) algorithm in the distributed asynchronous decentralized setting. Our analysis is based on the uniform stability tool, where stable means that the learned model does not change much in small variations of the training set. Under some mild assumptions, we perform a comprehensive generalizability analysis of the asynchronous decentralized SGD, including generalization error and excess generalization error bounds for the strongly convex, convex, and non-convex cases. Our theoretical results reveal the effects of the learning rate, training data size, training iterations, decentralized communication topology, and asynchronous delay on the generalization performance of the asynchronous decentralized SGD. We also study the optimization error regarding the objective function values and investigate how the initial point affects the excess generalization error. Finally, we conduct extensive experiments on MNIST, CIFAR-10, CIFAR-100, and Tiny-ImageNet datasets to validate the theoretical findings.","https://ojs.aaai.org/index.php/AAAI/article/view/25894/25666"
"25895","Integer Subspace Differential Privacy","['Prathamesh Dharangutte', 'Jie Gao', 'Ruobin Gong', 'Fang-Yi Yu']","['Rutgers University', 'Rutgers University', 'Rutgers University', 'George Mason University']","['ML: Privacy-Aware ML', 'APP: Other Applications']","Dharangutte, P., Gao, J., Gong, R., & Yu, F.-Y. (2023). Integer Subspace Differential Privacy. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7349-7357. https://doi.org/10.1609/aaai.v37i6.25895","Abstract 					We propose new differential privacy solutions for when external invariants and integer constraints are simultaneously enforced on the data product. These requirements arise in real world applications of private data curation, including the  public release of the 2020 U.S. Decennial Census. They pose a great challenge to the production of provably private data products with adequate statistical usability. We propose integer subspace differential privacy to rigorously articulate the privacy guarantee when data products maintain both the invariants and integer characteristics, and demonstrate the composition and post-processing properties of our proposal. To address the challenge of sampling from a potentially highly restricted discrete space, we devise a pair of unbiased additive mechanisms, the generalized Laplace and the generalized Gaussian mechanisms, by solving the Diophantine equations as defined by the constraints. The proposed mechanisms have good accuracy, with errors exhibiting sub-exponential and sub-Gaussian tail probabilities respectively. To implement our proposal, we design an MCMC algorithm and supply empirical convergence assessment using estimated upper bounds on the total variation distance via L-lag coupling. We demonstrate the efficacy of our proposal with applications to a synthetic problem with intersecting invariants, a sensitive contingency table with known margins, and the 2010 Census county-level demonstration data with mandated fixed state population totals.","https://ojs.aaai.org/index.php/AAAI/article/view/25895/25667"
"25896","Black-Box Adversarial Attack on Time Series Classification","['Daizong Ding', 'Mi Zhang', 'Fuli Feng', 'Yuanmin Huang', 'Erling Jiang', 'Min Yang']","['Fudan University', 'Fudan University', 'University of Science and Technology of China', 'Fudan University', 'Fudan University', 'Fudan University']","['ML: Time-Series/Data Streams', 'ML: Adversarial Learning & Robustness']","Ding, D., Zhang, M., Feng, F., Huang, Y., Jiang, E., & Yang, M. (2023). Black-Box Adversarial Attack on Time Series Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7358-7368. https://doi.org/10.1609/aaai.v37i6.25896","Abstract 					With the increasing use of deep neural network (DNN) in time series classification (TSC), recent work reveals the threat of adversarial attack, where the adversary can construct adversarial examples to cause model mistakes. However, existing researches on the adversarial attack of TSC typically adopt an unrealistic white-box setting with model details transparent to the adversary. In this work, we study a more rigorous black-box setting with attack detection applied, which restricts gradient access and requires the adversarial example to be also stealthy. Theoretical analyses reveal that the key lies in: estimating black-box gradient with diversity and non-convexity of TSC models resolved, and restricting the l0 norm of the perturbation to construct adversarial samples. Towards this end, we propose a new framework named BlackTreeS, which solves the hard optimization issue for adversarial example construction with two simple yet effective modules. In particular, we propose a tree search strategy to find influential positions in a sequence, and independently estimate the black-box gradients for these positions. Extensive experiments on three real-world TSC datasets and five DNN based models validate the effectiveness of BlackTreeS, e.g., it improves the attack success rate from 19.3% to 27.3%, and decreases the detection success rate from 90.9% to 6.8% for LSTM on the UWave dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/25896/25668"
"25897","C-NTPP: Learning Cluster-Aware Neural Temporal Point Process","['Fangyu Ding', 'Junchi Yan', 'Haiyang Wang']","['Department of Computer Science and Engineering and MOE Key Lab of AI, Shanghai Jiao Tong University', 'Department of Computer Science and Engineering and MOE Key Lab of AI, Shanghai Jiao Tong University', 'Ant Group, Hangzhou, China']","['ML: Time-Series/Data Streams', 'ML: Applications', 'ML: Bayesian Learning', 'ML: Classification and Regression', 'ML: Clustering', 'ML: Deep Generative Models & Autoencoders', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms', 'ML: Representation Learning', 'RU: Stochastic Models & Probabilistic Inference']","Ding, F., Yan, J., & Wang, H. (2023). C-NTPP: Learning Cluster-Aware Neural Temporal Point Process. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7369-7377. https://doi.org/10.1609/aaai.v37i6.25897","Abstract 					Event sequences in continuous time space are ubiquitous across applications and have been intensively studied with both classic temporal point process (TPP) and its recent deep network variants. This work is motivated by an observation that many of event data exhibit inherent clustering patterns in terms of the sparse correlation among events, while such characteristics are seldom explicitly considered in existing neural TPP models whereby the history encoders are often embodied by RNNs or Transformers. In this work, we propose a c-NTPP (Cluster-Aware Neural Temporal Point Process) model, which leverages a sequential variational autoencoder framework to infer the latent cluster each event belongs to in the sequence. Specially, a novel event-clustered attention mechanism is devised to learn each cluster and then aggregate them together to obtain the final representation for each event. Extensive experiments show that c-NTPP achieves superior performance on both real-world and synthetic datasets, and it can also uncover the underlying clustering correlations.","https://ojs.aaai.org/index.php/AAAI/article/view/25897/25669"
"25898","Eliciting Structural and Semantic Global Knowledge in Unsupervised Graph Contrastive Learning","['Kaize Ding', 'Yancheng Wang', 'Yingzhen Yang', 'Huan Liu']","['Arizona State University', 'Arizona State University', 'Arizona State University', 'Arizona State University']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Unsupervised & Self-Supervised Learning']","Ding, K., Wang, Y., Yang, Y., & Liu, H. (2023). Eliciting Structural and Semantic Global Knowledge in Unsupervised Graph Contrastive Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7378-7386. https://doi.org/10.1609/aaai.v37i6.25898","Abstract 					Graph Contrastive Learning (GCL) has recently drawn much research interest for learning generalizable node representations in a self-supervised manner. In general, the contrastive learning process in GCL is performed on top of the representations learned by a graph neural network (GNN) backbone, which transforms and propagates the node contextual information based on its local neighborhoods. However, nodes sharing similar characteristics may not always be geographically close, which poses a great challenge for unsupervised GCL efforts due to their inherent limitations in capturing such global graph knowledge. In this work, we address their inherent limitations by proposing a simple yet effective framework -- Simple Neural Networks with Structural and Semantic Contrastive Learning} (S^3-CL). Notably, by virtue of the proposed structural and semantic contrastive learning algorithms, even a simple neural network can learn expressive node representations that preserve valuable global structural and semantic patterns. Our experiments demonstrate that the node representations learned by S^3-CL) achieve superior performance on different downstream tasks compared with the state-of-the-art unsupervised GCL methods. Implementation and more experimental details are publicly available at https://github.com/kaize0409/S-3-CL.","https://ojs.aaai.org/index.php/AAAI/article/view/25898/25670"
"25899","Incremental Reinforcement Learning with Dual-Adaptive ε-Greedy Exploration","['Wei Ding', 'Siyang Jiang', 'Hsi-Wen Chen', 'Ming-Syan Chen']","['National Taiwan University', 'National Taiwan University', 'National Taiwan University', 'National Taiwan University']","['ML: Reinforcement Learning Algorithms', 'ML: Lifelong and Continual Learning']","Ding, W., Jiang, S., Chen, H.-W., & Chen, M.-S. (2023). Incremental Reinforcement Learning with Dual-Adaptive ε-Greedy Exploration. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7387-7395. https://doi.org/10.1609/aaai.v37i6.25899","Abstract 					Reinforcement learning (RL) has achieved impressive performance in various domains. However, most RL frameworks oversimplify the problem by assuming a fixed-yet-known environment and often have difficulty being generalized to real-world scenarios. In this paper, we address a new challenge with a more realistic setting, Incremental Reinforcement Learning, where the search space of the Markov Decision Process continually expands. While previous methods usually suffer from the lack of efficiency in exploring the unseen transitions, especially with increasing search space, we present a new exploration framework named Dual-Adaptive ϵ-greedy Exploration (DAE) to address the challenge of Incremental RL. Specifically, DAE employs a Meta Policy and an Explorer to avoid redundant computation on those sufficiently learned samples. Furthermore, we release a testbed based on a synthetic environment and the Atari benchmark to validate the effectiveness of any exploration algorithms under Incremental RL. Experimental results demonstrate that the proposed framework can efficiently learn the unseen transitions in new environments, leading to notable performance improvement, i.e., an average of more than 80%, over eight baselines examined.","https://ojs.aaai.org/index.php/AAAI/article/view/25899/25671"
"25900","Provably Efficient Primal-Dual Reinforcement Learning for CMDPs with Non-stationary Objectives and Constraints","['Yuhao Ding', 'Javad Lavaei']","['University of California - Berkeley', 'University of California - Berkeley']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms']","Ding, Y., & Lavaei, J. (2023). Provably Efficient Primal-Dual Reinforcement Learning for CMDPs with Non-stationary Objectives and Constraints. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7396-7404. https://doi.org/10.1609/aaai.v37i6.25900","Abstract 					We consider primal-dual-based reinforcement learning (RL) in episodic constrained Markov decision processes (CMDPs) with non-stationary objectives and constraints, which plays a central role in ensuring the safety of RL in time-varying environments. In this problem, the reward/utility functions and the state transition functions are both allowed to vary arbitrarily over time as long as their cumulative variations do not exceed certain known variation budgets. Designing safe RL algorithms in time-varying environments is particularly challenging because of the need to integrate the constraint violation reduction, safe exploration, and adaptation to the non-stationarity. To this end, we identify two alternative conditions on the time-varying constraints under which we can guarantee the safety in the long run. We also propose the Periodically Restarted Optimistic Primal-Dual Proximal Policy Optimization (PROPD-PPO) algorithm that can coordinate with both two conditions. Furthermore, a dynamic regret bound and a constraint violation bound are established for the proposed algorithm in both the linear kernel CMDP function approximation setting and the tabular CMDP setting under two alternative conditions. This paper provides the first provably efficient algorithm for non-stationary CMDPs with safe exploration.","https://ojs.aaai.org/index.php/AAAI/article/view/25900/25672"
"25901","Non-stationary Risk-Sensitive Reinforcement Learning: Near-Optimal Dynamic Regret, Adaptive Detection, and Separation Design","['Yuhao Ding', 'Ming Jin', 'Javad Lavaei']","['University of California - Berkeley', 'Virginia Tech', 'UC Berkeley']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms']","Ding, Y., Jin, M., & Lavaei, J. (2023). Non-stationary Risk-Sensitive Reinforcement Learning: Near-Optimal Dynamic Regret, Adaptive Detection, and Separation Design. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7405-7413. https://doi.org/10.1609/aaai.v37i6.25901","Abstract 					We study risk-sensitive reinforcement learning (RL) based on an entropic risk measure in episodic non-stationary Markov decision processes (MDPs). Both the reward functions and the state transition kernels are unknown and allowed to vary arbitrarily over time with a budget on their cumulative variations. When this variation budget is known a prior, we propose two restart-based algorithms, namely Restart-RSMB and Restart-RSQ, and establish their dynamic regrets. Based on these results, we further present a meta-algorithm that does not require any prior knowledge of the variation budget and can adaptively detect the non-stationarity on the exponential value functions. A dynamic regret lower bound is then established for non-stationary risk-sensitive RL to certify the near-optimality of the proposed algorithms. Our results also show that the risk control and the handling of the non-stationarity can be separately designed in the algorithm if the variation budget is known a prior, while the non-stationary detection mechanism in the adaptive algorithm depends on the risk parameter. This work offers the first non-asymptotic theoretical analyses for the non-stationary risk-sensitive RL in the literature.","https://ojs.aaai.org/index.php/AAAI/article/view/25901/25673"
"25902","SKDBERT: Compressing BERT via Stochastic Knowledge Distillation","['Zixiang Ding', 'Guoqing Jiang', 'Shuai Zhang', 'Lin Guo', 'Wei Lin']","['Meituan', 'Meituan', 'Meituan', 'Meituan', 'Individual']","['ML: Learning on the Edge & Model Compression', 'CV: Learning & Optimization for CV', 'CV: Representation Learning for Vision', 'SNLP: Language Models', 'SNLP: Learning & Optimization for SNLP', 'SNLP: Text Classification']","Ding, Z., Jiang, G., Zhang, S., Guo, L., & Lin, W. (2023). SKDBERT: Compressing BERT via Stochastic Knowledge Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7414-7422. https://doi.org/10.1609/aaai.v37i6.25902","Abstract 					In this paper, we propose Stochastic Knowledge Distillation (SKD) to obtain compact BERT-style language model dubbed SKDBERT. In each distillation iteration, SKD samples a teacher model from a pre-defined teacher team, which consists of multiple teacher models with multi-level capacities, to transfer knowledge into student model in an one-to-one manner. Sampling distribution plays an important role in SKD. We heuristically present three types of sampling distributions to assign appropriate probabilities for multi-level teacher models. SKD has two advantages: 1) it can preserve the diversities of multi-level teacher models via stochastically sampling single teacher model in each distillation iteration, and 2) it can also improve the efficacy of knowledge distillation via multi-level teacher models when large capacity gap exists between the teacher model and the student model. Experimental results on GLUE benchmark show that SKDBERT reduces the size of a BERT model by 40% while retaining 99.5% performances of language understanding and being 100% faster.","https://ojs.aaai.org/index.php/AAAI/article/view/25902/25674"
"25903","Model-Based Offline Reinforcement Learning with Local Misspecification","['Kefan Dong', 'Yannis Flet-Berliac', 'Allen Nie', 'Emma Brunskill']","['Stanford University', 'Stanford University', 'Stanford University', 'Stanford University']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms']","Dong, K., Flet-Berliac, Y., Nie, A., & Brunskill, E. (2023). Model-Based Offline Reinforcement Learning with Local Misspecification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7423-7431. https://doi.org/10.1609/aaai.v37i6.25903","Abstract 					We present a model-based offline reinforcement learning policy performance lower bound that explicitly captures dynamics model misspecification and distribution mismatch and we propose an empirical algorithm for optimal offline policy selection. Theoretically, we prove a novel safe policy improvement theorem by establishing pessimism approximations to the value function. Our key insight is to jointly consider selecting over dynamics models and policies: as long as a dynamics model can accurately represent the dynamics of the state-action pairs visited by a given policy, it is possible to approximate the value of that particular policy. We analyze our lower bound in the LQR setting and also show competitive performance to previous lower bounds on policy selection across a set of D4RL tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25903/25675"
"25904","Can Label-Specific Features Help Partial-Label Learning?","['Ruo-Jing Dong', 'Jun-Yi Hang', 'Tong Wei', 'Min-Ling Zhang']","['Southeast University', 'Southeast University', 'Southeast University', 'Southeast University']","['ML: Semi-Supervised Learning', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Multi-Instance/Multi-View Learning']","Dong, R.-J., Hang, J.-Y., Wei, T., & Zhang, M.-L. (2023). Can Label-Specific Features Help Partial-Label Learning?. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7432-7440. https://doi.org/10.1609/aaai.v37i6.25904","Abstract 					Partial label learning (PLL) aims to learn from inexact data annotations where each training example is associated with a coarse candidate label set. Due to its practicability, many PLL algorithms have been proposed in recent literature. Most prior PLL works attempt to identify the ground-truth labels from candidate sets and the classifier is trained afterward by fitting the features of examples and their exact ground-truth labels. From a different perspective, we propose to enrich the feature space and raise the question ``Can label-specific features help PLL?'' rather than learning from examples with identical features for all classes. Despite its benefits, previous label-specific feature approaches rely on ground-truth labels to split positive and negative examples of each class and then conduct clustering analysis, which is not directly applicable in PLL. To remedy this problem, we propose an uncertainty-aware confidence region to accommodate false positive labels. We first employ graph-based label enhancement to yield smooth pseudo-labels and facilitate the confidence region split. After acquiring label-specific features, a family of binary classifiers is induced. Extensive experiments on both synthesized and real-world datasets are conducted and the results show that our method consistently outperforms eight baselines. Our code is released at https://github.com/meteoseeker/UCL","https://ojs.aaai.org/index.php/AAAI/article/view/25904/25676"
"25905","Interpreting Unfairness in Graph Neural Networks via Training Node Attribution","['Yushun Dong', 'Song Wang', 'Jing Ma', 'Ninghao Liu', 'Jundong Li']","['University of Virginia', 'University of Virginia', 'University of Virginia', 'University of Georgia', 'University of Virginia']","['ML: Graph-based Machine Learning', 'PEAI: Bias', 'Fairness & Equity']","Dong, Y., Wang, S., Ma, J., Liu, N., & Li, J. (2023). Interpreting Unfairness in Graph Neural Networks via Training Node Attribution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7441-7449. https://doi.org/10.1609/aaai.v37i6.25905","Abstract 					Graph Neural Networks (GNNs) have emerged as the leading paradigm for solving graph analytical problems in various real-world applications. Nevertheless, GNNs could potentially render biased predictions towards certain demographic subgroups.  Understanding how the bias in predictions arises is critical, as it guides the design of GNN debiasing mechanisms. However, most existing works overwhelmingly focus on GNN debiasing, but fall short on explaining how such bias is induced. In this paper, we study a novel problem of interpreting GNN unfairness through attributing it to the influence of training nodes. Specifically, we propose a novel strategy named Probabilistic Distribution Disparity (PDD) to measure the bias exhibited in GNNs, and develop an algorithm to efficiently estimate the influence of each training node on such bias. We verify the validity of PDD and the effectiveness of influence estimation through experiments on real-world datasets. Finally, we also demonstrate how the proposed framework could be used for debiasing GNNs. Open-source code can be found at https://github.com/yushundong/BIND.","https://ojs.aaai.org/index.php/AAAI/article/view/25905/25677"
"25906","Robust and Fast Measure of Information via Low-Rank Representation","['Yuxin Dong', 'Tieliang Gong', 'Shujian Yu', 'Hong Chen', 'Chen Li']","[""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", 'Vrije Universiteit Amsterdam', 'Huazhong Agricultural University', ""Xi'an Jiaotong University""]","['ML: Probabilistic Methods', 'ML: Dimensionality Reduction/Feature Selection', 'ML: Kernel Methods']","Dong, Y., Gong, T., Yu, S., Chen, H., & Li, C. (2023). Robust and Fast Measure of Information via Low-Rank Representation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7450-7458. https://doi.org/10.1609/aaai.v37i6.25906","Abstract 					The matrix-based Rényi's entropy allows us to directly quantify information measures from given data, without explicit estimation of the underlying probability distribution. This intriguing property makes it widely applied in statistical inference and machine learning tasks. However, this information theoretical quantity is not robust against noise in the data, and is computationally prohibitive in large-scale applications. To address these issues, we propose a novel measure of information, termed low-rank matrix-based Rényi's entropy, based on low-rank representations of infinitely divisible kernel matrices. The proposed entropy functional inherits the specialty of of the original definition to directly quantify information from data, but enjoys additional advantages including robustness and effective calculation. Specifically, our low-rank variant is more sensitive to informative perturbations induced by changes in underlying distributions, while being insensitive to uninformative ones caused by noises. Moreover, low-rank Rényi's entropy can be efficiently approximated by random projection and Lanczos iteration techniques, reducing the overall complexity from O(n³) to O(n²s) or even O(ns²), where n is the number of data samples and s ≪ n. We conduct large-scale experiments to evaluate the effectiveness of this new information measure, demonstrating superior results compared to matrix-based Rényi's entropy in terms of both performance and computational efficiency.","https://ojs.aaai.org/index.php/AAAI/article/view/25906/25678"
"25907","Graph Anomaly Detection via Multi-Scale Contrastive Learning Networks with Augmented View","['Jingcan Duan', 'Siwei Wang', 'Pei Zhang', 'En Zhu', 'Jingtao Hu', 'Hu Jin', 'Yue Liu', 'Zhibin Dong']","['National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology']","['ML: Multi-Instance/Multi-View Learning', 'ML: Graph-based Machine Learning']","Duan, J., Wang, S., Zhang, P., Zhu, E., Hu, J., Jin, H., Liu, Y., & Dong, Z. (2023). Graph Anomaly Detection via Multi-Scale Contrastive Learning Networks with Augmented View. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7459-7467. https://doi.org/10.1609/aaai.v37i6.25907","Abstract 					Graph anomaly detection (GAD) is a vital task in graph-based machine learning and has been widely applied in many real-world applications. The primary goal of GAD is to capture anomalous nodes from graph datasets, which evidently deviate from the majority of nodes. Recent methods have paid attention to various scales of contrastive strategies for GAD, i.e., node-subgraph and node-node contrasts. However, they neglect the subgraph-subgraph comparison information which the normal and abnormal subgraph pairs behave differently in terms of embeddings and structures in GAD, resulting in sub-optimal task performance. In this paper, we fulfill the above idea in the proposed multi-view multi-scale contrastive learning framework with subgraph-subgraph contrast for the first practice. To be specific, we regard the original input graph as the first view and generate the second view by graph augmentation with edge modifications. With the guidance of maximizing the similarity of the subgraph pairs, the proposed subgraph-subgraph contrast contributes to more robust subgraph embeddings despite of the structure variation. Moreover, the introduced subgraph-subgraph contrast cooperates well with the widely-adopted node-subgraph and node-node contrastive counterparts for mutual GAD performance promotions. Besides, we also conduct sufficient experiments to investigate the impact of different graph augmentation approaches on detection performance. The comprehensive experimental results well demonstrate the superiority of our method compared with the state-of-the-art approaches and the effectiveness of the multi-view subgraph pair contrastive strategy for the GAD task. The source code is released at https://github.com/FelixDJC/GRADATE.","https://ojs.aaai.org/index.php/AAAI/article/view/25907/25679"
"25908","Diffeomorphic Information Neural Estimation","['Bao Duong', 'Thin Nguyen']","['Deakin University', 'Deakin University']","['ML: Applications', 'ML: Deep Generative Models & Autoencoders', 'ML: Other Foundations of Machine Learning']","Duong, B., & Nguyen, T. (2023). Diffeomorphic Information Neural Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7468-7475. https://doi.org/10.1609/aaai.v37i6.25908","Abstract 					Mutual Information (MI) and Conditional Mutual Information (CMI) are multi-purpose tools from information theory that are able to naturally measure the statistical dependencies between random variables, thus they are usually of central interest in several statistical and machine learning tasks, such as conditional independence testing and representation learning. However, estimating CMI, or even MI, is infamously challenging due the intractable formulation. In this study, we introduce DINE (Diffeomorphic Information Neural Estimator)–a novel approach for estimating CMI of continuous random variables, inspired by the invariance of CMI over diffeomorphic maps. We show that the variables of interest can be replaced with appropriate surrogates that follow simpler distributions, allowing the CMI to be efficiently evaluated via analytical solutions. Additionally, we demonstrate the quality of the proposed estimator in comparison with state-of-the-arts in three important tasks, including estimating MI, CMI, as well as its application in conditional independence testing. The empirical evaluations show that DINE consistently outperforms competitors in all tasks and is able to adapt very well to complex and high-dimensional relationships.","https://ojs.aaai.org/index.php/AAAI/article/view/25908/25680"
"25909","Combining Slow and Fast: Complementary Filtering for Dynamics Learning","['Katharina Ensinger', 'Sebastian Ziesche', 'Barbara Rakitsch', 'Michael Tiemann', 'Sebastian Trimpe']","['Bosch Center for Artificial Intelligence, Renningen, Germany\nInstitute for Data Science in Mechanical Engineering, RWTH Aachen University', 'Bosch Center for Artificial Intelligence, Renningen, Germany', 'Bosch Center for Artificial Intelligence, Renningen, Germany', 'Bosch Center for Artificial Intelligence, Renningen, Germany', 'Institute for Data Science in Mechanical Engineering, RWTH Aachen University']","['ML: Time-Series/Data Streams']","Ensinger, K., Ziesche, S., Rakitsch, B., Tiemann, M., & Trimpe, S. (2023). Combining Slow and Fast: Complementary Filtering for Dynamics Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7476-7484. https://doi.org/10.1609/aaai.v37i6.25909","Abstract 					Modeling an unknown dynamical system is crucial in order to predict the future behavior of the system. A standard approach is training recurrent models on measurement data. While these models typically provide exact short-term predictions, accumulating errors yield deteriorated long-term behavior. In contrast, models with reliable long-term predictions can often be obtained, either by training a robust but less detailed model, or by leveraging physics-based simulations. In both cases, inaccuracies in the models yield a lack of short-time details. Thus, different models with contrastive properties on different time horizons are available. This observation immediately raises the question: Can we obtain predictions that combine the best of both worlds? Inspired by sensor fusion tasks, we interpret the problem in the frequency domain and leverage classical methods from signal processing, in particular complementary filters. This filtering technique combines two signals by applying a high-pass filter to one signal, and low-pass filtering the other. Essentially, the high-pass filter extracts high-frequencies, whereas the low-pass filter extracts low frequencies. Applying this concept to dynamics model learning enables the construction of models that yield accurate long- and short-term predictions. Here, we propose two methods, one being purely learning-based and the other one being a hybrid model that requires an additional physics-based simulator.","https://ojs.aaai.org/index.php/AAAI/article/view/25909/25681"
"25910","Popularizing Fairness: Group Fairness and Individual Welfare","['Andrew Estornell', 'Sanmay Das', 'Brendan Juba', 'Yevgeniy Vorobeychik']","['Washington University in St Louis', 'George Mason University', 'Washington University in St Louis', 'Washington University in St. Louis']","['ML: Bias and Fairness']","Estornell, A., Das, S., Juba, B., & Vorobeychik, Y. (2023). Popularizing Fairness: Group Fairness and Individual Welfare. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7485-7493. https://doi.org/10.1609/aaai.v37i6.25910","Abstract 					Group-fair learning methods typically seek to ensure that some measure of prediction efficacy for (often historically) disadvantaged minority groups is comparable to that for the majority of the population. When a principal seeks to adopt a group-fair approach to replace another, the principal may face opposition from those who feel they may be harmed by the switch, and this, in turn, may deter adoption. We propose that a potential mitigation to this concern is to ensure that a group-fair model is also popular, in the sense that,  for a majority of the target population, it yields a preferred distribution over outcomes compared with the conventional model. In this paper, we show that state of the art fair learning approaches are often  unpopular in this sense. We propose several efficient algorithms for postprocessing an existing group-fair learning scheme to improve its popularity while retaining fairness. Through extensive experiments, we demonstrate that the proposed postprocessing approaches are highly effective in practice.","https://ojs.aaai.org/index.php/AAAI/article/view/25910/25682"
"25911","FairFed: Enabling Group Fairness in Federated Learning","['Yahya H. Ezzeldin', 'Shen Yan', 'Chaoyang He', 'Emilio Ferrara', 'A. Salman Avestimehr']","['University of Southern California', 'University of Southern California', 'University of Southern California', 'University of Southern California', 'University of Southern California']","['ML: Distributed Machine Learning & Federated Learning', 'ML: Bias and Fairness', 'PEAI: Bias', 'Fairness & Equity']","Ezzeldin, Y. H., Yan, S., He, C., Ferrara, E., & Avestimehr, A. S. (2023). FairFed: Enabling Group Fairness in Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7494-7502. https://doi.org/10.1609/aaai.v37i6.25911","Abstract 					Training ML models which are fair across different demographic groups is of critical importance due to the increased integration of ML in crucial decision-making scenarios such as healthcare and recruitment. Federated learning has been viewed as a promising solution for collaboratively training machine learning models among multiple parties while maintaining their local data privacy. However, federated learning also poses new challenges in mitigating the potential bias against certain populations (e.g., demographic groups), as this typically requires centralized access to the sensitive information (e.g., race, gender) of each datapoint. Motivated by the importance and challenges of group fairness in federated learning, in this work, we propose FairFed, a novel algorithm for fairness-aware aggregation to enhance group fairness in federated learning. Our proposed approach is server-side and agnostic to the applied local debiasing thus allowing for flexible use of different local debiasing methods across clients. We evaluate FairFed empirically versus common baselines for fair ML and federated learning and demonstrate that it provides fairer models, particularly under highly heterogeneous data distributions across clients. We also demonstrate the benefits of FairFed in scenarios involving naturally distributed real-life data collected from different geographical locations or departments within an organization.","https://ojs.aaai.org/index.php/AAAI/article/view/25911/25683"
"25912","Goal-Conditioned Generators of Deep Policies","['Francesco Faccio', 'Vincent Herrmann', 'Aditya Ramesh', 'Louis Kirsch', 'Jürgen Schmidhuber']","['The Swiss AI Lab IDSIA\nAI Initiative, KAUST', 'The Swiss AI Lab IDSIA', 'The Swiss AI Lab IDSIA', 'The Swiss AI Lab IDSIA', 'The Swiss AI Lab IDSIA\nAI Initiative, KAUST\nNNAISENSE, Lugano, Switzerland']","['ML: Reinforcement Learning Algorithms', 'ROB: Behavior Learning & Control', 'ROB: Learning & Optimization for ROB']","Faccio, F., Herrmann, V., Ramesh, A., Kirsch, L., & Schmidhuber, J. (2023). Goal-Conditioned Generators of Deep Policies. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7503-7511. https://doi.org/10.1609/aaai.v37i6.25912","Abstract 					Goal-conditioned Reinforcement Learning (RL) aims at learning optimal policies, given goals encoded in special command inputs. Here we study goal-conditioned neural nets (NNs) that learn to generate deep NN policies in form of context-specific weight matrices, similar to Fast Weight Programmers and other methods from the 1990s. Using context commands of the form ``generate a policy that achieves a desired expected return,'' our NN generators combine powerful exploration of parameter space with generalization across commands to iteratively find better and better policies. A form of weight-sharing HyperNetworks and policy embeddings scales our method to generate deep NNs. Experiments show how a single learned policy generator can produce policies that achieve any return seen during training. Finally, we evaluate our algorithm on a set of continuous control tasks where it exhibits competitive performance. Our code is public.","https://ojs.aaai.org/index.php/AAAI/article/view/25912/25684"
"25913","Directed Acyclic Graph Structure Learning from Dynamic Graphs","['Shaohua Fan', 'Shuyang Zhang', 'Xiao Wang', 'Chuan Shi']","['Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Causal Learning']","Fan, S., Zhang, S., Wang, X., & Shi, C. (2023). Directed Acyclic Graph Structure Learning from Dynamic Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7512-7521. https://doi.org/10.1609/aaai.v37i6.25913","Abstract 					Estimating the structure of directed acyclic graphs (DAGs) of features (variables) plays a vital role in revealing the latent data generation process and providing causal insights in various applications. Although there have been many studies on structure learning with various types of data, the structure learning on the dynamic graph has not been explored yet, and thus we study the learning problem of node feature generation mechanism on such ubiquitous dynamic graph data. In a dynamic graph, we propose to simultaneously estimate contemporaneous relationships and time-lagged interaction relationships between the node features. These two kinds of relationships form a DAG, which could effectively characterize the feature generation process in a concise way. To learn such a DAG, we cast the learning problem as a continuous score-based optimization problem, which consists of a differentiable score function to measure the validity of the learned DAGs and a smooth acyclicity constraint to ensure the acyclicity of the learned DAGs. These two components are translated into an unconstraint augmented Lagrangian objective which could be minimized by mature continuous optimization techniques. The resulting algorithm, named GraphNOTEARS, outperforms baselines on simulated data across a wide range of settings that may encounter in real-world applications. We also apply the proposed approach on two dynamic graphs constructed from the real-world Yelp dataset, demonstrating our method could learn the connections between node features, which conforms with the domain knowledge.","https://ojs.aaai.org/index.php/AAAI/article/view/25913/25685"
"25914","Dish-TS: A General Paradigm for Alleviating Distribution Shift in Time Series Forecasting","['Wei Fan', 'Pengyang Wang', 'Dongkun Wang', 'Dongjie Wang', 'Yuanchun Zhou', 'Yanjie Fu']","['University of Central Florida', 'State Key Laboratory of Internet of Things for Smart City, University of Macau', 'State Key Laboratory of Internet of Things for Smart City, University of Macau', 'University of Central Florida', 'Computer Network Information Center, Chinese Academy of Sciences', 'University of Central Florida']","['ML: Time-Series/Data Streams', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data']","Fan, W., Wang, P., Wang, D., Wang, D., Zhou, Y., & Fu, Y. (2023). Dish-TS: A General Paradigm for Alleviating Distribution Shift in Time Series Forecasting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7522-7529. https://doi.org/10.1609/aaai.v37i6.25914","Abstract 					The distribution shift in Time Series Forecasting (TSF), indicating series distribution changes over time, largely hinders the performance of TSF models. Existing works towards distribution shift in time series are mostly limited in the quantification of distribution and, more importantly, overlook the potential shift between lookback and horizon windows. To address above challenges, we systematically summarize the distribution shift in TSF into two categories. Regarding lookback windows as input-space and horizon windows as output-space, there exist (i) intra-space shift, that the distribution within the input-space keeps shifted over time, and (ii) inter-space shift, that the distribution is shifted between input-space and output-space. Then we introduce, Dish-TS, a general neural paradigm for alleviating distribution shift in TSF. Specifically, for better distribution estimation, we propose the coefficient net (Conet), which can be any neural architectures, to map input sequences into learnable distribution coefficients. To relieve intra-space and inter-space shift, we organize Dish-TS as a Dual-Conet framework to separately learn the distribution of input- and output-space, which naturally captures the distribution difference of two spaces. In addition, we introduce a more effective training strategy for intractable Conet learning. Finally, we conduct extensive experiments on several datasets coupled with different state-of-the-art forecasting models. Experimental results show Dish-TS consistently boosts them with a more than 20% average improvement. Code is available at https://github.com/weifantt/Dish-TS.","https://ojs.aaai.org/index.php/AAAI/article/view/25914/25686"
"25915","Learning Decomposed Spatial Relations for Multi-Variate Time-Series Modeling","['Yuchen Fang', 'Kan Ren', 'Caihua Shan', 'Yifei Shen', 'You Li', 'Weinan Zhang', 'Yong Yu', 'Dongsheng Li']","['Shanghai Jiao Tong University', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Central South University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Microsoft Research Asia']","['ML: Time-Series/Data Streams', 'ML: Deep Neural Architectures', 'ML: Graph-based Machine Learning']","Fang, Y., Ren, K., Shan, C., Shen, Y., Li, Y., Zhang, W., Yu, Y., & Li, D. (2023). Learning Decomposed Spatial Relations for Multi-Variate Time-Series Modeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7530-7538. https://doi.org/10.1609/aaai.v37i6.25915","Abstract 					Modeling multi-variate time-series (MVTS) data is a long-standing research subject and has found wide applications. Recently, there is a surge of interest in modeling spatial relations between variables as graphs, i.e., first learning one static graph for each dataset and then exploiting the graph structure via graph neural networks. However, as spatial relations may differ substantially across samples, building one static graph for all the samples inherently limits flexibility and severely degrades the performance in practice. To address this issue, we propose a framework for fine-grained modeling and utilization of spatial correlation between variables. By analyzing the statistical properties of real-world datasets, a universal decomposition of spatial correlation graphs is first identified. Specifically, the hidden spatial relations can be decomposed into a prior part, which applies across all the samples, and a dynamic part, which varies between samples, and building different graphs is necessary to model these relations. To better coordinate the learning of the two relational graphs, we propose a min-max learning paradigm that not only regulates the common part of different dynamic graphs but also guarantees spatial distinguishability among samples. The experimental results show that our proposed model outperforms the state-of-the-art baseline methods on both time-series forecasting and time-series point prediction tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25915/25687"
"25916","Wasserstein Graph Distance Based on L1–Approximated Tree Edit Distance between Weisfeiler–Lehman Subtrees","['Zhongxi Fang', 'Jianming Huang', 'Xun Su', 'Hiroyuki Kasai']","['WASEDA University', 'WASEDA University', 'WASEDA University', 'WASEDA University']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Fang, Z., Huang, J., Su, X., & Kasai, H. (2023). Wasserstein Graph Distance Based on L1–Approximated Tree Edit Distance between Weisfeiler–Lehman Subtrees. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7539-7549. https://doi.org/10.1609/aaai.v37i6.25916","Abstract 					The Weisfeiler-Lehman (WL) test is a widely used algorithm in graph machine learning, including graph kernels, graph metrics, and graph neural networks. However, it focuses only on the consistency of the graph, which means that it is unable to detect slight structural differences. Consequently, this limits its ability to capture structural information, which also limits the performance of existing models that rely on the WL test. This limitation is particularly severe for traditional metrics defined by the WL test, which cannot precisely capture slight structural differences. In this paper, we propose a novel graph metric called the Wasserstein WL Subtree (WWLS) distance to address this problem. Our approach leverages the WL subtree as structural information for node neighborhoods and defines node metrics using the L1-approximated tree edit distance (L1-TED) between WL subtrees of nodes. Subsequently, we combine the Wasserstein distance and the L1-TED to define the WWLS distance, which can capture slight structural differences that may be difficult to detect using conventional metrics. We demonstrate that the proposed WWLS distance outperforms baselines in both metric validation and graph classification experiments.","https://ojs.aaai.org/index.php/AAAI/article/view/25916/25688"
"25917","Combinatorial Causal Bandits","['Shi Feng', 'Wei Chen']","['Tsinghua University, Beijing, China', 'Microsoft Research, Beijing, China']","['ML: Online Learning & Bandits', 'RU: Causality']","Feng, S., & Chen, W. (2023). Combinatorial Causal Bandits. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7550-7558. https://doi.org/10.1609/aaai.v37i6.25917","Abstract 					In combinatorial causal bandits (CCB), the learning agent chooses at most K variables in each round to intervene, collects feedback from the observed variables, with the goal of minimizing expected regret on the target variable Y. We study under the context of binary generalized linear models (BGLMs) with a succinct parametric representation of the causal models. We present the algorithm BGLM-OFU for Markovian BGLMs (i.e., no hidden variables) based on the maximum likelihood estimation method and give regret analysis for it. For the special case of linear models with hidden variables, we apply causal inference techniques such as the do calculus to convert the original model into a Markovian model, and then show that our BGLM-OFU algorithm and another algorithm based on the linear regression both solve such linear models with hidden variables. Our novelty includes (a) considering the combinatorial intervention action space and the general causal graph structures including ones with hidden variables, (b) integrating and adapting techniques from diverse studies such as generalized linear bandits and online influence maximization, and (c) avoiding unrealistic assumptions (such as knowing the joint distribution of the parents of Y under all interventions) and regret factors exponential to causal graph size in prior studies.","https://ojs.aaai.org/index.php/AAAI/article/view/25917/25689"
"25918","Scalable Attributed-Graph Subspace Clustering","['Chakib Fettal', 'Lazhar Labiod', 'Mohamed Nadif']","['Centre Borelli UMR 9010, Université Paris-Cité\nInformatique Caisse des Dépôts et Consignations', 'Centre Borelli UMR 9010, Université Paris-Cité', 'Centre Borelli UMR 9010, Université Paris-Cité']","['ML: Clustering', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Fettal, C., Labiod, L., & Nadif, M. (2023). Scalable Attributed-Graph Subspace Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7559-7567. https://doi.org/10.1609/aaai.v37i6.25918","Abstract 					Over recent years, graph convolutional networks emerged as powerful node clustering methods and have set state of the art results for this task. In this paper, we argue that some of these methods are unnecessarily complex and propose a node clustering model that is more scalable while being more effective. The proposed model uses Laplacian smoothing to learn an initial representation of the graph before applying an efficient self-expressive subspace clustering procedure. This is performed via learning a factored coefficient matrix. These factors are then embedded into a new feature space in such a way as to generate a valid affinity matrix (symmetric and non-negative) on which an implicit spectral clustering algorithm is performed.  Experiments on several real-world attributed datasets demonstrate the cost-effective nature of our method with respect to the state of the art.","https://ojs.aaai.org/index.php/AAAI/article/view/25918/25690"
"25919","SigMaNet: One Laplacian to Rule Them All","['Stefano Fiorini', 'Stefano Coniglio', 'Michele Ciavotta', 'Enza Messina']","['University of Milano-Bicocca, Milan, Italy', 'University of Bergamo, Bergamo, Italy', 'University of Milano-Bicocca, Milan, Italy', 'University of Milano-Bicocca, Milan, Italy']","['ML: Graph-based Machine Learning', 'ML: Deep Neural Architectures', 'ML: Matrix & Tensor Methods']","Fiorini, S., Coniglio, S., Ciavotta, M., & Messina, E. (2023). SigMaNet: One Laplacian to Rule Them All. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7568-7576. https://doi.org/10.1609/aaai.v37i6.25919","Abstract 					This paper introduces SigMaNet, a generalized Graph Convolutional Network (GCN) capable of handling both undirected and directed graphs with weights not restricted in sign nor magnitude. The cornerstone of SigMaNet is the Sign-Magnetic Laplacian (LSM), a new Laplacian matrix that we introduce ex novo in this work. LSM allows us to bridge a gap in the current literature by extending the theory of spectral GCNs to (directed) graphs with both positive and negative weights. LSM exhibits several desirable properties not enjoyed by other Laplacian matrices on which several state-of-the-art architectures are based, among which encoding the edge direction and weight in a clear and natural way that is not negatively affected by the weight magnitude. LSM is also completely parameter-free, which is not the case of other Laplacian operators such as, e.g., the Magnetic Laplacian. The versatility and the performance of our proposed approach is amply demonstrated via computational experiments. Indeed, our results show that, for at least a metric, SigMaNet achieves the best performance in 15 out of 21 cases and either the first- or second-best performance in 21 cases out of 21, even when compared to architectures that are either more complex or that, due to being designed for a narrower class of graphs, should---but do not---achieve a better performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25919/25691"
"25920","Optimal Decision Diagrams for Classification","['Alexandre M. Florio', 'Pedro Martins', 'Maximilian Schiffer', 'Thiago Serra', 'Thibaut Vidal']","['CIRRELT & SCALE-AI Chair in Data-Driven Supply Chains\nDepartment of Mathematical and Industrial Engineering, Polytechnique Montreal, Canada', 'Department of Computer Science, Pontifical Catholic University of Rio de Janeiro, Brazil', 'School of Management & Munich Data Science Institute, Technical University of Munich, Germany', 'Freeman College of Management, Bucknell University, USA', 'CIRRELT & SCALE-AI Chair in Data-Driven Supply Chains\nDepartment of Mathematical and Industrial Engineering, Polytechnique Montreal, Canada']","['ML: Classification and Regression', 'SO: Mixed Discrete/Continuous Search', 'SO: Applications']","Florio, A. M., Martins, P., Schiffer, M., Serra, T., & Vidal, T. (2023). Optimal Decision Diagrams for Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7577-7585. https://doi.org/10.1609/aaai.v37i6.25920","Abstract 					Decision diagrams for classification have some notable advantages over decision trees, as their internal connections can be determined at training time and their width is not bound to grow exponentially with their depth. Accordingly, decision diagrams are usually less prone to data fragmentation in internal nodes. However, the inherent complexity of training these classifiers acted as a long-standing barrier to their widespread adoption. In this context, we study the training of optimal decision diagrams (ODDs) from a mathematical programming perspective. We introduce a novel mixed-integer linear programming model for training and demonstrate its applicability for many datasets of practical importance. Further, we show how this model can be easily extended for fairness, parsimony, and stability notions. We present numerical analyses showing that our model allows training ODDs in short computational times, and that ODDs achieve better accuracy than optimal decision trees, while allowing for improved stability without significant accuracy losses.","https://ojs.aaai.org/index.php/AAAI/article/view/25920/25692"
"25921","Estimating Average Causal Effects from Patient Trajectories","['Dennis Frauen', 'Tobias Hatt', 'Valentyn Melnychuk', 'Stefan Feuerriegel']","['LMU Munich\nMunich Center for Machine Learning', 'ETH Zurich', 'LMU Munich\nMunich Center for Machine Learning', 'LMU Munich\nMunich Center for Machine Learning']","['ML: Causal Learning', 'APP: Healthcare', 'Medicine & Wellness', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms', 'ML: Time-Series/Data Streams', 'RU: Causality']","Frauen, D., Hatt, T., Melnychuk, V., & Feuerriegel, S. (2023). Estimating Average Causal Effects from Patient Trajectories. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7586-7594. https://doi.org/10.1609/aaai.v37i6.25921","Abstract 					In medical practice, treatments are selected based on the expected causal effects on patient outcomes. Here, the gold standard for estimating causal effects are randomized controlled trials; however, such trials are costly and sometimes even unethical. Instead, medical practice is increasingly interested in estimating causal effects among patient (sub)groups from electronic health records, that is, observational data. In this paper, we aim at estimating the average causal effect (ACE) from observational data (patient trajectories) that are collected over time. For this, we propose DeepACE: an end-to-end deep learning model. DeepACE leverages the iterative G-computation formula to adjust for the bias induced by time-varying confounders. Moreover, we develop a novel sequential targeting procedure which ensures that DeepACE has favorable theoretical properties, i.e., is doubly robust and asymptotically efficient. To the best of our knowledge, this is the first work that proposes an end-to-end deep learning model tailored for estimating time-varying ACEs. We compare DeepACE in an extensive number of experiments, confirming that it achieves state-of-the-art performance. We further provide a case study for patients suffering from low back pain to demonstrate that DeepACE generates important and meaningful findings for clinical practice. Our work enables practitioners to develop effective treatment recommendations based on population effects.","https://ojs.aaai.org/index.php/AAAI/article/view/25921/25693"
"25922","Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation","['Yulu Gan', 'Yan Bai', 'Yihang Lou', 'Xianzheng Ma', 'Renrui Zhang', 'Nian Shi', 'Lin Luo']","['Peking University', 'Peking University', 'Huawei Technology', 'Wuhan University', 'Peking University', 'Aerospace Information Research Institute, Chinese Academy of Sciences', 'Peking University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'CV: Low Level & Physics-Based Vision', 'ML: Lifelong and Continual Learning', 'ML: Unsupervised & Self-Supervised Learning']","Gan, Y., Bai, Y., Lou, Y., Ma, X., Zhang, R., Shi, N., & Luo, L. (2023). Decorate the Newcomers: Visual Domain Prompt for Continual Test Time Adaptation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7595-7603. https://doi.org/10.1609/aaai.v37i6.25922","Abstract 					Continual Test-Time Adaptation (CTTA) aims to adapt the source model to continually changing unlabeled target domains without access to the source data. Existing methods mainly focus on model-based adaptation in a self-training manner, such as predicting pseudo labels for new domain datasets. Since pseudo labels are noisy and unreliable, these methods suffer from catastrophic forgetting and error accumulation when dealing with dynamic data distributions. Motivated by the prompt learning in NLP, in this paper, we propose to learn an image-layer visual domain prompt for target domains while having the source model parameters frozen. During testing, the changing target datasets can be adapted to the source model by reformulating the input data with the learned visual prompts. Specifically, we devise two types of prompts, i.e., domains-specific prompts and domains-agnostic prompts, to extract current domain knowledge and maintain the domain-shared knowledge in the continual adaptation. Furthermore, we design a homeostasis-based adaptation strategy to suppress domain-sensitive parameters in domain-invariant prompts to learn domain-shared knowledge more effectively. This transition from the model-dependent paradigm to the model-free one enables us to bypass the catastrophic forgetting and error accumulation problems. Experiments show that our proposed method achieves significant performance gains over state-of-the-art methods on four widely-used benchmarks, including CIFAR-10C, CIFAR-100C, ImageNet-C, and VLCS datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25922/25694"
"25923","EffConv: Efficient Learning of Kernel Sizes for Convolution Layers of CNNs","['Alireza Ganjdanesh', 'Shangqian Gao', 'Heng Huang']","['University of Pittsburgh', 'University of Pittsburgh', 'University of Pittsburgh']","['ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms']","Ganjdanesh, A., Gao, S., & Huang, H. (2023). EffConv: Efficient Learning of Kernel Sizes for Convolution Layers of CNNs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7604-7612. https://doi.org/10.1609/aaai.v37i6.25923","Abstract 					Determining kernel sizes of a CNN model is a crucial and non-trivial design choice and significantly impacts its performance. The majority of kernel size design methods rely on complex heuristic tricks or leverage neural architecture search that requires extreme computational resources. Thus, learning kernel sizes, using methods such as modeling kernels as a combination of basis functions, jointly with the model weights has been proposed as a workaround. However, previous methods cannot achieve satisfactory results or are inefficient for large-scale datasets. To fill this gap, we design a novel efficient kernel size learning method in which a size predictor model learns to predict optimal kernel sizes for a classifier given a desired number of parameters. It does so in collaboration with a kernel predictor model that predicts the weights of the kernels - given kernel sizes predicted by the size predictor - to minimize the training objective, and both models are trained end-to-end. Our method only needs a small fraction of the training epochs of the original CNN to train these two models and find proper kernel sizes for it. Thus, it offers an efficient and effective solution for the kernel size learning problem. Our extensive experiments on MNIST, CIFAR-10, STL-10, and ImageNet-32 demonstrate that our method can achieve the best training time vs. accuracy trade-off compared to previous kernel size learning methods and significantly outperform them on challenging datasets such as STL-10 and ImageNet-32. Our implementations are available at https://github.com/Alii-Ganjj/EffConv.","https://ojs.aaai.org/index.php/AAAI/article/view/25923/25695"
"25924","Fast Counterfactual Inference for History-Based Reinforcement Learning","['Haichuan Gao', 'Tianren Zhang', 'Zhile Yang', 'Yuqing Guo', 'Jinsheng Ren', 'Shangqi Guo', 'Feng Chen']","['Tsinghua University', 'Tsinghua University', 'University of Leeds', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University']","['ML: Reinforcement Learning Algorithms']","Gao, H., Zhang, T., Yang, Z., Guo, Y., Ren, J., Guo, S., & Chen, F. (2023). Fast Counterfactual Inference for History-Based Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7613-7623. https://doi.org/10.1609/aaai.v37i6.25924","Abstract 					Incorporating sequence-to-sequence models into history-based Reinforcement Learning (RL) provides a general way to extend RL to partially-observable tasks. This method compresses history spaces according to the correlations between historical observations and the rewards. However, they do not adjust for the confounding correlations caused by data sampling and assign high beliefs to uninformative historical observations, leading to limited compression of history spaces. Counterfactual Inference (CI), which estimates causal effects by single-variable intervention, is a promising way to adjust for confounding. However, it is computationally infeasible to directly apply the single-variable intervention to a huge number of historical observations. This paper proposes to perform CI on observation sub-spaces instead of single observations and develop a coarse-to-fine CI algorithm, called Tree-based History Counterfactual Inference (T-HCI), to reduce the number of interventions exponentially. We show that T-HCI is computationally feasible in practice and brings significant sample efficiency gains in various challenging partially-observable tasks, including Maze, BabyAI, and robot manipulation tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25924/25696"
"25925","Robust Causal Graph Representation Learning against Confounding Effects","['Hang Gao', 'Jiangmeng Li', 'Wenwen Qiang', 'Lingyu Si', 'Bing Xu', 'Changwen Zheng', 'Fuchun Sun']","['Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'China Communications Technology Information Group Co., Ltd.', 'Science and Technology on Integrated Information System Laboratory, Institute of Software Chinese Academy of Sciences', 'Tsinghua University']","['ML: Representation Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Causal Learning', 'ML: Deep Learning Theory', 'ML: Graph-based Machine Learning', 'ML: Learning Theory']","Gao, H., Li, J., Qiang, W., Si, L., Xu, B., Zheng, C., & Sun, F. (2023). Robust Causal Graph Representation Learning against Confounding Effects. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7624-7632. https://doi.org/10.1609/aaai.v37i6.25925","Abstract 					The prevailing graph neural network models have achieved significant progress in graph representation learning. However, in this paper, we uncover an ever-overlooked phenomenon: the pre-trained graph representation learning model tested with full graphs underperforms the model tested with well-pruned graphs. This observation reveals that there exist confounders in graphs, which may interfere with the model learning semantic information, and current graph representation learning methods have not eliminated their influence. To tackle this issue, we propose Robust Causal Graph Representation Learning (RCGRL) to learn robust graph representations against confounding effects. RCGRL introduces an active approach to generate instrumental variables under unconditional moment restrictions, which empowers the graph representation learning model to eliminate confounders, thereby capturing discriminative information that is causally related to downstream predictions. We offer theorems and proofs to guarantee the theoretical effectiveness of the proposed approach. Empirically, we conduct extensive experiments on a synthetic dataset and multiple benchmark datasets. Experimental results demonstrate the effectiveness and generalization ability of RCGRL. Our codes are available at https://github.com/hang53/RCGRL.","https://ojs.aaai.org/index.php/AAAI/article/view/25925/25697"
"25926","Towards Decision-Friendly AUC: Learning Multi-Classifier with AUCµ","['Peifeng Gao', 'Qianqian Xu', 'Peisong Wen', 'Huiyang Shao', 'Yuan He', 'Qingming Huang']","['School of Computer Science and Tech., University of Chinese Academy of Sciences', 'Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences', 'School of Computer Science and Tech., University of Chinese Academy of Sciences\nKey Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences', 'School of Computer Science and Tech., University of Chinese Academy of Sciences\nKey Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences', 'Alibaba Group', 'School of Computer Science and Tech., University of Chinese Academy of Sciences\nKey Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences\nBDKM, University of Chinese Academy of Sciences\nPeng Cheng Laboratory']","['ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Classification and Regression']","Gao, P., Xu, Q., Wen, P., Shao, H., He, Y., & Huang, Q. (2023). Towards Decision-Friendly AUC: Learning Multi-Classifier with AUCµ. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7633-7641. https://doi.org/10.1609/aaai.v37i6.25926","Abstract 					Area Under the ROC Curve (AUC) is a widely used ranking metric in imbalanced learning due to its insensitivity to label distributions. As a well-known multiclass extension of AUC, Multiclass AUC (MAUC, a.k.a. M-metric) measures the average AUC of multiple binary classifiers. In this paper, we argue that simply optimizing MAUC is far from enough for imbalanced multi-classification. More precisely, MAUC only focuses on learning scoring functions via ranking optimization, while leaving the decision process unconsidered. Therefore, scoring functions being able to make good decisions might suffer from low performance in terms of MAUC. To overcome this issue, we turn to explore AUCµ, another multiclass variant of AUC, which further takes the decision process into consideration. Motivated by this fact, we propose a surrogate risk optimization framework to improve model performance from the perspective of AUCµ. Practically, we propose a two-stage training framework for multi-classification, where at the first stage a scoring function is learned maximizing AUCµ, and at the second stage we seek for a decision function to improve the F1-metric via our proposed soft F1. Theoretically, we first provide sufficient conditions that optimizing the surrogate losses could lead to the Bayes optimal scoring function. Afterward, we show that the proposed surrogate risk enjoys a generalization bound in order of O(1/√N). Experimental results on four benchmark datasets demonstrate the effectiveness of our proposed method in both AUCµ and F1-metric.","https://ojs.aaai.org/index.php/AAAI/article/view/25926/25698"
"25927","Long-Tail Cross Modal Hashing","['Zijun Gao', 'Jun Wang', 'Guoxian Yu', 'Zhongmin Yan', 'Carlotta Domeniconi', 'Jinglin Zhang']","['Shandong University', 'Shandong University', 'Shandong University', 'Shandong University', 'George Mason University', 'Shandong University']","['ML: Multi-Instance/Multi-View Learning', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Multimodal Learning']","Gao, Z., Wang, J., Yu, G., Yan, Z., Domeniconi, C., & Zhang, J. (2023). Long-Tail Cross Modal Hashing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7642-7650. https://doi.org/10.1609/aaai.v37i6.25927","Abstract 					Existing Cross Modal Hashing (CMH) methods  are mainly designed for balanced data, while imbalanced data with long-tail distribution is more general in real-world. Several long-tail hashing methods have been proposed but they can not adapt for multi-modal data, due to the complex interplay between labels and individuality and commonality information of multi-modal data. Furthermore, CMH methods mostly mine the commonality of multi-modal data to learn hash codes, which may override tail labels encoded by the individuality of respective modalities. In this paper, we propose LtCMH (Long-tail CMH) to handle imbalanced multi-modal data. LtCMH firstly adopts auto-encoders to mine the individuality and commonality of different modalities by minimizing the dependency between the individuality of respective modalities and by enhancing the commonality of these modalities. Then it dynamically combines the individuality and commonality with direct features extracted from respective modalities to create meta features that enrich the representation of tail labels, and  binaries meta features to generate hash codes. LtCMH significantly outperforms state-of-the-art baselines on long-tail datasets and holds a better (or comparable) performance on datasets with balanced labels.","https://ojs.aaai.org/index.php/AAAI/article/view/25927/25699"
"25928","Handling Missing Data via Max-Entropy Regularized Graph Autoencoder","['Ziqi Gao', 'Yifan Niu', 'Jiashun Cheng', 'Jianheng Tang', 'Lanqing Li', 'Tingyang Xu', 'Peilin Zhao', 'Fugee Tsung', 'Jia Li']","['The Hong Kong University of Science and Technology', 'The Hong Kong University of Science and Technology (Guangzhou)', 'The Hong Kong University of Science and Technology', 'The Hong Kong University of Science and Technology', 'AI Lab, Tencent', 'AI Lab, Tencent', 'AI Lab, Tencent', 'The Hong Kong University of Science and Technology (Guangzhou)\nThe Hong Kong University of Science and Technology', 'The Hong Kong University of Science and Technology (Guangzhou)\nThe Hong Kong University of Science and Technology']","['ML: Graph-based Machine Learning']","Gao, Z., Niu, Y., Cheng, J., Tang, J., Li, L., Xu, T., Zhao, P., Tsung, F., & Li, J. (2023). Handling Missing Data via Max-Entropy Regularized Graph Autoencoder. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7651-7659. https://doi.org/10.1609/aaai.v37i6.25928","Abstract 					Graph neural networks (GNNs) are popular weapons for modeling relational data. Existing GNNs are not specified for attribute-incomplete graphs, making missing attribute imputation a burning issue. Until recently, many works notice that GNNs are coupled with spectral concentration, which means the spectrum obtained by GNNs concentrates on a local part in spectral domain, e.g., low-frequency due to oversmoothing issue. As a consequence, GNNs may be seriously flawed for reconstructing graph attributes as graph spectral concentration tends to cause a low imputation precision. In this work, we present a regularized graph autoencoder for graph attribute imputation, named MEGAE, which aims at mitigating spectral concentration problem by maximizing the graph spectral entropy. Notably, we first present the method for estimating graph spectral entropy without the eigen-decomposition of Laplacian matrix and provide the theoretical upper error bound. A maximum entropy regularization then acts in the latent space, which directly increases the graph spectral entropy. Extensive experiments show that MEGAE outperforms all the other state-of-the-art imputation methods on a variety of benchmark datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/25928/25700"
"25929","Reinforced Approximate Exploratory Data Analysis","['Shaddy Garg', 'Subrata Mitra', 'Tong Yu', 'Yash Gadhia', 'Arjun Kashettiwar']","['Adobe Research', 'Adobe Research', 'Adobe Research', 'IIT Bombay', 'IIT Bombay']","['ML: Applications', 'ML: Reinforcement Learning Algorithms', 'RU: Sequential Decision Making']","Garg, S., Mitra, S., Yu, T., Gadhia, Y., & Kashettiwar, A. (2023). Reinforced Approximate Exploratory Data Analysis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7660-7669. https://doi.org/10.1609/aaai.v37i6.25929","Abstract 					Exploratory data analytics (EDA) is a sequential decision making process where analysts choose subsequent queries that might lead to some interesting insights based on the previous queries and corresponding results. Data processing systems often execute the queries on samples to produce results with low latency. Different downsampling strategy preserves different statistics of the data and have different magnitude of latency reductions. The optimum choice of sampling strategy often depends on the particular context of the analysis flow and the hidden intent of the analyst. In this paper, we are the first to consider the impact of sampling in interactive data exploration settings as they introduce approximation errors. We propose a Deep Reinforcement Learning (DRL) based framework which can optimize the sample selection in order to keep the analysis and insight generation flow intact. Evaluations with real datasets show that our technique can preserve the original insight generation flow while improving the interaction latency, compared to baseline methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25929/25701"
"25930","Learning Program Synthesis for Integer Sequences from Scratch","['Thibault Gauthier', 'Josef Urban']","['Czech Technical University in Prague', 'Czech Technical University in Prague']","['ML: Unsupervised & Self-Supervised Learning', 'ML: Reinforcement Learning Algorithms', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'SNLP: Language Models']","Gauthier, T., & Urban, J. (2023). Learning Program Synthesis for Integer Sequences from Scratch. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7670-7677. https://doi.org/10.1609/aaai.v37i6.25930","Abstract 					We present a self-learning approach for synthesizing programs from integer sequences. Our method relies on a tree search guided by a learned policy.  Our system is tested on the On-Line Encyclopedia of Integer Sequences. There, it discovers, on its own, solutions for 27987 sequences starting from  basic operators and without human-written training examples.","https://ojs.aaai.org/index.php/AAAI/article/view/25930/25702"
"25931","Semi-transductive Learning for Generalized Zero-Shot Sketch-Based Image Retrieval","['Ce Ge', 'Jingyu Wang', 'Qi Qi', 'Haifeng Sun', 'Tong Xu', 'Jianxin Liao']","['Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications']","['ML: Semi-Supervised Learning', 'CV: Applications', 'CV: Image and Video Retrieval', 'CV: Multi-modal Vision', 'CV: Representation Learning for Vision', 'HAI: Human-Computer Interaction', 'ML: Active Learning', 'ML: Classification and Regression', 'ML: Learning Preferences or Rankings', 'ML: Multimodal Learning', 'ML: Unsupervised & Self-Supervised Learning']","Ge, C., Wang, J., Qi, Q., Sun, H., Xu, T., & Liao, J. (2023). Semi-transductive Learning for Generalized Zero-Shot Sketch-Based Image Retrieval. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7678-7686. https://doi.org/10.1609/aaai.v37i6.25931","Abstract 					Sketch-based image retrieval (SBIR) is an attractive research area where freehand sketches are used as queries to retrieve relevant images. Existing solutions have advanced the task to the challenging zero-shot setting (ZS-SBIR), where the trained models are tested on new classes without seen data. However, they are prone to overfitting under a realistic scenario when the test data includes both seen and unseen classes. In this paper, we study generalized ZS-SBIR (GZS-SBIR) and propose a novel semi-transductive learning paradigm. Transductive learning is performed on the image modality to explore the potential data distribution within unseen classes, and zero-shot learning is performed on the sketch modality sharing the learned knowledge through a semi-heterogeneous architecture. A hybrid metric learning strategy is proposed to establish semantics-aware ranking property and calibrate the joint embedding space. Extensive experiments are conducted on two large-scale benchmarks and four evaluation metrics. The results show that our method is superior over the state-of-the-art competitors in the challenging GZS-SBIR task.","https://ojs.aaai.org/index.php/AAAI/article/view/25931/25703"
"25932","Multi-Classifier Adversarial Optimization for Active Learning","['Lin Geng', 'Ningzhong Liu', 'Jie Qin']","['Nanjing University of Aeronautics and Astronautics', 'Nanjing University of Aeronautics and Astronautics', 'Nanjing University of Aeronautics and Astronautics']","['ML: Active Learning', 'CV: Object Detection & Categorization']","Geng, L., Liu, N., & Qin, J. (2023). Multi-Classifier Adversarial Optimization for Active Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7687-7695. https://doi.org/10.1609/aaai.v37i6.25932","Abstract 					Active learning (AL) aims to find a better trade-off between labeling costs and model performance by consciously selecting more informative samples to label. Recently, adversarial approaches have emerged as effective solutions. Most of them leverage generative adversarial networks to align feature distributions of labeled and unlabeled data, upon which discriminators are trained to better distinguish between them. However, these methods fail to consider the relationship between unlabeled samples and decision boundaries, and their training processes are often complex and unstable. To this end, this paper proposes a novel adversarial AL method, namely multi-classifier adversarial optimization for active learning (MAOAL). MAOAL employs task-specific decision boundaries for data alignment while selecting the most informative samples to label. To fulfill this, we introduce a novel classifier class confusion (C3) metric, which represents the classifier discrepancy as the inter-class correlation of classifier outputs. Without any additional hyper-parameters, the C3 metric further reduces the negative impacts of ambiguous samples in the process of distribution alignment and sample selection. More concretely, the network is trained adversarially by adding two auxiliary classifiers, reducing the distribution bias of labeled and unlabeled samples by minimizing the C3 loss between classifiers, while learning tighter decision boundaries and highlighting hard samples by maximizing the C3 loss. Finally, the unlabeled samples with the highest C3 loss are selected to label. Extensive experiments demonstrate the superiority of our approach over state-of-the-art AL methods in terms of image classification and object detection.","https://ojs.aaai.org/index.php/AAAI/article/view/25932/25704"
"25933","Differentially Private Heatmaps","['Badih Ghazi', 'Junfeng He', 'Kai Kohlhoff', 'Ravi Kumar', 'Pasin Manurangsi', 'Vidhya Navalpakkam', 'Nachiappan Valliappan']","['Google Research, Mountain View, CA', 'Google Research, Mountain View, CA', 'Google Research, Mountain View, CA', 'Google Research, Mountain View, CA', 'Google Research, Mountain View, CA', 'Google Research, Mountain View, CA', 'Google Research, Mountain View, CA']","['ML: Privacy-Aware ML', 'ML: Clustering']","Ghazi, B., He, J., Kohlhoff, K., Kumar, R., Manurangsi, P., Navalpakkam, V., & Valliappan, N. (2023). Differentially Private Heatmaps. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7696-7704. https://doi.org/10.1609/aaai.v37i6.25933","Abstract 					We consider the task of producing heatmaps from users' aggregated data while protecting their privacy. We give a differentially private (DP) algorithm for this task and demonstrate its advantages over previous algorithms on real-world datasets.  Our core algorithmic primitive is a DP procedure that takes in a set of distributions and produces an output that is close in Earth Mover's Distance (EMD) to the average of the inputs. We prove theoretical bounds on the error of our algorithm under a certain sparsity assumption and that these are essentially optimal.","https://ojs.aaai.org/index.php/AAAI/article/view/25933/25705"
"25934","DiFA: Differentiable Feature Acquisition","['Aritra Ghosh', 'Andrew Lan']","['University of Massachusetts Amherst', 'University of Massachusetts Amherst']","['ML: Dimensionality Reduction/Feature Selection', 'ML: Active Learning', 'ML: Classification and Regression', 'ML: Deep Neural Network Algorithms', 'ML: Other Foundations of Machine Learning']","Ghosh, A., & Lan, A. (2023). DiFA: Differentiable Feature Acquisition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7705-7713. https://doi.org/10.1609/aaai.v37i6.25934","Abstract 					Feature acquisition in predictive modeling is an important task in many practical applications. For example, in patient health prediction, we do not fully observe their personal features and need to dynamically select features to acquire. Our goal is to acquire a small subset of features that maximize prediction performance. Recently, some works reformulated feature acquisition as a Markov decision process and applied reinforcement learning (RL) algorithms, where the reward reflects both prediction performance and feature acquisition cost. However, RL algorithms only use zeroth-order information on the reward, which leads to slow empirical convergence, especially when there are many actions (number of features) to consider. For predictive modeling, it is possible to use first-order information on the reward, i.e., gradients, since we are often given an already collected dataset. Therefore, we propose differentiable feature acquisition (DiFA), which uses a differentiable representation of the feature selection policy to enable gradients to flow from the prediction loss to the policy parameters. We conduct extensive experiments on various real-world datasets and show that DiFA significantly outperforms existing feature acquisition methods when the number of features is large.","https://ojs.aaai.org/index.php/AAAI/article/view/25934/25706"
"25935","Local Intrinsic Dimensional Entropy","['Rohan Ghosh', 'Mehul Motani']","['National University of Singapore', 'National University of Singapore']","['ML: Calibration & Uncertainty Quantification', 'ML: Other Foundations of Machine Learning']","Ghosh, R., & Motani, M. (2023). Local Intrinsic Dimensional Entropy. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7714-7721. https://doi.org/10.1609/aaai.v37i6.25935","Abstract 					Most entropy measures depend on the spread of the probability distribution over the sample space |X|, and the maximum entropy achievable scales proportionately with the sample space cardinality |X|. For a finite |X|, this yields robust entropy measures which satisfy many important properties, such as invariance to bijections, while the same is not true for continuous spaces (where |X|=infinity). Furthermore, since R and R^d (d in Z+) have the same cardinality (from Cantor's correspondence argument), cardinality-dependent entropy measures cannot encode the data dimensionality. In this work, we question the role of cardinality and distribution spread in defining entropy measures for continuous spaces, which can undergo multiple rounds of transformations and distortions, e.g., in neural networks. We find that the average value of the local intrinsic dimension of a distribution, denoted as ID-Entropy, can serve as a robust entropy measure for continuous spaces, while capturing the data dimensionality. We find that ID-Entropy satisfies many desirable properties and can be extended to conditional entropy, joint entropy and mutual-information variants. ID-Entropy also yields new information bottleneck principles and also links to causality. In the context of deep learning, for feedforward architectures, we show, theoretically and empirically, that the ID-Entropy of a hidden layer directly controls the generalization gap for both classifiers and auto-encoders, when the target function is Lipschitz continuous. Our work primarily shows that, for continuous spaces, taking a structural rather than a statistical approach yields entropy measures which preserve intrinsic data dimensionality, while being relevant for studying various architectures.","https://ojs.aaai.org/index.php/AAAI/article/view/25935/25707"
"25936","Improving Uncertainty Quantification of Deep Classifiers via Neighborhood Conformal Prediction: Novel Algorithm and Theoretical Analysis","['Subhankar Ghosh', 'Taha Belkhouja', 'Yan Yan', 'Janardhan Rao Doppa']","['Washington State University', 'Washington State University', 'Washington State University', 'Washington State University']","['ML: Calibration & Uncertainty Quantification', 'ML: Classification and Regression']","Ghosh, S., Belkhouja, T., Yan, Y., & Doppa, J. R. (2023). Improving Uncertainty Quantification of Deep Classifiers via Neighborhood Conformal Prediction: Novel Algorithm and Theoretical Analysis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7722-7730. https://doi.org/10.1609/aaai.v37i6.25936","Abstract 					Safe deployment of deep neural networks in high-stake real-world applications require theoretically sound uncertainty quantification. Conformal prediction (CP) is a principled framework for uncertainty quantification of deep models in the form of prediction set for classification tasks with a user-specified  coverage (i.e., true class label is contained with high probability). This paper proposes a novel algorithm referred to as Neighborhood Conformal Prediction (NCP) to improve the efficiency of uncertainty quantification from CP for deep classifiers (i.e., reduce prediction set size). The key idea behind NCP is to use the learned representation of the neural network to identify k nearest-neighbor calibration examples for a given testing input and assign them importance weights proportional to their distance to create adaptive prediction sets. We theoretically show that if the learned data representation of the neural network satisfies some mild conditions, NCP will produce smaller prediction sets than traditional CP algorithms. Our comprehensive experiments on CIFAR-10, CIFAR-100, and ImageNet datasets using diverse deep neural networks strongly demonstrate that NCP leads to significant reduction in prediction set size over prior CP methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25936/25708"
"25937","Adaptive Hierarchy-Branch Fusion for Online Knowledge Distillation","['Linrui Gong', 'Shaohui Lin', 'Baochang Zhang', 'Yunhang Shen', 'Ke Li', 'Ruizhi Qiao', 'Bo Ren', 'Muqing Li', 'Zhou Yu', 'Lizhuang Ma']","['East China Normal University, China', 'East China Normal University, China', 'Beihang University, China', 'Tencent Youtu Lab, China', 'Tencent Youtu Lab, China', 'Tencent Youtu Lab, China', 'Tencent Youtu Lab, China', 'Tencent Youtu Lab, China', 'East China Normal University, China\nKey Laboratory of Advanced Theory and Application in Statistics and Data Science - MOE, China', 'East China Normal University, China']","['ML: Learning on the Edge & Model Compression', 'ML: Auto ML and Hyperparameter Tuning', 'ML: Ensemble Methods']","Gong, L., Lin, S., Zhang, B., Shen, Y., Li, K., Qiao, R., Ren, B., Li, M., Yu, Z., & Ma, L. (2023). Adaptive Hierarchy-Branch Fusion for Online Knowledge Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7731-7739. https://doi.org/10.1609/aaai.v37i6.25937","Abstract 					Online Knowledge Distillation (OKD) is designed to alleviate the dilemma that the high-capacity pre-trained teacher model is not available. However, the existing methods mostly focus on improving the ensemble prediction accuracy from multiple students (a.k.a. branches), which often overlook the homogenization problem that makes student model saturate quickly and hurts the performance. We assume that the intrinsic bottleneck of the homogenization problem comes from the identical branch architecture and coarse ensemble strategy. We propose a novel Adaptive Hierarchy-Branch Fusion framework for Online Knowledge Distillation, termed AHBF-OKD, which designs hierarchical branches and adaptive hierarchy-branch fusion module to boost the model diversity and aggregate complementary knowledge. Specifically, we first introduce hierarchical branch architectures to construct diverse peers by increasing the depth of branches monotonously on the basis of target branch. To effectively transfer knowledge from the most complex branch to the simplest target branch, we propose an adaptive hierarchy-branch fusion module to create hierarchical teacher assistants recursively, which regards the target branch as the smallest teacher assistant. During the training, the teacher assistant from the previous hierarchy is explicitly distilled by the teacher assistant and the branch from the current hierarchy. Thus, the important scores to different branches are effectively and adaptively allocated to reduce the branch homogenization. Extensive experiments demonstrate the effectiveness of AHBF-OKD on different datasets, including CIFAR-10/100 and ImageNet 2012. For example, on ImageNet 2012, the distilled ResNet-18 achieves Top-1 error of 29.28\%, which significantly outperforms the state-of-the-art  methods. The source code is available at https://github.com/linruigong965/AHBF.","https://ojs.aaai.org/index.php/AAAI/article/view/25937/25709"
"25938","Deep Latent Regularity Network for Modeling Stochastic Partial Differential Equations","['Shiqi Gong', 'Peiyan Hu', 'Qi Meng', 'Yue Wang', 'Rongchan Zhu', 'Bingguang Chen', 'Zhiming Ma', 'Hao Ni', 'Tie-Yan Liu']","['Academy of Mathematics and Systems Science, Chinese Academy of Sciences', 'Academy of Mathematics and Systems Science, Chinese Academy of Sciences', 'Microsoft Research AI4Science', 'Microsoft Research AI4Science', 'Bielefeld University', 'Academy of Mathematics and Systems Science,CAS', 'Academy of Mathematics and System Science, Chinese Academy of Sciences', 'University College London\nThe Alan Turing Institute', 'Microsoft Research AI4Science']","['ML: Time-Series/Data Streams', 'ML: Deep Neural Network Algorithms', 'APP: Natural Sciences']","Gong, S., Hu, P., Meng, Q., Wang, Y., Zhu, R., Chen, B., Ma, Z., Ni, H., & Liu, T.-Y. (2023). Deep Latent Regularity Network for Modeling Stochastic Partial Differential Equations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7740-7747. https://doi.org/10.1609/aaai.v37i6.25938","Abstract 					Stochastic partial differential equations (SPDEs) are crucial for modelling dynamics with randomness in many areas including economics, physics, and atmospheric sciences. Recently, using deep learning approaches to learn the PDE solution for accelerating PDE simulation becomes increasingly popular. However, SPDEs have two unique properties that require new design on the models. First, the model to approximate the solution of SPDE should be generalizable over both initial conditions and the random sampled forcing term. Second, the random forcing terms usually have poor regularity whose statistics may diverge (e.g., the space-time white noise). To deal with the problems, in this work, we design a deep neural network called \emph{Deep Latent Regularity Net} (DLR-Net).  DLR-Net includes a regularity feature block as the main component, which maps the initial condition and the random forcing term to a set of regularity features. The processing of regularity features is inspired by regularity structure theory and the features provably compose a set of basis to represent the SPDE solution. The regularity features are then fed into a small backbone neural operator to get the output. We conduct experiments on various SPDEs including the dynamic $\Phi^4_1$ model and the stochastic 2D Navier-Stokes equation to predict their solutions, and the results demonstrate that the proposed DLR-Net can achieve SOTA accuracy compared with the baselines. Moreover, the inference time is over 20 times faster than the traditional numerical solver and is comparable with the baseline deep learning models.","https://ojs.aaai.org/index.php/AAAI/article/view/25938/25710"
"25939","Dynamic Representation Learning with Temporal Point Processes for Higher-Order Interaction Forecasting","['Tony Gracious', 'Ambedkar Dukkipati']","['Indian Institute of Science Bangalore', 'Indian Institute of Science Bangalore']","['ML: Graph-based Machine Learning', 'ML: Representation Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Time-Series/Data Streams', 'ML: Deep Neural Network Algorithms', 'ML: Unsupervised & Self-Supervised Learning']","Gracious, T., & Dukkipati, A. (2023). Dynamic Representation Learning with Temporal Point Processes for Higher-Order Interaction Forecasting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7748-7756. https://doi.org/10.1609/aaai.v37i6.25939","Abstract 					The explosion of digital information and the growing involvement of people in social networks led to enormous research activity to develop methods that can extract meaningful information from interaction data. Commonly, interactions are represented by edges in a network or a graph, which implicitly assumes that the interactions are pairwise and static. However, real-world interactions deviate from these assumptions: (i) interactions can be multi-way, involving more than two nodes or individuals (e.g., family relationships, protein interactions), and (ii) interactions can change over a period of time (e.g., change of opinions and friendship status). While pairwise interactions have been studied in a dynamic network setting and multi-way interactions have been studied using hypergraphs in static networks, there exists no method, at present, that can predict multi-way interactions or hyperedges in dynamic settings. Existing related methods cannot answer temporal queries like what type of interaction will occur next and when it will occur. This paper proposes a temporal point process model for hyperedge prediction to address these problems. Our proposed model uses dynamic representation learning techniques for nodes in a neural point process framework to forecast hyperedges. We present several experimental results and set benchmark results. As far as our knowledge, this is the first work that uses the temporal point process to forecast hyperedges in dynamic networks.","https://ojs.aaai.org/index.php/AAAI/article/view/25939/25711"
"25940","An Adaptive Layer to Leverage Both Domain and Task Specific Information from Scarce Data","['Gaël Guibon', 'Matthieu Labeau', 'Luce Lefeuvre', 'Chloé Clavel']","['LTCI, Télécom Paris, Institut Polytechnique de Paris\nDirection Technologies, Innovation & Projets Groupe, SNCF', 'LTCI, Télécom Paris, Institut Polytechnique de Paris', 'Direction Technologies, Innovation & Projets Groupe, SNCF', 'LTCI, Télécom Paris, Institut Polytechnique de Paris']","['ML: Applications', 'ML: Classification and Regression', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'SNLP: Applications', 'SNLP: Sentiment Analysis and Stylistic Analysis', 'SNLP: Text Classification']","Guibon, G., Labeau, M., Lefeuvre, L., & Clavel, C. (2023). An Adaptive Layer to Leverage Both Domain and Task Specific Information from Scarce Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7757-7765. https://doi.org/10.1609/aaai.v37i6.25940","Abstract 					Many companies make use of customer service chats to help the customer and try to solve their problem. However, customer service data is confidential and as such, cannot easily be shared in the research community. This also implies that these data are rarely labeled, making it difficult to take advantage of it with machine learning methods. In this paper we present the first work on a customer’s problem status prediction and identification of problematic conversations. Given very small subsets of labeled textual conversations and unlabeled ones, we propose a semi-supervised framework dedicated to customer service data leveraging speaker role information to adapt the model to the domain and the task using a two-step process. Our framework, Task-Adaptive Fine-tuning, goes from predicting customer satisfaction to identifying the status of the customer’s problem, with the latter being the main objective of the multi-task setting. It outperforms recent inductive semi-supervised approaches on this novel task while only considering a relatively low number of parameters to train on during the final target task. We believe it can not only serve models dedicated to customer service but also to any other application making use of confidential conversational data where labeled sets are rare. Source code is available at https://github.com/gguibon/taft","https://ojs.aaai.org/index.php/AAAI/article/view/25940/25712"
"25941","Interpolating Graph Pair to Regularize Graph Classification","['Hongyu Guo', 'Yongyi Mao']","['University of Ottawa', 'University of Ottawa']","['ML: Deep Neural Network Algorithms', 'ML: Classification and Regression', 'ML: Graph-based Machine Learning']","Guo, H., & Mao, Y. (2023). Interpolating Graph Pair to Regularize Graph Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7766-7774. https://doi.org/10.1609/aaai.v37i6.25941","Abstract 					We present a simple and yet effective interpolation-based regularization technique, aiming to improve the generalization of  Graph Neural Networks (GNNs) on supervised graph classification. We leverage  Mixup, an effective regularizer for vision, where random sample pairs and their labels are interpolated to create synthetic images for training. Unlike images with grid-like coordinates, graphs have arbitrary structure and topology, which can be very sensitive to any modification that alters the graph's semantic meanings. This posts two unanswered questions for Mixup-like regularization schemes: Can we directly mix up a pair of graph inputs?  If so, how well does such mixing strategy  regularize the learning of GNNs? To answer these two questions, we propose ifMixup, which first adds dummy nodes  to make two graphs have the same input size and then simultaneously performs linear interpolation between  the aligned node feature vectors and the aligned edge representations of the two graphs. We empirically show that such simple mixing schema can effectively regularize the  classification learning, resulting in superior predictive accuracy to popular graph augmentation and GNN methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25941/25713"
"25942","Graph Knows Unknowns: Reformulate Zero-Shot Learning as Sample-Level Graph Recognition","['Jingcai Guo', 'Song Guo', 'Qihua Zhou', 'Ziming Liu', 'Xiaocheng Lu', 'Fushuo Huo']","['The Hong Kong Polytechnic University\nThe Hong Kong Polytechnic University Shenzhen Research Institute', 'The Hong Kong Polytechnic University\nThe Hong Kong Polytechnic University Shenzhen Research Institute', 'The Hong Kong Polytechnic University', 'The Hong Kong Polytechnic University', 'The Hong Kong Polytechnic University\nNorthwestern Polytechnical University', 'The Hong Kong Polytechnic University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Applications', 'ML: Classification and Regression', 'ML: Representation Learning']","Guo, J., Guo, S., Zhou, Q., Liu, Z., Lu, X., & Huo, F. (2023). Graph Knows Unknowns: Reformulate Zero-Shot Learning as Sample-Level Graph Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7775-7783. https://doi.org/10.1609/aaai.v37i6.25942","Abstract 					Zero-shot learning (ZSL) is an extreme case of transfer learning that aims to recognize samples (e.g., images) of unseen classes relying on a train-set covering only seen classes and a set of auxiliary knowledge (e.g., semantic descriptors). Existing methods usually resort to constructing a visual-to-semantics mapping based on features extracted from each whole sample. However, since the visual and semantic spaces are inherently independent and may exist in different manifolds, these methods may easily suffer from the domain bias problem due to the knowledge transfer from seen to unseen classes. Unlike existing works, this paper investigates the fine-grained ZSL from a novel perspective of sample-level graph. Specifically, we decompose an input into several fine-grained elements and construct a graph structure per sample to measure and utilize element-granularity relations within each sample. Taking advantage of recently developed graph neural networks (GNNs), we formulate the ZSL problem to a graph-to-semantics mapping task, which can better exploit element-semantics correlation and local sub-structural information in samples. Experimental results on the widely used benchmark datasets demonstrate that the proposed method can mitigate the domain bias problem and achieve competitive performance against other representative methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25942/25714"
"25943","Self-Supervised Bidirectional Learning for Graph Matching","['Wenqi Guo', 'Lin Zhang', 'Shikui Tu', 'Lei Xu']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['ML: Graph-based Machine Learning', 'ML: Optimization']","Guo, W., Zhang, L., Tu, S., & Xu, L. (2023). Self-Supervised Bidirectional Learning for Graph Matching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7784-7792. https://doi.org/10.1609/aaai.v37i6.25943","Abstract 					Deep learning methods have demonstrated promising performance on the NP-hard Graph Matching (GM) problems. However, the state-of-the-art methods usually require the ground-truth labels, which may take extensive human efforts or be impractical to collect. In this paper, we present a robust self-supervised bidirectional learning method (IA-SSGM) to tackle GM in an unsupervised manner. It involves an affinity learning component and a classic GM solver. Specifically, we adopt the Hungarian solver to generate pseudo correspondence labels for the simple probabilistic relaxation of the affinity matrix. In addition, a bidirectional recycling consistency module is proposed to generate pseudo samples by recycling the pseudo correspondence back to permute the input. It imposes a consistency constraint between the pseudo affinity and the original one, which is theoretically supported to help reduce the matching error. Our method further develops a graph contrastive learning jointly with the affinity learning to enhance its robustness against the noise and outliers in real applications. Experiments deliver superior performance over the previous state-of-the-arts on five real-world benchmarks, especially under the more difficult outlier scenarios, demon- strating the effectiveness of our method.","https://ojs.aaai.org/index.php/AAAI/article/view/25943/25715"
"25944","Boosting Graph Neural Networks via Adaptive Knowledge Distillation","['Zhichun Guo', 'Chunhui Zhang', 'Yujie Fan', 'Yijun Tian', 'Chuxu Zhang', 'Nitesh V. Chawla']","['University of Notre Dame, Notre Dame, IN 46545', 'Brandeis University, Waltham, MA 02453', 'Case Western Reserve University, Cleveland, OH 44106', 'University of Notre Dame, Notre Dame, IN 46545', 'Brandeis University, Waltham, MA 02453', 'University of Notre Dame, Notre Dame, IN 46545']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Guo, Z., Zhang, C., Fan, Y., Tian, Y., Zhang, C., & Chawla, N. V. (2023). Boosting Graph Neural Networks via Adaptive Knowledge Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7793-7801. https://doi.org/10.1609/aaai.v37i6.25944","Abstract 					Graph neural networks (GNNs) have shown remarkable performance on diverse graph mining tasks. While sharing the same message passing framework, our study shows that different GNNs learn distinct knowledge from the same graph. This implies potential performance improvement by distilling the complementary knowledge from multiple models. However, knowledge distillation (KD) transfers knowledge from high-capacity teachers to a lightweight student, which deviates from our scenario: GNNs are often shallow. To transfer knowledge effectively, we need to tackle two challenges: how to transfer knowledge from compact teachers to a student with the same capacity; and, how to exploit student GNN's own learning ability. In this paper, we propose a novel adaptive KD framework, called BGNN, which sequentially transfers knowledge from multiple GNNs into a student GNN. We also introduce an adaptive temperature module and a weight boosting module. These modules guide the student to the appropriate knowledge for effective learning. Extensive experiments have demonstrated the effectiveness of BGNN. In particular, we achieve up to 3.05% improvement for node classification and 6.35% improvement for graph classification over vanilla GNNs.","https://ojs.aaai.org/index.php/AAAI/article/view/25944/25716"
"25945","Dream to Generalize: Zero-Shot Model-Based Reinforcement Learning for Unseen Visual Distractions","['Jeongsoo Ha', 'Kyungsoo Kim', 'Yusung Kim']","['Mechatronics Research, Samsung Electronics', 'Intelligent Agent Lab, NCSOFT', 'Department of Computer Science and Engineering, Sungkyunkwan University']","['ML: Reinforcement Learning Algorithms', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning', 'ROB: Learning & Optimization for ROB']","Ha, J., Kim, K., & Kim, Y. (2023). Dream to Generalize: Zero-Shot Model-Based Reinforcement Learning for Unseen Visual Distractions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7802-7810. https://doi.org/10.1609/aaai.v37i6.25945","Abstract 					Model-based reinforcement learning (MBRL) has been used to efficiently solve vision-based control tasks in high-dimensional image observations. Although recent MBRL algorithms perform well in trained observations, they fail when faced with visual distractions in observations. These task-irrelevant distractions (e.g., clouds, shadows, and light) may be constantly present in real-world scenarios. In this study, we propose a novel self-supervised method, Dream to Generalize (Dr. G), for zero-shot MBRL. Dr. G trains its encoder and world model with dual contrastive learning which efficiently captures task-relevant features among multi-view data augmentations. We also introduce a recurrent state inverse dynamics model that helps the world model to better understand the temporal structure. The proposed methods can enhance the robustness of the world model against visual distractions. To evaluate the generalization performance, we first train Dr. G on simple backgrounds and then test it on complex natural video backgrounds in the DeepMind Control suite, and the randomizing environments in Robosuite. Dr. G yields a performance improvement of 117% and 14% over prior works, respectively. Our code is open-sourced and available at https://github.com/JeongsooHa/DrG.git","https://ojs.aaai.org/index.php/AAAI/article/view/25945/25717"
"25946","Discriminability and Transferability Estimation: A Bayesian Source Importance Estimation Approach for Multi-Source-Free Domain Adaptation","['Zhongyi Han', 'Zhiyan Zhang', 'Fan Wang', 'Rundong He', 'Wan Su', 'Xiaoming Xi', 'Yilong Yin']","['Shandong University', 'Shandong University', 'Shandong University', 'Shandong University', 'Shandong University', 'Shandong Jianzhu University', 'Shandong University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'DMKM: Anomaly/Outlier Detection', 'ML: Semi-Supervised Learning']","Han, Z., Zhang, Z., Wang, F., He, R., Su, W., Xi, X., & Yin, Y. (2023). Discriminability and Transferability Estimation: A Bayesian Source Importance Estimation Approach for Multi-Source-Free Domain Adaptation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7811-7820. https://doi.org/10.1609/aaai.v37i6.25946","Abstract 					Source free domain adaptation (SFDA) transfers a single-source model to the unlabeled target domain without accessing the source data. With the intelligence development of various fields, a zoo of source models is more commonly available,  arising in a new setting called multi-source-free domain adaptation (MSFDA). We find that the critical inborn challenge of MSFDA is how to estimate the importance (contribution) of each source model. In this paper, we shed new Bayesian light on the fact that the posterior probability of source importance connects to discriminability and transferability. We propose Discriminability And Transferability Estimation (DATE), a universal solution for source importance estimation. Specifically, a proxy discriminability perception module equips with habitat uncertainty and density to evaluate each sample's surrounding environment. A source-similarity transferability perception module quantifies the data distribution similarity and encourages the transferability to be reasonably distributed with a domain diversity loss. Extensive experiments show that DATE can precisely and objectively estimate the source importance and outperform prior arts by non-trivial margins. Moreover, experiments demonstrate that DATE can take the most popular SFDA networks as backbones and make them become advanced MSFDA solutions.","https://ojs.aaai.org/index.php/AAAI/article/view/25946/25718"
"25947","Astromorphic Self-Repair of Neuromorphic Hardware Systems","['Zhuangyu Han', 'A N M Nafiul Islam', 'Abhronil Sengupta']","['Pennsylvania State University', 'Pennsylvania State University', 'Pennsylvania State University']","['ML: Bio-Inspired Learning', 'CMS: Other Foundations of Cognitive Modeling & Systems']","Han, Z., Islam, A. N. M. N., & Sengupta, A. (2023). Astromorphic Self-Repair of Neuromorphic Hardware Systems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7821-7829. https://doi.org/10.1609/aaai.v37i6.25947","Abstract 					While neuromorphic computing architectures based on Spiking Neural Networks (SNNs) are increasingly gaining interest as a pathway toward bio-plausible machine learning, attention is still focused on computational units like the neuron and synapse. Shifting from this neuro-synaptic perspective, this paper attempts to explore the self-repair role of glial cells, in particular, astrocytes. The work investigates stronger correlations with astrocyte computational neuroscience models to develop macro-models with a higher degree of bio-fidelity that accurately captures the dynamic behavior of the self-repair process. Hardware-software co-design analysis reveals that bio-morphic astrocytic regulation has the potential to self-repair hardware realistic faults in neuromorphic hardware systems with significantly better accuracy and repair convergence for unsupervised learning tasks on the MNIST and F-MNIST datasets. Our implementation source code and trained models are available at https://github.com/NeuroCompLab-psu/Astromorphic_Self_Repair.","https://ojs.aaai.org/index.php/AAAI/article/view/25947/25719"
"25948","Estimating Regression Predictive Distributions with Sample Networks","['Ali Harakeh', 'Jordan Sir Kwang Hu', 'Naiqing Guan', 'Steven Waslander', 'Liam Paull']","['Mila - Quebec AI Institute\nUniversité de Montréal', 'University of Toronto Institute for Aerospace Studies\nUniversity of Toronto', 'University of Toronto', 'University of Toronto Institute for Aerospace Studies\nUniversity of Toronto', 'Mila - Quebec AI Institute\nUniversité de Montréal']","['ML: Probabilistic Methods', 'CV: 3D Computer Vision', 'ML: Bayesian Learning']","Harakeh, A., Hu, J. S. K., Guan, N., Waslander, S., & Paull, L. (2023). Estimating Regression Predictive Distributions with Sample Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7830-7838. https://doi.org/10.1609/aaai.v37i6.25948","Abstract 					Estimating the uncertainty in deep neural network predictions is crucial for many real-world applications. A common approach to model uncertainty is to choose a parametric distribution and fit the data to it using maximum likelihood estimation. The chosen parametric form can be a poor fit to the data-generating distribution, resulting in unreliable uncertainty estimates. In this work, we propose SampleNet, a flexible and scalable architecture for modeling uncertainty that avoids specifying a parametric form on the output distribution. SampleNets do so by defining an empirical distribution using samples that are learned with the Energy Score and regularized with the Sinkhorn Divergence. SampleNets are shown to be able to well-fit a wide range of distributions and to outperform baselines on large-scale real-world regression tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25948/25720"
"25949","NAS-LID: Efficient Neural Architecture Search with Local Intrinsic Dimension","['Xin He', 'Jiangchao Yao', 'Yuxin Wang', 'Zhenheng Tang', 'Ka Chun Cheung', 'Simon See', 'Bo Han', 'Xiaowen Chu']","['Hong Kong Baptist University\nNVIDIA AI Tech Center', 'Shanghai Jiao Tong University\nShanghai AI Laboratory', 'Hong Kong Baptist University', 'Hong Kong Baptist University', 'Hong Kong Baptist University\nNVIDIA AI Tech Centre', 'Shanghai Jiao Tong University\nNVIDIA AI Tech Centre\nMahindra University\nCoventry University', 'Hong Kong Baptist University', 'The Hong Kong University of Science and Technology (Guangzhou)\nHong Kong Baptist University']","['ML: Auto ML and Hyperparameter Tuning', 'ML: Classification and Regression', 'ML: Deep Neural Architectures']","He, X., Yao, J., Wang, Y., Tang, Z., Cheung, K. C., See, S., Han, B., & Chu, X. (2023). NAS-LID: Efficient Neural Architecture Search with Local Intrinsic Dimension. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7839-7847. https://doi.org/10.1609/aaai.v37i6.25949","Abstract 					One-shot neural architecture search (NAS) substantially improves the search efficiency by training one supernet to estimate the performance of every possible child architecture (i.e., subnet). However, the inconsistency of characteristics among subnets incurs serious interference in the optimization, resulting in poor performance ranking correlation of subnets. Subsequent explorations decompose supernet weights via a particular criterion, e.g., gradient matching, to reduce the interference; yet they suffer from huge computational cost and low space separability. In this work, we propose a lightweight and effective local intrinsic dimension (LID)-based method NAS-LID. NAS-LID evaluates the geometrical properties of architectures by calculating the low-cost LID features layer-by-layer, and the similarity characterized by LID enjoys better separability compared with gradients, which thus effectively reduces the interference among subnets. Extensive experiments on NASBench-201 indicate that NAS-LID achieves superior performance with better efficiency. Specifically, compared to the gradient-driven method, NAS-LID can save up to 86% of GPU memory overhead when searching on NASBench-201. We also demonstrate the effectiveness of NAS-LID on ProxylessNAS and OFA spaces. Source code:https://github.com/marsggbo/NAS-LID.","https://ojs.aaai.org/index.php/AAAI/article/view/25949/25721"
"25950","Safeguarded Learned Convex Optimization","['Howard Heaton', 'Xiaohan Chen', 'Zhangyang Wang', 'Wotao Yin']","['Typal LLC', 'University of Texas at Austin', 'University of Texas at Austin', 'Alibaba US, DAMO Academy']","['ML: Optimization', 'ML: Deep Neural Network Algorithms']","Heaton, H., Chen, X., Wang, Z., & Yin, W. (2023). Safeguarded Learned Convex Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(6), 7848-7855. https://doi.org/10.1609/aaai.v37i6.25950","Abstract 					Applications abound in which optimization problems must be repeatedly solved, each time with new (but similar) data. Analytic optimization algorithms can be hand-designed to provably solve these problems in an iterative fashion. On one hand, data-driven algorithms can ""learn to optimize"" (L2O) with much fewer iterations and similar cost per iteration as general-purpose optimization algorithms. On the other hand, unfortunately, many L2O algorithms lack converge guarantees. To fuse the advantages of these approaches, we present a Safe-L2O framework. Safe-L2O updates incorporate a safeguard to guarantee convergence for convex problems with proximal and/or gradient oracles. The safeguard is simple and computationally cheap to implement, and it is activated only when the data-driven L2O updates would perform poorly or appear to diverge. This yields the numerical benefits of employing machine learning to create rapid L2O algorithms while still guaranteeing convergence. Our numerical examples show convergence of Safe-L2O algorithms, even when the provided data is not from the distribution of training data.","https://ojs.aaai.org/index.php/AAAI/article/view/25950/25722"
"25951","Improving Long-Horizon Imitation through Instruction Prediction","['Joey Hejna', 'Pieter Abbeel', 'Lerrel Pinto']","['Stanford University', 'UC Berkeley', 'New York University']","['ML: Imitation Learning & Inverse Reinforcement Learning', 'ROB: Cognitive Robotics']","Hejna, J., Abbeel, P., & Pinto, L. (2023). Improving Long-Horizon Imitation through Instruction Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7857-7865. https://doi.org/10.1609/aaai.v37i7.25951","Abstract 					Complex, long-horizon planning and its combinatorial nature pose steep challenges for learning-based agents. Difficulties in such settings are exacerbated in low data regimes where over-fitting stifles generalization and compounding errors hurt accuracy. In this work, we explore the use of an often unused source of auxiliary supervision: language. Inspired by recent advances in transformer-based models, we train agents with an instruction prediction loss that encourages learning temporally extended representations that operate at a high level of abstraction. Concretely, we demonstrate that instruction modeling significantly improves performance in planning environments when training with a limited number of demonstrations on the BabyAI and Crafter benchmarks. In further analysis we find that instruction modeling is most important for tasks that require complex reasoning, while understandably offering smaller gains in environments that require simple plans. More details and code can be found at \url{https://github.com/jhejna/instruction-prediction}.","https://ojs.aaai.org/index.php/AAAI/article/view/25951/25723"
"25952","Self-Supervised Learning for Anomalous Channel Detection in EEG Graphs: Application to Seizure Analysis","['Thi Kieu Khanh Ho', 'Narges Armanfard']","['Department of Electrical and Computer Engineering, McGill University\nMila - Quebec AI Institute, Montreal, QC, Canada', 'Department of Electrical and Computer Engineering, McGill University\nMila - Quebec AI Institute, Montreal, QC, Canada']","['ML: Applications', 'DMKM: Anomaly/Outlier Detection', 'APP: Healthcare', 'Medicine & Wellness', 'ML: Time-Series/Data Streams']","Ho, T. K. K., & Armanfard, N. (2023). Self-Supervised Learning for Anomalous Channel Detection in EEG Graphs: Application to Seizure Analysis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7866-7874. https://doi.org/10.1609/aaai.v37i7.25952","Abstract 					Electroencephalogram (EEG) signals are effective tools towards seizure analysis where one of the most important challenges is accurate detection of seizure events and brain regions in which seizure happens or initiates. However, all existing machine learning-based algorithms for seizure analysis require access to the labeled seizure data while acquiring labeled data is very labor intensive, expensive, as well as clinicians dependent given the subjective nature of the visual qualitative interpretation of EEG signals. In this paper, we propose to detect seizure channels and clips in a self-supervised manner where no access to the seizure data is needed. The proposed method considers local structural and contextual information embedded in EEG graphs by employing positive and negative sub-graphs. We train our method through minimizing contrastive and generative losses. The employ of local EEG sub-graphs makes the algorithm an appropriate choice when accessing to the all EEG channels is impossible due to complications such as skull fractures. We conduct an extensive set of experiments on the largest seizure dataset and demonstrate that our proposed framework outperforms the state-of-the-art methods in the EEG-based seizure study. The proposed method is the only study that requires no access to the seizure data in its training phase, yet establishes a new state-of-the-art to the field, and outperforms all related supervised methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25952/25724"
"25953","Improving Pareto Front Learning via Multi-Sample Hypernetworks","['Long P. Hoang', 'Dung D. Le', 'Tran Anh Tuan', 'Tran Ngoc Thang']","['VinUniversity\nHanoi University of Science and Technology', 'VinUniversity', 'Hanoi University of Science and Technology', 'Hanoi University of Science and Technology']","['ML: Optimization', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Hoang, L. P., Le, D. D., Anh Tuan, T., & Ngoc Thang, T. (2023). Improving Pareto Front Learning via Multi-Sample Hypernetworks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7875-7883. https://doi.org/10.1609/aaai.v37i7.25953","Abstract 					Pareto Front Learning (PFL) was recently introduced as an effective approach to obtain a mapping function from a given trade-off vector to a solution on the Pareto front, which solves the multi-objective optimization (MOO) problem. Due to the inherent trade-off between conflicting objectives, PFL offers a flexible approach in many scenarios in which the decision makers can not specify the preference of one Pareto solution over another, and must switch between them depending on the situation. However, existing PFL methods ignore the relationship between the solutions during the optimization process, which hinders the quality of the obtained front. To overcome this issue, we propose a novel PFL framework namely PHN-HVI, which employs a hypernetwork to generate multiple solutions from a set of diverse trade-off preferences and enhance the quality of the Pareto front by maximizing the Hypervolume indicator defined by these solutions. The experimental results on several MOO machine learning tasks show that the proposed framework significantly outperforms the baselines in producing the trade-off Pareto front.","https://ojs.aaai.org/index.php/AAAI/article/view/25953/25725"
"25954","Towards Better Visualizing the Decision Basis of Networks via Unfold and Conquer Attribution Guidance","['Jung-Ho Hong', 'Woo-Jeoung Nam', 'Kyu-Sung Jeon', 'Seong-Whan Lee']","['Korea University', 'Kyungpook National University', 'Korea University', 'Korea University']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'CV: Interpretability and Transparency']","Hong, J.-H., Nam, W.-J., Jeon, K.-S., & Lee, S.-W. (2023). Towards Better Visualizing the Decision Basis of Networks via Unfold and Conquer Attribution Guidance. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7884-7892. https://doi.org/10.1609/aaai.v37i7.25954","Abstract 					Revealing the transparency of Deep Neural Networks (DNNs) has been widely studied to describe the decision mechanisms of network inner structures. In this paper, we propose a novel post-hoc framework, Unfold and Conquer Attribution Guidance (UCAG), which enhances the explainability of the network decision by spatially scrutinizing the input features with respect to the model confidence. Addressing the phenomenon of missing detailed descriptions, UCAG sequentially complies with the confidence of slices of the image, leading to providing an abundant and clear interpretation. Therefore, it is possible to enhance the representation ability of explanation by preserving the detailed descriptions of assistant input features, which are commonly overwhelmed by the main meaningful regions. We conduct numerous evaluations to validate the performance in several metrics: i) deletion and insertion, ii) (energy-based) pointing games, and iii) positive and negative density maps. Experimental results, including qualitative comparisons, demonstrate that our method outperforms the existing methods with the nature of clear and detailed explanations and applicability.","https://ojs.aaai.org/index.php/AAAI/article/view/25954/25726"
"25955","Federated Robustness Propagation: Sharing Adversarial Robustness in Heterogeneous Federated Learning","['Junyuan Hong', 'Haotao Wang', 'Zhangyang Wang', 'Jiayu Zhou']","['Michigan State University', 'University of Texas at Austin', 'University of Texas at Austin', 'Michigan State University']","['ML: Distributed Machine Learning & Federated Learning', 'ML: Adversarial Learning & Robustness']","Hong, J., Wang, H., Wang, Z., & Zhou, J. (2023). Federated Robustness Propagation: Sharing Adversarial Robustness in Heterogeneous Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7893-7901. https://doi.org/10.1609/aaai.v37i7.25955","Abstract 					Federated learning (FL) emerges as a popular distributed learning schema that learns a model from a set of participating users without sharing raw data. One major challenge of FL comes with heterogeneous users, who may have distributionally different (or non-iid) data and varying computation resources. As federated users would use the model for prediction, they often demand the trained model to be robust against malicious attackers at test time. Whereas adversarial training (AT) provides a sound solution for centralized learning, extending its usage for federated users has imposed significant challenges, as many users may have very limited training data and tight computational budgets, to afford the data-hungry and costly AT. In this paper, we study a novel FL strategy: propagating adversarial robustness from rich-resource users that can afford AT, to those with poor resources that cannot afford it, during federated learning. We show that existing FL techniques cannot be effectively integrated with the strategy to propagate robustness among non-iid users and propose an efficient propagation approach by the proper use of batch-normalization. We demonstrate the rationality and effectiveness of our method through extensive experiments. Especially, the proposed method is shown to grant federated models remarkable robustness even when only a small portion of users afford AT during learning. Source code can be accessed at https://github.com/illidanlab/FedRBN.","https://ojs.aaai.org/index.php/AAAI/article/view/25955/25727"
"25956","Compressed Decentralized Learning of Conditional Mean Embedding Operators in Reproducing Kernel Hilbert Spaces","['Boya Hou', 'Sina Sanjari', 'Nathan Dahlin', 'Subhonmesh Bose']","['University of Illinois, Urbana-Champaign', 'University of Illinois, Urbana-Champaign', 'University of Illinois, Urbana-Champaign', 'University of Illinois, Urbana-Champaign']","['ML: Kernel Methods', 'MAS: Multiagent Learning']","Hou, B., Sanjari, S., Dahlin, N., & Bose, S. (2023). Compressed Decentralized Learning of Conditional Mean Embedding Operators in Reproducing Kernel Hilbert Spaces. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7902-7909. https://doi.org/10.1609/aaai.v37i7.25956","Abstract 					Conditional mean embedding (CME) operators encode conditional probability densities within Reproducing Kernel Hilbert Space (RKHS). In this paper, we present a decentralized algorithm for a collection of agents to cooperatively approximate CME over a network. Communication constraints limit the agents from sending all data to their neighbors; we only allow sparse representations of covariance operators to be exchanged among agents, compositions of which defines CME. Using a coherence-based compression scheme, we present a consensus-type algorithm that preserves the average of the approximations of the covariance operators across the network. We theoretically prove that the iterative dynamics in RKHS is stable. We then empirically study our algorithm to estimate CMEs to learn spectra of Koopman operators for Markovian dynamical systems and to execute approximate value iteration for Markov decision processes (MDPs).","https://ojs.aaai.org/index.php/AAAI/article/view/25956/25728"
"25957","RLEKF: An Optimizer for Deep Potential with Ab Initio Accuracy","['Siyu Hu', 'Wentao Zhang', 'Qiuchen Sha', 'Feng Pan', 'Lin-Wang Wang', 'Weile Jia', 'Guangming Tan', 'Tong Zhao']","['State Key Lab of Processors, Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences, Beijing, China', 'School of Advanced Materials, Shenzhen Graduate School, Peking University', 'State Key Lab of Processors, Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences, Beijing, China', 'School of Advanced Materials, Shenzhen Graduate School, Peking University', 'Institute of Semiconductors, Chinese Academy of Sciences, Beijing, China', 'State Key Lab of Processors, Institute of Computing Technology, Chinese Academy of Sciences', 'State Key Lab of Processors, Institute of Computing Technology, Chinese Academy of Sciences', 'State Key Lab of Processors, Institute of Computing Technology, Chinese Academy of Sciences']","['ML: Applications', 'ML: Deep Learning Theory', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms', 'ML: Learning Theory', 'ML: Optimization', 'ML: Probabilistic Methods', 'ML: Scalability of ML Systems']","Hu, S., Zhang, W., Sha, Q., Pan, F., Wang, L.-W., Jia, W., Tan, G., & Zhao, T. (2023). RLEKF: An Optimizer for Deep Potential with Ab Initio Accuracy. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7910-7918. https://doi.org/10.1609/aaai.v37i7.25957","Abstract 					It is imperative to accelerate the training of neural network force field such as Deep Potential, which usually requires thousands of images based on first-principles calculation and a couple of days to generate an accurate potential energy surface. To this end, we propose a novel optimizer named reorganized layer extended Kalman filtering (RLEKF), an optimized version of global extended Kalman filtering (GEKF) with a strategy of splitting big and gathering small layers to overcome the O(N^2) computational cost of GEKF. This strategy provides an approximation of the dense weights error covariance matrix with a sparse diagonal block matrix for GEKF. We implement both RLEKF and the baseline Adam in our alphaDynamics package and numerical experiments are performed on 13 unbiased datasets. Overall, RLEKF converges faster with slightly better accuracy. For example, a test on a typical system, bulk copper, shows that RLEKF converges faster by both the number of training epochs (x11.67) and wall-clock time (x1.19). Besides, we theoretically prove that the updates of weights converge and thus are against the gradient exploding problem. Experimental results verify that RLEKF is not sensitive to the initialization of weights. The RLEKF sheds light on other AI-for-science applications where training a large neural network (with tons of thousands parameters) is a bottleneck.","https://ojs.aaai.org/index.php/AAAI/article/view/25957/25729"
"25958","Background-Mixed Augmentation for Weakly Supervised Change Detection","['Rui Huang', 'Ruofei Wang', 'Qing Guo', 'Jieda Wei', 'Yuxiang Zhang', 'Wei Fan', 'Yang Liu']","['Civil Aviation University of China', 'Civil Aviation University of China', 'Center for Frontier AI Research (CFAR), A*STAR, Singapore', 'Civil Aviation University of China', 'Civil Aviation University of China', 'Civil Aviation University of China', 'Zhejiang Sci-Tech University, China\nNanyang Technology University, Singapore']","['ML: Semi-Supervised Learning', 'CV: Scene Analysis & Understanding']","Huang, R., Wang, R., Guo, Q., Wei, J., Zhang, Y., Fan, W., & Liu, Y. (2023). Background-Mixed Augmentation for Weakly Supervised Change Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7919-7927. https://doi.org/10.1609/aaai.v37i7.25958","Abstract 					Change detection (CD) is to decouple object changes (i.e., object missing or appearing) from background changes (i.e., environment variations) like light and season variations in two images captured in the same scene over a long time span, presenting critical applications in disaster management, urban development, etc. In particular, the endless patterns of background changes require detectors to have a high generalization against unseen environment variations, making this task significantly challenging. Recent deep learning-based methods develop novel network architectures or optimization strategies with paired-training examples, which do not handle the generalization issue explicitly and require huge manual pixel-level annotation efforts. In this work, for the first attempt in the CD community, we study the generalization issue of CD from the perspective of data augmentation and develop a novel weakly supervised training algorithm that only needs image-level labels. Different from general augmentation techniques for classification, we propose the background-mixed augmentation that is specifically designed for change detection by augmenting examples under the guidance of a set of background changing images and letting deep CD models see diverse environment variations. Moreover, we propose the augmented & real data consistency loss that encourages the generalization increase significantly. Our method as a general framework can enhance a wide range of existing deep learning-based detectors. We conduct extensive experiments in two public datasets and enhance four state-of-the-art methods, demonstrating the advantages of our method. We release the code at https://github.com/tsingqguo/bgmix.","https://ojs.aaai.org/index.php/AAAI/article/view/25958/25730"
"25959","Enabling Knowledge Refinement upon New Concepts in Abductive Learning","['Yu-Xuan Huang', 'Wang-Zhou Dai', 'Yuan Jiang', 'Zhi-Hua Zhou']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University']","['ML: Classification and Regression', 'KRR: Diagnosis and Abductive Reasoning', 'KRR: Logic Programming']","Huang, Y.-X., Dai, W.-Z., Jiang, Y., & Zhou, Z.-H. (2023). Enabling Knowledge Refinement upon New Concepts in Abductive Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7928-7935. https://doi.org/10.1609/aaai.v37i7.25959","Abstract 					Recently there are great efforts on leveraging machine learning and logical reasoning. Many approaches start from a given knowledge base, and then try to utilize the knowledge to help machine learning. In real practice, however, the given knowledge base can often be incomplete or even noisy, and thus, it is crucial to develop the ability of knowledge refinement or enhancement. This paper proposes to enable the Abductive learning (ABL) paradigm to have the ability of knowledge refinement/enhancement. In particular, we focus on the problem that, in contrast to closed-environment tasks where a fixed set of symbols are enough to represent the concepts in the domain, in open-environment tasks new concepts may emerge. Ignoring those new concepts can lead to significant performance decay, whereas it is challenging to identify new concepts and add them to the existing knowledge base with potential conflicts resolved. We propose the ABL_nc approach which exploits machine learning in ABL to identify new concepts from data, exploits knowledge graph to match them with entities, and refines existing knowledge base to resolve conflicts. The refined/enhanced knowledge base can then be used in the next loop of ABL and help improve the performance of machine learning. Experiments on three neuro-symbolic learning tasks verified the effectiveness of the proposed approach.","https://ojs.aaai.org/index.php/AAAI/article/view/25959/25731"
"25960","Self-Supervised Graph Attention Networks for Deep Weighted Multi-View Clustering","['Zongmo Huang', 'Yazhou Ren', 'Xiaorong Pu', 'Shudong Huang', 'Zenglin Xu', 'Lifang He']","['University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China\nShenzhen Institute for Advanced Study, University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China\nShenzhen Institute for Advanced Study, University of Electronic Science and Technology of China', 'Sichuan University', 'Harbin Institute of Technology, Shenzhen', 'Lehigh University']","['ML: Multi-Instance/Multi-View Learning', 'ML: Clustering']","Huang, Z., Ren, Y., Pu, X., Huang, S., Xu, Z., & He, L. (2023). Self-Supervised Graph Attention Networks for Deep Weighted Multi-View Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7936-7943. https://doi.org/10.1609/aaai.v37i7.25960","Abstract 					As one of the most important research topics in the unsupervised learning field, Multi-View Clustering (MVC) has been widely studied in the past decade and numerous MVC methods have been developed. Among these methods, the recently emerged Graph Neural Networks (GNN) shine a light on modeling both topological structure and node attributes in the form of graphs, to guide unified embedding learning and clustering. However, the effectiveness of existing GNN-based MVC methods is still limited due to the insufficient consideration in utilizing the self-supervised information and graph information, which can be reflected from the following two aspects: 1) most of these models merely use the self-supervised information to guide the feature learning and fail to realize that such information can be also applied in graph learning and sample weighting; 2) the usage of graph information is generally limited to the feature aggregation in these models, yet it also provides valuable evidence in detecting noisy samples. To this end, in this paper we propose Self-Supervised Graph Attention Networks for Deep Weighted Multi-View Clustering (SGDMC), which promotes the performance of GNN-based deep MVC models by making full use of the self-supervised information and graph information. Specifically, a novel attention-allocating approach that considers both the similarity of node attributes and the self-supervised information is developed to comprehensively evaluate the relevance among different nodes. Meanwhile, to alleviate the negative impact caused by noisy samples and the discrepancy of cluster structures, we further design a sample-weighting strategy based on the attention graph as well as the discrepancy between the global pseudo-labels and the local cluster assignment. Experimental results on multiple real-world datasets demonstrate the effectiveness of our method over existing approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/25960/25732"
"25961","Reward-Biased Maximum Likelihood Estimation for Neural Contextual Bandits: A Distributional Learning Perspective","['Yu-Heng Hung', 'Ping-Chun Hsieh']","['National Yang Ming Chiao Tung University, Hsinchu, Taiwan', 'National Yang Ming Chiao Tung University, Hsinchu, Taiwan']","['ML: Online Learning & Bandits']","Hung, Y.-H., & Hsieh, P.-C. (2023). Reward-Biased Maximum Likelihood Estimation for Neural Contextual Bandits: A Distributional Learning Perspective. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7944-7952. https://doi.org/10.1609/aaai.v37i7.25961","Abstract 					Reward-biased maximum likelihood estimation (RBMLE) is a classic principle in the adaptive control literature for tackling explore-exploit trade-offs. This paper studies the neural contextual bandit problem from a distributional perspective and proposes NeuralRBMLE, which leverages the likelihood of surrogate parametric distributions to learn the unknown reward distributions and thereafter adapts the RBMLE principle to achieve efficient exploration by properly adding a reward-bias term. NeuralRBMLE leverages the representation power of neural networks and directly encodes exploratory behavior in the parameter space, without constructing confidence intervals of the estimated rewards. We propose two variants of NeuralRBMLE algorithms: The first variant directly obtains the RBMLE estimator by gradient ascent, and the second variant simplifies RBMLE to a simple index policy through an approximation. We show that both algorithms achieve order-optimality. Through extensive experiments, we demonstrate that the NeuralRBMLE algorithms achieve comparable or better empirical regrets than the state-of-the-art methods on real-world datasets with non-linear reward functions.","https://ojs.aaai.org/index.php/AAAI/article/view/25961/25733"
"25962","Learning Noise-Induced Reward Functions for Surpassing Demonstrations in Imitation Learning","['Liangyu Huo', 'Zulin Wang', 'Mai Xu']","['Beihang University', 'Beihang University', 'Beihang University']","['ML: Imitation Learning & Inverse Reinforcement Learning', 'ML: Reinforcement Learning Algorithms', 'ML: Learning Preferences or Rankings']","Huo, L., Wang, Z., & Xu, M. (2023). Learning Noise-Induced Reward Functions for Surpassing Demonstrations in Imitation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7953-7961. https://doi.org/10.1609/aaai.v37i7.25962","Abstract 					Imitation learning (IL) has recently shown impressive performance in training a reinforcement learning agent with human demonstrations, eliminating the difficulty of designing elaborate reward functions in complex environments. However, most IL methods work under the assumption of the optimality of the demonstrations and thus cannot learn policies to surpass the demonstrators. Some methods have been investigated to obtain better-than-demonstration (BD) performance with inner human feedback or preference labels. In this paper, we propose a method to learn rewards from suboptimal demonstrations via a weighted preference learning technique (LERP). Specifically, we first formulate the suboptimality of demonstrations as the inaccurate estimation of rewards. The inaccuracy is modeled with a reward noise random variable following the Gumbel distribution. Moreover, we derive an upper bound of the expected return with different noise coefficients and propose a theorem to surpass the demonstrations. Unlike existing literature, our analysis does not depend on the linear reward constraint. Consequently, we develop a BD model with a weighted preference learning technique. Experimental results on continuous control and high-dimensional discrete control tasks show the superiority of our LERP method over other state-of-the-art BD  methods.","https://ojs.aaai.org/index.php/AAAI/article/view/25962/25734"
"25963","XClusters: Explainability-First Clustering","['Hyunseung Hwang', 'Steven Euijong Whang']","['KAIST', 'KAIST']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'DMKM: Data Visualization & Summarization', 'ML: Clustering']","Hwang, H., & Whang, S. E. (2023). XClusters: Explainability-First Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7962-7970. https://doi.org/10.1609/aaai.v37i7.25963","Abstract 					We study the problem of explainability-first clustering where explainability becomes a first-class citizen for clustering. Previous clustering approaches use decision trees for explanation, but only after the clustering is completed. In contrast, our approach is to perform clustering and decision tree training holistically where the decision tree's performance and size also influence the clustering results. We assume the attributes for clustering and explaining are distinct, although this is not necessary. We observe that our problem is a monotonic optimization where the objective function is a difference of monotonic functions. We then propose an efficient branch-and-bound algorithm for finding the best parameters that lead to a balance of clustering accuracy and decision tree explainability. Our experiments show that our method can improve the explainability of any clustering that fits in our framework.","https://ojs.aaai.org/index.php/AAAI/article/view/25963/25735"
"25964","Model-Based Reinforcement Learning with Multinomial Logistic Function Approximation","['Taehyun Hwang', 'Min-hwan Oh']","['Seoul National University', 'Seoul National University']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms']","Hwang, T., & Oh, M.- hwan. (2023). Model-Based Reinforcement Learning with Multinomial Logistic Function Approximation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7971-7979. https://doi.org/10.1609/aaai.v37i7.25964","Abstract 					We study model-based reinforcement learning (RL) for episodic Markov decision processes (MDP) whose transition probability is parametrized by an unknown transition core with features of state and action. Despite much recent progress in analyzing algorithms in the linear MDP setting, the understanding of more general transition models is very restrictive. In this paper, we propose a provably efficient RL algorithm for the MDP whose state transition is given by a multinomial logistic model. We show that our proposed algorithm based on the upper confidence bounds achieves O(d√(H^3 T)) regret bound where d is the dimension of the transition core, H is the horizon, and T is the total number of steps. To the best of our knowledge, this is the first model-based RL algorithm with multinomial logistic function approximation with provable guarantees. We also comprehensively evaluate our proposed algorithm numerically and show that it consistently outperforms the existing methods, hence achieving both provable efficiency and practical superior performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25964/25736"
"25965","Fast Regularized Discrete Optimal Transport with Group-Sparse Regularizers","['Yasutoshi Ida', 'Sekitoshi Kanai', 'Kazuki Adachi', 'Atsutoshi Kumagai', 'Yasuhiro Fujiwara']","['NTT Computer and Data Science Laboratories', 'NTT Computer and Data Science Laboratories', 'NTT Computer and Data Science Laboratories', 'NTT Computer and Data Science Laboratories', 'NTT Communication Science Laboratories']","['ML: Optimization', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Dimensionality Reduction/Feature Selection', 'ML: Matrix & Tensor Methods']","Ida, Y., Kanai, S., Adachi, K., Kumagai, A., & Fujiwara, Y. (2023). Fast Regularized Discrete Optimal Transport with Group-Sparse Regularizers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7980-7987. https://doi.org/10.1609/aaai.v37i7.25965","Abstract 					Regularized discrete optimal transport (OT) is a powerful tool to measure the distance between two discrete distributions that have been constructed from data samples on two different domains. While it has a wide range of applications in machine learning, in some cases the sampled data from only one of the domains will have class labels such as unsupervised domain adaptation. In this kind of problem setting, a group-sparse regularizer is frequently leveraged as a regularization term to handle class labels. In particular, it can preserve the label structure on the data samples by corresponding the data samples with the same class label to one group-sparse regularization term. As a result, we can measure the distance while utilizing label information by solving the regularized optimization problem with gradient-based algorithms. However, the gradient computation is expensive when the number of classes or data samples is large because the number of regularization terms and their respective sizes also turn out to be large. This paper proposes fast discrete OT with group-sparse regularizers. Our method is based on two ideas. The first is to safely skip the computations of the gradients that must be zero. The second is to efficiently extract the gradients that are expected to be nonzero. Our method is guaranteed to return the same value of the objective function as that of the original approach. Experiments demonstrate that our method is up to 8.6 times faster than the original method without degrading accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25965/25737"
"25966","Neural Representations Reveal Distinct Modes of Class Fitting in Residual Convolutional Networks","['Michał Jamroż', 'Marcin Kurdziel']","['AGH University of Science and Technology, Krakow, Poland', 'AGH University of Science and Technology, Krakow, Poland']","['ML: Representation Learning', 'ML: Adversarial Learning & Robustness', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms', 'ML: Probabilistic Methods']","Jamroż, M., & Kurdziel, M. (2023). Neural Representations Reveal Distinct Modes of Class Fitting in Residual Convolutional Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7988-7995. https://doi.org/10.1609/aaai.v37i7.25966","Abstract 					We leverage probabilistic models of neural representations to investigate how residual networks fit classes. To this end, we estimate class-conditional density models for representations learned by deep ResNets. We then use these models to characterize distributions of representations across learned classes. Surprisingly, we find that classes in the investigated models are not fitted in a uniform way. On the contrary: we uncover two groups of classes that are fitted with markedly different distributions of representations. These distinct modes of class-fitting are evident only in the deeper layers of the investigated models, indicating that they are not related to low-level image features. We show that the uncovered structure in neural representations correlate with memorization of training examples and adversarial robustness. Finally, we compare class-conditional distributions of neural representations between memorized and typical examples. This allows us to uncover where in the network structure class labels arise for memorized and standard inputs.","https://ojs.aaai.org/index.php/AAAI/article/view/25966/25738"
"25967","Audio-Visual Contrastive Learning with Temporal Self-Supervision","['Simon Jenni', 'Alexander Black', 'John Collomosse']","['Adobe Research', 'University of Surrey', 'Adobe Research\nUniversity of Surrey']","['ML: Unsupervised & Self-Supervised Learning', 'CV: Image and Video Retrieval', 'CV: Multi-modal Vision', 'CV: Representation Learning for Vision', 'CV: Video Understanding & Activity Analysis']","Jenni, S., Black, A., & Collomosse, J. (2023). Audio-Visual Contrastive Learning with Temporal Self-Supervision. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 7996-8004. https://doi.org/10.1609/aaai.v37i7.25967","Abstract 					We propose a self-supervised learning approach for videos that learns representations of both the RGB frames and the accompanying audio without human supervision.    In contrast to images that capture the static scene appearance, videos also contain sound and temporal scene dynamics.   To leverage the temporal and aural dimension inherent to videos, our method extends temporal self-supervision to the audio-visual setting and integrates it with multi-modal contrastive objectives. As temporal self-supervision, we pose playback speed and direction recognition in both modalities and propose intra- and inter-modal temporal ordering tasks.  Furthermore, we design a novel contrastive objective in which the usual pairs are supplemented with additional sample-dependent positives and negatives sampled from the evolving feature space.  In our model, we apply such losses among video clips and between videos and their temporally corresponding audio clips.  We verify our model design in extensive ablation experiments and evaluate the video and audio representations in transfer experiments to action recognition and retrieval on UCF101 and HMBD51, audio classification on ESC50, and robust video fingerprinting on VGG-Sound, with state-of-the-art results.","https://ojs.aaai.org/index.php/AAAI/article/view/25967/25739"
"25968","Confidence-Aware Training of Smoothed Classifiers for Certified Robustness","['Jongheon Jeong', 'Seojin Kim', 'Jinwoo Shin']","['KAIST', 'KAIST', 'KAIST']","['ML: Adversarial Learning & Robustness', 'CV: Adversarial Attacks & Robustness', 'PEAI: Safety', 'Robustness & Trustworthiness']","Jeong, J., Kim, S., & Shin, J. (2023). Confidence-Aware Training of Smoothed Classifiers for Certified Robustness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8005-8013. https://doi.org/10.1609/aaai.v37i7.25968","Abstract 					Any classifier can be ""smoothed out"" under Gaussian noise to build a new classifier that is provably robust to l2-adversarial perturbations, viz., by averaging its predictions over the noise via randomized smoothing. Under the smoothed classifiers, the fundamental trade-off between accuracy and (adversarial) robustness has been well evidenced in the literature: i.e., increasing the robustness of a classifier for an input can be at the expense of decreased accuracy for some other inputs. In this paper, we propose a simple training method leveraging this trade-off to obtain robust smoothed classifiers, in particular, through a sample-wise control of robustness over the training samples. We make this control feasible by using ""accuracy under Gaussian noise"" as an easy-to-compute proxy of adversarial robustness for an input. Specifically, we differentiate the training objective depending on this proxy to filter out samples that are unlikely to benefit from the worst-case (adversarial) objective. Our experiments show that the proposed method, despite its simplicity, consistently exhibits improved certified robustness upon state-of-the-art training methods. Somewhat surprisingly, we find these improvements persist even for other notions of robustness, e.g., to various types of common corruptions. Code is available at https://github.com/alinlab/smoothing-catrs.","https://ojs.aaai.org/index.php/AAAI/article/view/25968/25740"
"25969","Learnable Path in Neural Controlled Differential Equations","['Sheo Yon Jhin', 'Minju Jo', 'Seungji Kook', 'Noseong Park']","['Yonsei University, Korea', 'Yonsei University, Korea', 'Yonsei University, Korea', 'Yonsei University, Korea']","['ML: Time-Series/Data Streams', 'ML: Deep Neural Architectures']","Jhin, S. Y., Jo, M., Kook, S., & Park, N. (2023). Learnable Path in Neural Controlled Differential Equations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8014-8022. https://doi.org/10.1609/aaai.v37i7.25969","Abstract 					Neural controlled differential equations (NCDEs), which are continuous analogues to recurrent neural networks (RNNs), are a specialized model in (irregular) time-series processing. In comparison with similar models, e.g., neural ordinary differential equations (NODEs), the key distinctive characteristics of NCDEs are i) the adoption of the continuous path created by an interpolation algorithm from each raw discrete time-series sample and ii) the adoption of the Riemann--Stieltjes integral. It is the continuous path which makes NCDEs be analogues to continuous RNNs. However, NCDEs use existing interpolation algorithms to create the path, which is unclear whether they can create an optimal path. To this end, we present a method to generate another latent path (rather than relying on existing interpolation algorithms), which is identical to learning an appropriate interpolation method. We design an encoder-decoder module based on NCDEs and NODEs, and a special training method for it. Our method shows the best performance in both time-series classification and forecasting.","https://ojs.aaai.org/index.php/AAAI/article/view/25969/25741"
"25970","DrugOOD: Out-of-Distribution Dataset Curator and Benchmark for AI-Aided Drug Discovery – a Focus on Affinity Prediction Problems with Noise Annotations","['Yuanfeng Ji', 'Lu Zhang', 'Jiaxiang Wu', 'Bingzhe Wu', 'Lanqing Li', 'Long-Kai Huang', 'Tingyang Xu', 'Yu Rong', 'Jie Ren', 'Ding Xue', 'Houtim Lai', 'Wei Liu', 'Junzhou Huang', 'Shuigeng Zhou', 'Ping Luo', 'Peilin Zhao', 'Yatao Bian']","['HKU, Tencent AI Lab', 'Fudan University, Tencent AI Lab', 'Tencent AI Lab', 'Tencent AI Lab', 'Tencent', 'Tencent AI Lab', 'Tencent AI Lab', 'Tencent AI Lab', 'Tencent AI Lab', 'Tencent AI Lab', 'Tencent AI Lab', 'Tencent AI Lab', 'University of Texas at Arlington', 'Fudan University', 'The University of Hong Kong', 'Tencent AI Lab', 'Tencent AI Lab']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'APP: Bioinformatics', 'APP: Healthcare', 'Medicine & Wellness', 'ML: Applications']","Ji, Y., Zhang, L., Wu, J., Wu, B., Li, L., Huang, L.-K., Xu, T., Rong, Y., Ren, J., Xue, D., Lai, H., Liu, W., Huang, J., Zhou, S., Luo, P., Zhao, P., & Bian, Y. (2023). DrugOOD: Out-of-Distribution Dataset Curator and Benchmark for AI-Aided Drug Discovery – a Focus on Affinity Prediction Problems with Noise Annotations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8023-8031. https://doi.org/10.1609/aaai.v37i7.25970","Abstract 					AI-aided drug discovery (AIDD) is gaining popularity due to its potential to make the search for new pharmaceuticals faster, less expensive, and more effective. Despite its extensive use in numerous fields (e.g., ADMET prediction, virtual screening), little research has been conducted on the out-of-distribution (OOD) learning problem with noise. We present DrugOOD, a systematic OOD dataset curator and benchmark for AIDD. Particularly, we focus on the drug-target binding affinity prediction problem, which involves both macromolecule (protein target) and small-molecule (drug compound). DrugOOD offers an automated dataset curator with user-friendly customization scripts, rich domain annotations aligned with biochemistry knowledge, realistic noise level annotations, and rigorous benchmarking of SOTA OOD algorithms, as opposed to only providing fixed datasets. Since the molecular data is often modeled as irregular graphs using graph neural network (GNN) backbones, DrugOOD also serves as a valuable testbed for graph OOD learning problems. Extensive empirical studies have revealed a significant performance gap between in-distribution and out-of-distribution experiments, emphasizing the need for the development of more effective schemes that permit OOD generalization under noise for AIDD.","https://ojs.aaai.org/index.php/AAAI/article/view/25970/25742"
"25971","MNER-QG: An End-to-End MRC Framework for Multimodal Named Entity Recognition with Query Grounding","['Meihuizi Jia', 'Lei Shen', 'Xin Shen', 'Lejian Liao', 'Meng Chen', 'Xiaodong He', 'Zhendong Chen', 'Jiaqi Li']","['Beijing Institute of Technology', 'JD AI, Beijing, China', 'Australian National University', 'School of Computer Science, Beijing Institute of Technology', 'JD AI', 'JD AI, Beijing', 'Beijing Institute of Technology', 'School of Computer Science, Beijing Institute of Technology']","['ML: Multimodal Learning', 'CV: Multi-modal Vision', 'DMKM: Mining of Visual', 'Multimedia & Multimodal Data', 'SNLP: Information Extraction', 'SNLP: Language Grounding']","Jia, M., Shen, L., Shen, X., Liao, L., Chen, M., He, X., Chen, Z., & Li, J. (2023). MNER-QG: An End-to-End MRC Framework for Multimodal Named Entity Recognition with Query Grounding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8032-8040. https://doi.org/10.1609/aaai.v37i7.25971","Abstract 					Multimodal named entity recognition (MNER) is a critical step in information extraction, which aims to detect entity spans and classify them to corresponding entity types given a sentence-image pair. Existing methods either (1) obtain named entities with coarse-grained visual clues from attention mechanisms, or (2) first detect fine-grained visual regions with toolkits and then recognize named entities. However, they suffer from improper alignment between entity types and visual regions or error propagation in the two-stage manner, which finally imports irrelevant visual information into texts. In this paper, we propose a novel end-to-end framework named MNER-QG that can simultaneously perform MRC-based multimodal named entity recognition and query grounding. Specifically, with the assistance of queries, MNER-QG can provide prior knowledge of entity types and visual regions, and further enhance representations of both text and image. To conduct the query grounding task, we provide manual annotations and weak supervisions that are obtained via training a highly flexible visual grounding model with transfer learning. We conduct extensive experiments on two public MNER datasets, Twitter2015 and Twitter2017. Experimental results show that MNER-QG outperforms the current state-of-the-art models on the MNER task, and also improves the query grounding performance.","https://ojs.aaai.org/index.php/AAAI/article/view/25971/25743"
"25972","Learning from Training Dynamics: Identifying Mislabeled Data beyond Manually Designed Features","['Qingrui Jia', 'Xuhong Li', 'Lei Yu', 'Jiang Bian', 'Penghao Zhao', 'Shupeng Li', 'Haoyi Xiong', 'Dejing Dou']","['Sino-French Engineer School, Beihang University\nBaidu Inc.', 'Baidu Inc.', 'Beihang University\nBeihang Hangzhou Innovation Institute Yuhang', 'Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.', 'BCG Greater China']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'CV: Interpretability and Transparency']","Jia, Q., Li, X., Yu, L., Bian, J., Zhao, P., Li, S., Xiong, H., & Dou, D. (2023). Learning from Training Dynamics: Identifying Mislabeled Data beyond Manually Designed Features. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8041-8049. https://doi.org/10.1609/aaai.v37i7.25972","Abstract 					While mislabeled or ambiguously-labeled samples in the training set could negatively affect the performance of deep models, diagnosing the dataset and identifying mislabeled samples helps to improve the generalization power. Training dynamics, i.e., the traces left by iterations of optimization algorithms, have recently been proved to be effective to localize mislabeled samples with hand-crafted features. In this paper, beyond manually designed features, we introduce a novel learning-based solution, leveraging a noise detector, instanced by an LSTM network, which learns to predict whether a sample was mislabeled using the raw training dynamics as input.  Specifically, the proposed method trains the noise detector in a supervised manner using the dataset with synthesized label noises and can adapt to various datasets (either naturally or synthesized label-noised) without retraining.  We conduct extensive experiments to evaluate the proposed method. We train the noise detector based on the synthesized label-noised CIFAR dataset and test such noise detector on Tiny ImageNet, CUB-200, Caltech-256, WebVision and Clothing1M.  Results show that the proposed method precisely detects mislabeled samples on various datasets without further adaptation, and outperforms state-of-the-art methods. Besides, more experiments demonstrate that the mislabel identification can guide a label correction, namely data debugging, providing orthogonal improvements of algorithm-centric state-of-the-art techniques from the data aspect.","https://ojs.aaai.org/index.php/AAAI/article/view/25972/25744"
"25973","Online Tuning for Offline Decentralized Multi-Agent Reinforcement Learning","['Jiechuan Jiang', 'Zongqing Lu']","['Peking University', 'Peking University']","['ML: Reinforcement Learning Algorithms', 'MAS: Multiagent Learning']","Jiang, J., & Lu, Z. (2023). Online Tuning for Offline Decentralized Multi-Agent Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8050-8059. https://doi.org/10.1609/aaai.v37i7.25973","Abstract 					Offline reinforcement learning could learn effective policies from a fixed dataset, which is promising for real-world applications. However, in offline decentralized multi-agent reinforcement learning, due to the discrepancy between the behavior policy and learned policy, the transition dynamics in offline experiences do not accord with the transition dynamics in online execution, which creates severe errors in value estimates, leading to uncoordinated low-performing policies. One way to overcome this problem is to bridge offline training and online tuning. However, considering both deployment efficiency and sample efficiency, we could only collect very limited online experiences, making it insufficient to use merely online data for updating the agent policy. To utilize both offline and online experiences to tune the policies of agents, we introduce online transition correction (OTC) to implicitly correct the offline transition dynamics by modifying sampling probabilities. We design two types of distances, i.e., embedding-based and value-based distance, to measure the similarity between transitions, and further propose an adaptive rank-based prioritization to sample transitions according to the transition similarity. OTC is simple yet effective to increase data efficiency and improve agent policies in online tuning. Empirically, OTC outperforms baselines in a variety of tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/25973/25745"
"25974","Robust Domain Adaptation for Machine Reading Comprehension","['Liang Jiang', 'Zhenyu Huang', 'Jia Liu', 'Zujie Wen', 'Xi Peng']","['Ant Group', 'College of Computer Science, Sichuan University', 'Ant Group', 'Ant Group', 'College of Computer Science, Sichuan University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Unsupervised & Self-Supervised Learning']","Jiang, L., Huang, Z., Liu, J., Wen, Z., & Peng, X. (2023). Robust Domain Adaptation for Machine Reading Comprehension. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8060-8069. https://doi.org/10.1609/aaai.v37i7.25974","Abstract 					Most domain adaptation methods for machine reading comprehension (MRC) use a pre-trained question-answer (QA) construction model to generate pseudo QA pairs for MRC transfer. Such a process will inevitably introduce mismatched pairs (i.e., Noisy Correspondence) due to i) the unavailable QA pairs in target documents, and ii) the domain shift during applying the QA construction model to the target domain. Undoubtedly, the noisy correspondence will degenerate the performance of MRC, which however is neglected by existing works. To solve such an untouched problem, we propose to construct QA pairs by additionally using the dialogue related to the documents, as well as a new domain adaptation method for MRC. Specifically, we propose Robust Domain Adaptation for Machine Reading Comprehension (RMRC) method which consists of an answer extractor (AE), a question selector (QS), and an MRC model. Specifically, RMRC filters out the irrelevant answers by estimating the correlation to the document via the AE, and extracts the questions by fusing the candidate questions in multiple rounds of dialogue chats via the QS. With the extracted QA pairs, MRC is fine-tuned and provides the feedback to optimize the QS through a novel reinforced self-training method. Thanks to the optimization of the QS, our method will greatly alleviate the noisy correspondence problem caused by the domain shift. To the best of our knowledge, this could be the first study to reveal the influence of noisy correspondence in domain adaptation MRC models and show a feasible solution to achieve the robustness against the mismatched pairs. Extensive experiments on three datasets demonstrate the effectiveness of our method.","https://ojs.aaai.org/index.php/AAAI/article/view/25974/25746"
"25975","Multi-View MOOC Quality Evaluation via Information-Aware Graph Representation Learning","['Lu Jiang', 'Yibin Wang', 'Jianan Wang', 'Pengyang Wang', 'Minghao Yin']","['Northeast Normal University', 'Northeast Normal University', 'Northeast Normal University', 'University of Macau', 'Northeast Normal University']","['ML: Active Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Graph-based Machine Learning', 'ML: Representation Learning']","Jiang, L., Wang, Y., Wang, J., Wang, P., & Yin, M. (2023). Multi-View MOOC Quality Evaluation via Information-Aware Graph Representation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8070-8077. https://doi.org/10.1609/aaai.v37i7.25975","Abstract 					In this paper, we study the problem of MOOC quality evaluation that is essential for improving the course materials, promoting students' learning efficiency, and benefiting user services.  While achieving promising performances, current works still suffer from the complicated interactions and relationships of entities in MOOC platforms.  To tackle the challenges, we formulate the problem as a course representation learning task based, and develop an Information-aware Graph Representation Learning(IaGRL) for multi-view MOOC quality evaluation.  Specifically, We first build a MOOC Heterogeneous Network (HIN) to represent the interactions and relationships among entities in MOOC platforms.  And then we decompose the MOOC HIN into multiple single-relation graphs based on meta-paths to depict multi-view semantics of courses.  The course representation learning can be further converted to a multi-view graph representation task.  Different from traditional graph representation learning, the learned course representations are expected to match the following three types of validity:  (1) the agreement on expressiveness between the raw course portfolio and the learned course representations;  (2) the consistency between the representations in each view and the unified representations;  (3) the alignment between the course and MOOC platform representations.  Therefore, we propose to exploit mutual information for preserving the validity of course representations.  We conduct extensive experiments over real-world MOOC datasets to demonstrate the effectiveness of our proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/25975/25747"
"25976","Spatio-Temporal Meta-Graph Learning for Traffic Forecasting","['Renhe Jiang', 'Zhaonan Wang', 'Jiawei Yong', 'Puneet Jeph', 'Quanjun Chen', 'Yasumasa Kobayashi', 'Xuan Song', 'Shintaro Fukushima', 'Toyotaro Suzumura']","['The University of Tokyo', 'The University of Tokyo', 'Toyota Motor Corporation', 'The University of Tokyo', 'The University of Tokyo', 'Toyota Motor Corporation', 'The University of Tokyo', 'Toyota Motor Corporation', 'The University of Tokyo']","['ML: Time-Series/Data Streams', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'KRR: Geometric', 'Spatial', 'and Temporal Reasoning', 'ML: Graph-based Machine Learning']","Jiang, R., Wang, Z., Yong, J., Jeph, P., Chen, Q., Kobayashi, Y., Song, X., Fukushima, S., & Suzumura, T. (2023). Spatio-Temporal Meta-Graph Learning for Traffic Forecasting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8078-8086. https://doi.org/10.1609/aaai.v37i7.25976","Abstract 					Traffic forecasting as a canonical task of multivariate time series forecasting has been a significant research topic in AI community. To address the spatio-temporal heterogeneity and non-stationarity implied in the traffic stream, in this study, we propose Spatio-Temporal Meta-Graph Learning as a novel Graph Structure Learning mechanism on spatio-temporal data. Specifically, we implement this idea into Meta-Graph Convolutional Recurrent Network (MegaCRN) by plugging the Meta-Graph Learner powered by a Meta-Node Bank into GCRN encoder-decoder. We conduct a comprehensive evaluation on two benchmark datasets (i.e., METR-LA and PEMS-BAY) and a new large-scale traffic speed dataset called EXPY-TKY that covers 1843 expressway road links in Tokyo. Our model outperformed the state-of-the-arts on all three datasets. Besides, through a series of qualitative evaluations, we demonstrate that our model can explicitly disentangle the road links and time slots with different patterns and be robustly adaptive to any anomalous traffic situations. Codes and datasets are available at https://github.com/deepkashiwa20/MegaCRN.","https://ojs.aaai.org/index.php/AAAI/article/view/25976/25748"
"25977","Complement Sparsification: Low-Overhead Model Pruning for Federated Learning","['Xiaopeng Jiang', 'Cristian Borcea']","['New Jersey Institute of Technology', 'New Jersey Institute of Technology']","['ML: Distributed Machine Learning & Federated Learning', 'ML: Learning on the Edge & Model Compression']","Jiang, X., & Borcea, C. (2023). Complement Sparsification: Low-Overhead Model Pruning for Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8087-8095. https://doi.org/10.1609/aaai.v37i7.25977","Abstract 					Federated Learning (FL) is a privacy-preserving distributed deep learning paradigm that involves substantial communication and computation effort, which is a problem for resource-constrained mobile and IoT devices. Model pruning/sparsification develops sparse models that could solve this problem, but existing sparsification solutions cannot satisfy at the same time the requirements for low bidirectional communication overhead between the server and the clients, low computation overhead at the clients, and good model accuracy, under the FL assumption that the server does not have access to raw data to fine-tune the pruned models. We propose Complement Sparsification (CS), a pruning mechanism that satisfies all these requirements through a complementary and collaborative pruning done at the server and the clients.  At each round, CS creates a global sparse model that contains the weights that capture the general data distribution of all clients, while the clients create local sparse models with the weights pruned from the global model to capture the local trends. For improved model performance, these two types of complementary sparse models are aggregated into a dense model in each round, which is subsequently pruned in an iterative process. CS requires little computation overhead on the top of vanilla FL for both the server and the clients. We demonstrate that CS is an approximation of vanilla FL and, thus, its models perform well. We evaluate CS experimentally with two popular FL benchmark datasets. CS achieves substantial reduction in bidirectional communication, while achieving performance comparable with vanilla FL. In addition, CS outperforms baseline pruning mechanisms for FL.","https://ojs.aaai.org/index.php/AAAI/article/view/25977/25749"
"25978","Energy-Motivated Equivariant Pretraining for 3D Molecular Graphs","['Rui Jiao', 'Jiaqi Han', 'Wenbing Huang', 'Yu Rong', 'Yang Liu']","['Beijing National Research Center for Information Science and Technology (BNRist), Department of Computer Science and Technology, Tsinghua University\nInstitute for AI Industry Research (AIR), Tsinghua University', 'Beijing National Research Center for Information Science and Technology (BNRist), Department of Computer Science and Technology, Tsinghua University\nInstitute for AI Industry Research (AIR), Tsinghua University', 'Gaoling School of Artificial Intelligence, Renmin University of China\nBeijing Key Laboratory of Big Data Management and Analysis Methods', 'Tencent AI Lab', 'Beijing National Research Center for Information Science and Technology (BNRist), Department of Computer Science and Technology, Tsinghua University\nInstitute for AI Industry Research (AIR), Tsinghua University\nBeijing Academy of Artificial Intelligence']","['ML: Graph-based Machine Learning', 'ML: Unsupervised & Self-Supervised Learning']","Jiao, R., Han, J., Huang, W., Rong, Y., & Liu, Y. (2023). Energy-Motivated Equivariant Pretraining for 3D Molecular Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8096-8104. https://doi.org/10.1609/aaai.v37i7.25978","Abstract 					Pretraining molecular representation models without labels is fundamental to various applications. Conventional methods mainly process 2D molecular graphs and focus solely on 2D tasks, making their pretrained models incapable of characterizing 3D geometry and thus defective for downstream 3D tasks. In this work, we tackle 3D molecular pretraining in a complete and novel sense. In particular, we first propose to adopt an equivariant energy-based model as the backbone for pretraining, which enjoys the merits of fulfilling the symmetry of 3D space. Then we develop a node-level pretraining loss for force prediction, where we further exploit the Riemann-Gaussian distribution to ensure the loss to be E(3)-invariant, enabling more robustness. Moreover, a graph-level noise scale prediction task is also leveraged to further promote the eventual performance. We evaluate our model pretrained from a large-scale 3D dataset GEOM-QM9 on two challenging 3D benchmarks: MD17 and QM9. Experimental results demonstrate the efficacy of our method against current state-of-the-art pretraining approaches, and verify the validity of our design for each proposed component. Code is available at https://github.com/jiaor17/3D-EMGP.","https://ojs.aaai.org/index.php/AAAI/article/view/25978/25750"
"25979","Local-Global Defense against Unsupervised Adversarial Attacks on Graphs","['Di Jin', 'Bingdao Feng', 'Siqi Guo', 'Xiaobao Wang', 'Jianguo Wei', 'Zhen Wang']","['College of Intelligence and Computing, Tianjin University, Tianjin, China', 'College of Intelligence and Computing, Tianjin University, Tianjin, China', 'College of Intelligence and Computing, Tianjin University, Tianjin, China', 'College of Intelligence and Computing, Tianjin University, Tianjin, China', 'College of Intelligence and Computing, Tianjin University, Tianjin, China', 'School of Cybersecurity, Northwestern Polytechnical University, Xi’an, Shaanxi, China']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Adversarial Learning & Robustness']","Jin, D., Feng, B., Guo, S., Wang, X., Wei, J., & Wang, Z. (2023). Local-Global Defense against Unsupervised Adversarial Attacks on Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8105-8113. https://doi.org/10.1609/aaai.v37i7.25979","Abstract 					Unsupervised pre-training algorithms for graph representation learning are vulnerable to adversarial attacks, such as first-order perturbations on graphs, which will have an impact on particular downstream applications. Designing an effective representation learning strategy against white-box attacks remains a crucial open topic. Prior research attempts to improve representation robustness by maximizing mutual information between the representation and the perturbed graph, which is sub-optimal because it does not adapt its defense techniques to the severity of the attack. To address this issue, we propose an unsupervised defense method that combines local and global defense to improve the robustness of representation. Note that we put forward the Perturbed Edges Harmfulness (PEH) metric to determine the riskiness of the attack. Thus, when the edges are attacked, the model can automatically identify the risk of attack. We present a method of attention-based protection against high-risk attacks that penalizes attention coefficients of perturbed edges to encoders. Extensive experiments demonstrate that our strategies can enhance the robustness of representation against various adversarial attacks on three benchmark graphs.","https://ojs.aaai.org/index.php/AAAI/article/view/25979/25751"
"25980","Trafformer: Unify Time and Space in Traffic Prediction","['Di Jin', 'Jiayi Shi', 'Rui Wang', 'Yawen Li', 'Yuxiao Huang', 'Yu-Bin Yang']","['Tianjin University,\nNanjing University', 'Tianjin University', 'Tianjin University', 'Beijing University of Posts and Telecommunications', 'George Washington University', 'State Key Laboratory for Novel Software Technology, Nanjing University']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'APP: Transportation']","Jin, D., Shi, J., Wang, R., Li, Y., Huang, Y., & Yang, Y.-B. (2023). Trafformer: Unify Time and Space in Traffic Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8114-8122. https://doi.org/10.1609/aaai.v37i7.25980","Abstract 					Traffic prediction is an important component of the intelligent transportation system. Existing deep learning methods encode temporal information and spatial information separately or iteratively. However, the spatial and temporal information is highly correlated in a traffic network, so existing methods may not learn the complex spatial-temporal dependencies hidden in the traffic network due to the decomposed model design. To overcome this limitation, we propose a new model named Trafformer, which unifies spatial and temporal information in one transformer-style model. Trafformer enables every node at every timestamp interact with every other node in every other timestamp in just one step in the spatial-temporal correlation matrix. This design enables Trafformer to catch complex spatial-temporal dependencies. Following the same design principle, we use the generative style decoder to predict multiple timestamps in only one forward operation instead of the iterative style decoder in Transformer. Furthermore, to reduce the complexity brought about by the huge spatial-temporal self-attention matrix, we also propose two variants of Trafformer to further improve the training and inference speed without losing much effectivity. Extensive experiments on two traffic datasets demonstrate that Trafformer outperforms existing methods and provides a promising future direction for the spatial-temporal traffic prediction problem.","https://ojs.aaai.org/index.php/AAAI/article/view/25980/25752"
"25981","On Solution Functions of Optimization: Universal Approximation and Covering Number Bounds","['Ming Jin', 'Vanshaj Khattar', 'Harshal Kaushik', 'Bilgehan Sel', 'Ruoxi Jia']","['Virginia Tech', 'Virginia Tech', 'Virginia Tech', 'Virginia Tech', 'Virginia Tech']","['ML: Optimization', 'ML: Learning Theory', 'ML: Other Foundations of Machine Learning']","Jin, M., Khattar, V., Kaushik, H., Sel, B., & Jia, R. (2023). On Solution Functions of Optimization: Universal Approximation and Covering Number Bounds. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8123-8131. https://doi.org/10.1609/aaai.v37i7.25981","Abstract 					We study the expressibility and learnability of solution functions of convex optimization and their multi-layer architectural extension. The main results are: (1) the class of solution functions of linear programming (LP) and quadratic programming (QP) is a universal approximant for the smooth model class or some restricted Sobolev space, and we characterize the rate-distortion, (2) the approximation power is investigated through a viewpoint of regression error, where information about the target function is provided in terms of data observations, (3) compositionality in the form of deep architecture with optimization as a layer is shown to reconstruct some basic functions used in numerical analysis without error, which implies that (4) a substantial reduction in rate-distortion can be achieved with a universal network architecture, and (5) we discuss the statistical bounds of empirical covering numbers for LP/QP, as well as a generic optimization problem (possibly nonconvex) by exploiting tame geometry. Our results provide the **first rigorous analysis of the approximation and learning-theoretic properties of solution functions** with implications for algorithmic design and performance guarantees.","https://ojs.aaai.org/index.php/AAAI/article/view/25981/25753"
"25982","Pointerformer: Deep Reinforced Multi-Pointer Transformer for the Traveling Salesman Problem","['Yan Jin', 'Yuandong Ding', 'Xuanhao Pan', 'Kun He', 'Li Zhao', 'Tao Qin', 'Lei Song', 'Jiang Bian']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Microsoft Research', 'Microsoft Research Asia', 'Microsoft Research', 'Microsoft Research']","['ML: Reinforcement Learning Algorithms']","Jin, Y., Ding, Y., Pan, X., He, K., Zhao, L., Qin, T., Song, L., & Bian, J. (2023). Pointerformer: Deep Reinforced Multi-Pointer Transformer for the Traveling Salesman Problem. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8132-8140. https://doi.org/10.1609/aaai.v37i7.25982","Abstract 					Traveling Salesman Problem (TSP), as a classic routing optimization problem originally arising in the domain of transportation and logistics, has become a critical task in broader domains, such as manufacturing and biology. Recently, Deep Reinforcement Learning (DRL) has been increasingly employed to solve TSP due to its high inference efficiency. Nevertheless, most of existing end-to-end DRL algorithms only perform well on small TSP instances and can hardly generalize to large scale because of the drastically soaring memory consumption and computation time along with the enlarging problem scale. In this paper, we propose a novel end-to-end DRL approach, referred to as Pointerformer, based on multi-pointer Transformer. Particularly, Pointerformer adopts both reversible residual network in the encoder and multi-pointer network in the decoder to effectively contain memory consumption of the encoder-decoder architecture. To further improve the performance of TSP solutions, Pointerformer employs a feature augmentation method to explore the symmetries of TSP at both training and inference stages as well as an enhanced context embedding approach to include more comprehensive context information in the query. Extensive experiments on a randomly generated benchmark and a public benchmark have shown that, while achieving comparative results on most small-scale TSP instances as state-of-the-art DRL approaches do, Pointerformer can also well generalize to large-scale TSPs.","https://ojs.aaai.org/index.php/AAAI/article/view/25982/25754"
"25983","Knowledge-Constrained Answer Generation for Open-Ended Video Question Answering","['Yao Jin', 'Guocheng Niu', 'Xinyan Xiao', 'Jian Zhang', 'Xi Peng', 'Jun Yu']","['Hangzhou Dianzi University', 'Baidu Inc.', 'Baidu Inc.', 'Zhejiang International Studies University', 'College of Computer Science, Sichuan Univerisity', 'Hangzhou Dianzi University']","['ML: Multi-Instance/Multi-View Learning', 'ML: Multimodal Learning']","Jin, Y., Niu, G., Xiao, X., Zhang, J., Peng, X., & Yu, J. (2023). Knowledge-Constrained Answer Generation for Open-Ended Video Question Answering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8141-8149. https://doi.org/10.1609/aaai.v37i7.25983","Abstract 					Open-ended Video question answering (open-ended VideoQA) aims to understand video content and question semantics to generate the correct answers. Most of the best performing models define the problem as a discriminative task of multi-label classification. In real-world scenarios, however, it is difficult to define a candidate set that includes all possible answers. In this paper, we propose a Knowledge-constrained Generative VideoQA Algorithm (KcGA) with an encoder-decoder pipeline, which enables out-of-domain answer generation through an adaptive external knowledge module and a multi-stream information control mechanism. We use ClipBERT to extract the video-question features, extract framewise object-level external knowledge from a commonsense knowledge base and compute the contextual-aware episode memory units via an attention based GRU to form the external knowledge features, and exploit multi-stream information control mechanism to fuse video-question and external knowledge features such that the semantic complementation and alignment are well achieved. We evaluate our model on two open-ended benchmark datasets to demonstrate that we can effectively and robustly generate high-quality answers without restrictions of training data.","https://ojs.aaai.org/index.php/AAAI/article/view/25983/25755"
"25984","POEM: Polarization of Embeddings for Domain-Invariant Representations","['Sang-Yeong Jo', 'Sung Whan Yoon']","['Ulsan National Institute of Science and Technology (UNIST), Republic of Korea', 'Ulsan National Institute of Science and Technology (UNIST), Republic of Korea']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'CV: Adversarial Attacks & Robustness', 'CV: Learning & Optimization for CV', 'CV: Representation Learning for Vision', 'ML: Adversarial Learning & Robustness', 'ML: Representation Learning']","Jo, S.-Y., & Yoon, S. W. (2023). POEM: Polarization of Embeddings for Domain-Invariant Representations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8150-8158. https://doi.org/10.1609/aaai.v37i7.25984","Abstract 					Handling out-of-distribution samples is a long-lasting challenge for deep visual models. In particular, domain generalization (DG) is one of the most relevant tasks that aims to train a model with a generalization capability on novel domains. Most existing DG approaches share the same philosophy to minimize the discrepancy between domains by finding the domain-invariant representations. On the contrary, our proposed method called POEM acquires a strong DG capability by learning domain-invariant and domain-specific representations and polarizing them. Specifically, POEM co-trains category-classifying and domain-classifying embeddings while regularizing them to be orthogonal via minimizing the cosine-similarity between their features, i.e., the polarization of embeddings. The clear separation of embeddings suppresses domain-specific features in the domain-invariant embeddings. The concept of POEM shows a unique direction to enhance the domain robustness of representations that brings considerable and consistent performance gains when combined with existing DG methods. Extensive simulation results in popular DG benchmarks with the PACS, VLCS, OfficeHome, TerraInc, and DomainNet datasets show that POEM indeed facilitates the category-classifying embedding to be more domain-invariant.","https://ojs.aaai.org/index.php/AAAI/article/view/25984/25756"
"25985","An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret","['Matthew Jones', 'Huy Nguyen', 'Thy Nguyen']","['Northeastern University', 'Northeastern University', 'Northeastern University']","['ML: Bias and Fairness', 'ML: Online Learning & Bandits']","Jones, M., Nguyen, H., & Nguyen, T. (2023). An Efficient Algorithm for Fair Multi-Agent Multi-Armed Bandit with Low Regret. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8159-8167. https://doi.org/10.1609/aaai.v37i7.25985","Abstract 					Recently a multi-agent variant of the classical multi-armed bandit was proposed to tackle fairness issues in online learning. Inspired by a long line of work in social choice and economics, the goal is to optimize the Nash social welfare instead of the total utility. Unfortunately previous algorithms either are not efficient or achieve sub-optimal regret in terms of the number of rounds. We propose a new efficient algorithm with lower regret than even previous inefficient ones. We also complement our efficient algorithm with an inefficient approach with regret that matches the lower bound for one agent. The experimental findings confirm the effectiveness of our efficient algorithm compared to the previous approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/25985/25757"
"25986","Towards More Robust Interpretation via Local Gradient Alignment","['Sunghwan Joo', 'SeokHyeon Jeong', 'Juyeon Heo', 'Adrian Weller', 'Taesup Moon']","['Department of ECE, Sungkyunkwan University', 'Department of ECE, Seoul National University', 'University of Cambridge', 'University of Cambridge,\nThe Alan Turing Institute', 'Department of ECE, Seoul National University,\nASRI/INMC/IPAI/AIIS, Seoul National University']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'ML: Adversarial Learning & Robustness', 'ML: Deep Neural Network Algorithms', 'PEAI: Safety', 'Robustness & Trustworthiness']","Joo, S., Jeong, S., Heo, J., Weller, A., & Moon, T. (2023). Towards More Robust Interpretation via Local Gradient Alignment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8168-8176. https://doi.org/10.1609/aaai.v37i7.25986","Abstract 					Neural network interpretation methods, particularly feature attribution methods, are known to be fragile with respect to adversarial input perturbations.  To address this, several methods for enhancing the local smoothness of the gradient while training have been proposed for attaining robust feature attributions. However, the lack of considering the normalization of the attributions, which is essential in their visualizations, has been an obstacle to understanding and improving the robustness of feature attribution methods.  In this paper, we provide new insights by taking such normalization into account. First, we show that for every non-negative homogeneous neural network, a naive l2-robust criterion for gradients is not normalization invariant, which means that two functions with the same normalized gradient can have different values.  Second, we formulate a normalization invariant cosine distance-based criterion and derive its upper bound, which gives insight for why simply minimizing the Hessian norm at the input, as has been done in previous work, is not sufficient for attaining robust feature attribution. Finally, we propose to combine both l2 and cosine distance-based criteria as regularization terms to leverage the advantages of both in aligning the local gradient. As a result, we experimentally show that models trained with our method produce much more robust interpretations on CIFAR-10 and ImageNet-100 without significantly hurting the accuracy, compared to the recent baselines. To the best of our knowledge, this is the first work to verify the robustness of interpretation on a larger-scale dataset beyond CIFAR-10, thanks to the computational efficiency of our method.","https://ojs.aaai.org/index.php/AAAI/article/view/25986/25758"
"25987","Identifying Selection Bias from Observational Data","['David Kaltenpoth', 'Jilles Vreeken']","['CISPA Helmholtz Center for Information Security', 'CISPA Helmholtz Center for Information Security']","['ML: Causal Learning', 'RU: Causality']","Kaltenpoth, D., & Vreeken, J. (2023). Identifying Selection Bias from Observational Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8177-8185. https://doi.org/10.1609/aaai.v37i7.25987","Abstract 					Access to a representative sample from the population is an assumption that underpins all of machine learning. Selection effects can cause observations to instead come from a subpopulation, by which our inferences may be subject to bias.  It is therefore important to know whether or not a sample is affected by selection effects. We study under which conditions we can identify selection bias and give results for both parametric and non-parametric families of distributions. Based on these results we develop two practical methods to determine whether or not an observed sample comes from a distribution subject to selection bias. Through extensive evaluation on synthetic and real world data we verify that our methods beat the state of the art both in detecting as well as characterizing selection bias.","https://ojs.aaai.org/index.php/AAAI/article/view/25987/25759"
"25988","PIXEL: Physics-Informed Cell Representations for Fast and Accurate PDE Solvers","['Namgyu Kang', 'Byeonghyeon Lee', 'Youngjoon Hong', 'Seok-Bae Yun', 'Eunbyung Park']","['Sungkyunkwan University', 'Sungkyunkwan University', 'Sungkyunkwan University', 'Sungkyunkwan University', 'Sungkyunkwan University']","['ML: Applications', 'ML: Deep Neural Network Algorithms', 'APP: Natural Sciences']","Kang, N., Lee, B., Hong, Y., Yun, S.-B., & Park, E. (2023). PIXEL: Physics-Informed Cell Representations for Fast and Accurate PDE Solvers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8186-8194. https://doi.org/10.1609/aaai.v37i7.25988","Abstract 					With the increases in computational power and advances in machine learning, data-driven learning-based methods have gained significant attention in solving PDEs. Physics-informed neural networks (PINNs) have recently emerged and succeeded in various forward and inverse PDE problems thanks to their excellent properties, such as flexibility, mesh-free solutions, and unsupervised training. However, their slower convergence speed and relatively inaccurate solutions often limit their broader applicability in many science and engineering domains. This paper proposes a new kind of data-driven PDEs solver, physics-informed cell representations (PIXEL), elegantly combining classical numerical methods and learning-based approaches. We adopt a grid structure from the numerical methods to improve accuracy and convergence speed and overcome the spectral bias presented in PINNs. Moreover, the proposed method enjoys the same benefits in PINNs, e.g., using the same optimization frameworks to solve both forward and inverse PDE problems and readily enforcing PDE constraints with modern automatic differentiation techniques. We provide experimental results on various challenging PDEs that the original PINNs have struggled with and show that PIXEL achieves fast convergence speed and high accuracy. Project page: https://namgyukang.github.io/PIXEL/","https://ojs.aaai.org/index.php/AAAI/article/view/25988/25760"
"25989","On the Sample Complexity of Vanilla Model-Based Offline Reinforcement Learning with Dependent Samples","['Mustafa O. Karabag', 'Ufuk Topcu']","['The University of Texas at Austin', 'University of Texas at Austin']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms', 'PRS: Planning Under Uncertainty', 'PRS: Planning With Markov Models (MDPs', 'POMDPs)']","Karabag, M. O., & Topcu, U. (2023). On the Sample Complexity of Vanilla Model-Based Offline Reinforcement Learning with Dependent Samples. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8195-8202. https://doi.org/10.1609/aaai.v37i7.25989","Abstract 					Offline reinforcement learning (offline RL) considers problems where learning is performed using only previously collected samples and is helpful for the settings in which collecting new data is costly or risky. In model-based offline RL, the learner performs estimation (or optimization) using a model constructed according to the empirical transition frequencies. We analyze the sample complexity of vanilla model-based offline RL with dependent samples in the infinite-horizon discounted-reward setting. In our setting, the samples obey the dynamics of the Markov decision process and, consequently, may have interdependencies. Under no assumption of independent samples, we provide a high-probability, polynomial sample complexity bound for vanilla model-based off-policy evaluation that requires partial or uniform coverage. We extend this result to the off-policy optimization under uniform coverage. As a comparison to the model-based approach, we analyze the sample complexity of off-policy evaluation with vanilla importance sampling in the infinite-horizon setting. Finally, we provide an estimator that outperforms the sample-mean estimator for almost deterministic dynamics that are prevalent in reinforcement learning.","https://ojs.aaai.org/index.php/AAAI/article/view/25989/25761"
"25990","Communication-Efficient Collaborative Best Arm Identification","['Nikolai Karpov', 'Qin Zhang']","['Indiana University Bloomington', 'Indiana University Bloomington']","['ML: Online Learning & Bandits', 'ML: Distributed Machine Learning & Federated Learning', 'MAS: Agent Communication']","Karpov, N., & Zhang, Q. (2023). Communication-Efficient Collaborative Best Arm Identification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8203-8210. https://doi.org/10.1609/aaai.v37i7.25990","Abstract 					We investigate top-m arm identification, a basic problem in bandit theory, in a multi-agent learning model in which agents collaborate to learn an objective function.  We are interested in designing collaborative learning algorithms that achieve maximum speedup (compared to single-agent learning algorithms) using minimum communication cost, as communication is frequently the bottleneck in multi-agent learning.  We give both algorithmic and impossibility results, and conduct a set of experiments to demonstrate the effectiveness of our algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/25990/25762"
"25991","Variable-Based Calibration for Machine Learning Classifiers","['Markelle Kelly', 'Padhraic Smyth']","['University of California, Irvine', 'University of California, Irvine']","['ML: Calibration & Uncertainty Quantification', 'ML: Bias and Fairness']","Kelly, M., & Smyth, P. (2023). Variable-Based Calibration for Machine Learning Classifiers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8211-8219. https://doi.org/10.1609/aaai.v37i7.25991","Abstract 					The deployment of machine learning classifiers in high-stakes domains requires well-calibrated confidence scores for model predictions. In this paper we introduce the notion of variable-based calibration to characterize calibration properties of a model with respect to a variable of interest, generalizing traditional score-based metrics such as expected calibration error (ECE). In particular, we find that models with near-perfect ECE can exhibit significant miscalibration as a function of features of the data. We demonstrate this phenomenon both theoretically and in practice on multiple well-known datasets, and show that it can persist after the application of existing calibration methods. To mitigate this issue, we propose strategies for detection, visualization, and quantification of variable-based calibration error. We then examine the limitations of current score-based calibration methods and explore potential modifications. Finally, we discuss the implications of these findings, emphasizing that an understanding of calibration beyond simple aggregate measures is crucial for endeavors such as fairness and model interpretability.","https://ojs.aaai.org/index.php/AAAI/article/view/25991/25763"
"25992","Design Amortization for Bayesian Optimal Experimental Design","['Noble Kennamer', 'Steven Walton', 'Alexander Ihler']","['University of California, Irvine', 'University of Oregon', 'UC Irvine']","['ML: Probabilistic Methods', 'ML: Applications', 'ML: Bayesian Learning', 'ML: Deep Generative Models & Autoencoders']","Kennamer, N., Walton, S., & Ihler, A. (2023). Design Amortization for Bayesian Optimal Experimental Design. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8220-8227. https://doi.org/10.1609/aaai.v37i7.25992","Abstract 					Bayesian optimal experimental design is a sub-field of statistics focused on developing methods to make efficient use of experimental resources. Any potential design is evaluated in terms of a utility function, such as the (theoretically well-justified) expected information gain (EIG); unfortunately however, under most circumstances the EIG is intractable to evaluate. In this work we build off of successful variational approaches, which optimize a parameterized variational model with respect to bounds on the EIG. Past work focused on learning a new variational model from scratch for each new design considered. Here we present a novel neural architecture that allows experimenters to optimize a single variational model that can estimate the EIG for potentially infinitely many designs. To further improve computational efficiency, we also propose to train the variational model on a significantly cheaper-to-evaluate lower bound, and show empirically that the resulting model provides an excellent guide for more accurate, but expensive to evaluate  bounds on the EIG. We demonstrate the effectiveness of our technique on generalized linear models, a class of statistical models that is widely used in the analysis of controlled experiments. Experiments show that our method is able to greatly improve accuracy over existing approximation strategies, and achieve these results with far better sample efficiency.","https://ojs.aaai.org/index.php/AAAI/article/view/25992/25764"
"25993","On Error and Compression Rates for Prototype Rules","['Omer Kerem', 'Roi Weiss']","['Ben Gurion University', 'Ariel University']","['ML: Learning Theory', 'ML: Other Foundations of Machine Learning']","Kerem, O., & Weiss, R. (2023). On Error and Compression Rates for Prototype Rules. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8228-8236. https://doi.org/10.1609/aaai.v37i7.25993","Abstract 					We study the close interplay between error and compression in the non-parametric multiclass classification setting in terms of prototype learning rules. We focus in particular on a recently proposed compression-based learning rule termed OptiNet. Beyond its computational merits, this rule has been recently shown to be universally consistent in any metric instance space that admits a universally consistent rule---the first learning algorithm known to enjoy this property. However, its error and compression rates have been left open. Here we derive such rates in the case where instances reside in Euclidean space under commonly posed smoothness and tail conditions on the data distribution. We first show that OptiNet achieves non-trivial compression rates while enjoying near minimax-optimal error rates. We then proceed to study a novel general compression scheme for further compressing prototype rules that locally adapts to the noise level without sacrificing accuracy. Applying it to OptiNet, we show that under a geometric margin condition further gain in the compression rate is achieved. Experimental results comparing the performance of the various methods are presented.","https://ojs.aaai.org/index.php/AAAI/article/view/25993/25765"
"25994","CertiFair: A Framework for Certified Global Fairness of Neural Networks","['Haitham Khedr', 'Yasser Shoukry']","['University of California, Irvine', 'University of California, Irvine']","['ML: Bias and Fairness', 'ML: Adversarial Learning & Robustness']","Khedr, H., & Shoukry, Y. (2023). CertiFair: A Framework for Certified Global Fairness of Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8237-8245. https://doi.org/10.1609/aaai.v37i7.25994","Abstract 					We consider the problem of whether a Neural Network (NN) model satisfies global individual fairness. Individual Fairness (defined in (Dwork et al. 2012)) suggests that similar individuals with respect to a certain task are to be treated similarly by the decision model. In this work, we have two main objectives. The first is to construct a verifier which checks whether the fairness property holds for a given NN in a classification task or provides a counterexample if it is violated, i.e., the model is fair if all similar individuals are classified the same, and unfair if a pair of similar individuals are classified differently. To that end, we construct a sound and complete verifier that verifies global individual fairness properties of ReLU NN classifiers using distance-based similarity metrics. The second objective of this paper is to provide a method for training provably fair NN classifiers from unfair (biased) data. We propose a fairness loss that can be used during training to enforce fair outcomes for similar individuals. We then provide provable bounds on the fairness of the resulting NN. We run experiments on commonly used fairness datasets that are publicly available and we show that global individual fairness can be improved by 96 % without a significant drop in test accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/25994/25766"
"25995","Key Feature Replacement of In-Distribution Samples for Out-of-Distribution Detection","['Jaeyoung Kim', 'Seo Taek Kong', 'Dongbin Na', 'Kyu-Hwan Jung']","['VUNO Inc.', 'University of Illinois, Urbana-Champaign', 'VUNO Inc.', 'Samsung Advanced Institute for Health Sciences and Technology, Sungkyunkwan University']","['ML: Calibration & Uncertainty Quantification', 'ML: Classification and Regression']","Kim, J., Kong, S. T., Na, D., & Jung, K.-H. (2023). Key Feature Replacement of In-Distribution Samples for Out-of-Distribution Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8246-8254. https://doi.org/10.1609/aaai.v37i7.25995","Abstract 					Out-of-distribution (OOD) detection can be used in deep learning-based applications to reject outlier samples from being unreliably classified by deep neural networks. Learning to classify between OOD and in-distribution samples is difficult because data comprising the former is extremely diverse. It has been observed that an auxiliary OOD dataset is most effective in training a ``rejection'' network when its samples are semantically similar to in-distribution images. We first deduce that OOD images are perceived by a deep neural network to be semantically similar to in-distribution samples when they share a common background, as deep networks are observed to incorrectly classify such images with high confidence. We then propose a simple yet effective Key In-distribution feature Replacement BY inpainting (KIRBY) procedure that constructs a surrogate OOD dataset by replacing class-discriminative features of in-distribution samples with marginal background features. The procedure can be implemented using off-the-shelf vision algorithms, where each step within the algorithm is shown to make the surrogate data increasingly similar to in-distribution data. Design choices in each step are studied extensively, and an exhaustive comparison with state-of-the-art algorithms demonstrates KIRBY's competitiveness on various benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/25995/25767"
"25996","FLAME: Free-Form Language-Based Motion Synthesis & Editing","['Jihoon Kim', 'Jiseob Kim', 'Sungjoon Choi']","['Korea University', 'Kakao Brain Corp.', 'Korea University']","['ML: Deep Generative Models & Autoencoders', 'CV: Motion & Tracking']","Kim, J., Kim, J., & Choi, S. (2023). FLAME: Free-Form Language-Based Motion Synthesis & Editing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8255-8263. https://doi.org/10.1609/aaai.v37i7.25996","Abstract 					Text-based motion generation models are drawing a surge of interest for their potential for automating the motion-making process in the game, animation, or robot industries. In this paper, we propose a diffusion-based motion synthesis and editing model named FLAME. Inspired by the recent successes in diffusion models, we integrate diffusion-based generative models into the motion domain. FLAME can generate high-fidelity motions well aligned with the given text. Also, it can edit the parts of the motion, both frame-wise and joint-wise, without any fine-tuning. FLAME involves a new transformer-based architecture we devise to better handle motion data, which is found to be crucial to manage variable-length motions and well attend to free-form text. In experiments, we show that FLAME achieves state-of-the-art generation performances on three text-motion datasets: HumanML3D, BABEL, and KIT. We also demonstrate that FLAME’s editing capability can be extended to other tasks such as motion prediction or motion in-betweening, which have been previously covered by dedicated models.","https://ojs.aaai.org/index.php/AAAI/article/view/25996/25768"
"25997","Inverse-Reference Priors for Fisher Regularization of Bayesian Neural Networks","['Keunseo Kim', 'Eun-Yeol Ma', 'Jeongman Choi', 'Heeyoung Kim']","['Samsung Advanced Institute of Technology', 'KAIST', 'KAIST', 'KAIST']","['ML: Bayesian Learning']","Kim, K., Ma, E.-Y., Choi, J., & Kim, H. (2023). Inverse-Reference Priors for Fisher Regularization of Bayesian Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8264-8272. https://doi.org/10.1609/aaai.v37i7.25997","Abstract 					Recent studies have shown that the generalization ability of deep neural networks (DNNs) is closely related to the Fisher information matrix (FIM) calculated during the early training phase. Several methods have been proposed to regularize the FIM for increased generalization of DNNs. However, they cannot be used directly for Bayesian neural networks (BNNs) because the variable parameters of BNNs make it difficult to calculate the FIM. To address this problem, we achieve regularization of the FIM of BNNs by specifying a new suitable prior distribution called the inverse-reference (IR) prior. To regularize the FIM, the IR prior is derived as the inverse of the reference prior that imposes minimal prior knowledge on the parameters and maximizes the trace of the FIM. We demonstrate that the IR prior can enhance the generalization ability of BNNs for large-scale data over previously used priors while providing adequate uncertainty quantifications using various benchmark image datasets and BNN structures.","https://ojs.aaai.org/index.php/AAAI/article/view/25997/25769"
"25998","Deep Visual Forced Alignment: Learning to Align Transcription with Talking Face Video","['Minsu Kim', 'Chae Won Kim', 'Yong Man Ro']","['KAIST', 'KAIST', 'KAIST']","['ML: Multimodal Learning', 'CV: Language and Vision', 'CV: Multi-modal Vision', 'SNLP: Speech and Multimodality']","Kim, M., Kim, C. W., & Ro, Y. M. (2023). Deep Visual Forced Alignment: Learning to Align Transcription with Talking Face Video. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8273-8281. https://doi.org/10.1609/aaai.v37i7.25998","Abstract 					Forced alignment refers to a technology that time-aligns a given transcription with a corresponding speech. However, as the forced alignment technologies have developed using speech audio, they might fail in alignment when the input speech audio is noise-corrupted or is not accessible. We focus on that there is another component that the speech can be inferred from, the speech video (i.e., talking face video). Since the drawbacks of audio-based forced alignment can be complemented using the visual information when the audio signal is under poor condition, we try to develop a novel video-based forced alignment method. However, different from audio forced alignment, it is challenging to develop a reliable visual forced alignment technology for the following two reasons: 1) Visual Speech Recognition (VSR) has a much lower performance compared to audio-based Automatic Speech Recognition (ASR), and 2) the translation from text to video is not reliable, so the method typically used for building audio forced alignment cannot be utilized in developing visual forced alignment. In order to alleviate these challenges, in this paper, we propose a new method that is appropriate for visual forced alignment, namely Deep Visual Forced Alignment (DVFA). The proposed DVFA can align the input transcription (i.e., sentence) with the talking face video without accessing the speech audio. Moreover, by augmenting the alignment task with anomaly case detection, DVFA can detect mismatches between the input transcription and the input video while performing the alignment. Therefore, we can robustly align the text with the talking face video even if there exist error words in the text. Through extensive experiments, we show the effectiveness of the proposed DVFA not only in the alignment task but also in interpreting the outputs of VSR models.","https://ojs.aaai.org/index.php/AAAI/article/view/25998/25770"
"25999","Better Generalized Few-Shot Learning Even without Base Data","['Seong-Woong Kim', 'Dong-Wan Choi']","['Inha University', 'Inha University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Deep Neural Network Algorithms', 'ML: Meta Learning', 'ML: Representation Learning']","Kim, S.-W., & Choi, D.-W. (2023). Better Generalized Few-Shot Learning Even without Base Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8282-8290. https://doi.org/10.1609/aaai.v37i7.25999","Abstract 					This paper introduces and studies zero-base generalized few-shot learning (zero-base GFSL), which is an extreme yet practical version of few-shot learning problem. Motivated by the cases where base data is not available due to privacy or ethical issues, the goal of zero-base GFSL is to newly incorporate the knowledge of few samples of novel classes into a pretrained model without any samples of base classes. According to our analysis, we discover the fact that both mean and variance of the weight distribution of novel classes are not properly established, compared to those of base classes. The existing GFSL methods attempt to make the weight norms balanced, which we find help only the variance part, but discard the importance of mean of weights particularly for novel classes, leading to the limited performance in the GFSL problem even with base data. In this paper, we overcome this limitation by proposing a simple yet effective normalization method that can effectively control both mean and variance of the weight distribution of novel classes without using any base samples and thereby achieve a satisfactory performance on both novel and base classes. Our experimental results somewhat surprisingly show that the proposed zero-base GFSL method that does not utilize any base samples even outperforms the existing GFSL methods that make the best use of base data.  Our implementation is available at: https://github.com/bigdata-inha/Zero-Base-GFSL.","https://ojs.aaai.org/index.php/AAAI/article/view/25999/25771"
"26000","Learning Topology-Specific Experts for Molecular Property Prediction","['Suyeon Kim', 'Dongha Lee', 'SeongKu Kang', 'Seonghyeon Lee', 'Hwanjo Yu']","['Pohang University of Science and Technology (POSTECH)', 'University of Illinois at Urbana-Champaign (UIUC)', 'Pohang University of Science and Technology (POSTECH)', 'Pohang University of Science and Technology (POSTECH)', 'Pohang University of Science and Technology (POSTECH)']","['ML: Graph-based Machine Learning', 'ML: Bio-Inspired Learning', 'ML: Clustering', 'ML: Classification and Regression']","Kim, S., Lee, D., Kang, S., Lee, S., & Yu, H. (2023). Learning Topology-Specific Experts for Molecular Property Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8291-8299. https://doi.org/10.1609/aaai.v37i7.26000","Abstract 					Recently, graph neural networks (GNNs) have been successfully applied to predicting molecular properties, which is one of the most classical cheminformatics tasks with various applications. Despite their effectiveness, we empirically observe that training a single GNN model for diverse molecules with distinct structural patterns limits its prediction performance. In this paper, motivated by this observation, we propose TopExpert to leverage topology-specific prediction models (referred to as experts), each of which is responsible for each molecular group sharing similar topological semantics. That is, each expert learns topology-specific discriminative features while being trained with its corresponding topological group. To tackle the key challenge of grouping molecules by their topological patterns, we introduce a clustering-based gating module that assigns an input molecule into one of the clusters and further optimizes the gating module with two different types of self-supervision: topological semantics induced by GNNs and molecular scaffolds, respectively. Extensive experiments demonstrate that TopExpert has boosted the performance for molecular property prediction and also achieved better generalization for new molecules with unseen scaffolds than baselines. The code is available at https://github.com/kimsu55/ToxExpert.","https://ojs.aaai.org/index.php/AAAI/article/view/26000/25772"
"26001","Double Doubly Robust Thompson Sampling for Generalized Linear Contextual Bandits","['Wonyoung Kim', 'Kyungbok Lee', 'Myunghee Cho Paik']","['Columbia University', 'Seoul National University', 'Seoul National University\nShepherd23 Inc.']","['ML: Online Learning & Bandits', 'RU: Sequential Decision Making']","Kim, W., Lee, K., & Paik, M. C. (2023). Double Doubly Robust Thompson Sampling for Generalized Linear Contextual Bandits. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8300-8307. https://doi.org/10.1609/aaai.v37i7.26001","Abstract 					We propose a novel algorithm for generalized linear contextual bandits (GLBs) with a regret bound sublinear to the time horizon, the minimum eigenvalue of the covariance of contexts and a lower bound of the variance of rewards. In several identified cases, our result is the first regret bound for generalized linear bandits (GLBs) achieving the regret bound sublinear to the dimension of contexts without discarding the observed rewards. Previous approaches achieve the regret bound sublinear to the dimension of contexts by discarding the observed rewards, whereas our algorithm achieves the bound incorporating contexts from all arms in our double doubly robust (DDR) estimator. The DDR estimator is a subclass of doubly robust estimator but with a tighter error bound. We also provide a logarithmic cumulative regret bound under a probabilistic margin condition. This is the first regret bound under the margin condition for linear models or GLMs when contexts are different for all arms but coefficients are common. We conduct empirical studies using synthetic data and real examples, demonstrating the effectiveness of our algorithm.","https://ojs.aaai.org/index.php/AAAI/article/view/26001/25773"
"26002","Exploring Temporal Information Dynamics in Spiking Neural Networks","['Youngeun Kim', 'Yuhang Li', 'Hyoungseob Park', 'Yeshwanth Venkatesha', 'Anna Hambitzer', 'Priyadarshini Panda']","['Yale University', 'Yale University', 'Yale University', 'Yale university', 'Technology Innovation Institute', 'Yale University']","['ML: Bio-Inspired Learning', 'ML: Deep Neural Network Algorithms']","Kim, Y., Li, Y., Park, H., Venkatesha, Y., Hambitzer, A., & Panda, P. (2023). Exploring Temporal Information Dynamics in Spiking Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8308-8316. https://doi.org/10.1609/aaai.v37i7.26002","Abstract 					Most existing Spiking Neural Network (SNN) works state that SNNs may utilize temporal information dynamics of spikes. However, an explicit analysis of temporal information dynamics is still missing. In this paper, we ask several important questions for providing a fundamental understanding of SNNs: What are temporal information dynamics inside SNNs? How can we measure the temporal information dynamics? How do the temporal information dynamics affect the overall learning performance? To answer these questions, we estimate the Fisher Information of the weights to measure the distribution of temporal information during training in an empirical manner. Surprisingly, as training goes on, Fisher information starts to concentrate in the early timesteps. After training, we observe that information becomes highly concentrated in earlier few timesteps, a phenomenon we refer to as temporal information concentration. We observe that the temporal information concentration phenomenon is a common learning feature of SNNs by conducting extensive experiments on various configurations such as architecture, dataset, optimization strategy, time constant, and timesteps. Furthermore, to reveal how temporal information concentration affects the performance of SNNs, we design a loss function to change the trend of temporal information. We find that temporal information concentration is crucial to building a robust SNN but has little effect on classification accuracy. Finally, we propose an efficient iterative pruning method based on our observation on temporal information concentration.  Code is available at https://github.com/Intelligent-Computing-Lab-Yale/Exploring-Temporal-Information-Dynamics-in-Spiking-Neural-Networks.","https://ojs.aaai.org/index.php/AAAI/article/view/26002/25774"
"26003","FastAMI – a Monte Carlo Approach to the Adjustment for Chance in Clustering Comparison Metrics","['Kai Klede', 'Leo Schwinn', 'Dario Zanca', 'Björn Eskofier']","['Friedrich-Alexander-Universität Erlangen-Nürnberg', 'Friedrich-Alexander-Universität Erlangen-Nürnberg', 'Friedrich-Alexander-Universität Erlangen-Nürnberg', 'Friedrich-Alexander-Universität Erlangen-Nürnberg']","['ML: Clustering', 'ML: Probabilistic Methods']","Klede, K., Schwinn, L., Zanca, D., & Eskofier, B. (2023). FastAMI – a Monte Carlo Approach to the Adjustment for Chance in Clustering Comparison Metrics. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8317-8324. https://doi.org/10.1609/aaai.v37i7.26003","Abstract 					Clustering is at the very core of machine learning, and its applications proliferate with the increasing availability of data. However, as datasets grow, comparing clusterings with an adjustment for chance becomes computationally difficult, preventing unbiased ground-truth comparisons and solution selection. We propose FastAMI, a Monte Carlo-based method to efficiently approximate the Adjusted Mutual Information (AMI) and extend it to the Standardized Mutual Information (SMI). The approach is compared with the exact calculation and a recently developed variant of the AMI based on pairwise permutations, using both synthetic and real data. In contrast to the exact calculation our method is fast enough to enable these adjusted information-theoretic comparisons for large datasets while maintaining considerably more accurate results than the pairwise approach.","https://ojs.aaai.org/index.php/AAAI/article/view/26003/25775"
"26004","A Gift from Label Smoothing: Robust Training with Adaptive Label Smoothing via Auxiliary Classifier under Label Noise","['Jongwoo Ko', 'Bongsoo Yi', 'Se-Young Yun']","['KAIST', 'University of North Carolina at Chapel Hill', 'KAIST']","['ML: Adversarial Learning & Robustness', 'ML: Deep Neural Network Algorithms']","Ko, J., Yi, B., & Yun, S.-Y. (2023). A Gift from Label Smoothing: Robust Training with Adaptive Label Smoothing via Auxiliary Classifier under Label Noise. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8325-8333. https://doi.org/10.1609/aaai.v37i7.26004","Abstract 					As deep neural networks can easily overfit noisy labels, robust training in the presence of noisy labels is becoming an important challenge in modern deep learning. While existing methods address this problem in various directions, they still produce unpredictable sub-optimal results since they rely on the posterior information estimated by the feature extractor corrupted by noisy labels. Lipschitz regularization successfully alleviates this problem by training a robust feature extractor, but it requires longer training time and expensive computations. Motivated by this, we propose a simple yet effective method, called ALASCA, which efficiently provides a robust feature extractor under label noise. ALASCA integrates two key ingredients: (1) adaptive label smoothing based on our theoretical analysis that label smoothing implicitly induces Lipschitz regularization, and (2) auxiliary classifiers that enable practical application of intermediate Lipschitz regularization with negligible computations. We conduct wide-ranging experiments for ALASCA and combine our proposed method with previous noise-robust methods on several synthetic and real-world datasets. Experimental results show that our framework consistently improves the robustness of feature extractors and the performance of existing baselines with efficiency.","https://ojs.aaai.org/index.php/AAAI/article/view/26004/25776"
"26005","Grouping Matrix Based Graph Pooling with Adaptive Number of Clusters","['Sung Moon Ko', 'Sungjun Cho', 'Dae-Woong Jeong', 'Sehui Han', 'Moontae Lee', 'Honglak Lee']","['LG AI Research', 'LG AI Research', 'LG AI Research', 'LG AI Research', 'LG AI Research\nUniversity of Illinois Chicago', 'LG AI Research']","['ML: Graph-based Machine Learning', 'ML: Classification and Regression', 'ML: Clustering', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms', 'ML: Dimensionality Reduction/Feature Selection', 'ML: Matrix & Tensor Methods', 'ML: Representation Learning']","Ko, S. M., Cho, S., Jeong, D.-W., Han, S., Lee, M., & Lee, H. (2023). Grouping Matrix Based Graph Pooling with Adaptive Number of Clusters. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8334-8342. https://doi.org/10.1609/aaai.v37i7.26005","Abstract 					Graph pooling is a crucial operation for encoding hierarchical structures within graphs. Most existing graph pooling approaches formulate the problem as a node clustering task which effectively captures the graph topology. Conventional methods ask users to specify an appropriate number of clusters as a hyperparameter, then assuming that all input graphs share the same number of clusters. In inductive settings where the number of clusters could vary, however, the model should be able to represent this variation in its pooling layers in order to learn suitable clusters. Thus we propose GMPool, a novel differentiable graph pooling architecture that automatically determines the appropriate number of clusters based on the input data. The main intuition involves a grouping matrix defined as a quadratic form of the pooling operator, which induces use of binary classification probabilities of pairwise combinations of nodes. GMPool obtains the pooling operator by first computing the grouping matrix, then decomposing it. Extensive evaluations on molecular property prediction tasks demonstrate that our method outperforms conventional methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26005/25777"
"26006","The Influence of Dimensions on the Complexity of Computing Decision Trees","['Stephen G. Kobourov', 'Maarten Löffler', 'Fabrizio Montecchiani', 'Marcin Pilipczuk', 'Ignaz Rutter', 'Raimund Seidel', 'Manuel Sorge', 'Jules Wulms']","['University of Arizona', 'Utrecht University', 'Università degli Studi di Perugia', 'University of Warsaw', 'University of Passau', 'Saarland University', 'TU Wien', 'TU Wien']","['ML: Classification and Regression', 'CSO: Applications', 'ML: Optimization', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'SO: Applications']","Kobourov, S. G., Löffler, M., Montecchiani, F., Pilipczuk, M., Rutter, I., Seidel, R., Sorge, M., & Wulms, J. (2023). The Influence of Dimensions on the Complexity of Computing Decision Trees. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8343-8350. https://doi.org/10.1609/aaai.v37i7.26006","Abstract 					A decision tree recursively splits a feature space \mathbb{R}^d and then assigns class labels based on the resulting partition. Decision trees have been part of the basic machine-learning toolkit for decades. A large body of work considers heuristic algorithms that compute a decision tree from training data, usually aiming to minimize in particular the size of the resulting tree. In contrast, little is known about the complexity of the underlying computational problem of computing a minimum-size tree for the given training data. We study this problem with respect to the number d of dimensions of the feature space \mathbb{R}^d, which contains n training examples. We show that it can be solved in O(n^(2d + 1)) time, but under reasonable complexity-theoretic assumptions it is not possible to achieve f(d) * n^o(d / log d) running time. The problem is solvable in (dR)^O(dR) * n^(1+o(1)) time, if there are exactly two classes and R is an upper bound on the number of tree leaves labeled with the first class.","https://ojs.aaai.org/index.php/AAAI/article/view/26006/25778"
"26007","Learning Similarity Metrics for Volumetric Simulations with Multiscale CNNs","['Georg Kohl', 'Li-Wei Chen', 'Nils Thuerey']","['Technical University of Munich', 'Technical University of Munich', 'Technical University of Munich']","['ML: Learning Preferences or Rankings', 'APP: Natural Sciences', 'ML: Representation Learning', 'ML: Applications']","Kohl, G., Chen, L.-W., & Thuerey, N. (2023). Learning Similarity Metrics for Volumetric Simulations with Multiscale CNNs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8351-8359. https://doi.org/10.1609/aaai.v37i7.26007","Abstract 					Simulations that produce three-dimensional data are ubiquitous in science, ranging from fluid flows to plasma physics. We propose a similarity model based on entropy, which allows for the creation of physically meaningful ground truth distances for the similarity assessment of scalar and vectorial data, produced from transport and motion-based simulations. Utilizing two data acquisition methods derived from this model, we create collections of fields from numerical PDE solvers and existing simulation data repositories. Furthermore, a multiscale CNN architecture that computes a volumetric similarity metric (VolSiM) is proposed. To the best of our knowledge this is the first learning method inherently designed to address the challenges arising for the similarity assessment of high-dimensional simulation data. Additionally, the tradeoff between a large batch size and an accurate correlation computation for correlation-based loss functions is investigated, and the metric's invariance with respect to rotation and scale operations is analyzed. Finally, the robustness and generalization of VolSiM is evaluated on a large range of test data, as well as a particularly challenging turbulence case study, that is close to potential real-world applications.","https://ojs.aaai.org/index.php/AAAI/article/view/26007/25779"
"26008","Peeling the Onion: Hierarchical Reduction of Data Redundancy for Efficient Vision Transformer Training","['Zhenglun Kong', 'Haoyu Ma', 'Geng Yuan', 'Mengshu Sun', 'Yanyue Xie', 'Peiyan Dong', 'Xin Meng', 'Xuan Shen', 'Hao Tang', 'Minghai Qin', 'Tianlong Chen', 'Xiaolong Ma', 'Xiaohui Xie', 'Zhangyang Wang', 'Yanzhi Wang']","['Northeastern University', 'University of California, Irvine', 'Northeastern University', 'Northeastern University', 'Northeastern University', 'Northeastern University', 'Peking university', 'Northeastern University', 'ETH Zurich', 'Western Digital Research', 'Unversity of Texas at Austin', 'Clemson University', 'University of California, Irvine', 'University of Texas at Austin', 'Northeastern University']","['ML: Learning on the Edge & Model Compression', 'CV: Applications', 'CV: Object Detection & Categorization']","Kong, Z., Ma, H., Yuan, G., Sun, M., Xie, Y., Dong, P., Meng, X., Shen, X., Tang, H., Qin, M., Chen, T., Ma, X., Xie, X., Wang, Z., & Wang, Y. (2023). Peeling the Onion: Hierarchical Reduction of Data Redundancy for Efficient Vision Transformer Training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8360-8368. https://doi.org/10.1609/aaai.v37i7.26008","Abstract 					Vision transformers (ViTs) have recently obtained success in many applications, but their intensive computation and heavy memory usage at both training and inference time limit their generalization. Previous compression algorithms usually start from the pre-trained dense models and only focus on efficient inference, while time-consuming training is still unavoidable.  In contrast, this paper points out that the million-scale training data is redundant, which is the fundamental reason for the tedious training. To address the issue, this paper aims to introduce sparsity into data and proposes an end-to-end efficient training framework from three sparse perspectives, dubbed Tri-Level E-ViT. Specifically,  we leverage a hierarchical data redundancy reduction scheme, by exploring the sparsity under three levels: number of training examples in the dataset, number of patches (tokens) in each example, and number of connections between tokens that lie in attention weights. With extensive experiments, we demonstrate that our proposed technique can noticeably accelerate training for various ViT architectures while maintaining accuracy.   Remarkably, under certain ratios, we are able to improve the ViT accuracy rather than compromising it. For example, we can achieve 15.2% speedup with 72.6% (+0.4) Top-1 accuracy on Deit-T, and 15.7% speedup with 79.9% (+0.1) Top-1 accuracy on Deit-S. This proves the existence of data redundancy in ViT. Our codeis released at https://github.com/ZLKong/Tri-Level-ViT","https://ojs.aaai.org/index.php/AAAI/article/view/26008/25780"
"26009","Adversarial Robust Deep Reinforcement Learning Requires Redefining Robustness","['Ezgi Korkmaz']","['---']","['ML: Reinforcement Learning Algorithms', 'ML: Adversarial Learning & Robustness', 'ML: Deep Neural Network Algorithms', 'PEAI: Safety', 'Robustness & Trustworthiness']","Korkmaz, E. (2023). Adversarial Robust Deep Reinforcement Learning Requires Redefining Robustness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8369-8377. https://doi.org/10.1609/aaai.v37i7.26009","Abstract 					Learning from raw high dimensional data via interaction with a given environment has been effectively achieved through the utilization of deep neural networks. Yet the observed degradation in policy performance caused by imperceptible worst-case policy dependent translations along high sensitivity directions (i.e. adversarial perturbations) raises concerns on the robustness of deep reinforcement learning policies. In our paper, we show that these high sensitivity directions do not lie only along particular worst-case directions, but rather are more abundant in the deep neural policy landscape and can be found via more natural means in a black-box setting. Furthermore, we show that vanilla training techniques intriguingly result in learning more robust policies compared to the policies learnt via the state-of-the-art adversarial training techniques. We believe our work lays out intriguing properties of the deep reinforcement learning policy manifold and our results can help to build robust and generalizable deep reinforcement learning policies.","https://ojs.aaai.org/index.php/AAAI/article/view/26009/25781"
"26010","Almost Cost-Free Communication in Federated Best Arm Identification","['Srinivas Reddy Kota', 'P. N. Karthik', 'Vincent Y. F. Tan']","['National University of Singapore', 'National University of Singapore', 'NUS']","['ML: Online Learning & Bandits', 'ML: Distributed Machine Learning & Federated Learning', 'MAS: Agent Communication', 'MAS: Distributed Problem Solving', 'RU: Sequential Decision Making']","Kota, S. R., Karthik, P. N., & Tan, V. Y. F. (2023). Almost Cost-Free Communication in Federated Best Arm Identification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8378-8385. https://doi.org/10.1609/aaai.v37i7.26010","Abstract 					We study the problem of best arm identification in a federated learning multi-armed bandit setup with a central server and multiple clients. Each client is associated with a multi-armed bandit in which each arm yields i.i.d. rewards following a Gaussian distribution with an unknown mean and known variance. The set of arms is assumed to be the same at all the clients. We define two notions of best arm local and global. The local best arm at a client is the arm with the largest mean among the arms local to the client, whereas the global best arm is the arm with the largest average mean across all the clients. We assume that each client can only observe the rewards from its local arms and thereby estimate its local best arm. The clients communicate with a central server on uplinks that entail a cost of C>=0 units per usage per uplink. The global best arm is estimated at the server. The goal is to identify the local best arms and the global best arm with minimal total cost, defined as the sum of the total number of arm selections at all the clients and the total communication cost, subject to an upper bound on the error probability. We propose a novel algorithm FedElim that is based on successive elimination and communicates only in exponential time steps and obtain a high probability instance-dependent upper bound on its total cost. The key takeaway from our paper is that for any C>=0 and error probabilities sufficiently small, the total number of arm selections (resp. the total cost) under FedElim is at most 2 (resp. 3) times the maximum total number of arm selections under its variant that communicates in every time step. Additionally, we show that the latter is optimal in expectation up to a constant factor, thereby demonstrating that communication is almost cost-free in FedElim. We numerically validate the efficacy of FedElim on two synthetic datasets and the MovieLens dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/26010/25782"
"26011","UEQMS: UMAP Embedded Quick Mean Shift Algorithm for High Dimensional Clustering","['Abhishek Kumar', 'Swagatam Das', 'Rammohan Mallipeddi']","['TCG Crest\nKyungpook National University', 'Indian Statistical Institute', 'Kyungpook national University']","['ML: Clustering', 'ML: Unsupervised & Self-Supervised Learning']","Kumar, A., Das, S., & Mallipeddi, R. (2023). UEQMS: UMAP Embedded Quick Mean Shift Algorithm for High Dimensional Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8386-8395. https://doi.org/10.1609/aaai.v37i7.26011","Abstract 					The mean shift algorithm is a simple yet very effective clustering method widely used for image and video segmentation as well as other exploratory data analysis applications. Recently, a new algorithm called MeanShift++ (MS++) for low-dimensional clustering was proposed with a speedup of 4000 times over the vanilla mean shift. In this work, starting with a first-of-its-kind theoretical analysis of MS++, we extend its reach to high-dimensional data clustering by integrating the Uniform Manifold Approximation and Projection (UMAP) based dimensionality reduction in the same framework. Analytically, we show that MS++ can indeed converge to a non-critical point. Subsequently, we suggest modifications to MS++ to improve its convergence characteristics. In addition, we propose a way to further speed up MS++ by avoiding the execution of the MS++ iterations for every data point. By incorporating UMAP with modified MS++, we design a faster algorithm, named UMAP embedded quick mean shift (UEQMS), for partitioning data with a relatively large number of recorded features. Through extensive experiments,  we showcase the efficacy of UEQMS over other state-of-the-art algorithms in terms of accuracy and runtime.","https://ojs.aaai.org/index.php/AAAI/article/view/26011/25783"
"26012","The Effect of Diversity in Meta-Learning","['Ramnath Kumar', 'Tristan Deleu', 'Yoshua Bengio']","['Google Research, India', 'Mila, Quebec Artificial Intelligence Institute, Université de Montréal', 'Mila, Quebec Artificial Intelligence Institute, Université de Montréal\nCIFAR, IVADO']","['ML: Meta Learning', 'ML: Multi-Instance/Multi-View Learning', 'ML: Representation Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Active Learning', 'ML: Optimization', 'ML: Deep Neural Network Algorithms', 'ML: Other Foundations of Machine Learning', 'ML: Classification and Regression', 'ML: Evaluation and Analysis (Machine Learning)']","Kumar, R., Deleu, T., & Bengio, Y. (2023). The Effect of Diversity in Meta-Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8396-8404. https://doi.org/10.1609/aaai.v37i7.26012","Abstract 					Recent studies show that task distribution plays a vital role in the meta-learner's performance. Conventional wisdom is that task diversity should improve the performance of meta-learning. In this work, we find evidence to the contrary; (i) our experiments draw into question the efficacy of our learned models: similar manifolds can be learned with a subset of the data (lower task diversity). This finding questions the advantage of providing more data to the model, and (ii) adding diversity to the task distribution (higher task diversity) sometimes hinders the model and does not lead to a significant improvement in performance as previously believed. To strengthen our findings, we provide both empirical and theoretical evidence.","https://ojs.aaai.org/index.php/AAAI/article/view/26012/25784"
"26013","Gradient Estimation for Binary Latent Variables via Gradient Variance Clipping","['Russell Z. Kunes', 'Mingzhang Yin', 'Max Land', 'Doron Haviv', ""Dana Pe'er"", 'Simon Tavaré']","['Department of Statistics, Columbia University\nComputational and Systems Biology, Memorial Sloan Kettering Cancer Center\nIrving Institute of Cancer Dynamics, Columbia University', 'Irving Institute of Cancer Dynamics, Columbia University\nWarrington College of Business, University of Florida', 'Computational and Systems Biology, Memorial Sloan Kettering Cancer Center', 'Computational and Systems Biology, Memorial Sloan Kettering Cancer Center', 'Computational and Systems Biology, Memorial Sloan Kettering Cancer Center\nHoward Hughes Medical Institute', 'Department of Statistics, Columbia University\nIrving Institute of Cancer Dynamics, Columbia University']","['ML: Deep Generative Models & Autoencoders', 'ML: Probabilistic Methods']","Kunes, R. Z., Yin, M., Land, M., Haviv, D., Pe’er, D., & Tavaré, S. (2023). Gradient Estimation for Binary Latent Variables via Gradient Variance Clipping. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8405-8412. https://doi.org/10.1609/aaai.v37i7.26013","Abstract 					Gradient estimation is often necessary for fitting generative models with discrete latent variables, in contexts such as reinforcement learning and variational autoencoder (VAE) training. The DisARM estimator achieves state of the art gradient variance for Bernoulli latent variable models in many contexts. However, DisARM and other estimators have potentially exploding variance near the boundary of the parameter space, where solutions tend to lie. To ameliorate this issue, we propose a new gradient estimator bitflip-1  that is lower variance at the boundaries of the parameter space. As bitflip-1 has complementary properties to existing estimators, we introduce an aggregated estimator, unbiased gradient variance clipping (UGC) that uses either a bitflip-1 or a DisARM gradient update for each coordinate.  We theoretically prove that UGC has uniformly lower variance than DisARM. Empirically, we observe that UGC achieves the optimal value of the optimization objectives  in toy experiments, discrete VAE training, and in a best subset selection problem.","https://ojs.aaai.org/index.php/AAAI/article/view/26013/25785"
"26014","LoNe Sampler: Graph Node Embeddings by Coordinated Local Neighborhood Sampling","['Konstantin Kutzkov']","['Teva Pharmaceuticals']","['ML: Graph-based Machine Learning', 'DMKM: Data Stream Mining', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Classification and Regression', 'ML: Dimensionality Reduction/Feature Selection', 'ML: Kernel Methods', 'ML: Other Foundations of Machine Learning', 'ML: Representation Learning', 'ML: Scalability of ML Systems']","Kutzkov, K. (2023). LoNe Sampler: Graph Node Embeddings by Coordinated Local Neighborhood Sampling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8413-8420. https://doi.org/10.1609/aaai.v37i7.26014","Abstract 					Local graph neighborhood sampling is a fundamental computational problem that is at the heart of algorithms for node representation learning.  Several works have presented algorithms for learning discrete node embeddings where graph nodes are represented by discrete features such as attributes of neighborhood nodes. Discrete embeddings offer several advantages compared to continuous word2vec-like node embeddings: ease of computation, scalability, and interpretability. We present LoNe Sampler, a suite of algorithms for generating discrete node embeddings by Local Neighborhood Sampling, and address two shortcomings of previous work. First, our algorithms have rigorously understood theoretical properties. Second, we show how to generate approximate explicit vector maps that avoid the expensive computation of a Gram matrix for the training of a kernel model. Experiments on benchmark datasets confirm the theoretical findings and demonstrate the advantages of the proposed methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26014/25786"
"26015","WLD-Reg: A Data-Dependent Within-Layer Diversity Regularizer","['Firas Laakom', 'Jenni Raitoharju', 'Alexandros Iosifidis', 'Moncef Gabbouj']","['Tampere University', 'University of Jyväskylä', 'Aarhus University', 'Tampere University']","['ML: Deep Neural Network Algorithms', 'ML: Classification and Regression', 'CV: Learning & Optimization for CV', 'ML: Optimization']","Laakom, F., Raitoharju, J., Iosifidis, A., & Gabbouj, M. (2023). WLD-Reg: A Data-Dependent Within-Layer Diversity Regularizer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8421-8429. https://doi.org/10.1609/aaai.v37i7.26015","Abstract 					Neural networks are composed of multiple layers arranged in a hierarchical structure jointly trained with a gradient-based optimization, where the errors are back-propagated from the last layer back to the first one. At each optimization step, neurons at a given layer receive feedback from neurons belonging to higher layers of the hierarchy. In this paper, we propose to complement this traditional 'between-layer' feedback with additional 'within-layer' feedback to encourage the diversity of the activations within the same layer. To this end, we measure the pairwise similarity between the outputs of the neurons and use it to model the layer's overall diversity. We present an extensive empirical study confirming that the proposed approach enhances the performance of several state-of-the-art neural network models in multiple tasks. The code is publically available at https://github.com/firasl/AAAI-23-WLD-Reg.","https://ojs.aaai.org/index.php/AAAI/article/view/26015/25787"
"26016","SpatialFormer: Semantic and Target Aware Attentions for Few-Shot Learning","['Jinxiang Lai', 'Siqian Yang', 'Wenlong Wu', 'Tao Wu', 'Guannan Jiang', 'Xi Wang', 'Jun Liu', 'Bin-Bin Gao', 'Wei Zhang', 'Yuan Xie', 'Chengjie Wang']","['Tencent', 'Tencent', 'Tencent', 'Tencent', 'CATL', 'CATL', 'Tencent', 'Tencent', 'CATL', 'East China Normal University', 'Tencent; Shanghai Jiao Tong University']","['ML: Classification and Regression', 'CV: Object Detection & Categorization', 'CV: Representation Learning for Vision', 'ML: Meta Learning']","Lai, J., Yang, S., Wu, W., Wu, T., Jiang, G., Wang, X., Liu, J., Gao, B.-B., Zhang, W., Xie, Y., & Wang, C. (2023). SpatialFormer: Semantic and Target Aware Attentions for Few-Shot Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8430-8437. https://doi.org/10.1609/aaai.v37i7.26016","Abstract 					Recent Few-Shot Learning (FSL) methods put emphasis on generating a discriminative embedding features to precisely measure the similarity between support and query sets. Current CNN-based cross-attention approaches generate discriminative representations via enhancing the mutually semantic similar regions of support and query pairs. However, it suffers from two problems: CNN structure produces inaccurate attention map based on local features, and mutually similar backgrounds cause distraction. To alleviate these problems, we design a novel SpatialFormer structure to generate more accurate attention regions based on global features. Different from the traditional Transformer modeling intrinsic instance-level similarity which causes accuracy degradation in FSL, our SpatialFormer explores the semantic-level similarity between pair inputs to boost the performance. Then we derive two specific attention modules, named SpatialFormer Semantic Attention (SFSA) and SpatialFormer Target Attention (SFTA), to enhance the target object regions while reduce the background distraction. Particularly, SFSA highlights the regions with same semantic information between pair features, and SFTA finds potential foreground object regions of novel feature that are similar to base categories. Extensive experiments show that our methods are effective and achieve new state-of-the-art results on few-shot classification benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/26016/25788"
"26017","A Data Source for Reasoning Embodied Agents","['Jack Lanchantin', 'Sainbayar Sukhbaatar', 'Gabriel Synnaeve', 'Yuxuan Sun', 'Kavya Srinet', 'Arthur Szlam']","['Meta AI', 'Meta AI', 'Meta AI', 'Meta AI', 'Meta AI', 'Meta AI']","['ML: Applications', 'ML: Relational Learning', 'ML: Representation Learning', 'SNLP: Applications', 'SNLP: Language Grounding', 'SNLP: Other Foundations of Speech & Natural Language Processing', 'SNLP: Question Answering']","Lanchantin, J., Sukhbaatar, S., Synnaeve, G., Sun, Y., Srinet, K., & Szlam, A. (2023). A Data Source for Reasoning Embodied Agents. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8438-8446. https://doi.org/10.1609/aaai.v37i7.26017","Abstract 					Recent progress in using machine learning models for reasoning tasks has been driven by novel model architectures, large-scale pre-training protocols, and dedicated reasoning datasets for fine-tuning.  In this work, to further pursue these advances, we introduce a new data generator for machine reasoning that integrates with an embodied agent.  The generated data consists of templated text queries and answers, matched with world-states encoded into a database.  The world-states are a result of both world dynamics and the actions of the agent.  We show the results of several baseline models on instantiations of train sets.  These include pre-trained language models fine-tuned on a text-formatted representation of the database, and graph-structured Transformers operating on a knowledge-graph representation of the database.  We find that these models can answer some questions about the world-state, but struggle with others. These results hint at new research directions in designing neural reasoning models and database representations. Code to generate the data and train the models will be released at github.com/facebookresearch/neuralmemory","https://ojs.aaai.org/index.php/AAAI/article/view/26017/25789"
"26018","Generalization Bounds for Inductive Matrix Completion in Low-Noise Settings","['Antoine Ledent', 'Rodrigo Alves', 'Yunwen Lei', 'Yann Guermeur', 'Marius Kloft']","['Singapore Management University', 'Czech Technical University', 'Hong Kong Baptist University', 'CNRS', 'Technische Universität Kaiserslautern']","['ML: Learning Theory', 'ML: Matrix & Tensor Methods', 'ML: Other Foundations of Machine Learning']","Ledent, A., Alves, R., Lei, Y., Guermeur, Y., & Kloft, M. (2023). Generalization Bounds for Inductive Matrix Completion in Low-Noise Settings. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8447-8455. https://doi.org/10.1609/aaai.v37i7.26018","Abstract 					We study inductive matrix completion (matrix completion with side information) under an i.i.d. subgaussian noise assumption at a low noise regime, with uniform sampling of the entries. We obtain for the first time generalization bounds with the following three properties:  	(1) they scale like the standard deviation of the noise and in particular approach zero in the exact recovery case; (2) even in the presence of noise, they converge to zero when the sample size approaches infinity; and (3) for a fixed dimension of the side information, they only have a logarithmic dependence on the size of the matrix. Differently from many works in approximate recovery, we present results both for bounded Lipschitz losses and for the absolute loss, with the latter relying on Talagrand-type inequalities.  The proofs create a bridge between two approaches to the theoretical analysis of matrix completion, since they consist in a combination of techniques from both the exact recovery literature and the approximate recovery literature.","https://ojs.aaai.org/index.php/AAAI/article/view/26018/25790"
"26019","I’m Me, We’re Us, and I’m Us: Tri-directional Contrastive Learning on Hypergraphs","['Dongjin Lee', 'Kijung Shin']","['KAIST', 'KAIST']","['ML: Graph-based Machine Learning', 'ML: Unsupervised & Self-Supervised Learning']","Lee, D., & Shin, K. (2023). I’m Me, We’re Us, and I’m Us: Tri-directional Contrastive Learning on Hypergraphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8456-8464. https://doi.org/10.1609/aaai.v37i7.26019","Abstract 					Although machine learning on hypergraphs has attracted considerable attention, most of the works have focused on (semi-)supervised learning, which may cause heavy labeling costs and poor generalization. Recently, contrastive learning has emerged as a successful unsupervised representation learning method. Despite the prosperous development of contrastive learning in other domains, contrastive learning on hypergraphs remains little explored. In this paper, we propose TriCL (Tri-directional Contrastive Learning), a general framework for contrastive learning on hypergraphs. Its main idea is tri-directional contrast, and specifically, it aims to maximize in two augmented views the agreement (a) between the same node, (b) between the same group of nodes, and (c) between each group and its members. Together with simple but surprisingly effective data augmentation and negative sampling schemes, these three forms of contrast enable TriCL to capture both node- and group-level structural information in node embeddings. Our extensive experiments using 14 baseline approaches, 10 datasets, and two tasks demonstrate the effectiveness of TriCL, and most noticeably, TriCL almost consistently outperforms not just unsupervised competitors but also (semi-)supervised competitors mostly by significant margins for node classification. The code and datasets are available at https://github.com/wooner49/TriCL.","https://ojs.aaai.org/index.php/AAAI/article/view/26019/25791"
"26020","Bespoke: A Block-Level Neural Network Optimization Framework for Low-Cost Deployment","['Jong-Ryul Lee', 'Yong-Hyuk Moon']","['Electronics and Telecommunications Research Institute (ETRI)', 'Electronics and Telecommunications Research Institute (ETRI)\nUniversity of Science and Technology (UST)']","['ML: Auto ML and Hyperparameter Tuning', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms', 'ML: Dimensionality Reduction/Feature Selection']","Lee, J.-R., & Moon, Y.-H. (2023). Bespoke: A Block-Level Neural Network Optimization Framework for Low-Cost Deployment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8465-8472. https://doi.org/10.1609/aaai.v37i7.26020","Abstract 					As deep learning models become popular, there is a lot of need for deploying them to diverse device environments. Because it is costly to develop and optimize a neural network for every single environment, there is a line of research to search neural networks for multiple target environments efficiently. However, existing works for such a situation still suffer from requiring many GPUs and expensive costs. Motivated by this, we propose a novel neural network optimization framework named Bespoke for low-cost deployment. Our framework searches for a lightweight model by replacing parts of an original model with randomly selected alternatives, each of which comes from a pretrained neural network or the original model. In the practical sense, Bespoke has two significant merits. One is that it requires near zero cost for designing the search space of neural networks. The other merit is that it exploits the sub-networks of public pretrained neural networks, so the total cost is minimal compared to the existing works. We conduct experiments exploring Bespoke's the merits, and the results show that it finds efficient models for multiple targets with meager cost.","https://ojs.aaai.org/index.php/AAAI/article/view/26020/25792"
"26021","Time-Aware Random Walk Diffusion to Improve Dynamic Graph Learning","['Jong-whi Lee', 'Jinhong Jung']","['Jeonbuk National University', 'Jeonbuk National University']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Lee, J.- whi, & Jung, J. (2023). Time-Aware Random Walk Diffusion to Improve Dynamic Graph Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8473-8481. https://doi.org/10.1609/aaai.v37i7.26021","Abstract 					How can we augment a dynamic graph for improving the performance of dynamic graph neural networks? Graph augmentation has been widely utilized to boost the learning performance of GNN-based models. However, most existing approaches only enhance spatial structure within an input static graph by transforming the graph, and do not consider dynamics caused by time such as temporal locality, i.e., recent edges are more influential than earlier ones, which remains challenging for dynamic graph augmentation. In this work, we propose TiaRa (Time-aware Random Walk Diffusion), a novel diffusion-based method for augmenting a dynamic graph represented as a discrete-time sequence of graph snapshots. For this purpose, we first design a time-aware random walk proximity so that a surfer can walk along the time dimension as well as edges, resulting in spatially and temporally localized scores. We then derive our diffusion matrices based on the time-aware random walk, and show they become enhanced adjacency matrices that both spatial and temporal localities are augmented. Throughout extensive experiments, we demonstrate that TiaRa effectively augments a given dynamic graph, and leads to significant improvements in dynamic GNN models for various graph datasets and tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26021/25793"
"26022","Demystifying Randomly Initialized Networks for Evaluating Generative Models","['Junghyuk Lee', 'Jun-Hyuk Kim', 'Jong-Seok Lee']","['Yonsei University', 'Yonsei University', 'Yonsei University']","['ML: Deep Generative Models & Autoencoders', 'ML: Evaluation and Analysis (Machine Learning)']","Lee, J., Kim, J.-H., & Lee, J.-S. (2023). Demystifying Randomly Initialized Networks for Evaluating Generative Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8482-8490. https://doi.org/10.1609/aaai.v37i7.26022","Abstract 					Evaluation of generative models is mostly based on the comparison between the estimated distribution and the ground truth distribution in a certain feature space. To embed samples into informative features, previous works often use convolutional neural networks optimized for classification, which is criticized by recent studies. Therefore, various feature spaces have been explored to discover alternatives. Among them, a surprising approach is to use a randomly initialized neural network for feature embedding. However, the fundamental basis to employ the random features has not been sufficiently justified. In this paper, we rigorously investigate the feature space of models with random weights in comparison to that of trained models. Furthermore, we provide an empirical evidence to choose networks for random features to obtain consistent and reliable results. Our results indicate that the features from random networks can evaluate generative models well similarly to those from trained networks, and furthermore, the two types of features can be used together in a complementary way.","https://ojs.aaai.org/index.php/AAAI/article/view/26022/25794"
"26023","Layer-Wise Adaptive Model Aggregation for Scalable Federated Learning","['Sunwoo Lee', 'Tuo Zhang', 'A. Salman Avestimehr']","['University of Southern California\nInha University', 'University of Southern California', 'University of Southern California']","['ML: Distributed Machine Learning & Federated Learning', 'ML: Scalability of ML Systems']","Lee, S., Zhang, T., & Avestimehr, A. S. (2023). Layer-Wise Adaptive Model Aggregation for Scalable Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8491-8499. https://doi.org/10.1609/aaai.v37i7.26023","Abstract 					In Federated Learning (FL), a common approach for aggregating local solutions across clients is periodic full model averaging. It is, however, known that different layers of neural networks can have a different degree of model discrepancy across the clients. The conventional full aggregation scheme does not consider such a difference and synchronizes the whole model parameters at once, resulting in inefficient network bandwidth consumption. Aggregating the parameters that are similar across the clients does not make meaningful training progress while increasing the communication cost. We propose FedLAMA, a layer-wise adaptive model aggregation scheme for scalable FL. FedLAMA adjusts the aggregation interval in a layer-wise manner, jointly considering the model discrepancy and the communication cost. This fine-grained aggregation strategy enables to reduce the communication cost without significantly harming the model accuracy. Our extensive empirical study shows that, as the aggregation interval increases, FedLAMA shows a remarkably smaller accuracy drop than the periodic full aggregation, while achieving comparable communication efficiency.","https://ojs.aaai.org/index.php/AAAI/article/view/26023/25795"
"26024","Goal-Conditioned Q-learning as Knowledge Distillation","['Alexander Levine', 'Soheil Feizi']","['University of Maryland', 'University of Maryland']","['ML: Reinforcement Learning Algorithms']","Levine, A., & Feizi, S. (2023). Goal-Conditioned Q-learning as Knowledge Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8500-8509. https://doi.org/10.1609/aaai.v37i7.26024","Abstract 					Many applications of reinforcement learning can be formalized as goal-conditioned environments, where, in each episode, there is a ""goal"" that affects the rewards obtained during that episode but does not affect the dynamics. Various techniques have been proposed to improve performance in goal-conditioned environments, such as automatic curriculum generation and goal relabeling. In this work, we explore a connection between off-policy reinforcement learning in goal-conditioned settings and knowledge distillation. In particular: the current Q-value function and the target Q-value estimate are both functions of the goal, and we would like to train the Q-value function to match its target for all goals. We therefore apply Gradient-Based Attention Transfer (Zagoruyko and Komodakis 2017), a knowledge distillation technique, to the Q-function update. We empirically show that this can improve the performance of goal-conditioned off-policy reinforcement learning when the space of goals is high-dimensional. We also show that this technique can be adapted to allow for efficient learning in the case of multiple simultaneous sparse goals, where the agent can attain a reward by achieving any one of a large set of objectives, all specified at test time. Finally, to provide theoretical support, we give examples of classes of environments where (under some assumptions) standard off-policy algorithms such as DDPG require at least O(d^2) replay buffer transitions to learn an optimal policy, while our proposed technique requires only O(d) transitions, where d is the dimensionality of the goal and state space. Code and appendix are available at https://github.com/alevine0/ReenGAGE.","https://ojs.aaai.org/index.php/AAAI/article/view/26024/25796"
"26025","Optimism in Face of a Context:Regret Guarantees for Stochastic Contextual MDP","['Orin Levy', 'Yishay Mansour']","['Tel Aviv University', 'Tel Aviv University and Google Research']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms', 'ML: Online Learning & Bandits']","Levy, O., & Mansour, Y. (2023). Optimism in Face of a Context:Regret Guarantees for Stochastic Contextual MDP. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8510-8517. https://doi.org/10.1609/aaai.v37i7.26025","Abstract 					We present regret minimization algorithms for stochastic contextual MDPs under minimum reachability assumption, using an access to an offline least square regression oracle. We analyze three different settings: where the dynamics is known, where the dynamics is unknown but independent of the context and the most challenging setting where the dynamics is unknown and context-dependent. For the latter, our algorithm obtains regret bound (up to poly-logarithmic factors) of order  (H+1/pₘᵢₙ)H|S|³ᐟ²(|A|Tlog(max{|?|,|?|} /?))¹ᐟ²  with probability 1−?, where ? and ? are finite and realizable function classes used to approximate the dynamics and rewards respectively, pₘᵢₙ is the minimum reachability parameter, S is the set of states, A the set of actions, H the horizon, and T the number of episodes. To our knowledge, our approach is the first optimistic approach applied to contextual MDPs with general function approximation (i.e., without additional knowledge regarding the function class, such as it being linear and etc.). We present a lower bound of ?((TH|S||A|ln|?| /ln|A| )¹ᐟ² ), on the expected regret which holds even in the case of known dynamics. Lastly, we discuss an extension of our results to CMDPs without minimum reachability, that obtains order of T³ᐟ⁴ regret.","https://ojs.aaai.org/index.php/AAAI/article/view/26025/25797"
"26026","Differentiable Meta Multigraph Search with Partial Message Propagation on Heterogeneous Information Networks","['Chao Li', 'Hao Xu', 'Kun He']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology']","['ML: Graph-based Machine Learning', 'ML: Auto ML and Hyperparameter Tuning', 'ML: Deep Neural Architectures']","Li, C., Xu, H., & He, K. (2023). Differentiable Meta Multigraph Search with Partial Message Propagation on Heterogeneous Information Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8518-8526. https://doi.org/10.1609/aaai.v37i7.26026","Abstract 					Heterogeneous information networks (HINs) are widely employed for describing real-world data with intricate entities and relationships. To automatically utilize their semantic information, graph neural architecture search has recently been developed for various tasks of HINs. Existing works, on the other hand, show weaknesses in instability and inflexibility. To address these issues, we propose a novel method called Partial Message Meta Multigraph search (PMMM) to automatically optimize the neural architecture design on HINs. Specifically, to learn how graph neural networks (GNNs) propagate messages along various types of edges, PMMM adopts an efficient differentiable framework to search for a meaningful meta multigraph, which can capture more flexible and complex semantic relations than a meta graph. The differentiable search typically suffers from performance instability, so we further propose a stable algorithm called partial message search to ensure that the searched meta multigraph consistently surpasses the manually designed meta-structures, i.e., meta-paths. Extensive experiments on six benchmark datasets over two representative tasks, including node classification and recommendation, demonstrate the effectiveness of the proposed method. Our approach outperforms the state-of-the-art heterogeneous GNNs, finds out meaningful meta multigraphs, and is significantly more stable. Our code is available at https://github.com/JHL-HUST/PMMM.","https://ojs.aaai.org/index.php/AAAI/article/view/26026/25798"
"26027","Learning Adversarially Robust Sparse Networks via Weight Reparameterization","['Chenhao Li', 'Qiang Qiu', 'Zhibin Zhang', 'Jiafeng Guo', 'Xueqi Cheng']","['Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Institute of Computing Technology, Chinese Academy of Sciences', 'Institute of Computing Technology, Chinese Academy of Sciences', 'Institute of Computing Technology, Chinese Academy of Sciences', 'Institute of Computing Technology, Chinese Academy of Sciences']","['ML: Adversarial Learning & Robustness', 'CV: Adversarial Attacks & Robustness', 'ML: Learning on the Edge & Model Compression']","Li, C., Qiu, Q., Zhang, Z., Guo, J., & Cheng, X. (2023). Learning Adversarially Robust Sparse Networks via Weight Reparameterization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8527-8535. https://doi.org/10.1609/aaai.v37i7.26027","Abstract 					Although increasing model size can enhance the adversarial robustness of deep neural networks, in resource-constrained environments, there exist critical sparsity constraints. While the recent robust pruning technologies show promising direction to obtain adversarially robust sparse networks, they perform poorly with high sparsity. In this work, we bridge this performance gap by reparameterizing network parameters to simultaneously learn the sparse structure and the robustness. Specifically, we introduce Twin-Rep, which reparameterizes original weights into the product of two factors during training and performs pruning on the reparameterized weights to satisfy the target sparsity constraint. Twin-Rep implicitly adds the sparsity constraint without changing the robust training objective, thus can enhance robustness under high sparsity. We also introduce another variant of weight reparameterization for better channel pruning. When inferring, we restore the original weight structure to obtain compact and robust networks. Extensive experiments on diverse datasets demonstrate that our method achieves state-of-the-art results, outperforming the current sparse robust training method and robustness-aware pruning method. Our code is available at https://github.com/UCAS-LCH/Twin-Rep.","https://ojs.aaai.org/index.php/AAAI/article/view/26027/25799"
"26028","ACE: Cooperative Multi-Agent Q-learning with Bidirectional Action-Dependency","['Chuming Li', 'Jie Liu', 'Yinmin Zhang', 'Yuhong Wei', 'Yazhe Niu', 'Yaodong Yang', 'Yu Liu', 'Wanli Ouyang']","['The University of Sydney\nShanghai Artificial Intelligence Laboratory', 'Shanghai Artificial Intelligence Laboratory', 'The University of Sydney\nShanghai Artificial Intelligence Laboratory', 'SenseTime Group LTD', 'Shanghai Artificial Intelligence Laboratory\nSenseTime Group LTD', 'Institute for AI, Peking University', 'Shanghai Artificial Intelligence Laboratory\nSenseTime Group LTD', 'The University of Sydney\nShanghai Artificial Intelligence Laboratory']","['ML: Reinforcement Learning Algorithms', 'MAS: Coordination and Collaboration', 'MAS: Multiagent Learning']","Li, C., Liu, J., Zhang, Y., Wei, Y., Niu, Y., Yang, Y., Liu, Y., & Ouyang, W. (2023). ACE: Cooperative Multi-Agent Q-learning with Bidirectional Action-Dependency. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8536-8544. https://doi.org/10.1609/aaai.v37i7.26028","Abstract 					Multi-agent reinforcement learning (MARL) suffers from the non-stationarity problem, which is the ever-changing targets at every iteration when multiple agents update their policies at the same time. Starting from first principle, in this paper, we manage to solve the non-stationarity problem by proposing bidirectional action-dependent Q-learning (ACE). Central to the development of ACE is the sequential decision making process wherein only one agent is allowed to take action at one time. Within this process, each agent maximizes its value function given the actions taken by the preceding agents at the inference stage. In the learning phase, each agent minimizes the TD error that is dependent on how the subsequent agents have reacted to their chosen action. Given the design of bidirectional dependency, ACE effectively turns a multi-agent MDP into a single-agent MDP. We implement the ACE framework by identifying the proper network representation to formulate the action dependency, so that the sequential decision process is computed implicitly in one forward pass. To validate ACE, we compare it with strong baselines on two MARL benchmarks. Empirical experiments demonstrate that ACE outperforms the state-of-the-art algorithms on Google Research Football and StarCraft Multi-Agent Challenge by a large margin. In particular, on SMAC tasks, ACE achieves 100% success rate on almost all the hard and super hard maps. We further study extensive research problems regarding ACE, including extension, generalization and practicability.","https://ojs.aaai.org/index.php/AAAI/article/view/26028/25800"
"26029","When Online Learning Meets ODE: Learning without Forgetting on Variable Feature Space","['Diyang Li', 'Bin Gu']","['Nanjing University of Information Science & Technology', 'Nanjing University of Information Science & Technology\nMBZUAI']","['ML: Lifelong and Continual Learning', 'ML: Online Learning & Bandits', 'ML: Optimization']","Li, D., & Gu, B. (2023). When Online Learning Meets ODE: Learning without Forgetting on Variable Feature Space. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8545-8553. https://doi.org/10.1609/aaai.v37i7.26029","Abstract 					Machine learning systems that built upon varying feature space are ubiquitous across the world. When the set of practical or virtual features changes, the online learning approach can adjust the learned model accordingly rather than re-training from scratch and has been an attractive area of research. Despite its importance, most studies for algorithms that are capable of handling online features have no ensurance of stationarity point convergence, while the accuracy guaranteed methods are still limited to some simple cases such as L_1 or L_2 norms with square loss. To address this challenging problem, we develop an efficient Dynamic Feature Learning System (DFLS) to perform online learning on the unfixed feature set for more general statistical models and demonstrate how DFLS opens up many new applications. We are the first to achieve accurate & reliable feature-wise online learning for a broad class of models like logistic regression, spline interpolation, group Lasso and Poisson regression. By utilizing DFLS, the updated model is theoretically the same as the model trained from scratch using the entire new feature space. Specifically, we reparameterize the feature-varying procedure and devise the corresponding ordinary differential equation (ODE) system to compute the optimal solutions of the new model status. Simulation studies reveal that the proposed DFLS can substantially ease the computational cost without forgetting.","https://ojs.aaai.org/index.php/AAAI/article/view/26029/25801"
"26030","FanoutNet: A Neuralized PCB Fanout Automation Method Using Deep Reinforcement Learning","['Haiyun Li', 'Jixin Zhang', 'Ning Xu', 'Mingyu Liu']","['Wuhan University of Technology', 'Hubei University of Technology', 'Wuhan University of Technology', 'Huawei Device Co., Ltd.']","['ML: Applications', 'CSO: Applications', 'APP: Design', 'ML: Deep Neural Network Algorithms', 'ML: Reinforcement Learning Algorithms']","Li, H., Zhang, J., Xu, N., & Liu, M. (2023). FanoutNet: A Neuralized PCB Fanout Automation Method Using Deep Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8554-8561. https://doi.org/10.1609/aaai.v37i7.26030","Abstract 					In modern electronic manufacturing processes, multi-layer Printed Circuit Board (PCB) routing requires connecting more than hundreds of nets with perplexing topology under complex routing constraints and highly limited resources, so that takes intense effort and time of human engineers. PCB fanout as a pre-design of PCB routing has been proved to be an ideal technique to reduce the complexity of PCB routing by pre-allocating resources and pre-routing. However, current PCB fanout design heavily relies on the experience of human engineers, and there is no existing solution for PCB fanout automation in industry, which limits the quality of PCB routing automation. To address the problem, we propose a neuralized PCB fanout method by deep reinforcement learning. To the best of our knowledge, we are the first in the literature to propose the automation method for PCB fanout. We combine with Convolution Neural Network (CNN) and attention-based network to train our fanout policy model and value model. The models learn representations of PCB layout and netlist to make decisions and evaluations in place of human engineers. We employ Proximal Policy Optimization (PPO) to update the parameters of the models. In addition, we apply our PCB fanout method to a PCB router to improve the quality of PCB routing. Extensive experimental results on real-world industrial PCB benchmarks demonstrate that our approach achieves 100% routability in all industrial cases and improves wire length by an average of 6.8%, which makes a significant improvement compared with the state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26030/25802"
"26031","Causal Recurrent Variational Autoencoder for Medical Time Series Generation","['Hongming Li', 'Shujian Yu', 'Jose Principe']","['University of Florida', 'UiT - The Arctic University of Norway', 'University of Florida']","['ML: Deep Generative Models & Autoencoders', 'CMS: Brain Modeling', 'ML: Causal Learning', 'ML: Time-Series/Data Streams']","Li, H., Yu, S., & Principe, J. (2023). Causal Recurrent Variational Autoencoder for Medical Time Series Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8562-8570. https://doi.org/10.1609/aaai.v37i7.26031","Abstract 					We propose causal recurrent variational autoencoder (CR-VAE), a novel generative model that is able to learn a Granger causal graph from a multivariate time series x and incorporates the underlying causal mechanism into its data generation process. Distinct to the classical recurrent VAEs, our CR-VAE uses a multi-head decoder, in which the p-th head is responsible for generating the p-th dimension of x (i.e., x^p). By imposing a sparsity-inducing penalty on the weights (of the decoder) and encouraging specific sets of weights to be zero, our CR-VAE learns a sparse adjacency matrix that encodes causal relations between all pairs of variables. Thanks to this causal matrix, our decoder strictly obeys the underlying principles of Granger causality, thereby making the data generating process transparent. We develop a two-stage approach to train the overall objective. Empirically, we evaluate the behavior of our model in synthetic data and two real-world human brain datasets involving, respectively, the electroencephalography (EEG) signals and the functional magnetic resonance imaging (fMRI) data. Our model consistently outperforms state-of-the-art time series generative models both qualitatively and quantitatively. Moreover, it also discovers a faithful causal graph with similar or improved accuracy over existing Granger causality-based causal inference methods.  Code of CR-VAE is publicly available at https://github.com/hongmingli1995/CR-VAE.","https://ojs.aaai.org/index.php/AAAI/article/view/26031/25803"
"26032","Dual Mutual Information Constraints for Discriminative Clustering","['Hongyu Li', 'Lefei Zhang', 'Kehua Su']","['School of Computer Science, Wuhan University, Wuhan, P. R. China', 'School of Computer Science, Wuhan University, Wuhan, P. R. China\nHubei Luojia Laboratory, Wuhan, P. R. China', 'School of Computer Science, Wuhan University, Wuhan, P. R. China']","['ML: Clustering', 'ML: Dimensionality Reduction/Feature Selection']","Li, H., Zhang, L., & Su, K. (2023). Dual Mutual Information Constraints for Discriminative Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8571-8579. https://doi.org/10.1609/aaai.v37i7.26032","Abstract 					Deep clustering is a fundamental task in machine learning and data mining that aims at learning clustering-oriented feature representations. In previous studies, most of deep clustering methods follow the idea of self-supervised representation learning by maximizing the consistency of all similar instance pairs while ignoring the effect of feature redundancy on clustering performance. In this paper, to address the above issue, we design a dual mutual information constrained clustering method named DMICC which is based on deep contrastive clustering architecture, in which the dual mutual information constraints are particularly employed with solid theoretical guarantees and experimental validations. Specifically, at the feature level, we reduce the redundancy among features by minimizing the mutual information across all the dimensionalities to encourage the neural network to extract more discriminative features. At the instance level, we maximize the mutual information of the similar instance pairs to obtain more unbiased and robust representations. The dual mutual information constraints happen simultaneously and thus complement each other to jointly optimize better features that are suitable for the clustering task. We also prove that our adopted mutual information constraints are superior in feature extraction, and the proposed dual mutual information constraints are clearly bounded and thus solvable. Extensive experiments on five benchmark datasets show that our proposed approach outperforms most other clustering algorithms. The code is available at https://github.com/Li-Hyn/DMICC.","https://ojs.aaai.org/index.php/AAAI/article/view/26032/25804"
"26033","AdaBoost.C2: Boosting Classifiers Chains for Multi-Label Classification","['Jiaxuan Li', 'Xiaoyan Zhu', 'Jiayin Wang']","[""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", 'Xi’an Jiaotong University']","['ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Ensemble Methods']","Li, J., Zhu, X., & Wang, J. (2023). AdaBoost.C2: Boosting Classifiers Chains for Multi-Label Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8580-8587. https://doi.org/10.1609/aaai.v37i7.26033","Abstract 					During the last decades, multi-label classification (MLC) has attracted the attention of more and more researchers due to its wide real-world applications. Many boosting methods for MLC have been proposed and achieved great successes. However, these methods only extend existing boosting frameworks to MLC and take loss functions in multi-label version to guide the iteration. These loss functions generally give a comprehensive evaluation on the label set entirety, and thus the characteristics of different labels are ignored. In this paper, we propose a multi-path AdaBoost framework specific to MLC, where each boosting path is established for distinct label and the combination of them is able to provide a maximum optimization to Hamming Loss. In each iteration, classifiers chain is taken as the base classifier to strengthen the connection between multiple AdaBoost paths and exploit the label correlation. Extensive experiments demonstrate the effectiveness of the proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/26033/25805"
"26034","Scaling Up Dynamic Graph Representation Learning via Spiking Neural Networks","['Jintang Li', 'Zhouxin Yu', 'Zulun Zhu', 'Liang Chen', 'Qi Yu', 'Zibin Zheng', 'Sheng Tian', 'Ruofan Wu', 'Changhua Meng']","['Sun Yat-sen University', 'Sun Yat-sen University', 'Rochester Institute of Technology', 'Sun Yat-sen University', 'Rochester Institute of Technology', 'Sun Yat-sen University', 'Ant Group', 'Ant Group', 'Ant Group']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data']","Li, J., Yu, Z., Zhu, Z., Chen, L., Yu, Q., Zheng, Z., Tian, S., Wu, R., & Meng, C. (2023). Scaling Up Dynamic Graph Representation Learning via Spiking Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8588-8596. https://doi.org/10.1609/aaai.v37i7.26034","Abstract 					Recent years have seen a surge in research on dynamic graph representation learning, which aims to model temporal graphs that are dynamic and evolving constantly over time. However, current work typically models graph dynamics with recurrent neural networks (RNNs), making them suffer seriously from computation and memory overheads on large temporal graphs. So far, scalability of dynamic graph representation learning on large temporal graphs remains one of the major challenges. In this paper, we present a scalable framework, namely SpikeNet, to efficiently capture the temporal and structural patterns of temporal graphs. We explore a new direction in that we can capture the evolving dynamics of temporal graphs with spiking neural networks (SNNs) instead of RNNs. As a low-power alternative to RNNs, SNNs explicitly model graph dynamics as spike trains of neuron populations and enable spike-based propagation in an efficient way. Experiments on three large real-world temporal graph datasets demonstrate that SpikeNet outperforms strong baselines on the temporal node classification task with lower computational costs. Particularly, SpikeNet generalizes to a large temporal graph (2.7M nodes and 13.9M edges) with significantly fewer parameters and computation overheads.","https://ojs.aaai.org/index.php/AAAI/article/view/26034/25806"
"26035","Improved Kernel Alignment Regret Bound for Online Kernel Learning","['Junfan Li', 'Shizhong Liao']","['Tianjin University', 'Tianjin University']","['ML: Online Learning & Bandits', 'ML: Kernel Methods']","Li, J., & Liao, S. (2023). Improved Kernel Alignment Regret Bound for Online Kernel Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8597-8604. https://doi.org/10.1609/aaai.v37i7.26035","Abstract 					In this paper, we improve the kernel alignment regret bound for online kernel learning in the regime of the Hinge loss function. Previous algorithm achieves a regret of O((A_TT ln T)^{1/4}) at a computational complexity (space and per-round time) of O((A_TT ln T)^{1/2}), where A_T is called kernel alignment. We propose an algorithm whose regret bound and computational complexity are better than previous results. Our results depend on the decay rate of eigenvalues of the kernel matrix. If the eigenvalues of the kernel matrix decay exponentially, then our algorithm enjoys a regret of O((A_T)^{1/2}) at a computational complexity of O((ln T)^2). Otherwise, our algorithm enjoys a regret of O((A_TT)^{1/4}) at a computational complexity of O((A_TT)^{1/2}). We extend our algorithm to batch learning and obtain a O(T^{-1}(E[A_T])^{1/2}) excess risk bound which improves the previous O(T^{-1/2}) bound.","https://ojs.aaai.org/index.php/AAAI/article/view/26035/25807"
"26036","VBLC: Visibility Boosting and Logit-Constraint Learning for Domain Adaptive Semantic Segmentation under Adverse Conditions","['Mingjia Li', 'Binhui Xie', 'Shuang Li', 'Chi Harold Liu', 'Xinjing Cheng']","['Beijing Institute of Technology', 'Beijing Institute of Technology', 'Beijing Institute of Technology', 'Beijing Institute of Technology', 'Tsinghua University\nInceptio Technology']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'CV: Segmentation']","Li, M., Xie, B., Li, S., Liu, C. H., & Cheng, X. (2023). VBLC: Visibility Boosting and Logit-Constraint Learning for Domain Adaptive Semantic Segmentation under Adverse Conditions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8605-8613. https://doi.org/10.1609/aaai.v37i7.26036","Abstract 					Generalizing models trained on normal visual conditions to target domains under adverse conditions is demanding in the practical systems. One prevalent solution is to bridge the domain gap between clear- and adverse-condition images to make satisfactory prediction on the target. However, previous methods often reckon on additional reference images of the same scenes taken from normal conditions, which are quite tough to collect in reality. Furthermore, most of them mainly focus on individual adverse condition such as nighttime or foggy, weakening the model versatility when encountering other adverse weathers. To overcome the above limitations, we propose a novel framework, Visibility Boosting and Logit-Constraint learning (VBLC), tailored for superior normal-toadverse adaptation. VBLC explores the potential of getting rid of reference images and resolving the mixture of adverse conditions simultaneously. In detail, we first propose the visibility boost module to dynamically improve target images via certain priors in the image level. Then, we figure out the overconfident drawback in the conventional cross-entropy loss for self-training method and devise the logit-constraint learning, which enforces a constraint on logit outputs during training to mitigate this pain point. To the best of our knowledge, this is a new perspective for tackling such a challenging task. Extensive experiments on two normal-to-adverse domain adaptation benchmarks, i.e., Cityscapes to ACDC and Cityscapes to FoggyCityscapes + RainCityscapes, verify the effectiveness of VBLC, where it establishes the new state of the art. Code is available at https://github.com/BIT-DA/VBLC.","https://ojs.aaai.org/index.php/AAAI/article/view/26036/25808"
"26037","Understanding the Generalization Performance of Spectral Clustering Algorithms","['Shaojie Li', 'Sheng Ouyang', 'Yong Liu']","['Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China\nBeijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China', 'Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China\nBeijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China', 'Gaoling School of Artificial Intelligence, Renmin University of China, Beijing, China\nBeijing Key Laboratory of Big Data Management and Analysis Methods, Beijing, China']","['ML: Clustering', 'ML: Learning Theory', 'ML: Unsupervised & Self-Supervised Learning']","Li, S., Ouyang, S., & Liu, Y. (2023). Understanding the Generalization Performance of Spectral Clustering Algorithms. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8614-8621. https://doi.org/10.1609/aaai.v37i7.26037","Abstract 					The theoretical analysis of spectral clustering is mainly devoted to consistency, while there is little research on its generalization performance. In this paper, we study the excess risk bounds of the popular spectral clustering algorithms: relaxed RatioCut and relaxed NCut. Our analysis follows the two practical steps of spectral clustering algorithms: continuous solution and discrete solution. Firstly, we provide the convergence rate of the excess risk bounds between the empirical continuous optimal solution and the population-level continuous optimal solution. Secondly, we show the fundamental quantity influencing the excess risk between the empirical discrete optimal solution and the population-level discrete optimal solution. At the empirical level, algorithms can be designed to reduce this quantity. Based on our theoretical analysis, we propose two novel algorithms that can penalize this quantity and, additionally, can cluster the out-of-sample data without re-eigendecomposition on the overall samples. Numerical experiments on toy and real datasets confirm the effectiveness of our proposed algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26037/25809"
"26038","Restructuring Graph for Higher Homophily via Adaptive Spectral Clustering","['Shouheng Li', 'Dongwoo Kim', 'Qing Wang']","['The Australian National University', 'Pohang University of Science and Technology', 'The Australian National University']","['ML: Representation Learning', 'ML: Clustering', 'ML: Dimensionality Reduction/Feature Selection', 'ML: Semi-Supervised Learning']","Li, S., Kim, D., & Wang, Q. (2023). Restructuring Graph for Higher Homophily via Adaptive Spectral Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8622-8630. https://doi.org/10.1609/aaai.v37i7.26038","Abstract 					While a growing body of literature has been studying new Graph Neural Networks (GNNs) that work on both homophilic and heterophilic graphs, little has been done on adapting classical GNNs to less-homophilic graphs. Although the ability to handle less-homophilic graphs is restricted, classical GNNs still stand out in several nice properties such as efficiency, simplicity, and explainability. In this work, we propose a novel graph restructuring method that can be integrated into any type of GNNs, including classical GNNs, to leverage the benefits of existing GNNs while alleviating their limitations. Our contribution is threefold: a) learning the weight of pseudo-eigenvectors for an adaptive spectral clustering that aligns well with known node labels, b) proposing a new density-aware homophilic metric that is robust to label imbalance, and c) reconstructing the adjacency matrix based on the result of adaptive spectral clustering to maximize the homophilic scores. The experimental results show that our graph restructuring method can significantly boost the performance of six classical GNNs by an average of 25% on less-homophilic graphs. The boosted performance is comparable to state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26038/25810"
"26039","Nearest-Neighbor Sampling Based Conditional Independence Testing","['Shuai Li', 'Ziqi Chen', 'Hongtu Zhu', 'Christina Dan Wang', 'Wang Wen']","['School of Statistics, KLATASDS-MOE, East China Normal University, Shanghai, China', 'School of Statistics, KLATASDS-MOE, East China Normal University, Shanghai, China', 'Departments of Biostatistics, Statistics, Computer Science, and Genetics, The University of North Carolina at Chapel Hill, Chapel Hill, USA', 'Business Division, New York University Shanghai, Shanghai, China', 'School of Mathematics and Statistics, Central South University, Changsha, China']","['ML: Causal Learning', 'ML: Classification and Regression', 'ML: Deep Generative Models & Autoencoders']","Li, S., Chen, Z., Zhu, H., Wang, C. D., & Wen, W. (2023). Nearest-Neighbor Sampling Based Conditional Independence Testing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8631-8639. https://doi.org/10.1609/aaai.v37i7.26039","Abstract 					The conditional randomization test (CRT) was recently proposed to test whether two random variables X and Y are conditionally independent given random variables Z. The CRT assumes that the conditional distribution of X given Z is known under the null hypothesis and then it is compared to the distribution of the observed samples of the original data. The aim of this paper is to develop a novel alternative of CRT by using nearest-neighbor sampling without assuming the exact form of the distribution of X given Z. Specifically, we utilize the computationally efficient 1-nearest-neighbor to approximate the conditional distribution that encodes the null hypothesis. Then, theoretically, we show that the distribution of the generated samples is very close to the true conditional distribution in terms of total variation distance.  Furthermore, we take the classifier-based conditional mutual information estimator as our test statistic. The test statistic as an empirical fundamental information theoretic quantity is able to well capture the conditional-dependence feature. We show that our proposed test is computationally very fast, while controlling type I and II errors quite well. Finally, we demonstrate the efficiency of our proposed test in both synthetic and real data analyses.","https://ojs.aaai.org/index.php/AAAI/article/view/26039/25811"
"26040","Towards Fine-Grained Explainability for Heterogeneous Graph Neural Network","['Tong Li', 'Jiale Deng', 'Yanyan Shen', 'Luyu Qiu', 'Huang Yongxiang', 'Caleb Chen Cao']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Huawei Research Hong Kong', 'Huawei Research Hong Kong', 'Huawei Research Hong Kong']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'ML: Graph-based Machine Learning']","Li, T., Deng, J., Shen, Y., Qiu, L., Yongxiang, H., & Cao, C. C. (2023). Towards Fine-Grained Explainability for Heterogeneous Graph Neural Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8640-8647. https://doi.org/10.1609/aaai.v37i7.26040","Abstract 					Heterogeneous graph neural networks (HGNs) are prominent approaches to node classification tasks on heterogeneous graphs. Despite the superior performance, insights about the predictions made from HGNs are obscure to humans. Existing explainability techniques are mainly proposed for GNNs on homogeneous graphs. They focus on highlighting salient graph objects to the predictions whereas the problem of how these objects affect the predictions remains unsolved. Given heterogeneous graphs with complex structures and rich semantics, it is imperative that salient objects can be accompanied with their influence paths to the predictions, unveiling the reasoning process of HGNs. In this paper, we develop xPath, a new framework that provides fine-grained explanations for black-box HGNs specifying a cause node with its influence path to the target node. In xPath, we differentiate the influence of a node on the prediction w.r.t. every individual influence path, and measure the influence by perturbing graph structure via a novel graph rewiring algorithm. Furthermore, we introduce a greedy search algorithm to find the most influential fine-grained explanations efficiently. Empirical results on various HGNs and heterogeneous graphs show that xPath yields faithful explanations efficiently, outperforming the adaptations of advanced GNN explanation approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/26040/25812"
"26041","Metric Nearness Made Practical","['Wenye Li', 'Fangchen Yu', 'Zichen Ma']","['The Chinese University of Hong Kong, Shenzhen\nShenzhen Research Institute of Big Data', 'The Chinese University of Hong Kong, Shenzhen', 'The Chinese University of Hong Kong, Shenzhen']","['ML: Optimization', 'ML: Unsupervised & Self-Supervised Learning']","Li, W., Yu, F., & Ma, Z. (2023). Metric Nearness Made Practical. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8648-8656. https://doi.org/10.1609/aaai.v37i7.26041","Abstract 					Given a square matrix with noisy dissimilarity measures between pairs of data samples, the metric nearness model computes the best approximation of the matrix from a set of valid distance metrics. Despite its wide applications in machine learning and data processing tasks, the model faces non-trivial computational requirements in seeking the solution due to the large number of metric constraints associated with the feasible region. Our work designed a practical approach in two stages to tackle the challenge and improve the model's scalability and applicability. The first stage computes a fast yet high-quality approximate solution from a set of isometrically embeddable metrics, further improved by an effective heuristic. The second stage refines the approximate solution with the Halpern-Lions-Wittmann-Bauschke projection algorithm, which converges quickly to the optimal solution. In empirical evaluations, the proposed approach runs at least an order of magnitude faster than the state-of-the-art solutions, with significantly improved scalability, complete conformity to constraints, less memory consumption, and other desirable features in real applications.","https://ojs.aaai.org/index.php/AAAI/article/view/26041/25813"
"26042","Predictive Exit: Prediction of Fine-Grained Early Exits for Computation- and Energy-Efficient Inference","['Xiangjie Li', 'Chenfei Lou', 'Yuchi Chen', 'Zhengping Zhu', 'Yingtao Shen', 'Yehan Ma', 'An Zou']","['Shanghai Jiao Tong Univerisity', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['ML: Learning on the Edge & Model Compression', 'APP: Energy', 'Environment & Sustainability', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms']","Li, X., Lou, C., Chen, Y., Zhu, Z., Shen, Y., Ma, Y., & Zou, A. (2023). Predictive Exit: Prediction of Fine-Grained Early Exits for Computation- and Energy-Efficient Inference. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8657-8665. https://doi.org/10.1609/aaai.v37i7.26042","Abstract 					By adding exiting layers to the deep learning networks, early exit can terminate the inference earlier with accurate results. However, the passive decision-making of whether to exit or continue the next layer has to go through every pre-placed exiting layer until it exits. In addition, it is hard to adjust the configurations of the computing platforms alongside the inference proceeds. By incorporating a low-cost prediction engine, we propose a Predictive Exit framework for computation- and energy-efficient deep learning applications. Predictive Exit can forecast where the network will exit (i.e., establish the number of remaining layers to finish the inference), which effectively reduces the network computation cost by exiting on time without running every pre-placed exiting layer. Moreover, according to the number of remaining layers, proper computing configurations (i.e., frequency and voltage) are selected to execute the network to further save energy. Extensive experimental results demonstrate that Predictive Exit achieves up to 96.2% computation reduction and 72.9% energy-saving compared with classic deep learning networks; and 12.8% computation reduction and 37.6% energy-saving compared with the early exit under state-of-the-art exiting strategies, given the same inference accuracy and latency.","https://ojs.aaai.org/index.php/AAAI/article/view/26042/25814"
"26043","Learning with Partial Labels from Semi-supervised Perspective","['Ximing Li', 'Yuanzhi Jiang', 'Changchun Li', 'Yiyuan Wang', 'Jihong Ouyang']","['Jilin University', 'Jilin University', 'Jilin University', 'Northeast Normal University', 'Jilin University']","['ML: Semi-Supervised Learning', 'ML: Classification and Regression', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification']","Li, X., Jiang, Y., Li, C., Wang, Y., & Ouyang, J. (2023). Learning with Partial Labels from Semi-supervised Perspective. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8666-8674. https://doi.org/10.1609/aaai.v37i7.26043","Abstract 					Partial Label (PL) learning refers to the task of learning from the partially labeled data, where each training instance is ambiguously equipped with a set of candidate labels but only one is valid. Advances in the recent deep PL learning literature have shown that the deep learning paradigms, e.g., self-training, contrastive learning, or class activate values, can achieve promising performance. Inspired by the impressive success of deep Semi-Supervised (SS) learning, we transform the PL learning problem into the SS learning problem, and propose a novel PL learning method, namely Partial Label learning with Semi-supervised Perspective (PLSP). Specifically, we first form the pseudo-labeled dataset by selecting a small number of reliable pseudo-labeled instances with high-confidence prediction scores and treating the remaining instances as pseudo-unlabeled ones. Then we design a SS learning objective, consisting of a supervised loss for pseudo-labeled instances and a semantic consistency regularization for pseudo-unlabeled instances. We further introduce a complementary regularization for those non-candidate labels to constrain the model predictions on them to be as small as possible. Empirical results demonstrate that PLSP significantly outperforms the existing PL baseline methods, especially on high ambiguity levels. Code available: https://github.com/changchunli/PLSP.","https://ojs.aaai.org/index.php/AAAI/article/view/26043/25815"
"26044","Learning Compact Features via In-Training Representation Alignment","['Xin Li', 'Xiangrui Li', 'Deng Pan', 'Yao Qiang', 'Dongxiao Zhu']","['Wayne State University', 'Wayne State University', 'Wayne State University', 'Wayne State University', 'Wayne State Unversity']","['ML: Representation Learning', 'ML: Learning Theory']","Li, X., Li, X., Pan, D., Qiang, Y., & Zhu, D. (2023). Learning Compact Features via In-Training Representation Alignment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8675-8683. https://doi.org/10.1609/aaai.v37i7.26044","Abstract 					Deep neural networks (DNNs) for supervised learning can be viewed as a pipeline of the feature extractor (i.e., last hidden layer) and a linear classifier (i.e., output layer) that are trained jointly with stochastic gradient descent (SGD) on the loss function (e.g., cross-entropy). In each epoch, the true gradient of the loss function is estimated using a mini-batch sampled from the training set and model parameters are then updated with the mini-batch gradients. Although the latter provides an unbiased estimation of the former, they are subject to substantial variances derived from the size and number of sampled mini-batches, leading to noisy and jumpy updates. To stabilize such undesirable variance in estimating the true gradients, we propose In-Training Representation Alignment (ITRA) that explicitly aligns feature distributions of two different mini-batches with a matching loss in the SGD training process. We also provide a rigorous analysis of the desirable effects of the matching loss on feature representation learning: (1) extracting compact feature representation; (2) reducing over-adaption on mini-batches via an adaptively weighting mechanism; and (3) accommodating to multi-modalities. Finally, we conduct large-scale experiments on both image and text classifications to demonstrate its superior performance to the strong baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/26044/25816"
"26045","An Extreme-Adaptive Time Series Prediction Model Based on Probability-Enhanced LSTM Neural Networks","['Yanhong Li', 'Jack Xu', 'David C. Anastasiu']","['Santa Clara University', 'Santa Clara Valley Water District', 'Santa Clara University']","['ML: Time-Series/Data Streams', 'ML: Classification and Regression']","Li, Y., Xu, J., & Anastasiu, D. C. (2023). An Extreme-Adaptive Time Series Prediction Model Based on Probability-Enhanced LSTM Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8684-8691. https://doi.org/10.1609/aaai.v37i7.26045","Abstract 					Forecasting time series with extreme events has been a challenging and prevalent research topic, especially when the time series data are affected by complicated uncertain factors, such as is the case in hydrologic prediction. Diverse traditional and deep learning models have been applied to discover the nonlinear relationships and recognize the complex patterns in these types of data. However, existing methods usually ignore the negative influence of imbalanced data, or severe events, on model training. Moreover, methods are usually evaluated on a small number of generally well-behaved time series, which does not show their ability to generalize. To tackle these issues, we propose a novel probability-enhanced neural network model, called NEC+, which concurrently learns extreme and normal prediction functions and a way to choose among them via selective back propagation. We evaluate the proposed model on the difficult 3-day ahead hourly water level prediction task applied to 9 reservoirs in California. Experimental results demonstrate that the proposed model significantly outperforms state-of-the-art baselines and exhibits superior generalization ability on data with diverse distributions.","https://ojs.aaai.org/index.php/AAAI/article/view/26045/25817"
"26046","Implicit Stochastic Gradient Descent for Training Physics-Informed Neural Networks","['Ye Li', 'Song-Can Chen', 'Sheng-Jun Huang']","['Nanjing University of Aeronautics and Astronautics', 'Nanjing University of Aeronautics and Astronautics', 'Nanjing University of Aeronautics and Astronautics']","['ML: Optimization', 'ML: Applications', 'ML: Auto ML and Hyperparameter Tuning', 'ML: Deep Learning Theory', 'ML: Deep Neural Architectures', 'ML: Other Foundations of Machine Learning', 'ML: Unsupervised & Self-Supervised Learning']","Li, Y., Chen, S.-C., & Huang, S.-J. (2023). Implicit Stochastic Gradient Descent for Training Physics-Informed Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8692-8700. https://doi.org/10.1609/aaai.v37i7.26046","Abstract 					Physics-informed neural networks (PINNs) have effectively been demonstrated in solving forward and inverse differential equation problems, but they are still trapped in training failures when the target functions to be approximated exhibit high-frequency or multi-scale features. In this paper, we propose to employ implicit stochastic gradient descent (ISGD) method to train PINNs for improving the stability of training process. We heuristically analyze how ISGD overcome stiffness in the gradient flow dynamics of PINNs, especially for problems with multi-scale solutions. We theoretically prove that for two-layer fully connected neural networks with large hidden nodes, randomly initialized ISGD converges to a globally optimal solution for the quadratic loss function. Empirical results demonstrate that ISGD works well in practice and compares favorably to other gradient-based optimization methods such as SGD and Adam, while can also effectively address the numerical stiffness in training dynamics via gradient descent.","https://ojs.aaai.org/index.php/AAAI/article/view/26046/25818"
"26047","Provable Pathways: Learning Multiple Tasks over Multiple Paths","['Yingcong Li', 'Samet Oymak']","['University of California, Riverside', 'University of California, Riverside\nUniversity of Michigan, Ann Arbor']","['ML: Learning Theory', 'ML: Representation Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Li, Y., & Oymak, S. (2023). Provable Pathways: Learning Multiple Tasks over Multiple Paths. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8701-8710. https://doi.org/10.1609/aaai.v37i7.26047","Abstract 					Constructing useful representations across a large number of tasks is a key requirement for sample-efficient intelligent systems. A traditional idea in multitask learning (MTL) is building a shared representation across tasks which can then be adapted to new tasks by tuning last layers. A desirable refinement of using a shared one-fits-all representation is to construct task-specific representations. To this end, recent PathNet/muNet architectures represent individual tasks as pathways within a larger supernet. The subnetworks induced by pathways can be viewed as task-specific representations that are composition of modules within supernet's computation graph. This work explores the pathways proposal from the lens of statistical learning: We first develop novel generalization bounds for empirical risk minimization problems learning multiple tasks over multiple paths (Multipath MTL). In conjunction, we formalize the benefits of resulting multipath representation when adapting to new downstream tasks. Our bounds are expressed in terms of Gaussian complexity, lead to tangible guarantees for the class of linear representations, and provide novel insights into the quality and benefits of a multipath representation. When computation graph is a tree, Multipath MTL hierarchically clusters the tasks and builds cluster-specific representations. We provide further discussion and experiments for hierarchical MTL and rigorously identify the conditions under which Multipath MTL is provably superior to traditional MTL approaches with shallow supernets.","https://ojs.aaai.org/index.php/AAAI/article/view/26047/25819"
"26048","Towards Inference Efficient Deep Ensemble Learning","['Ziyue Li', 'Kan Ren', 'Yifan Yang', 'Xinyang Jiang', 'Yuqing Yang', 'Dongsheng Li']","['Microsoft Research', 'Microsoft Research', 'Microsoft Research', 'Microsoft Research', 'Microsoft Research', 'Microsoft Research']","['ML: Ensemble Methods']","Li, Z., Ren, K., Yang, Y., Jiang, X., Yang, Y., & Li, D. (2023). Towards Inference Efficient Deep Ensemble Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8711-8719. https://doi.org/10.1609/aaai.v37i7.26048","Abstract 					Ensemble methods can deliver surprising performance gains but also bring significantly higher computational costs, e.g., can be up to 2048X in large-scale ensemble tasks. However, we found that the majority of computations in ensemble methods are redundant. For instance, over 77% of samples in CIFAR-100 dataset can be correctly classified with only a single ResNet-18 model, which indicates that only around 23% of the samples need an ensemble of extra models. To this end, we propose an inference efficient ensemble learning method, to simultaneously optimize for effectiveness and efficiency in ensemble learning. More specifically, we regard ensemble of models as a sequential inference process and learn the optimal halting event for inference on a specific sample. At each timestep of the inference process, a common selector judges if the current ensemble has reached ensemble effectiveness and halt further inference, otherwise filters this challenging sample for the subsequent models to conduct more powerful ensemble. Both the base models and common selector are jointly optimized to dynamically adjust ensemble inference for different samples with various hardness, through the novel optimization goals including sequential ensemble boosting and computation saving. The experiments with different backbones on real-world datasets illustrate our method can bring up to 56% inference cost reduction while maintaining comparable performance to full ensemble, achieving significantly better ensemble utility than other baselines. Code and supplemental materials are available at https://seqml.github.io/irene.","https://ojs.aaai.org/index.php/AAAI/article/view/26048/25820"
"26049","SplitNet: A Reinforcement Learning Based Sequence Splitting Method for the MinMax Multiple Travelling Salesman Problem","['Hebin Liang', 'Yi Ma', 'Zilin Cao', 'Tianyang Liu', 'Fei Ni', 'Zhigang Li', 'Jianye Hao']","['Tianjin University', 'Tianjin University', 'Tianjin University', 'Tianjin University', 'Tianjin University', 'Tianjin University', 'Tianjin University\nNoah’s Ark Lab, Huawei']","['ML: Applications']","Liang, H., Ma, Y., Cao, Z., Liu, T., Ni, F., Li, Z., & Hao, J. (2023). SplitNet: A Reinforcement Learning Based Sequence Splitting Method for the MinMax Multiple Travelling Salesman Problem. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8720-8727. https://doi.org/10.1609/aaai.v37i7.26049","Abstract 					MinMax Multiple Travelling Salesman Problem (mTSP) is an important class of combinatorial optimization problems with many practical applications, of which the goal is to minimize the longest tour of all vehicles. Due to its high computational complexity, existing methods for solving this problem cannot obtain a solution of satisfactory quality with fast speed, especially when the scale of the problem is large. In this paper, we propose a learning-based method named SplitNet to transform the single TSP solutions into the MinMax mTSP solutions of the same instances. Specifically, we generate single TSP solution sequences and split them into mTSP subsequences using an attention-based model trained by reinforcement learning. We also design a decision region for the splitting policy, which significantly reduces the policy action space on instances of various scales and thus improves the generalization ability of SplitNet. The experimental results show that SplitNet generalizes well and outperforms existing learning-based baselines and Google OR-Tools on widely-used random datasets of different scales and public datasets with fast solving speed.","https://ojs.aaai.org/index.php/AAAI/article/view/26049/25821"
"26050","Stepdown SLOPE for Controlled Feature Selection","['Jingxuan Liang', 'Xuelin Zhang', 'Hong Chen', 'Weifu Li', 'Xin Tang']","['Huazhong Agricultural University', 'Huazhong Agricultural University', 'Huazhong Agricultural University\nEngineering Research Center of Intelligent Technology for Agriculture, Ministry of Education\nHubei Engineering Technology Research Center of Agricultural Big Data', 'Huazhong Agricultural University\nKey Laboratory of Smart Farming for Agricultural Animals\nHubei Engineering Technology Research Center of Agricultural Big Data', 'Ping An Property & Casualty Insurance Company']","['ML: Dimensionality Reduction/Feature Selection']","Liang, J., Zhang, X., Chen, H., Li, W., & Tang, X. (2023). Stepdown SLOPE for Controlled Feature Selection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8728-8736. https://doi.org/10.1609/aaai.v37i7.26050","Abstract 					Sorted L-One Penalized Estimation (SLOPE) has shown the nice theoretical property as well as empirical behavior recently on the false discovery rate (FDR) control of high-dimensional feature selection by adaptively imposing the non-increasing sequence of tuning parameters on the sorted L1 penalties. This paper goes beyond the previous concern limited to the FDR control by considering the stepdown-based SLOPE in order to control the probability of k or more false rejections (k-FWER) and the false discovery proportion (FDP). Two new SLOPEs, called k-SLOPE and F-SLOPE, are proposed to realize k-FWER and FDP control respectively, where the stepdown procedure is injected into the SLOPE scheme. For the proposed stepdown SLOPEs, we establish their theoretical guarantees on controlling k-FWER and FDP under the orthogonal design setting, and also provide an intuitive guideline for the choice of regularization parameter sequence in much general setting. Empirical evaluations on simulated data validate the effectiveness of our approaches on controlled feature selection and support our theoretical findings.","https://ojs.aaai.org/index.php/AAAI/article/view/26050/25822"
"26051","Positive Distribution Pollution: Rethinking Positive Unlabeled Learning from a Unified Perspective","['Qianqiao Liang', 'Mengying Zhu', 'Yan Wang', 'Xiuyuan Wang', 'Wanjia Zhao', 'Mengyuan Yang', 'Hua Wei', 'Bing Han', 'Xiaolin Zheng']","['Zhejiang University', 'Zhejiang University', 'Macquarie University, Austrilia', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'MYbank, Ant Group', 'MYbank, Ant Group', 'Zhejiang University']","['ML: Semi-Supervised Learning', 'ML: Deep Generative Models & Autoencoders', 'ML: Unsupervised & Self-Supervised Learning']","Liang, Q., Zhu, M., Wang, Y., Wang, X., Zhao, W., Yang, M., Wei, H., Han, B., & Zheng, X. (2023). Positive Distribution Pollution: Rethinking Positive Unlabeled Learning from a Unified Perspective. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8737-8745. https://doi.org/10.1609/aaai.v37i7.26051","Abstract 					Positive Unlabeled (PU) learning, which has a wide range of applications, is becoming increasingly prevalent. However, it suffers from problems such as data imbalance, selection bias, and prior agnostic in real scenarios. Existing studies focus on addressing part of these problems, which fail to provide a unified perspective to understand these problems. In this paper, we first rethink these problems by analyzing a typical PU scenario and come up with an insightful point of view that all these problems are inherently connected to one problem, i.e., positive distribution pollution, which refers to the inaccuracy in estimating positive data distribution under very little labeled data. Then, inspired by this insight, we devise a variational model named CoVPU, which addresses all three problems in a unified perspective by targeting the positive distribution pollution problem. CoVPU not only accurately separates the positive data from the unlabeled data based on discrete normalizing flows, but also effectively approximates the positive distribution based on our derived unbiased rebalanced risk estimator and supervises the approximation based on a novel prior-free variational loss. Rigorous theoretical analysis proves the convergence of CoVPU to an optimal Bayesian classifier. Extensive experiments demonstrate the superiority of CoVPU over the state-of-the-art PU learning methods under these problems.","https://ojs.aaai.org/index.php/AAAI/article/view/26051/25823"
"26052","Policy-Independent Behavioral Metric-Based Representation for Deep Reinforcement Learning","['Weijian Liao', 'Zongzhang Zhang', 'Yang Yu']","['Nanjing University', 'Nanjing University', 'Nanjing University\nPeng Cheng Laboratory, Shenzhen']","['ML: Reinforcement Learning Algorithms', 'ML: Representation Learning', 'ML: Scalability of ML Systems']","Liao, W., Zhang, Z., & Yu, Y. (2023). Policy-Independent Behavioral Metric-Based Representation for Deep Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8746-8754. https://doi.org/10.1609/aaai.v37i7.26052","Abstract 					Behavioral metrics can calculate the distance between states or state-action pairs from the rewards and transitions difference. By virtue of their capability to filter out task-irrelevant information in theory, using them to shape a state embedding space becomes a new trend of representation learning for deep reinforcement learning (RL), especially when there are explicit distracting factors in observation backgrounds. However, due to the tight coupling between the metric and the RL policy, such metric-based methods may result in less informative embedding spaces which can weaken their aid to the baseline RL algorithm and even consume more samples to learn. We resolve this by proposing a new behavioral metric. It decouples the learning of RL policy and metric owing to its independence on RL policy. We theoretically justify its scalability to continuous state and action spaces and design a practical way to incorporate it into an RL procedure as a representation learning target. We evaluate our approach on DeepMind control tasks with default and distracting backgrounds. By statistically reliable evaluation protocols, our experiments demonstrate our approach is superior to previous metric-based methods in terms of sample efficiency and asymptotic performance in both backgrounds.","https://ojs.aaai.org/index.php/AAAI/article/view/26052/25824"
"26053","Geometry-Aware Network for Domain Adaptive Semantic Segmentation","['Yinghong Liao', 'Wending Zhou', 'Xu Yan', 'Zhen Li', 'Yizhou Yu', 'Shuguang Cui']","['The Chinese University of Hong Kong, Shenzhen', 'The Chinese University of Hong Kong, Shenzhen', 'The Chinese University of Hong Kong, Shenzhen', 'The Chinese University of Hong Kong, Shenzhen', 'The University of Hong Kong', 'The Chinese University of Hong Kong, Shenzhen']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'CV: Scene Analysis & Understanding', 'CV: Segmentation']","Liao, Y., Zhou, W., Yan, X., Li, Z., Yu, Y., & Cui, S. (2023). Geometry-Aware Network for Domain Adaptive Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8755-8763. https://doi.org/10.1609/aaai.v37i7.26053","Abstract 					Measuring and alleviating the discrepancies between the synthetic (source) and real scene (target) data is the core issue for domain adaptive semantic segmentation. Though recent works have introduced depth information in the source domain to reinforce the geometric and semantic knowledge transfer, they cannot extract the intrinsic 3D information of objects, including positions and shapes, merely based on 2D estimated depth. In this work, we propose a novel Geometry-Aware Network for Domain Adaptation (GANDA), leveraging more compact 3D geometric point cloud representations to shrink the domain gaps. In particular, we first utilize the auxiliary depth supervision from the source domain to obtain the depth prediction in the target domain to accomplish structure-texture disentanglement. Beyond depth estimation, we explicitly exploit 3D topology on the point clouds generated from RGB-D images for further coordinate-color disentanglement and pseudo-labels refinement in the target domain. Moreover, to improve the 2D classifier in the target domain, we perform domain-invariant geometric adaptation from source to target and unify the 2D semantic and 3D geometric segmentation results in two domains. Note that our GANDA is plug-and-play in any existing UDA framework. Qualitative and quantitative results demonstrate that our model outperforms state-of-the-arts on GTA5->Cityscapes and SYNTHIA->Cityscapes.","https://ojs.aaai.org/index.php/AAAI/article/view/26053/25825"
"26054","Social Bias Meets Data Bias: The Impacts of Labeling and Measurement Errors on Fairness Criteria","['Yiqiao Liao', 'Parinaz Naghizadeh']","['The Ohio State University', 'The Ohio State University']","['ML: Bias and Fairness', 'PEAI: Societal Impact of AI']","Liao, Y., & Naghizadeh, P. (2023). Social Bias Meets Data Bias: The Impacts of Labeling and Measurement Errors on Fairness Criteria. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8764-8772. https://doi.org/10.1609/aaai.v37i7.26054","Abstract 					Although many fairness criteria have been proposed to ensure that machine learning algorithms do not exhibit or amplify our existing social biases, these algorithms are trained on datasets that can themselves be statistically biased. In this paper, we investigate the robustness of existing (demographic) fairness criteria when the algorithm is trained on biased data. We consider two forms of dataset bias: errors by prior decision makers in the labeling process, and errors in the measurement of the features of disadvantaged individuals. We analytically show that some constraints (such as Demographic Parity) can remain robust when facing certain statistical biases, while others (such as Equalized Odds) are significantly violated if trained on biased data. We provide numerical experiments based on three real-world datasets (the FICO, Adult, and German credit score datasets) supporting our analytical findings. While fairness criteria are primarily chosen under normative considerations in practice, our results show that naively applying a fairness constraint can lead to not only a loss in utility for the decision maker, but more severe unfairness when data bias exists. Thus, understanding how fairness criteria react to different forms of data bias presents a critical guideline for choosing among existing fairness criteria, or for proposing new criteria, when available datasets may be biased.","https://ojs.aaai.org/index.php/AAAI/article/view/26054/25826"
"26055","On the Expressive Flexibility of Self-Attention Matrices","['Valerii Likhosherstov', 'Krzysztof Choromanski', 'Adrian Weller']","['University of Cambridge', 'Google Brain', 'University of Cambridge\nThe Alan Turing Institute']","['ML: Deep Learning Theory', 'ML: Kernel Methods']","Likhosherstov, V., Choromanski, K., & Weller, A. (2023). On the Expressive Flexibility of Self-Attention Matrices. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8773-8781. https://doi.org/10.1609/aaai.v37i7.26055","Abstract 					Transformer networks are able to capture patterns in data coming from many domains (text, images, videos, proteins, etc.) with little or no change to architecture components. We perform a theoretical analysis of the core component responsible for signal propagation between elements, i.e. the self-attention matrix. We ask the following question: Can self-attention matrix approximate arbitrary patterns? How small is the query dimension d required for such approximation? Our first result shows that the task of deciding whether approximation of a given pattern is possible or not is NP-hard for a fixed d greater than one. In practice, self-attention matrix typically exhibits two properties: it is sparse, and it changes dynamically depending on the input to the module. Motivated by this observation, we show that the self-attention matrix can provably approximate sparse matrices. While the parameters of self-attention are fixed, various sparse matrices can be approximated by only modifying the inputs. Our proof is based on the random projection technique and uses the seminal Johnson-Lindenstrauss lemma. In particular, we show that, in order to approximate any sparse matrix up to a given precision defined in terms of preserving matrix element ratios, d grows only logarithmically with the sequence length n.","https://ojs.aaai.org/index.php/AAAI/article/view/26055/25827"
"26056","Wasserstein Actor-Critic: Directed Exploration via Optimism for Continuous-Actions Control","['Amarildo Likmeta', 'Matteo Sacco', 'Alberto Maria Metelli', 'Marcello Restelli']","['Universita di Bologna, Politecnico di Milano', 'Politecnico di Milano', 'Politecnico di Milano', 'Politecnico di Milano']","['ML: Reinforcement Learning Algorithms', 'RU: Sequential Decision Making']","Likmeta, A., Sacco, M., Metelli, A. M., & Restelli, M. (2023). Wasserstein Actor-Critic: Directed Exploration via Optimism for Continuous-Actions Control. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8782-8790. https://doi.org/10.1609/aaai.v37i7.26056","Abstract 					Uncertainty quantification has been extensively used as a means to achieve efficient directed exploration in Reinforcement Learning (RL). However, state-of-the-art methods for continuous actions still suffer from high sample complexity requirements. Indeed, they either completely lack strategies for propagating the epistemic uncertainty throughout the updates, or they mix it with aleatoric uncertainty while learning the full return distribution (e.g., distributional RL). In this paper, we propose Wasserstein Actor-Critic (WAC), an actor-critic architecture inspired by the recent Wasserstein Q-Learning (WQL), that employs approximate Q-posteriors to represent the epistemic uncertainty and Wasserstein barycenters for uncertainty propagation across the state-action space. WAC enforces exploration in a principled way by guiding the policy learning process with the optimization of an upper bound of the Q-value estimates. Furthermore, we study some peculiar issues that arise when using function approximation, coupled with the uncertainty estimation, and propose a regularized loss for the uncertainty estimation. Finally, we evaluate our algorithm on standard MujoCo tasks as well as suite of continuous-actions domains, where exploration is crucial, in comparison with state-of-the-art baselines. Additional details and results can be found in the supplementary material with our Arxiv preprint.","https://ojs.aaai.org/index.php/AAAI/article/view/26056/25828"
"26057","Dual Label-Guided Graph Refinement for Multi-View Graph Clustering","['Yawen Ling', 'Jianpeng Chen', 'Yazhou Ren', 'Xiaorong Pu', 'Jie Xu', 'Xiaofeng Zhu', 'Lifang He']","['University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'Lehigh University']","['ML: Clustering', 'ML: Graph-based Machine Learning', 'ML: Multi-Instance/Multi-View Learning']","Ling, Y., Chen, J., Ren, Y., Pu, X., Xu, J., Zhu, X., & He, L. (2023). Dual Label-Guided Graph Refinement for Multi-View Graph Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8791-8798. https://doi.org/10.1609/aaai.v37i7.26057","Abstract 					With the increase of multi-view graph data, multi-view graph clustering (MVGC) that can discover the hidden clusters without label supervision has attracted growing attention from researchers. Existing MVGC methods are often sensitive to the given graphs, especially influenced by the low quality graphs, i.e., they tend to be limited by the homophily assumption. However, the widespread real-world data hardly satisfy the homophily assumption. This gap limits the performance of existing MVGC methods on low homophilous graphs. To mitigate this limitation, our motivation is to extract high-level view-common information which is used to refine each view's graph, and reduce the influence of non-homophilous edges. To this end, we propose dual label-guided graph refinement for multi-view graph clustering (DuaLGR), to alleviate the vulnerability in facing low homophilous graphs. Specifically, DuaLGR consists of two modules named dual label-guided graph refinement module and graph encoder module. The first module is designed to extract the soft label from node features and graphs, and then learn a refinement matrix. In cooperation with the pseudo label from the second module, these graphs are refined and aggregated adaptively with different orders. Subsequently, a consensus graph can be generated in the guidance of the pseudo label. Finally, the graph encoder module encodes the consensus graph along with node features to produce the high-level pseudo label for iteratively clustering. The experimental results show the superior performance on coping with low homophilous graph data. The source code for DuaLGR is available at https://github.com/YwL-zhufeng/DuaLGR.","https://ojs.aaai.org/index.php/AAAI/article/view/26057/25829"
"26058","Metric Residual Network for Sample Efficient Goal-Conditioned Reinforcement Learning","['Bo Liu', 'Yihao Feng', 'Qiang Liu', 'Peter Stone']","['University of Texas, Austin', 'Salesforce Research', 'University of Texas, Austin', 'University of Texas at Austin\nSony AI']","['ML: Deep Neural Architectures', 'ML: Reinforcement Learning Algorithms']","Liu, B., Feng, Y., Liu, Q., & Stone, P. (2023). Metric Residual Network for Sample Efficient Goal-Conditioned Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8799-8806. https://doi.org/10.1609/aaai.v37i7.26058","Abstract 					Goal-conditioned reinforcement learning (GCRL) has a wide range of potential real-world applications, including manipulation and navigation problems in robotics. Especially in such robotics tasks, sample efficiency is of the utmost importance for GCRL since, by default, the agent is only rewarded when it reaches its goal. While several methods have been proposed to improve the sample efficiency of GCRL, one relatively under-studied approach is the design of neural architectures to support sample efficiency. In this work, we introduce a novel neural architecture for GCRL that achieves significantly better sample efficiency than the commonly-used monolithic network architecture.  The key insight is that the  optimal action-value function must satisfy the triangle inequality in a specific sense. Furthermore, we introduce the metric residual network (MRN)  that deliberately decomposes the action-value function into the negated summation of a metric plus a residual asymmetric component. MRN provably approximates any optimal action-value function, thus making it a fitting neural architecture for GCRL. We conduct comprehensive experiments across 12 standard benchmark environments in GCRL. The empirical results demonstrate that MRN uniformly outperforms other state-of-the-art GCRL neural architectures in terms of sample efficiency. The code is available at https://github.com/Cranial-XIX/metric-residual-network.","https://ojs.aaai.org/index.php/AAAI/article/view/26058/25830"
"26059","DICNet: Deep Instance-Level Contrastive Network for Double Incomplete Multi-View Multi-Label Classification","['Chengliang Liu', 'Jie Wen', 'Xiaoling Luo', 'Chao Huang', 'Zhihao Wu', 'Yong Xu']","['Harbin Institute of Technology, Shenzhen', 'Harbin Institute of Technology, Shenzhen', 'Harbin Institute of Technology, Shenzhen', 'Sun Yat-sen University', 'Harbin Institute of Technology, Shenzhen', 'Harbin Institute of Technology, Shenzhen\nPengcheng Laboratory']","['ML: Multi-Instance/Multi-View Learning', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Multimodal Learning', 'ML: Representation Learning']","Liu, C., Wen, J., Luo, X., Huang, C., Wu, Z., & Xu, Y. (2023). DICNet: Deep Instance-Level Contrastive Network for Double Incomplete Multi-View Multi-Label Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8807-8815. https://doi.org/10.1609/aaai.v37i7.26059","Abstract 					In recent years, multi-view multi-label learning has aroused extensive research enthusiasm. However, multi-view multi-label data in the real world is commonly incomplete due to the uncertain factors of data collection and manual annotation, which means that not only multi-view features are often missing, and label completeness is also difficult to be satisfied. To deal with the double incomplete multi-view multi-label classification problem, we propose a deep instance-level contrastive network, namely DICNet. Different from conventional methods, our DICNet focuses on leveraging deep neural network to exploit the high-level semantic representations of samples rather than shallow-level features. First, we utilize the stacked autoencoders to build an end-to-end multi-view feature extraction framework to learn the view-specific representations of samples. Furthermore, in order to improve the consensus representation ability, we introduce an incomplete instance-level contrastive learning scheme to guide the encoders to better extract the consensus information of multiple views and use a multi-view weighted fusion module to enhance the discrimination of semantic features. Overall, our DICNet is adept in capturing consistent discriminative representations of multi-view multi-label data and avoiding the negative effects of missing views and missing labels. Extensive experiments performed on five datasets validate that our method outperforms other state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26059/25831"
"26060","Incomplete Multi-View Multi-Label Learning via Label-Guided Masked View- and Category-Aware Transformers","['Chengliang Liu', 'Jie Wen', 'Xiaoling Luo', 'Yong Xu']","['Harbin Institute of Technology, Shenzhen', 'Harbin Institute of Technology, Shenzhen', 'Harbin Institute of Technology, Shenzhen', 'Harbin Institute of Technology, Shenzhen\nPengcheng Laboratory']","['ML: Multi-Instance/Multi-View Learning', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Multimodal Learning', 'ML: Representation Learning']","Liu, C., Wen, J., Luo, X., & Xu, Y. (2023). Incomplete Multi-View Multi-Label Learning via Label-Guided Masked View- and Category-Aware Transformers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8816-8824. https://doi.org/10.1609/aaai.v37i7.26060","Abstract 					As we all know, multi-view data is more expressive than single-view data and multi-label annotation enjoys richer supervision information than single-label, which makes multi-view multi-label learning widely applicable for various pattern recognition tasks. In this complex representation learning problem, three main challenges can be characterized as follows: i) How to learn consistent representations of samples across all views? ii) How to exploit and utilize category correlations of multi-label to guide inference? iii) How to avoid the negative impact resulting from the incompleteness of views or labels? To cope with these problems, we propose a general multi-view multi-label learning framework named label-guided masked view- and category-aware transformers in this paper. First, we design two transformer-style based modules for cross-view features aggregation and multi-label classification, respectively. The former aggregates information from different views in the process of extracting view-specific features, and the latter learns subcategory embedding to improve classification performance. Second, considering the imbalance of expressive power among views, an adaptively weighted view fusion module is proposed to obtain view-consistent embedding features. Third, we impose a label manifold constraint in sample-level representation learning to maximize the utilization of supervised information. Last but not least, all the modules are designed under the premise of incomplete views and labels, which makes our method adaptable to arbitrary multi-view and multi-label data. Extensive experiments on five datasets confirm that our method has clear advantages over other state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26060/25832"
"26061","Adaptive Discrete Communication Bottlenecks with Dynamic Vector Quantization for Heterogeneous Representational Coarseness","['Dianbo Liu', 'Alex Lamb', 'Xu Ji', 'Pascal Junior Tikeng Notsawo', 'Michael Mozer', 'Yoshua Bengio', 'Kenji Kawaguchi']","['Mila-Quebec AI Institute', 'Mila-Quebec AI Institute', 'Mila-Quebec AI Institute', 'MILA-Quebec AI Institute', 'Google Research, Brain Team', 'Mila-Quebec AI Institute,\nCIFAR AI Chair', 'National University of Singapore']","['ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms']","Liu, D., Lamb, A., Ji, X., Tikeng Notsawo, P. J., Mozer, M., Bengio, Y., & Kawaguchi, K. (2023). Adaptive Discrete Communication Bottlenecks with Dynamic Vector Quantization for Heterogeneous Representational Coarseness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8825-8833. https://doi.org/10.1609/aaai.v37i7.26061","Abstract 					Vector Quantization (VQ) is a method for discretizing latent representations and has become a major part of the deep learning toolkit. It has been theoretically and empirically shown that discretization of representations leads to improved generalization, including in reinforcement learning where discretization can be used to bottleneck multi-agent communication to promote agent specialization and robustness. The discretization tightness of most VQ-based methods is defined by the number of discrete codes in the representation vector and the codebook size, which are fixed as hyperparameters. In this work, we propose learning to dynamically select discretization tightness conditioned on inputs, based on the hypothesis that data naturally contains variations in complexity that call for different levels of representational coarseness which is observed in many heterogeneous data sets. We show that dynamically varying tightness in communication bottlenecks can improve model performance on visual reasoning and reinforcement learning tasks with heterogeneity in representations.","https://ojs.aaai.org/index.php/AAAI/article/view/26061/25833"
"26062","Combating Mode Collapse via Offline Manifold Entropy Estimation","['Haozhe Liu', 'Bing Li', 'Haoqian Wu', 'Hanbang Liang', 'Yawen Huang', 'Yuexiang Li', 'Bernard Ghanem', 'Yefeng Zheng']","['AI Initiative, King Abdullah University of Science and Technology\nJarvis Lab, Tencent', 'AI Initiative, King Abdullah University of Science and Technology', 'YouTu Lab, Tencent\nShenzhen University', 'Shenzhen University', 'Jarvis Lab, Tencent', 'Jarvis Lab, Tencent', 'AI Initiative, King Abdullah University of Science and Technology', 'Jarvis Lab, Tencent']","['ML: Deep Generative Models & Autoencoders', 'CV: Computational Photography', 'Image & Video Synthesis']","Liu, H., Li, B., Wu, H., Liang, H., Huang, Y., Li, Y., Ghanem, B., & Zheng, Y. (2023). Combating Mode Collapse via Offline Manifold Entropy Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8834-8842. https://doi.org/10.1609/aaai.v37i7.26062","Abstract 					Generative Adversarial Networks (GANs) have shown compelling results in various tasks and applications in recent years. However, mode collapse remains a critical problem in GANs. In this paper, we propose a novel training pipeline to address the mode collapse issue of GANs. Different from existing methods, we propose to generalize the discriminator as feature embedding and maximize the entropy of distributions in the embedding space learned by the discriminator. Specifically, two regularization terms, i.e., Deep Local Linear Embedding (DLLE) and Deep Isometric feature Mapping (DIsoMap), are introduced to encourage the discriminator to learn the structural information embedded in the data, such that the embedding space learned by the discriminator can be well-formed. Based on the well-learned embedding space supported by the discriminator, a non-parametric entropy estimator is designed to efficiently maximize the entropy of embedding vectors, playing as an approximation of maximizing the entropy of the generated distribution. By improving the discriminator and maximizing the distance of the most similar samples in the embedding space, our pipeline effectively reduces the mode collapse without sacrificing the quality of generated samples. Extensive experimental results show the effectiveness of our method which outperforms the GAN baseline, MaF-GAN on CelebA (9.13 vs. 12.43 in FID) and surpasses the recent state-of-the-art energy-based model on the ANIMEFACE dataset (2.80 vs. 2.26 in Inception score).","https://ojs.aaai.org/index.php/AAAI/article/view/26062/25834"
"26063","Robust Representation Learning by Clustering with Bisimulation Metrics for Visual Reinforcement Learning with Distractions","['Qiyuan Liu', 'Qi Zhou', 'Rui Yang', 'Jie Wang']","['University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China\nHefei Comprehensive National Science Center']","['ML: Reinforcement Learning Algorithms', 'ML: Representation Learning']","Liu, Q., Zhou, Q., Yang, R., & Wang, J. (2023). Robust Representation Learning by Clustering with Bisimulation Metrics for Visual Reinforcement Learning with Distractions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8843-8851. https://doi.org/10.1609/aaai.v37i7.26063","Abstract 					Recent work has shown that representation learning plays a critical role in sample-efficient reinforcement learning (RL) from pixels. Unfortunately, in real-world scenarios, representation learning is usually fragile to task-irrelevant distractions such as variations in background or viewpoint. To tackle this problem, we propose a novel clustering-based approach, namely Clustering with Bisimulation Metrics (CBM), which learns robust representations by grouping visual observations in the latent space. Specifically, CBM alternates between two steps: (1) grouping observations by measuring their bisimulation distances to the learned prototypes; (2) learning a set of prototypes according to the current cluster assignments. Computing cluster assignments with bisimulation metrics enables CBM to capture task-relevant information, as bisimulation metrics quantify the behavioral similarity between observations. Moreover, CBM encourages the consistency of representations within each group, which facilitates filtering out task-irrelevant information and thus induces robust representations against distractions. An appealing feature is that CBM can achieve sample-efficient representation learning even if multiple distractions exist simultaneously. Experiments demonstrate that CBM significantly improves the sample efficiency of popular visual RL algorithms and achieves state-of-the-art performance on both multiple and single distraction settings. The code is available at https://github.com/MIRALab-USTC/RL-CBM.","https://ojs.aaai.org/index.php/AAAI/article/view/26063/25835"
"26064","Reliable Robustness Evaluation via Automatically Constructed Attack Ensembles","['Shengcai Liu', 'Fu Peng', 'Ke Tang']","['Southern University of Science and Technology', 'Southern University of Science and Technology', 'Southern University of Science and Technology']","['ML: Adversarial Learning & Robustness', 'APP: Security']","Liu, S., Peng, F., & Tang, K. (2023). Reliable Robustness Evaluation via Automatically Constructed Attack Ensembles. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8852-8860. https://doi.org/10.1609/aaai.v37i7.26064","Abstract 					Attack Ensemble (AE), which combines multiple attacks together, provides a reliable way to evaluate adversarial robustness. In practice, AEs are often constructed and tuned by human experts, which however tends to be sub-optimal and time-consuming. In this work, we present AutoAE, a conceptually simple approach for automatically constructing AEs. In brief, AutoAE repeatedly adds the attack and its iteration steps to the ensemble that maximizes ensemble improvement per additional iteration consumed. We show theoretically that AutoAE yields AEs provably within a constant factor of the optimal for a given defense. We then use AutoAE to construct two AEs for l∞ and l2 attacks, and apply them without any tuning or adaptation to 45 top adversarial defenses on the RobustBench leaderboard. In all except one cases we achieve equal or better (often the latter) robustness evaluation than existing AEs, and notably, in 29 cases we achieve better robustness evaluation than the best known one. Such performance of AutoAE shows itself as a reliable evaluation protocol for adversarial robustness, which further indicates the huge potential of automatic AE construction. Code is available at https://github.com/LeegerPENG/AutoAE.","https://ojs.aaai.org/index.php/AAAI/article/view/26064/25836"
"26065","Enhancing the Antidote: Improved Pointwise Certifications against Poisoning Attacks","['Shijie Liu', 'Andrew C. Cullen', 'Paul Montague', 'Sarah M. Erfani', 'Benjamin I. P. Rubinstein']","['University of Melbourne, Melbourne, Australia', 'University of Melbourne, Melbourne, Australia', 'Defence Science and Technology Group, Adelaide, Australia', 'University of Melbourne, Melbourne, Australia', 'University of Melbourne, Melbourne, Australia']","['ML: Adversarial Learning & Robustness', 'CV: Adversarial Attacks & Robustness']","Liu, S., Cullen, A. C., Montague, P., Erfani, S. M., & Rubinstein, B. I. P. (2023). Enhancing the Antidote: Improved Pointwise Certifications against Poisoning Attacks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8861-8869. https://doi.org/10.1609/aaai.v37i7.26065","Abstract 					Poisoning attacks can disproportionately influence model behaviour by making small changes to the training corpus. While defences against specific poisoning attacks do exist, they in general do not provide any guarantees, leaving them potentially countered by novel attacks. In contrast, by examining worst-case behaviours Certified Defences make it possible to provide guarantees of the robustness of a sample against adversarial attacks modifying a finite number of training samples, known as pointwise certification. We achieve this by exploiting both Differential Privacy and the Sampled Gaussian Mechanism to ensure the invariance of prediction for each testing instance against finite numbers of poisoned examples. In doing so, our model provides guarantees of adversarial robustness that are more than twice as large as those provided by prior certifications.","https://ojs.aaai.org/index.php/AAAI/article/view/26065/25837"
"26066","Safe Multi-View Deep Classification","['Wei Liu', 'Yufei Chen', 'Xiaodong Yue', 'Changqing Zhang', 'Shaorong Xie']","['Tongji University', 'Tongji University', 'Shanghai University', 'Tianjin University', 'Shanghai University']","['ML: Multi-Instance/Multi-View Learning', 'ML: Deep Neural Network Algorithms', 'ML: Multimodal Learning', 'RU: Uncertainty Representations']","Liu, W., Chen, Y., Yue, X., Zhang, C., & Xie, S. (2023). Safe Multi-View Deep Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8870-8878. https://doi.org/10.1609/aaai.v37i7.26066","Abstract 					Multi-view deep classification expects to obtain better classification performance than using a single view. However, due to the uncertainty and inconsistency of data sources, adding data views does not necessarily lead to the performance improvements in multi-view classification. How to avoid worsening classification performance when adding views is crucial for multi-view deep learning but rarely studied. To tackle this limitation, in this paper, we reformulate the multi-view classification problem from the perspective of safe learning and thereby propose a Safe Multi-view Deep Classification (SMDC) method, which can guarantee that the classification performance does not deteriorate when fusing multiple views. In the SMDC method, we dynamically integrate multiple views and estimate the inherent uncertainties among multiple views with different root causes based on evidence theory. Through minimizing the uncertainties, SMDC promotes the evidences from data views for correct classification, and in the meantime excludes the incorrect evidences to produce the safe multi-view classification results. Furthermore, we theoretically prove that in the safe multi-view classification, adding data views will certainly not increase the empirical risk of classification. The experiments on various kinds of multi-view datasets validate that the proposed SMDC method can achieve precise and safe classification results.","https://ojs.aaai.org/index.php/AAAI/article/view/26066/25838"
"26067","Tensor Compressive Sensing Fused Low-Rankness and Local-Smoothness","['Xinling Liu', 'Jingyao Hou', 'Jiangjun Peng', 'Hailin Wang', 'Deyu Meng', 'Jianjun Wang']","['Southwest University\nChina West Normal University', 'China West Normal University', 'Xi’an Jiaotong University', 'Xi’an Jiaotong University', ""Xi'an Jiaotong University\nMacau University of Science and Technology"", 'Southwest University']","['ML: Matrix & Tensor Methods', 'CV: Image and Video Retrieval', 'CV: Interpretability and Transparency', 'ML: Dimensionality Reduction/Feature Selection', 'ML: Transparent', 'Interpretable', 'Explainable ML']","Liu, X., Hou, J., Peng, J., Wang, H., Meng, D., & Wang, J. (2023). Tensor Compressive Sensing Fused Low-Rankness and Local-Smoothness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8879-8887. https://doi.org/10.1609/aaai.v37i7.26067","Abstract 					A plethora of previous studies indicates that making full use of multifarious intrinsic properties of primordial data is a valid pathway to recover original images from their degraded observations. Typically, both low-rankness and local-smoothness broadly exist in real-world tensor data such as hyperspectral images and videos. Modeling based on both properties has received a great deal of attention, whereas most studies concentrate on experimental performance, and theoretical investigations are still lacking. In this paper, we study the tensor compressive sensing problem based on the tensor correlated total variation, which is a new regularizer used to simultaneously capture both properties existing in the same dataset. The new regularizer has the outstanding advantage of not using a trade-off parameter to balance the two properties. The obtained theories provide a robust recovery guarantee, where the error bound shows that our model certainly benefits from both properties in ground-truth data adaptively. Moreover, based on the ADMM update procedure, we design an algorithm with a global convergence guarantee to solve this model. At last, we carry out experiments to apply our model to hyperspectral image and video restoration problems. The experimental results show that our method is prominently better than many other competing ones. Our code and Supplementary Material are available at https://github.com/fsliuxl/cs-tctv.","https://ojs.aaai.org/index.php/AAAI/article/view/26067/25839"
"26068","Coupling Artificial Neurons in BERT and Biological Neurons in the Human Brain","['Xu Liu', 'Mengyue Zhou', 'Gaosheng Shi', 'Yu Du', 'Lin Zhao', 'Zihao Wu', 'David Liu', 'Tianming Liu', 'Xintao Hu']","['School of Automation, Northwestern Polytechnical University', 'School of Automation, Northwestern Polytechnical University', 'School of Automation, Northwestern Polytechnical University', 'School of Automation, Northwestern Polytechnical University', 'School of Computing, University of Georgia', 'School of Computing, University of Georgia', 'Athens Academy', 'School of Computing, University of Georgia', 'School of Automation, Northwestern Polytechnical University']","['ML: Bio-Inspired Learning', 'SNLP: Interpretability & Analysis of NLP Models']","Liu, X., Zhou, M., Shi, G., Du, Y., Zhao, L., Wu, Z., Liu, D., Liu, T., & Hu, X. (2023). Coupling Artificial Neurons in BERT and Biological Neurons in the Human Brain. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8888-8896. https://doi.org/10.1609/aaai.v37i7.26068","Abstract 					Linking computational natural language processing (NLP) models and neural responses to language in the human brain on the one hand facilitates the effort towards disentangling the neural representations underpinning language perception, on the other hand provides neurolinguistics evidence to evaluate and improve NLP models. Mappings of an NLP model’s representations of and the brain activities evoked by linguistic input are typically deployed to reveal this symbiosis. However, two critical problems limit its advancement: 1) The model’s representations (artificial neurons, ANs) rely on layer-level embeddings and thus lack fine-granularity; 2) The brain activities (biological neurons, BNs) are limited to neural recordings of isolated cortical unit (i.e., voxel/region) and thus lack integrations and interactions among brain functions. To address those problems, in this study, we 1) define ANs with fine-granularity in transformer-based NLP models (BERT in this study) and measure their temporal activations to input text sequences; 2) define BNs as functional brain networks (FBNs) extracted from functional magnetic resonance imaging (fMRI) data to capture functional interactions in the brain; 3) couple ANs and BNs by maximizing the synchronization of their temporal activations. Our experimental results demonstrate 1) The activations of ANs and BNs are significantly synchronized; 2) the ANs carry meaningful linguistic/semantic information and anchor to their BN signatures; 3) the anchored BNs are interpretable in a neurolinguistic context. Overall, our study introduces a novel, general, and effective framework to link transformer-based NLP models and neural activities in response to language and may provide novel insights for future studies such as brain-inspired evaluation and development of NLP models.","https://ojs.aaai.org/index.php/AAAI/article/view/26068/25840"
"26069","EASAL: Entity-Aware Subsequence-Based Active Learning for Named Entity Recognition","['Yang Liu', 'Jinpeng Hu', 'Zhihong Chen', 'Xiang Wan', 'Tsung-Hui Chang']","['Shenzhen Research Institute of Big Data\nChinese University of Hong Kong, Shenzhen, China', 'Shenzhen Research Institute of Big Data\nChinese University of Hong Kong, Shenzhen, China', 'Shenzhen Research Institute of Big Data\nChinese University of Hong Kong, Shenzhen, China', 'Shenzhen Research Institute of Big Data\nPazhou Lab, Guangzhou, 510330, China', 'Shenzhen Research Institute of Big Data\nChinese University of Hong Kong, Shenzhen, China']","['ML: Active Learning', 'SNLP: Information Extraction']","Liu, Y., Hu, J., Chen, Z., Wan, X., & Chang, T.-H. (2023). EASAL: Entity-Aware Subsequence-Based Active Learning for Named Entity Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8897-8905. https://doi.org/10.1609/aaai.v37i7.26069","Abstract 					Active learning is a critical technique for reducing labelling load by selecting the most informative data. Most previous works applied active learning on Named Entity Recognition (token-level task) similar to the text classification (sentence-level task). They failed to consider the heterogeneity of uncertainty within each sentence and required access to the entire sentence for the annotator when labelling. To overcome the mentioned limitations, in this paper, we allow the active learning algorithm to query subsequences within sentences and propose an Entity-Aware Subsequences-based Active Learning (EASAL) that utilizes an effective Head-Tail pointer to query one entity-aware subsequence for each sentence based on BERT. For other tokens outside this subsequence, we randomly select 30% of these tokens to be pseudo-labelled for training together where the model directly predicts their pseudo-labels. Experimental results on both news and biomedical datasets demonstrate the effectiveness of our proposed method. The code is released at https://github.com/lylylylylyly/EASAL.","https://ojs.aaai.org/index.php/AAAI/article/view/26069/25841"
"26070","Online Hyperparameter Optimization for Class-Incremental Learning","['Yaoyao Liu', 'Yingying Li', 'Bernt Schiele', 'Qianru Sun']","['Max Planck Institute for Informatics, Saarland Informatics Campus\nDepartment of Computer Science, Johns Hopkins University', 'Computing and Mathematical Sciences, California Institute of Technology', 'Max Planck Institute for Informatics, Saarland Informatics Campus', 'School of Computing and Information Systems, Singapore Management University']","['ML: Lifelong and Continual Learning', 'ML: Classification and Regression']","Liu, Y., Li, Y., Schiele, B., & Sun, Q. (2023). Online Hyperparameter Optimization for Class-Incremental Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8906-8913. https://doi.org/10.1609/aaai.v37i7.26070","Abstract 					Class-incremental learning (CIL) aims to train a classification model while the number of classes increases phase-by-phase. An inherent challenge of CIL is the stability-plasticity tradeoff, i.e., CIL models should keep stable to retain old knowledge and keep plastic to absorb new knowledge. However, none of the existing CIL models can achieve the optimal tradeoff in different data-receiving settings—where typically the training-from-half (TFH) setting needs more stability, but the training-from-scratch (TFS) needs more plasticity. To this end, we design an online learning method that can adaptively optimize the tradeoff without knowing the setting as a priori. Specifically, we first introduce the key hyperparameters that influence the tradeoff, e.g., knowledge distillation (KD) loss weights, learning rates, and classifier types. Then, we formulate the hyperparameter optimization process as an online Markov Decision Process (MDP) problem and propose a specific algorithm to solve it. We apply local estimated rewards and a classic bandit algorithm Exp3 to address the issues when applying online MDP methods to the CIL protocol. Our method consistently improves top-performing CIL methods in both TFH and TFS settings, e.g., boosting the average accuracy of TFH and TFS by 2.2 percentage points on ImageNet-Full, compared to the state-of-the-art. Code is provided at https://class-il.mpi-inf.mpg.de/online/","https://ojs.aaai.org/index.php/AAAI/article/view/26070/25842"
"26071","Hard Sample Aware Network for Contrastive Deep Graph Clustering","['Yue Liu', 'Xihong Yang', 'Sihang Zhou', 'Xinwang Liu', 'Zhen Wang', 'Ke Liang', 'Wenxuan Tu', 'Liang Li', 'Jingcan Duan', 'Cancan Chen']","['National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'Northwestern Polytechnical University', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'Beijing Information Science and Technology University']","['ML: Clustering', 'ML: Graph-based Machine Learning', 'ML: Multi-Instance/Multi-View Learning']","Liu, Y., Yang, X., Zhou, S., Liu, X., Wang, Z., Liang, K., Tu, W., Li, L., Duan, J., & Chen, C. (2023). Hard Sample Aware Network for Contrastive Deep Graph Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8914-8922. https://doi.org/10.1609/aaai.v37i7.26071","Abstract 					Contrastive deep graph clustering, which aims to divide nodes into disjoint groups via contrastive mechanisms, is a challenging research spot. Among the recent works, hard sample mining-based algorithms have achieved great attention for their promising performance. However, we find that the existing hard sample mining methods have two problems as follows. 1) In the hardness measurement, the important structural information is overlooked for similarity calculation, degrading the representativeness of the selected hard negative samples. 2) Previous works merely focus on the hard negative sample pairs while neglecting the hard positive sample pairs. Nevertheless, samples within the same cluster but with low similarity should also be carefully learned. To solve the problems, we propose a novel contrastive deep graph clustering method dubbed Hard Sample Aware Network (HSAN) by introducing a comprehensive similarity measure criterion and a general dynamic sample weighing strategy. Concretely, in our algorithm, the similarities between samples are calculated by considering both the attribute embeddings and the structure embeddings, better revealing sample relationships and assisting hardness measurement. Moreover, under the guidance of the carefully collected high-confidence clustering information, our proposed weight modulating function will first recognize the positive and negative samples and then dynamically up-weight the hard sample pairs while down-weighting the easy ones. In this way, our method can mine not only the hard negative samples but also the hard positive sample, thus improving the discriminative capability of the samples further. Extensive experiments and analyses demonstrate the superiority and effectiveness of our proposed method.  The source code of HSAN is shared at https://github.com/yueliu1999/HSAN and a collection (papers, codes and, datasets) of deep graph clustering is shared at https://github.com/yueliu1999/Awesome-Deep-Graph-Clustering on Github.","https://ojs.aaai.org/index.php/AAAI/article/view/26071/25843"
"26072","Temporal-Frequency Co-training for Time Series Semi-supervised Learning","['Zhen Liu', 'Qianli Ma', 'Peitian Ma', 'Linghao Wang']","['South China University of Technology', 'South China University of Technology', 'South China University of Technology', 'South China University of Technology']","['ML: Time-Series/Data Streams', 'ML: Representation Learning', 'ML: Semi-Supervised Learning']","Liu, Z., Ma, Q., Ma, P., & Wang, L. (2023). Temporal-Frequency Co-training for Time Series Semi-supervised Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8923-8931. https://doi.org/10.1609/aaai.v37i7.26072","Abstract 					Semi-supervised learning (SSL) has been actively studied due to its ability to alleviate the reliance of deep learning models on labeled data. Although existing SSL methods based on pseudo-labeling strategies have made great progress, they rarely consider time-series data's intrinsic properties (e.g., temporal dependence). Learning representations by mining the inherent properties of time series has recently gained much attention. Nonetheless, how to utilize feature representations to design SSL paradigms for time series has not been explored. To this end, we propose a Time Series SSL framework via Temporal-Frequency Co-training (TS-TFC), leveraging the complementary information from two distinct views for unlabeled data learning. In particular, TS-TFC employs time-domain and frequency-domain views to train two deep neural networks simultaneously, and each view's pseudo-labels generated by label propagation in the representation space are adopted to guide the training of the other view's classifier. To enhance the discriminative of representations between categories, we propose a temporal-frequency supervised contrastive learning module, which integrates the learning difficulty of categories to improve the quality of pseudo-labels. Through co-training the pseudo-labels obtained from temporal-frequency representations, the complementary information in the two distinct views is exploited to enable the model to better learn the distribution of categories. Extensive experiments on 106 UCR datasets show that TS-TFC outperforms state-of-the-art methods, demonstrating the effectiveness and robustness of our proposed model.","https://ojs.aaai.org/index.php/AAAI/article/view/26072/25844"
"26073","Q-functionals for Value-Based Continuous Control","['Samuel Lobel', 'Sreehari Rammohan', 'Bowen He', 'Shangqun Yu', 'George Konidaris']","['Brown University', 'Brown University', 'Brown University', 'University of Massachusetts, Amherst', 'Brown University']","['ML: Reinforcement Learning Algorithms']","Lobel, S., Rammohan, S., He, B., Yu, S., & Konidaris, G. (2023). Q-functionals for Value-Based Continuous Control. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8932-8939. https://doi.org/10.1609/aaai.v37i7.26073","Abstract 					We present Q-functionals, an alternative architecture for continuous control deep reinforcement learning. Instead of returning a single value for a state-action pair, our network transforms a state into a function that can be rapidly evaluated in parallel for many actions, allowing us to efficiently choose high-value actions through sampling. This contrasts with the typical architecture of off-policy continuous control, where a policy network is trained for the sole purpose of selecting actions from the Q-function. We represent our action-dependent Q-function as a weighted sum of basis functions (Fourier, Polynomial, etc) over the action space, where the weights are state-dependent and output by the Q-functional network. Fast sampling makes practical a variety of techniques that require Monte-Carlo integration over Q-functions, and enables action-selection strategies besides simple value-maximization. We characterize our framework, describe various implementations of Q-functionals, and demonstrate strong performance on a suite of continuous control tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26073/25845"
"26074","A Coreset Learning Reality Check","['Fred Lu', 'Edward Raff', 'James Holt']","['Booz Allen Hamilton', 'Booz Allen Hamilton', 'Laboratory for Physical Sciences']","['ML: Dimensionality Reduction/Feature Selection', 'ML: Classification and Regression', 'ML: Scalability of ML Systems']","Lu, F., Raff, E., & Holt, J. (2023). A Coreset Learning Reality Check. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8940-8948. https://doi.org/10.1609/aaai.v37i7.26074","Abstract 					Subsampling algorithms are a natural approach to reduce data size before fitting models on massive datasets. In recent years, several works have proposed methods for subsampling rows from a data matrix while maintaining relevant information for classification. While these works are supported by theory and limited experiments, to date there has not been a comprehensive evaluation of these methods. In our work, we directly compare multiple methods for logistic regression drawn from the coreset and optimal subsampling literature and discover inconsistencies in their effectiveness. In many cases, methods do not outperform simple uniform subsampling.","https://ojs.aaai.org/index.php/AAAI/article/view/26074/25846"
"26075","Centerless Multi-View K-means Based on the Adjacency Matrix","['Han Lu', 'Quanxue Gao', 'Qianqian Wang', 'Ming Yang', 'Wei Xia']","[""School of Telecommunications Engineering, Xidian University, Xi'an 710071, P.R.China."", ""School of Telecommunications Engineering, Xidian University, Xi'an 710071, P.R.China."", ""School of Telecommunications Engineering, Xidian University, Xi'an 710071, P.R.China."", 'Mathematics department of the University of Evansville, Evansville, IN 47722 USA', ""School of Telecommunications Engineering, Xidian University, Xi'an 710071, P.R.China.""]","['ML: Clustering', 'ML: Matrix & Tensor Methods', 'ML: Multi-Instance/Multi-View Learning', 'ML: Unsupervised & Self-Supervised Learning']","Lu, H., Gao, Q., Wang, Q., Yang, M., & Xia, W. (2023). Centerless Multi-View K-means Based on the Adjacency Matrix. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8949-8956. https://doi.org/10.1609/aaai.v37i7.26075","Abstract 					Although K-Means clustering has been widely studied due to its simplicity, these methods still have the following fatal drawbacks. Firstly, they need to initialize the cluster centers, which causes unstable clustering performance. Secondly, they have poor performance on non-Gaussian datasets. Inspired by the affinity matrix, we propose a novel multi-view K-Means based on the adjacency matrix. It maps the affinity matrix to the distance matrix according to the principle that every sample has a small distance from the points in its neighborhood and a large distance from the points outside of the neighborhood. Moreover, this method well exploits the complementary information embedded in different views by minimizing the tensor Schatten p-norm regularize on the third-order tensor which consists of cluster assignment matrices of different views. Additionally, this method avoids initializing cluster centroids to obtain stable performance. And there is no need to compute the means of clusters so that our model is not sensitive to outliers. Experiment on a toy dataset shows the excellent performance on non-Gaussian datasets. And other experiments on several benchmark datasets demonstrate the superiority of our proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/26075/25847"
"26076","PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor","['Shun Lu', 'Yu Hu', 'Peihao Wang', 'Yan Han', 'Jianchao Tan', 'Jixiang Li', 'Sen Yang', 'Ji Liu']","['Research Center for Intelligent Computing Systems, Institute of Computing Technology, Chinese Academy of Sciences\nSchool of Computer Science and Technology, University of Chinese Academy of Sciences', 'Research Center for Intelligent Computing Systems, Institute of Computing Technology, Chinese Academy of Sciences\nSchool of Computer Science and Technology, University of Chinese Academy of Sciences', 'University of Texas at Austin', 'University of Texas at Austin', 'Kuaishou Technology.', 'Kuaishou Technology.', 'Snap Inc.', 'Meta Platforms, Inc.']","['ML: Auto ML and Hyperparameter Tuning', 'ML: Deep Neural Architectures']","Lu, S., Hu, Y., Wang, P., Han, Y., Tan, J., Li, J., Yang, S., & Liu, J. (2023). PINAT: A Permutation INvariance Augmented Transformer for NAS Predictor. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8957-8965. https://doi.org/10.1609/aaai.v37i7.26076","Abstract 					Time-consuming performance evaluation is the bottleneck of traditional Neural Architecture Search (NAS) methods. Predictor-based NAS can speed up performance evaluation by directly predicting performance, rather than training a large number of sub-models and then validating their performance. Most predictor-based NAS approaches use a proxy dataset to train model-based predictors efficiently but suffer from performance degradation and generalization problems. We attribute these problems to the poor abilities of existing predictors to character the sub-models' structure, specifically the topology information extraction and the node feature representation of the input graph data. To address these problems, we propose a Transformer-like NAS predictor PINAT, consisting of a Permutation INvariance Augmentation module serving as both token embedding layer and self-attention head, as well as a Laplacian matrix to be the positional encoding. Our design produces more representative features of the encoded architecture and outperforms state-of-the-art NAS predictors on six search spaces: NAS-Bench-101, NAS-Bench-201, DARTS, ProxylessNAS, PPI, and ModelNet. The code is available at https://github.com/ShunLu91/PINAT.","https://ojs.aaai.org/index.php/AAAI/article/view/26076/25848"
"26077","Multi-View Domain Adaptive Object Detection on Camera Networks","['Yan Lu', 'Zhun Zhong', 'Yuanchao Shu']","['New York University', 'University of Trento', 'Zhejiang University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'CV: Applications', 'CV: Object Detection & Categorization', 'ML: Unsupervised & Self-Supervised Learning']","Lu, Y., Zhong, Z., & Shu, Y. (2023). Multi-View Domain Adaptive Object Detection on Camera Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8966-8974. https://doi.org/10.1609/aaai.v37i7.26077","Abstract 					In this paper, we study a new domain adaptation setting on camera networks, namely Multi-View Domain Adaptive Object Detection (MVDA-OD), in which labeled source data is unavailable in the target adaptation process and target data is captured from multiple overlapping cameras. In such a challenging context, existing methods including adversarial training and self-training fall short due to multi-domain data shift and the lack of source data. To tackle this problem, we propose a novel training framework consisting of two stages. First, we pre-train the backbone using self-supervised learning, in which a multi-view association is developed to construct an effective pretext task. Second, we fine-tune the detection head using robust self-training, where a tracking-based single-view augmentation is introduced to achieve weak-hard consistency learning. By doing so, an object detection model can take advantage of informative samples generated by multi-view association and single-view augmentation to learn discriminative backbones as well as robust detection classifiers. Experiments on two real-world multi-camera datasets demonstrate significant advantages of our approach over the state-of-the-art domain adaptive object detection methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26077/25849"
"26078","Generative Label Enhancement with Gaussian Mixture and Partial Ranking","['Yunan Lu', 'Liang He', 'Fan Min', 'Weiwei Li', 'Xiuyi Jia']","['Nanjing University of Science and Technology', 'Nanjing University of Science and Technology', 'Southwest Petroleum University', 'Nanjing University of Aeronautics and Astronautics', 'Nanjing University of Science and Technology']","['ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Unsupervised & Self-Supervised Learning']","Lu, Y., He, L., Min, F., Li, W., & Jia, X. (2023). Generative Label Enhancement with Gaussian Mixture and Partial Ranking. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8975-8983. https://doi.org/10.1609/aaai.v37i7.26078","Abstract 					Label distribution learning (LDL) is an effective learning paradigm for dealing with label ambiguity. When applying LDL, the datasets annotated with label distributions (i.e., the real-valued vectors like the probability distribution) are typically required. Unfortunately, most existing datasets only contain the logical labels, and manual annotating with label distributions is costly. To address this problem, we treat the label distribution as a latent vector and infer its posterior by variational Bayes. Specifically, we propose a generative label enhancement model to encode the process of generating feature vectors and logical label vectors from label distributions in a principled way. In terms of features, we assume that the feature vector is generated by a Gaussian mixture dominated by the label distribution, which captures the one-to-many relationship from the label distribution to the feature vector and thus reduces the feature generation error. In terms of logical labels, we design a probability distribution to generate the logical label vector from a label distribution, which captures partial label ranking in the logical label vector and thus provides a more accurate guidance for inferring the label distribution. Besides, to approximate the posterior of the label distribution, we design a inference model, and derive the variational learning objective. Finally, extensive experiments on real-world datasets validate our proposal.","https://ojs.aaai.org/index.php/AAAI/article/view/26078/25850"
"26079","Crowd-Level Abnormal Behavior Detection via Multi-Scale Motion Consistency Learning","['Linbo Luo', 'Yuanjing Li', 'Haiyan Yin', 'Shangwei Xie', 'Ruimin Hu', 'Wentong Cai']","['Xidian University', 'Xidian University', 'Sea AI Lab', 'Xidian University', 'Xidian University', 'Nanyang Technological University']","['ML: Applications', 'APP: Humanities & Computational Social Science']","Luo, L., Li, Y., Yin, H., Xie, S., Hu, R., & Cai, W. (2023). Crowd-Level Abnormal Behavior Detection via Multi-Scale Motion Consistency Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8984-8992. https://doi.org/10.1609/aaai.v37i7.26079","Abstract 					Detecting abnormal crowd motion emerging from complex interactions of individuals is paramount to ensure the safety of crowds. Crowd-level abnormal behaviors (CABs), e.g., counter flow and crowd turbulence, are proven to be the crucial causes of many crowd disasters. In the recent decade, video anomaly detection (VAD) techniques have achieved remarkable success in detecting individual-level abnormal behaviors (e.g., sudden running, fighting and stealing), but research on VAD for CABs is rather limited. Unlike individual-level anomaly, CABs usually do not exhibit salient difference from the normal behaviors when observed locally, and the scale of CABs could vary from one scenario to another. In this paper, we present a systematic study to tackle the important problem of VAD for CABs with a novel crowd motion learning framework, multi-scale motion consistency network (MSMC-Net). MSMC-Net first captures the spatial and temporal crowd motion consistency information in a graph representation. Then, it simultaneously trains multiple feature graphs constructed at different scales to capture rich crowd patterns. An attention network is used to adaptively fuse the multi-scale features for better CAB detection. For the empirical study, we consider three large-scale crowd event datasets, UMN, Hajj and Love Parade. Experimental results show that MSMC-Net could substantially improve the state-of-the-art performance on all the datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26079/25851"
"26080","MVCINN: Multi-View Diabetic Retinopathy Detection Using a Deep Cross-Interaction Neural Network","['Xiaoling Luo', 'Chengliang Liu', 'Waikeung Wong', 'Jie Wen', 'Xiaopeng Jin', 'Yong Xu']","['Harbin Institute of Technology, Shenzhen, China', 'Harbin Institute of Technology, Shenzhen, China', 'The Hong Kong Polytechnic University, Kowloon, Hong Kong\nLaboratory for Artificial Intelligence in Design, Hong Kong', 'Harbin Institute of Technology, Shenzhen, China', 'Shenzhen Technology University, Shenzhen, China', 'Harbin Institute of Technology, Shenzhen, China']","['ML: Multi-Instance/Multi-View Learning', 'ML: Classification and Regression']","Luo, X., Liu, C., Wong, W., Wen, J., Jin, X., & Xu, Y. (2023). MVCINN: Multi-View Diabetic Retinopathy Detection Using a Deep Cross-Interaction Neural Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 8993-9001. https://doi.org/10.1609/aaai.v37i7.26080","Abstract 					Diabetic retinopathy (DR) is the main cause of irreversible blindness for working-age adults. The previous models for DR detection have difficulties in clinical application. The main reason is that most of the previous methods only use single-view data, and the single field of view (FOV) only accounts for about 13% of the FOV of the retina, resulting in the loss of most lesion features. To alleviate this problem, we propose a multi-view model for DR detection, which takes full advantage of multi-view images covering almost all of the retinal field. To be specific, we design a Cross-Interaction Self-Attention based Module (CISAM) that interfuses local features extracted from convolutional blocks with long-range global features learned from transformer blocks. Furthermore, considering the pathological association in different views, we use the feature jigsaw to assemble and learn the features of multiple views. Extensive experiments on the latest public multi-view MFIDDR dataset with 34,452 images demonstrate the superiority of our method, which performs favorably against state-of-the-art models. To the best of our knowledge, this work is the first study on the public large-scale multi-view fundus images dataset for DR detection.","https://ojs.aaai.org/index.php/AAAI/article/view/26080/25852"
"26081","Local Explanations for Reinforcement Learning","['Ronny Luss', 'Amit Dhurandhar', 'Miao Liu']","['IBM Research', 'IBM Research', 'IBM Research']","['ML: Transparent', 'Interpretable', 'Explainable ML']","Luss, R., Dhurandhar, A., & Liu, M. (2023). Local Explanations for Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 9002-9010. https://doi.org/10.1609/aaai.v37i7.26081","Abstract 					Many works in explainable AI have focused on explaining black-box classification models. Explaining deep reinforcement learning (RL) policies in a manner that could be understood by domain users has received much less attention. In this paper, we propose a novel perspective to understanding RL policies based on identifying important states from automatically learned meta-states. The key conceptual difference between our approach and many previous ones is that we form meta-states based on locality governed by the expert policy dynamics rather than based on similarity of actions, and that we do not assume any particular knowledge of the underlying topology of the state space. Theoretically, we show that our algorithm to find meta-states converges and the objective that selects important states from each meta-state is submodular leading to efficient high quality greedy selection. Experiments on four domains (four rooms, door-key, minipacman, and pong) and a carefully conducted user study illustrate that our perspective leads to better understanding of the policy. We conjecture that this is a result of our meta-states being more intuitive in that the corresponding important states are strong indicators of tractable intermediate goals that are easier for humans to interpret and follow.","https://ojs.aaai.org/index.php/AAAI/article/view/26081/25853"
"26082","Compositional Prototypical Networks for Few-Shot Classification","['Qiang Lyu', 'Weiqiang Wang']","['University of Chinese Academy of Sciences', 'University of Chinese Academy of Sciences']","['ML: Meta Learning', 'ML: Representation Learning', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'ML: Classification and Regression']","Lyu, Q., & Wang, W. (2023). Compositional Prototypical Networks for Few-Shot Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 9011-9019. https://doi.org/10.1609/aaai.v37i7.26082","Abstract 					It is assumed that pre-training provides the feature extractor with strong class transferability and that high novel class generalization can be achieved by simply reusing the transferable feature extractor. In this work, our motivation is to explicitly learn some fine-grained and transferable meta-knowledge so that feature reusability can be further improved. Concretely, inspired by the fact that humans can use learned concepts or components to help them recognize novel classes, we propose Compositional Prototypical Networks (CPN) to learn a transferable prototype for each human-annotated attribute, which we call a component prototype. We empirically demonstrate that the learned component prototypes have good class transferability and can be reused to construct compositional prototypes for novel classes. Then a learnable weight generator is utilized to adaptively fuse the compositional and visual prototypes. Extensive experiments demonstrate that our method can achieve state-of-the-art results on different datasets and settings. The performance gains are especially remarkable in the 5-way 1-shot setting. The code is available at https://github.com/fikry102/CPN.","https://ojs.aaai.org/index.php/AAAI/article/view/26082/25854"
"26083","Poisoning with Cerberus: Stealthy and Colluded Backdoor Attack against Federated Learning","['Xiaoting Lyu', 'Yufei Han', 'Wei Wang', 'Jingkai Liu', 'Bin Wang', 'Jiqiang Liu', 'Xiangliang Zhang']","['Beijing Jiaotong University', 'INRIA', 'Beijing Jiaotong University', 'Beijing Jiaotong University', 'Zhejiang Key Laboratory of Multi-dimensional Perception Technology, Application and Cybersecurity', 'Beijing Jiaotong University', 'University of Notre Dame']","['ML: Distributed Machine Learning & Federated Learning', 'ML: Adversarial Learning & Robustness', 'ML: Classification and Regression']","Lyu, X., Han, Y., Wang, W., Liu, J., Wang, B., Liu, J., & Zhang, X. (2023). Poisoning with Cerberus: Stealthy and Colluded Backdoor Attack against Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 9020-9028. https://doi.org/10.1609/aaai.v37i7.26083","Abstract 					Are Federated Learning (FL) systems free from backdoor poisoning with the arsenal of various defense strategies deployed? This is an intriguing problem with significant practical implications regarding the utility of FL services. Despite the recent flourish of poisoning-resilient FL methods, our study shows that carefully tuning the collusion between malicious participants can minimize the trigger-induced bias of the poisoned local model from the poison-free one, which plays the key role in delivering stealthy backdoor attacks and circumventing a wide spectrum of state-of-the-art defense methods in FL. In our work, we instantiate the attack strategy by proposing a distributed backdoor attack method, namely Cerberus Poisoning (CerP). It jointly tunes the backdoor trigger and controls the poisoned model changes on each malicious participant to achieve a stealthy yet successful backdoor attack against a wide spectrum of defensive mechanisms of federated learning techniques. Our extensive study on 3 large-scale benchmark datasets and 13 mainstream defensive mechanisms confirms that Cerberus Poisoning raises a significantly severe threat to the integrity and security of federated learning practices, regardless of the flourish of robust Federated Learning methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26083/25855"
"26084","OMPQ: Orthogonal Mixed Precision Quantization","['Yuexiao Ma', 'Taisong Jin', 'Xiawu Zheng', 'Yan Wang', 'Huixia Li', 'Yongjian Wu', 'Guannan Jiang', 'Wei Zhang', 'Rongrong Ji']","['Xiamen University', 'Xiamen University', 'Peng Cheng Laboratory', 'Samsara', 'Xiamen University', 'Tencent Technology (Shanghai) Co.,Ltd', 'CATL', 'CATL', 'Xiamen University, China']","['ML: Learning on the Edge & Model Compression']","Ma, Y., Jin, T., Zheng, X., Wang, Y., Li, H., Wu, Y., Jiang, G., Zhang, W., & Ji, R. (2023). OMPQ: Orthogonal Mixed Precision Quantization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 9029-9037. https://doi.org/10.1609/aaai.v37i7.26084","Abstract 					To bridge the ever-increasing gap between deep neural networks' complexity and hardware capability, network quantization has attracted more and more research attention. The latest trend of mixed precision quantization takes advantage of hardware's multiple bit-width arithmetic operations to unleash the full potential of network quantization. However, existing approaches rely heavily on an extremely time-consuming search process and various relaxations when seeking the optimal bit configuration. To address this issue, we propose to optimize a proxy metric of network orthogonality that can be efficiently solved with linear programming, which proves to be highly correlated with quantized model accuracy and bit-width. Our approach significantly reduces the search time and the required data amount by orders of magnitude, but without a compromise on quantization accuracy. Specifically, we achieve 72.08% Top-1 accuracy on ResNet-18 with 6.7Mb parameters, which does not require any searching iterations. Given the high efficiency and low data dependency of our algorithm, we use it for the post-training quantization, which achieves 71.27% Top-1 accuracy on MobileNetV2 with only 1.5Mb parameters.","https://ojs.aaai.org/index.php/AAAI/article/view/26084/25856"
"26085","Recovering the Graph Underlying Networked Dynamical Systems under Partial Observability: A Deep Learning Approach","['Sérgio Machado', 'Anirudh Sridhar', 'Paulo Gil', 'Jorge Henriques', 'José M. F. Moura', 'Augusto Santos']","['University of Coimbra, Portugal\nDepartment of Electrical and Computer Engineering at Carnegie Mellon University, Pittsburgh, PA, USA', 'Department of Electrical and Computer Engineering at Princeton University, New Jersey, NJ, USA', 'Universidade Nova de Lisboa, Portugal\nUniversity of Coimbra, Portugal', 'University of Coimbra, Portugal', 'Department of Electrical and Computer Engineering at Carnegie Mellon University, Pittsburgh, PA, USA', 'Instituto de Telecomunicações, Portugal\nUniversity of Coimbra, Portugal']","['ML: Causal Learning', 'RU: Causality', 'ML: Probabilistic Methods', 'ML: Time-Series/Data Streams', 'ML: Graph-based Machine Learning', 'RU: Graphical Model', 'RU: Stochastic Models & Probabilistic Inference']","Machado, S., Sridhar, A., Gil, P., Henriques, J., Moura, J. M. F., & Santos, A. (2023). Recovering the Graph Underlying Networked Dynamical Systems under Partial Observability: A Deep Learning Approach. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 9038-9046. https://doi.org/10.1609/aaai.v37i7.26085","Abstract 					We study the problem of graph structure identification, i.e., of recovering the graph of dependencies among time series. We model these time series data as components of the state of linear stochastic networked dynamical systems. We assume partial observability, where the state evolution of only a subset of nodes comprising the network is observed. We propose a new feature-based paradigm: to each pair of nodes, we compute a feature vector from the observed time series. We prove that these features are linearly separable, i.e., there exists a hyperplane that separates the cluster of features associated with connected pairs of nodes from those of disconnected pairs. This renders the features amenable to train a variety of classifiers to perform causal inference. In particular, we use these features to train Convolutional Neural Networks (CNNs). The resulting causal inference mechanism outperforms state-of-the-art counterparts w.r.t. sample-complexity. The trained CNNs generalize well over structurally distinct networks (dense or sparse) and noise-level profiles. Remarkably, they also generalize well to real-world networks while trained over a synthetic network -- namely, a particular realization of a random graph.","https://ojs.aaai.org/index.php/AAAI/article/view/26085/25857"
"26086","LIMIP: Lifelong Learning to Solve Mixed Integer Programs","['Sahil Manchanda', 'Sayan Ranu']","['Indian Institute of Technology, Delhi', 'Indian Institute of Technology, Delhi']","['ML: Graph-based Machine Learning', 'ML: Applications']","Manchanda, S., & Ranu, S. (2023). LIMIP: Lifelong Learning to Solve Mixed Integer Programs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 9047-9054. https://doi.org/10.1609/aaai.v37i7.26086","Abstract 					Mixed Integer programs (MIPs) are typically solved by the Branch-and-Bound algorithm. Recently, Learning to imitate fast approximations of the expert strong branching heuristic has gained attention due to its success in reducing the running time for solving MIPs. However, existing learning-to-branch methods assume that the entire training data is available in a single session of training. This assumption is often not true, and if the training data is supplied in continual fashion over time, existing techniques suffer from catastrophic forgetting. In this work, we study the hitherto unexplored paradigm of Lifelong Learning to Branch on Mixed Integer Programs. To mitigate catastrophic forgetting, we propose LIMIP, which is powered by the idea of modeling an MIP instance in the form of a bipartite graph, which we map to an embedding space using a bipartite Graph Attention Network. This rich embedding space avoids catastrophic forgetting through the application of knowledge distillation and elastic weight consolidation, wherein we learn the parameters key towards retaining efficacy and are therefore protected from significant drift. We evaluate LIMIP on a series of NP-hard problems and establish that in comparison to existing baselines, LIMIP is up to 50% better when confronted with lifelong learning","https://ojs.aaai.org/index.php/AAAI/article/view/26086/25858"
"26087","Proximal Stochastic Recursive Momentum Methods for Nonconvex Composite Decentralized Optimization","['Gabriel Mancino-Ball', 'Shengnan Miao', 'Yangyang Xu', 'Jie Chen']","['Rensselaer Polytechnic Institute', 'Rensselaer Polytechnic Institute', 'Rensselaer Polytechnic Institute', 'IBM Research']","['ML: Optimization', 'ML: Distributed Machine Learning & Federated Learning']","Mancino-Ball, G., Miao, S., Xu, Y., & Chen, J. (2023). Proximal Stochastic Recursive Momentum Methods for Nonconvex Composite Decentralized Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 9055-9063. https://doi.org/10.1609/aaai.v37i7.26087","Abstract 					Consider a network of N decentralized computing agents collaboratively solving a nonconvex stochastic composite problem. In this work, we propose a single-loop algorithm, called DEEPSTORM, that achieves optimal sample complexity for this setting. Unlike double-loop algorithms that require a large batch size to compute the (stochastic) gradient once in a while, DEEPSTORM uses a small batch size, creating advantages in occasions such as streaming data and online learning. This is the first method achieving optimal sample complexity for decentralized nonconvex stochastic composite problems, requiring O(1) batch size. We conduct convergence analysis for DEEPSTORM with both constant and diminishing step sizes. Additionally, under proper initialization and a small enough desired solution error, we show that DEEPSTORM with a constant step size achieves a network-independent sample complexity, with an additional linear speed-up with respect to N over centralized methods. All codes are made available at https://github.com/gmancino/DEEPSTORM.","https://ojs.aaai.org/index.php/AAAI/article/view/26087/25859"
"26088","Online Reinforcement Learning with Uncertain Episode Lengths","['Debmalya Mandal', 'Goran Radanovic', 'Jiarui Gan', 'Adish Singla', 'Rupak Majumdar']","['Max Planck Institute for Software Systems', 'Max Planck Institute for Software Systems', 'University of Oxford', 'Max Planck Institute for Software Systems', 'Max Planck Institute for Software Systems']","['ML: Reinforcement Learning Algorithms', 'ML: Online Learning & Bandits', 'RU: Sequential Decision Making']","Mandal, D., Radanovic, G., Gan, J., Singla, A., & Majumdar, R. (2023). Online Reinforcement Learning with Uncertain Episode Lengths. Proceedings of the AAAI Conference on Artificial Intelligence, 37(7), 9064-9071. https://doi.org/10.1609/aaai.v37i7.26088","Abstract 					Existing episodic reinforcement algorithms assume that the  length of an episode is fixed across time and known a priori. In this paper, we consider a general framework of  episodic reinforcement learning when the length of each episode is drawn from a distribution. We first establish that this problem is equivalent to online reinforcement learning with general discounting where the learner is trying to optimize the expected discounted sum of rewards over an infinite horizon, but where the discounting function is not necessarily geometric. We show that minimizing regret with this new general discounting is equivalent to minimizing regret with uncertain episode lengths. We then design a reinforcement learning algorithm that minimizes regret with general discounting but acts for the setting with uncertain episode lengths. We instantiate  our general bound for different types of discounting, including geometric and polynomial discounting. We also show that we can obtain similar regret bounds even when the uncertainty over the episode lengths is unknown, by estimating the unknown distribution over time. Finally, we compare our learning algorithms with existing value-iteration based episodic RL algorithms on a grid-world environment.","https://ojs.aaai.org/index.php/AAAI/article/view/26088/25860"
"26089","Tight Performance Guarantees of Imitator Policies with Continuous Actions","['Davide Maran', 'Alberto Maria Metelli', 'Marcello Restelli']","['Politecnico di Milano', 'Politecnico di Milano', 'Politecnico di Milano']","['ML: Imitation Learning & Inverse Reinforcement Learning', 'ML: Reinforcement Learning Algorithms', 'ML: Reinforcement Learning Theory', 'ML: Learning Theory']","Maran, D., Metelli, A. M., & Restelli, M. (2023). Tight Performance Guarantees of Imitator Policies with Continuous Actions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9073-9080. https://doi.org/10.1609/aaai.v37i8.26089","Abstract 					Behavioral Cloning (BC) aims at learning a policy that mimics the behavior demonstrated by an expert. The current theoretical understanding of BC is limited to the case of finite actions. In this paper, we study BC with the goal of providing theoretical guarantees on the performance of the imitator policy in the case of continuous actions. We start by deriving a novel bound on the performance gap based on Wasserstein distance, applicable for continuous-action experts, holding under the assumption that the value function is Lipschitz continuous. Since this latter condition is hardy fulfilled in practice, even for Lipschitz Markov Decision Processes and policies, we propose a relaxed setting, proving that value function is always H\""older continuous. This result is of independent interest and allows obtaining in BC a general bound for the performance of the imitator policy. Finally, we analyze noise injection, a common practice in which the expert's action is executed in the environment after the application of a noise kernel. We show that this practice allows deriving stronger performance guarantees, at the price of a bias due to the noise addition.","https://ojs.aaai.org/index.php/AAAI/article/view/26089/25861"
"26090","Weight Predictor Network with Feature Selection for Small Sample Tabular Biomedical Data","['Andrei Margeloiu', 'Nikola Simidjievski', 'Pietro Liò', 'Mateja Jamnik']","['University of Cambridge, UK', 'University of Cambridge, UK', 'University of Cambridge, UK', 'University of Cambridge, UK']","['ML: Classification and Regression', 'APP: Healthcare', 'Medicine & Wellness', 'APP: Bioinformatics', 'ML: Deep Neural Architectures', 'ML: Dimensionality Reduction/Feature Selection']","Margeloiu, A., Simidjievski, N., Liò, P., & Jamnik, M. (2023). Weight Predictor Network with Feature Selection for Small Sample Tabular Biomedical Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9081-9089. https://doi.org/10.1609/aaai.v37i8.26090","Abstract 					Tabular biomedical data is often high-dimensional but with a very small number of samples. Although recent work showed that well-regularised simple neural networks could outperform more sophisticated architectures on tabular data, they are still prone to overfitting on tiny datasets with many potentially irrelevant features. To combat these issues, we propose Weight Predictor Network with Feature Selection (WPFS) for learning neural networks from high-dimensional and small sample data by reducing the number of learnable parameters and simultaneously performing feature selection. In addition to the classification network, WPFS uses two small auxiliary networks that together output the weights of the first layer of the classification model. We evaluate on nine real-world biomedical datasets and demonstrate that WPFS outperforms other standard as well as more recent methods typically applied to tabular data. Furthermore, we investigate the proposed feature selection mechanism and show that it improves performance while providing useful insights into the learning task.","https://ojs.aaai.org/index.php/AAAI/article/view/26090/25862"
"26091","Learning Revenue Maximization Using Posted Prices for Stochastic Strategic Patient Buyers","['Eitan-Hai Mashiah', 'Idan Attias', 'Yishay Mansour']","['Tel Aviv University', 'Ben-Gurion University', 'Tel Aviv University\nGoogle Research']","['ML: Learning Theory', 'GTEP: Equilibrium']","Mashiah, E.-H., Attias, I., & Mansour, Y. (2023). Learning Revenue Maximization Using Posted Prices for Stochastic Strategic Patient Buyers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9090-9098. https://doi.org/10.1609/aaai.v37i8.26091","Abstract 					We consider a seller faced with buyers which have the ability to delay their decision, which we call patience. Each buyer's type is composed of value and patience, and it is sampled i.i.d. from a distribution. The seller, using posted prices, would like to maximize her revenue from selling to the buyer.  In this paper, we formalize this setting and characterize the resulting Stackelberg equilibrium, where the seller first commits to her strategy, and then the buyers best respond. Following this, we show how to compute both the optimal pure and mixed strategies.  We then consider a learning setting, where the seller does not have access to the distribution over buyer's types. Our main results are the following. We derive a sample complexity bound for the learning of an approximate optimal pure strategy, by computing the fat-shattering dimension of this setting. Moreover, we provide a general sample complexity bound for the approximate optimal mixed strategy.  We also consider an online setting and derive a vanishing regret bound with respect to both the optimal pure strategy and the optimal mixed strategy.","https://ojs.aaai.org/index.php/AAAI/article/view/26091/25863"
"26092","Boundary Graph Neural Networks for 3D Simulations","['Andreas Mayr', 'Sebastian Lehner', 'Arno Mayrhofer', 'Christoph Kloss', 'Sepp Hochreiter', 'Johannes Brandstetter']","['Johannes Kepler University Linz, Linz, Austria', 'Johannes Kepler University Linz, Linz, Austria', 'DCS Computing GmbH, Linz, Austria', 'DCS Computing GmbH, Linz, Austria', 'Johannes Kepler University Linz, Linz, Austria\nInstitute of Advanced Research in Artificial Intelligence (IARAI), Vienna, Austria', 'Johannes Kepler University Linz, Linz, Austria']","['ML: Applications', 'APP: Natural Sciences', 'KRR: Applications', 'KRR: Geometric', 'Spatial', 'and Temporal Reasoning', 'ML: Deep Neural Architectures', 'ML: Graph-based Machine Learning']","Mayr, A., Lehner, S., Mayrhofer, A., Kloss, C., Hochreiter, S., & Brandstetter, J. (2023). Boundary Graph Neural Networks for 3D Simulations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9099-9107. https://doi.org/10.1609/aaai.v37i8.26092","Abstract 					The abundance of data has given machine learning considerable momentum in natural sciences and engineering, though modeling of physical processes is often difficult. A particularly tough problem is the efficient representation of geometric boundaries. Triangularized geometric boundaries are well understood and ubiquitous in engineering applications. However, it is notoriously difficult to integrate them into machine learning approaches due to their heterogeneity with respect to size and orientation. In this work, we introduce an effective theory to model particle-boundary interactions, which leads to our new Boundary Graph Neural Networks (BGNNs) that dynamically modify graph structures to obey boundary conditions. The new BGNNs are tested on complex 3D granular flow processes of hoppers, rotating drums and mixers, which are all standard components of modern industrial machinery but still have complicated geometry. BGNNs are evaluated in terms of computational efficiency as well as prediction accuracy of particle flows and mixing entropies. BGNNs are able to accurately reproduce 3D granular flows within simulation uncertainties over hundreds of thousands of simulation timesteps. Most notably, in our experiments, particles stay within the geometric objects without using handcrafted conditions or restrictions.","https://ojs.aaai.org/index.php/AAAI/article/view/26092/25864"
"26093","Diffusion Models Beat GANs on Topology Optimization","['François Mazé', 'Faez Ahmed']","['Massachusetts Institute of Technology', 'Massachusetts Institute of Technology']","['ML: Deep Generative Models & Autoencoders', 'APP: Design', 'ML: Applications', 'ML: Representation Learning']","Mazé, F., & Ahmed, F. (2023). Diffusion Models Beat GANs on Topology Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9108-9116. https://doi.org/10.1609/aaai.v37i8.26093","Abstract 					Structural topology optimization, which aims to find the optimal physical structure that maximizes mechanical performance, is vital in engineering design applications in aerospace, mechanical, and civil engineering. Recently, generative adversarial networks (GANs) have emerged as a popular alternative to traditional iterative topology optimization methods. However, GANs can be challenging to train, have limited generalizability, and often neglect important performance objectives such as mechanical compliance and manufacturability. To address these issues, we propose a new architecture called TopoDiff that uses conditional diffusion models to perform performance-aware and manufacturability-aware topology optimization. Our method introduces a surrogate model-based guidance strategy that actively favors structures with low compliance and good manufacturability. Compared to a state-of-the-art conditional GAN, our approach reduces the average error on physical performance by a factor of eight and produces eleven times fewer infeasible samples. Our work demonstrates the potential of using diffusion models in topology optimization and suggests a general framework for solving engineering optimization problems using external performance with constraint-aware guidance. We provide access to our data, code, and trained models at the following link: https://decode.mit.edu/projects/topodiff/.","https://ojs.aaai.org/index.php/AAAI/article/view/26093/25865"
"26094","VIDM: Video Implicit Diffusion Models","['Kangfu Mei', 'Vishal Patel']","['Johns Hopkins University', 'Johns Hopkins University']","['ML: Deep Generative Models & Autoencoders']","Mei, K., & Patel, V. (2023). VIDM: Video Implicit Diffusion Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9117-9125. https://doi.org/10.1609/aaai.v37i8.26094","Abstract 					Diffusion models have emerged as a powerful generative method for synthesizing high-quality and diverse set of images. In this paper, we propose a video generation method based on diffusion models, where the effects of motion are modeled in an implicit condition manner, i.e. one can sample plausible video motions according to the latent feature of frames. We improve the quality of the generated videos by proposing multiple strategies such as sampling space truncation, robustness penalty, and positional group normalization. Various experiments are conducted on datasets consisting of videos with different resolutions and different number of frames. Results show that the proposed method outperforms the state-of-the-art generative adversarial network-based methods by a significant margin in terms of FVD scores as well as perceptible visual quality.","https://ojs.aaai.org/index.php/AAAI/article/view/26094/25866"
"26095","Towards Interpreting and Utilizing Symmetry Property in Adversarial Examples","['Shibin Mei', 'Chenglong Zhao', 'Bingbing Ni', 'Shengchao Yuan']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['ML: Representation Learning', 'CV: Applications']","Mei, S., Zhao, C., Ni, B., & Yuan, S. (2023). Towards Interpreting and Utilizing Symmetry Property in Adversarial Examples. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9126-9133. https://doi.org/10.1609/aaai.v37i8.26095","Abstract 					In this paper, we identify symmetry property in adversarial scenario by viewing adversarial attack in a fine-grained manner. A newly designed metric called attack proportion, is thus proposed to count the proportion of the adversarial examples misclassified between classes. We observe that the distribution of attack proportion is unbalanced as each class shows vulnerability to particular classes. Further, some class pairs correlate strongly and have the same degree of attack proportion for each other. We call this intriguing phenomenon symmetry property. We empirically prove this phenomenon is widespread and then analyze the reason behind the existence of symmetry property. This explanation, to some extent, could be utilized to understand robust models, which also inspires us to strengthen adversarial defenses.","https://ojs.aaai.org/index.php/AAAI/article/view/26095/25867"
"26096","The Unreasonable Effectiveness of Deep Evidential Regression","['Nis Meinert', 'Jakob Gawlikowski', 'Alexander Lavin']","['Pasteur Labs', 'German Aerospace Center (DLR)', 'Pasteur Labs']","['ML: Calibration & Uncertainty Quantification', 'ML: Classification and Regression', 'ML: Deep Neural Architectures', 'RU: Uncertainty Representations']","Meinert, N., Gawlikowski, J., & Lavin, A. (2023). The Unreasonable Effectiveness of Deep Evidential Regression. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9134-9142. https://doi.org/10.1609/aaai.v37i8.26096","Abstract 					There is a significant need for principled uncertainty reasoning in machine learning systems as they are increasingly deployed in safety-critical domains. A new approach with uncertainty-aware regression-based neural networks (NNs), based on learning evidential distributions for aleatoric and epistemic uncertainties, shows promise over traditional deterministic methods and typical Bayesian NNs, notably with the capabilities to disentangle aleatoric and epistemic uncertainties. Despite some empirical success of Deep Evidential Regression (DER), there are important gaps in the mathematical foundation that raise the question of why the proposed technique seemingly works. We detail the theoretical shortcomings and analyze the performance on synthetic and real-world data sets, showing that Deep Evidential Regression is a heuristic rather than an exact uncertainty quantification. We go on to discuss corrections and redefinitions of how aleatoric and epistemic uncertainties should be extracted from NNs.","https://ojs.aaai.org/index.php/AAAI/article/view/26096/25868"
"26097","HyperJump: Accelerating HyperBand via Risk Modelling","['Pedro Mendes', 'Maria Casimiro', 'Paolo Romano', 'David Garlan']","['INESC-ID and Instituto Superior Técnico, Universidade de Lisboa\nSoftware and Societal Systems Department, Carnegie Mellon University', 'INESC-ID and Instituto Superior Técnico, Universidade de Lisboa\nSoftware and Societal Systems Department, Carnegie Mellon University', 'INESC-ID and Instituto Superior Técnico, Universidade de Lisboa', 'Software and Societal Systems Department, Carnegie Mellon University']","['ML: Auto ML and Hyperparameter Tuning']","Mendes, P., Casimiro, M., Romano, P., & Garlan, D. (2023). HyperJump: Accelerating HyperBand via Risk Modelling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9143-9152. https://doi.org/10.1609/aaai.v37i8.26097","Abstract 					In the literature on hyper-parameter tuning, a number of recent solutions rely on low-fidelity observations (e.g., training with sub-sampled datasets) to identify promising configurations to be tested via high-fidelity observations (e.g., using the full dataset). Among these, HyperBand is arguably one of the most popular solutions, due to its efficiency and theoretically provable robustness. In this work, we introduce HyperJump, a new approach that builds on HyperBand’s robust search strategy and complements it with novel model-based risk analysis techniques that accelerate the search by skipping the evaluation of low risk configurations, i.e., configurations that are likely to be eventually discarded by HyperBand. We evaluate HyperJump on a suite of hyper-parameter optimization problems and show that it provides over one-order of magnitude speed-ups, both in sequential and parallel deployments, on a variety of deep-learning, kernel-based learning and neural architectural search problems when compared to HyperBand and to several state-of-the-art optimizers.","https://ojs.aaai.org/index.php/AAAI/article/view/26097/25869"
"26098","MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series","['Qianwen Meng', 'Hangwei Qian', 'Yong Liu', 'Lizhen Cui', 'Yonghui Xu', 'Zhiqi Shen']","['Shandong University\nJoint SDU-NTU Centre for Artificial Intelligence Research (C-FAIR)', 'Lund University', 'Nanyang Technological University', 'Shandong University\nJoint SDU-NTU Centre for Artificial Intelligence Research (C-FAIR)', 'Shandong University\nJoint SDU-NTU Centre for Artificial Intelligence Research (C-FAIR)', 'Nanyang Technological University']","['ML: Unsupervised & Self-Supervised Learning', 'ML: Clustering', 'ML: Representation Learning', 'ML: Time-Series/Data Streams']","Meng, Q., Qian, H., Liu, Y., Cui, L., Xu, Y., & Shen, Z. (2023). MHCCL: Masked Hierarchical Cluster-Wise Contrastive Learning for Multivariate Time Series. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9153-9161. https://doi.org/10.1609/aaai.v37i8.26098","Abstract 					Learning semantic-rich representations from raw unlabeled time series data is critical for downstream tasks such as classification and forecasting. Contrastive learning has recently shown its promising representation learning capability in the absence of expert annotations. However, existing contrastive approaches generally treat each instance independently, which leads to false negative pairs that share the same semantics. To tackle this problem, we propose MHCCL, a Masked Hierarchical Cluster-wise Contrastive Learning model, which exploits semantic information obtained from the hierarchical structure consisting of multiple latent partitions for multivariate time series. Motivated by the observation that fine-grained clustering preserves higher purity while coarse-grained one reflects higher-level semantics, we propose a novel downward masking strategy to filter out fake negatives and supplement positives by incorporating the multi-granularity information from the clustering hierarchy. In addition, a novel upward masking strategy is designed in MHCCL to remove outliers of clusters at each partition to refine prototypes, which helps speed up the hierarchical clustering process and improves the clustering quality. We conduct experimental evaluations on seven widely-used multivariate time series datasets. The results demonstrate the superiority of MHCCL over the state-of-the-art approaches for unsupervised time series representation learning.","https://ojs.aaai.org/index.php/AAAI/article/view/26098/25870"
"26099","Off-Policy Proximal Policy Optimization","['Wenjia Meng', 'Qian Zheng', 'Gang Pan', 'Yilong Yin']","['School of Software, Shandong University, Jinan, China', 'The State Key Lab of Brain-Machine Intelligence, Zhejiang University, Hangzhou, China\nCollege of Computer Science and Technology, Zhejiang University, Hangzhou, China', 'The State Key Lab of Brain-Machine Intelligence, Zhejiang University, Hangzhou, China\nCollege of Computer Science and Technology, Zhejiang University, Hangzhou, China', 'School of Software, Shandong University, Jinan, China']","['ML: Reinforcement Learning Algorithms', 'PRS: Control of High-Dimensional Systems', 'RU: Sequential Decision Making']","Meng, W., Zheng, Q., Pan, G., & Yin, Y. (2023). Off-Policy Proximal Policy Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9162-9170. https://doi.org/10.1609/aaai.v37i8.26099","Abstract 					Proximal Policy Optimization (PPO) is an important reinforcement learning method, which has achieved great success in sequential decision-making problems. However, PPO faces the issue of sample inefficiency, which is due to the PPO cannot make use of off-policy data. In this paper, we propose an Off-Policy Proximal Policy Optimization method (Off-Policy PPO) that improves the sample efficiency of PPO by utilizing off-policy data. Specifically, we first propose a clipped surrogate objective function that can utilize off-policy data and avoid excessively large policy updates. Next, we theoretically clarify the stability of the optimization process of the proposed surrogate objective by demonstrating the degree of policy update distance is consistent with that in the PPO. We then describe the implementation details of the proposed Off-Policy PPO which iteratively updates policies by optimizing the proposed clipped surrogate objective. Finally, the experimental results on representative continuous control tasks validate that our method outperforms the state-of-the-art methods on most tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26099/25871"
"26100","Information-Theoretic Causal Discovery and Intervention Detection over Multiple Environments","['Osman Mian', 'Michael Kamp', 'Jilles Vreeken']","['CISPA Helmholtz Center for Information Security', 'Institute for AI in Medicine (IKIM), Ruhr-University Bochum, and Monash University', 'CISPA Helmholtz Center for Information Security']","['ML: Causal Learning', 'RU: Causality']","Mian, O., Kamp, M., & Vreeken, J. (2023). Information-Theoretic Causal Discovery and Intervention Detection over Multiple Environments. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9171-9179. https://doi.org/10.1609/aaai.v37i8.26100","Abstract 					Given multiple datasets over a fixed set of random variables, each collected from a different environment, we are interested in discovering the shared underlying causal network and the local interventions per environment, without assuming prior knowledge on which datasets are observational or interventional, and without assuming the shape of the causal dependencies. We formalize this problem using the Algorithmic Model of Causation, instantiate a consistent score via the Minimum Description Length principle, and show under which conditions the network and interventions are identifiable. To efficiently discover causal networks and intervention targets in practice, we introduce the ORION algorithm, which through extensive experiments we show outperforms the state of the art in causal inference over multiple environments.","https://ojs.aaai.org/index.php/AAAI/article/view/26100/25872"
"26101","AIO-P: Expanding Neural Performance Predictors beyond Image Classification","['Keith G. Mills', 'Di Niu', 'Mohammad Salameh', 'Weichen Qiu', 'Fred X. Han', 'Puyuan Liu', 'Jialin Zhang', 'Wei Lu', 'Shangling Jui']","['Department of Electrical and Computer Engineering, University of Alberta\nHuawei Technologies, Edmonton, Alberta, Canada', 'Department of Electrical and Computer Engineering, University of Alberta', 'Huawei Technologies, Edmonton, Alberta, Canada', 'Department of Electrical and Computer Engineering, University of Alberta', 'Huawei Technologies, Edmonton, Alberta, Canada', 'Huawei Technologies, Edmonton, Alberta, Canada', 'Huawei Kirin Solution, Shanghai, China', 'Huawei Technologies, Edmonton, Alberta, Canada', 'Huawei Kirin Solution, Shanghai, China']","['ML: Auto ML and Hyperparameter Tuning', 'CV: Applications', 'DMKM: Applications', 'ML: Graph-based Machine Learning', 'ML: Deep Neural Architectures', 'ML: Classification and Regression', 'ML: Optimization', 'CV: Segmentation', 'CV: Object Detection & Categorization']","Mills, K. G., Niu, D., Salameh, M., Qiu, W., Han, F. X., Liu, P., Zhang, J., Lu, W., & Jui, S. (2023). AIO-P: Expanding Neural Performance Predictors beyond Image Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9180-9189. https://doi.org/10.1609/aaai.v37i8.26101","Abstract 					Evaluating neural network performance is critical to deep neural network design but a costly procedure. Neural predictors provide an efficient solution by treating architectures as samples and learning to estimate their performance on a given task. However, existing predictors are task-dependent, predominantly estimating neural network performance on image classification benchmarks. They are also search-space dependent; each predictor is designed to make predictions for a specific architecture search space with predefined topologies and set of operations. In this paper, we propose a novel All-in-One Predictor (AIO-P), which aims to pretrain neural predictors on architecture examples from multiple, separate computer vision (CV) task domains and multiple architecture spaces, and then transfer to unseen downstream CV tasks or neural architectures. We describe our proposed techniques for general graph representation, efficient predictor pretraining and knowledge infusion techniques, as well as methods to transfer to downstream tasks/spaces. Extensive experimental results show that AIO-P can achieve Mean Absolute Error (MAE) and Spearman’s Rank Correlation (SRCC) below 1p% and above 0.5, respectively, on a breadth of target downstream CV tasks with or without fine-tuning, outperforming a number of baselines. Moreover, AIO-P can directly transfer to new architectures not seen during training, accurately rank them and serve as an effective performance estimator when paired with an algorithm designed to preserve performance while reducing FLOPs.","https://ojs.aaai.org/index.php/AAAI/article/view/26101/25873"
"26102","GENNAPE: Towards Generalized Neural Architecture Performance Estimators","['Keith G. Mills', 'Fred X. Han', 'Jialin Zhang', 'Fabian Chudak', 'Ali Safari Mamaghani', 'Mohammad Salameh', 'Wei Lu', 'Shangling Jui', 'Di Niu']","['Department of Electrical and Computer Engineering, University of Alberta\nHuawei Technologies, Edmonton, Alberta, Canada', 'Huawei Technologies, Edmonton, Alberta, Canada', 'Huawei Kirin Solution, Shanghai, China', 'Huawei Technologies, Edmonton, Alberta, Canada', 'Department of Electrical and Computer Engineering, University of Alberta', 'Huawei Technologies, Edmonton, Alberta, Canada', 'Huawei Technologies, Edmonton, Alberta, Canada', 'Huawei Kirin Solution, Shanghai, China', 'Department of Electrical and Computer Engineering, University of Alberta']","['ML: Auto ML and Hyperparameter Tuning', 'CV: Applications', 'ML: Applications', 'ML: Classification and Regression', 'ML: Graph-based Machine Learning', 'ML: Deep Neural Architectures']","Mills, K. G., Han, F. X., Zhang, J., Chudak, F., Safari Mamaghani, A., Salameh, M., Lu, W., Jui, S., & Niu, D. (2023). GENNAPE: Towards Generalized Neural Architecture Performance Estimators. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9190-9199. https://doi.org/10.1609/aaai.v37i8.26102","Abstract 					Predicting neural architecture performance is a challenging task and is crucial to neural architecture design and search. Existing approaches either rely on neural performance predictors which are limited to modeling architectures in a predefined design space involving specific sets of operators and connection rules, and cannot generalize to unseen architectures, or resort to Zero-Cost Proxies which are not always accurate. In this paper, we propose GENNAPE, a Generalized Neural Architecture Performance Estimator, which is pretrained on open neural architecture benchmarks, and aims to generalize to completely unseen architectures through combined innovations in network representation, contrastive pretraining, and a fuzzy clustering-based predictor ensemble. Specifically, GENNAPE represents a given neural network as a Computation Graph (CG) of atomic operations which can model an arbitrary architecture. It first learns a graph encoder via Contrastive Learning to encourage network separation by topological features, and then trains multiple predictor heads, which are soft-aggregated according to the fuzzy membership of a neural network. Experiments show that GENNAPE pretrained on NAS-Bench-101 can achieve superior transferability to 5 different public neural network benchmarks, including NAS-Bench-201, NAS-Bench-301, MobileNet and ResNet families under no or minimum fine-tuning. We further introduce 3 challenging newly labelled neural network benchmarks: HiAML, Inception and Two-Path, which can concentrate in narrow accuracy ranges. Extensive experiments show that GENNAPE can correctly discern high-performance architectures in these families. Finally, when paired with a search algorithm, GENNAPE can find architectures that improve accuracy while reducing FLOPs on three families.","https://ojs.aaai.org/index.php/AAAI/article/view/26102/25874"
"26103","Adaptive Perturbation-Based Gradient Estimation for Discrete Latent Variable Models","['Pasquale Minervini', 'Luca Franceschi', 'Mathias Niepert']","['University of Edinburgh\nUniversity College London', 'University College London', 'University of Stuttgart']","['ML: Deep Neural Network Algorithms', 'ML: Optimization']","Minervini, P., Franceschi, L., & Niepert, M. (2023). Adaptive Perturbation-Based Gradient Estimation for Discrete Latent Variable Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9200-9208. https://doi.org/10.1609/aaai.v37i8.26103","Abstract 					The integration of discrete algorithmic components in deep learning architectures has numerous applications. Recently, Implicit Maximum Likelihood Estimation, a class of gradient estimators for discrete exponential family distributions, was proposed by combining implicit differentiation through perturbation with the path-wise gradient estimator. However, due to the finite difference approximation of the gradients, it is especially sensitive to the choice of the finite difference step size, which needs to be specified by the user. In this work, we present Adaptive IMLE (AIMLE), the first adaptive gradient estimator for complex discrete distributions: it adaptively identifies the target distribution for IMLE by trading off the density of gradient information with the degree of bias in the gradient estimates. We empirically evaluate our estimator on synthetic examples, as well as on Learning to Explain, Discrete Variational Auto-Encoders, and Neural Relational Inference tasks. In our experiments, we show that our adaptive gradient estimator can produce faithful estimates while requiring orders of magnitude fewer samples than other gradient estimators.","https://ojs.aaai.org/index.php/AAAI/article/view/26103/25875"
"26104","Why Capsule Neural Networks Do Not Scale: Challenging the Dynamic Parse-Tree Assumption","['Matthias Mitterreiter', 'Marcel Koch', 'Joachim Giesen', 'Sören Laue']","['Friedrich-Schiller-University, Jena, Germany\nData Assessment Solutions GmbH, Hannover, Germany', 'Ernst Abbe University of Applied Sciences, Jena, Germany', 'Friedrich-Schiller-University, Jena, Germany', 'Technical University Kaiserslautern, Germany']","['ML: Representation Learning', 'CV: Representation Learning for Vision', 'ML: Deep Neural Architectures', 'ML: Scalability of ML Systems']","Mitterreiter, M., Koch, M., Giesen, J., & Laue, S. (2023). Why Capsule Neural Networks Do Not Scale: Challenging the Dynamic Parse-Tree Assumption. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9209-9216. https://doi.org/10.1609/aaai.v37i8.26104","Abstract 					Capsule neural networks replace simple, scalar-valued neurons with vector-valued capsules. They are motivated by the pattern recognition system in the human brain, where complex objects are decomposed into a hierarchy of simpler object parts. Such a hierarchy is referred to as a parse-tree. Conceptually, capsule neural networks have been defined to mimic this behavior. The capsule neural network (CapsNet), by Sabour, Frosst, and Hinton, is the first actual implementation of the conceptual idea of capsule neural networks. CapsNets achieved state-of-the-art performance on simple image recognition tasks with fewer parameters and greater robustness to affine transformations than comparable approaches. This sparked extensive follow-up research. However, despite major efforts, no work was able to scale the CapsNet architecture to more reasonable-sized datasets. Here, we provide a reason for this failure and argue that it is most likely not possible to scale CapsNets beyond toy examples. In particular, we show that the concept of a parse-tree, the main idea behind capsule neuronal networks, is not present in CapsNets. We also show theoretically and experimentally that CapsNets suffer from a vanishing gradient problem that results in the starvation of many capsules during training.","https://ojs.aaai.org/index.php/AAAI/article/view/26104/25876"
"26105","Multiplex Graph Representation Learning via Common and Private Information Mining","['Yujie Mo', 'Zongqian Wu', 'Yuhuan Chen', 'Xiaoshuang Shi', 'Heng Tao Shen', 'Xiaofeng Zhu']","['School of Computer Science and Engineering, University of Electronic Science and Technology of China', 'Guangxi Key Lab of Multi-Source Information Mining and Security, Guangxi Normal University', 'School of Computer Science and Engineering, University of Electronic Science and Technology of China', 'School of Computer Science and Engineering, University of Electronic Science and Technology of China', 'School of Computer Science and Engineering, University of Electronic Science and Technology of China\nPeng Cheng Laboratory', 'School of Computer Science and Engineering, University of Electronic Science and Technology of China\nShenzhen Institute for Advanced Study, University of Electronic Science and Technology of China']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning']","Mo, Y., Wu, Z., Chen, Y., Shi, X., Shen, H. T., & Zhu, X. (2023). Multiplex Graph Representation Learning via Common and Private Information Mining. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9217-9225. https://doi.org/10.1609/aaai.v37i8.26105","Abstract 					Self-supervised multiplex graph representation learning (SMGRL) has attracted increasing interest, but previous SMGRL methods still suffer from the following issues: (i) they focus on the common information only (but ignore the private information in graph structures) to lose some essential characteristics related to downstream tasks, and (ii) they ignore the redundant information in node representations of each graph. To solve these issues, this paper proposes a new SMGRL method by jointly mining the common information and the private information in the multiplex graph while minimizing the redundant information within node representations. Specifically, the proposed method investigates the decorrelation losses to extract the common information and minimize the redundant information, while investigating the reconstruction losses to maintain the private information. Comprehensive experimental results verify the superiority of the proposed method, on four public benchmark datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26105/25877"
"26106","Fundamentals of Task-Agnostic Data Valuation","['Mohammad Mohammadi Amiri', 'Frederic Berdoz', 'Ramesh Raskar']","['T Massachusetts Institute of Technology', 'Ecole polytechnique federale de Lausanne', 'Massachusetts Institute of Technology']","['ML: Distributed Machine Learning & Federated Learning', 'GTEP: Auctions and Market-Based Systems', 'GTEP: Applications', 'ML: Learning on the Edge & Model Compression']","Mohammadi Amiri, M., Berdoz, F., & Raskar, R. (2023). Fundamentals of Task-Agnostic Data Valuation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9226-9234. https://doi.org/10.1609/aaai.v37i8.26106","Abstract 					We study valuing the data of a data owner/seller for a data seeker/buyer. Data valuation is often carried out for a specific task assuming a particular utility metric, such as test accuracy on a validation set, that may not exist in practice. In this work, we focus on task-agnostic data valuation without any validation requirements. The data buyer has access to a limited amount of data (which could be publicly available) and seeks more data samples from a data seller. We formulate the problem as estimating the differences in the statistical properties of the data at the seller with respect to the baseline data available at the buyer. We capture these statistical differences through second moment by measuring diversity and relevance of the seller’s data for the buyer; we estimate these measures through queries to the seller without requesting the raw data. We design the queries with the proposed approach so that the seller is blind to the buyer’s raw data and has no knowledge to fabricate responses to the queries to obtain a desired outcome of the diversity and relevance trade-off. We will show through extensive experiments on real tabular and image datasets that the proposed estimates capture the diversity and relevance of the seller’s data for the buyer.","https://ojs.aaai.org/index.php/AAAI/article/view/26106/25878"
"26107","Exploring the Interaction between Local and Global Latent Configurations for Clustering Single-Cell RNA-Seq: A Unified Perspective","['Nairouz Mrabah', 'Mohamed Mahmoud Amar', 'Mohamed Bouguessa', 'Abdoulaye Banire Diallo']","['University of Quebec at Montreal, Montreal, Quebec, Canada', 'University of Quebec at Montreal, Montreal, Quebec, Canada', 'University of Quebec at Montreal, Montreal, Quebec, Canada', 'University of Quebec at Montreal, Montreal, Quebec, Canada']","['ML: Applications', 'ML: Unsupervised & Self-Supervised Learning']","Mrabah, N., Amar, M. M., Bouguessa, M., & Diallo, A. B. (2023). Exploring the Interaction between Local and Global Latent Configurations for Clustering Single-Cell RNA-Seq: A Unified Perspective. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9235-9242. https://doi.org/10.1609/aaai.v37i8.26107","Abstract 					The most recent approaches for clustering single-cell RNA-sequencing data rely on deep auto-encoders. However, three major challenges remain unaddressed. First, current models overlook the impact of the cumulative errors induced by the pseudo-supervised embedding clustering task (Feature Randomness). Second, existing methods neglect the effect of the strong competition between embedding clustering and reconstruction (Feature Drift). Third, the previous deep clustering models regularly fail to consider the topological information of the latent data, even though the local and global latent configurations can bring complementary views to the clustering task. To address these challenges, we propose a novel approach that explores the interaction between local and global latent configurations to progressively adjust the reconstruction and embedding clustering tasks. We elaborate a topological and probabilistic filter to mitigate Feature Randomness and a cell-cell graph structure and content correction mechanism to counteract Feature Drift. The Zero-Inflated Negative Binomial model is also integrated to capture the characteristics of gene expression profiles. We conduct detailed experiments on real-world datasets from multiple representative genome sequencing platforms. Our approach outperforms the state-of-the-art clustering methods in various evaluation metrics.","https://ojs.aaai.org/index.php/AAAI/article/view/26107/25879"
"26108","Corruption-Tolerant Algorithms for Generalized Linear Models","['Bhaskar Mukhoty', 'Debojyoti Dey', 'Purushottam Kar']","['Mohamed Bin Zayed University of Artificial Intelligence, Abu Dhabi, UAE', 'Indian Institute of Technology Kanpur, Uttar Pradesh, India', 'Indian Institute of Technology Kanpur, Uttar Pradesh, India']","['ML: Learning Theory', 'ML: Adversarial Learning & Robustness', 'ML: Classification and Regression', 'ML: Optimization']","Mukhoty, B., Dey, D., & Kar, P. (2023). Corruption-Tolerant Algorithms for Generalized Linear Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9243-9250. https://doi.org/10.1609/aaai.v37i8.26108","Abstract 					This paper presents SVAM (Sequential Variance-Altered MLE), a unified framework for learning generalized linear models under adversarial label corruption in training data. SVAM extends to tasks such as least squares regression, logistic regression, and gamma regression, whereas many existing works on learning with label corruptions focus only on least squares regression. SVAM is based on a novel variance reduction technique that may be of independent interest and works by iteratively solving weighted MLEs over variance-altered versions of the GLM objective. SVAM offers provable model recovery guarantees superior to the state-of-the-art for robust regression even when a constant fraction of training labels are adversarially corrupted. SVAM also empirically outperforms several existing problem-specific techniques for robust regression and classification. Code for SVAM is available at https://github.com/purushottamkar/svam/","https://ojs.aaai.org/index.php/AAAI/article/view/26108/25880"
"26109","Provably Efficient Causal Model-Based Reinforcement Learning for Systematic Generalization","['Mirco Mutti', 'Riccardo De Santi', 'Emanuele Rossi', 'Juan Felipe Calderon', 'Michael Bronstein', 'Marcello Restelli']","['Politecnico di Milano\nUniversità di Bologna', 'ETH Zurich', 'Imperial College London\nTwitter', 'Politecnico di Milano', 'University of Oxford\nTwitter', 'Politecnico di Milano']","['ML: Reinforcement Learning Theory', 'ML: Causal Learning']","Mutti, M., De Santi, R., Rossi, E., Calderon, J. F., Bronstein, M., & Restelli, M. (2023). Provably Efficient Causal Model-Based Reinforcement Learning for Systematic Generalization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9251-9259. https://doi.org/10.1609/aaai.v37i8.26109","Abstract 					In the sequential decision making setting, an agent aims to achieve systematic generalization over a large, possibly infinite, set of environments. Such environments are modeled as discrete Markov decision processes with both states and actions represented through a feature vector. The underlying structure of the environments allows the transition dynamics to be factored into two components: one that is environment-specific and another that is shared. Consider a set of environments that share the laws of motion as an example. In this setting, the agent can take a finite amount of reward-free interactions from a subset of these environments. The agent then must be able to approximately solve any planning task defined over any environment in the original set, relying on the above interactions only. Can we design a provably efficient algorithm that achieves this ambitious goal of systematic generalization? In this paper, we give a partially positive answer to this question. First, we provide a tractable formulation of systematic generalization by employing a causal viewpoint. Then, under specific structural assumptions, we provide a simple learning algorithm that guarantees any desired planning error up to an unavoidable sub-optimality term, while showcasing a polynomial sample complexity.","https://ojs.aaai.org/index.php/AAAI/article/view/26109/25881"
"26110","Mean Estimation of Truncated Mixtures of Two Gaussians: A Gradient Based Approach","['Sai Ganesh Nagarajan', 'Gerasimos Palaiopanos', 'Ioannis Panageas', 'Tushar Vaidya', 'Samson Yu']","['EPFL', 'University of Pittsburgh', 'University of California, Irvine', 'NTU', 'NUS']","['ML: Learning Theory', 'ML: Optimization']","Nagarajan, S. G., Palaiopanos, G., Panageas, I., Vaidya, T., & Yu, S. (2023). Mean Estimation of Truncated Mixtures of Two Gaussians: A Gradient Based Approach. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9260-9267. https://doi.org/10.1609/aaai.v37i8.26110","Abstract 					Even though data is abundant, it is often subjected to some form of censoring or truncation which inherently creates biases. Removing such biases and performing parameter estimation is a classical challenge in Statistics. In this paper, we focus on the problem of estimating the means of a mixture of two balanced d-dimensional Gaussians when the samples are prone to truncation. A recent theoretical study on the performance of the Expectation-Maximization (EM) algorithm for the aforementioned problem showed EM almost surely converges for d=1 and exhibits local convergence for d>1 to the true means. Nevertheless, the EM algorithm for the case of truncated mixture of two Gaussians is not easy to implement as it requires solving a set of nonlinear equations at every iteration which makes the algorithm impractical. In this work, we propose a gradient based variant of the EM algorithm that has global convergence guarantees when d=1 and local convergence for d>1 to the true means. Moreover, the update rule at every iteration is easy to compute which makes the proposed method practical. We also provide numerous experiments to obtain more insights into the effect of truncation on the convergence to the true parameters in high dimensions.","https://ojs.aaai.org/index.php/AAAI/article/view/26110/25882"
"26111","An Operator Theoretic Approach for Analyzing Sequence Neural Networks","['Ilan Naiman', 'Omri Azencot']","['Ben Gurion University', 'Ben Gurion University']","['ML: Evaluation and Analysis (Machine Learning)', 'ML: Time-Series/Data Streams']","Naiman, I., & Azencot, O. (2023). An Operator Theoretic Approach for Analyzing Sequence Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9268-9276. https://doi.org/10.1609/aaai.v37i8.26111","Abstract 					Analyzing the inner mechanisms of deep neural networks is a fundamental task in machine learning. Existing work provides limited analysis or it depends on local theories, such as fixed-point analysis. In contrast, we propose to analyze trained neural networks using an operator theoretic approach which is rooted in Koopman theory, the Koopman Analysis of Neural Networks (KANN). Key to our method is the Koopman operator, which is a linear object that globally represents the dominant behavior of the network dynamics. The linearity of the Koopman operator facilitates analysis via its eigenvectors and eigenvalues. Our method reveals that the latter eigendecomposition holds semantic information related to the neural network inner workings. For instance,  the eigenvectors highlight positive and negative n-grams in the sentiments analysis task; similarly, the eigenvectors capture the salient features of healthy heart beat signals in the ECG classification problem.","https://ojs.aaai.org/index.php/AAAI/article/view/26111/25883"
"26112","Do Invariances in Deep Neural Networks Align with Human Perception?","['Vedant Nanda', 'Ayan Majumdar', 'Camila Kolling', 'John P. Dickerson', 'Krishna P. Gummadi', 'Bradley C. Love', 'Adrian Weller']","['University of Maryland, College Park\nMax Planck Institute for Software Systems (MPI-SWS)', 'Max Planck Institute for Software Systems (MPI-SWS)', 'Max Planck Institue for Software Systems (MPI-SWS)', 'University of Maryland, College Park', 'Max Planck Institue for Software Systems (MPI-SWS)', 'University College London\nThe Alan Turing Institute', 'University of Cambridge\nThe Alan Turing Institute']","['ML: Evaluation and Analysis (Machine Learning)', 'ML: Representation Learning', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'PEAI: Safety', 'Robustness & Trustworthiness']","Nanda, V., Majumdar, A., Kolling, C., Dickerson, J. P., Gummadi, K. P., Love, B. C., & Weller, A. (2023). Do Invariances in Deep Neural Networks Align with Human Perception?. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9277-9285. https://doi.org/10.1609/aaai.v37i8.26112","Abstract 					An evaluation criterion for safe and trustworthy deep learning is how well the invariances captured by representations of deep neural networks (DNNs) are shared with humans. We identify challenges in measuring these invariances. Prior works used gradient-based methods to generate identically represented inputs (IRIs), ie, inputs which have identical representations (on a given layer) of a neural network, and thus capture invariances of a given network. One necessary criterion for a network's invariances to align with human perception is for its IRIs look 'similar' to humans. Prior works, however, have mixed takeaways; some argue that later layers of DNNs do not learn human-like invariances yet others seem to indicate otherwise. We argue that the loss function used to generate IRIs can heavily affect takeaways about invariances of the network and is the primary reason for these conflicting findings. We propose an adversarial regularizer on the IRI generation loss that finds IRIs that make any model appear to have very little shared invariance with humans. Based on this evidence, we argue that there is scope for improving models to have human-like invariances, and further, to have meaningful comparisons between models one should use IRIs generated using the regularizer-free loss. We then conduct an in-depth investigation of how different components (eg architectures, training losses, data augmentations) of the deep learning pipeline contribute to learning models that have good alignment with humans. We find that architectures with residual connections trained using a (self-supervised) contrastive loss with l_p ball adversarial data augmentation tend to learn invariances that are most aligned with humans. Code: github.com/nvedant07/Human-NN-Alignment","https://ojs.aaai.org/index.php/AAAI/article/view/26112/25884"
"26113","Counterfactual Learning with General Data-Generating Policies","['Yusuke Narita', 'Kyohei Okumura', 'Akihiro Shimizu', 'Kohei Yata']","['Yale University', 'Northwestern University', 'Mercari, Inc.,', 'University of Wisconsin-Madison']","['ML: Reinforcement Learning Theory', 'APP: Business/Marketing/Advertising/E-Commerce', 'ML: Causal Learning', 'ML: Online Learning & Bandits', 'ML: Reinforcement Learning Algorithms']","Narita, Y., Okumura, K., Shimizu, A., & Yata, K. (2023). Counterfactual Learning with General Data-Generating Policies. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9286-9293. https://doi.org/10.1609/aaai.v37i8.26113","Abstract 					Off-policy evaluation (OPE) attempts to predict the performance of counterfactual policies using log data from a different policy. We extend its applicability by developing an OPE method for a class of both full support and deficient support logging policies in contextual-bandit settings. This class includes deterministic bandit (such as Upper Confidence Bound) as well as deterministic decision-making based on supervised and unsupervised learning. We prove that our method's prediction converges in probability to the true performance of a counterfactual policy as the sample size increases. We validate our method with experiments on partly and entirely deterministic logging policies. Finally, we apply it to evaluate coupon targeting policies by a major online platform and show how to improve the existing policy.","https://ojs.aaai.org/index.php/AAAI/article/view/26113/25885"
"26114","Efficient and Accurate Learning of Mixtures of Plackett-Luce Models","['Duc Nguyen', 'Anderson Y. Zhang']","['University of Pennsylvania', 'University of Pennsylvania']","['ML: Learning Preferences or Rankings', 'HAI: Crowdsourcing', 'KRR: Preferences', 'ML: Clustering', 'ML: Multimodal Learning']","Nguyen, D., & Zhang, A. Y. (2023). Efficient and Accurate Learning of Mixtures of Plackett-Luce Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9294-9301. https://doi.org/10.1609/aaai.v37i8.26114","Abstract 					Mixture models of Plackett-Luce (PL), one of the most fundamental ranking models, are an active research area of both theoretical and practical significance. Most previously proposed parameter estimation algorithms instantiate the EM algorithm, often with random initialization. However, such an initialization scheme may not yield a good initial estimate and the algorithms require multiple restarts, incurring a large time complexity. As for the EM procedure, while the E-step can be performed efficiently, maximizing the log-likelihood in the M-step is difficult due to the combinatorial nature of the PL likelihood function. Therefore, previous authors favor algorithms that maximize surrogate likelihood functions. However, the final estimate may deviate from the true maximum likelihood estimate as a consequence. In this paper, we address these known limitations. We propose an initialization algorithm that can provide a provably accurate initial estimate and an EM algorithm that maximizes the true log-likelihood function efficiently. Experiments on both synthetic and real datasets show that our algorithm is competitive in terms of accuracy and speed to baseline algorithms, especially on datasets with a large number of items.","https://ojs.aaai.org/index.php/AAAI/article/view/26114/25886"
"26115","Behavioral Learning in Security Games: Threat of Multi-Step Manipulative Attacks","['Thanh H. Nguyen', 'Arunesh Sinha']","['University of Oregon', 'Rutgers University']","['ML: Adversarial Learning & Robustness']","Nguyen, T. H., & Sinha, A. (2023). Behavioral Learning in Security Games: Threat of Multi-Step Manipulative Attacks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9302-9309. https://doi.org/10.1609/aaai.v37i8.26115","Abstract 					This paper studies the problem of multi-step manipulative attacks in Stackelberg security games, in which a clever attacker attempts to orchestrate its attacks over multiple time steps to mislead the defender's learning of the attacker's behavior. This attack manipulation eventually influences the defender's patrol strategy towards the attacker's benefit. Previous work along this line of research only focuses on one-shot games in which the defender learns the attacker's behavior and then designs a corresponding strategy only once. Our work, on the other hand, investigates the long-term impact of the attacker's manipulation in which current attack and defense choices of players determine the future learning and patrol planning of the defender. This paper has three key contributions. First, we introduce a new multi-step manipulative attack game model that captures the impact of sequential manipulative attacks carried out by the attacker over the entire time horizon. Second, we propose a new algorithm to compute an optimal manipulative attack plan for the attacker, which tackles the challenge of multiple connected optimization components involved in the computation across multiple time steps. Finally, we present extensive experimental results on the impact of such misleading attacks, showing a significant benefit for the attacker and loss for the defender.","https://ojs.aaai.org/index.php/AAAI/article/view/26115/25887"
"26116","On Instance-Dependent Bounds for Offline Reinforcement Learning with Linear Function Approximation","['Thanh Nguyen-Tang', 'Ming Yin', 'Sunil Gupta', 'Svetha Venkatesh', 'Raman Arora']","['Johns Hopkins University', 'UC Santa Barbara', 'Deakin University, Australia', 'Deakin University, Australia', 'Johns Hopkins University']","['ML: Reinforcement Learning Theory']","Nguyen-Tang, T., Yin, M., Gupta, S., Venkatesh, S., & Arora, R. (2023). On Instance-Dependent Bounds for Offline Reinforcement Learning with Linear Function Approximation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9310-9318. https://doi.org/10.1609/aaai.v37i8.26116","Abstract 					Sample-efficient offline reinforcement learning (RL) with linear function approximation has been studied extensively recently. Much of the prior work has yielded instance-independent rates that hold even for the worst-case realization of problem instances. This work seeks to understand instance-dependent bounds for offline RL with linear function approximation. We present an algorithm called Bootstrapped and Constrained Pessimistic Value Iteration (BCP-VI), which leverages data bootstrapping and constrained optimization on top of pessimism. We show that under a partial data coverage assumption, that of concentrability with respect to an optimal policy, the proposed algorithm yields a fast rate for offline RL when there is a positive gap in the optimal Q-value functions, even if the offline data were collected adaptively. Moreover, when the linear features of the optimal actions in the states reachable by an optimal policy span those reachable by the behavior policy and the optimal actions are unique, offline RL achieves absolute zero sub-optimality error when the number of episodes exceeds a  (finite) instance-dependent threshold. To the best of our knowledge, these are the first results that give a fast rate bound on the sub-optimality and an absolute zero sub-optimality bound for offline RL with linear function approximation from adaptive data with partial coverage. We also provide instance-agnostic and instance-dependent information-theoretical lower bounds to complement our upper bounds.","https://ojs.aaai.org/index.php/AAAI/article/view/26116/25888"
"26117","Fast Saturating Gate for Learning Long Time Scales with Recurrent Neural Networks","['Kentaro Ohno', 'Sekitoshi Kanai', 'Yasutoshi Ida']","['NTT', 'NTT', 'NTT']","['ML: Deep Neural Architectures', 'ML: Deep Learning Theory', 'ML: Deep Neural Network Algorithms', 'ML: Time-Series/Data Streams']","Ohno, K., Kanai, S., & Ida, Y. (2023). Fast Saturating Gate for Learning Long Time Scales with Recurrent Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9319-9326. https://doi.org/10.1609/aaai.v37i8.26117","Abstract 					Gate functions in recurrent models, such as an LSTM and GRU, play a central role in learning various time scales in modeling time series data by using a bounded activation function. However, it is difficult to train gates to capture extremely long time scales due to gradient vanishing of the bounded function for large inputs, which is known as the saturation problem. We closely analyze the relation between saturation of the gate function and efficiency of the training. We prove that the gradient vanishing of the gate function can be mitigated by accelerating the convergence of the saturating function, i.e., making the output of the function converge to 0 or 1 faster. Based on the analysis results, we propose a gate function called fast gate that has a doubly exponential convergence rate with respect to inputs by simple function composition. We empirically show that our method outperforms previous methods in accuracy and computational efficiency on benchmark tasks involving extremely long time scales.","https://ojs.aaai.org/index.php/AAAI/article/view/26117/25889"
"26118","Backpropagation-Free Deep Learning with Recursive Local Representation Alignment","['Alexander G. Ororbia', 'Ankur Mali', 'Daniel Kifer', 'C. Lee Giles']","['Rochester Institute of Techonology', 'University of South Florida', 'The Pennsylvania State University', 'The Pennsylvania State University']","['ML: Bio-Inspired Learning', 'ML: Optimization', 'ML: Deep Neural Network Algorithms']","Ororbia, A. G., Mali, A., Kifer, D., & Giles, C. L. (2023). Backpropagation-Free Deep Learning with Recursive Local Representation Alignment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9327-9335. https://doi.org/10.1609/aaai.v37i8.26118","Abstract 					Training deep neural networks on large-scale datasets requires significant hardware resources whose costs (even on cloud platforms) put them out of reach of smaller organizations, groups, and individuals. Backpropagation (backprop), the workhorse for training these networks, is an inherently sequential process that is difficult to parallelize. Furthermore, researchers must continually develop various specialized techniques, such as particular weight initializations and enhanced activation functions, to ensure stable parameter optimization. Our goal is to seek an effective, neuro-biologically plausible alternative to backprop that can be used to train deep networks. In this paper, we propose a backprop-free procedure, recursive local representation alignment, for training large-scale architectures. Experiments with residual networks on CIFAR-10 and the large benchmark, ImageNet, show that our algorithm generalizes as well as backprop while converging sooner due to weight updates that are parallelizable and computationally less demanding. This is empirical evidence that a backprop-free algorithm can scale up to larger datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26118/25890"
"26119","Bilinear Exponential Family of MDPs: Frequentist Regret Bound with Tractable Exploration & Planning","['Reda Ouhamma', 'Debabrota Basu', 'Odalric Maillard']","['Univ. Lille, CNRS, Inria, Centrale Lille, UMR 9189 - CRIStAL, F-59000', 'Univ. Lille, CNRS, Inria, Centrale Lille, UMR 9189 - CRIStAL, F-59000', 'Univ. Lille, CNRS, Inria, Centrale Lille, UMR 9189 - CRIStAL, F-59000']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms']","Ouhamma, R., Basu, D., & Maillard, O. (2023). Bilinear Exponential Family of MDPs: Frequentist Regret Bound with Tractable Exploration & Planning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9336-9344. https://doi.org/10.1609/aaai.v37i8.26119","Abstract 					We study the problem of episodic reinforcement learning in continuous state-action spaces with unknown rewards and transitions. Specifically, we consider the setting where the rewards and transitions are modeled using parametric bilinear exponential families. We propose an algorithm, that a) uses penalized maximum likelihood estimators to learn the unknown parameters, b) injects a calibrated Gaussian noise in the parameter of rewards to ensure exploration, and c) leverages linearity of the bilinear exponential family transitions with respect to an underlying RKHS to perform tractable planning. We provide a frequentist regret upper-bound for our algorithm which, in the case of tabular MDPs, is order-optimal with respect to H and K, where H is the episode length and K is the number of episodes. Our analysis improves the existing bounds for the bilinear exponential family of MDPs by square root of H and removes the handcrafted clipping deployed in existing RLSVI-type algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26119/25891"
"26120","H-TSP: Hierarchically Solving the Large-Scale Traveling Salesman Problem","['Xuanhao Pan', 'Yan Jin', 'Yuandong Ding', 'Mingxiao Feng', 'Li Zhao', 'Lei Song', 'Jiang Bian']","['Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'Huazhong University of Science and Technology', 'University of Science and Technology of China', 'Microsoft Research', 'Microsoft Research', 'Microsoft Research']","['ML: Reinforcement Learning Algorithms']","Pan, X., Jin, Y., Ding, Y., Feng, M., Zhao, L., Song, L., & Bian, J. (2023). H-TSP: Hierarchically Solving the Large-Scale Traveling Salesman Problem. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9345-9353. https://doi.org/10.1609/aaai.v37i8.26120","Abstract 					We propose an end-to-end learning framework based on hierarchical reinforcement learning, called H-TSP, for addressing the large-scale Traveling Salesman Problem (TSP). The proposed H-TSP constructs a solution of a TSP instance starting from the scratch relying on two components: the upper-level policy chooses a small subset of nodes (up to 200 in our experiment) from all nodes that are to be traversed, while the lower-level policy takes the chosen nodes as input and outputs a tour connecting them to the existing partial route (initially only containing the depot). After jointly training the upper-level and lower-level policies, our approach can directly generate solutions for the given TSP instances without relying on any time-consuming search procedures. To demonstrate effectiveness of the proposed approach, we have conducted extensive experiments on randomly generated TSP instances with different numbers of nodes. We show that H-TSP can achieve comparable results (gap 3.42% vs. 7.32%) as SOTA search-based approaches, and more importantly, we reduce the time consumption up to two orders of magnitude (3.32s vs. 395.85s). To the best of our knowledge, H-TSP is the first end-to-end deep reinforcement learning approach that can scale to TSP instances of up to 10000 nodes. Although there are still gaps to SOTA results with respect to solution quality, we believe that H-TSP will be useful for practical applications, particularly those that are time-sensitive e.g., on-call routing and ride hailing service.","https://ojs.aaai.org/index.php/AAAI/article/view/26120/25892"
"26121","Ising-Traffic: Using Ising Machine Learning to Predict Traffic Congestion under Uncertainty","['Zhenyu Pan', 'Anshujit Sharma', 'Jerry Yao-Chieh Hu', 'Zhuo Liu', 'Ang Li', 'Han Liu', 'Michael Huang', 'Tony Geng']","['University of Rochester', 'University of Rochester', 'Northwestern University', 'University of Rochester', 'Pacific Northwest National Laboratory', 'Northwestern University', 'University of Rochester', 'University of Rochester']","['ML: Classification and Regression', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'ML: Graph-based Machine Learning', 'ML: Time-Series/Data Streams']","Pan, Z., Sharma, A., Hu, J. Y.-C., Liu, Z., Li, A., Liu, H., Huang, M., & Geng, T. (2023). Ising-Traffic: Using Ising Machine Learning to Predict Traffic Congestion under Uncertainty. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9354-9363. https://doi.org/10.1609/aaai.v37i8.26121","Abstract 					This paper addresses the challenges in accurate and real-time traffic congestion prediction under uncertainty by proposing Ising-Traffic, a dual-model Ising-based traffic prediction framework that delivers higher accuracy and lower latency than SOTA solutions. While traditional solutions face the dilemma from the trade-off between algorithm complexity and computational efficiency, our Ising-based method breaks away from the trade-off leveraging the Ising model's strong expressivity and the Ising machine's strong computation power. In particular, Ising-Traffic formulates traffic prediction under uncertainty into two Ising models: Reconstruct-Ising and Predict-Ising. Reconstruct-Ising is mapped onto modern Ising machines and handles uncertainty in traffic accurately with negligible latency and energy consumption, while Predict-Ising is mapped onto traditional processors and predicts future congestion precisely with only at most 1.8% computational demands of existing solutions. Our evaluation shows Ising-Traffic delivers on average 98X speedups and 5% accuracy improvement over SOTA.","https://ojs.aaai.org/index.php/AAAI/article/view/26121/25893"
"26122","FedMDFG: Federated Learning with Multi-Gradient Descent and Fair Guidance","['Zibin Pan', 'Shuyi Wang', 'Chi Li', 'Haijin Wang', 'Xiaoying Tang', 'Junhua Zhao']","['The School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen\nThe Shenzhen Institute of Artificial Intelligence and Robotics for Society', 'The School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen\nThe Shenzhen Institute of Artificial Intelligence and Robotics for Society', 'The School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen', 'The School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen', 'The School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen\nThe Shenzhen Institute of Artificial Intelligence and Robotics for Society\nThe Guangdong Provincial Key Laboratory of Future Networks of Intelligence', 'The School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen\nThe Shenzhen Institute of Artificial Intelligence and Robotics for Society']","['ML: Distributed Machine Learning & Federated Learning', 'ML: Applications', 'ML: Bias and Fairness', 'PEAI: Bias', 'Fairness & Equity']","Pan, Z., Wang, S., Li, C., Wang, H., Tang, X., & Zhao, J. (2023). FedMDFG: Federated Learning with Multi-Gradient Descent and Fair Guidance. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9364-9371. https://doi.org/10.1609/aaai.v37i8.26122","Abstract 					Fairness has been considered as a critical problem in federated learning (FL). In this work, we analyze two direct causes of unfairness in FL - an unfair direction and an improper step size when updating the model. To solve these issues, we introduce an effective way to measure fairness of the model through the cosine similarity, and then propose a federated multiple gradient descent algorithm with fair guidance (FedMDFG) to drive the model fairer. We first convert FL into a multi-objective optimization problem (MOP) and design an advanced multiple gradient descent algorithm to calculate a fair descent direction by adding a fair-driven objective to MOP. A low-communication-cost line search strategy is then designed to find a better step size for the model update. We further show the theoretical analysis on how it can enhance fairness and guarantee the convergence. Finally, extensive experiments in several FL scenarios verify that FedMDFG is robust and outperforms the SOTA FL algorithms in convergence and fairness. The source code is available at https://github.com/zibinpan/FedMDFG.","https://ojs.aaai.org/index.php/AAAI/article/view/26122/25894"
"26123","Geometric Inductive Biases for Identifiable Unsupervised Learning of Disentangled Representations","['Ziqi Pan', 'Li Niu', 'Liqing Zhang']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['ML: Representation Learning', 'ML: Deep Generative Models & Autoencoders', 'ML: Other Foundations of Machine Learning', 'ML: Unsupervised & Self-Supervised Learning']","Pan, Z., Niu, L., & Zhang, L. (2023). Geometric Inductive Biases for Identifiable Unsupervised Learning of Disentangled Representations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9372-9380. https://doi.org/10.1609/aaai.v37i8.26123","Abstract 					The model identifiability is a considerable issue in the unsupervised learning of disentangled representations. The PCA inductive biases revealed recently for unsupervised disentangling in VAE-based models are shown to improve local alignment of latent dimensions with principal components of the data. In this paper, in additional to the PCA inductive biases, we propose novel geometric inductive biases from the manifold perspective for unsupervised disentangling, which induce the model to capture the global geometric properties of the data manifold with guaranteed model identifiability. We also propose a Geometric Disentangling Regularized AutoEncoder (GDRAE) that combines the PCA and the proposed geometric inductive biases in one unified framework. The experimental results show the usefulness of the geometric inductive biases in unsupervised disentangling and the effectiveness of our GDRAE in capturing the geometric inductive biases.","https://ojs.aaai.org/index.php/AAAI/article/view/26123/25895"
"26124","Isometric Manifold Learning Using Hierarchical Flow","['Ziqi Pan', 'Jianfu Zhang', 'Li Niu', 'Liqing Zhang']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['ML: Representation Learning', 'ML: Deep Generative Models & Autoencoders', 'ML: Other Foundations of Machine Learning', 'ML: Unsupervised & Self-Supervised Learning']","Pan, Z., Zhang, J., Niu, L., & Zhang, L. (2023). Isometric Manifold Learning Using Hierarchical Flow. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9381-9388. https://doi.org/10.1609/aaai.v37i8.26124","Abstract 					We propose the Hierarchical Flow (HF) model constrained by isometric regularizations for manifold learning that combines manifold learning goals such as dimensionality reduction, inference, sampling, projection and density estimation into one unified framework. Our proposed HF model is regularized to not only produce embeddings preserving the geometric structure of the manifold, but also project samples onto the manifold in a manner conforming to the rigorous definition of projection. Theoretical guarantees are provided for our HF model to satisfy the two desired properties. In order to detect the real dimensionality of the manifold, we also propose a two-stage dimensionality reduction algorithm, which is a time-efficient algorithm thanks to the hierarchical architecture design of our HF model. Experimental results justify our theoretical analysis, demonstrate the superiority of our dimensionality reduction algorithm in cost of training time, and verify the effect of the aforementioned properties in improving performances on downstream tasks such as anomaly detection.","https://ojs.aaai.org/index.php/AAAI/article/view/26124/25896"
"26125","Evidential Conditional Neural Processes","['Deep Shankar Pandey', 'Qi Yu']","['Rochester Institute of Technology', 'Rochester Institute of Technology']","['ML: Meta Learning']","Pandey, D. S., & Yu, Q. (2023). Evidential Conditional Neural Processes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9389-9397. https://doi.org/10.1609/aaai.v37i8.26125","Abstract 					The Conditional Neural Process (CNP) family of models offer a promising direction to tackle few-shot problems by achieving better scalability and competitive predictive performance. However, the current CNP models only capture the overall uncertainty for the prediction made on a target data point. They lack a systematic fine-grained quantification on the distinct sources of uncertainty that are essential for model training and decision-making under the few-shot setting. We propose Evidential Conditional Neural Processes (ECNP), which replace the standard Gaussian distribution used by CNP with a much richer hierarchical Bayesian structure through evidential learning to achieve epistemic-aleatoric uncertainty decomposition. The evidential hierarchical structure also leads to a theoretically justified robustness over noisy training tasks. Theoretical analysis on the proposed ECNP establishes the relationship with CNP while offering deeper insights on the roles of the evidential parameters. Extensive experiments conducted on both synthetic and real-world data demonstrate the effectiveness of our proposed model in various few-shot settings.","https://ojs.aaai.org/index.php/AAAI/article/view/26125/25897"
"26126","Balanced Column-Wise Block Pruning for Maximizing GPU Parallelism","['Cheonjun Park', 'Mincheol Park', 'Hyun Jae Oh', 'Minkyu Kim', 'Myung Kuk Yoon', 'Suhyun Kim', 'Won Woo Ro']","['Yonsei University', 'Yonsei University\nKorea Institute of Science and Technology', 'Memory Division, Samsung Electronics Co.', 'Yonsei University', 'Ewha Womans University', 'Korea Institute of Science and Technology', 'Yonsei University']","['ML: Learning on the Edge & Model Compression', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms']","Park, C., Park, M., Oh, H. J., Kim, M., Yoon, M. K., Kim, S., & Ro, W. W. (2023). Balanced Column-Wise Block Pruning for Maximizing GPU Parallelism. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9398-9407. https://doi.org/10.1609/aaai.v37i8.26126","Abstract 					Pruning has been an effective solution to reduce the number of computations and the memory requirement in deep learning. The pruning unit plays an important role in exploiting the GPU resources efficiently.  The filter is proposed as a simple pruning unit of structured pruning. However, since the filter is quite large as pruning unit, the accuracy drop is considerable with a high pruning ratio. GPU rearranges the weight and input tensors into tiles (blocks) for efficient computation.  To fully utilize GPU resources, this tile structure should be considered, which is the goal of block pruning.  However, previous block pruning prunes both row vectors and column vectors.  Pruning of row vectors in a tile corresponds to filter pruning, and it also interferes with column-wise block pruning of the following layer. In contrast, column vectors are much smaller than row vectors and can achieve lower accuracy drop. Additionally, if the pruning ratio for each tile is different, GPU utilization can be limited by imbalanced workloads by irregular-sized blocks. The same pruning ratio for the weight tiles processed in parallel enables the actual inference process to fully utilize the resources without idle time. This paper proposes balanced column-wise block pruning, named BCBP, to satisfy two conditions: the column-wise minimal size of the pruning unit and balanced workloads.  We demonstrate that BCBP is superior to previous pruning methods through comprehensive experiments.","https://ojs.aaai.org/index.php/AAAI/article/view/26126/25898"
"26127","Dynamic Structure Pruning for Compressing CNNs","['Jun-Hyung Park', 'Yeachan Kim', 'Junho Kim', 'Joon-Young Choi', 'SangKeun Lee']","['Korea University', 'Korea University', 'Korea Univeristy', 'Korea University', 'Korea University']","['ML: Learning on the Edge & Model Compression']","Park, J.-H., Kim, Y., Kim, J., Choi, J.-Y., & Lee, S. (2023). Dynamic Structure Pruning for Compressing CNNs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9408-9416. https://doi.org/10.1609/aaai.v37i8.26127","Abstract 					Structure pruning is an effective method to compress and accelerate neural networks. While filter and channel pruning are preferable to other structure pruning methods in terms of realistic acceleration and hardware compatibility, pruning methods with a finer granularity, such as intra-channel pruning, are expected to be capable of yielding more compact and computationally efficient networks. Typical intra-channel pruning methods utilize a static and hand-crafted pruning granularity due to a large search space, which leaves room for improvement in their pruning performance. In this work, we introduce a novel structure pruning method, termed as dynamic structure pruning, to identify optimal pruning granularities for intra-channel pruning. In contrast to existing intra-channel pruning methods, the proposed method automatically optimizes dynamic pruning granularities in each layer while training deep neural networks. To achieve this, we propose a differentiable group learning method designed to efficiently learn a pruning granularity based on gradient-based learning of filter groups. The experimental results show that dynamic structure pruning achieves state-of-the-art pruning performance and better realistic acceleration on a GPU compared with channel pruning. In particular, it reduces the FLOPs of ResNet50 by 71.85% without accuracy degradation on the ImageNet dataset. Our code is available at https://github.com/irishev/DSP.","https://ojs.aaai.org/index.php/AAAI/article/view/26127/25899"
"26128","Scaling Marginalized Importance Sampling to High-Dimensional State-Spaces via State Abstraction","['Brahma S. Pavse', 'Josiah P. Hanna']","['University of Wisconsin -- Madison', 'University of Wisconsin -- Madison']","['ML: Reinforcement Learning Algorithms']","Pavse, B. S., & Hanna, J. P. (2023). Scaling Marginalized Importance Sampling to High-Dimensional State-Spaces via State Abstraction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9417-9425. https://doi.org/10.1609/aaai.v37i8.26128","Abstract 					We consider the problem of off-policy evaluation (OPE) in reinforcement learning (RL), where the goal is to estimate the performance of an evaluation policy, pie, using a fixed dataset, D, collected by one or more policies that may be different from pie. Current OPE algorithms may produce poor OPE estimates under policy distribution shift i.e., when the probability of a particular state-action pair occurring under pie is very different from the probability of that same pair occurring in D. In this work, we propose to improve the accuracy of OPE estimators by projecting the high-dimensional state-space into a low-dimensional state-space using concepts from the state abstraction literature. Specifically, we consider marginalized importance sampling (MIS) OPE algorithms which compute state-action distribution correction ratios to produce their OPE estimate. In the original ground state-space, these ratios may have high variance which may lead to high variance OPE. However, we prove that in the lower-dimensional abstract state-space the ratios can have lower variance resulting in lower variance OPE. We then highlight the challenges that arise when estimating the abstract ratios from data, identify sufficient conditions to overcome these issues, and present a minimax optimization problem whose solution yields these abstract ratios. Finally, our empirical evaluation on difficult, high-dimensional state-space OPE tasks shows that the abstract ratios can make MIS OPE estimators achieve lower mean-squared error and more robust to hyperparameter tuning than the ground ratios.","https://ojs.aaai.org/index.php/AAAI/article/view/26128/25900"
"26129","Conceptual Reinforcement Learning for Language-Conditioned Tasks","['Shaohui Peng', 'Xing Hu', 'Rui Zhang', 'Jiaming Guo', 'Qi Yi', 'Ruizhi Chen', 'Zidong Du', 'Ling Li', 'Qi Guo', 'Yunji Chen']","['SKL of Processors, Institute of Computing Technology, CAS; University of Chinese Academy of Sciences; Cambricon Technologies', 'SKL of Processors, Institute of Computing Technology, CAS', 'SKL of Processors, Institute of Computing Technology, CAS; Cambricon Technologies', 'SKL of Processors, Institute of Computing Technology, CAS; University of Chinese Academy of Sciences; Cambricon Technologies', 'SKL of Processors, Institute of Computing Technology, CAS; Cambricon Technologies; University of Science and Technology of China', 'University of Chinese Academy of Sciences; SKL of Computer Science, Institute of Software, CAS', 'SKL of Processors, Institute of Computing Technology, CAS; Cambricon Technologies', 'University of Chinese Academy of Sciences; SKL of Computer Science, Institute of Software, CAS', 'SKL of Processors, Institute of Computing Technology, CAS', 'SKL of Processors, Institute of Computing Technology, CAS; University of Chinese Academy of Sciences']","['ML: Reinforcement Learning Algorithms', 'ML: Multimodal Learning', 'ML: Representation Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Peng, S., Hu, X., Zhang, R., Guo, J., Yi, Q., Chen, R., Du, Z., Li, L., Guo, Q., & Chen, Y. (2023). Conceptual Reinforcement Learning for Language-Conditioned Tasks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9426-9434. https://doi.org/10.1609/aaai.v37i8.26129","Abstract 					Despite the broad application of deep reinforcement learning (RL), transferring and adapting the policy to unseen but similar environments is still a significant challenge. Recently, the language-conditioned policy is proposed to facilitate policy transfer through learning the joint representation of observation and text that catches the compact and invariant information across various environments. Existing studies of language-conditioned RL methods often learn the joint representation as a simple latent layer for the given instances (episode-specific observation and text), which inevitably includes noisy or irrelevant information and cause spurious correlations that are dependent on instances, thus hurting generalization performance and training efficiency. To address the above issue, we propose a conceptual reinforcement learning (CRL) framework to learn the concept-like joint representation for language-conditioned policy. The key insight is that concepts are compact and invariant representations in human cognition through extracting similarities from numerous instances in real-world. In CRL, we propose a multi-level attention encoder and two mutual information constraints for learning compact and invariant concepts. Verified in two challenging environments, RTFM and Messenger, CRL significantly improves the training efficiency (up to 70%) and generalization ability (up to 30%) to the new environment dynamics.","https://ojs.aaai.org/index.php/AAAI/article/view/26129/25901"
"26130","Weighted Policy Constraints for Offline Reinforcement Learning","['Zhiyong Peng', 'Changlin Han', 'Yadong Liu', 'Zongtan Zhou']","['National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology']","['ML: Reinforcement Learning Algorithms', 'ML: Imitation Learning & Inverse Reinforcement Learning', 'ML: Optimization', 'ML: Reinforcement Learning Theory', 'PRS: Planning With Markov Models (MDPs', 'POMDPs)']","Peng, Z., Han, C., Liu, Y., & Zhou, Z. (2023). Weighted Policy Constraints for Offline Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9435-9443. https://doi.org/10.1609/aaai.v37i8.26130","Abstract 					Offline reinforcement learning (RL) aims to learn policy from the passively collected offline dataset. Applying existing RL methods on the static dataset straightforwardly will raise distribution shift, causing these unconstrained RL methods to fail. To cope with the distribution shift problem, a common practice in offline RL is to constrain the policy explicitly or implicitly close to behavioral policy. However, the available dataset usually contains sub-optimal or inferior actions, constraining the policy near all these actions will make the policy inevitably learn inferior behaviors, limiting the performance of the algorithm. Based on this observation, we propose a weighted policy constraints (wPC) method that only constrains the learned policy to desirable behaviors, making room for policy improvement on other parts. Our algorithm outperforms existing state-of-the-art offline RL algorithms on the D4RL offline gym datasets. Moreover, the proposed algorithm is simple to implement with few hyper-parameters, making the proposed wPC algorithm a robust offline RL method with low computational complexity.","https://ojs.aaai.org/index.php/AAAI/article/view/26130/25902"
"26131","Latent Autoregressive Source Separation","['Emilian Postolache', 'Giorgio Mariani', 'Michele Mancusi', 'Andrea Santilli', 'Luca Cosmo', 'Emanuele Rodolà']","['Sapienza University of Rome, Italy', 'Sapienza University of Rome, Italy', 'Sapienza University of Rome, Italy', 'Sapienza University of Rome, Italy', 'Ca’ Foscari University of Venice, Italy\nUniversity of Lugano, Switzerland', 'Sapienza University of Rome, Italy']","['ML: Deep Generative Models & Autoencoders', 'ML: Applications', 'ML: Bayesian Learning', 'ML: Deep Neural Network Algorithms', 'ML: Dimensionality Reduction/Feature Selection', 'ML: Unsupervised & Self-Supervised Learning']","Postolache, E., Mariani, G., Mancusi, M., Santilli, A., Cosmo, L., & Rodolà, E. (2023). Latent Autoregressive Source Separation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9444-9452. https://doi.org/10.1609/aaai.v37i8.26131","Abstract 					Autoregressive models have achieved impressive results over a wide range of domains in terms of generation quality and downstream task performance. In the continuous domain, a key factor behind this success is the usage of quantized latent spaces (e.g., obtained via VQ-VAE autoencoders), which allow for dimensionality reduction and faster inference times. However, using existing pre-trained models to perform new non-trivial tasks is difficult since it requires additional fine-tuning or extensive training to elicit prompting. This paper introduces LASS as a way to perform vector-quantized Latent Autoregressive Source Separation (i.e., de-mixing an input signal into its constituent sources) without requiring additional gradient-based optimization or modifications of existing models. Our separation method relies on the Bayesian formulation in which the autoregressive models are the priors, and a discrete (non-parametric) likelihood function is constructed by performing frequency counts over latent sums of addend tokens. We test our method on images and audio with several sampling strategies (e.g., ancestral, beam search) showing competitive results with existing approaches in terms of separation quality while offering at the same time significant speedups in terms of inference time and scalability to higher dimensional data.","https://ojs.aaai.org/index.php/AAAI/article/view/26131/25903"
"26132","Explaining Random Forests Using Bipolar Argumentation and Markov Networks","['Nico Potyka', 'Xiang Yin', 'Francesca Toni']","['Imperial College London', 'Imperial College London', 'Imperial College London']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'KRR: Argumentation', 'PEAI: Interpretability and Explainability']","Potyka, N., Yin, X., & Toni, F. (2023). Explaining Random Forests Using Bipolar Argumentation and Markov Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9453-9460. https://doi.org/10.1609/aaai.v37i8.26132","Abstract 					Random forests are decision tree ensembles that can be used  to solve a variety of machine learning problems. However, as the number of trees and their individual size can be large, their decision making process is often incomprehensible. We show that their decision process can be naturally represented  as an argumentation problem, which allows creating global explanations  via argumentative reasoning. We generalize sufficient and necessary  argumentative explanations using a Markov network encoding, discuss  the relevance of these explanations and establish relationships to families of abductive explanations from the literature. As the complexity  of the explanation problems is high, we present an efficient approximation algorithm with probabilistic approximation guarantees.","https://ojs.aaai.org/index.php/AAAI/article/view/26132/25904"
"26133","A Model-Agnostic Heuristics for Selective Classification","['Andrea Pugnana', 'Salvatore Ruggieri']","['Scuola Normale Superiore, Pisa, IT', 'University of Pisa, Pisa, IT']","['ML: Classification and Regression', 'ML: Ensemble Methods', 'PEAI: Safety', 'Robustness & Trustworthiness', 'RU: Other Foundations of Reasoning Under Uncertainty']","Pugnana, A., & Ruggieri, S. (2023). A Model-Agnostic Heuristics for Selective Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9461-9469. https://doi.org/10.1609/aaai.v37i8.26133","Abstract 					Selective classification (also known as classification with reject option) conservatively extends a classifier with a selection function to determine whether or not a  prediction should be accepted (i.e., trusted, used, deployed). This is a highly relevant issue in socially sensitive tasks, such as credit scoring. State-of-the-art approaches rely on Deep Neural Networks (DNNs) that train at the same time both the classifier and the selection function. These approaches are model-specific and computationally expensive.  We propose a model-agnostic approach, as it can work with any base probabilistic binary classification algorithm, and it can be scalable to large tabular datasets if the base classifier is so. The proposed algorithm, called SCROSS, exploits a cross-fitting strategy and theoretical results for quantile estimation to build the selection function. Experiments on real-world data show that SCROSS improves over existing methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26133/25905"
"26134","Experimental Observations of the Topology of Convolutional Neural Network Activations","['Emilie Purvine', 'Davis Brown', 'Brett Jefferson', 'Cliff Joslyn', 'Brenda Praggastis', 'Archit Rathore', 'Madelyn Shapiro', 'Bei Wang', 'Youjia Zhou']","['Pacific Northwest National Laboratory', 'Pacific Northwest National Laboratory', 'Pacific Northwest National Laboratory', 'Pacific Northwest National Laboratory', 'Pacific Northwest National Laboratory', 'Scientific Computing and Imaging (SCI) Institute and School of Computing, University of Utah', 'Pacific Northwest National Laboratory', 'Scientific Computing and Imaging (SCI) Institute and School of Computing, University of Utah', 'Scientific Computing and Imaging (SCI) Institute and School of Computing, University of Utah']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'KRR: Other Foundations of Knowledge Representation & Reasoning', 'CV: Interpretability and Transparency', 'ML: Other Foundations of Machine Learning', 'CV: Other Foundations of Computer Vision', 'DMKM: Data Visualization & Summarization', 'ML: Evaluation and Analysis (Machine Learning)', 'ML: Clustering', 'ML: Deep Neural Network Algorithms']","Purvine, E., Brown, D., Jefferson, B., Joslyn, C., Praggastis, B., Rathore, A., Shapiro, M., Wang, B., & Zhou, Y. (2023). Experimental Observations of the Topology of Convolutional Neural Network Activations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9470-9479. https://doi.org/10.1609/aaai.v37i8.26134","Abstract 					Topological data analysis (TDA) is a branch of computational mathematics, bridging algebraic topology and data science, that provides compact, noise-robust representations of complex structures. Deep neural networks (DNNs) learn millions of parameters associated with a series of transformations defined by the model architecture resulting in high-dimensional, difficult to interpret internal representations of input data. As DNNs become more ubiquitous across multiple sectors of our society, there is increasing recognition that mathematical methods are needed to aid analysts, researchers, and practitioners in understanding and interpreting how these models' internal representations relate to the final classification. In this paper we apply cutting edge techniques from TDA with the goal of gaining insight towards interpretability of convolutional neural networks used for image classification. We use  two common TDA approaches to explore several methods for modeling hidden layer activations as high-dimensional point clouds, and provide experimental evidence that these point clouds capture valuable structural information about the model's process. First, we demonstrate that a distance metric based on persistent homology can be used to quantify meaningful differences between layers and discuss these distances in the broader context of existing representational similarity metrics for neural network interpretability. Second, we show that a mapper graph can provide semantic insight as to how these models organize hierarchical class knowledge at each layer. These observations demonstrate that TDA is a useful tool to help deep learning practitioners unlock the hidden structures of their models.","https://ojs.aaai.org/index.php/AAAI/article/view/26134/25906"
"26135","CMVAE: Causal Meta VAE for Unsupervised Meta-Learning","['Guodong Qi', 'Huimin Yu']","['Zhejiang University\nZJU-League Research & Development Center;', 'Zhejiang University\nZJU-League Research & Development Center\nState Key Lab of CAD&CG, Zhejiang University\nZhejiang Provincial Key Laboratory of Information Processing, Communication and Networking']","['ML: Meta Learning', 'ML: Unsupervised & Self-Supervised Learning', 'CV: Visual Reasoning & Symbolic Representations', 'CV: Object Detection & Categorization']","Qi, G., & Yu, H. (2023). CMVAE: Causal Meta VAE for Unsupervised Meta-Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9480-9488. https://doi.org/10.1609/aaai.v37i8.26135","Abstract 					Unsupervised meta-learning aims to learn the meta knowledge from unlabeled data and rapidly adapt to novel tasks. However, existing approaches may be misled by the  context-bias (e.g. background) from the training data. In this paper, we abstract the unsupervised meta-learning problem into a Structural Causal Model (SCM) and point out that such bias arises due to hidden confounders. To eliminate the confounders, we define the priors are conditionally independent, learn the relationships between priors and intervene on them with casual factorization. Furthermore, we propose Causal Meta VAE (CMVAE) that encodes the priors into latent codes in the causal space and learns their relationships simultaneously to achieve the downstream few-shot image classification task. Results on toy datasets and three benchmark datasets demonstrate that our method can remove the context-bias and it outperforms other state-of-the-art unsupervised meta-learning algorithms because of bias-removal. Code is available at https://github.com/GuodongQi/CMVAE.","https://ojs.aaai.org/index.php/AAAI/article/view/26135/25907"
"26136","Rethinking Data-Free Quantization as a Zero-Sum Game","['Biao Qian', 'Yang Wang', 'Richang Hong', 'Meng Wang']","['Hefei University of Technology', 'Hefei University of Technology', 'Hefei University of Technology', 'Hefei University of Technology']","['ML: Learning on the Edge & Model Compression', 'GTEP: Game Theory', 'ML: Classification and Regression', 'ML: Deep Generative Models & Autoencoders']","Qian, B., Wang, Y., Hong, R., & Wang, M. (2023). Rethinking Data-Free Quantization as a Zero-Sum Game. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9489-9497. https://doi.org/10.1609/aaai.v37i8.26136","Abstract 					Data-free quantization (DFQ) recovers the performance of quantized network (Q) without accessing the real data, but generates the fake sample via a generator (G) by learning from full-precision network (P) instead. However, such sample generation process is totally independence of Q, specialized as failing to consider the adaptability of the generated samples, i.e., beneficial or adversarial, over the learning process of Q, resulting into non-ignorable performance loss. Building on this, several crucial questions --- how to measure and exploit the sample adaptability to Q under varied bit-width scenarios? how to generate the samples with desirable adaptability to benefit the quantized network? --- impel us to revisit DFQ. In this paper, we answer the above questions from a game-theory perspective to specialize DFQ as a zero-sum game between two players --- a generator and a quantized network, and further propose an Adaptability-aware Sample Generation (AdaSG) method. Technically, AdaSG reformulates DFQ as a dynamic maximization-vs-minimization game process anchored on the sample adaptability. The maximization process aims to generate the sample with desirable adaptability, such sample adaptability is further reduced by the minimization process after calibrating Q for performance recovery. The Balance Gap is defined to guide the stationarity of the game process to maximally benefit Q. The theoretical analysis and empirical studies verify the superiority of AdaSG over the state-of-the-arts. Our code is available at https://github.com/hfutqian/AdaSG.","https://ojs.aaai.org/index.php/AAAI/article/view/26136/25908"
"26137","Mixture Uniform Distribution Modeling and Asymmetric Mix Distillation for Class Incremental Learning","['Sunyuan Qiang', 'Jiayi Hou', 'Jun Wan', 'Yanyan Liang', 'Zhen Lei', 'Du Zhang']","['Macau University of Science and Technology', 'Lafayette College', 'Macau University of Science and Technology\nNational Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Macau University of Science and Technology', 'National Laboratory of Pattern Recognition, Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Macau University of Science and Technology']","['ML: Lifelong and Continual Learning']","Qiang, S., Hou, J., Wan, J., Liang, Y., Lei, Z., & Zhang, D. (2023). Mixture Uniform Distribution Modeling and Asymmetric Mix Distillation for Class Incremental Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9498-9506. https://doi.org/10.1609/aaai.v37i8.26137","Abstract 					Exemplar rehearsal-based methods with knowledge distillation (KD) have been widely used in class incremental learning (CIL) scenarios. However, they still suffer from performance degradation because of severely distribution discrepancy between training and test set caused by the limited storage memory on previous classes. In this paper, we mathematically model the data distribution and the discrepancy at the incremental stages with mixture uniform distribution (MUD). Then, we propose the asymmetric mix distillation method to uniformly minimize the error of each class from distribution discrepancy perspective. Specifically, we firstly promote mixup in CIL scenarios with the incremental mix samplers and incremental mix factor to calibrate the raw training data distribution. Next, mix distillation label augmentation is incorporated into the data distribution to inherit the knowledge information from the previous models. Based on the above augmented data distribution, our trained model effectively alleviates the performance degradation and extensive experimental results validate that our method exhibits superior performance on CIL benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/26137/25909"
"26138","Mutual-Enhanced Incongruity Learning Network for Multi-Modal Sarcasm Detection","['Yang Qiao', 'Liqiang Jing', 'Xuemeng Song', 'Xiaolin Chen', 'Lei Zhu', 'Liqiang Nie']","['Shandong University', 'Shandong University', 'Shandong University', 'Shandong University', 'Shandong Normal Unversity', 'Harbin Institute of Technology (Shenzhen)']","['ML: Multimodal Learning', 'SNLP: Sentiment Analysis and Stylistic Analysis']","Qiao, Y., Jing, L., Song, X., Chen, X., Zhu, L., & Nie, L. (2023). Mutual-Enhanced Incongruity Learning Network for Multi-Modal Sarcasm Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9507-9515. https://doi.org/10.1609/aaai.v37i8.26138","Abstract 					Sarcasm is a sophisticated linguistic phenomenon that is prevalent on today's social media platforms. Multi-modal sarcasm detection aims to identify whether a given sample with multi-modal information (i.e., text and image) is sarcastic. This task's key lies in capturing both inter- and intra-modal incongruities within the same context. Although existing methods have achieved compelling success, they are disturbed by irrelevant information extracted from the whole image and text, or overlooking some important information due to the incomplete input. To address these limitations, we propose a Mutual-enhanced Incongruity Learning Network for multi-modal sarcasm detection, named MILNet. In particular, we design a local semantic-guided incongruity learning module and a global incongruity learning module. Moreover, we introduce a mutual enhancement module to take advantage of the underlying consistency between the two modules to boost the performance. Extensive experiments on a widely-used dataset demonstrate the superiority of our model over cutting-edge methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26138/25910"
"26139","Training Meta-Surrogate Model for Transferable Adversarial Attack","['Yunxiao Qin', 'Yuanhao Xiong', 'Jinfeng Yi', 'Cho-Jui Hsieh']","['State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China\nNeuroscience and Intelligent Media Institute, Communication University of China, Beijing, China', 'University of California, Los Angeles, USA', 'JD AI Research, Beijing, China', 'University of California, Los Angeles, USA']","['ML: Adversarial Learning & Robustness', 'CV: Adversarial Attacks & Robustness', 'PEAI: Safety', 'Robustness & Trustworthiness']","Qin, Y., Xiong, Y., Yi, J., & Hsieh, C.-J. (2023). Training Meta-Surrogate Model for Transferable Adversarial Attack. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9516-9524. https://doi.org/10.1609/aaai.v37i8.26139","Abstract 					The problem of adversarial attacks to a black-box model when no queries are allowed has posed a great challenge to the community and has been extensively investigated. In this setting, one simple yet effective method is to transfer the obtained adversarial examples from attacking surrogate models to fool the target model. Previous works have studied what kind of attacks to the surrogate model can generate more transferable adversarial examples, but their performances are still limited due to the mismatches between surrogate models and the target model. In this paper, we tackle this problem from a novel angle---instead of using the original surrogate models, can we obtain a Meta-Surrogate Model (MSM) such that attacks to this model can be easily transferred to other models? We show that this goal can be mathematically formulated as a bi-level optimization problem and design a differentiable attacker to make training feasible. Given one or a set of surrogate models, our method can thus obtain an MSM such that adversarial examples generated on MSM enjoy eximious transferability. Comprehensive experiments on Cifar-10 and ImageNet demonstrate that by attacking the MSM, we can obtain stronger transferable adversarial examples to deceive black-box models including adversarially trained ones, with much higher success rates than existing methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26139/25911"
"26140","Stochastic Contextual Bandits with Long Horizon Rewards","['Yuzhen Qin', 'Yingcong Li', 'Fabio Pasqualetti', 'Maryam Fazel', 'Samet Oymak']","['University of California, Riverside', 'University of California, Riverside', 'University of California, Riverside', 'University of Washington', 'University of California, Riverside\nUniversity of Michigan']","['ML: Online Learning & Bandits', 'ML: Reinforcement Learning Theory']","Qin, Y., Li, Y., Pasqualetti, F., Fazel, M., & Oymak, S. (2023). Stochastic Contextual Bandits with Long Horizon Rewards. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9525-9533. https://doi.org/10.1609/aaai.v37i8.26140","Abstract 					The growing interest in complex decision-making and language modeling problems highlights the importance of sample-efficient learning over very long horizons. This work takes a step in this direction by investigating contextual linear bandits where the current reward depends on at most s prior actions and contexts (not necessarily consecutive), up to a time horizon of h. In order to avoid polynomial dependence on h, we propose new algorithms that leverage sparsity to discover the dependence pattern and arm parameters jointly. We consider both the data-poor (T= h) regimes and derive respective regret upper bounds O(d square-root(sT) +min(q, T) and O( square-root(sdT) ),  with sparsity s, feature dimension d,  total time horizon T, and q that is adaptive to the reward dependence pattern. Complementing upper bounds, we also show that learning over a single trajectory brings inherent challenges: While the dependence pattern and arm parameters form a rank-1 matrix, circulant matrices are not isometric over rank-1 manifolds and sample complexity indeed benefits from the sparse reward dependence structure. Our results necessitate a new analysis to address long-range temporal dependencies across data and avoid polynomial dependence on the reward horizon h. Specifically, we utilize connections to the restricted isometry property of circulant matrices formed by dependent sub-Gaussian vectors and establish new guarantees that are also of independent interest.","https://ojs.aaai.org/index.php/AAAI/article/view/26140/25912"
"26141","Gradient-Variation Bound for Online Convex Optimization with Constraints","['Shuang Qiu', 'Xiaohan Wei', 'Mladen Kolar']","['Booth School of Business, the University of Chicago', 'Meta Platforms, Inc.', 'Booth School of Business, the University of Chicago']","['ML: Optimization', 'ML: Online Learning & Bandits']","Qiu, S., Wei, X., & Kolar, M. (2023). Gradient-Variation Bound for Online Convex Optimization with Constraints. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9534-9542. https://doi.org/10.1609/aaai.v37i8.26141","Abstract 					We study online convex optimization with constraints consisting of multiple functional constraints and a relatively simple constraint set, such as a Euclidean ball. As enforcing the constraints at each time step through projections is computationally challenging in general, we allow decisions to violate the functional constraints but aim to achieve a low regret and cumulative violation of the constraints over a horizon of T time steps. First-order methods achieve an O(sqrt{T}) regret and an O(1) constraint violation, which is the best-known bound under the Slater's condition, but do not take into account the structural information of the problem. Furthermore, the existing algorithms and analysis are limited to Euclidean space. In this paper, we provide an instance-dependent bound for online convex optimization with complex constraints obtained by a novel online primal-dual mirror-prox algorithm. Our instance-dependent regret is quantified by the total gradient variation V_*(T) in the sequence of loss functions. The proposed algorithm works in general normed spaces and simultaneously achieves an O(sqrt{V_*(T)}) regret and an O(1) constraint violation, which is never worse than the best-known (O(sqrt{T}), O(1)) result and improves over previous works that applied mirror-prox-type algorithms for this problem achieving O(T^{2/3}) regret and constraint violation. Finally, our algorithm is computationally efficient, as it only performs mirror descent steps in each iteration instead of solving a general Lagrangian minimization problem.","https://ojs.aaai.org/index.php/AAAI/article/view/26141/25913"
"26142","Bellman Meets Hawkes: Model-Based Reinforcement Learning via Temporal Point Processes","['Chao Qu', 'Xiaoyu Tan', 'Siqiao Xue', 'Xiaoming Shi', 'James Zhang', 'Hongyuan Mei']","['Ant Group, Hangzhou, China', 'Ant Group, Hangzhou, China', 'Ant Group, Hangzhou, China', 'Ant Group, Hangzhou, China', 'Ant Group, Hangzhou, China', 'Toyota Technological Institute at Chicago, Chicago, IL, United States']","['ML: Reinforcement Learning Algorithms']","Qu, C., Tan, X., Xue, S., Shi, X., Zhang, J., & Mei, H. (2023). Bellman Meets Hawkes: Model-Based Reinforcement Learning via Temporal Point Processes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9543-9551. https://doi.org/10.1609/aaai.v37i8.26142","Abstract 					We consider a sequential decision making problem where the agent faces the environment characterized by the stochastic discrete events and seeks an optimal intervention policy such that its long-term reward is maximized. This problem exists ubiquitously in social media, finance and health informatics but is rarely investigated by the conventional research in reinforcement learning. To this end, we present a novel framework of the model-based reinforcement learning where the agent's actions and observations  are  asynchronous stochastic discrete events occurring in continuous-time.  We model the dynamics of the environment by Hawkes process with external intervention control term and develop an algorithm to embed such process in the Bellman equation which guides the direction of the value gradient. We demonstrate the superiority of our method  in both synthetic simulator and real-data experiments.","https://ojs.aaai.org/index.php/AAAI/article/view/26142/25914"
"26143","GLUECons: A Generic Benchmark for Learning under Constraints","['Hossein Rajaby Faghihi', 'Aliakbar Nafar', 'Chen Zheng', 'Roshanak Mirzaee', 'Yue Zhang', 'Andrzej Uszok', 'Alexander Wan', 'Tanawan Premsri', 'Dan Roth', 'Parisa Kordjamshidi']","['Michigan State University', 'Michigan State University', 'Michigan State University', 'Michigan State University', 'Michigan State University', 'Florida Institute for Human and Machine Cognition', 'University of California Berkeley', 'Michigan State University', 'University of Pennsylvania', 'Michigan State University']","['ML: Evaluation and Analysis (Machine Learning)', 'CV: Language and Vision', 'SNLP: Learning & Optimization for SNLP', 'CSO: Solvers and Tools', 'KRR: Logic Programming', 'KRR: Ontologies and Semantic Web', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Optimization', 'ML: Semi-Supervised Learning']","Rajaby Faghihi, H., Nafar, A., Zheng, C., Mirzaee, R., Zhang, Y., Uszok, A., Wan, A., Premsri, T., Roth, D., & Kordjamshidi, P. (2023). GLUECons: A Generic Benchmark for Learning under Constraints. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9552-9561. https://doi.org/10.1609/aaai.v37i8.26143","Abstract 					Recent research has shown that integrating domain knowledge into deep learning architectures is effective; It helps reduce the amount of required data, improves the accuracy of the models' decisions, and improves the interpretability of models. However, the research community lacks a convened benchmark for systematically evaluating knowledge integration methods. In this work, we create a benchmark that is a collection of nine tasks in the domains of natural language processing and computer vision. In all cases, we model external knowledge as constraints, specify the sources of the constraints for each task, and implement various models that use these constraints. We report the results of these models using a new set of extended evaluation criteria in addition to the task performances for a more in-depth analysis. This effort provides a framework for a more comprehensive and systematic comparison of constraint integration techniques and for identifying related research challenges. It will facilitate further research for alleviating some problems of state-of-the-art neural models.","https://ojs.aaai.org/index.php/AAAI/article/view/26143/25915"
"26144","Provable Detection of Propagating Sampling Bias in Prediction Models","['Pavan Ravishankar', 'Qingyu Mo', 'Edward McFowland III', 'Daniel B. Neill']","['NYU Courant', 'NYU Courant', 'Harvard University', 'New York University']","['ML: Bias and Fairness', 'PEAI: AI and Law', 'Justice', 'Regulation & Governance', 'PEAI: Bias', 'Fairness & Equity', 'PEAI: Societal Impact of AI']","Ravishankar, P., Mo, Q., McFowland III, E., & Neill, D. B. (2023). Provable Detection of Propagating Sampling Bias in Prediction Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9562-9569. https://doi.org/10.1609/aaai.v37i8.26144","Abstract 					With an increased focus on incorporating fairness in machine learning models, it becomes imperative not only to assess and mitigate bias at each stage of the machine learning pipeline but also to understand the downstream impacts of bias across stages. Here we consider a general, but realistic, scenario in which a predictive model is learned from (potentially biased) training data, and model predictions are assessed post-hoc for fairness by some auditing method. We provide a theoretical analysis of how a specific form of data bias, differential sampling bias, propagates from the data stage to the prediction stage. Unlike prior work, we evaluate the downstream impacts of data biases quantitatively rather than qualitatively and prove theoretical guarantees for detection. Under reasonable assumptions, we quantify how the amount of bias in the model predictions varies as a function of the amount of differential sampling bias in the data, and at what point this bias becomes provably detectable by the auditor. Through experiments on two criminal justice datasets-- the well-known COMPAS dataset and historical data from NYPD's stop and frisk policy-- we demonstrate that the theoretical results hold in practice even when our assumptions are relaxed.","https://ojs.aaai.org/index.php/AAAI/article/view/26144/25916"
"26145","Diffusing Gaussian Mixtures for Generating Categorical Data","['Florence Regol', 'Mark Coates']","['McGill University', 'McGill University']","['ML: Deep Generative Models & Autoencoders', 'RU: Uncertainty Representations']","Regol, F., & Coates, M. (2023). Diffusing Gaussian Mixtures for Generating Categorical Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9570-9578. https://doi.org/10.1609/aaai.v37i8.26145","Abstract 					Learning a categorical distribution comes with its own set of challenges. A successful approach taken by state-of-the-art works is to cast the problem in a continuous domain to take advantage of the impressive performance of the generative models for continuous data. Amongst them are the recently emerging diffusion probabilistic models, which have the observed advantage of generating high-quality samples. Recent advances for categorical generative models have focused on log likelihood improvements. In this work, we propose a generative model for categorical data based on diffusion models with a focus on high-quality sample generation, and propose sampled-based evaluation methods. The efficacy of our method stems from performing diffusion in the continuous domain while having its parameterization informed by the structure of the categorical nature of the target distribution. Our method of evaluation highlights the capabilities and limitations of different generative models for generating categorical data, and includes experiments on synthetic and real-world protein datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26145/25917"
"26146","Hypernetworks for Zero-Shot Transfer in Reinforcement Learning","['Sahand Rezaei-Shoshtari', 'Charlotte Morissette', 'Francois R. Hogan', 'Gregory Dudek', 'David Meger']","['McGill University\nMila - Quebec AI Institute\nSamsung AI Center Montreal', 'McGill University\nSamsung AI Center Montreal', 'Samsung AI Center Montreal', 'McGill University\nSamsung AI Center Montreal\nMila - Quebec AI Institute', 'McGill University\nSamsung AI Center Montreal\nMila - Quebec AI Institute']","['ML: Reinforcement Learning Algorithms', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Rezaei-Shoshtari, S., Morissette, C., Hogan, F. R., Dudek, G., & Meger, D. (2023). Hypernetworks for Zero-Shot Transfer in Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9579-9587. https://doi.org/10.1609/aaai.v37i8.26146","Abstract 					In this paper, hypernetworks are trained to generate behaviors across a range of unseen task conditions, via a novel TD-based training objective and data from a set of near-optimal RL solutions for training tasks. This work relates to meta RL, contextual RL, and transfer learning, with a particular focus on  zero-shot performance at test time, enabled by knowledge of the task parameters (also known as context). Our technical approach is based upon viewing each RL algorithm as a mapping from the MDP specifics to the near-optimal value function and policy and seek to approximate it with a hypernetwork that can generate near-optimal value functions and policies, given the parameters of the MDP. We show that, under certain conditions, this mapping can be considered as a supervised learning problem. We empirically evaluate the effectiveness of our method for zero-shot transfer to new reward and transition dynamics on a series of continuous control tasks from DeepMind Control Suite. Our method demonstrates significant improvements over baselines from multitask and meta RL approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/26146/25918"
"26147","Automata Cascades: Expressivity and Sample Complexity","['Alessandro Ronca', 'Nadezda Alexandrovna Knorozova', 'Giuseppe De Giacomo']","['Sapienza University of Rome', 'RelationalAI\nUniversity of Zurich', 'University of Oxford\nSapienza University of Rome']","['ML: Learning Theory', 'KRR: Computational Complexity of Reasoning', 'KRR: Geometric', 'Spatial', 'and Temporal Reasoning', 'ML: Classification and Regression', 'ML: Reinforcement Learning Theory', 'ML: Time-Series/Data Streams']","Ronca, A., Knorozova, N. A., & De Giacomo, G. (2023). Automata Cascades: Expressivity and Sample Complexity. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9588-9595. https://doi.org/10.1609/aaai.v37i8.26147","Abstract 					Every automaton can be decomposed into a cascade of basic prime automata. This is the Prime Decomposition Theorem by Krohn and Rhodes. Guided by this theory, we propose automata cascades as a structured, modular, way to describe automata as complex systems made of many components, each implementing a specific functionality. Any automaton can serve as a component; using specific components allows for a fine-grained control of the expressivity of the resulting class of automata; using prime automata as components implies specific expressivity guarantees. Moreover, specifying automata as cascades allows for describing the sample complexity of automata in terms of their components. We show that the sample complexity is linear in the number of components and the maximum complexity of a single component, modulo logarithmic factors. This opens to the possibility of learning automata representing large dynamical systems consisting of many parts interacting with each other. It is in sharp contrast with the established understanding of the sample complexity of automata, described in terms of the overall number of states and input letters, which implies that it is only possible to learn automata where the number of states is linear in the amount of data available. Instead our results show that one can learn automata with a number of states that is exponential in the amount of data available.","https://ojs.aaai.org/index.php/AAAI/article/view/26147/25919"
"26148","ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving Few-Shot Learning","['Yi Rong', 'Xiongbo Lu', 'Zhaoyang Sun', 'Yaxiong Chen', 'Shengwu Xiong']","['School of Computer Science and Artificial Intelligence, Wuhan University of Technology\nSanya Science and Education Innovation Park, Wuhan University of Technology\nHainan Yazhou Bay Seed Laboratory\nShanghai Artificial Intelligence Laboratory', 'School of Computer Science and Artificial Intelligence, Wuhan University of Technology', 'School of Computer Science and Artificial Intelligence, Wuhan University of Technology', 'School of Computer Science and Artificial Intelligence, Wuhan University of Technology\nSanya Science and Education Innovation Park, Wuhan University of Technology', 'School of Computer Science and Artificial Intelligence, Wuhan University of Technology\nSanya Science and Education Innovation Park, Wuhan University of Technology\nHainan Yazhou Bay Seed Laboratory\nShanghai Artificial Intelligence Laboratory']","['ML: Classification and Regression', 'ML: Unsupervised & Self-Supervised Learning', 'ML: Deep Neural Network Algorithms', 'CV: Representation Learning for Vision']","Rong, Y., Lu, X., Sun, Z., Chen, Y., & Xiong, S. (2023). ESPT: A Self-Supervised Episodic Spatial Pretext Task for Improving Few-Shot Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9596-9605. https://doi.org/10.1609/aaai.v37i8.26148","Abstract 					Self-supervised learning (SSL) techniques have recently been integrated into the few-shot learning (FSL) framework and have shown promising results in improving the few-shot image classification performance. However, existing SSL approaches used in FSL typically seek the supervision signals from the global embedding of every single image. Therefore, during the episodic training of FSL, these methods cannot capture and fully utilize the local visual information in image samples and the data structure information of the whole episode, which are beneficial to FSL. To this end, we propose to augment the few-shot learning objective with a novel self-supervised Episodic Spatial Pretext Task (ESPT). Specifically, for each few-shot episode, we generate its corresponding transformed episode by applying a random geometric transformation to all the images in it. Based on these, our ESPT objective is defined as maximizing the local spatial relationship consistency between the original episode and the transformed one. With this definition, the ESPT-augmented FSL objective promotes learning more transferable feature representations that capture the local spatial features of different images and their inter-relational structural information in each input episode, thus enabling the model to generalize better to new categories with only a few samples. Extensive experiments indicate that our ESPT method achieves new state-of-the-art performance for few-shot image classification on three mainstay benchmark datasets. The source code will be available at: https://github.com/Whut-YiRong/ESPT.","https://ojs.aaai.org/index.php/AAAI/article/view/26148/25920"
"26149","Planning and Learning with Adaptive Lookahead","['Aviv Rosenberg', 'Assaf Hallak', 'Shie Mannor', 'Gal Chechik', 'Gal Dalal']","['Amazon Science', 'Nvidia Research', 'Nvidia Research\nTechnion', 'Nvidia Research\nBar-Ilan University', 'Nvidia Research']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms']","Rosenberg, A., Hallak, A., Mannor, S., Chechik, G., & Dalal, G. (2023). Planning and Learning with Adaptive Lookahead. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9606-9613. https://doi.org/10.1609/aaai.v37i8.26149","Abstract 					Some of the most powerful reinforcement learning frameworks use planning for action selection. Interestingly, their planning horizon is either fixed or determined arbitrarily by the state visitation history. Here, we expand beyond the naive fixed horizon and propose a theoretically justified strategy for adaptive selection of the planning horizon as a function of the state-dependent value estimate. We propose two variants for lookahead selection and analyze the trade-off between iteration count and computational complexity per iteration. We then devise a corresponding deep Q-network algorithm with an adaptive tree search horizon. We separate the value estimation per depth to compensate for the off-policy discrepancy between depths. Lastly, we demonstrate the efficacy of our adaptive lookahead method in a maze environment and Atari.","https://ojs.aaai.org/index.php/AAAI/article/view/26149/25921"
"26150","DisGUIDE: Disagreement-Guided Data-Free Model Extraction","['Jonathan Rosenthal', 'Eric Enouen', 'Hung Viet Pham', 'Lin Tan']","['Purdue University', 'The Ohio State University', 'York University', 'Purdue University']","['ML: Active Learning', 'CV: Applications', 'CV: Learning & Optimization for CV', 'ML: Classification and Regression', 'ML: Ensemble Methods', 'ML: Unsupervised & Self-Supervised Learning']","Rosenthal, J., Enouen, E., Pham, H. V., & Tan, L. (2023). DisGUIDE: Disagreement-Guided Data-Free Model Extraction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9614-9622. https://doi.org/10.1609/aaai.v37i8.26150","Abstract 					Recent model-extraction attacks on Machine Learning as a Service (MLaaS) systems have moved towards data-free approaches, showing the feasibility of stealing models trained with difficult-to-access data. However, these attacks are ineffective or limited due to the low accuracy of extracted models and the high number of queries to the models under attack. The high query cost makes such techniques infeasible for online MLaaS systems that charge per query. We create a novel approach to get higher accuracy and query efficiency than prior data-free model extraction techniques. Specifically, we introduce a novel generator training scheme that maximizes the disagreement loss between two clone models that attempt to copy the model under attack. This loss, combined with diversity loss and experience replay, enables the generator to produce better instances to train the clone models. Our evaluation on popular datasets CIFAR-10 and CIFAR-100 shows that our approach improves the final model accuracy by up to 3.42% and 18.48% respectively. The average number of queries required to achieve the accuracy of the prior state of the art is reduced by up to 64.95%. We hope this will promote future work on feasible data-free model extraction and defenses against such attacks.","https://ojs.aaai.org/index.php/AAAI/article/view/26150/25922"
"26151","Overcoming Concept Shift in Domain-Aware Settings through Consolidated Internal Distributions","['Mohammad Rostami', 'Aram Galstyan']","['University of Southern California', 'USC Information Sciences Institute']","['ML: Lifelong and Continual Learning', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning']","Rostami, M., & Galstyan, A. (2023). Overcoming Concept Shift in Domain-Aware Settings through Consolidated Internal Distributions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9623-9631. https://doi.org/10.1609/aaai.v37i8.26151","Abstract 					We develop an algorithm to improve the predictive performance of a pre-trained model under \textit{concept shift} without retraining the model from scratch when only unannotated samples of initial concepts are accessible. We model this problem as a domain adaptation problem, where the source domain data is inaccessible during model adaptation. The core idea is based on consolidating the intermediate internal distribution, learned to represent the source domain data, after adapting the model. We provide theoretical analysis and conduct extensive experiments on five benchmark datasets to demonstrate that the proposed method is effective.","https://ojs.aaai.org/index.php/AAAI/article/view/26151/25923"
"26152","Inferring Patient Zero on Temporal Networks via Graph Neural Networks","['Xiaolei Ru', 'Jack Murdoch Moore', 'Xin-Ya Zhang', 'Yeting Zeng', 'Gang Yan']","['Tongji University', 'Tongji University', 'Tongji University', 'Zhongshan Hospital, Fudan University', 'Tongji University']","['ML: Applications', 'APP: Healthcare', 'Medicine & Wellness', 'APP: Humanities & Computational Social Science', 'APP: Social Networks', 'ML: Classification and Regression', 'ML: Graph-based Machine Learning']","Ru, X., Murdoch Moore, J., Zhang, X.-Y., Zeng, Y., & Yan, G. (2023). Inferring Patient Zero on Temporal Networks via Graph Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9632-9640. https://doi.org/10.1609/aaai.v37i8.26152","Abstract 					The world is currently seeing frequent local outbreaks of epidemics, such as COVID-19 and Monkeypox. Preventing further propagation of the outbreak requires prompt implementation of control measures, and a critical step is to quickly infer patient zero. This backtracking task is challenging for two reasons. First, due to the sudden emergence of local epidemics, information recording the spreading process is limited. Second, the spreading process has strong randomness. To address these challenges, we tailor a gnn-based model to establish the inverse statistical association between the current and initial state implicitly. This model uses contact topology and the current state of the local population to determine the possibility that each individual could be patient zero. We benchmark our model on data from important epidemiological models on five real temporal networks, showing performance significantly superior to previous methods. We also demonstrate that our method is robust to missing information about contact structure or current state. Further, we find the individuals assigned higher inferred possibility by model are closer to patient zero in terms of core number and the activity sequence recording the times at which the individual had contact with other nodes.","https://ojs.aaai.org/index.php/AAAI/article/view/26152/25924"
"26153","Accommodating Audio Modality in CLIP for Multimodal Processing","['Ludan Ruan', 'Anwen Hu', 'Yuqing Song', 'Liang Zhang', 'Sipeng Zheng', 'Qin Jin']","['Renmin University of China', 'Renmin University of China', 'Renmin University of China', 'Renmin University of China', 'Renmin University of China', 'Renmin University of China']","['ML: Multimodal Learning', 'CV: Multi-modal Vision', 'CV: Video Understanding & Activity Analysis', 'DMKM: Mining of Visual', 'Multimedia & Multimodal Data']","Ruan, L., Hu, A., Song, Y., Zhang, L., Zheng, S., & Jin, Q. (2023). Accommodating Audio Modality in CLIP for Multimodal Processing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9641-9649. https://doi.org/10.1609/aaai.v37i8.26153","Abstract 					Multimodal processing has attracted much attention lately especially with the success of pre-training. However, the exploration has mainly focused on vision-language pre-training, as introducing more modalities can greatly complicate model design and optimization. In this paper, we extend the state-of-the-art Vision-Language model CLIP to accommodate the audio modality for Vision-Language-Audio multimodal processing. Specifically, we apply inter-modal and intra-modal contrastive learning to explore the correlation between audio and other modalities in addition to the inner characteristics of the audio modality. Moreover, we further design an audio type token to dynamically learn different audio information type for different scenarios, as both verbal and nonverbal heterogeneous information is conveyed in general audios. Our proposed CLIP4VLA model is validated in different downstream tasks including video retrieval and video captioning, and achieves the state-of-the-art performance on the benchmark datasets of MSR-VTT, VATEX, and Audiocaps.The corresponding code and checkpoints will be released at https://github.com/ludanruan/CLIP4VLA.","https://ojs.aaai.org/index.php/AAAI/article/view/26153/25925"
"26154","Forecasting with Sparse but Informative Variables: A Case Study in Predicting Blood Glucose","['Harry Rubin-Falcone', 'Joyce Lee', 'Jenna Wiens']","['University of Michigan', 'University of Michigan', 'University of Michigan']","['ML: Time-Series/Data Streams', 'APP: Healthcare', 'Medicine & Wellness', 'ML: Deep Neural Architectures']","Rubin-Falcone, H., Lee, J., & Wiens, J. (2023). Forecasting with Sparse but Informative Variables: A Case Study in Predicting Blood Glucose. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9650-9657. https://doi.org/10.1609/aaai.v37i8.26154","Abstract 					In time-series forecasting, future target values may be affected by both intrinsic and extrinsic effects. When forecasting blood glucose, for example, intrinsic effects can be inferred from the history of the target signal alone (i.e. blood glucose), but accurately modeling the impact of extrinsic effects requires auxiliary signals, like the amount of carbohydrates ingested. Standard forecasting techniques often assume that extrinsic and intrinsic effects vary at similar rates. However, when auxiliary signals are generated at a much lower frequency than the target variable (e.g., blood glucose measurements are made every 5 minutes, while meals occur once every few hours), even well-known extrinsic effects (e.g., carbohydrates increase blood glucose) may prove difficult to learn. To better utilize these sparse but informative variables (SIVs), we introduce a novel encoder/decoder forecasting approach that accurately learns the per-timepoint effect of the SIV, by (i) isolating it from intrinsic effects and (ii) restricting its learned effect based on domain knowledge. On a simulated dataset pertaining to the task of blood glucose forecasting, when the SIV is accurately recorded our approach outperforms baseline approaches in terms of rMSE (13.07 [95% CI: 11.77,14.16] vs. 14.14 [12.69,15.27]). In the presence of a corrupted SIV, the proposed approach can still result in lower error compared to the baseline but the advantage is reduced as noise increases. By isolating their effects and incorporating domain knowledge, our approach makes it possible to better utilize SIVs in forecasting.","https://ojs.aaai.org/index.php/AAAI/article/view/26154/25926"
"26155","On the Sample Complexity of Representation Learning in Multi-Task Bandits with Global and Local Structure","['Alessio Russo', 'Alexandre Proutiere']","['KTH Royal Institute of Technology', 'KTH Royal Institute of Technology']","['ML: Representation Learning', 'ML: Online Learning & Bandits', 'ML: Reinforcement Learning Algorithms', 'ML: Reinforcement Learning Theory']","Russo, A., & Proutiere, A. (2023). On the Sample Complexity of Representation Learning in Multi-Task Bandits with Global and Local Structure. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9658-9667. https://doi.org/10.1609/aaai.v37i8.26155","Abstract 					We investigate the sample complexity of learning the optimal arm for multi-task bandit problems. Arms consist of two components: one that is shared across tasks (that we call representation) and one that is task-specific (that we call predictor).  The objective is to learn the optimal (representation, predictor)-pair for each task, under the assumption that the optimal representation is common to all tasks. Within this framework, efficient learning algorithms should transfer knowledge across tasks.  We consider the best-arm identification problem with fixed confidence, where, in each round, the learner actively selects both a task, and an arm, and observes the corresponding reward. We derive instance-specific sample complexity lower bounds, which apply to any algorithm that identifies the best representation, and the best predictor for a task, with prescribed confidence levels.    We devise an algorithm, OSRL-SC, that can learn the optimal representation, and the optimal predictors, separately, and whose sample complexity approaches the lower bound. Theoretical and numerical results demonstrate that OSRL-SC achieves a better scaling with respect to the number of tasks compared to the classical best-arm identification algorithm. The code can be found here https://github.com/rssalessio/OSRL-SC.","https://ojs.aaai.org/index.php/AAAI/article/view/26155/25927"
"26156","Simultaneously Updating All Persistence Values in Reinforcement Learning","['Luca Sabbioni', 'Luca Al Daire', 'Lorenzo Bisi', 'Alberto Maria Metelli', 'Marcello Restelli']","['Politecnico di Milano', 'Politecnico di Milano', 'ML cube', 'Politecnico di Milano', 'Politecnico di Milano']","['ML: Reinforcement Learning Algorithms']","Sabbioni, L., Al Daire, L., Bisi, L., Metelli, A. M., & Restelli, M. (2023). Simultaneously Updating All Persistence Values in Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9668-9676. https://doi.org/10.1609/aaai.v37i8.26156","Abstract 					In Reinforcement Learning, the performance of learning agents is highly sensitive to the choice of time discretization. Agents acting at high frequencies have the best control opportunities, along with some drawbacks, such as possible inefficient exploration and vanishing of the action advantages. The repetition of the actions, i.e., action persistence, comes into help, as it allows the agent to visit wider regions of the state space and improve the estimation of the action effects. In this work, we derive a novel operator, the All-Persistence Bellman Operator, which allows an effective use of both the low-persistence experience, by decomposition into sub-transition, and the high-persistence experience, thanks to the introduction of a suitable bootstrap procedure. In this way, we employ transitions collected at any time scale to update simultaneously the action values of the considered persistence set. We prove the contraction property of the All-Persistence Bellman Operator and, based on it, we extend classic Q-learning and DQN. After providing a study on the effects of persistence, we experimentally evaluate our approach in both tabular contexts and more challenging frameworks, including some Atari games.","https://ojs.aaai.org/index.php/AAAI/article/view/26156/25928"
"26157","Continual Learning with Scaled Gradient Projection","['Gobinda Saha', 'Kaushik Roy']","['Purdue University', 'Purdue University']","['ML: Lifelong and Continual Learning', 'ML: Deep Neural Network Algorithms', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Saha, G., & Roy, K. (2023). Continual Learning with Scaled Gradient Projection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9677-9685. https://doi.org/10.1609/aaai.v37i8.26157","Abstract 					In neural networks, continual learning results in gradient interference among sequential tasks, leading to catastrophic forgetting of old tasks while learning new ones. This issue is addressed in recent methods by storing the important gradient spaces for old tasks and updating the model orthogonally during new tasks. However, such restrictive orthogonal gradient updates hamper the learning capability of the new tasks resulting in sub-optimal performance. To improve new learning while minimizing forgetting, in this paper we propose a Scaled Gradient Projection (SGP) method, where we combine the orthogonal gradient projections with scaled gradient steps along the important gradient spaces for the past tasks. The degree of gradient scaling along these spaces depends on the importance of the bases spanning them. We propose an efficient method for computing and accumulating importance of these bases using the singular value decomposition of the input representations for each task. We conduct extensive experiments ranging from continual image classification to reinforcement learning tasks and report better performance with less training overhead than the state-of-the-art approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/26157/25929"
"26158","Fast Offline Policy Optimization for Large Scale Recommendation","['Otmane Sakhi', 'David Rohde', 'Alexandre Gilotte']","['Criteo\nENSAE, IPP', 'Criteo', 'Criteo']","['ML: Scalability of ML Systems', 'DMKM: Recommender Systems', 'RU: Sequential Decision Making']","Sakhi, O., Rohde, D., & Gilotte, A. (2023). Fast Offline Policy Optimization for Large Scale Recommendation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9686-9694. https://doi.org/10.1609/aaai.v37i8.26158","Abstract 					Personalised interactive systems such as recommender systems require selecting relevant items from massive catalogs dependent on context. Reward-driven offline optimisation of these systems can be achieved by a relaxation of the discrete problem resulting in policy learning or REINFORCE style learning algorithms. Unfortunately, this relaxation step requires computing a sum over the entire catalogue making the complexity of the evaluation of the gradient (and hence each stochastic gradient descent iterations) linear in the catalogue size. This calculation is untenable in many real world examples such as large catalogue recommender systems, severely limiting the usefulness of this method in practice. In this paper, we derive an approximation of these policy learning algorithms that scale logarithmically with the catalogue size. Our contribution is based upon combining three novel ideas: a new Monte Carlo estimate of the gradient of a policy, the self normalised importance sampling estimator and the use of fast maximum inner product search at training time. Extensive experiments show that our algorithm is an order of magnitude faster than naive approaches yet produces equally good policies.","https://ojs.aaai.org/index.php/AAAI/article/view/26158/25930"
"26159","Losses over Labels: Weakly Supervised Learning via Direct Loss Construction","['Dylan Sam', 'J. Zico Kolter']","['Carnegie Mellon University', 'Carnegie Mellon University\nBosch Center for Artificial Intelligence']","['ML: Unsupervised & Self-Supervised Learning', 'ML: Semi-Supervised Learning', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification']","Sam, D., & Kolter, J. Z. (2023). Losses over Labels: Weakly Supervised Learning via Direct Loss Construction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9695-9703. https://doi.org/10.1609/aaai.v37i8.26159","Abstract 					Owing to the prohibitive costs of generating large amounts of labeled data, programmatic weak supervision is a growing paradigm within machine learning. In this setting, users design heuristics that provide noisy labels for subsets of the data. These weak labels are combined (typically via a graphical model) to form pseudolabels, which are then used to train a downstream model. In this work, we question a foundational premise of the typical weakly supervised learning pipeline: given that the heuristic provides all “label” information, why do we need to generate pseudolabels at all? Instead, we propose to directly transform the heuristics themselves into corresponding loss functions that penalize differences between our model and the heuristic. By constructing losses directly from the heuristics, we can incorporate more information than is used in the standard weakly supervised pipeline, such as how the heuristics make their decisions, which explicitly informs feature selection during training. We call our method Losses over Labels (LoL) as it creates losses directly from heuristics without going through the intermediate step of a label. We show that LoL improves upon existing weak supervision methods on several benchmark text and image classification tasks and further demonstrate that incorporating gradient information leads to better performance on almost every task.","https://ojs.aaai.org/index.php/AAAI/article/view/26159/25931"
"26160","Representation Learning by Detecting Incorrect Location Embeddings","['Sepehr Sameni', 'Simon Jenni', 'Paolo Favaro']","['University of Bern', 'Adobe Research', 'University of Bern']","['ML: Unsupervised & Self-Supervised Learning', 'CV: Representation Learning for Vision', 'ML: Representation Learning']","Sameni, S., Jenni, S., & Favaro, P. (2023). Representation Learning by Detecting Incorrect Location Embeddings. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9704-9713. https://doi.org/10.1609/aaai.v37i8.26160","Abstract 					In this paper, we introduce a novel self-supervised learning (SSL) loss for image representation learning. There is a growing belief that generalization in deep neural networks is linked to their ability to discriminate object shapes. Since object shape is related to the location of its parts, we propose to detect those that have been artificially misplaced. We represent object parts with image tokens and train a ViT to detect which token has been combined with an incorrect positional embedding. We then introduce sparsity in the inputs to make the model more robust to occlusions and to speed up the training. We call our method DILEMMA, which stands for Detection of Incorrect Location EMbeddings with MAsked inputs. We apply DILEMMA to MoCoV3, DINO and SimCLR and show an improvement in their performance of respectively 4.41%, 3.97%, and 0.5% under the same training time and with a linear probing transfer on ImageNet-1K. We also show full fine-tuning improvements of MAE combined with our method on ImageNet-100. We evaluate our method via fine-tuning on common SSL benchmarks. Moreover, we show that when downstream tasks are strongly reliant on shape (such as in the YOGA-82 pose dataset), our pre-trained features yield a significant gain over prior work.","https://ojs.aaai.org/index.php/AAAI/article/view/26160/25932"
"26161","Sparse Coding in a Dual Memory System for Lifelong Learning","['Fahad Sarfraz', 'Elahe Arani', 'Bahram Zonooz']","['Navinfo Europe\nTUE', 'Navinfo Europe\nTUE', 'Navinfo Europe\nTUE']","['ML: Lifelong and Continual Learning', 'ML: Bio-Inspired Learning']","Sarfraz, F., Arani, E., & Zonooz, B. (2023). Sparse Coding in a Dual Memory System for Lifelong Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9714-9722. https://doi.org/10.1609/aaai.v37i8.26161","Abstract 					Efficient continual learning in humans is enabled by a rich set of neurophysiological mechanisms and interactions between multiple memory systems. The brain efficiently encodes information in non-overlapping sparse codes, which facilitates the learning of new associations faster with controlled interference with previous associations. To mimic sparse coding in DNNs, we enforce activation sparsity along with a dropout mechanism which encourages the model to activate similar units for semantically similar inputs and have less overlap with activation patterns of semantically dissimilar inputs. This provides us with an efficient mechanism for balancing the reusability and interference of features, depending on the similarity of classes across tasks. Furthermore, we employ sparse coding in a multiple-memory replay mechanism. Our method maintains an additional long-term semantic memory that aggregates and consolidates information encoded in the synaptic weights of the working model. Our extensive evaluation and characteristics analysis show that equipped with these biologically inspired mechanisms, the model can further mitigate forgetting. Code available at \url{https://github.com/NeurAI-Lab/SCoMMER}.","https://ojs.aaai.org/index.php/AAAI/article/view/26161/25933"
"26162","Self-Supervised Audio-Visual Representation Learning with Relaxed Cross-Modal Synchronicity","['Pritam Sarkar', 'Ali Etemad']","[""Queen's Univesity, Canada\nVector Institute"", ""Queen's University, Canada""]","['ML: Unsupervised & Self-Supervised Learning', 'CV: Video Understanding & Activity Analysis', 'CV: Multi-modal Vision', 'CV: Representation Learning for Vision']","Sarkar, P., & Etemad, A. (2023). Self-Supervised Audio-Visual Representation Learning with Relaxed Cross-Modal Synchronicity. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9723-9732. https://doi.org/10.1609/aaai.v37i8.26162","Abstract 					We present CrissCross, a self-supervised framework for learning audio-visual representations. A novel notion is introduced in our framework whereby in addition to learning the intra-modal and standard 'synchronous' cross-modal relations, CrissCross also learns 'asynchronous' cross-modal relationships. We perform in-depth studies showing that by relaxing the temporal synchronicity between the audio and visual modalities, the network learns strong generalized representations useful for a variety of downstream tasks. To pretrain our proposed solution, we use 3 different datasets with varying sizes, Kinetics-Sound, Kinetics400, and AudioSet. The learned representations are evaluated on a number of downstream tasks namely action recognition, sound classification, and action retrieval. Our experiments show that CrissCross either outperforms or achieves performances on par with the current state-of-the-art self-supervised methods on action recognition and action retrieval with UCF101 and HMDB51, as well as sound classification with ESC50 and DCASE. Moreover, CrissCross outperforms fully-supervised pretraining while pretrained on Kinetics-Sound.","https://ojs.aaai.org/index.php/AAAI/article/view/26162/25934"
"26163","Dropout Is NOT All You Need to Prevent Gradient Leakage","['Daniel Scheliga', 'Patrick Maeder', 'Marco Seeland']","['Technische Universität Ilmenau, Ilmenau, Germany', 'Technische Universität Ilmenau, Germany\nFriedrich Schiller Universität Jena, Germany', 'Technische Universität Ilmenau, Germany']","['ML: Privacy-Aware ML', 'CV: Bias', 'Fairness & Privacy', 'ML: Distributed Machine Learning & Federated Learning']","Scheliga, D., Maeder, P., & Seeland, M. (2023). Dropout Is NOT All You Need to Prevent Gradient Leakage. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9733-9741. https://doi.org/10.1609/aaai.v37i8.26163","Abstract 					Gradient inversion attacks on federated learning systems reconstruct client training data from exchanged gradient information. To defend against such attacks, a variety of defense mechanisms were proposed. However, they usually lead to an unacceptable trade-off between privacy and model utility. Recent observations suggest that dropout could mitigate gradient leakage and improve model utility if added to neural networks. Unfortunately, this phenomenon has not been systematically researched yet. In this work, we thoroughly analyze the effect of dropout on iterative gradient inversion attacks. We find that state of the art attacks are not able to reconstruct the client data due to the stochasticity induced by dropout during model training. Nonetheless, we argue that dropout does not offer reliable protection if the dropout induced stochasticity is adequately modeled during attack optimization. Consequently, we propose a novel Dropout Inversion Attack (DIA) that jointly optimizes for client data and dropout masks to approximate the stochastic client model. We conduct an extensive systematic evaluation of our attack on four seminal model architectures and three image classification datasets of increasing complexity. We find that our proposed attack bypasses the protection seemingly induced by dropout and reconstructs client data with high fidelity. Our work demonstrates that privacy inducing changes to model architectures alone cannot be assumed to reliably protect from gradient leakage and therefore should be combined with complementary defense mechanisms.","https://ojs.aaai.org/index.php/AAAI/article/view/26163/25935"
"26164","Exploration via Epistemic Value Estimation","['Simon Schmitt', 'John Shawe-Taylor', 'Hado van Hasselt']","['DeepMind\nUniversity College London', 'University College London', 'DeepMind']","['ML: Reinforcement Learning Algorithms', 'ML: Reinforcement Learning Theory']","Schmitt, S., Shawe-Taylor, J., & van Hasselt, H. (2023). Exploration via Epistemic Value Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9742-9751. https://doi.org/10.1609/aaai.v37i8.26164","Abstract 					How to efficiently explore in reinforcement learning is an open problem. Many exploration algorithms employ the epistemic uncertainty of their own value predictions -- for instance to compute an exploration bonus or upper confidence bound. Unfortunately the required uncertainty is difficult to estimate in general with function approximation.  We propose epistemic value estimation (EVE): a recipe that is compatible with sequential decision making and with neural network function approximators. It equips agents with a tractable posterior over all their parameters from which epistemic value uncertainty can be computed efficiently.  We use the recipe to derive an epistemic Q-Learning agent and observe competitive performance on a series of benchmarks. Experiments confirm that the EVE recipe facilitates efficient exploration in hard exploration tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26164/25936"
"26165","Multi-Source Survival Domain Adaptation","['Ammar Shaker', 'Carolin Lawrence']","['NEC Laboratories Europe', 'NEC Laboratories Europe']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'APP: Healthcare', 'Medicine & Wellness']","Shaker, A., & Lawrence, C. (2023). Multi-Source Survival Domain Adaptation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9752-9762. https://doi.org/10.1609/aaai.v37i8.26165","Abstract 					Survival analysis is the branch of statistics that studies the relation between the characteristics of living entities and their respective survival times, taking into account the partial information held by censored cases. A good analysis can, for example, determine whether one medical treatment for a group of patients is better than another. With the rise of machine learning, survival analysis can be modeled as learning a function that maps studied patients to their survival times. To succeed with that, there are three crucial issues to be tackled.   First, some patient data is censored: we do not know the true survival times for all patients. Second, data is scarce, which led past research to treat different illness types as domains in a multi-task setup. Third, there is the need for adaptation to new or extremely rare illness types, where little or no labels are available. In contrast to previous multi-task setups, we want to investigate how to efficiently adapt to a new survival target domain from multiple survival source domains.   For this, we introduce a new survival metric and the corresponding discrepancy measure between survival distributions. These allow us to define domain adaptation for survival analysis while incorporating censored data, which would otherwise have to be dropped. Our experiments on two cancer data sets reveal a superb performance on target domains, a better treatment recommendation, and a weight matrix with a plausible explanation.","https://ojs.aaai.org/index.php/AAAI/article/view/26165/25937"
"26166","What Do You MEME? Generating Explanations for Visual Semantic Role Labelling in Memes","['Shivam Sharma', 'Siddhant Agarwal', 'Tharun Suresh', 'Preslav Nakov', 'Md. Shad Akhtar', 'Tanmoy Chakraborty']","['Indraprastha Institute of Information Technology - Delhi\nWipro AI Labs (Lab45)', 'Indraprastha Institute of Information Technology, Delhi', 'Indraprastha Institute of Information Technology - Delhi', 'Mohamed bin Zayed University of Artificial Intelligence', 'Indraprastha Institute of Information Technology - Delhi', 'Indian Institute of Technology Delhi']","['ML: Multimodal Learning', 'CV: Language and Vision', 'CV: Multi-modal Vision', 'APP: Humanities & Computational Social Science', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'PEAI: Societal Impact of AI', 'SNLP: Generation']","Sharma, S., Agarwal, S., Suresh, T., Nakov, P., Akhtar, M. S., & Chakraborty, T. (2023). What Do You MEME? Generating Explanations for Visual Semantic Role Labelling in Memes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9763-9771. https://doi.org/10.1609/aaai.v37i8.26166","Abstract 					Memes are powerful means for effective communication on social media. Their effortless amalgamation of viral visuals and compelling messages can have far-reaching implications with proper marketing. Previous research on memes has primarily focused on characterizing their affective spectrum and detecting whether the meme's message insinuates any intended harm, such as hate, offense, racism, etc. However, memes often use abstraction, which can be elusive. Here, we introduce a novel task - EXCLAIM, generating explanations for visual semantic role labeling in memes. To this end, we curate ExHVV, a novel dataset that offers natural language explanations of connotative roles for three types of entities - heroes, villains, and victims, encompassing 4,680 entities present in 3K memes. We also benchmark ExHVV with several strong unimodal and multimodal baselines. Moreover, we posit LUMEN, a novel multimodal, multi-task learning framework that endeavors to address EXCLAIM optimally by jointly learning to predict the correct semantic roles and correspondingly to generate suitable natural language explanations. LUMEN distinctly outperforms the best baseline across 18 standard natural language generation evaluation metrics. Our systematic evaluation and analyses demonstrate that characteristic multimodal cues required for adjudicating semantic roles are also helpful for generating suitable explanations.","https://ojs.aaai.org/index.php/AAAI/article/view/26166/25938"
"26167","Post-hoc Uncertainty Learning Using a Dirichlet Meta-Model","['Maohao Shen', 'Yuheng Bu', 'Prasanna Sattigeri', 'Soumya Ghosh', 'Subhro Das', 'Gregory Wornell']","['MIT', 'University of Florida', 'IBM Research', 'IBM Research', 'MIT-IBM Watson AI Lab, IBM Research', 'MIT']","['ML: Calibration & Uncertainty Quantification']","Shen, M., Bu, Y., Sattigeri, P., Ghosh, S., Das, S., & Wornell, G. (2023). Post-hoc Uncertainty Learning Using a Dirichlet Meta-Model. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9772-9781. https://doi.org/10.1609/aaai.v37i8.26167","Abstract 					It is known that neural networks have the problem of being over-confident when directly using the output label distribution to generate uncertainty measures. Existing methods mainly resolve this issue by retraining the entire model to impose the uncertainty quantification capability so that the learned model can achieve desired performance in accuracy and uncertainty prediction simultaneously. However, training the model from scratch is computationally expensive, and a trade-off might exist between prediction accuracy and uncertainty quantification. To this end, we consider a more practical post-hoc uncertainty learning setting, where a well-trained base model is given, and we focus on the uncertainty quantification task at the second stage of training. We propose a novel Bayesian uncertainty learning approach using the Dirichlet meta-model, which is effective and computationally efficient. Our proposed method requires no additional training data and is flexible enough to quantify different uncertainties and easily adapt to different application settings, including out-of-domain data detection, misclassification detection, and trustworthy transfer learning. Finally, we demonstrate our proposed meta-model approach's flexibility and superior empirical performance on these applications over multiple representative image classification benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/26167/25939"
"26168","Neighbor Contrastive Learning on Learnable Graph Augmentation","['Xiao Shen', 'Dewang Sun', 'Shirui Pan', 'Xi Zhou', 'Laurence T. Yang']","['Hainan University', 'Hainan University', 'Griffith University', 'Hainan University', 'Hainan University\nSt. Francis Xavier University']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'APP: Social Networks', 'ML: Representation Learning', 'ML: Semi-Supervised Learning', 'ML: Unsupervised & Self-Supervised Learning']","Shen, X., Sun, D., Pan, S., Zhou, X., & Yang, L. T. (2023). Neighbor Contrastive Learning on Learnable Graph Augmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9782-9791. https://doi.org/10.1609/aaai.v37i8.26168","Abstract 					Recent years, graph contrastive learning (GCL), which aims to learn representations from unlabeled graphs, has made great progress. However, the existing GCL methods mostly adopt human-designed graph augmentations, which are sensitive to various graph datasets. In addition, the contrastive losses originally developed in computer vision have been directly applied to graph data, where the neighboring nodes are regarded as negatives and consequently pushed far apart from the anchor. However, this is contradictory with the homophily assumption of net-works that connected nodes often belong to the same class and should be close to each other. In this work, we propose an end-to-end automatic GCL method, named NCLA to apply neighbor contrastive learning on learnable graph augmentation. Several graph augmented views with adaptive topology are automatically learned by the multi-head graph attention mechanism, which can be compatible with various graph datasets without prior domain knowledge. In addition, a neighbor contrastive loss is devised to allow multiple positives per anchor by taking network topology as the supervised signals. Both augmentations and embeddings are learned end-to-end in the proposed NCLA. Extensive experiments on the benchmark datasets demonstrate that NCLA yields the state-of-the-art node classification performance on self-supervised GCL and even exceeds the supervised ones, when the labels are extremely limited. Our code is released at https://github.com/shenxiaocam/NCLA.","https://ojs.aaai.org/index.php/AAAI/article/view/26168/25940"
"26169","ProxyBO: Accelerating Neural Architecture Search via Bayesian Optimization with Zero-Cost Proxies","['Yu Shen', 'Yang Li', 'Jian Zheng', 'Wentao Zhang', 'Peng Yao', 'Jixiang Li', 'Sen Yang', 'Ji Liu', 'Bin Cui']","['Key Lab of High Confidence Software Technologies, Peking University, China\nKuaishou Technology, China', 'Data Platform, TEG, Tencent Inc., China', 'School of Computer Science and Engineering, Beihang University, China', 'Mila - Quebec AI Institute\nHEC, Montreal, Canada', 'Kuaishou Technology, China', 'Kuaishou Technology, China', 'Kuaishou Technology, China', 'Kuaishou Technology, China', 'Key Lab of High Confidence Software Technologies, Peking University, China\nInstitute of Computational Social Science, Peking University (Qingdao), China']","['ML: Auto ML and Hyperparameter Tuning', 'SO: Algorithm Configuration']","Shen, Y., Li, Y., Zheng, J., Zhang, W., Yao, P., Li, J., Yang, S., Liu, J., & Cui, B. (2023). ProxyBO: Accelerating Neural Architecture Search via Bayesian Optimization with Zero-Cost Proxies. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9792-9801. https://doi.org/10.1609/aaai.v37i8.26169","Abstract 					Designing neural architectures requires immense manual efforts. This has promoted the development of neural architecture search (NAS) to automate the design. While previous NAS methods achieve promising results but run slowly, zero-cost proxies run extremely fast but are less promising. Therefore, it’s of great potential to accelerate NAS via those zero-cost proxies. The existing method has two limitations, which are unforeseeable reliability and one-shot usage. To address the limitations, we present ProxyBO, an efficient Bayesian optimization (BO) framework that utilizes the zero-cost proxies to accelerate neural architecture search. We apply the generalization ability measurement to estimate the fitness of proxies on the task during each iteration and design a novel acquisition function to combine BO with zero-cost proxies based on their dynamic influence. Extensive empirical studies show that ProxyBO consistently outperforms competitive baselines on five tasks from three public benchmarks. Concretely, ProxyBO achieves up to 5.41× and 3.86× speedups over the state-of-the-art approaches REA and BRP-NAS.","https://ojs.aaai.org/index.php/AAAI/article/view/26169/25941"
"26170","Contrastive Predictive Autoencoders for Dynamic Point Cloud Self-Supervised Learning","['Xiaoxiao Sheng', 'Zhiqiang Shen', 'Gang Xiao']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['ML: Unsupervised & Self-Supervised Learning', 'CV: 3D Computer Vision', 'CV: Video Understanding & Activity Analysis', 'CV: Biometrics', 'Face', 'Gesture & Pose']","Sheng, X., Shen, Z., & Xiao, G. (2023). Contrastive Predictive Autoencoders for Dynamic Point Cloud Self-Supervised Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9802-9810. https://doi.org/10.1609/aaai.v37i8.26170","Abstract 					We present a new self-supervised paradigm on point cloud sequence understanding. Inspired by the discriminative and generative self-supervised methods, we design two tasks, namely point cloud sequence based Contrastive Prediction and Reconstruction (CPR), to collaboratively learn more comprehensive spatiotemporal representations. Specifically, dense point cloud segments are first input into an encoder to extract embeddings. All but the last ones are then aggregated by a context-aware autoregressor to make predictions for the last target segment. Towards the goal of modeling multi-granularity structures, local and global contrastive learning are performed between predictions and targets. To further improve the generalization of representations, the predictions are also utilized to reconstruct raw point cloud sequences by a decoder, where point cloud colorization is employed to discriminate against different frames. By combining classic contrast and reconstruction paradigms, it makes the learned representations with both global discrimination and local perception. We conduct experiments on four point cloud sequence benchmarks, and report the results on action recognition and gesture recognition under multiple experimental settings. The performances are comparable with supervised methods and show powerful transferability.","https://ojs.aaai.org/index.php/AAAI/article/view/26170/25942"
"26171","Fixed-Weight Difference Target Propagation","['Tatsukichi Shibuya', 'Nakamasa Inoue', 'Rei Kawakami', 'Ikuro Sato']","['Tokyo Institute of Technology', 'Tokyo Institute of Technology', 'Tokyo Institute of Technology', 'Tokyo Institute of Technology\nDenso IT Laboratory']","['ML: Deep Neural Network Algorithms', 'ML: Bio-Inspired Learning']","Shibuya, T., Inoue, N., Kawakami, R., & Sato, I. (2023). Fixed-Weight Difference Target Propagation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9811-9819. https://doi.org/10.1609/aaai.v37i8.26171","Abstract 					Target Propagation (TP) is a biologically more plausible algorithm than the error backpropagation (BP) to train deep networks, and improving practicality of TP is an open issue. TP methods  require the feedforward and feedback networks to form layer-wise autoencoders for propagating the target values generated at the output layer. However, this causes certain drawbacks; e.g., careful hyperparameter tuning is required to synchronize the feedforward and feedback training, and frequent updates of the feedback path are usually required than that of the feedforward path. Learning of the feedforward and feedback networks is sufficient to make TP methods capable of training, but is having these layer-wise autoencoders a necessary condition for TP to work? We answer this question by presenting Fixed-Weight Difference Target Propagation (FW-DTP) that keeps the feedback weights constant during training. We confirmed that this simple method, which naturally resolves the abovementioned problems of TP, can still deliver informative target values to hidden layers for a given task; indeed, FW-DTP consistently achieves higher test performance than a baseline, the Difference Target Propagation (DTP), on four classification datasets. We also present a novel propagation architecture that explains the exact form of the feedback function of DTP to analyze FW-DTP. Our code is available at https://github.com/TatsukichiShibuya/Fixed-Weight-Difference-Target-Propagation.","https://ojs.aaai.org/index.php/AAAI/article/view/26171/25943"
"26172","Concurrent Multi-Label Prediction in Event Streams","['Xiao Shou', 'Tian Gao', 'Dharmashankar Subramanian', 'Debarun Bhattacharjya', 'Kristin P. Bennett']","['Rensselaer Polytechnic Institute', 'IBM Research', 'IBM Research', 'IBM Research', 'Rensselaer Polytechnic Institute']","['ML: Time-Series/Data Streams', 'DMKM: Data Stream Mining', 'ML: Graph-based Machine Learning', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'RU: Graphical Model']","Shou, X., Gao, T., Subramanian, D., Bhattacharjya, D., & Bennett, K. P. (2023). Concurrent Multi-Label Prediction in Event Streams. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9820-9828. https://doi.org/10.1609/aaai.v37i8.26172","Abstract 					Streams of irregularly occurring events are commonly modeled as a marked temporal point process. Many real-world datasets such as e-commerce transactions and electronic health records often involve events where multiple event types co-occur, e.g. multiple items purchased or multiple diseases diagnosed simultaneously. In this paper, we tackle multi-label prediction in such a problem setting, and propose a novel Transformer-based Conditional Mixture of Bernoulli Network (TCMBN) that leverages neural density estimation to capture complex temporal dependence as well as probabilistic dependence between concurrent event types. We also propose potentially incorporating domain knowledge in the objective by regularizing the predicted probability. To represent probabilistic dependence of concurrent event types graphically, we design a two-step approach that first learns the mixture of Bernoulli network and then solves a least-squares semi-definite constrained program to numerically approximate the sparse precision matrix from a learned covariance matrix. This approach proves to be effective for event prediction while also providing an interpretable and possibly non-stationary structure for insights into event co-occurrence. We demonstrate the superior performance of our approach compared to existing baselines on multiple synthetic and real benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/26172/25944"
"26173","A Generalized Unbiased Risk Estimator for Learning with Augmented Classes","['Senlin Shu', 'Shuo He', 'Haobo Wang', 'Hongxin Wei', 'Tao Xiang', 'Lei Feng']","['Chongqing University', 'University of Electronic Science and Technology of China', 'Zhejiang University', 'Nanyang Technological University', 'Chongqing University', 'Nanyang Technological University']","['ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Classification and Regression', 'ML: Semi-Supervised Learning']","Shu, S., He, S., Wang, H., Wei, H., Xiang, T., & Feng, L. (2023). A Generalized Unbiased Risk Estimator for Learning with Augmented Classes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9829-9836. https://doi.org/10.1609/aaai.v37i8.26173","Abstract 					In contrast to the standard learning paradigm where all classes can be observed in training data, learning with augmented classes (LAC) tackles the problem where augmented classes unobserved in the training data may emerge in the test phase. Previous research showed that given unlabeled data, an unbiased risk estimator (URE) can be derived, which can be minimized for LAC with theoretical guarantees. However, this URE is only restricted to the specific type of one-versus-rest loss functions for multi-class classification, making it not flexible enough when the loss needs to be changed with the dataset in practice. In this paper, we propose a generalized URE that can be equipped with arbitrary loss functions while maintaining the theoretical guarantees, given unlabeled data for LAC. To alleviate the issue of negative empirical risk commonly encountered by previous studies, we further propose a novel risk-penalty regularization term. Experiments demonstrate the effectiveness of our proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/26173/25945"
"26174","Logical Satisfiability of Counterfactuals for Faithful Explanations in NLI","['Suzanna Sia', 'Anton Belyy', 'Amjad Almahairi', 'Madian Khabsa', 'Luke Zettlemoyer', 'Lambert Mathias']","['Johns Hopkins University', 'Johns Hopkins University', 'Meta AI', 'Meta AI', 'Meta AI', 'Meta AI']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'CV: Language and Vision']","Sia, S., Belyy, A., Almahairi, A., Khabsa, M., Zettlemoyer, L., & Mathias, L. (2023). Logical Satisfiability of Counterfactuals for Faithful Explanations in NLI. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9837-9845. https://doi.org/10.1609/aaai.v37i8.26174","Abstract 					Evaluating an explanation's faithfulness is desired for many reasons such as trust, interpretability and diagnosing the sources of model's errors. In this work, which focuses on the NLI task, we introduce the methodology of Faithfulness-through-Counterfactuals, which first generates a counterfactual hypothesis based on the logical predicates expressed in the explanation, and then evaluates if the model's prediction on the counterfactual is consistent with that expressed logic (i.e. if the new formula is \textit{logically satisfiable}). In contrast to existing approaches, this does not require any explanations for training a separate verification model. We first validate the efficacy of automatic counterfactual hypothesis generation, leveraging on the few-shot priming paradigm. Next, we show that our proposed metric distinguishes between human-model agreement and disagreement on new counterfactual input. In addition, we conduct a sensitivity analysis to validate that our metric is sensitive to unfaithful explanations.","https://ojs.aaai.org/index.php/AAAI/article/view/26174/25946"
"26175","SLIQ: Quantum Image Similarity Networks on Noisy Quantum Computers","['Daniel Silver', 'Tirthak Patel', 'Aditya Ranjan', 'Harshitta Gandhi', 'William Cutler', 'Devesh Tiwari']","['Northeastern University', 'Northeastern University', 'Northeastern University', 'Northeastern University', 'Northeastern University', 'Northeastern University']","['ML: Quantum Machine Learning']","Silver, D., Patel, T., Ranjan, A., Gandhi, H., Cutler, W., & Tiwari, D. (2023). SLIQ: Quantum Image Similarity Networks on Noisy Quantum Computers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9846-9854. https://doi.org/10.1609/aaai.v37i8.26175","Abstract 					Exploration into quantum machine learning has grown tremendously in recent years due to the ability of quantum computers to speed up classical programs. However, these ef- forts have yet to solve unsupervised similarity detection tasks due to the challenge of porting them to run on quantum com- puters. To overcome this challenge, we propose SLIQ, the first open-sourced work for resource-efficient quantum sim- ilarity detection networks, built with practical and effective quantum learning and variance-reducing algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26175/25947"
"26176","Adaptive Mixing of Auxiliary Losses in Supervised Learning","['Durga Sivasubramanian', 'Ayush Maheshwari', 'Prathosh AP', 'Pradeep Shenoy', 'Ganesh Ramakrishnan']","['Indian Institute of Technology Bombay\nGoogle Research, India', 'Indian Institute of Technology Bombay', 'Indian Institute of Science, Bengaluru', 'Google Research, India', 'Indian Institute of Technology Bombay']","['ML: Classification and Regression', 'ML: Meta Learning', 'ML: Learning on the Edge & Model Compression']","Sivasubramanian, D., Maheshwari, A., AP, P., Shenoy, P., & Ramakrishnan, G. (2023). Adaptive Mixing of Auxiliary Losses in Supervised Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9855-9863. https://doi.org/10.1609/aaai.v37i8.26176","Abstract 					In many supervised learning scenarios, auxiliary losses are used in order to introduce additional information or constraints into the supervised learning objective. For instance, knowledge distillation aims to mimic outputs of a powerful teacher model; similarly, in rule-based approaches, weak labeling information is provided by labeling functions which may be noisy rule-based approximations to true labels. We tackle the problem of learning to combine these losses in a principled manner. Our proposal, AMAL, uses a bi-level optimization criterion on validation data to learn optimal mixing weights, at an instance-level, over the training data. We describe a meta-learning approach towards solving this bi-level objective, and show how it can be applied to different scenarios in supervised learning. Experiments in a number of knowledge distillation and rule denoising domains show that AMAL provides noticeable gains over competitive baselines in those domains. We empirically analyze our method and share insights into the mechanisms through which it provides performance gains. The code for AMAL is at: https://github.com/durgas16/AMAL.git.","https://ojs.aaai.org/index.php/AAAI/article/view/26176/25948"
"26177","Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in Federated Learning","['Jinhyun So', 'Ramy E. Ali', 'Başak Güler', 'Jiantao Jiao', 'A. Salman Avestimehr']","['University of Southern California', 'University of Southern California', 'University of California, Riverside', 'University of California, Berkeley', 'University of Southern California']","['ML: Privacy-Aware ML', 'PEAI: Privacy and Security']","So, J., E. Ali, R., Güler, B., Jiao, J., & Avestimehr, A. S. (2023). Securing Secure Aggregation: Mitigating Multi-Round Privacy Leakage in Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9864-9873. https://doi.org/10.1609/aaai.v37i8.26177","Abstract 					Secure aggregation is a critical component in federated learning (FL), which enables the server to learn the aggregate model of the users without observing their local models. Conventionally, secure aggregation algorithms focus only on ensuring the privacy of individual users in a single training round. We contend that such designs can lead to significant privacy leakages over multiple training rounds, due to partial user selection/participation at each round of FL. In fact, we show that the conventional random user selection strategies in FL lead to leaking users' individual models within number of rounds that is linear in the number of users. To address this challenge, we introduce a secure aggregation framework, Multi-RoundSecAgg, with multi-round privacy guarantees. In particular, we introduce a new metric to quantify the privacy guarantees of FL over multiple training rounds, and develop a structured user selection strategy that guarantees the long-term privacy of each user (over any number of training rounds).  Our framework also carefully accounts for the fairness and the average number of participating users at each round. Our experiments on MNIST, CIFAR-10 and CIFAR-100 datasets in the IID and the non-IID settings demonstrate the performance improvement over the baselines, both in terms of privacy protection and test accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/26177/25949"
"26178","Mixture Manifold Networks: A Computationally Efficient Baseline for Inverse Modeling","['Gregory P. Spell', 'Simiao Ren', 'Leslie M. Collins', 'Jordan M. Malof']","['Duke University', 'Duke University', 'Duke University', 'University of Montana']","['ML: Applications', 'ML: Deep Neural Network Algorithms', 'APP: Design']","Spell, G. P., Ren, S., Collins, L. M., & Malof, J. M. (2023). Mixture Manifold Networks: A Computationally Efficient Baseline for Inverse Modeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9874-9881. https://doi.org/10.1609/aaai.v37i8.26178","Abstract 					We propose and show the efficacy of a new method to address generic inverse problems. Inverse modeling is the task whereby one seeks to determine the hidden parameters of a natural system that produce a given set of observed measurements. Recent work has shown impressive results using deep learning, but we note that there is a trade-off between model performance and computational time. For some applications, the computational time at inference for the best performing inverse modeling method may be overly prohibitive to its use. In seeking a faster, high-performing model, we present a new method that leverages multiple manifolds as a mixture of backward (e.g., inverse) models in a forward-backward model architecture. These multiple backwards models all share a common forward model, and their training is mitigated by generating training examples from the forward model. The proposed method thus has two innovations: 1) the multiple Manifold Mixture Network (MMN) architecture, and 2) the training procedure involving augmenting backward model training data using the forward model. We demonstrate the advantages of our method by comparing to several baselines on four benchmark inverse problems, and we furthermore provide analysis to motivate its design.","https://ojs.aaai.org/index.php/AAAI/article/view/26178/25950"
"26179","Sharing Pattern Submodels for Prediction with Missing Values","['Lena Stempfle', 'Ashkan Panahi', 'Fredrik D. Johansson']","['Chalmers University of Technology, Gothenburg, Sweden', 'Chalmers University of Technology, Gothenburg, Sweden', 'Chalmers University of Technology, Gothenburg, Sweden']","['ML: Classification and Regression', 'APP: Healthcare', 'Medicine & Wellness', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'RU: Other Foundations of Reasoning Under Uncertainty']","Stempfle, L., Panahi, A., & Johansson, F. D. (2023). Sharing Pattern Submodels for Prediction with Missing Values. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9882-9890. https://doi.org/10.1609/aaai.v37i8.26179","Abstract 					Missing values are unavoidable in many applications of machine learning and present challenges both during training and at test time. When variables are missing in recurring patterns, fitting separate pattern submodels have been proposed as a solution. However, fitting models independently does not make efficient use of all available data. Conversely, fitting a single shared model to the full data set relies on imputation which often leads to biased results when missingness depends on unobserved factors. We propose an alternative approach, called sharing pattern submodels (SPSM), which i) makes predictions that are robust to missing values at test time, ii) maintains or improves the predictive power of pattern submodels, and iii) has a short description, enabling improved interpretability. Parameter sharing is enforced through sparsity-inducing regularization which we prove leads to consistent estimation. Finally, we give conditions for when a sharing model is optimal, even when both missingness and the target outcome depend on unobserved variables. Classification and regression experiments on synthetic and real-world data sets demonstrate that our models achieve a favorable tradeoff between pattern specialization and information sharing.","https://ojs.aaai.org/index.php/AAAI/article/view/26179/25951"
"26180","Scalable Optimal Multiway-Split Decision Trees with Constraints","['Shivaram Subramanian', 'Wei Sun']","['IBM Research', 'IBM Research']","['ML: Classification and Regression', 'ML: Applications', 'ML: Optimization']","Subramanian, S., & Sun, W. (2023). Scalable Optimal Multiway-Split Decision Trees with Constraints. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9891-9899. https://doi.org/10.1609/aaai.v37i8.26180","Abstract 					There has been a surge of interest in learning optimal decision trees using mixed-integer programs (MIP) in recent years, as heuristic-based methods do not guarantee optimality and find it challenging to incorporate constraints that are critical for many practical applications.  However, existing MIP methods that build on an arc-based formulation do not scale well as the number of binary variables is in the order of 2 to the power of the depth of the tree and the size of the dataset. Moreover, they can only handle sample-level constraints and linear metrics. In this paper, we propose a novel path-based MIP formulation where the number of decision variables is independent of dataset size. We present a scalable column generation framework to solve the MIP. Our framework produces a multiway-split tree which is more interpretable than the typical binary-split trees due to its shorter rules. Our framework is more general as it can handle nonlinear metrics such as F1 score, and incorporate a broader class of constraints. We demonstrate its efficacy with extensive experiments. We present results on datasets containing up to 1,008,372  samples while existing MIP-based decision tree models do not scale well on data beyond a few thousand points. We report superior or competitive results compared to the state-of-art MIP-based methods with up to a 24X reduction in runtime.","https://ojs.aaai.org/index.php/AAAI/article/view/26180/25952"
"26181","REMIT: Reinforced Multi-Interest Transfer for Cross-Domain Recommendation","['Caiqi Sun', 'Jiewei Gu', 'Binbin Hu', 'Xin Dong', 'Hai Li', 'Lei Cheng', 'Linjian Mo']","['Ant Group', 'Ant Group\nSchool of Data Science, Fudan University', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Antgroup']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Reinforcement Learning Algorithms', 'ML: Representation Learning']","Sun, C., Gu, J., Hu, B., Dong, X., Li, H., Cheng, L., & Mo, L. (2023). REMIT: Reinforced Multi-Interest Transfer for Cross-Domain Recommendation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9900-9908. https://doi.org/10.1609/aaai.v37i8.26181","Abstract 					Cold-start problem is one of the most challenging problems for recommender systems. One promising solution to this problem is cross-domain recommendation (CDR) which leverages rich information from an auxiliary source domain to improve the performance of recommender system in the target domain. In particular, the family of embedding and mapping methods for CDR is very effective, which explicitly learn a mapping function from source embeddings to target embeddings to transfer user’s preferences. Recent works usually transfer an overall source embedding by modeling a common or personalized preference bridge for all users. However, a unified user embedding cannot reflect the user’s multiple interests in auxiliary source domain. In this paper, we propose a novel framework called reinforced multi-interest transfer for CDR (REMIT). Specifically, we first construct a heterogeneous information network and employ different meta-path based aggregations to get user’s multiple interests in source domain, then transform different interest embeddings with different meta-generated personalized bridge functions for each user. To better coordinate the transformed user interest embeddings and the item embedding in target domain, we systematically develop a reinforced method to dynamically assign weights to transformed interests for different training instances and optimize the performance of target model. In addition, the REMIT is a general framework that can be applied upon various base models in target domain. Our extensive experimental results on large real-world datasets demonstrate the superior performance and compatibility of REMIT.","https://ojs.aaai.org/index.php/AAAI/article/view/26181/25953"
"26182","Cooperative and Adversarial Learning: Co-enhancing Discriminability and Transferability in Domain Adaptation","['Hui Sun', 'Zheng Xie', 'Xin-Ye Li', 'Ming Li']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Representation Learning']","Sun, H., Xie, Z., Li, X.-Y., & Li, M. (2023). Cooperative and Adversarial Learning: Co-enhancing Discriminability and Transferability in Domain Adaptation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9909-9917. https://doi.org/10.1609/aaai.v37i8.26182","Abstract 					Discriminability and transferability are two goals of feature learning for domain adaptation (DA), as we aim to find the transferable features from the source domain that are helpful for discriminating the class label in the target domain. Modern DA approaches optimize discriminability and transferability by adopting two separate modules for the two goals upon a feature extractor, but lack fully exploiting their relationship. This paper argues that by letting the discriminative module and transfer module help each other, better DA can be achieved. We propose Cooperative and Adversarial LEarning (CALE) to combine the optimization of discriminability and transferability into a whole, provide one solution for making the discriminative module and transfer module guide each other. Specifically, CALE generates cooperative (easy) examples and adversarial (hard) examples with both discriminative module and transfer module. While the easy examples that contain the module knowledge can be used to enhance each other, the hard ones are used to enhance the robustness of the corresponding goal. Experimental results show the effectiveness of CALE for unifying the learning of discriminability and transferability, as well as its superior performance.","https://ojs.aaai.org/index.php/AAAI/article/view/26182/25954"
"26183","Fair-CDA: Continuous and Directional Augmentation for Group Fairness","['Rui Sun', 'Fengwei Zhou', 'Zhenhua Dong', 'Chuanlong Xie', 'Lanqing Hong', 'Jiawei Li', 'Rui Zhang', 'Zhen Li', 'Zhenguo Li']","['The Chinese University of Hong Kong, Shenzhen', ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", 'Beijing Normal University', ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", 'Tsinghua University', 'The Chinese University of Hong Kong, Shenzhen', ""Huawei Noah's Ark Lab""]","['ML: Bias and Fairness']","Sun, R., Zhou, F., Dong, Z., Xie, C., Hong, L., Li, J., Zhang, R., Li, Z., & Li, Z. (2023). Fair-CDA: Continuous and Directional Augmentation for Group Fairness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9918-9926. https://doi.org/10.1609/aaai.v37i8.26183","Abstract 					In this work, we propose Fair-CDA, a fine-grained data augmentation strategy for imposing fairness constraints. We use a feature disentanglement method to extract the features highly related to the sensitive attributes. Then we show that group fairness can be achieved by regularizing the models on transition paths of sensitive features between groups. By adjusting the perturbation strength in the direction of the paths, our proposed augmentation is controllable and auditable. To alleviate the accuracy degradation caused by fairness constraints, we further introduce a calibrated model to impute labels for the augmented data. Our proposed method does not assume any data generative model and ensures good generalization for both accuracy and fairness. Experimental results show that Fair-CDA consistently outperforms state-of-the-art methods on widely-used benchmarks, e.g., Adult, CelebA and MovieLens. Especially, Fair-CDA obtains an 86.3% relative improvement for fairness while maintaining the accuracy on the Adult dataset. Moreover, we evaluate Fair-CDA in an online recommendation system to demonstrate the effectiveness of our method in terms of accuracy and fairness.","https://ojs.aaai.org/index.php/AAAI/article/view/26183/25955"
"26184","Neural Spline Search for Quantile Probabilistic Modeling","['Ruoxi Sun', 'Chun-Liang Li', 'Sercan Ö. Arik', 'Michael W. Dusenberry', 'Chen-Yu Lee', 'Tomas Pfister']","['Google', 'Google', 'Google', 'Google', 'Google', 'Google']","['ML: Time-Series/Data Streams', 'CMS: Applications', 'ML: Probabilistic Methods']","Sun, R., Li, C.-L., Arik, S. Ö., Dusenberry, M. W., Lee, C.-Y., & Pfister, T. (2023). Neural Spline Search for Quantile Probabilistic Modeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9927-9934. https://doi.org/10.1609/aaai.v37i8.26184","Abstract 					Accurate estimation of output quantiles is crucial in many use cases, where it is desired to model the range of possibility. Modeling target distribution at arbitrary quantile levels and at arbitrary input attribute levels are important to offer a comprehensive picture of the data, and requires the quantile function to be expressive enough. The quantile function describing the target distribution using quantile levels is critical for quantile regression. Although various parametric forms for the distributions (that the quantile function specifies) can be adopted, an everlasting problem is selecting the most appropriate one that can properly approximate the data distributions. In this paper, we propose a non-parametric and data-driven approach, Neural Spline Search (NSS), to represent the observed data distribution without parametric assumptions. NSS is flexible and expressive for modeling data distributions by transforming the inputs with a series of monotonic spline regressions guided by symbolic operators. We demonstrate that NSS outperforms previous methods on synthetic, real-world regression and time-series forecasting tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26184/25956"
"26185","Domain Adaptation with Adversarial Training on Penultimate Activations","['Tao Sun', 'Cheng Lu', 'Haibin Ling']","['Stony Brook University', 'XPeng Motors', 'Stony Brook University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Adversarial Learning & Robustness', 'ML: Classification and Regression']","Sun, T., Lu, C., & Ling, H. (2023). Domain Adaptation with Adversarial Training on Penultimate Activations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9935-9943. https://doi.org/10.1609/aaai.v37i8.26185","Abstract 					Enhancing model prediction confidence on target data is an important objective in Unsupervised Domain Adaptation (UDA). In this paper, we explore adversarial training on penultimate activations, i.e., input features of the final linear classification layer. We show that this strategy is more efficient and better correlated with the objective of boosting prediction confidence than adversarial training on input images or intermediate features, as used in previous works. Furthermore, with activation normalization  commonly used in domain adaptation to reduce domain gap, we derive two variants and systematically analyze the effects of normalization on our adversarial training. This is illustrated both in theory and through empirical analysis on real adaptation tasks. Extensive experiments are conducted on popular UDA benchmarks under both standard setting and source-data free setting. The results validate that our method achieves the best scores against previous arts. Code is available at https://github.com/tsun/APA.","https://ojs.aaai.org/index.php/AAAI/article/view/26185/25957"
"26186","Fast Convergence in Learning Two-Layer Neural Networks with Separable Data","['Hossein Taheri', 'Christos Thrampoulidis']","['University of California, Santa Barbara', 'University of British Columbia']","['ML: Optimization', 'ML: Classification and Regression', 'ML: Learning Theory']","Taheri, H., & Thrampoulidis, C. (2023). Fast Convergence in Learning Two-Layer Neural Networks with Separable Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9944-9952. https://doi.org/10.1609/aaai.v37i8.26186","Abstract 					Normalized gradient descent has shown substantial success in speeding up the convergence of  exponentially-tailed loss functions (which includes exponential and logistic losses) on linear classifiers with separable data.  In this paper, we go beyond linear models by studying normalized GD on two-layer neural nets. We prove for exponentially-tailed losses that using normalized GD leads to linear rate of convergence of the training loss to the global optimum. This is made possible by showing certain gradient self-boundedness conditions and a log-Lipschitzness property. We also study generalization of normalized GD for convex objectives via an algorithmic-stability analysis. In particular, we show that normalized GD does not overfit during training by establishing finite-time generalization bounds.","https://ojs.aaai.org/index.php/AAAI/article/view/26186/25958"
"26187","Federated Learning on Non-IID Graphs via Structural Knowledge Sharing","['Yue Tan', 'Yixin Liu', 'Guodong Long', 'Jing Jiang', 'Qinghua Lu', 'Chengqi Zhang']","['University of Technology Sydney', 'Monash University', 'University of Technology Sydney', 'University of Technology Sydney', 'Data61, CSIRO', 'University of Technology Sydney']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Distributed Machine Learning & Federated Learning']","Tan, Y., Liu, Y., Long, G., Jiang, J., Lu, Q., & Zhang, C. (2023). Federated Learning on Non-IID Graphs via Structural Knowledge Sharing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9953-9961. https://doi.org/10.1609/aaai.v37i8.26187","Abstract 					Graph neural networks (GNNs) have shown their superiority in modeling graph data. Owing to the advantages of federated learning, federated graph learning (FGL) enables clients to train strong GNN models in a distributed manner without sharing their private data. A core challenge in federated systems is the non-IID problem, which also widely exists in real-world graph data. For example, local data of clients may come from diverse datasets or even domains, e.g., social networks and molecules, increasing the difficulty for FGL methods to capture commonly shared knowledge and learn a generalized encoder. From real-world graph datasets, we observe that some structural properties are shared by various domains, presenting great potential for sharing structural knowledge in FGL. Inspired by this, we propose FedStar, an FGL framework that extracts and shares the common underlying structure information for inter-graph federated learning tasks. To explicitly extract the structure information rather than encoding them along with the node features, we define structure embeddings and encode them with an independent structure encoder. Then, the structure encoder is shared across clients while the feature-based knowledge is learned in a personalized way, making FedStar capable of capturing more structure-based domain-invariant information and avoiding feature misalignment issues. We perform extensive experiments over both cross-dataset and cross-domain non-IID FGL settings, demonstrating the superiority of FedStar.","https://ojs.aaai.org/index.php/AAAI/article/view/26187/25959"
"26188","Metric Multi-View Graph Clustering","['Yuze Tan', 'Yixi Liu', 'Hongjie Wu', 'Jiancheng Lv', 'Shudong Huang']","['Sichuan University', 'Sichuan University', 'Sichuan University', 'Sichuan University', 'Sichuan University']","['ML: Clustering', 'ML: Multi-Instance/Multi-View Learning']","Tan, Y., Liu, Y., Wu, H., Lv, J., & Huang, S. (2023). Metric Multi-View Graph Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9962-9970. https://doi.org/10.1609/aaai.v37i8.26188","Abstract 					Graph-based methods have hitherto been used to pursue the coherent patterns of data due to its ease of implementation and efficiency. These methods have been increasingly applied in multi-view learning and achieved promising performance in various clustering tasks. However, despite their noticeable empirical success, existing graph-based multi-view clustering methods may still suffer the suboptimal solution considering that multi-view data can be very complicated in raw feature space. Moreover, existing methods usually adopt the similarity metric by an ad hoc approach, which largely simplifies the relationship among real-world data and results in an inaccurate output. To address these issues, we propose to seamlessly integrates metric learning and graph learning for multi-view clustering. Specifically, we employ a useful metric to depict the inherent structure with linearity-aware of affinity graph representation learned based on the self-expressiveness property. Furthermore, instead of directly utilizing the raw features, we prefer to recover a smooth representation such that the geometric structure of the original data can be retained. We model the above concerns into a unified learning framework, and hence complements each learning subtask in a mutual reinforcement manner. The empirical studies corroborate our theoretical findings, and demonstrate that the proposed method is able to boost the multi-view clustering performance.","https://ojs.aaai.org/index.php/AAAI/article/view/26188/25960"
"26189","DE-net: Dynamic Text-Guided Image Editing Adversarial Networks","['Ming Tao', 'Bing-Kun Bao', 'Hao Tang', 'Fei Wu', 'Longhui Wei', 'Qi Tian']","['Nanjing University Of Posts And Telecommunications', 'Nanjing University of Posts and Telecommunications', 'CVL, ETH Zürich', 'Nanjing University of Posts and Telecommunications', 'Huawei Inc.', 'Huawei Inc.']","['ML: Deep Generative Models & Autoencoders', 'ML: Multimodal Learning']","Tao, M., Bao, B.-K., Tang, H., Wu, F., Wei, L., & Tian, Q. (2023). DE-net: Dynamic Text-Guided Image Editing Adversarial Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9971-9979. https://doi.org/10.1609/aaai.v37i8.26189","Abstract 					Text-guided image editing models have shown remarkable results. However, there remain two problems. First, they employ fixed manipulation modules for various editing requirements (e.g., color changing, texture changing, content adding and removing), which results in over-editing or insufficient editing. Second, they do not clearly distinguish between text-required and text-irrelevant parts, which leads to inaccurate editing. To solve these limitations, we propose: (i) a Dynamic Editing Block (DEBlock) that composes different editing modules dynamically for various editing requirements. (ii) a Composition Predictor (Comp-Pred), which predicts the composition weights for DEBlock according to the inference on target texts and source images. (iii) a Dynamic text-adaptive Convolution Block (DCBlock) that queries source image features to distinguish text-required parts and text-irrelevant parts. Extensive experiments demonstrate that our DE-Net achieves excellent performance and manipulates source images more correctly and accurately.","https://ojs.aaai.org/index.php/AAAI/article/view/26189/25961"
"26190","Knowledge Amalgamation for Multi-Label Classification via Label Dependency Transfer","['Jidapa Thadajarassiri', 'Thomas Hartvigsen', 'Walter Gerych', 'Xiangnan Kong', 'Elke Rundensteiner']","['Worcester Polytechnic Institute', 'MIT', 'Worcester Polytechnic Institute', 'Worcester Polytechnic Institute', 'Worcester Polytechnic Institute']","['ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'KRR: Knowledge Acquisition', 'ML: Ensemble Methods']","Thadajarassiri, J., Hartvigsen, T., Gerych, W., Kong, X., & Rundensteiner, E. (2023). Knowledge Amalgamation for Multi-Label Classification via Label Dependency Transfer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9980-9988. https://doi.org/10.1609/aaai.v37i8.26190","Abstract 					Multi-label classification (MLC), which assigns multiple labels to each instance, is crucial to domains from computer vision to text mining. Conventional methods for MLC require huge amounts of labeled data to capture complex dependencies between labels. However, such labeled datasets are expensive, or even impossible, to acquire. Worse yet, these pre-trained MLC models can only be used for the particular label set covered in the training data. Despite this severe limitation, few methods exist for expanding the set of labels predicted by pre-trained models. Instead, we acquire vast amounts of new labeled data and retrain a new model from scratch. Here, we propose combining the knowledge from multiple pre-trained models (teachers) to train a new student model that covers the union of the labels predicted by this set of teachers. This student supports a broader label set than any one of its teachers without using labeled data. We call this new problem knowledge amalgamation for multi-label classification. Our new method, Adaptive KNowledge Transfer (ANT), trains a student by learning from each teacher’s partial knowledge of label dependencies to infer the global dependencies between all labels across the teachers. We show that ANT succeeds in unifying label dependencies among teachers, outperforming five state-of-the-art methods on eight real-world datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26190/25962"
"26191","Leveraging Contaminated Datasets to Learn Clean-Data Distribution with Purified Generative Adversarial Networks","['Bowen Tian', 'Qinliang Su', 'Jianxing Yu']","['SUN YAT-SEN UNIVERSITY', 'SUN YAT-SEN UNIVERSITY', 'Sun Yat-sen University']","['ML: Deep Generative Models & Autoencoders']","Tian, B., Su, Q., & Yu, J. (2023). Leveraging Contaminated Datasets to Learn Clean-Data Distribution with Purified Generative Adversarial Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9989-9996. https://doi.org/10.1609/aaai.v37i8.26191","Abstract 					Generative adversarial networks (GANs) are known for their strong abilities on capturing the underlying distribution of training instances. Since the seminal work of GAN, many variants of GAN have been proposed. However, existing GANs are almost established on the assumption that the training dataset is clean. But in many real-world applications, this may not hold, that is, the training dataset may be contaminated by a proportion of undesired instances. When training on such datasets, existing GANs will learn a mixture distribution of desired and contaminated instances, rather than the desired distribution of desired data only (target distribution). To learn the target distribution from contaminated datasets, two purified generative adversarial networks (PuriGAN) are developed, in which the discriminators are augmented with the capability to distinguish between target and contaminated instances by leveraging an extra dataset solely composed of contamination instances. We prove that under some mild conditions, the proposed PuriGANs are guaranteed to converge to the distribution of desired instances. Experimental results on several datasets demonstrate that the proposed PuriGANs are able to generate much better images from the desired distribution than comparable baselines when trained on contaminated datasets. In addition, we also demonstrate the usefulness of PuriGAN on downstream applications by applying it to the tasks of semi-supervised anomaly detection on contaminated datasets and PU-learning. Experimental results show that PuriGAN is able to deliver the best performance over comparable baselines on both tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26191/25963"
"26192","Heterogeneous Graph Masked Autoencoders","['Yijun Tian', 'Kaiwen Dong', 'Chunhui Zhang', 'Chuxu Zhang', 'Nitesh V. Chawla']","['Department of Computer Science and Engineering, University of Notre Dame\nLucy Family Institute for Data and Society, University of Notre Dame', 'Department of Computer Science and Engineering, University of Notre Dame\nLucy Family Institute for Data and Society, University of Notre Dame', 'Department of Computer Science, Brandeis University', 'Department of Computer Science, Brandeis University', 'Department of Computer Science and Engineering, University of Notre Dame\nLucy Family Institute for Data and Society, University of Notre Dame']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Unsupervised & Self-Supervised Learning', 'ML: Deep Generative Models & Autoencoders']","Tian, Y., Dong, K., Zhang, C., Zhang, C., & Chawla, N. V. (2023). Heterogeneous Graph Masked Autoencoders. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 9997-10005. https://doi.org/10.1609/aaai.v37i8.26192","Abstract 					Generative self-supervised learning (SSL), especially masked autoencoders, has become one of the most exciting learning paradigms and has shown great potential in handling graph data. However, real-world graphs are always heterogeneous, which poses three critical challenges that existing methods ignore: 1) how to capture complex graph structure? 2) how to incorporate various node attributes? and 3) how to encode different node positions? In light of this, we study the problem of generative SSL on heterogeneous graphs and propose HGMAE, a novel heterogeneous graph masked autoencoder model to address these challenges. HGMAE captures comprehensive graph information via two innovative masking techniques and three unique training strategies. In particular, we first develop metapath masking and adaptive attribute masking with dynamic mask rate to enable effective and stable learning on heterogeneous graphs. We then design several training strategies including metapath-based edge reconstruction to adopt complex structural information, target attribute restoration to incorporate various node attributes, and positional feature prediction to encode node positional information. Extensive experiments demonstrate that HGMAE outperforms both contrastive and generative state-of-the-art baselines on several tasks across multiple datasets. Codes are available at https://github.com/meettyj/HGMAE.","https://ojs.aaai.org/index.php/AAAI/article/view/26192/25964"
"26193","Unbalanced CO-optimal Transport","['Quang Huy Tran', 'Hicham Janati', 'Nicolas Courty', 'Rémi Flamary', 'Ievgen Redko', 'Pinar Demetci', 'Ritambhara Singh']","['Université Bretagne Sud, IRISA\nCMAP, Ecole Polytechnique, IP Paris', 'LTCI, Télécom Paris, IP Paris', 'Université Bretagne Sud, IRISA', 'CMAP, Ecole Polytechnique, IP Paris', 'Univ. Lyon, UJM-Saint-Etienne, CNRS, UMR 5516', 'Center for Computational Molecular Biology, Brown University\nDepartment of Computer Science, Brown University', 'Center for Computational Molecular Biology, Brown University\nDepartment of Computer Science, Brown University']","['ML: Applications', 'CSO: Constraint Optimization', 'APP: Bioinformatics', 'ML: Optimization', 'ML: Other Foundations of Machine Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Tran, Q. H., Janati, H., Courty, N., Flamary, R., Redko, I., Demetci, P., & Singh, R. (2023). Unbalanced CO-optimal Transport. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10006-10016. https://doi.org/10.1609/aaai.v37i8.26193","Abstract 					Optimal transport (OT) compares probability distributions by computing a meaningful alignment between their samples. CO-optimal transport (COOT) takes this comparison further by inferring an alignment between features as well. While this approach leads to better alignments and generalizes both OT and Gromov-Wasserstein distances, we provide a theoretical result showing that it is sensitive to outliers that are omnipresent in real-world data. This prompts us to propose unbalanced COOT for which we provably show its robustness to noise in the compared datasets. To the best of our knowledge, this is the first such result for OT methods in incomparable spaces. With this result in hand, we provide empirical evidence of this robustness for the challenging tasks of heterogeneous domain adaptation with and without varying proportions of classes and simultaneous alignment of samples and features across two single-cell measurements.","https://ojs.aaai.org/index.php/AAAI/article/view/26193/25965"
"26194","Linear Regularizers Enforce the Strict Saddle Property","['Matthew Ubl', 'Matthew Hale', 'Kasra Yazdani']","['University of Florida', 'University of Florida', 'University of Florida']","['ML: Optimization']","Ubl, M., Hale, M., & Yazdani, K. (2023). Linear Regularizers Enforce the Strict Saddle Property. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10017-10024. https://doi.org/10.1609/aaai.v37i8.26194","Abstract 					Satisfaction of the strict saddle property has become a standard assumption in non-convex optimization, and it ensures that many first-order optimization algorithms will almost always escape saddle points. However, functions exist in machine learning that do not satisfy this property, such as the loss function of a neural network with at least two hidden layers. First-order methods such as gradient descent may converge to non-strict saddle points of such functions, and there do not currently exist any first-order methods that reliably escape non-strict saddle points. To address this need, we demonstrate that regularizing a function with a linear term enforces the strict saddle property, and we provide justification for only regularizing locally, i.e., when the norm of the gradient falls below a certain threshold. We analyze bifurcations that may result from this form of regularization, and then we provide a selection rule for regularizers that depends only on the gradient of an objective function. This rule is shown to guarantee that gradient descent will escape the neighborhoods around a broad class of non-strict saddle points, and this behavior is demonstrated on numerical examples of non-strict saddle points common in the optimization literature.","https://ojs.aaai.org/index.php/AAAI/article/view/26194/25966"
"26195","Policy-Adaptive Estimator Selection for Off-Policy Evaluation","['Takuma Udagawa', 'Haruka Kiyohara', 'Yusuke Narita', 'Yuta Saito', 'Kei Tateno']","['Sony Group Corporation', 'Tokyo Institute of Technology', 'Yale University', 'Cornell University', 'Sony Group Corporation']","['ML: Causal Learning', 'DMKM: Recommender Systems', 'RU: Causality', 'RU: Sequential Decision Making']","Udagawa, T., Kiyohara, H., Narita, Y., Saito, Y., & Tateno, K. (2023). Policy-Adaptive Estimator Selection for Off-Policy Evaluation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10025-10033. https://doi.org/10.1609/aaai.v37i8.26195","Abstract 					Off-policy evaluation (OPE) aims to accurately evaluate the performance of counterfactual policies using only offline logged data. Although many estimators have been developed, there is no single estimator that dominates the others, because the estimators' accuracy can vary greatly depending on a given OPE task such as the evaluation policy, number of actions, and noise level. Thus, the data-driven estimator selection problem is becoming increasingly important and can have a significant impact on the accuracy of OPE. However, identifying the most accurate estimator using only the logged data is quite challenging because the ground-truth estimation accuracy of estimators is generally unavailable. This paper thus studies this challenging problem of estimator selection for OPE for the first time. In particular, we enable an estimator selection that is adaptive to a given OPE task, by appropriately subsampling available logged data and constructing pseudo policies useful for the underlying estimator selection task. Comprehensive experiments on both synthetic and real-world company data demonstrate that the proposed procedure substantially improves the estimator selection compared to a non-adaptive heuristic. Note that  complete version with technical appendix is available on arXiv: http://arxiv.org/abs/2211.13904.","https://ojs.aaai.org/index.php/AAAI/article/view/26195/25967"
"26196","A Fair Generative Model Using LeCam Divergence","['Soobin Um', 'Changho Suh']","['KAIST', 'KAIST']","['ML: Bias and Fairness', 'CV: Bias', 'Fairness & Privacy', 'ML: Deep Generative Models & Autoencoders', 'ML: Deep Neural Network Algorithms']","Um, S., & Suh, C. (2023). A Fair Generative Model Using LeCam Divergence. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10034-10042. https://doi.org/10.1609/aaai.v37i8.26196","Abstract 					We explore a fairness-related challenge that arises in generative models. The challenge is that biased training data with imbalanced demographics may yield a high asymmetry in size of generated samples across distinct groups. We focus on practically-relevant scenarios wherein demographic labels are not available and therefore the design of a fair generative model is non-straightforward. In this paper, we propose an optimization framework that regulates the unfairness under such practical settings via one statistical measure, LeCam (LC)-divergence. Specifically to quantify the degree of unfairness, we employ a balanced-yet-small reference dataset and then measure its distance with generated samples using the LC-divergence, which is shown to be particularly instrumental to a small size of the reference dataset. We take a variational optimization approach to implement the LC-based measure. Experiments on benchmark real datasets demonstrate that the proposed framework can significantly improve the fairness performance while maintaining realistic sample quality for a wide range of the reference set size all the way down to 1% relative to training set.","https://ojs.aaai.org/index.php/AAAI/article/view/26196/25968"
"26197","Efficient Distribution Similarity Identification in Clustered Federated Learning via Principal Angles between Client Data Subspaces","['Saeed Vahidian', 'Mahdi Morafah', 'Weijia Wang', 'Vyacheslav Kungurtsev', 'Chen Chen', 'Mubarak Shah', 'Bill Lin']","['University of California San Diego', 'University of California San Diego', 'University of California San Diego', 'Czech Technical University', 'University of Central Florida', 'University of Central Florida', 'University of California San Diego']","['ML: Deep Neural Network Algorithms', 'ML: Distributed Machine Learning & Federated Learning']","Vahidian, S., Morafah, M., Wang, W., Kungurtsev, V., Chen, C., Shah, M., & Lin, B. (2023). Efficient Distribution Similarity Identification in Clustered Federated Learning via Principal Angles between Client Data Subspaces. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10043-10052. https://doi.org/10.1609/aaai.v37i8.26197","Abstract 					Clustered federated learning (FL) has been shown to produce promising results by grouping clients into clusters. This is especially effective in scenarios where separate groups of clients have significant differences in the distributions of their local data. Existing clustered FL algorithms are essentially trying to group together clients with similar distributions so that clients in the same cluster can leverage each other's data to better perform federated learning. However, prior clustered FL algorithms attempt to learn these distribution similarities indirectly during training, which can be quite time consuming as many rounds of federated learning may be required until the formation of clusters is stabilized. In this paper, we propose a new approach to federated learning that directly aims to efficiently identify distribution similarities among clients by analyzing the principal angles between the client data subspaces. Each client applies a truncated singular value decomposition (SVD) step on its local data in a single-shot manner to derive a small set of principal vectors, which provides a signature that succinctly captures the main characteristics of the underlying distribution. This small set of principal vectors is provided to the server so that the server can directly identify distribution similarities among the clients to form clusters. This is achieved by comparing the similarities of the principal angles between the client data subspaces spanned by those principal vectors. The approach provides a simple, yet effective clustered FL framework that addresses a broad range of data heterogeneity issues beyond simpler forms of Non-IIDness like label skews. Our clustered FL approach also enables convergence guarantees for non-convex objectives.","https://ojs.aaai.org/index.php/AAAI/article/view/26197/25969"
"26198","Training-Time Attacks against K-nearest Neighbors","['Ara Vartanian', 'Will Rosenbaum', 'Scott Alfeld']","['University Wisconsin--Madison', 'Amherst College', 'Amherst College']","['ML: Adversarial Learning & Robustness']","Vartanian, A., Rosenbaum, W., & Alfeld, S. (2023). Training-Time Attacks against K-nearest Neighbors. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10053-10060. https://doi.org/10.1609/aaai.v37i8.26198","Abstract 					Nearest neighbor-based methods are commonly used for classification tasks and as subroutines of other data-analysis methods.  An attacker with the capability of inserting their own data points into the training set can manipulate the inferred nearest neighbor structure. We distill this goal to the task of performing a training-set data insertion attack against k-Nearest Neighbor classification (kNN). We prove that computing an optimal training-time (a.k.a. poisoning) attack against kNN classification is NP-Hard, even when k = 1 and the attacker can insert only a single data point. We provide an anytime algorithm to perform such an attack, and a greedy algorithm for general k and attacker budget. We provide theoretical bounds and empirically demonstrate the effectiveness and practicality of our methods on synthetic and real-world datasets. Empirically, we find that kNN is vulnerable in practice and that dimensionality reduction is an effective defense. We conclude with a discussion of open problems illuminated by our analysis.","https://ojs.aaai.org/index.php/AAAI/article/view/26198/25970"
"26199","Machines of Finite Depth: Towards a Formalization of Neural Networks","['Pietro Vertechi', 'Mattia G. Bergomi']","['Independent Researcher', 'Independent Researcher']","['ML: Deep Learning Theory', 'ML: Optimization', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms', 'ML: Learning Theory', 'ML: Auto ML and Hyperparameter Tuning', 'ML: Transparent', 'Interpretable', 'Explainable ML']","Vertechi, P., & Bergomi, M. G. (2023). Machines of Finite Depth: Towards a Formalization of Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10061-10068. https://doi.org/10.1609/aaai.v37i8.26199","Abstract 					We provide a unifying framework where artificial neural networks and their architectures can be formally described as particular cases of a general mathematical construction---machines of finite depth. Unlike neural networks, machines have a precise definition, from which several properties follow naturally. Machines of finite depth are modular (they can be combined), efficiently computable, and differentiable. The backward pass of a machine is again a machine and can be computed without overhead using the same procedure as the forward pass. We prove this statement theoretically and practically via a unified implementation that generalizes several classical architectures---dense, convolutional, and recurrent neural networks with a rich shortcut structure---and their respective backpropagation rules.","https://ojs.aaai.org/index.php/AAAI/article/view/26199/25971"
"26200","Kalman Bayesian Neural Networks for Closed-Form Online Learning","['Philipp Wagner', 'Xinyang Wu', 'Marco F. Huber']","['Fraunhofer Institute for Manufacturing Engineering and Automation IPA', 'Fraunhofer Institute for Manufacturing Engineering and Automation IPA', 'Fraunhofer Institute for Manufacturing Engineering and Automation IPA']","['ML: Bayesian Learning', 'ML: Deep Neural Network Algorithms', 'ML: Online Learning & Bandits', 'ML: Deep Learning Theory']","Wagner, P., Wu, X., & Huber, M. F. (2023). Kalman Bayesian Neural Networks for Closed-Form Online Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10069-10077. https://doi.org/10.1609/aaai.v37i8.26200","Abstract 					Compared to point estimates calculated by standard neural networks, Bayesian neural networks (BNN) provide probability distributions over the output predictions and model parameters, i.e., the weights. Training the weight distribution of a BNN, however, is more involved due to the intractability of the underlying Bayesian inference problem and thus, requires efficient approximations. In this paper, we propose a novel approach for BNN learning via closed-form Bayesian inference. For this purpose, the calculation of the predictive distribution of the output and the update of the weight distribution are treated as Bayesian filtering and smoothing problems, where the weights are modeled as Gaussian random variables. This allows closed-form expressions for training the network's parameters in a sequential/online fashion without gradient descent. We demonstrate our method on several UCI datasets and compare it to the state of the art.","https://ojs.aaai.org/index.php/AAAI/article/view/26200/25972"
"26201","Auto-Weighted Multi-View Clustering for Large-Scale Data","['Xinhang Wan', 'Xinwang Liu', 'Jiyuan Liu', 'Siwei Wang', 'Yi Wen', 'Weixuan Liang', 'En Zhu', 'Zhe Liu', 'Lu Zhou']","['National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'Nanjing University of Aeronautics and Astronautics', 'Nanjing University of Aeronautics and Astronautics']","['ML: Clustering', 'ML: Multimodal Learning']","Wan, X., Liu, X., Liu, J., Wang, S., Wen, Y., Liang, W., Zhu, E., Liu, Z., & Zhou, L. (2023). Auto-Weighted Multi-View Clustering for Large-Scale Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10078-10086. https://doi.org/10.1609/aaai.v37i8.26201","Abstract 					Multi-view clustering has gained broad attention owing to its capacity to exploit complementary information across multiple data views. Although existing methods demonstrate delightful clustering performance, most of them are of high time complexity and cannot handle large-scale data. Matrix factorization-based models are a representative of solving this problem. However, they assume that the views share a dimension-fixed consensus coefficient matrix and view-specific base matrices, limiting their representability. Moreover, a series of large-scale algorithms that bear one or more hyperparameters are impractical in real-world applications. To address the two issues, we propose an auto-weighted multi-view clustering (AWMVC) algorithm. Specifically, AWMVC first learns coefficient matrices from corresponding base matrices of different dimensions, then fuses them to obtain an optimal consensus matrix. By mapping original features into distinctive low-dimensional spaces, we can attain more comprehensive knowledge, thus obtaining better clustering results. Moreover, we design a six-step alternative optimization algorithm proven to be convergent theoretically. Also, AWMVC shows excellent performance on various benchmark datasets compared with existing ones. The code of AWMVC is publicly available at https://github.com/wanxinhang/AAAI-2023-AWMVC.","https://ojs.aaai.org/index.php/AAAI/article/view/26201/25973"
"26202","Quantum Multi-Armed Bandits and Stochastic Linear Bandits Enjoy Logarithmic Regrets","['Zongqi Wan', 'Zhijie Zhang', 'Tongyang Li', 'Jialin Zhang', 'Xiaoming Sun']","['Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Fuzhou University', 'Peking University', 'Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences']","['ML: Quantum Machine Learning', 'ML: Online Learning & Bandits']","Wan, Z., Zhang, Z., Li, T., Zhang, J., & Sun, X. (2023). Quantum Multi-Armed Bandits and Stochastic Linear Bandits Enjoy Logarithmic Regrets. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10087-10094. https://doi.org/10.1609/aaai.v37i8.26202","Abstract 					Multi-arm bandit (MAB) and stochastic linear bandit (SLB) are important models in reinforcement learning, and it is well-known that classical algorithms for bandits with time horizon T suffer from the regret of at least the square root of T. In this paper, we study MAB and SLB with quantum reward oracles and propose quantum algorithms for both models with the order of the polylog T regrets, exponentially improving the dependence in terms of T. To the best of our knowledge, this is the first provable quantum speedup for regrets of bandit problems and in general exploitation in reinforcement learning. Compared to previous literature on quantum exploration algorithms for MAB and reinforcement learning, our quantum input model is simpler and only assumes quantum oracles for each individual arm.","https://ojs.aaai.org/index.php/AAAI/article/view/26202/25974"
"26203","FedABC: Targeting Fair Competition in Personalized Federated Learning","['Dui Wang', 'Li Shen', 'Yong Luo', 'Han Hu', 'Kehua Su', 'Yonggang Wen', 'Dacheng Tao']","['National Engineering Research Center for Multimedia Software, School of Computer Science, Institute of Artificial Intelligence and Hubei Key Laboratory of Multimedia and Network Communication Engineering, Wuhan University;\nHubei Luojia Laboratory;\nJD Explore Academy', 'JD Explore Academy', 'National Engineering Research Center for Multimedia Software, School of Computer Science, Institute of Artificial Intelligence and Hubei Key Laboratory of Multimedia and Network Communication Engineering, Wuhan University;\nHubei Luojia Laboratory;', 'Beijing Institute of Technology', 'National Engineering Research Center for Multimedia Software, School of Computer Science, Institute of Artificial Intelligence and Hubei Key Laboratory of Multimedia and Network Communication Engineering, Wuhan University', 'Nanyang Technological University', 'JD Explore Academy']","['ML: Distributed Machine Learning & Federated Learning', 'ML: Classification and Regression', 'ML: Representation Learning']","Wang, D., Shen, L., Luo, Y., Hu, H., Su, K., Wen, Y., & Tao, D. (2023). FedABC: Targeting Fair Competition in Personalized Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10095-10103. https://doi.org/10.1609/aaai.v37i8.26203","Abstract 					Federated learning aims to collaboratively train models without accessing their client's local private data. The data may be Non-IID for different clients and thus resulting in poor performance. Recently, personalized federated learning (PFL) has achieved great success in handling Non-IID data by enforcing regularization in local optimization or improving the model aggregation scheme on the server. However, most of the PFL approaches do not take into account the unfair competition issue caused by the imbalanced data distribution and lack of positive samples for some classes in each client. To address this issue, we propose a novel and generic PFL framework termed Federated Averaging via Binary Classification, dubbed FedABC. In particular, we adopt the ``one-vs-all'' training strategy in each client to alleviate the unfair competition between classes by constructing a personalized binary classification problem for each class. This may aggravate the class imbalance challenge and thus a novel personalized binary classification loss that incorporates both the under-sampling and hard sample mining strategies is designed. Extensive experiments are conducted on two popular datasets under different settings, and the results demonstrate that our FedABC can significantly outperform the existing counterparts.","https://ojs.aaai.org/index.php/AAAI/article/view/26203/25975"
"26204","Spearman Rank Correlation Screening for Ultrahigh-Dimensional Censored Data","['Hongni Wang', 'Jingxin Yan', 'Xiaodong Yan']","['Shandong University of Finance and Economics', 'Academy of Mathematics and Systems Science, Chinese Academy of Sciences', 'Zhongtai Securities Institute for Financial Studies, Shandong University\nShandong Province Key Laboratory of Financial Risk\nShandong National Center for Applied Mathematics']","['ML: Dimensionality Reduction/Feature Selection', 'ML: Classification and Regression']","Wang, H., Yan, J., & Yan, X. (2023). Spearman Rank Correlation Screening for Ultrahigh-Dimensional Censored Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10104-10112. https://doi.org/10.1609/aaai.v37i8.26204","Abstract 					Herein, we propose a Spearman rank correlation-based screening procedure for ultrahigh-dimensional data with censored response cases. The proposed method is model-free without specifying any regression forms of predictors or response variables and is robust under the unknown monotone transformations of these response variable and predictors. The sure-screening and rank-consistency properties are established under some mild regularity conditions. Simulation studies demonstrate that the new screening method performs well in the presence of a heavy-tailed distribution, strongly dependent predictors or outliers, and offers superior performance over the existing nonparametric screening procedures. In particular, the new screening method still works well when a response variable is observed under a high censoring rate. An illustrative example is provided.","https://ojs.aaai.org/index.php/AAAI/article/view/26204/25976"
"26205","Stability-Based Generalization Analysis for Mixtures of Pointwise and Pairwise Learning","['Jiahuan Wang', 'Jun Chen', 'Hong Chen', 'Bin Gu', 'Weifu Li', 'Xin Tang']","['Huazhong Agricultural University', 'Huazhong Agricultural University', 'Huazhong Agricultural University\nEngineering Research Center of Intelligent Technology for Agriculture, Ministry of Education\nKey Laboratory of Smart Farming for Agricultural Animals', 'Mohamed bin Zayed University of Artificial Intelligence', 'Huazhong Agricultural University\nEngineering Research Center of Intelligent Technology for Agriculture, Ministry of Education\nKey Laboratory of Smart Farming for Agricultural Animals', 'Ping An Property & Casualty Insurance Company']","['ML: Other Foundations of Machine Learning', 'ML: Evaluation and Analysis (Machine Learning)', 'ML: Learning Theory']","Wang, J., Chen, J., Chen, H., Gu, B., Li, W., & Tang, X. (2023). Stability-Based Generalization Analysis for Mixtures of Pointwise and Pairwise Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10113-10121. https://doi.org/10.1609/aaai.v37i8.26205","Abstract 					Recently, some mixture algorithms of pointwise and pairwise learning (PPL) have been formulated by employing the hybrid error metric of “pointwise loss + pairwise loss” and have shown empirical effectiveness on feature selection, ranking and recommendation tasks. However, to the best of our knowledge, the learning theory foundation of PPL has not been touched in the existing works. In this paper, we try to fill this theoretical gap by investigating the generalization properties of PPL. After extending the definitions of algorithmic stability to the PPL setting, we establish the high-probability generalization bounds for uniformly stable PPL algorithms. Moreover, explicit convergence rates of stochastic gradient descent (SGD) and regularized risk minimization (RRM) for PPL are stated by developing the stability analysis technique of pairwise learning. In addition, the refined generalization bounds of PPL are obtained by replacing uniform stability with on-average stability.","https://ojs.aaai.org/index.php/AAAI/article/view/26205/25977"
"26206","Effective Continual Learning for Text Classification with Lightweight Snapshots","['Jue Wang', 'Dajie Dong', 'Lidan Shou', 'Ke Chen', 'Gang Chen']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University']","['ML: Lifelong and Continual Learning', 'SNLP: Text Classification']","Wang, J., Dong, D., Shou, L., Chen, K., & Chen, G. (2023). Effective Continual Learning for Text Classification with Lightweight Snapshots. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10122-10130. https://doi.org/10.1609/aaai.v37i8.26206","Abstract 					Continual learning is known for suffering from catastrophic forgetting, a phenomenon where previously learned concepts are forgotten upon learning new tasks. A natural remedy is to use trained models for old tasks as ‘teachers’ to regularize the update of the current model to prevent such forgetting. However, this requires storing all past models, which is very space-consuming for large models, e.g. BERT, thus impractical in real-world applications. To tackle this issue, we propose to construct snapshots of seen tasks whose key knowledge is captured in lightweight adapters. During continual learning, we transfer knowledge from past snapshots to the current model through knowledge distillation, allowing the current model to review previously learned knowledge while learning new tasks. We also design representation recalibration to better handle the class-incremental setting. Experiments over various task sequences show that our approach effectively mitigates catastrophic forgetting and outperforms all baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/26206/25978"
"26207","Optimistic Whittle Index Policy: Online Learning for Restless Bandits","['Kai Wang', 'Lily Xu', 'Aparna Taneja', 'Milind Tambe']","['Harvard University', 'Harvard University', 'Google Research, India', 'Google Research, India\nHarvard University']","['ML: Online Learning & Bandits', 'PRS: Planning Under Uncertainty', 'PRS: Planning With Markov Models (MDPs', 'POMDPs)', 'RU: Sequential Decision Making']","Wang, K., Xu, L., Taneja, A., & Tambe, M. (2023). Optimistic Whittle Index Policy: Online Learning for Restless Bandits. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10131-10139. https://doi.org/10.1609/aaai.v37i8.26207","Abstract 					Restless multi-armed bandits (RMABs) extend multi-armed bandits to allow for stateful arms, where the state of each arm evolves restlessly with different transitions depending on whether that arm is pulled. Solving RMABs requires information on transition dynamics, which are often unknown upfront. To plan in RMAB settings with unknown transitions, we propose the first online learning algorithm based on the Whittle index policy, using an upper confidence bound (UCB) approach to learn transition dynamics. Specifically, we estimate confidence bounds of the transition probabilities and formulate a bilinear program to compute optimistic Whittle indices using these estimates. Our algorithm, UCWhittle, achieves sublinear O(H \sqrt{T log T}) frequentist regret to solve RMABs with unknown transitions in T episodes with a constant horizon H. Empirically, we demonstrate that UCWhittle leverages the structure of RMABs and the Whittle index policy solution to achieve better performance than existing online learning baselines across three domains, including one constructed from a real-world maternal and childcare dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/26207/25979"
"26208","AEC-GAN: Adversarial Error Correction GANs for Auto-Regressive Long Time-Series Generation","['Lei Wang', 'Liang Zeng', 'Jian Li']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University']","['ML: Deep Generative Models & Autoencoders', 'ML: Applications', 'ML: Time-Series/Data Streams']","Wang, L., Zeng, L., & Li, J. (2023). AEC-GAN: Adversarial Error Correction GANs for Auto-Regressive Long Time-Series Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10140-10148. https://doi.org/10.1609/aaai.v37i8.26208","Abstract 					Large-scale high-quality data is critical for training modern deep neural networks. However, data acquisition can be costly or time-consuming for many time-series applications, thus researchers turn to generative models for generating synthetic time-series data. In particular, recent generative adversarial networks (GANs) have achieved remarkable success in time-series generation. Despite their success, existing GAN models typically generate the sequences in an auto-regressive manner, and we empirically observe that they suffer from severe distribution shifts and bias amplification, especially when generating long sequences. To resolve this problem, we propose Adversarial Error Correction GAN (AEC-GAN), which is capable of dynamically correcting the bias in the past generated data to alleviate the risk of distribution shifts and thus can generate high-quality long sequences. AEC-GAN contains two main innovations: (1) We develop an error correction module to mitigate the bias. In the training phase, we adversarially perturb the realistic time-series data and then optimize this module to reconstruct the original data. In the generation phase, this module can act as an efficient regulator to detect and mitigate the bias. (2) We propose an augmentation method to facilitate GAN's training by introducing adversarial examples. Thus, AEC-GAN can generate high-quality sequences of arbitrary lengths, and the synthetic data can be readily applied to downstream tasks to boost their performance. We conduct extensive experiments on six widely used datasets and three state-of-the-art time-series forecasting models to evaluate the quality of our synthetic time-series data in different lengths and downstream tasks. Both the qualitative and quantitative experimental results demonstrate the superior performance of AEC-GAN over other deep generative models for time-series generation.","https://ojs.aaai.org/index.php/AAAI/article/view/26208/25980"
"26209","The Implicit Regularization of Momentum Gradient Descent in Overparametrized Models","['Li Wang', 'Zhiguo Fu', 'Yingcong Zhou', 'Zili Yan']","['Northeast Normal University', 'Northeast Normal University', 'Northeast Normal University', 'Beihua University']","['ML: Deep Learning Theory', 'ML: Classification and Regression', 'ML: Deep Neural Network Algorithms', 'ML: Optimization', 'ML: Transparent', 'Interpretable', 'Explainable ML']","Wang, L., Fu, Z., Zhou, Y., & Yan, Z. (2023). The Implicit Regularization of Momentum Gradient Descent in Overparametrized Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10149-10156. https://doi.org/10.1609/aaai.v37i8.26209","Abstract 					The study of the implicit regularization induced by gradient-based optimization in deep learning is a long-standing pursuit. In the present paper, we  characterize the implicit regularization of momentum gradient descent (MGD) in the continuous-time view, so-called momentum gradient flow (MGF). We show that the components of weight vector are learned for a deep linear neural networks at different evolution rates, and this evolution gap increases with the depth. Firstly, we show that if the depth equals one, the evolution gap between the weight vector components is linear, which is consistent with the performance of ridge. In particular, we establish a tight coupling between MGF and ridge for the least squares regression. In detail, we show that when the regularization parameter of ridge is inversely proportional to the square of the time parameter of MGF, the risk of MGF is no more than 1.54 times that of  ridge, and their relative Bayesian risks are almost indistinguishable. Secondly, if the model becomes deeper, i.e. the depth is greater than or equal to 2, the evolution gap becomes more significant, which implies an implicit bias towards sparse solutions. The numerical experiments strongly support our theoretical results.","https://ojs.aaai.org/index.php/AAAI/article/view/26209/25981"
"26210","Meta-Reinforcement Learning Based on Self-Supervised Task Representation Learning","['Mingyang Wang', 'Zhenshan Bing', 'Xiangtong Yao', 'Shuai Wang', 'Huang Kai', 'Hang Su', 'Chenguang Yang', 'Alois Knoll']","['Technical University Munich', 'Technical University Munich', 'Technical University Munich', 'Tencent Robotics X Lab', 'Sun Yat-Sen University', 'Politecnico di Milano', 'University of the West of England', 'Technical University Munich']","['ML: Reinforcement Learning Algorithms', 'ROB: Behavior Learning & Control', 'ML: Meta Learning', 'ML: Unsupervised & Self-Supervised Learning']","Wang, M., Bing, Z., Yao, X., Wang, S., Kai, H., Su, H., Yang, C., & Knoll, A. (2023). Meta-Reinforcement Learning Based on Self-Supervised Task Representation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10157-10165. https://doi.org/10.1609/aaai.v37i8.26210","Abstract 					Meta-reinforcement learning enables artificial agents to learn from related training tasks and adapt to new tasks efficiently with minimal interaction data. However, most existing research is still limited to narrow task distributions that are parametric and stationary, and does not consider out-of-distribution tasks during the evaluation, thus, restricting its application. In this paper, we propose MoSS, a context-based Meta-reinforcement learning algorithm based on Self-Supervised task representation learning to address this challenge. We extend meta-RL to broad non-parametric task distributions which have never been explored before, and also achieve state-of-the-art results in non-stationary and out-of-distribution tasks. Specifically, MoSS consists of a task inference module and a policy module. We utilize the Gaussian mixture model for task representation to imitate the parametric and non-parametric task variations. Additionally, our online adaptation strategy enables the agent to react at the first sight of a task change, thus being applicable in non-stationary tasks. MoSS also exhibits strong generalization robustness in out-of-distributions tasks which benefits from the reliable and robust task representation. The policy is built on top of an off-policy RL algorithm and the entire network is trained completely off-policy to ensure high sample efficiency. On MuJoCo and Meta-World benchmarks, MoSS outperforms prior works in terms of asymptotic performance, sample efficiency (3-50x faster), adaptation efficiency, and generalization robustness on broad and diverse task distributions.","https://ojs.aaai.org/index.php/AAAI/article/view/26210/25982"
"26211","Hierarchical Contrastive Learning for Temporal Point Processes","['Qingmei Wang', 'Minjie Cheng', 'Shen Yuan', 'Hongteng Xu']","['Gaoling School of Artificial Intelligence, Renmin University of China', 'Gaoling School of Artificial Intelligence, Renmin University of China', 'Gaoling School of Artificial Intelligence, Renmin University of China', 'Gaoling School of Artificial Intelligence, Renmin University of China\nBeijing Key Laboratory of Big Data Management and Analysis Methods']","['ML: Time-Series/Data Streams', 'ML: Unsupervised & Self-Supervised Learning']","Wang, Q., Cheng, M., Yuan, S., & Xu, H. (2023). Hierarchical Contrastive Learning for Temporal Point Processes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10166-10174. https://doi.org/10.1609/aaai.v37i8.26211","Abstract 					As an important sequential model, the temporal point process (TPP) plays a central role in real-world sequence modeling and analysis, whose learning is often based on the maximum likelihood estimation (MLE). However, due to imperfect observations, such as incomplete and sparse sequences that are common in practice, the MLE of TPP models often suffers from overfitting and leads to unsatisfactory generalization power. In this work, we develop a novel hierarchical contrastive (HCL) learning method for temporal point processes, which provides a new regularizer of MLE. In principle, our HCL considers the noise contrastive estimation (NCE) problem at the event-level and at the sequence-level jointly. Given a sequence, the event-level NCE maximizes the probability of each observed event given its history while penalizing the conditional probabilities of the unobserved events. At the same time, we generate positive and negative event sequences from the observed sequence and maximize the discrepancy between their likelihoods through the sequence-level NCE. Instead of using time-consuming simulation methods, we generate the positive and negative sequences via a simple but efficient model-guided thinning process. Experimental results show that the MLE method assisted by the HCL regularizer outperforms classic MLE and other contrastive learning methods in learning various TPP models consistently. The code is available at https://github.com/qingmeiwangdaily/HCL_TPP.","https://ojs.aaai.org/index.php/AAAI/article/view/26211/25983"
"26212","Beyond ADMM: A Unified Client-Variance-Reduced Adaptive Federated Learning Framework","['Shuai Wang', 'Yanqing Xu', 'Zhiguo Wang', 'Tsung-Hui Chang', 'Tony Q. S. Quek', 'Defeng Sun']","['Information Systems Technology and Design, Singapore University of Technology and Design', 'School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen', 'College of Mathematics, Sichuan Unversity', 'School of Science and Engineering, The Chinese University of Hong Kong, Shenzhen', 'Information Systems Technology and Design, Singapore University of Technology and Design', 'Department of Applied Mathematics, The Hong Kong Polytechnic University']","['ML: Distributed Machine Learning & Federated Learning', 'ML: Optimization']","Wang, S., Xu, Y., Wang, Z., Chang, T.-H., Quek, T. Q. S., & Sun, D. (2023). Beyond ADMM: A Unified Client-Variance-Reduced Adaptive Federated Learning Framework. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10175-10183. https://doi.org/10.1609/aaai.v37i8.26212","Abstract 					As a novel distributed learning paradigm, federated learning (FL) faces serious challenges in dealing with massive clients with heterogeneous data distribution and computation and communication resources. Various client-variance-reduction schemes and client sampling strategies have been respectively introduced to improve the robustness of FL. Among others, primal-dual algorithms such as the alternating direction of method multipliers (ADMM) have been found being resilient to data distribution and outperform most of the primal-only FL algorithms. However, the reason behind remains a mystery still. In this paper, we firstly reveal the fact that the federated ADMM is essentially a client-variance-reduced algorithm. While this explains the inherent robustness of federated ADMM, the vanilla version of it lacks the ability to be adaptive to the degree of client heterogeneity. Besides, the global model at the server under client sampling is biased which slows down the practical convergence. To go beyond ADMM, we propose a novel primal-dual FL algorithm, termed FedVRA, that allows one to adaptively control the variance-reduction level and biasness of the global model. In addition, FedVRA unifies several representative FL algorithms in the sense that they are either special instances of FedVRA or are close to it. Extensions of FedVRA to semi/un-supervised learning are also presented. Experiments based on (semi-)supervised image classification tasks demonstrate superiority of FedVRA over the existing schemes in learning scenarios with massive heterogeneous clients and client sampling.","https://ojs.aaai.org/index.php/AAAI/article/view/26212/25984"
"26213","State-Conditioned Adversarial Subgoal Generation","['Vivienne Huiling Wang', 'Joni Pajarinen', 'Tinghuai Wang', 'Joni-Kristian Kämäräinen']","['Computing Sciences, Tampere University, Finland\nDepartment of Electrical Engineering and Automation, Aalto University, Finland', 'Department of Electrical Engineering and Automation, Aalto University, Finland', 'Huawei Helsinki Research Center, Finland', 'Computing Sciences, Tampere University, Finland']","['ML: Reinforcement Learning Theory', 'ML: Reinforcement Learning Algorithms']","Wang, V. H., Pajarinen, J., Wang, T., & Kämäräinen, J.-K. (2023). State-Conditioned Adversarial Subgoal Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10184-10191. https://doi.org/10.1609/aaai.v37i8.26213","Abstract 					Hierarchical reinforcement learning (HRL) proposes to solve difficult tasks by performing decision-making and control at successively higher levels of temporal abstraction. However, off-policy HRL often suffers from the problem of a non-stationary high-level policy since the low-level policy is constantly changing. In this paper, we propose a novel HRL approach for mitigating the non-stationarity by adversarially enforcing the high-level policy to generate subgoals compatible with the current instantiation of the low-level policy. In practice, the adversarial learning is implemented by training a simple state conditioned discriminator network concurrently with the high-level policy which determines the compatibility level of subgoals. Comparison to state-of-the-art algorithms shows that our approach improves both learning efficiency and performance in challenging continuous control tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26213/25985"
"26214","Deep Attentive Model for Knowledge Tracing","['Xinping Wang', 'Liangyu Chen', 'Min Zhang']","['East China Normal University', 'East China Normal University', 'East China Normal University']","['ML: Applications']","Wang, X., Chen, L., & Zhang, M. (2023). Deep Attentive Model for Knowledge Tracing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10192-10199. https://doi.org/10.1609/aaai.v37i8.26214","Abstract 					Knowledge Tracing (KT) is a crucial task in the field of online education, since it aims to predict students' performance on exercises based on their learning history. One typical solution for knowledge tracing is to combine the classic models in educational psychology, such as Item Response Theory (IRT) and Cognitive Diagnosis (CD), with Deep Neural Networks (DNN) technologies. In this solution, a student and related exercises are mapped into feature vectors based on the student's performance at the current time step, however, it does not consider the impact of historical behavior sequences, and the relationships between historical sequences and students. In this paper, we develop DAKTN, a novel model which assimilates the historical sequences to tackle this challenge for better knowledge tracing. To be specific, we apply a pooling layer to incorporate the student behavior sequence in the embedding layer. After that, we further design a local activation unit, which can adaptively calculate the representation vectors by taking the relevance of historical sequences into consideration with respect to candidate student and exercises. Through experimental results on three real-world datasets, DAKTN significantly outperforms state-of-the-art baseline models. We also present the reasonableness of DAKTN by ablation testing.","https://ojs.aaai.org/index.php/AAAI/article/view/26214/25986"
"26215","Correspondence-Free Domain Alignment for Unsupervised Cross-Domain Image Retrieval","['Xu Wang', 'Dezhong Peng', 'Ming Yan', 'Peng Hu']","['Sichuan University', 'Sichuan University', 'Institute of High Performance Computing', 'College of Computer Science, Sichuan University']","['ML: Multi-Instance/Multi-View Learning', 'CV: Image and Video Retrieval', 'ML: Multimodal Learning', 'ML: Representation Learning']","Wang, X., Peng, D., Yan, M., & Hu, P. (2023). Correspondence-Free Domain Alignment for Unsupervised Cross-Domain Image Retrieval. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10200-10208. https://doi.org/10.1609/aaai.v37i8.26215","Abstract 					Cross-domain image retrieval aims at retrieving images across different domains to excavate cross-domain classificatory or correspondence relationships. This paper studies a less-touched problem of cross-domain image retrieval, i.e., unsupervised cross-domain image retrieval, considering the following practical assumptions: (i) no correspondence relationship, and (ii) no category annotations. It is challenging to align and bridge distinct domains without cross-domain correspondence. To tackle the challenge, we present a novel Correspondence-free Domain Alignment (CoDA) method to effectively eliminate the cross-domain gap through In-domain Self-matching Supervision (ISS) and Cross-domain Classifier Alignment (CCA). To be specific, ISS is presented to encapsulate discriminative information into the latent common space by elaborating a novel self-matching supervision mechanism. To alleviate the cross-domain discrepancy, CCA is proposed to align distinct domain-specific classifiers. Thanks to the ISS and CCA, our method could encode the discrimination into the domain-invariant embedding space for unsupervised cross-domain image retrieval. To verify the effectiveness of the proposed method, extensive experiments are conducted on four benchmark datasets compared with six state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26215/25987"
"26216","Isolation and Impartial Aggregation: A Paradigm of Incremental Learning without Interference","['Yabin Wang', 'Zhiheng Ma', 'Zhiwu Huang', 'Yaowei Wang', 'Zhou Su', 'Xiaopeng Hong']","[""Xi'an Jiaotong University\nSingapore Management University"", 'Shenzhen Institute of Advanced Technology,Chinese Academy of Sciences', 'Singapore Management University\nUniversity of Southampton', 'Peng Cheng Laboratory', ""Xi'an Jiaotong University"", 'Harbin Institute of Technology\nPeng Cheng Laboratory']","['ML: Lifelong and Continual Learning', 'CV: Representation Learning for Vision', 'ML: Classification and Regression', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Wang, Y., Ma, Z., Huang, Z., Wang, Y., Su, Z., & Hong, X. (2023). Isolation and Impartial Aggregation: A Paradigm of Incremental Learning without Interference. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10209-10217. https://doi.org/10.1609/aaai.v37i8.26216","Abstract 					This paper focuses on the prevalent stage interference and stage performance imbalance of incremental learning. To avoid obvious stage learning bottlenecks, we propose a new incremental learning framework, which leverages a series of stage-isolated classifiers to perform the learning task at each stage, without interference from others. To be concrete, to aggregate multiple stage classifiers as a uniform one impartially, we first introduce a temperature-controlled energy metric for indicating the confidence score levels of the stage classifiers. We then propose an anchor-based energy self-normalization strategy to ensure the stage classifiers work at the same energy level. Finally, we design a voting-based inference augmentation strategy for robust inference. The proposed method is rehearsal-free and can work for almost all incremental learning scenarios. We evaluate the proposed method on four large datasets. Extensive results demonstrate the superiority of the proposed method in setting up new state-of-the-art overall performance. Code is available at https://github.com/iamwangyabin/ESN.","https://ojs.aaai.org/index.php/AAAI/article/view/26216/25988"
"26217","Robust Self-Supervised Multi-Instance Learning with Structure Awareness","['Yejiang Wang', 'Yuhai Zhao', 'Zhengkui Wang', 'Meixia Wang']","['Northeastern University', 'Northeastern University', 'Singapore Institute of Technology', 'Northeastern University']","['ML: Multi-Instance/Multi-View Learning', 'ML: Adversarial Learning & Robustness', 'ML: Classification and Regression', 'ML: Graph-based Machine Learning', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Unsupervised & Self-Supervised Learning']","Wang, Y., Zhao, Y., Wang, Z., & Wang, M. (2023). Robust Self-Supervised Multi-Instance Learning with Structure Awareness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10218-10225. https://doi.org/10.1609/aaai.v37i8.26217","Abstract 					Multi-instance learning (MIL) is a supervised learning where each example is a labeled bag with many instances. The typical MIL strategies are to train an instance-level feature extractor followed by aggregating instances features as bag-level representation with labeled information. However, learning such a bag-level representation highly depends on a large number of labeled datasets, which are difficult to get in real-world scenarios. In this paper, we make the first attempt to propose a robust Self-supervised Multi-Instance LEarning architecture with Structure awareness (SMILEs) that learns unsupervised bag representation. Our proposed approach is: 1) permutation invariant to the order of instances in bag; 2) structure-aware to encode the topological structures among the instances; and 3) robust against instances noise or permutation. Specifically, to yield robust MIL model without label information, we augment the multi-instance bag and train the representation encoder to maximize the correspondence between the representations of the same bag in its different augmented forms. Moreover, to capture topological structures from nearby instances in bags, our framework learns optimal graph structures for the bags and these graphs are optimized together with message passing layers and the ordered weighted averaging operator towards contrastive loss. Our main theorem characterizes the permutation invariance of the bag representation. Compared with state-of-the-art supervised MIL baselines, SMILEs achieves average improvement of 4.9%, 4.4% in classification accuracy on 5 benchmark datasets and 20 newsgroups datasets, respectively. In addition, we show that the model is robust to the input corruption.","https://ojs.aaai.org/index.php/AAAI/article/view/26217/25989"
"26218","Distributed Projection-Free Online Learning for Smooth and Convex Losses","['Yibo Wang', 'Yuanyu Wan', 'Shimao Zhang', 'Lijun Zhang']","['Nanjing University\nPeng Cheng Laboratory', 'Zhejiang University', 'Nanjing University', 'Nanjing University\nPeng Cheng Laboratory']","['ML: Online Learning & Bandits', 'ML: Optimization', 'ML: Time-Series/Data Streams']","Wang, Y., Wan, Y., Zhang, S., & Zhang, L. (2023). Distributed Projection-Free Online Learning for Smooth and Convex Losses. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10226-10234. https://doi.org/10.1609/aaai.v37i8.26218","Abstract 					We investigate the problem of distributed online convex optimization with complicated constraints, in which the projection operation could be the computational bottleneck. To avoid projections, distributed online projection-free methods have been proposed and attain an O(T^{3/4}) regret bound for general convex losses. However, they cannot utilize the smoothness condition, which has been exploited in the centralized setting to improve the regret. In this paper, we propose a new distributed online projection-free method with a tighter regret bound of O(T^{2/3}) for smooth and convex losses. Specifically, we first provide a distributed extension of Follow-the-Perturbed-Leader so that the smoothness can be utilized in the distributed setting. Then, we reduce the computational cost via sampling and blocking techniques. In this way, our method only needs to solve one linear optimization per round on average. Finally, we conduct experiments on benchmark datasets to verify the effectiveness of our proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/26218/25990"
"26219","USER: Unsupervised Structural Entropy-Based Robust Graph Neural Network","['Yifei Wang', 'Yupan Wang', 'Zeyu Zhang', 'Song Yang', 'Kaiqi Zhao', 'Jiamou Liu']","['The University of Auckland', 'The University of Auckland', 'The University of Auckland', 'The University of Auckland', 'The University of Auckland', 'The University of Auckland']","['ML: Graph-based Machine Learning', 'ML: Unsupervised & Self-Supervised Learning']","Wang, Y., Wang, Y., Zhang, Z., Yang, S., Zhao, K., & Liu, J. (2023). USER: Unsupervised Structural Entropy-Based Robust Graph Neural Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10235-10243. https://doi.org/10.1609/aaai.v37i8.26219","Abstract 					Unsupervised/self-supervised graph neural networks (GNN) are susceptible to the inherent randomness in the input graph data, which adversely affects the model's performance in downstream tasks. In this paper, we propose USER, an unsupervised and robust version of GNN based on structural entropy, to alleviate the interference of graph perturbations and learn appropriate representations of nodes without label information. To mitigate the effects of undesirable perturbations, we analyze the property of intrinsic connectivity and define the intrinsic connectivity graph. We also identify the rank of the adjacency matrix as a crucial factor in revealing a graph that provides the same embeddings as the intrinsic connectivity graph. To capture such a graph, we introduce structural entropy in the objective function. Extensive experiments conducted on clustering and link prediction tasks under random-perturbation and meta-attack over three datasets show that USER outperforms benchmarks and is robust to heavier perturbations.","https://ojs.aaai.org/index.php/AAAI/article/view/26219/25991"
"26220","AutoNF: Automated Architecture Optimization of Normalizing Flows with Unconstrained Continuous Relaxation Admitting Optimal Discrete Solution","['Yu Wang', 'Ján Drgoňa', 'Jiaxin Zhang', 'Karthik Somayaji Nanjangud Suryanarayana', 'Malachi Schram', 'Frank Liu', 'Peng Li']","['University of California, Santa Barbara', 'Pacific Northwest National Laboratory', 'Intuit AI Research', 'University of California, Santa Barbara', 'Thomas Jefferson National Accelerator Facility', 'Oak Ridge National Laboratory', 'University of California at Santa Barbara']","['ML: Auto ML and Hyperparameter Tuning', 'ML: Applications', 'ML: Optimization', 'ML: Probabilistic Methods']","Wang, Y., Drgoňa, J., Zhang, J., Nanjangud Suryanarayana, K. S., Schram, M., Liu, F., & Li, P. (2023). AutoNF: Automated Architecture Optimization of Normalizing Flows with Unconstrained Continuous Relaxation Admitting Optimal Discrete Solution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10244-10252. https://doi.org/10.1609/aaai.v37i8.26220","Abstract 					Normalizing flows (NF) build upon invertible neural networks and have wide applications in probabilistic modeling. Currently, building a powerful yet computationally efficient flow model relies on empirical fine-tuning over a large design space. While introducing neural architecture search (NAS) to NF is desirable, the invertibility constraint of NF brings new challenges to existing NAS methods whose application is limited to unstructured neural networks. Developing efficient NAS methods specifically for NF remains an open problem. We present AutoNF, the first automated NF architectural optimization framework. First, we present a new mixture distribution formulation that allows efficient differentiable architecture search of flow models without violating the invertibility constraint. Second, under the new formulation, we convert the original NP-hard combinatorial NF architectural optimization problem to an unconstrained continuous relaxation admitting the discrete optimal architectural solution, circumventing the loss of optimality due to binarization in architectural optimization.   We evaluate AutoNF with various density estimation datasets and show its superior performance-cost trade-offs over a set of existing hand-crafted baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/26220/25992"
"26221","SEnsor Alignment for Multivariate Time-Series Unsupervised Domain Adaptation","['Yucheng Wang', 'Yuecong Xu', 'Jianfei Yang', 'Zhenghua Chen', 'Min Wu', 'Xiaoli Li', 'Lihua Xie']","['Institute for Infocomm Research , Agency for Science, Technology and Research (A*STAR), Singapore\nNanyang Technological University', 'Institute for Infocomm Research, Agency for Science, Technology and Research (A*STAR), Singapore', 'Nanyang Technological University', 'Institute for Infocomm Research, Agency for Science, Technology and Research (A*STAR), Singapore\nCentre for Frontier AI Research, Agency for Science, Technology and Research (A*STAR), Singapore', 'Institute for Infocomm Research, Agency for Science, Technology and Research (A*STAR), Singapore', 'Institute for Infocomm Research , Agency for Science, Technology and Research (A*STAR), Singapore\nCentre for Frontier AI Research, Agency for Science, Technology and Research (A*STAR), Singapore\nNanyang Technological University', 'Nanyang Technological University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Time-Series/Data Streams']","Wang, Y., Xu, Y., Yang, J., Chen, Z., Wu, M., Li, X., & Xie, L. (2023). SEnsor Alignment for Multivariate Time-Series Unsupervised Domain Adaptation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10253-10261. https://doi.org/10.1609/aaai.v37i8.26221","Abstract 					Unsupervised Domain Adaptation (UDA) methods can reduce label dependency by mitigating the feature discrepancy between labeled samples in a source domain and unlabeled samples in a similar yet shifted target domain. Though achieving good performance, these methods are inapplicable for Multivariate Time-Series (MTS) data. MTS data are collected from multiple sensors, each of which follows various distributions. However, most UDA methods solely focus on aligning global features but cannot consider the distinct distributions of each sensor. To cope with such concerns, a practical domain adaptation scenario is formulated as Multivariate Time-Series Unsupervised Domain Adaptation (MTS-UDA). In this paper, we propose SEnsor Alignment (SEA) for MTS-UDA to reduce the domain discrepancy at both the local and global sensor levels. At the local sensor level, we design the endo-feature alignment to align sensor features and their correlations across domains, whose information represents the features of each sensor and the interactions between sensors. Further, to reduce domain discrepancy at the global sensor level, we design the exo-feature alignment to enforce restrictions on the global sensor features. Meanwhile, MTS also incorporates the essential spatial-temporal dependencies information between sensors, which cannot be transferred by existing UDA methods. Therefore, we model the spatial-temporal information of MTS with a multi-branch self-attention mechanism for simple and effective transfer across domains. Empirical results demonstrate the state-of-the-art performance of our proposed SEA on two public MTS datasets for MTS-UDA. The code is available at   https://github.com/Frank-Wang-oss/SEA","https://ojs.aaai.org/index.php/AAAI/article/view/26221/25993"
"26222","Unlabeled Imperfect Demonstrations in Adversarial Imitation Learning","['Yunke Wang', 'Bo Du', 'Chang Xu']","['Wuhan University', 'Wuhan University', 'The University of Sydney']","['ML: Adversarial Learning & Robustness', 'ML: Imitation Learning & Inverse Reinforcement Learning']","Wang, Y., Du, B., & Xu, C. (2023). Unlabeled Imperfect Demonstrations in Adversarial Imitation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10262-10270. https://doi.org/10.1609/aaai.v37i8.26222","Abstract 					Adversarial imitation learning has become a widely used imitation learning framework. The discriminator is often trained by taking expert demonstrations and policy trajectories as examples respectively from two categories (positive vs. negative) and the policy is then expected to produce trajectories that are indistinguishable from the expert demonstrations. But in the real world, the collected expert demonstrations are more likely to be imperfect, where only an unknown fraction of the demonstrations are optimal. Instead of treating imperfect expert demonstrations as absolutely positive or negative, we investigate unlabeled imperfect expert demonstrations as they are. A positive-unlabeled adversarial imitation learning algorithm is developed to dynamically sample expert demonstrations that can well match the trajectories from the constantly optimized agent policy. The trajectories of an initial agent policy could be closer to those non-optimal expert demonstrations, but within the framework of adversarial imitation learning, agent policy will be optimized to cheat the discriminator and produce trajectories that are similar to those optimal expert demonstrations. Theoretical analysis shows that our method learns from the imperfect demonstrations via a self-paced way. Experimental results on MuJoCo and RoboSuite platforms demonstrate the effectiveness of our method from different aspects.","https://ojs.aaai.org/index.php/AAAI/article/view/26222/25994"
"26223","FedGS: Federated Graph-Based Sampling with Arbitrary Client Availability","['Zheng Wang', 'Xiaoliang Fan', 'Jianzhong Qi', 'Haibing Jin', 'Peizhen Yang', 'Siqi Shen', 'Cheng Wang']","['Xiamen University', 'Xiamen University', 'The University of Melbourne', 'Xiamen University', 'Xiamen University', 'Xiamen University', 'Xiamen University']","['ML: Distributed Machine Learning & Federated Learning', 'ML: Graph-based Machine Learning', 'ML: Privacy-Aware ML']","Wang, Z., Fan, X., Qi, J., Jin, H., Yang, P., Shen, S., & Wang, C. (2023). FedGS: Federated Graph-Based Sampling with Arbitrary Client Availability. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10271-10278. https://doi.org/10.1609/aaai.v37i8.26223","Abstract 					While federated learning has shown strong results in opti- mizing a machine learning model without direct access to the original data, its performance may be hindered by in- termittent client availability which slows down the conver- gence and biases the final learned model. There are significant challenges to achieve both stable and bias-free training un- der arbitrary client availability. To address these challenges, we propose a framework named Federated Graph-based Sam- pling (FEDGS), to stabilize the global model update and mitigate the long-term bias given arbitrary client availabil- ity simultaneously. First, we model the data correlations of clients with a Data-Distribution-Dependency Graph (3DG) that helps keep the sampled clients data apart from each other, which is theoretically shown to improve the approximation to the optimal model update. Second, constrained by the far- distance in data distribution of the sampled clients, we fur- ther minimize the variance of the numbers of times that the clients are sampled, to mitigate long-term bias. To validate the effectiveness of FEDGS, we conduct experiments on three datasets under a comprehensive set of seven client availability modes. Our experimental results confirm FEDGS’s advantage in both enabling a fair client-sampling scheme and improving the model performance under arbitrary client availability. Our code is available at https://github.com/WwZzz/FedGS.","https://ojs.aaai.org/index.php/AAAI/article/view/26223/25995"
"26224","Efficient Exploration in Resource-Restricted Reinforcement Learning","['Zhihai Wang', 'Taoxing Pan', 'Qi Zhou', 'Jie Wang']","['University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China\nHefei Comprehensive National Science Center']","['ML: Reinforcement Learning Algorithms']","Wang, Z., Pan, T., Zhou, Q., & Wang, J. (2023). Efficient Exploration in Resource-Restricted Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10279-10287. https://doi.org/10.1609/aaai.v37i8.26224","Abstract 					In many real-world applications of reinforcement learning (RL), performing actions requires consuming certain types of resources that are non-replenishable in each episode. Typical applications include robotic control with limited energy and video games with consumable items. In tasks with non-replenishable resources, we observe that popular RL methods such as soft actor critic suffer from poor sample efficiency. The major reason is that, they tend to exhaust resources fast and thus the subsequent exploration is severely restricted due to the absence of resources. To address this challenge, we first formalize the aforementioned problem as a resource-restricted reinforcement learning, and then propose a novel resource-aware exploration bonus (RAEB) to make reasonable usage of resources. An appealing feature of RAEB is that, it can significantly reduce unnecessary resource-consuming trials while effectively encouraging the agent to explore unvisited states. Experiments demonstrate that the proposed RAEB significantly outperforms state-of-the-art exploration strategies in resource-restricted reinforcement learning environments, improving the sample efficiency by up to an order of magnitude.","https://ojs.aaai.org/index.php/AAAI/article/view/26224/25996"
"26225","Efficient Explorative Key-Term Selection Strategies for Conversational Contextual Bandits","['Zhiyong Wang', 'Xutong Liu', 'Shuai Li', 'John C. S. Lui']","['The Chinese University of Hong Kong', 'The Chinese University of Hong Kong', 'Shanghai Jiao Tong University', 'The Chinese University of Hong Kong']","['ML: Online Learning & Bandits', 'DMKM: Recommender Systems']","Wang, Z., Liu, X., Li, S., & Lui, J. C. S. (2023). Efficient Explorative Key-Term Selection Strategies for Conversational Contextual Bandits. Proceedings of the AAAI Conference on Artificial Intelligence, 37(8), 10288-10295. https://doi.org/10.1609/aaai.v37i8.26225","Abstract 					Conversational contextual bandits elicit user preferences by occasionally querying for explicit feedback on key-terms to accelerate learning.  However, there are aspects of existing approaches which limit their performance. First, information gained from key-term-level conversations and arm-level recommendations is not appropriately incorporated to speed up learning. Second, it is important to ask explorative key-terms to quickly elicit the user's potential interests in various domains to accelerate the convergence of user preference estimation, which has never been considered in existing works.  To tackle these issues, we first propose ``ConLinUCB"", a general framework for conversational bandits with better information incorporation, combining arm-level and key-term-level feedback to estimate user preference in one step at each time. Based on this framework, we further design two bandit algorithms with explorative key-term selection strategies, ConLinUCB-BS and ConLinUCB-MCR. We prove tighter regret upper bounds of our proposed algorithms. Particularly, ConLinUCB-BS achieves a better regret bound than the previous result. Extensive experiments on synthetic and real-world data show significant advantages of our algorithms in learning accuracy (up to 54% improvement) and computational efficiency (up to 72% improvement), compared to the classic ConUCB algorithm, showing the potential benefit to recommender systems.","https://ojs.aaai.org/index.php/AAAI/article/view/26225/25997"
"26226","Code-Aware Cross-Program Transfer Hyperparameter Optimization","['Zijia Wang', 'Xiangyu He', 'Kehan Chen', 'Chen Lin', 'Jinsong Su']","['School of Informatics, Xiamen University', 'School of Informatics, Xiamen University', 'School of Informatics, Xiamen University', 'School of Informatics, Xiamen University', 'School of Informatics, Xiamen University']","['ML: Auto ML and Hyperparameter Tuning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Wang, Z., He, X., Chen, K., Lin, C., & Su, J. (2023). Code-Aware Cross-Program Transfer Hyperparameter Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10297-10305. https://doi.org/10.1609/aaai.v37i9.26226","Abstract 					Hyperparameter tuning is an essential task in automatic machine learning and big data management.  To accelerate tuning, many recent studies focus on augmenting BO, the primary hyperparameter tuning strategy, by transferring information from other tuning tasks. However, existing studies ignore program similarities in their transfer mechanism, thus they are sub-optimal in cross-program transfer when tuning tasks involve different programs.  This paper proposes CaTHPO, a code-aware cross-program transfer hyperparameter optimization framework, which makes three improvements.  (1) It learns code-aware program representation in a self-supervised manner to give an off-the-shelf estimate of program similarities.  (2) It adjusts the surrogate and AF in BO based on program similarities, thus the hyperparameter search is guided by accumulated information across similar programs.  (3) It presents a safe controller to dynamically prune undesirable sample points based on tuning experiences of similar programs.  Extensive experiments on tuning various recommendation models and Spark applications have demonstrated that CatHPO can steadily obtain better and more robust hyperparameter performances within fewer samples than state-of-the-art competitors.","https://ojs.aaai.org/index.php/AAAI/article/view/26226/25998"
"26227","Predictive Multiplicity in Probabilistic Classification","['Jamelle Watson-Daniels', 'David C. Parkes', 'Berk Ustun']","['Harvard University', 'Harvard University\nDeepMind', 'U.C. San Diego']","['ML: Bias and Fairness', 'ML: Classification and Regression', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'ML: Optimization', 'ML: Applications', 'ML: Adversarial Learning & Robustness', 'ML: Calibration & Uncertainty Quantification', 'ML: Probabilistic Methods']","Watson-Daniels, J., Parkes, D. C., & Ustun, B. (2023). Predictive Multiplicity in Probabilistic Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10306-10314. https://doi.org/10.1609/aaai.v37i9.26227","Abstract 					Machine learning models are often used to inform real world risk assessment tasks: predicting consumer default risk, predicting whether a person suffers from a serious illness, or predicting a person's risk to appear in court. Given multiple models that perform almost equally well for a  prediction task, to what extent do predictions vary across these models? If predictions are relatively consistent for similar models, then the standard approach of choosing the model that optimizes a penalized loss suffices. But what if predictions vary significantly for similar models? In machine learning, this is referred to as predictive multiplicity i.e. the prevalence of conflicting predictions assigned by near-optimal competing models. In this paper, we present a framework for measuring predictive multiplicity in probabilistic classification (predicting the probability of a positive outcome). We introduce measures that capture the variation in risk estimates over the set of competing models, and develop optimization-based methods to compute these measures efficiently and reliably for convex empirical risk minimization problems. We demonstrate the incidence and prevalence of predictive multiplicity in real-world tasks. Further, we provide insight into how predictive multiplicity arises by analyzing the relationship between predictive multiplicity and data set characteristics (outliers, separability, and  majority-minority structure). Our results emphasize the need to report predictive multiplicity more widely.","https://ojs.aaai.org/index.php/AAAI/article/view/26227/25999"
"26228","Feature Distribution Fitting with Direction-Driven Weighting for Few-Shot Images Classification","['Xin Wei', 'Wei Du', 'Huan Wan', 'Weidong Min']","['School of Software, Nanchang University', 'School of Software, Nanchang University', 'School of Computer and Information Engineering, Jiangxi Normal University', 'School of Mathematics and Computer Science, Institute of Metaverse, Nanchang University\nJiangxi Key Laboratory of Smart City, Nanchang University']","['ML: Classification and Regression', 'ML: Deep Generative Models & Autoencoders', 'ML: Deep Neural Network Algorithms']","Wei, X., Du, W., Wan, H., & Min, W. (2023). Feature Distribution Fitting with Direction-Driven Weighting for Few-Shot Images Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10315-10323. https://doi.org/10.1609/aaai.v37i9.26228","Abstract 					Few-shot learning has received increasing attention and witnessed significant advances in recent years. However, most of the few-shot learning methods focus on the optimization of training process, and the learning of metric and sample generating networks. They ignore the importance of learning the ground-truth feature distributions of few-shot classes. This paper proposes a direction-driven weighting method to make the feature distributions of few-shot classes precisely fit the ground-truth distributions. The learned feature distributions can generate an unlimited number of training samples for the few-shot classes to avoid overfitting. Specifically, the proposed method consists of two optimization strategies. The direction-driven strategy is for capturing more complete direction information that can describe the feature distributions. The similarity-weighting strategy is proposed to estimate the impact of different classes in the fitting procedure and assign corresponding weights. Our method outperforms the current state-of-the-art performance by an average of 3% for 1-shot on standard few-shot learning benchmarks like miniImageNet, CIFAR-FS, and CUB. The excellent performance and compelling visualization show that our method can more accurately estimate the ground-truth distributions.","https://ojs.aaai.org/index.php/AAAI/article/view/26228/26000"
"26229","Learning Instrumental Variable from Data Fusion for Treatment Effect Estimation","['Anpeng Wu', 'Kun Kuang', 'Ruoxuan Xiong', 'Minqin Zhu', 'Yuxuan Liu', 'Bo Li', 'Furui Liu', 'Zhihua Wang', 'Fei Wu']","['Zhejiang University', 'Zhejiang University', 'Emory University', 'Zhejiang University', 'Zhejiang University', 'Tsinghua University', ""Huawei Noah's Ark Lab"", 'Shanghai AI Laboratory\nShanghai Institute for Advanced Study of Zhejiang University, China', 'Zhejiang University\nShanghai AI Laboratory\nShanghai Institute for Advanced Study of Zhejiang University, China']","['ML: Causal Learning']","Wu, A., Kuang, K., Xiong, R., Zhu, M., Liu, Y., Li, B., Liu, F., Wang, Z., & Wu, F. (2023). Learning Instrumental Variable from Data Fusion for Treatment Effect Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10324-10332. https://doi.org/10.1609/aaai.v37i9.26229","Abstract 					The advent of the big data era brought new opportunities and challenges to draw treatment effect in data fusion, that is, a mixed dataset collected from multiple sources (each source with an independent treatment assignment mechanism). Due to possibly omitted source labels and unmeasured confounders, traditional methods cannot estimate individual treatment assignment probability and infer treatment effect effectively. Therefore, we propose to reconstruct the source label and model it as a Group Instrumental Variable (GIV) to implement IV-based Regression for treatment effect estimation. In this paper, we conceptualize this line of thought and develop a unified framework (Meta-EM) to (1) map the raw data into a representation space to construct Linear Mixed Models for the assigned treatment variable; (2) estimate the distribution differences and model the GIV for the different treatment assignment mechanisms; and (3) adopt an alternating training strategy to iteratively optimize the representations and the joint distribution to model GIV for IV regression. Empirical results demonstrate the advantages of our Meta-EM compared with state-of-the-art methods. The project page with the code and the Supplementary materials is available at https://github.com/causal-machine-learning-lab/meta-em.","https://ojs.aaai.org/index.php/AAAI/article/view/26229/26001"
"26230","Towards In-Distribution Compatible Out-of-Distribution Detection","['Boxi Wu', 'Jie Jiang', 'Haidong Ren', 'Zifan Du', 'Wenxiao Wang', 'Zhifeng Li', 'Deng Cai', 'Xiaofei He', 'Binbin Lin', 'Wei Liu']","['State Key Lab of CAD&CG, Zhejiang University', 'Tencent Data Platform', 'Ningbo Zhoushan Port Group Co.,Ltd., Ningbo, China.', 'School of Software Technology, Zhejiang University', 'School of Software Technology, Zhejiang University', 'Tencent Data Platform', 'State Key Lab of CAD&CG, Zhejiang University', 'State Key Lab of CAD&CG, Zhejiang University', 'School of Software Technology, Zhejiang University', 'Tencent Data Platform']","['ML: Deep Neural Network Algorithms', 'CV: Applications']","Wu, B., Jiang, J., Ren, H., Du, Z., Wang, W., Li, Z., Cai, D., He, X., Lin, B., & Liu, W. (2023). Towards In-Distribution Compatible Out-of-Distribution Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10333-10341. https://doi.org/10.1609/aaai.v37i9.26230","Abstract 					Deep neural network, despite its remarkable capability of discriminating targeted in-distribution samples, shows poor performance on detecting anomalous out-of-distribution data. To address this defect, state-of-the-art solutions choose to train deep networks on an auxiliary dataset of outliers. Various training criteria for these auxiliary outliers are proposed based on heuristic intuitions. However, we find that these intuitively designed outlier training criteria can hurt in-distribution learning and eventually lead to inferior performance. To this end, we identify three causes of the in-distribution incompatibility: contradictory gradient, false likelihood, and distribution shift. Based on our new understandings, we propose a new out-of-distribution detection method by adapting both the top-design of deep models and the loss function. Our method achieves in-distribution compatibility by pursuing less interference with the probabilistic characteristic of in-distribution features. On several benchmarks, our method not only achieves the state-of-the-art out-of-distribution detection performance but also improves the in-distribution accuracy.","https://ojs.aaai.org/index.php/AAAI/article/view/26230/26002"
"26231","Non-IID Transfer Learning on Graphs","['Jun Wu', 'Jingrui He', 'Elizabeth Ainsworth']","['University of Illinois Urbana–Champaign', 'University of Illinois Urbana-Champaign', 'University of Illinois Urbana-Champaign\nUSDA ARS Global Change and Photosynthesis Research Unit']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Wu, J., He, J., & Ainsworth, E. (2023). Non-IID Transfer Learning on Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10342-10350. https://doi.org/10.1609/aaai.v37i9.26231","Abstract 					Transfer learning refers to the transfer of knowledge or information from a relevant source domain to a target domain. However, most existing transfer learning theories and algorithms focus on IID tasks, where the source/target samples are assumed to be independent and identically distributed. Very little effort is devoted to theoretically studying the knowledge transferability on non-IID tasks, e.g., cross-network mining. To bridge the gap, in this paper, we propose rigorous generalization bounds and algorithms for cross-network transfer learning from a source graph to a target graph. The crucial idea is to characterize the cross-network knowledge transferability from the perspective of the Weisfeiler-Lehman graph isomorphism test. To this end, we propose a novel Graph Subtree Discrepancy to measure the graph distribution shift between source and target graphs. Then the generalization error bounds on cross-network transfer learning, including both cross-network node classification and link prediction tasks, can be derived in terms of the source knowledge and the Graph Subtree Discrepancy across domains. This thereby motivates us to propose a generic graph adaptive network (GRADE) to minimize the distribution shift between source and target graphs for cross-network transfer learning. Experimental results verify the effectiveness and efficiency of our GRADE framework on both cross-network node classification and cross-domain recommendation tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26231/26003"
"26232","Extracting Low-/High- Frequency Knowledge from Graph Neural Networks and Injecting It into MLPs: An Effective GNN-to-MLP Distillation Framework","['Lirong Wu', 'Haitao Lin', 'Yufei Huang', 'Tianyu Fan', 'Stan Z. Li']","['Westlake University\nZhejiang University', 'Westlake university\nZhejiang University', 'Westlake University\nZhejiang University', 'Zhejiang University', 'Westlake University']","['ML: Graph-based Machine Learning', 'ML: Semi-Supervised Learning']","Wu, L., Lin, H., Huang, Y., Fan, T., & Li, S. Z. (2023). Extracting Low-/High- Frequency Knowledge from Graph Neural Networks and Injecting It into MLPs: An Effective GNN-to-MLP Distillation Framework. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10351-10360. https://doi.org/10.1609/aaai.v37i9.26232","Abstract 					Recent years have witnessed the great success of Graph Neural Networks (GNNs) in handling graph-related tasks. However, MLPs remain the primary workhorse for practical industrial applications due to their desirable inference efficiency and scalability. To reduce their gaps, one can directly distill knowledge from a well-designed teacher GNN to a student MLP, which is termed as GNN-to-MLP distillation. However, the process of distillation usually entails a loss of information, and ``which knowledge patterns of GNNs are more likely to be left and distilled into MLPs?"" becomes an important question. In this paper, we first factorize the knowledge learned by GNNs into low- and high-frequency components in the spectral domain and then derive their correspondence in the spatial domain. Furthermore, we identified a potential information drowning problem for existing GNN-to-MLP distillation, i.e., the high-frequency knowledge of the pre-trained GNNs may be overwhelmed by the low-frequency knowledge during distillation; we have described in detail what it represents, how it arises, what impact it has, and how to deal with it. In this paper, we propose an efficient Full-Frequency GNN-to-MLP (FF-G2M) distillation framework, which extracts both low-frequency and high-frequency knowledge from GNNs and injects it into MLPs. Extensive experiments show that FF-G2M improves over the vanilla MLPs by 12.6% and outperforms its corresponding teacher GNNs by 2.6% averaged over six graph datasets and three common GNN architectures.","https://ojs.aaai.org/index.php/AAAI/article/view/26232/26004"
"26233","Symphony in the Latent Space: Provably Integrating High-Dimensional Techniques with Non-linear Machine Learning Models","['Qiong Wu', 'Jian Li', 'Zhenming Liu', 'Yanhua Li', 'Mihai Cucuringu']","['College of William and Mary', 'Tsinghua University, China', 'College of William & Mary', 'Worcester Polytechnic Institute, USA', 'University of Oxford\nThe Alan Turing Institute']","['ML: Representation Learning', 'APP: Economic/Financial', 'ML: Applications', 'ML: Time-Series/Data Streams']","Wu, Q., Li, J., Liu, Z., Li, Y., & Cucuringu, M. (2023). Symphony in the Latent Space: Provably Integrating High-Dimensional Techniques with Non-linear Machine Learning Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10361-10369. https://doi.org/10.1609/aaai.v37i9.26233","Abstract 					This paper revisits building  machine learning algorithms that involve interactions between entities, such as those between financial assets in an actively managed portfolio, or interactions between users in a social network. Our goal is to forecast the future evolution of ensembles of multivariate time series in such applications (e.g., the future return of a financial asset or the future popularity of a Twitter account). Designing ML algorithms for such systems requires addressing the challenges of high-dimensional interactions and non-linearity. Existing approaches usually adopt an ad-hoc approach to integrating high-dimensional techniques into non-linear models and recent studies have shown these approaches have questionable efficacy in time-evolving interacting systems.    To this end, we propose a novel framework, which we dub as the additive influence model. Under our modeling assumption, we show that it is possible to decouple the learning of high-dimensional interactions from the learning of non-linear feature interactions. To learn the high-dimensional interactions, we leverage kernel-based techniques, with provable guarantees, to embed the entities in a low-dimensional latent space. To learn the non-linear feature-response interactions, we generalize prominent machine learning techniques, including designing a new statistically sound non-parametric method and an ensemble learning algorithm optimized for vector regressions.  Extensive experiments on two common applications demonstrate that our new algorithms deliver significantly stronger forecasting power compared to standard and recently proposed methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26233/26005"
"26234","Decentralized Riemannian Algorithm for Nonconvex Minimax Problems","['Xidong Wu', 'Zhengmian Hu', 'Heng Huang']","['University of Pittsburgh', 'University of Pittsburgh', 'University of Pittsburgh']","['ML: Optimization', 'ML: Distributed Machine Learning & Federated Learning']","Wu, X., Hu, Z., & Huang, H. (2023). Decentralized Riemannian Algorithm for Nonconvex Minimax Problems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10370-10378. https://doi.org/10.1609/aaai.v37i9.26234","Abstract 					The minimax optimization over Riemannian manifolds (possibly nonconvex constraints) has been actively applied to solve many problems, such as robust dimensionality reduction and deep neural networks with orthogonal weights (Stiefel manifold). Although many optimization algorithms for minimax problems have been developed in the Euclidean setting, it is difficult to convert them into Riemannian cases, and algorithms for nonconvex minimax problems with nonconvex constraints are even rare. On the other hand, to address the big data challenges, decentralized (serverless) training techniques have recently been emerging since they can reduce communications overhead and avoid the bottleneck problem on the server node. Nonetheless, the algorithm for decentralized Riemannian minimax problems has not been studied. In this paper, we study the distributed nonconvex-strongly-concave minimax optimization problem over the Stiefel manifold and propose both deterministic and stochastic minimax methods. The Steifel manifold is a non-convex set. The global function is represented as the finite sum of local functions. For the deterministic setting, we propose DRGDA and prove that our deterministic method achieves a gradient complexity of O( epsilon(-2)) under mild conditions. For the stochastic setting, we propose DRSGDA and prove that our stochastic method achieves a gradient complexity of O( epsilon(-4)). The DRGDA and DRSGDA are the first algorithms for distributed minimax optimization with nonconvex constraints with exact convergence. Extensive experimental results on the Deep Neural Networks (DNNs) training over the Stiefel manifold demonstrate the efficiency of our algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26234/26006"
"26235","Faster Adaptive Federated Learning","['Xidong Wu', 'Feihu Huang', 'Zhengmian Hu', 'Heng Huang']","['University of Pittsburgh', 'University of Pittsburgh\nNanjing University of Aeronautics and Astronautics', 'University of Pittsburgh', 'University of Pittsburgh']","['ML: Optimization', 'ML: Distributed Machine Learning & Federated Learning']","Wu, X., Huang, F., Hu, Z., & Huang, H. (2023). Faster Adaptive Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10379-10387. https://doi.org/10.1609/aaai.v37i9.26235","Abstract 					Federated learning has attracted increasing attention with the emergence of distributed data. While extensive federated learning algorithms have been proposed for the non-convex distributed problem, the federated learning in practice still faces numerous challenges, such as the large training iterations to converge since the sizes of models and datasets keep increasing, and the lack of adaptivity by SGD-based model updates. Meanwhile, the study of adaptive methods in federated learning is scarce and existing works either lack a complete theoretical convergence guarantee or have slow sample complexity. In this paper, we propose an efficient adaptive algorithm (i.e., FAFED) based on the momentum-based variance reduced technique in cross-silo FL. We first explore how to design the adaptive algorithm in the FL setting. By providing a counter-example, we prove that a simple combination of FL and adaptive methods could lead to divergence. More importantly, we provide a convergence analysis for our method and prove that our algorithm is the first adaptive FL algorithm to reach the best-known samples O(epsilon(-3)) and O(epsilon(-2)) communication rounds to find an epsilon-stationary point without large batches. The experimental results on the language modeling task and image classification task with heterogeneous data demonstrate the efficiency of our algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26235/26007"
"26236","Practical Markov Boundary Learning without Strong Assumptions","['Xingyu Wu', 'Bingbing Jiang', 'Tianhao Wu', 'Huanhuan Chen']","['University of Science and Technology of China', 'Hangzhou Normal University', 'University of Science and Technology of China', 'School of Computer Science and Technology, University of Science and Technology of China']","['ML: Dimensionality Reduction/Feature Selection', 'ML: Causal Learning', 'RU: Causality', 'RU: Bayesian Networks']","Wu, X., Jiang, B., Wu, T., & Chen, H. (2023). Practical Markov Boundary Learning without Strong Assumptions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10388-10398. https://doi.org/10.1609/aaai.v37i9.26236","Abstract 					Theoretically, the Markov boundary (MB) is the optimal solution for feature selection. However, existing MB learning algorithms often fail to identify some critical features in real-world feature selection tasks, mainly because the strict assumptions of existing algorithms, on either data distribution, variable types, or correctness of criteria, cannot be satisfied in application scenarios. This paper takes further steps toward opening the door to real-world applications for MB. We contribute in particular to a practical MB learning strategy, which can maintain feasibility and effectiveness in real-world data where variables can be numerical or categorical with linear or nonlinear, pairwise or multivariate relationships. Specifically, the equivalence between MB and the minimal conditional covariance operator (CCO) is investigated, which inspires us to design the objective function based on the predictability evaluation of the mapping variables in a reproducing kernel Hilbert space. Based on this, a kernel MB learning algorithm is proposed, where nonlinear multivariate dependence could be considered without extra requirements on data distribution and variable types. Extensive experiments demonstrate the efficacy of these contributions.","https://ojs.aaai.org/index.php/AAAI/article/view/26236/26008"
"26237","FedNP: Towards Non-IID Federated Learning via Federated Neural Propagation","['Xueyang Wu', 'Hengguan Huang', 'Youlong Ding', 'Hao Wang', 'Ye Wang', 'Qian Xu']","['The Hong Kong University of Science and Technology', 'National University of Singapore', 'Shenzhen University', 'Rutgers University', 'National University of Singapore', 'HKUST']","['ML: Distributed Machine Learning & Federated Learning', 'RU: Stochastic Models & Probabilistic Inference']","Wu, X., Huang, H., Ding, Y., Wang, H., Wang, Y., & Xu, Q. (2023). FedNP: Towards Non-IID Federated Learning via Federated Neural Propagation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10399-10407. https://doi.org/10.1609/aaai.v37i9.26237","Abstract 					Traditional federated learning (FL) algorithms, such as FedAvg, fail to handle non-i.i.d data because they learn a global model by simply averaging biased local models that are trained on non-i.i.d local data, therefore failing to model the global data distribution.  In this paper, we present a novel Bayesian FL algorithm that successfully handles such a non-i.i.d FL setting by enhancing the local training task with an auxiliary task that explicitly estimates the global data distribution.  One key challenge in estimating the global data distribution is that the data are partitioned in FL, and therefore the ground-truth global data distribution is inaccessible. To address this challenge, we propose an expectation-propagation-inspired probabilistic neural network, dubbed federated neural propagation (FedNP), which efficiently estimates the global data distribution given non-i.i.d data partitions. Our algorithm is sampling-free and end-to-end differentiable, can be applied with any conventional FL frameworks and learns richer global data representation. Experiments on both image classification tasks with synthetic non-i.i.d image data partitions and real-world non-i.i.d speech recognition tasks demonstrate that our framework effectively alleviates the performance deterioration caused by non-i.i.d data.","https://ojs.aaai.org/index.php/AAAI/article/view/26237/26009"
"26238","MetaZSCIL: A Meta-Learning Approach for Generalized Zero-Shot Class Incremental Learning","['Yanan Wu', 'Tengfei Liang', 'Songhe Feng', 'Yi Jin', 'Gengyu Lyu', 'Haojun Fei', 'Yang Wang']","['Beijing Jiaotong University', 'Beijing Jiaotong University', 'School of Computer and Information Technology, Beijing Jiaotong University', 'Beijing JiaoTong University', 'Beijing University of Technology', '360 DigiTech, Inc.', 'Concordia University']","['ML: Multi-Instance/Multi-View Learning', 'CV: Image and Video Retrieval']","Wu, Y., Liang, T., Feng, S., Jin, Y., Lyu, G., Fei, H., & Wang, Y. (2023). MetaZSCIL: A Meta-Learning Approach for Generalized Zero-Shot Class Incremental Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10408-10416. https://doi.org/10.1609/aaai.v37i9.26238","Abstract 					Generalized zero-shot learning (GZSL) aims to recognize samples whose categories may not have been seen at training. Standard GZSL cannot handle dynamic addition of new seen and unseen classes. In order to address this limitation, some recent attempts have been made to develop continual GZSL methods. However, these methods require end-users to continuously collect and annotate numerous seen class samples, which is unrealistic and hampers the applicability in the real-world. Accordingly, in this paper, we propose a more practical and challenging setting named Generalized Zero-Shot Class Incremental Learning (CI-GZSL). Our setting aims to incrementally learn unseen classes without any training samples, while recognizing all classes previously encountered. We further propose a bi-level meta-learning based method called MetaZSCIL to directly optimize the network to learn how to incrementally learn. Specifically, we sample sequential tasks from seen classes during the offline training to simulate the incremental learning process. For each task, the model is learned using a meta-objective such that it is capable to perform fast adaptation without forgetting. Note that our optimization can be flexibly equipped with most existing generative methods to tackle CI-GZSL. This work introduces a feature generative framework that leverages visual feature distribution alignment to produce replayed samples of previously seen classes to reduce catastrophic forgetting. Extensive experiments conducted on five widely used benchmarks demonstrate the superiority of our proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/26238/26010"
"26239","Adversarial Weight Perturbation Improves Generalization in Graph Neural Networks","['Yihan Wu', 'Aleksandar Bojchevski', 'Heng Huang']","['University of Pittsburgh', 'CISPA Helmholtz Center for Information Security', 'University of Pittsburgh']","['ML: Graph-based Machine Learning', 'ML: Adversarial Learning & Robustness']","Wu, Y., Bojchevski, A., & Huang, H. (2023). Adversarial Weight Perturbation Improves Generalization in Graph Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10417-10425. https://doi.org/10.1609/aaai.v37i9.26239","Abstract 					A lot of theoretical and empirical evidence shows that the flatter local minima tend to improve generalization. Adversarial Weight Perturbation (AWP) is an emerging technique to efficiently and effectively find such minima. In AMP we minimize the loss w.r.t. a bounded worst-case perturbation of the model parameters thereby favoring local minima with a small loss in a neighborhood around them. The benefits of AWP, and more generally the connections between flatness and generalization, have been extensively studied for i.i.d. data such as images. In this paper, we extensively study this phenomenon for graph data. Along the way, we first derive a generalization bound for non-i.i.d. node classification tasks. Then we identify a vanishing-gradient issue with all existing formulations of AWP and we propose a new Weighted Truncated AWP (WT-AWP) to alleviate this issue. We show that regularizing graph neural networks with WT-AWP consistently improves both natural and robust generalization across many different graph learning tasks and models.","https://ojs.aaai.org/index.php/AAAI/article/view/26239/26011"
"26240","Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning","['Young Wu', 'Jeremy McMahan', 'Xiaojin Zhu', 'Qiaomin Xie']","['University of Wisconsin-Madison', 'University of Wisconsin-Madison', 'University of Wisconsin-Madison', 'University of Wisconsin-Madison']","['ML: Adversarial Learning & Robustness', 'GTEP: Adversarial Learning']","Wu, Y., McMahan, J., Zhu, X., & Xie, Q. (2023). Reward Poisoning Attacks on Offline Multi-Agent Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10426-10434. https://doi.org/10.1609/aaai.v37i9.26240","Abstract 					In offline multi-agent reinforcement learning (MARL), agents estimate policies from a given dataset. We study reward-poisoning attacks in this setting where an exogenous attacker modifies the rewards in the dataset before the agents see the dataset. The attacker wants to guide each agent into a nefarious target policy while minimizing the Lp norm of the reward modification. Unlike attacks on single-agent RL, we show that the attacker can install the target policy as a Markov Perfect Dominant Strategy Equilibrium (MPDSE), which rational agents are guaranteed to follow. This attack can be significantly cheaper than separate single-agent attacks. We show that the attack works on various MARL agents including uncertainty-aware learners, and we exhibit linear programs to efficiently solve the attack problem. We also study the relationship between the structure of the datasets and the minimal attack cost. Our work paves the way for studying defense in offline MARL.","https://ojs.aaai.org/index.php/AAAI/article/view/26240/26012"
"26241","Models as Agents: Optimizing Multi-Step Predictions of Interactive Local Models in Model-Based Multi-Agent Reinforcement Learning","['Zifan Wu', 'Chao Yu', 'Chen Chen', 'Jianye Hao', 'Hankz Hankui Zhuo']","['Sun Yat-sen University', 'Sun Yat-sen University\nPengcheng Laboratory', 'Huawei Noah’s Ark Lab', ""Huawei Noah's Ark Lab"", 'Sun Yat-sen University']","['ML: Reinforcement Learning Algorithms', 'MAS: Multiagent Learning']","Wu, Z., Yu, C., Chen, C., Hao, J., & Zhuo, H. H. (2023). Models as Agents: Optimizing Multi-Step Predictions of Interactive Local Models in Model-Based Multi-Agent Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10435-10443. https://doi.org/10.1609/aaai.v37i9.26241","Abstract 					Research in model-based reinforcement learning has made significant progress in recent years. Compared to single-agent settings, the exponential dimension growth of the joint state-action space in multi-agent systems dramatically increases the complexity of the environment dynamics, which makes it infeasible to learn an accurate global model and thus necessitates the use of agent-wise local models. However, during multi-step model rollouts, the prediction of one local model can affect the predictions of other local models in the next step. As a result, local prediction errors can be propagated to other localities and eventually give rise to considerably large global errors. Furthermore, since the models are generally used to predict for multiple steps, simply minimizing one-step prediction errors regardless of their long-term effect on other models may further aggravate the propagation of local errors. To this end, we propose Models as AGents (MAG), a multi-agent model optimization framework that reversely treats the local models as multi-step decision making agents and the current policies as the dynamics during the model rollout process. In this way, the local models are able to consider the multi-step mutual affect between each other before making predictions. Theoretically, we show that the objective of MAG is approximately equivalent to maximizing a lower bound of the true environment return. Experiments on the challenging StarCraft II benchmark demonstrate the effectiveness of MAG.","https://ojs.aaai.org/index.php/AAAI/article/view/26241/26013"
"26242","Differentially Private Learning with Per-Sample Adaptive Clipping","['Tianyu Xia', 'Shuheng Shen', 'Su Yao', 'Xinyi Fu', 'Ke Xu', 'Xiaolong Xu', 'Xing Fu']","['School of Software & Microelectronics, Peking University', 'Tiansuan Lab, Ant Group', 'Beijing National Research Center for Information Science and Technology (BNRist), Tsinghua University', 'Tiansuan Lab, Ant Group', 'Department of Computer Science & Technology, Tsinghua University\nZhongguancun Laboratory, Beijing', 'Tiansuan Lab, Ant Group', 'Tiansuan Lab, Ant Group']","['ML: Privacy-Aware ML', 'CV: Bias', 'Fairness & Privacy', 'ML: Optimization', 'PEAI: Privacy and Security']","Xia, T., Shen, S., Yao, S., Fu, X., Xu, K., Xu, X., & Fu, X. (2023). Differentially Private Learning with Per-Sample Adaptive Clipping. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10444-10452. https://doi.org/10.1609/aaai.v37i9.26242","Abstract 					Privacy in AI remains a topic that draws attention from researchers and the general public in recent years. As one way to implement privacy-preserving AI, differentially private learning is a framework that enables AI models to use differential privacy (DP). To achieve DP in the learning process, existing algorithms typically limit the magnitude of gradients with a constant clipping, which requires carefully tuned due to its significant impact on model performance. As a solution to this issue, latest works NSGD and Auto-S innovatively propose to use normalization instead of clipping to avoid hyperparameter tuning. However, normalization-based approaches like NSGD and Auto-S rely on a monotonic weight function, which imposes excessive weight on small gradient samples and introduces extra deviation to the update. In this paper, we propose a Differentially Private Per-Sample Adaptive Clipping (DP-PSAC) algorithm based on a non-monotonic adaptive weight function, which guarantees privacy without the typical hyperparameter tuning process of using a constant clipping while significantly reducing the deviation between the update and true batch-averaged gradient. We provide a rigorous theoretical convergence analysis and show that with convergence rate at the same order, the proposed algorithm achieves a lower non-vanishing bound, which is maintained over training iterations, compared with NSGD/Auto-S.  In addition, through extensive experimental evaluation, we show that DP-PSAC outperforms or matches the state-of-the-art methods on multiple main-stream vision and language tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26242/26014"
"26243","Zero-Cost Operation Scoring in Differentiable Architecture Search","['Lichuan Xiang', 'Lukasz Dudziak', 'Mohamed S. Abdelfattah', 'Thomas Chau', 'Nicholas D. Lane', 'Hongkai Wen']","['University of Warwick', 'Samsung AI Center Cambridge', 'Cornell University', 'Samsung AI Center Cambridge', 'Samsung AI Center Cambridge\nUniversity of Cambridge', 'University of Warwick\nSamsung AI Center Cambridge']","['ML: Auto ML and Hyperparameter Tuning', 'ML: Deep Neural Architectures']","Xiang, L., Dudziak, L., Abdelfattah, M. S., Chau, T., Lane, N. D., & Wen, H. (2023). Zero-Cost Operation Scoring in Differentiable Architecture Search. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10453-10463. https://doi.org/10.1609/aaai.v37i9.26243","Abstract 					We formalize and analyze a fundamental component of dif- ferentiable neural architecture search (NAS): local “opera- tion scoring” at each operation choice. We view existing operation scoring functions as inexact proxies for accuracy, and we find that they perform poorly when analyzed empir- ically on NAS benchmarks. From this perspective, we intro- duce a novel perturbation-based zero-cost operation scor- ing (Zero-Cost-PT) approach, which utilizes zero-cost prox- ies that were recently studied in multi-trial NAS but de- grade significantly on larger search spaces, typical for dif- ferentiable NAS. We conduct a thorough empirical evalu- ation on a number of NAS benchmarks and large search spaces, from NAS-Bench-201, NAS-Bench-1Shot1, NAS- Bench-Macro, to DARTS-like and MobileNet-like spaces, showing significant improvements in both search time and accuracy. On the ImageNet classification task on the DARTS search space, our approach improved accuracy compared to the best current training-free methods (TE-NAS) while be- ing over 10× faster (total searching time 25 minutes on a single GPU), and observed significantly better transferabil- ity on architectures searched on the CIFAR-10 dataset with an accuracy increase of 1.8 pp. Our code is available at: https://github.com/zerocostptnas/zerocost operation score.","https://ojs.aaai.org/index.php/AAAI/article/view/26243/26015"
"26244","HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks","['Jinqi Xiao', 'Chengming Zhang', 'Yu Gong', 'Miao Yin', 'Yang Sui', 'Lizhi Xiang', 'Dingwen Tao', 'Bo Yuan']","['Rutgers University', 'Indiana University', 'Rutgers University', 'Rutgers University', 'Rutgers University', 'Washington State University', 'Indiana University', 'Rutgers university']","['ML: Learning on the Edge & Model Compression']","Xiao, J., Zhang, C., Gong, Y., Yin, M., Sui, Y., Xiang, L., Tao, D., & Yuan, B. (2023). HALOC: Hardware-Aware Automatic Low-Rank Compression for Compact Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10464-10472. https://doi.org/10.1609/aaai.v37i9.26244","Abstract 					Low-rank compression is an important model compression strategy for obtaining compact neural network models. In general, because the rank values directly determine the model complexity and model accuracy, proper selection of layer-wise rank is very critical and desired. To date, though many low-rank compression approaches, either selecting the ranks in a manual or automatic way, have been proposed, they suffer from costly manual trials or unsatisfied compression performance. In addition, all of the existing works are not designed in a hardware-aware way, limiting the practical performance of the compressed models on real-world hardware platforms.    To address these challenges, in this paper we propose HALOC, a hardware-aware automatic low-rank compression framework. By interpreting automatic rank selection from an architecture search perspective, we develop an end-to-end solution to determine the suitable layer-wise ranks in a differentiable and hardware-aware way. We further propose design principles and mitigation strategy to efficiently explore the rank space and reduce the potential interference problem.  Experimental results on different datasets and hardware platforms demonstrate the effectiveness of our proposed approach.  On CIFAR-10 dataset, HALOC enables 0.07% and 0.38% accuracy increase over the uncompressed ResNet-20 and VGG-16 models with 72.20% and 86.44% fewer FLOPs, respectively. On ImageNet dataset, HALOC achieves 0.9% higher top-1 accuracy than the original ResNet-18 model with 66.16% fewer FLOPs. HALOC also shows 0.66% higher top-1 accuracy increase than the state-of-the-art automatic low-rank compression solution with fewer computational and memory costs. In addition, HALOC demonstrates the practical speedups on different hardware platforms, verified by the measurement results on desktop GPU, embedded GPU and ASIC accelerator.","https://ojs.aaai.org/index.php/AAAI/article/view/26244/26016"
"26245","Bayesian Federated Neural Matching That Completes Full Information","['Peng Xiao', 'Samuel Cheng']","['Tongji University', 'University of Oklahoma']","['ML: Bayesian Learning', 'ML: Distributed Machine Learning & Federated Learning']","Xiao, P., & Cheng, S. (2023). Bayesian Federated Neural Matching That Completes Full Information. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10473-10480. https://doi.org/10.1609/aaai.v37i9.26245","Abstract 					Federated learning is a contemporary machine learning paradigm where locally trained models are distilled into a global model. Due to the intrinsic permutation invariance of neural networks, Probabilistic Federated Neural Matching (PFNM) employs a Bayesian nonparametric framework in the generation process of local neurons, and then creates a linear sum assignment formulation in each alternative optimization iteration. But according to our theoretical analysis, the optimization iteration in PFNM omits global information from existing. In this study, we propose a novel approach that overcomes this flaw by introducing a Kullback-Leibler  divergence penalty at each iteration. The effectiveness of our approach is demonstrated by experiments on both image classification and semantic segmentation tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26245/26017"
"26246","CDMA: A Practical Cross-Device Federated Learning Algorithm for General Minimax Problems","['Jiahao Xie', 'Chao Zhang', 'Zebang Shen', 'Weijie Liu', 'Hui Qian']","['College of Computer Science and Technology, Zhejiang University', 'Advanced Technology Institute, Zhejiang University', 'ETH Zurich', 'Qiushi Academy for Advanced Studies, Zhejiang University\nCollege of Computer Science and Technology, Zhejiang University', 'College of Computer Science and Technology, Zhejiang University\nState Key Lab of CAD&CG, Zhejiang University']","['ML: Distributed Machine Learning & Federated Learning', 'ML: Optimization']","Xie, J., Zhang, C., Shen, Z., Liu, W., & Qian, H. (2023). CDMA: A Practical Cross-Device Federated Learning Algorithm for General Minimax Problems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10481-10489. https://doi.org/10.1609/aaai.v37i9.26246","Abstract 					Minimax problems arise in a wide range of important applications including robust adversarial learning and Generative Adversarial Network (GAN) training. Recently, algorithms for minimax problems in the Federated Learning (FL) paradigm have received considerable interest. Existing federated algorithms for general minimax problems require the full aggregation (i.e., aggregation of local model information from all clients) in each training round. Thus, they are inapplicable to an important setting of FL known as the cross-device setting, which involves numerous unreliable mobile/IoT devices. In this paper, we develop the first practical algorithm named CDMA for general minimax problems in the cross-device FL setting. CDMA is based on a Start-Immediately-With-Enough-Responses mechanism, in which the server first signals a subset of clients to perform local computation and then starts to aggregate the local results reported by clients once it receives responses from enough clients in each round. With this mechanism, CDMA is resilient to the low client availability. In addition, CDMA is incorporated with a lightweight global correction in the local update steps of clients, which mitigates the impact of slow network connections. We establish theoretical guarantees of CDMA under different choices of hyperparameters and conduct experiments on AUC maximization, robust adversarial network training, and GAN training tasks. Theoretical and experimental results demonstrate the efficiency of CDMA.","https://ojs.aaai.org/index.php/AAAI/article/view/26246/26018"
"26247","Towards Optimal Randomized Strategies in Adversarial Example Game","['Jiahao Xie', 'Chao Zhang', 'Weijie Liu', 'Wensong Bai', 'Hui Qian']","['College of Computer Science and Technology, Zhejiang University', 'Advanced Technology Institute, Zhejiang University', 'Qiushi Academy for Advanced Studies, Zhejiang University\nCollege of Computer Science and Technology, Zhejiang University', 'College of Computer Science and Technology, Zhejiang University\nAdvanced Technology Institute, Zhejiang University', 'College of Computer Science and Technology, Zhejiang University\nState Key Lab of CAD&CG, Zhejiang University']","['ML: Adversarial Learning & Robustness', 'ML: Optimization']","Xie, J., Zhang, C., Liu, W., Bai, W., & Qian, H. (2023). Towards Optimal Randomized Strategies in Adversarial Example Game. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10490-10498. https://doi.org/10.1609/aaai.v37i9.26247","Abstract 					The vulnerability of deep neural network models to adversarial example attacks is a practical challenge in many artificial intelligence applications. A recent line of work shows that the use of randomization in adversarial training is the key to find optimal strategies against adversarial example attacks. However, in a fully randomized setting where both the defender and the attacker can use randomized strategies, there are no efficient algorithm for finding such an optimal strategy. To fill the gap, we propose the first algorithm of its kind, called FRAT, which models the problem with a new infinite-dimensional continuous-time flow on probability distribution spaces. FRAT maintains a lightweight mixture of models for the defender, with flexibility to efficiently update mixing weights and model parameters at each iteration. Furthermore, FRAT utilizes lightweight sampling subroutines to construct a random strategy for the attacker. We prove that the continuous-time limit of FRAT converges to a mixed Nash equilibria in a zero-sum game formed by a defender and an attacker. Experimental results also demonstrate the efficiency of FRAT on CIFAR-10 and CIFAR-100 datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26247/26019"
"26248","A Tale of Two Latent Flows: Learning Latent Space Normalizing Flow with Short-Run Langevin Flow for Approximate Inference","['Jianwen Xie', 'Yaxuan Zhu', 'Yifei Xu', 'Dingcheng Li', 'Ping Li']","['Baidu Research', 'Baidu Research', 'Baidu Research', 'Baidu Research', 'Baidu Research']","['ML: Deep Generative Models & Autoencoders', 'CV: Computational Photography', 'Image & Video Synthesis', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning']","Xie, J., Zhu, Y., Xu, Y., Li, D., & Li, P. (2023). A Tale of Two Latent Flows: Learning Latent Space Normalizing Flow with Short-Run Langevin Flow for Approximate Inference. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10499-10509. https://doi.org/10.1609/aaai.v37i9.26248","Abstract 					We study a normalizing flow in the latent space of a top-down generator model, in which the normalizing flow model plays the role of the informative prior model of the generator. We propose to jointly learn the latent space normalizing flow prior model and the top-down generator model by a Markov chain Monte Carlo (MCMC)-based maximum likelihood algorithm, where a short-run Langevin sampling from the intractable posterior distribution is performed to infer the latent variables for each observed example, so that the parameters of the normalizing flow prior and the generator can be updated with the inferred latent variables. We show that, under the scenario of non-convergent short-run MCMC, the finite step Langevin dynamics is a flow-like approximate inference model and the learning objective actually follows the perturbation of the maximum likelihood estimation (MLE). We further point out that the learning framework seeks to (i) match the latent space normalizing flow and the aggregated posterior produced by the short-run Langevin flow, and (ii) bias the model from MLE such that the short-run Langevin flow inference is close to the true posterior. Empirical results of extensive experiments validate the effectiveness of the proposed latent space normalizing flow model in the tasks of image generation, image reconstruction, anomaly detection, supervised image inpainting and unsupervised image recovery.","https://ojs.aaai.org/index.php/AAAI/article/view/26248/26020"
"26249","Semi-supervised Learning with Support Isolation by Small-Paced Self-Training","['Zheng Xie', 'Hui Sun', 'Ming Li']","['Nanjing University', 'Nanjing University', 'Nanjing University']","['ML: Semi-Supervised Learning']","Xie, Z., Sun, H., & Li, M. (2023). Semi-supervised Learning with Support Isolation by Small-Paced Self-Training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10510-10518. https://doi.org/10.1609/aaai.v37i9.26249","Abstract 					In this paper, we address a special scenario of semi-supervised learning, where the label missing is caused by a preceding filtering mechanism, i.e., an instance can enter a subsequent process in which its label is revealed if and only if it passes the filtering mechanism. The rejected instances are prohibited to enter the subsequent labeling process due to economical or ethical reasons, making the support of the labeled and unlabeled distributions isolated from each other. In this case, semi-supervised learning approaches which rely on certain coherence of the labeled and unlabeled distribution would suffer from the consequent distribution mismatch, and hence result in poor prediction performance. In this paper, we propose a Small-Paced Self-Training framework, which iteratively discovers labeled and unlabeled instance subspaces with bounded Wasserstein distance. We theoretically prove that such a framework may achieve provably low error on the pseudo labels during learning. Experiments on both benchmark and pneumonia diagnosis tasks show that our method is effective.","https://ojs.aaai.org/index.php/AAAI/article/view/26249/26021"
"26250","On the Connection between Invariant Learning and Adversarial Training for Out-of-Distribution Generalization","['Shiji Xin', 'Yifei Wang', 'Jingtong Su', 'Yisen Wang']","['Peking University', 'Peking University', 'New York University', 'Peking University']","['ML: Adversarial Learning & Robustness']","Xin, S., Wang, Y., Su, J., & Wang, Y. (2023). On the Connection between Invariant Learning and Adversarial Training for Out-of-Distribution Generalization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10519-10527. https://doi.org/10.1609/aaai.v37i9.26250","Abstract 					Despite impressive success in many tasks, deep learning models are shown to rely on spurious features, which will catastrophically fail when generalized to out-of-distribution (OOD) data. Invariant Risk Minimization (IRM) is proposed to alleviate this issue by extracting domain-invariant features for OOD generalization. Nevertheless, recent work shows that IRM is only effective for a certain type of distribution shift (e.g., correlation shift) while it fails for other cases (e.g., diversity shift). Meanwhile, another thread of method, Adversarial Training (AT), has shown better domain transfer performance, suggesting that it has the potential to be an effective candidate for extracting domain-invariant features. This paper investigates this possibility by exploring the similarity between the IRM and AT objectives. Inspired by this connection, we propose Domain-wise Adversarial Training (DAT), an AT-inspired method for alleviating distribution shift by domain-specific perturbations. Extensive experiments show that our proposed DAT can effectively remove domain-varying features and improve OOD generalization under both correlation shift and diversity shift.","https://ojs.aaai.org/index.php/AAAI/article/view/26250/26022"
"26251","Decentralized Stochastic Multi-Player Multi-Armed Walking Bandits","['Guojun Xiong', 'Jian Li']","['SUNY-Binghamton University', 'SUNY-Binghamton University']","['ML: Online Learning & Bandits']","Xiong, G., & Li, J. (2023). Decentralized Stochastic Multi-Player Multi-Armed Walking Bandits. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10528-10536. https://doi.org/10.1609/aaai.v37i9.26251","Abstract 					Multi-player multi-armed bandit is an increasingly relevant decision-making problem, motivated by applications to cognitive radio systems.  Most research for this problem focuses exclusively on the settings that players have full access to all arms and receive no reward when pulling the same arm.  Hence all players solve the same bandit problem with the goal of maximizing their cumulative reward. However, these settings neglect several important factors in many real-world applications, where players have limited access to a dynamic local subset of arms (i.e., an arm could sometimes be ``walking'' and not accessible to the player).  To this end, this paper proposes a multi-player multi-armed walking bandits model, aiming to address aforementioned modeling issues. The goal now is to maximize the reward, however, players can only pull arms from the local subset and only collect a full reward if no other players pull the same arm.  We adopt Upper Confidence Bound (UCB) to deal with the exploration-exploitation tradeoff and employ distributed optimization techniques to properly handle collisions.  By carefully integrating these two techniques, we propose a decentralized algorithm with near-optimal guarantee on the regret, and can be easily implemented to obtain competitive empirical performance.","https://ojs.aaai.org/index.php/AAAI/article/view/26251/26023"
"26252","Federated Generative Model on Multi-Source Heterogeneous Data in IoT","['Zuobin Xiong', 'Wei Li', 'Zhipeng Cai']","['Georgia State University', 'Georgia State University', 'Georgia State University']","['ML: Deep Generative Models & Autoencoders', 'ML: Adversarial Learning & Robustness', 'ML: Distributed Machine Learning & Federated Learning']","Xiong, Z., Li, W., & Cai, Z. (2023). Federated Generative Model on Multi-Source Heterogeneous Data in IoT. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10537-10545. https://doi.org/10.1609/aaai.v37i9.26252","Abstract 					The study of generative models is a promising branch of deep learning techniques, which has been successfully applied to different scenarios, such as Artificial Intelligence and the Internet of Things. While in most of the existing works, the generative models are realized as a centralized structure, raising the threats of security and privacy and the overburden of communication costs. Rare efforts have been committed to investigating distributed generative models, especially when the training data comes from multiple heterogeneous sources under realistic IoT settings. In this paper, to handle this challenging problem, we design a federated generative model framework that can learn a powerful generator for the hierarchical IoT systems. Particularly, our generative model framework can solve the problem of distributed data generation on multi-source heterogeneous data in two scenarios, i.e., feature related scenario and label related scenario. In addition, in our federated generative models, we develop a synchronous and an asynchronous updating methods to satisfy different application requirements. Extensive experiments on a simulated dataset and multiple real datasets are conducted to evaluate the data generation performance of our proposed generative models through comparison with the state-of-the-arts.","https://ojs.aaai.org/index.php/AAAI/article/view/26252/26024"
"26253","Contrastive Open Set Recognition","['Baile Xu', 'Furao Shen', 'Jian Zhao']","['State Key Laboratory for Novel Software Technology, Nanjing University\nDepartment of Computer Science and Technology, Nanjing University', 'State Key Laboratory for Novel Software Technology, Nanjing University\nSchool of Artificial Intelligence, Nanjing University', 'School of Electronic Science and Engineering, Nanjing University']","['ML: Classification and Regression', 'ML: Representation Learning']","Xu, B., Shen, F., & Zhao, J. (2023). Contrastive Open Set Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10546-10556. https://doi.org/10.1609/aaai.v37i9.26253","Abstract 					In conventional recognition tasks, models are only trained to recognize learned targets, but it is usually difficult to collect training examples of all potential categories. In the testing phase, when models receive test samples from unknown classes, they mistakenly classify the samples into known classes. Open set recognition (OSR) is a more realistic recognition task, which requires the classifier to detect unknown test samples while keeping a high classification accuracy of known classes. In this paper, we study how to improve the OSR performance of deep neural networks from the perspective of representation learning. We employ supervised contrastive learning to improve the quality of feature representations, propose a new supervised contrastive learning method that enables the model to learn from soft training targets, and design an OSR framework on its basis. With the proposed method, we are able to make use of label smoothing and mixup when training deep neural networks contrastively, so as to improve both the robustness of outlier detection in OSR tasks and the accuracy in conventional classification tasks. We validate our method on multiple benchmark datasets and testing scenarios, achieving experimental results that verify the effectiveness of the proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/26253/26025"
"26254","Progressive Deep Multi-View Comprehensive Representation Learning","['Cai Xu', 'Wei Zhao', 'Jinglong Zhao', 'Ziyu Guan', 'Yaming Yang', 'Long Chen', 'Xiangyu Song']","['Xidian University', 'Xidian University', 'Xidian University', 'Xidian University', 'Xidian University', 'Xi’an University of Posts & Telecommunications', 'Deakin University']","['ML: Multi-Instance/Multi-View Learning', 'ML: Classification and Regression', 'ML: Multimodal Learning', 'ML: Representation Learning']","Xu, C., Zhao, W., Zhao, J., Guan, Z., Yang, Y., Chen, L., & Song, X. (2023). Progressive Deep Multi-View Comprehensive Representation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10557-10565. https://doi.org/10.1609/aaai.v37i9.26254","Abstract 					Multi-view Comprehensive Representation Learning (MCRL) aims to synthesize information from multiple views to learn comprehensive representations of data items. Prevalent deep MCRL methods typically concatenate synergistic view-specific representations or average aligned view-specific representations in the fusion stage. However, the performance of synergistic fusion methods inevitably degenerate or even fail when partial views are missing in real-world applications; the aligned based fusion methods usually cannot fully exploit the complementarity of multi-view data. To eliminate all these drawbacks, in this work we present a Progressive Deep Multi-view Fusion (PDMF) method. Considering the multi-view comprehensive representation should contain complete information and the view-specific data contain partial information, we deem that it is unstable to directly learn the mapping from partial information to complete information. Hence, PDMF employs a progressive learning strategy, which contains the pre-training and fine-tuning stages. In the pre-training stage, PDMF decodes the auxiliary comprehensive representation to the view-specific data. It also captures the consistency and complementarity by learning the relations between the dimensions of the auxiliary comprehensive representation and all views. In the fine-tuning stage, PDMF learns the mapping from the original data to the comprehensive representation with the help of the auxiliary comprehensive representation and relations. Experiments conducted on a synthetic toy dataset and 4 real-world datasets show that PDMF outperforms state-of-the-art baseline methods. The code is released at https://github.com/winterant/PDMF.","https://ojs.aaai.org/index.php/AAAI/article/view/26254/26026"
"26255","A Survey on Model Compression and Acceleration for Pretrained Language Models","['Canwen Xu', 'Julian McAuley']","['University of California, San Diego', 'University of California, San Diego']","['ML: Learning on the Edge & Model Compression', 'SNLP: Language Models']","Xu, C., & McAuley, J. (2023). A Survey on Model Compression and Acceleration for Pretrained Language Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10566-10575. https://doi.org/10.1609/aaai.v37i9.26255","Abstract 					Despite achieving state-of-the-art performance on many NLP tasks, the high energy cost and long inference delay prevent Transformer-based pretrained language models (PLMs) from seeing broader adoption including for edge and mobile computing. Efficient NLP research aims to comprehensively consider computation, time and carbon emission for the entire life-cycle of NLP, including data preparation, model training and inference. In this survey, we focus on the inference stage and review the current state of model compression and acceleration for pretrained language models, including benchmarks, metrics and methodology.","https://ojs.aaai.org/index.php/AAAI/article/view/26255/26027"
"26256","GraphPrompt: Graph-Based Prompt Templates for Biomedical Synonym Prediction","['Hanwen Xu', 'Jiayou Zhang', 'Zhirui Wang', 'Shizhuo Zhang', 'Megh Bhalerao', 'Yucong Liu', 'Dawei Zhu', 'Sheng Wang']","['University of Washington', 'Mohamed bin Zayed University of Artificial Intelligence', 'Carnegie Mellon University', 'Nanyang Technological University', 'University of Washington', 'Peking University', 'Peking University', 'Paul G. Allen School of Computer Science\nUniversity of Washington']","['ML: Representation Learning', 'ML: Classification and Regression', 'ML: Relational Learning']","Xu, H., Zhang, J., Wang, Z., Zhang, S., Bhalerao, M., Liu, Y., Zhu, D., & Wang, S. (2023). GraphPrompt: Graph-Based Prompt Templates for Biomedical Synonym Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10576-10584. https://doi.org/10.1609/aaai.v37i9.26256","Abstract 					In the expansion of biomedical dataset, the same category may be labeled with different terms, thus being tedious and onerous to curate these terms. Therefore, automatically mapping synonymous terms onto the ontologies is desirable, which we name as biomedical synonym prediction task. Unlike biomedical concept normalization (BCN), no clues from context can be used to enhance synonym prediction, making it essential to extract graph features from ontology. We introduce an expert-curated dataset OBO-syn encompassing 70 different types of concepts and 2 million curated concept-term pairs for evaluating synonym prediction methods. We find BCN methods perform weakly on this task for not making full use of graph information. Therefore, we propose GraphPrompt, a prompt-based learning approach that creates prompt templates according to the graphs. GraphPrompt obtained 37.2% and 28.5% improvement on zero-shot and few-shot settings respectively, indicating the effectiveness of these graph-based prompt templates. We envision that our method GraphPrompt and OBO-syn dataset can be broadly applied to graph-based NLP tasks, and serve as the basis for analyzing diverse and accumulating biomedical data. All the data and codes are avalible at: https://github.com/HanwenXuTHU/GraphPrompt","https://ojs.aaai.org/index.php/AAAI/article/view/26256/26028"
"26257","Open-Ended Diverse Solution Discovery with Regulated Behavior Patterns for Cross-Domain Adaptation","['Kang Xu', 'Yan Ma', 'Bingsheng Wei', 'Wei Li']","['Academy for Engineering and Technology, Fudan University', 'Academy for Engineering and Technology, Fudan University', 'Academy for Engineering and Technology, Fudan University', 'Academy for Engineering and Technology, Fudan University, Shanghai, China']","['ML: Reinforcement Learning Algorithms', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Ensemble Methods']","Xu, K., Ma, Y., Wei, B., & Li, W. (2023). Open-Ended Diverse Solution Discovery with Regulated Behavior Patterns for Cross-Domain Adaptation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10585-10593. https://doi.org/10.1609/aaai.v37i9.26257","Abstract 					While Reinforcement Learning can achieve impressive results for complex tasks, the learned policies are generally prone to fail in downstream tasks with even minor model mismatch or unexpected perturbations. Recent works have demonstrated that a policy population with diverse behavior characteristics can generalize to downstream environments with various discrepancies. However, such policies might result in catastrophic damage during the deployment in practical scenarios like real-world systems due to the unrestricted behaviors of trained policies. Furthermore, training diverse policies without regulation of the behavior can result in inadequate feasible policies for extrapolating to a wide range of test conditions with dynamics shifts. In this work, we aim to train diverse policies under the regularization of the behavior patterns. We motivate our paradigm by observing the inverse dynamics in the environment with partial state information and propose Diversity in Regulation (DiR) training diverse policies with regulated behaviors to discover desired patterns that benefit the generalization. Considerable empirical results on various variations of different environments indicate that our method attains improvements over other diversity-driven counterparts.","https://ojs.aaai.org/index.php/AAAI/article/view/26257/26029"
"26258","Efficient Top-K Feature Selection Using Coordinate Descent Method","['Lei Xu', 'Rong Wang', 'Feiping Nie', 'Xuelong Li']","['School of Computer Science, Northwestern Polytechnical University\nSchool of Artificial Intelligence, OPtics and ElectroNics (iOPEN), Northwestern Polytechnical University', 'School of Artificial Intelligence, OPtics and ElectroNics (iOPEN), Northwestern Polytechnical University', 'School of Computer Science, Northwestern Polytechnical University\nSchool of Artificial Intelligence, OPtics and ElectroNics (iOPEN), Northwestern Polytechnical University', 'School of Artificial Intelligence, OPtics and ElectroNics (iOPEN), Northwestern Polytechnical University']","['ML: Dimensionality Reduction/Feature Selection', 'ML: Optimization']","Xu, L., Wang, R., Nie, F., & Li, X. (2023). Efficient Top-K Feature Selection Using Coordinate Descent Method. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10594-10601. https://doi.org/10.1609/aaai.v37i9.26258","Abstract 					Sparse learning based feature selection has been widely investigated in recent years. In this study, we focus on the l2,0-norm based feature selection, which is effective for exact top-k feature selection but challenging to optimize. To solve the general l2,0-norm constrained problems, we novelly develop a parameter-free optimization framework based on the coordinate descend (CD) method, termed CD-LSR. Specifically, we devise a skillful conversion from the original problem to solving one continuous matrix and one discrete selection matrix. Then the nontrivial l2,0-norm constraint can be solved efficiently by solving the selection matrix with CD method. We impose the l2,0-norm on a vanilla least square regression (LSR) model for feature selection and optimize it with CD-LSR. Extensive experiments exhibit the efficiency of CD-LSR, as well as the discrimination ability of l2,0-norm to identify informative features. More importantly, the versatility of CD-LSR facilitates the applications of the l2,0-norm in more sophisticated models. Based on the competitive performance of l2,0-norm on the baseline LSR model, the satisfactory performance of its applications is reasonably expected. The source MATLAB code are available at: https://github.com/solerxl/Code_For_AAAI_2023.","https://ojs.aaai.org/index.php/AAAI/article/view/26258/26030"
"26259","Label-Specific Feature Augmentation for Long-Tailed Multi-Label Text Classification","['Pengyu Xu', 'Lin Xiao', 'Bing Liu', 'Sijin Lu', 'Liping Jing', 'Jian Yu']","['Beijing Jiaotong University', 'Beijing Jiaotong University', 'Beijing Jiaotong University', 'Beijing Jiaotong University,', 'Beijing Jiaotong University', 'Beijing Jiaotong University']","['ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'ML: Classification and Regression', 'ML: Deep Generative Models & Autoencoders', 'SNLP: Text Classification', 'ML: Deep Neural Network Algorithms', 'ML: Representation Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Unsupervised & Self-Supervised Learning', 'SNLP: Sentiment Analysis and Stylistic Analysis']","Xu, P., Xiao, L., Liu, B., Lu, S., Jing, L., & Yu, J. (2023). Label-Specific Feature Augmentation for Long-Tailed Multi-Label Text Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10602-10610. https://doi.org/10.1609/aaai.v37i9.26259","Abstract 					Multi-label text classification (MLTC) involves tagging a document with its most relevant subset of labels from a label set. In real applications, labels usually follow a long-tailed distribution, where most labels (called as tail-label) only contain a small number of documents and limit the performance of MLTC. To facilitate this low-resource problem, researchers introduced a simple but effective strategy, data augmentation (DA). However, most existing DA approaches struggle in multi-label settings. The main reason is that the augmented documents for one label may inevitably influence the other co-occurring labels and further exaggerate the long-tailed problem. To mitigate this issue, we propose a new pair-level augmentation framework for MLTC, called Label-Specific Feature Augmentation (LSFA), which merely augments positive feature-label pairs for the tail-labels. LSFA contains two main parts. The first is for label-specific document representation learning in the high-level latent space, the second is for augmenting tail-label features in latent space by transferring the documents second-order statistics (intra-class semantic variations) from head labels to tail labels. At last, we design a new loss function for adjusting classifiers based on augmented datasets. The whole learning procedure can be effectively trained. Comprehensive experiments on benchmark datasets have shown that the proposed LSFA outperforms the state-of-the-art counterparts.","https://ojs.aaai.org/index.php/AAAI/article/view/26259/26031"
"26260","Neighborhood-Regularized Self-Training for Learning with Few Labels","['Ran Xu', 'Yue Yu', 'Hejie Cui', 'Xuan Kan', 'Yanqiao Zhu', 'Joyce Ho', 'Chao Zhang', 'Carl Yang']","['Emory University', 'Georgia Institute of Technology', 'Emory University', 'Emory University', 'University of California, Los Angeles', 'Emory University', 'Georgia Institute of Technology', 'Emory University']","['ML: Semi-Supervised Learning', 'APP: Bioinformatics', 'SNLP: Text Classification']","Xu, R., Yu, Y., Cui, H., Kan, X., Zhu, Y., Ho, J., Zhang, C., & Yang, C. (2023). Neighborhood-Regularized Self-Training for Learning with Few Labels. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10611-10619. https://doi.org/10.1609/aaai.v37i9.26260","Abstract 					Training deep neural networks (DNNs) with limited supervision has been a popular research topic as it can significantly alleviate the annotation burden. Self-training has been successfully applied in semi-supervised learning tasks, but one drawback of self-training is that it is vulnerable to the label noise from incorrect pseudo labels. Inspired by the fact that samples with similar labels tend to share similar representations, we develop a neighborhood-based sample selection approach to tackle the issue of noisy pseudo labels. We further stabilize self-training via aggregating the predictions from different rounds during sample selection. Experiments on eight tasks show that our proposed method outperforms the strongest self-training baseline with 1.83% and 2.51% performance gain for text and graph datasets on average. Our further analysis demonstrates that our proposed data selection strategy reduces the noise of pseudo labels by 36.8% and saves 57.3% of the time when compared with the best baseline. Our code and appendices will be uploaded to: https://github.com/ritaranx/NeST.","https://ojs.aaai.org/index.php/AAAI/article/view/26260/26032"
"26261","Resilient Binary Neural Network","['Sheng Xu', 'Yanjing Li', 'Teli Ma', 'Mingbao Lin', 'Hao Dong', 'Baochang Zhang', 'Peng Gao', 'Jinhu Lu']","['Beihang University', 'Beihang University', 'Shanghai AI Laboratory', 'Tencent', 'Peking University', 'Beihang University\nZhongguancun Laboratory', 'Shanghai AI Laboratory', 'Beihang University\nZhongguancun Laboratory']","['ML: Learning on the Edge & Model Compression', 'CV: Language and Vision', 'CV: Other Foundations of Computer Vision']","Xu, S., Li, Y., Ma, T., Lin, M., Dong, H., Zhang, B., Gao, P., & Lu, J. (2023). Resilient Binary Neural Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10620-10628. https://doi.org/10.1609/aaai.v37i9.26261","Abstract 					Binary neural networks (BNNs) have received ever-increasing popularity for their great capability of reducing storage burden as well as quickening inference time. However, there is a severe performance drop compared with {real-valued} networks, due to its intrinsic frequent weight oscillation during training. In this paper, we introduce a Resilient Binary Neural Network (ReBNN) to mitigate the frequent oscillation for better BNNs' training. We identify that the weight oscillation mainly stems from the non-parametric scaling factor. To address this issue, we propose to parameterize the scaling factor and introduce a weighted reconstruction loss to build an adaptive training objective. For the first time, we show that the weight oscillation  is  controlled by the balanced parameter attached to the reconstruction loss, which provides a theoretical foundation to  parameterize it in back propagation. Based on this, we learn our ReBNN by calculating the balanced parameter based on its maximum magnitude, which can  effectively mitigate the weight oscillation with a resilient training process. Extensive experiments are conducted  upon various network models, such as ResNet and Faster-RCNN for computer vision, as well as BERT for natural language processing. The results demonstrate the overwhelming performance of our ReBNN over prior arts. For example, our ReBNN achieves 66.9% Top-1 accuracy with ResNet-18 backbone on the ImageNet dataset, surpassing existing state-of-the-arts by a significant margin. Our code is open-sourced at https://github.com/SteveTsui/ReBNN.","https://ojs.aaai.org/index.php/AAAI/article/view/26261/26033"
"26262","Transfer Learning Enhanced DeepONet for Long-Time Prediction of Evolution Equations","['Wuzhe Xu', 'Yulong Lu', 'Li Wang']","['University of Minnesota', 'University of Massachusetts Amherst', 'University of Minnesota']","['ML: Deep Neural Network Algorithms', 'ML: Applications', 'ML: Deep Neural Architectures', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Xu, W., Lu, Y., & Wang, L. (2023). Transfer Learning Enhanced DeepONet for Long-Time Prediction of Evolution Equations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10629-10636. https://doi.org/10.1609/aaai.v37i9.26262","Abstract 					Deep operator network (DeepONet) has demonstrated great success in various learning tasks, including learning solution operators of partial differential equations. In particular, it provides  an efficient approach to predicting the evolution equations in a finite time horizon. Nevertheless, the vanilla DeepONet suffers from the issue of stability degradation in the long- time prediction. This paper proposes a transfer-learning aided DeepONet to enhance the stability. Our idea is to use transfer learning to sequentially update the DeepONets as the surro- gates for propagators learned in different time frames. The evolving DeepONets can better track the varying complexities of the evolution equations, while only need to be updated by efficient training of a tiny fraction of the operator networks. Through systematic experiments, we show that the proposed method not only improves the long-time accuracy of Deep- ONet while maintaining similar computational cost but also substantially reduces the sample size of the training set.","https://ojs.aaai.org/index.php/AAAI/article/view/26262/26034"
"26263","BridgeTower: Building Bridges between Encoders in Vision-Language Representation Learning","['Xiao Xu', 'Chenfei Wu', 'Shachar Rosenman', 'Vasudev Lal', 'Wanxiang Che', 'Nan Duan']","['Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology\nMicrosoft Research Asia', 'Microsoft Research Asia', 'Intel Labs, Cognitive Computing Research', 'Intel Labs, Cognitive Computing Research', 'Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology', 'Microsoft Research Asia']","['ML: Multimodal Learning', 'SNLP: Speech and Multimodality']","Xu, X., Wu, C., Rosenman, S., Lal, V., Che, W., & Duan, N. (2023). BridgeTower: Building Bridges between Encoders in Vision-Language Representation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10637-10647. https://doi.org/10.1609/aaai.v37i9.26263","Abstract 					Vision-Language (VL) models with the Two-Tower architecture have dominated visual-language representation learning in recent years. Current VL models either use lightweight uni-modal encoders and learn to extract, align and fuse both modalities simultaneously in a deep cross-modal encoder, or feed the last-layer uni-modal representations from the deep pre-trained uni-modal encoders into the top cross-modal encoder. Both approaches potentially restrict vision-language representation learning and limit model performance. In this paper, we propose BridgeTower, which introduces multiple bridge layers that build a connection between the top layers of uni-modal encoders and each layer of the cross-modal encoder. This enables effective bottom-up cross-modal alignment and fusion between visual and textual representations of different semantic levels of pre-trained uni-modal encoders in the cross-modal encoder. Pre-trained with only 4M images, BridgeTower achieves state-of-the-art performance on various downstream vision-language tasks. In particular, on the VQAv2 test-std set, BridgeTower achieves an accuracy of 78.73%, outperforming the previous state-of-the-art model METER by 1.09% with the same pre-training data and almost negligible additional parameters and computational costs. Notably, when further scaling the model, BridgeTower achieves an accuracy of 81.15%, surpassing models that are pre-trained on orders-of-magnitude larger datasets. Code and checkpoints are available at https://github.com/microsoft/BridgeTower.","https://ojs.aaai.org/index.php/AAAI/article/view/26263/26035"
"26264","USDNL: Uncertainty-Based Single Dropout in Noisy Label Learning","['Yuanzhuo Xu', 'Xiaoguang Niu', 'Jie Yang', 'Steve Drew', 'Jiayu Zhou', 'Ruizhi Chen']","['Wuhan University', 'Wuhan University', 'Wuhan University', 'University of Calgary', 'Michigan State University', 'Wuhan University']","['ML: Adversarial Learning & Robustness', 'ML: Classification and Regression']","Xu, Y., Niu, X., Yang, J., Drew, S., Zhou, J., & Chen, R. (2023). USDNL: Uncertainty-Based Single Dropout in Noisy Label Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10648-10656. https://doi.org/10.1609/aaai.v37i9.26264","Abstract 					Deep Neural Networks (DNNs) possess powerful prediction capability thanks to their over-parameterization design, although the large model complexity makes it suffer from noisy supervision. Recent approaches seek to eliminate impacts from noisy labels by excluding data points with large loss values and showing promising performance. However, these approaches usually associate with significant computation overhead and lack of theoretical analysis. In this paper, we adopt a perspective to connect label noise with epistemic uncertainty. We design a simple, efficient, and theoretically provable robust algorithm named USDNL for DNNs with uncertainty-based Dropout. Specifically, we estimate the epistemic uncertainty of the network prediction after early training through single Dropout. The epistemic uncertainty is then combined with cross-entropy loss to select the clean samples during training. Finally, we theoretically show the equivalence of replacing selection loss with single cross-entropy loss. Compared to existing small-loss selection methods, USDNL features its simplicity for practical scenarios by only applying Dropout to a standard network, while still achieving high model accuracy. Extensive empirical results on both synthetic and real-world datasets show that USDNL outperforms other methods. Our code is available at https://github.com/kovelxyz/USDNL.","https://ojs.aaai.org/index.php/AAAI/article/view/26264/26036"
"26265","Trusted Fine-Grained Image Classification through Hierarchical Evidence Fusion","['Zhikang Xu', 'Xiaodong Yue', 'Ying Lv', 'Wei Liu', 'Zihao Li']","['Shanghai University', 'Shanghai University', 'Shanghai University', 'Tongji University', 'Shanghai University']","['ML: Deep Neural Network Algorithms', 'ML: Classification and Regression', 'RU: Applications', 'RU: Uncertainty Representations']","Xu, Z., Yue, X., Lv, Y., Liu, W., & Li, Z. (2023). Trusted Fine-Grained Image Classification through Hierarchical Evidence Fusion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10657-10665. https://doi.org/10.1609/aaai.v37i9.26265","Abstract 					Fine-Grained Image Classification (FGIC) aims to classify images into specific subordinate classes of a superclass. Due to insufficient training data and confusing data samples, FGIC may produce uncertain classification results that are untrusted for data applications. In fact, FGIC can be viewed as a hierarchical classification process and the multilayer information facilitates to reduce  uncertainty and improve the reliability of FGIC. In this paper, we adopt the evidence theory to measure uncertainty and confidence in hierarchical classification process and propose a trusted FGIC method through fusing multilayer classification evidence. Comparing with the traditional approaches, the trusted FGIC method not only generates accurate classification results but also reduces the uncertainty of fine-grained classification. Specifically, we construct an evidence extractor at each classification layer to extract multilayer (multi-grained) evidence for image classification. To fuse the extracted multi-grained evidence from coarse to fine, we formulate  evidence fusion with the Dirichlet hyper probability distribution and thereby hierarchically decompose the evidence of coarse-grained classes into fine-grained classes to enhance the classification performances. The ablation experiments validate that the hierarchical evidence fusion can improve the precision and also reduce the uncertainty of fine-grained classification. The comparison with state-of-the-art FGIC methods shows that our proposed method achieves competitive performances.","https://ojs.aaai.org/index.php/AAAI/article/view/26265/26037"
"26266","Disentangled Representation for Causal Mediation Analysis","['Ziqi Xu', 'Debo Cheng', 'Jiuyong Li', 'Jixue Liu', 'Lin Liu', 'Ke Wang']","['University of South Australia', 'University of South Australia', 'University of South Australia', 'University of South Australia', 'University of South Australia', 'Simon Fraser University']","['ML: Causal Learning', 'ML: Deep Generative Models & Autoencoders']","Xu, Z., Cheng, D., Li, J., Liu, J., Liu, L., & Wang, K. (2023). Disentangled Representation for Causal Mediation Analysis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10666-10674. https://doi.org/10.1609/aaai.v37i9.26266","Abstract 					Estimating direct and indirect causal effects from observational data is crucial to understanding the causal mechanisms and predicting the behaviour under different interventions. Causal mediation analysis is a method that is often used to reveal direct and indirect effects. Deep learning shows promise in mediation analysis, but the current methods only assume latent confounders that affect treatment, mediator and outcome simultaneously, and fail to identify different types of latent confounders (e.g., confounders that only affect the mediator or outcome). Furthermore, current methods are based on the sequential ignorability assumption, which is not feasible for dealing with multiple types of latent confounders. This work aims to circumvent the sequential ignorability assumption and applies the piecemeal deconfounding assumption as an alternative. We propose the Disentangled Mediation Analysis Variational AutoEncoder (DMAVAE), which disentangles the representations of latent confounders into three types to accurately estimate the natural direct effect, natural indirect effect and total effect. Experimental results show that the proposed method outperforms existing methods and has strong generalisation ability. We further apply the method to a real-world dataset to show its potential application.","https://ojs.aaai.org/index.php/AAAI/article/view/26266/26038"
"26267","Global Concept-Based Interpretability for Graph Neural Networks via Neuron Analysis","['Han Xuanyuan', 'Pietro Barbiero', 'Dobrik Georgiev', 'Lucie Charlotte Magister', 'Pietro Liò']","['University of Cambridge', 'University of Cambridge', 'University of Cambridge', 'University of Cambridge', 'University of Cambridge']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'ML: Graph-based Machine Learning']","Xuanyuan, H., Barbiero, P., Georgiev, D., Magister, L. C., & Liò, P. (2023). Global Concept-Based Interpretability for Graph Neural Networks via Neuron Analysis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10675-10683. https://doi.org/10.1609/aaai.v37i9.26267","Abstract 					Graph neural networks (GNNs) are highly effective on a variety of graph-related tasks; however, they lack interpretability and transparency. Current explainability approaches are typically local and treat GNNs as black-boxes. They do not look inside the model, inhibiting human trust in the model and explanations. Motivated by the ability of neurons to detect high-level semantic concepts in vision models, we perform a novel analysis on the behaviour of individual GNN neurons to answer questions about GNN interpretability. We propose a novel approach for producing global explanations for GNNs using neuron-level concepts to enable practitioners to have a high-level view of the model. Specifically, (i) to the best of our knowledge, this is the first work which shows that GNN neurons act as concept detectors and have strong alignment with concepts formulated as logical compositions of node degree and neighbourhood properties; (ii) we quantitatively assess the importance of detected concepts, and identify a trade-off between training duration and neuron-level interpretability; (iii) we demonstrate that our global explainability approach has advantages over the current state-of-the-art -- we can disentangle the explanation into individual interpretable concepts backed by logical descriptions, which reduces potential for bias and improves user-friendliness.","https://ojs.aaai.org/index.php/AAAI/article/view/26267/26039"
"26268","Fast and Accurate Binary Neural Networks Based on Depth-Width Reshaping","['Ping Xue', 'Yang Lu', 'Jingfei Chang', 'Xing Wei', 'Zhen Wei']","['School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China', 'School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China\nAnhui Mine IOT and Security Monitoring Technology Key Laboratory, Hefei, China\nEngineering Research Center of Safety Critical Industrial Measurement and Control Technology, Ministry of Education, Hefei University of Technology, Hefei, China', 'School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China', 'School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China\nAnhui Mine IOT and Security Monitoring Technology Key Laboratory, Hefei, China\nIntelligent Manufacturing Institute of HeFei University of Technology, Hefei, China', 'School of Computer Science and Information Engineering, Hefei University of Technology, Hefei, China\nAnhui Mine IOT and Security Monitoring Technology Key Laboratory, Hefei, China\nEngineering Research Center of Safety Critical Industrial Measurement and Control Technology, Ministry of Education, Hefei University of Technology, Hefei, China']","['ML: Learning on the Edge & Model Compression']","Xue, P., Lu, Y., Chang, J., Wei, X., & Wei, Z. (2023). Fast and Accurate Binary Neural Networks Based on Depth-Width Reshaping. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10684-10692. https://doi.org/10.1609/aaai.v37i9.26268","Abstract 					Network binarization (i.e., binary neural networks, BNNs) can efficiently compress deep neural networks and accelerate model inference but cause severe accuracy degradation. Existing BNNs are mainly implemented based on the commonly used full-precision network backbones, and then the accuracy is improved with various techniques. However, there is a question of whether the full-precision network backbone is well adapted to BNNs. We start from the factors of the performance degradation of BNNs and analyze the problems of directly using full-precision network backbones for BNNs: for a given computational budget, the backbone of a BNN may need to be shallower and wider compared to the backbone of a full-precision network. With this in mind, Depth-Width Reshaping (DWR) is proposed to reshape the depth and width of existing full-precision network backbones and further optimize them by incorporating pruning techniques to better fit the BNNs. Extensive experiments demonstrate the analytical result and the effectiveness of the proposed method. Compared with the original backbones, the DWR backbones constructed by the proposed method result in close to O(√s) decrease in activations, while achieving an absolute accuracy increase by up to 1.7% with comparable computational cost. Besides, by using the DWR backbones, existing methods can achieve new state-of-the-art (SOTA) accuracy (e.g., 67.2% on ImageNet with ResNet-18 as the original backbone). We hope this work provides a novel insight into the backbone design of BNNs. The code is available at https://github.com/pingxue-hfut/DWR.","https://ojs.aaai.org/index.php/AAAI/article/view/26268/26040"
"26269","Learning the Finer Things: Bayesian Structure Learning at the Instantiation Level","['Chase Yakaboski', 'Eugene Santos, Jr']","['Thayer School of Engineering at Dartmouth College', 'Thayer School of Engineering at Dartmouth College']","['ML: Bayesian Learning', 'RU: Applications', 'RU: Bayesian Networks', 'RU: Graphical Model', 'RU: Uncertainty Representations']","Yakaboski, C., & Santos, Jr, E. (2023). Learning the Finer Things: Bayesian Structure Learning at the Instantiation Level. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10693-10701. https://doi.org/10.1609/aaai.v37i9.26269","Abstract 					Successful machine learning methods require a trade-off between memorization and generalization. Too much memorization and the model cannot generalize to unobserved examples. Too much over-generalization and we risk under-fitting the data. While we commonly measure their performance through cross validation and accuracy metrics, how should these algorithms cope in domains that are extremely under-determined where accuracy is always unsatisfactory? We present a novel probabilistic graphical model structure learning approach that can learn, generalize and explain in these elusive domains by operating at the random variable instantiation level. Using Minimum Description Length (MDL) analysis, we propose a new decomposition of the learning problem over all training exemplars, fusing together minimal entropy inferences to construct a final knowledge base. By leveraging Bayesian Knowledge Bases (BKBs), a framework that operates at the instantiation level and inherently subsumes Bayesian Networks (BNs), we develop both a theoretical MDL score and associated structure learning algorithm that demonstrates significant improvements over learned BNs on 40 benchmark datasets. Further, our algorithm incorporates recent off-the-shelf DAG learning techniques enabling tractable results even on large problems. We then demonstrate the utility of our approach in a significantly under-determined domain by learning gene regulatory networks on breast cancer gene mutational data available from The Cancer Genome Atlas (TCGA).","https://ojs.aaai.org/index.php/AAAI/article/view/26269/26041"
"26270","Semidefinite Programming versus Burer-Monteiro Factorization for Matrix Sensing","['Baturalp Yalçın', 'Ziye Ma', 'Javad Lavaei', 'Somayeh Sojoudi']","['University of California, Berkeley', 'University of California, Berkeley', 'University of California, Berkeley', 'University of California, Berkeley']","['ML: Matrix & Tensor Methods', 'ML: Optimization']","Yalçın, B., Ma, Z., Lavaei, J., & Sojoudi, S. (2023). Semidefinite Programming versus Burer-Monteiro Factorization for Matrix Sensing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10702-10710. https://doi.org/10.1609/aaai.v37i9.26270","Abstract 					Many fundamental low-rank optimization problems, such as matrix completion, phase retrieval, and robust PCA, can be formulated as the matrix sensing problem. Two main approaches for solving matrix sensing are based on semidefinite programming (SDP) and Burer-Monteiro (B-M) factorization. The former suffers from high computational and space complexities, whereas the latter may return a spurious solution due to the non-convexity of the problem. The existing theoretical guarantees for the success of these methods have led to similar conservative conditions, which may wrongly imply that these methods have comparable performances. In this paper, we shed light on some major differences between these two methods. First, we present a class of structured matrix completion problems for which the B-M methods fail with an overwhelming probability, while the SDP method works correctly. Second, we identify a class of highly sparse matrix completion problems for which the B-M method works and the SDP method fails. Third, we prove that although the B-M method exhibits the same performance independent of the rank of the unknown solution, the success of the SDP method is correlated to the rank of the solution and improves as the rank increases. Unlike the existing literature that has mainly focused on those instances of matrix sensing for which both SDP and B-M work, this paper offers the first result on the unique merit of each method over the alternative approach.","https://ojs.aaai.org/index.php/AAAI/article/view/26270/26042"
"26271","DeFL: Defending against Model Poisoning Attacks in Federated Learning via Critical Learning Periods Awareness","['Gang Yan', 'Hao Wang', 'Xu Yuan', 'Jian Li']","['SUNY-Binghamton University', 'Louisiana State University', 'University of Louisiana at Lafayette', 'SUNY-Binghamton University']","['ML: Distributed Machine Learning & Federated Learning']","Yan, G., Wang, H., Yuan, X., & Li, J. (2023). DeFL: Defending against Model Poisoning Attacks in Federated Learning via Critical Learning Periods Awareness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10711-10719. https://doi.org/10.1609/aaai.v37i9.26271","Abstract 					Federated learning (FL) is known to be susceptible to model poisoning attacks in which malicious clients hamper the accuracy of the global model by sending manipulated model updates to the central server during the FL training process.  Existing defenses mainly focus on Byzantine-robust FL aggregations, and largely ignore the impact of the underlying deep neural network (DNN) that is used to FL training.  Inspired by recent findings on critical learning periods (CLP) in DNNs, where small gradient errors have irrecoverable impact on the final model accuracy, we propose a new defense, called a CLP-aware defense against poisoning of FL (DeFL).  The key idea of DeFL is to measure fine-grained differences between DNN model updates via an easy-to-compute federated gradient norm vector (FGNV) metric.  Using FGNV, DeFL simultaneously detects malicious clients and identifies CLP, which in turn is leveraged to guide the adaptive removal of detected malicious clients from aggregation.  As a result, DeFL not only mitigates model poisoning attacks on the global model but also is robust to detection errors.  Our extensive experiments on three benchmark datasets demonstrate that DeFL produces significant performance gain over conventional defenses against state-of-the-art model poisoning attacks.","https://ojs.aaai.org/index.php/AAAI/article/view/26271/26043"
"26272","T2G-FORMER: Organizing Tabular Features into Relation Graphs Promotes Heterogeneous Feature Interaction","['Jiahuan Yan', 'Jintai Chen', 'Yixuan Wu', 'Danny Z. Chen', 'Jian Wu']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'University of Notre Dame', 'Zhejiang University']","['ML: Deep Neural Architectures', 'DMKM: Applications', 'ML: Classification and Regression']","Yan, J., Chen, J., Wu, Y., Chen, D. Z., & Wu, J. (2023). T2G-FORMER: Organizing Tabular Features into Relation Graphs Promotes Heterogeneous Feature Interaction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10720-10728. https://doi.org/10.1609/aaai.v37i9.26272","Abstract 					Recent development of deep neural networks (DNNs) for tabular learning has largely benefited from the capability of DNNs for automatic feature interaction. However, the heterogeneity nature of tabular features makes such features relatively independent, and developing effective methods to promote tabular feature interaction still remains an open problem. In this paper, we propose a novel Graph Estimator, which automatically estimates the relations among tabular features and builds graphs by assigning edges between related features. Such relation graphs organize independent tabular features into a kind of graph data such that interaction of nodes (tabular features) can be conducted in an orderly fashion. Based on our proposed Graph Estimator, we present a bespoke Transformer network tailored for tabular learning, called T2G-Former, which processes tabular data by performing tabular feature interaction guided by the relation graphs. A specific Cross-level Readout collects salient features predicted by the layers in T2G-Former across different levels, and attains global semantics for final prediction. Comprehensive experiments show that our T2G-Former achieves superior performance among DNNs and is competitive with non-deep Gradient Boosted Decision Tree models. The code and detailed results are available at https://github.com/jyansir/t2g-former.","https://ojs.aaai.org/index.php/AAAI/article/view/26272/26044"
"26273","Computably Continuous Reinforcement-Learning Objectives Are PAC-Learnable","['Cambridge Yang', 'Michael Littman', 'Michael Carbin']","['MIT', 'Brown University', 'MIT']","['ML: Reinforcement Learning Theory']","Yang, C., Littman, M., & Carbin, M. (2023). Computably Continuous Reinforcement-Learning Objectives Are PAC-Learnable. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10729-10736. https://doi.org/10.1609/aaai.v37i9.26273","Abstract 					In reinforcement learning, the classic objectives of maximizing discounted and finite-horizon cumulative rewards are PAC-learnable: There are algorithms that learn a near-optimal policy with high probability using a finite amount of samples and computation.  In recent years, researchers have introduced objectives and corresponding reinforcement-learning algorithms beyond the classic cumulative rewards, such as objectives specified as linear temporal logic formulas.  However, questions about the PAC-learnability of these new objectives have remained open.   This work demonstrates the PAC-learnability of general reinforcement-learning objectives through sufficient conditions for PAC-learnability in two analysis settings.  In particular, for the analysis that considers only sample complexity, we prove that if an objective given as an oracle is uniformly continuous, then it is PAC-learnable. Further, for the analysis that considers computational complexity, we prove that if an objective is computable, then it is PAC-learnable.  In other words, if a procedure computes successive approximations of the objective's value, then the objective is PAC-learnable.   We give three applications of our condition on objectives from the literature with previously unknown PAC-learnability and prove that these objectives are PAC-learnable.   Overall, our result helps verify existing objectives' PAC-learnability.  Also, as some studied objectives that are not uniformly continuous have been shown to be not PAC-learnable, our results could guide the design of new PAC-learnable objectives.","https://ojs.aaai.org/index.php/AAAI/article/view/26273/26045"
"26274","Reinforcement Causal Structure Learning on Order Graph","['Dezhi Yang', 'Guoxian Yu', 'Jun Wang', 'Zhengtian Wu', 'Maozu Guo']","['Shandong University', 'Shandong University', 'Shandong University', 'Suzhou University of Science and Technology', 'Beijing University of Civil Engineering and Architecture']","['ML: Causal Learning', 'ML: Bayesian Learning', 'ML: Optimization', 'ML: Reinforcement Learning Algorithms', 'PRS: Planning With Markov Models (MDPs', 'POMDPs)', 'SO: Sampling/Simulation-Based Search']","Yang, D., Yu, G., Wang, J., Wu, Z., & Guo, M. (2023). Reinforcement Causal Structure Learning on Order Graph. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10737-10744. https://doi.org/10.1609/aaai.v37i9.26274","Abstract 					Learning directed acyclic graph (DAG) that  describes the causality of observed data is a very challenging but important task. Due to the limited quantity and quality of observed data, and non-identifiability of causal graph, it is almost impossible to infer a single precise DAG. Some methods approximate the posterior distribution of DAGs to explore the DAG space via Markov chain Monte Carlo (MCMC), but the DAG space is over the nature of super-exponential growth, accurately characterizing the whole distribution over DAGs is very intractable. In this paper, we propose Reinforcement Causal Structure Learning on Order Graph (RCL-OG) that uses order graph instead of MCMC to model different DAG topological orderings and to reduce the problem size. RCL-OG first defines reinforcement learning with a new reward mechanism to approximate the posterior distribution of orderings in an efficacy way, and uses deep Q-learning to update and transfer rewards between nodes. Next, it obtains the probability transition model of nodes on order graph, and computes the posterior probability of different orderings. In this way, we can sample on this model to obtain the ordering with high probability. Experiments on synthetic and benchmark datasets show that RCL-OG provides accurate posterior probability approximation and achieves better results than competitive causal discovery algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26274/26046"
"26275","AdaTask: A Task-Aware Adaptive Learning Rate Approach to Multi-Task Learning","['Enneng Yang', 'Junwei Pan', 'Ximei Wang', 'Haibin Yu', 'Li Shen', 'Xihua Chen', 'Lei Xiao', 'Jie Jiang', 'Guibing Guo']","['Northeastern University, China', 'Tencent Inc, China', 'Tencent Inc, China', 'Tencent Inc, China', 'JD Explore Academy, China', 'Tencent Inc, China', 'Tencent Inc, China', 'Tencent Inc, China', 'Northeastern University, China']","['ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'DMKM: Recommender Systems', 'DMKM: Web Personalization & User Modeling']","Yang, E., Pan, J., Wang, X., Yu, H., Shen, L., Chen, X., Xiao, L., Jiang, J., & Guo, G. (2023). AdaTask: A Task-Aware Adaptive Learning Rate Approach to Multi-Task Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10745-10753. https://doi.org/10.1609/aaai.v37i9.26275","Abstract 					Multi-task learning (MTL) models have demonstrated impressive results in computer vision, natural language processing, and recommender systems. Even though many approaches have been proposed, how well these approaches balance different tasks on each parameter still remains unclear. In this paper, we propose to measure the task dominance degree of a parameter by the total updates of each task on this parameter. Specifically, we compute the total updates by the exponentially decaying Average of the squared Updates (AU) on a parameter from the corresponding task. Based on this novel metric, we observe that many parameters in existing MTL methods, especially those in the higher shared layers, are still dominated by one or several tasks. The dominance of AU is mainly due to the dominance of accumulative gradients from one or several tasks. Motivated by this, we propose a Task-wise Adaptive learning rate approach, AdaTask in short, to separate the accumulative gradients and hence the learning rate of each task for each parameter in adaptive learning rate approaches (e.g., AdaGrad, RMSProp, and Adam). Comprehensive experiments on computer vision and recommender system MTL datasets demonstrate that AdaTask significantly improves the performance of dominated tasks, resulting SOTA average task-wise performance.  Analysis on both synthetic and real-world datasets shows AdaTask  balance parameters in every shared layer well.","https://ojs.aaai.org/index.php/AAAI/article/view/26275/26047"
"26276","WaveForM: Graph Enhanced Wavelet Learning for Long Sequence Forecasting of Multivariate Time Series","['Fuhao Yang', 'Xin Li', 'Min Wang', 'Hongyu Zang', 'Wei Pang', 'Mingzhong Wang']","['Beijing Institute of Technology', 'Beijing Institute of Technology', 'Beijing Institute of Technology', 'Beijing Institute of Technology', 'Heriot-Watt University', 'The University of the Sunshine Coast']","['ML: Time-Series/Data Streams', 'ML: Deep Neural Architectures', 'ML: Graph-based Machine Learning', 'ML: Representation Learning']","Yang, F., Li, X., Wang, M., Zang, H., Pang, W., & Wang, M. (2023). WaveForM: Graph Enhanced Wavelet Learning for Long Sequence Forecasting of Multivariate Time Series. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10754-10761. https://doi.org/10.1609/aaai.v37i9.26276","Abstract 					Multivariate time series (MTS) analysis and forecasting are crucial in many real-world applications, such as smart traffic management and weather forecasting. However, most existing work either focuses on short sequence forecasting or makes predictions predominantly with time domain features, which is not effective at removing noises with irregular frequencies in MTS. Therefore, we propose WaveForM, an end-to-end graph enhanced Wavelet learning framework for long sequence FORecasting of MTS. WaveForM first utilizes Discrete Wavelet Transform (DWT) to represent MTS in the wavelet domain, which captures both frequency and time domain features with a sound theoretical basis. To enable the effective learning in the wavelet domain, we further propose a graph constructor, which learns a global graph to represent the relationships between MTS variables, and graph-enhanced prediction modules, which utilize dilated convolution and graph convolution to capture the correlations between time series and predict the wavelet coefficients at different levels. Extensive experiments on five real-world forecasting datasets show that our model can achieve considerable performance improvement over different prediction lengths against the most competitive baseline of each dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/26276/26048"
"26277","Layout Generation as Intermediate Action Sequence Prediction","['Huiting Yang', 'Danqing Huang', 'Chin-Yew Lin', 'Shengfeng He']","['South China University of Technology', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Singapore Management University\nSouth China University of Technology']","['ML: Deep Generative Models & Autoencoders', 'CV: Applications', 'CV: Computational Photography', 'Image & Video Synthesis', 'ML: Applications', 'ML: Deep Neural Network Algorithms', 'ML: Evaluation and Analysis (Machine Learning)']","Yang, H., Huang, D., Lin, C.-Y., & He, S. (2023). Layout Generation as Intermediate Action Sequence Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10762-10770. https://doi.org/10.1609/aaai.v37i9.26277","Abstract 					Layout generation plays a crucial role in graphic design intelligence. One important characteristic of the graphic layouts is that they usually follow certain design principles. For example, the principle of repetition emphasizes the reuse of similar visual elements throughout the design. To generate a layout, previous works mainly attempt at predicting the absolute value of bounding box for each element, where such target representation has hidden the information of higher-order design operations like repetition (e.g. copy the size of the previously generated element). In this paper, we introduce a novel action schema to encode these operations for better modeling the generation process. Instead of predicting the bounding box values, our approach autoregressively outputs the intermediate action sequence, which can then be deterministically converted to the final layout. We achieve state-of-the-art performances on three datasets. Both automatic and human evaluations show that our approach generates high-quality and diverse layouts. Furthermore, we revisit the commonly used evaluation metric FID adapted in this task, and observe that previous works use different settings to train the feature extractor for obtaining real/generated data distribution, which leads to inconsistent conclusions. We conduct an in-depth analysis on this metric and settle for a more robust and reliable evaluation setting. Code is available at this website.","https://ojs.aaai.org/index.php/AAAI/article/view/26277/26049"
"26278","Learning-Assisted Algorithm Unrolling for Online Optimization with Budget Constraints","['Jianyi Yang', 'Shaolei Ren']","['UC Riverside', 'UCR']","['ML: Online Learning & Bandits', 'PRS: Scheduling']","Yang, J., & Ren, S. (2023). Learning-Assisted Algorithm Unrolling for Online Optimization with Budget Constraints. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10771-10779. https://doi.org/10.1609/aaai.v37i9.26278","Abstract 					Online optimization with multiple budget constraints is challenging since the online decisions over a short time horizon are coupled together by strict inventory constraints. The existing manually-designed algorithms cannot achieve satisfactory average performance for this setting because they often need a large number of time steps for convergence and/or may violate the inventory constraints. In this paper, we propose a new machine learning (ML) assisted unrolling approach, called LAAU (Learning-Assisted Algorithm Unrolling), which unrolls the agent’s online decision pipeline and leverages an ML model for updating the Lagrangian multiplier online. For efficient training via backpropagation, we derive gradients of the decision pipeline over time. We also provide the average cost bounds for two cases when training data is available offline and collected online, respectively. Finally, we present numerical results to highlight that LAAU can outperform the existing baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/26278/26050"
"26279","ADEPT: A DEbiasing PrompT Framework","['Ke Yang', 'Charles Yu', 'Yi R. Fung', 'Manling Li', 'Heng Ji']","['Tsinghua University', 'University of Illinois at Urbana-Champaign', 'University of Illinois at Urbana-Champaign', 'University of Illinois at Urbana-Champaign', 'University of Illinois at Urbana-Champaign']","['ML: Bias and Fairness']","Yang, K., Yu, C., Fung, Y. R., Li, M., & Ji, H. (2023). ADEPT: A DEbiasing PrompT Framework. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10780-10788. https://doi.org/10.1609/aaai.v37i9.26279","Abstract 					Several works have proven that finetuning is an applicable approach for debiasing contextualized word embeddings. Similarly, discrete prompts with semantic meanings have shown to be effective in debiasing tasks. With unfixed mathematical representation at the token level, continuous prompts usually surpass discrete ones at providing a pre-trained language model (PLM) with additional task-specific information. Despite this, relatively few efforts have been made to debias PLMs by prompt tuning with continuous prompts compared to its discrete counterpart. Furthermore, for most debiasing methods that alter a PLM's original parameters, a major problem is the need to not only decrease the bias in the PLM but also to ensure that the PLM does not lose its representation ability. Finetuning methods typically have a hard time maintaining this balance, as they tend to violently remove meanings of attribute words (like the words developing our concepts of ""male"" and ""female"" for gender), which also leads to an unstable and unpredictable training process. In this paper, we propose ADEPT, a method to debias PLMs using prompt tuning while maintaining the delicate balance between removing biases and ensuring representation ability. To achieve this, we propose a new training criterion inspired by manifold learning and equip it with an explicit debiasing term to optimize prompt tuning. In addition, we conduct several experiments with regard to the reliability, quality, and quantity of a previously proposed attribute training corpus in order to obtain a clearer prototype of a certain attribute, which indicates the attribute's position and relative distances to other words on the manifold. We evaluate ADEPT on several widely acknowledged debiasing benchmarks and downstream tasks, and find that it achieves competitive results while maintaining (and in some cases even improving) the PLM's representation ability. We further visualize words' correlation before and after debiasing a PLM, and give some possible explanations for the visible effects.","https://ojs.aaai.org/index.php/AAAI/article/view/26279/26051"
"26280","Generalized Semantic Segmentation by Self-Supervised Source Domain Projection and Multi-Level Contrastive Learning","['Liwei Yang', 'Xiang Gu', 'Jian Sun']","[""Xi'an Jiaotong University"", 'Xi’an Jiaotong University', ""Xi'an Jiaotong University\nPazhou Laboratory (Huangpu), China\nPeng Cheng Laboratory, China""]","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'CV: Segmentation', 'ML: Unsupervised & Self-Supervised Learning']","Yang, L., Gu, X., & Sun, J. (2023). Generalized Semantic Segmentation by Self-Supervised Source Domain Projection and Multi-Level Contrastive Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10789-10797. https://doi.org/10.1609/aaai.v37i9.26280","Abstract 					Deep networks trained on the source domain show degraded performance when tested on unseen target domain data. To enhance the model's generalization ability, most existing domain generalization methods learn domain invariant features by suppressing domain sensitive features. Different from them, we propose a Domain Projection and Contrastive Learning (DPCL) approach for generalized semantic segmentation, which includes two modules: Self-supervised Source Domain Projection (SSDP) and Multi-Level Contrastive Learning (MLCL). SSDP aims to reduce domain gap by projecting data to the source domain, while MLCL is a learning scheme to learn discriminative and generalizable features on the projected data. During test time, we first project the target data by SSDP to mitigate domain shift, then generate the segmentation results by the learned segmentation network based on MLCL. At test time, we can update the projected data by minimizing our proposed pixel-to-pixel contrastive loss to obtain better results. Extensive experiments for semantic segmentation demonstrate the favorable generalization capability of our method on benchmark datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26280/26052"
"26281","CEM: Constrained Entropy Maximization for Task-Agnostic Safe Exploration","['Qisong Yang', 'Matthijs T.J. Spaan']","['Delft University of Technology', 'Delft University of Technology']","['ML: Reinforcement Learning Algorithms']","Yang, Q., & Spaan, M. T. (2023). CEM: Constrained Entropy Maximization for Task-Agnostic Safe Exploration. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10798-10806. https://doi.org/10.1609/aaai.v37i9.26281","Abstract 					In the absence of assigned tasks, a learning agent typically seeks to explore its environment efficiently. However, the pursuit of exploration will bring more safety risks. An under-explored aspect of reinforcement learning is how to achieve safe efficient exploration when the task is unknown. In this paper, we propose a practical Constrained Entropy Maximization (CEM) algorithm to solve task-agnostic safe exploration problems, which naturally require a finite horizon and undiscounted constraints on safety costs. The CEM algorithm aims to learn a policy that maximizes state entropy under the premise of safety. To avoid approximating the state density in complex domains, CEM leverages a k-nearest neighbor entropy estimator to evaluate the efficiency of exploration. In terms of safety, CEM minimizes the safety costs, and adaptively trades off safety and exploration based on the current constraint satisfaction. The empirical analysis shows that CEM enables the acquisition of a safe exploration policy in complex environments, resulting in improved performance in both safety and sample efficiency for target tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26281/26053"
"26282","Understanding Representation Learnability of Nonlinear Self-Supervised Learning","['Ruofeng Yang', 'Xiangyuan Li', 'Bo Jiang', 'Shuai Li']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['ML: Unsupervised & Self-Supervised Learning']","Yang, R., Li, X., Jiang, B., & Li, S. (2023). Understanding Representation Learnability of Nonlinear Self-Supervised Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10807-10815. https://doi.org/10.1609/aaai.v37i9.26282","Abstract 					Self-supervised learning (SSL) has empirically shown its data representation learnability in many downstream tasks. There are only a few theoretical works on data representation learnability, and many of those focus on final data representation, treating the nonlinear neural network as a ``black box"". However, the accurate learning results of neural networks are crucial for describing the data distribution features learned by SSL models. Our paper is the first to analyze the learning results of the nonlinear SSL model accurately. We consider a toy data distribution that contains two features: the label-related feature and the hidden feature. Unlike previous linear setting work that depends on closed-form solutions, we use the gradient descent algorithm to train a 1-layer nonlinear SSL model with a certain initialization region and prove that the model converges to a local minimum. Furthermore, different from the complex iterative analysis, we propose a new analysis process which uses the exact version of  Inverse Function Theorem to accurately describe the features learned by the local minimum. With this local minimum, we prove that the nonlinear SSL model can capture the label-related feature and hidden feature at the same time. In contrast, the nonlinear supervised learning (SL) model can only learn the label-related feature. We also present the learning processes and results of the nonlinear SSL and SL model via simulation experiments.","https://ojs.aaai.org/index.php/AAAI/article/view/26282/26054"
"26283","Simple and Efficient Heterogeneous Graph Neural Network","['Xiaocheng Yang', 'Mingyu Yan', 'Shirui Pan', 'Xiaochun Ye', 'Dongrui Fan']","['State Key Lab of Processors, Institute for Computing Technology, Chinese Academy of Sciences, China', 'State Key Lab of Processors, Institute for Computing Technology, Chinese Academy of Sciences, China', 'School of Information and Communication Technology, Griffith University, Australia', 'State Key Lab of Processors, Institute for Computing Technology, Chinese Academy of Sciences, China', 'State Key Lab of Processors, Institute for Computing Technology, Chinese Academy of Sciences, China\nSchool of Computer Science and Technology, University of Chinese Academy of Sciences, China']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Yang, X., Yan, M., Pan, S., Ye, X., & Fan, D. (2023). Simple and Efficient Heterogeneous Graph Neural Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10816-10824. https://doi.org/10.1609/aaai.v37i9.26283","Abstract 					Heterogeneous graph neural networks (HGNNs) have the powerful capability to embed rich structural and semantic information of a heterogeneous graph into node representations. Existing HGNNs inherit many mechanisms from graph neural networks (GNNs) designed for homogeneous graphs, especially the attention mechanism and the multi-layer structure. These mechanisms bring excessive complexity, but seldom work studies whether they are really effective on heterogeneous graphs. In this paper, we conduct an in-depth and detailed study of these mechanisms and propose the Simple and Efficient Heterogeneous Graph Neural Network (SeHGNN). To easily capture structural information, SeHGNN pre-computes the neighbor aggregation using a light-weight mean aggregator, which reduces complexity by removing overused neighbor attention and avoiding repeated neighbor aggregation in every training epoch. To better utilize semantic information, SeHGNN adopts the single-layer structure with long metapaths to extend the receptive field, as well as a transformer-based semantic fusion module to fuse features from different metapaths. As a result, SeHGNN exhibits the characteristics of a simple network structure, high prediction accuracy, and fast training speed. Extensive experiments on five real-world heterogeneous graphs demonstrate the superiority of SeHGNN over the state-of-the-arts on both accuracy and training speed.","https://ojs.aaai.org/index.php/AAAI/article/view/26283/26055"
"26284","T-distributed Spherical Feature Representation for Imbalanced Classification","['Xiaoyu Yang', 'Yufei Chen', 'Xiaodong Yue', 'Shaoxun Xu', 'Chao Ma']","['College of Electronics and Information Engineering, Tongji University, Shanghai, China', 'College of Electronics and Information Engineering, Tongji University, Shanghai, China', 'School of Computer Engineering and Science, Shanghai University, Shanghai, China\nArtificial Intelligence Institute of Shanghai University, Shanghai, China\nVLN Lab, NAVI MedTech Co., Ltd. Shanghai, China', 'College of Electronics and Information Engineering, Tongji University, Shanghai, China', 'Department of Radiology, Changhai Hospital of Shanghai, Shanghai, China']","['ML: Classification and Regression', 'CV: Medical and Biological Imaging', 'ML: Deep Neural Network Algorithms']","Yang, X., Chen, Y., Yue, X., Xu, S., & Ma, C. (2023). T-distributed Spherical Feature Representation for Imbalanced Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10825-10833. https://doi.org/10.1609/aaai.v37i9.26284","Abstract 					Real-world classification tasks often show an extremely imbalanced problem. The extreme imbalance will cause a strong bias that the decision boundary of the classifier is completely dominated by the categories with abundant samples, which are also called the head categories. Current methods have alleviated the imbalanced impact from mainly three aspects: class re-balance, decoupling and domain adaptation. However, the existing criterion with the winner-take-all strategy still leads to the crowding problem in the eigenspace. The head categories with many samples can extract features more accurately, but occupy most of the eigenspace. The tail categories sharing the rest of the narrow eigenspace are too crowded together to accurately extract features. Above these issues, we propose a novel T-distributed spherical metric for equalized eigenspace in the imbalanced classification, which has the following innovations: 1) We design the T-distributed spherical metric, which has the characteristics of high kurtosis. Instead of the winner-take-all strategy, the T-distributed spherical metric produces a high logit only when the extracted feature is close enough to the category center, without a strong bias against other categories. 2) The T-distributed spherical metric is integrated into the classifier, which is able to equalize the eigenspace for alleviating the crowding issue in the imbalanced problem. The equalized eigenspace by the T-distributed spherical classifier is capable of improving the accuracy of the tail categories while maintaining the accuracy of the head, which significantly promotes the intraclass compactness and interclass separability of features. Extensive experiments on large-scale imbalanced datasets verify our method, which shows superior results in the long-tailed CIFAR-100/-10 with the imbalanced ratio IR = 100/50. Our method also achieves excellent results on the large-scale ImageNet-LT dataset and the iNaturalist dataset with various backbones. In addition, we provide a case study of the real clinical classification of pancreatic tumor subtypes with 6 categories. Among them, the largest number of PDAC accounts for 315 cases, and the least CP has only 8 cases. After 4-fold cross-validation, we achieved a top-1 accuracy of 69.04%.","https://ojs.aaai.org/index.php/AAAI/article/view/26284/26056"
"26285","Cluster-Guided Contrastive Graph Clustering Network","['Xihong Yang', 'Yue Liu', 'Sihang Zhou', 'Siwei Wang', 'Wenxuan Tu', 'Qun Zheng', 'Xinwang Liu', 'Liming Fang', 'En Zhu']","['National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'University of Science and Technology of China', 'National University of Defense Technology', 'Nanjing University of Aeronautics and Astronautics', 'National University of Defense Technology']","['ML: Clustering', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Graph-based Machine Learning', 'ML: Multi-Instance/Multi-View Learning']","Yang, X., Liu, Y., Zhou, S., Wang, S., Tu, W., Zheng, Q., Liu, X., Fang, L., & Zhu, E. (2023). Cluster-Guided Contrastive Graph Clustering Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10834-10842. https://doi.org/10.1609/aaai.v37i9.26285","Abstract 					Benefiting from the intrinsic supervision information exploitation capability, contrastive learning has achieved promising performance in the field of deep graph clustering recently. However, we observe that two drawbacks of the positive and negative sample construction mechanisms limit the performance of existing algorithms from further improvement. 1) The quality of positive samples heavily depends on the carefully designed data augmentations, while inappropriate data augmentations would easily lead to the semantic drift and indiscriminative positive samples. 2) The constructed negative samples are not reliable for ignoring important clustering information. To solve these problems, we propose a Cluster-guided Contrastive deep Graph Clustering network (CCGC) by mining the intrinsic supervision information in the high-confidence clustering results. Specifically, instead of conducting complex node or edge perturbation, we construct two views of the graph by designing special Siamese encoders whose weights are not shared between the sibling sub-networks. Then, guided by the high-confidence clustering information, we carefully select and construct the positive samples from the same high-confidence cluster in two views. Moreover, to construct semantic meaningful negative sample pairs, we regard the centers of different high-confidence clusters as negative samples, thus improving the discriminative capability and reliability of the constructed sample pairs. Lastly, we design an objective function to pull close the samples from the same cluster while pushing away those from other clusters by maximizing and minimizing the cross-view cosine similarity between positive and negative samples. Extensive experimental results on six datasets demonstrate the effectiveness of CCGC compared with the existing state-of-the-art algorithms. The code of CCGC is available at https://github.com/xihongyang1999/CCGC on Github.","https://ojs.aaai.org/index.php/AAAI/article/view/26285/26057"
"26286","Flow to Control: Offline Reinforcement Learning with Lossless Primitive Discovery","['Yiqin Yang', 'Hao Hu', 'Wenzhe Li', 'Siyuan Li', 'Jun Yang', 'Qianchuan Zhao', 'Chongjie Zhang']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Harbin Institute of Technology', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University']","['ML: Reinforcement Learning Algorithms', 'ML: Reinforcement Learning Theory']","Yang, Y., Hu, H., Li, W., Li, S., Yang, J., Zhao, Q., & Zhang, C. (2023). Flow to Control: Offline Reinforcement Learning with Lossless Primitive Discovery. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10843-10851. https://doi.org/10.1609/aaai.v37i9.26286","Abstract 					Offline reinforcement learning (RL) enables the agent to effectively learn from logged data, which significantly extends the applicability of RL algorithms in real-world scenarios where exploration can be expensive or unsafe. Previous works have shown that extracting primitive skills from the recurring and temporally extended structures in the logged data yields better learning. However, these methods suffer greatly when the primitives have limited representation ability to recover the original policy space, especially in offline settings. In this paper, we give a quantitative characterization of the performance of offline hierarchical learning and highlight the importance of learning lossless primitives. To this end, we propose to use a flow-based structure as the representation for low-level policies. This allows us to represent the behaviors in the dataset faithfully while keeping the expression ability to recover the whole policy space. We show that such lossless primitives can drastically improve the performance of hierarchical policies. The experimental results and extensive ablation studies on the standard D4RL benchmark show that our method has a good representation ability for policies and achieves superior performance in most tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26286/26058"
"26287","Prototypical Partial Optimal Transport for Universal Domain Adaptation","['Yucheng Yang', 'Xiang Gu', 'Jian Sun']","[""Xi'an Jiaotong University"", 'Xi’an Jiaotong University', ""Xi'an Jiaotong University""]","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'CV: Representation Learning for Vision', 'ML: Unsupervised & Self-Supervised Learning']","Yang, Y., Gu, X., & Sun, J. (2023). Prototypical Partial Optimal Transport for Universal Domain Adaptation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10852-10860. https://doi.org/10.1609/aaai.v37i9.26287","Abstract 					Universal domain adaptation (UniDA) aims to transfer knowledge from a labeled source domain to an unlabeled target domain without requiring the same label sets of both domains. The existence of domain and category shift makes the task challenging and requires us to distinguish “known” samples (i.e., samples whose labels exist in both domains) and “unknown” samples (i.e., samples whose labels exist in only one domain) in both domains before reducing the domain gap. In this paper, we consider the problem from the point of view of distribution matching which we only need to align two distributions partially. A novel approach, dubbed mini-batch Prototypical Partial Optimal Transport (m-PPOT), is proposed to conduct partial distribution alignment for UniDA. In training phase, besides minimizing m-PPOT, we also leverage the transport plan of m-PPOT to reweight source prototypes and target samples, and design reweighted entropy loss and reweighted cross-entropy loss to distinguish “known” and “unknown” samples. Experiments on four benchmarks show that our method outperforms the previous state-of-the-art UniDA methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26287/26059"
"26288","DeCOM: Decomposed Policy for Constrained Cooperative Multi-Agent Reinforcement Learning","['Zhaoxing Yang', 'Haiming Jin', 'Rong Ding', 'Haoyi You', 'Guiyun Fan', 'Xinbing Wang', 'Chenghu Zhou']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['ML: Reinforcement Learning Algorithms', 'MAS: Multiagent Learning']","Yang, Z., Jin, H., Ding, R., You, H., Fan, G., Wang, X., & Zhou, C. (2023). DeCOM: Decomposed Policy for Constrained Cooperative Multi-Agent Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10861-10870. https://doi.org/10.1609/aaai.v37i9.26288","Abstract 					In recent years, multi-agent reinforcement learning (MARL) has presented impressive performance in various applications. However, physical limitations, budget restrictions, and many other factors usually impose constraints on a multi-agent system (MAS), which cannot be handled by traditional MARL frameworks. Specifically, this paper focuses on constrained MASes where agents work cooperatively to maximize the expected team-average return under various constraints on expected team-average costs, and develops a constrained cooperative MARL framework, named DeCOM, for such MASes. In particular, DeCOM decomposes the policy of each agent into two modules, which empowers information sharing among agents to achieve better cooperation. In addition, with such modularization, the training algorithm of DeCOM separates the original constrained optimization into an unconstrained optimization on reward and a constraints satisfaction problem on costs. DeCOM then iteratively solves these problems in a computationally efficient manner, which makes DeCOM highly scalable. We also provide theoretical guarantees on the convergence of DeCOM's policy update algorithm. Finally, we conduct extensive experiments to show the effectiveness of DeCOM with various types of costs in both moderate-scale and large-scale (with 500 agents) environments that originate from real-world applications.","https://ojs.aaai.org/index.php/AAAI/article/view/26288/26060"
"26289","Purifier: Defending Data Inference Attacks via Transforming Confidence Scores","['Ziqi Yang', 'Lijin Wang', 'Da Yang', 'Jie Wan', 'Ziming Zhao', 'Ee-Chien Chang', 'Fan Zhang', 'Kui Ren']","['Zhejiang University\nZJU-Hangzhou Global Scientific and Technological Innovation Center\nKey Laboratory of Blockchain and Cyberspace Governance of Zhejiang Province', 'ZheJiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'National University of Singapore', 'Zhejiang University\nJiaxing Research Institute, Zhejiang University\nZhengzhou Xinda Institute of Advanced Technology', 'Zhejiang University\nZJU-Hangzhou Global Scientific and Technological Innovation Center\nKey Laboratory of Blockchain and Cyberspace Governance of Zhejiang Province\nJiaxing Research Institute, Zhejiang University']","['ML: Privacy-Aware ML', 'CV: Bias', 'Fairness & Privacy', 'PEAI: Privacy and Security']","Yang, Z., Wang, L., Yang, D., Wan, J., Zhao, Z., Chang, E.-C., Zhang, F., & Ren, K. (2023). Purifier: Defending Data Inference Attacks via Transforming Confidence Scores. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10871-10879. https://doi.org/10.1609/aaai.v37i9.26289","Abstract 					Neural networks are susceptible to data inference attacks such as the membership inference attack, the adversarial model inversion attack and the attribute inference attack, where the attacker could infer useful information such as the membership, the reconstruction or the sensitive attributes of a data sample from the confidence scores predicted by the target classifier. In this paper, we propose a method, namely PURIFIER, to defend against membership inference attacks. It transforms the confidence score vectors predicted by the target classifier and makes purified confidence scores indistinguishable in individual shape, statistical distribution and prediction label between members and non-members. The experimental results show that PURIFIER helps defend membership inference attacks with high effectiveness and efficiency, outperforming previous defense methods, and also incurs negligible utility loss. Besides, our further experiments show that PURIFIER is also effective in defending adversarial model inversion attacks and attribute inference attacks. For example, the inversion error is raised about 4+ times on the Facescrub530 classifier, and the attribute inference accuracy drops significantly when PURIFIER is deployed in our experiment.","https://ojs.aaai.org/index.php/AAAI/article/view/26289/26061"
"26290","i-Code: An Integrative and Composable Multimodal Learning Framework","['Ziyi Yang', 'Yuwei Fang', 'Chenguang Zhu', 'Reid Pryzant', 'DongDong Chen', 'Yu Shi', 'Yichong Xu', 'Yao Qian', 'Mei Gao', 'Yi-Ling Chen', 'Liyang Lu', 'Yujia Xie', 'Robert Gmyr', 'Noel Codella', 'Naoyuki Kanda', 'Bin Xiao', 'Lu Yuan', 'Takuya Yoshioka', 'Michael Zeng', 'Xuedong Huang']","['Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft', 'Microsoft']","['ML: Multimodal Learning', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning']","Yang, Z., Fang, Y., Zhu, C., Pryzant, R., Chen, D., Shi, Y., Xu, Y., Qian, Y., Gao, M., Chen, Y.-L., Lu, L., Xie, Y., Gmyr, R., Codella, N., Kanda, N., Xiao, B., Yuan, L., Yoshioka, T., Zeng, M., & Huang, X. (2023). i-Code: An Integrative and Composable Multimodal Learning Framework. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10880-10890. https://doi.org/10.1609/aaai.v37i9.26290","Abstract 					Human intelligence is multimodal; we integrate visual, linguistic, and acoustic signals to maintain a holistic worldview. Most current pretraining methods, however, are limited to one or two modalities. We present i-Code, a self-supervised pretraining framework where users may flexibly combine the modalities of vision, speech, and language into unified and general-purpose vector representations. In this framework, data from each modality are first given to pretrained single-modality encoders. The encoder outputs are then integrated with a multimodal fusion network, which uses novel merge- and co-attention mechanisms to effectively combine information from the different modalities. The entire system is pretrained end-to-end with new objectives including masked modality unit modeling and cross-modality contrastive learning. Unlike previous research using only video for pretraining, the i-Code framework can dynamically process single, dual, and triple-modality data during training and inference, flexibly projecting different combinations of modalities into a single representation space. Experimental results demonstrate how i-Code can outperform state-of-the-art techniques on five multimodal understanding tasks and single-modality benchmarks, improving by as much as 11% and demonstrating the power of integrative multimodal pretraining.","https://ojs.aaai.org/index.php/AAAI/article/view/26290/26062"
"26291","Learning Dynamic Latent Spaces for Lifelong Generative Modelling","['Fei Ye', 'Adrian G. Bors']","['University of york', 'University of York']","['ML: Lifelong and Continual Learning', 'ML: Ensemble Methods', 'ML: Representation Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Ye, F., & Bors, A. G. (2023). Learning Dynamic Latent Spaces for Lifelong Generative Modelling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10891-10899. https://doi.org/10.1609/aaai.v37i9.26291","Abstract 					Task Free Continual Learning (TFCL) aims to capture novel concepts from non-stationary data streams without forgetting previously learned knowledge. Mixture models, which add new components when certain conditions are met, have shown promising results in TFCL tasks. However, such approaches do not make use of the knowledge already accumulated for positive knowledge transfer. In this paper, we develop a new model, namely the Online Recursive Variational Autoencoder (ORVAE). ORVAE utilizes the prior knowledge by selectively incorporating the newly learnt information, by adding new components, according to the knowledge already known from the past learnt data. We introduce a new attention mechanism to regularize the structural latent space in which the most important information is reused while the information that interferes with novel samples is inactivated. The proposed attention mechanism can maximize the benefit from the forward transfer for learning novel information without forgetting previously learnt knowledge. We perform several experiments which show that ORVAE achieves state-of-the-art results under TFCL.","https://ojs.aaai.org/index.php/AAAI/article/view/26291/26063"
"26292","Lifelong Compression Mixture Model via Knowledge Relationship Graph","['Fei Ye', 'Adrian G. Bors']","['University of York', 'University of York']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Graph-based Machine Learning', 'ML: Learning on the Edge & Model Compression', 'ML: Lifelong and Continual Learning']","Ye, F., & Bors, A. G. (2023). Lifelong Compression Mixture Model via Knowledge Relationship Graph. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10900-10908. https://doi.org/10.1609/aaai.v37i9.26292","Abstract 					Task-Free Continual Learning (TFCL) represents a challenging scenario for lifelong learning because the model, under this paradigm, does not access any task information. The Dynamic Expansion Model (DEM) has shown promising results in this scenario due to its scalability and generalisation power. However, DEM focuses only on addressing forgetting and ignores minimizing  the model size, which limits its deployment in practical systems. In this work, we aim to simultaneously address network forgetting and model size optimization by developing the Lifelong Compression Mixture Model (LGMM) equipped with the Maximum Mean Discrepancy (MMD) based expansion criterion for model expansion. A diversity-aware sample selection approach is proposed to selectively store a variety of samples to promote information diversity among the components of the LGMM, which allows more knowledge to be captured with an appropriate model size. In order to avoid having multiple components with similar knowledge in the LGMM, we propose a data-free component discarding mechanism that evaluates a knowledge relation graph matrix describing the relevance between each pair of components. A greedy selection procedure is proposed to identify and remove the redundant    components from the LGMM. The proposed discarding mechanism can be performed during or after the training. Experiments on different datasets show that LGMM achieves the best performance for TFCL.","https://ojs.aaai.org/index.php/AAAI/article/view/26292/26064"
"26293","Lifelong Variational Autoencoder via Online Adversarial Expansion Strategy","['Fei Ye', 'Adrian G. Bors']","['University of York', 'University of York']","['ML: Deep Learning Theory', 'ML: Deep Generative Models & Autoencoders', 'ML: Ensemble Methods', 'ML: Representation Learning']","Ye, F., & Bors, A. G. (2023). Lifelong Variational Autoencoder via Online Adversarial Expansion Strategy. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10909-10917. https://doi.org/10.1609/aaai.v37i9.26293","Abstract 					The Variational Autoencoder (VAE) suffers from a significant loss of information when trained  on a non-stationary data distribution. This loss in VAE models, called catastrophic forgetting, has not been studied theoretically before. We analyse the forgetting behaviour of a VAE in continual generative modelling by developing a new lower bound on the data likelihood, which interprets the forgetting process as an increase in the probability distance between the generator's distribution and the evolved data distribution. The proposed bound shows that a VAE-based dynamic expansion model can achieve better performance if its capacity increases appropriately considering the shift in the data distribution. Based on this analysis, we propose a novel expansion criterion that aims to preserve the information diversity among the VAE components, while ensuring that it acquires more knowledge with fewer parameters. Specifically, we implement this expansion criterion from the perspective of a multi-player game and propose the Online Adversarial Expansion Strategy (OAES), which considers all previously learned components as well as the currently updated component as multiple players in a game, while an adversary model evaluates their performance. The proposed OAES can dynamically estimate the discrepancy between each player and the adversary without accessing task information. This leads to the gradual addition of new components while ensuring the knowledge diversity among all of them. We show theoretically and empirically that the proposed extension strategy can enable a VAE model to achieve the best performance given an appropriate model size.","https://ojs.aaai.org/index.php/AAAI/article/view/26293/26065"
"26294","Continual Variational Autoencoder via Continual Generative Knowledge Distillation","['Fei Ye', 'Adrian G. Bors']","['University of York', 'University of York']","['ML: Deep Generative Models & Autoencoders', 'ML: Deep Learning Theory', 'ML: Ensemble Methods', 'ML: Lifelong and Continual Learning']","Ye, F., & Bors, A. G. (2023). Continual Variational Autoencoder via Continual Generative Knowledge Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10918-10926. https://doi.org/10.1609/aaai.v37i9.26294","Abstract 					Humans and other living beings have the ability of short and long-term memorization during their entire lifespan. However, most existing Continual Learning (CL) methods can only account for short-term information when training on infinite streams of data. In this paper, we develop a new unsupervised continual learning framework consisting of two memory systems using Variational Autoencoders (VAEs). We develop a Short-Term Memory (STM), and a parameterised scalable memory implemented by a Teacher model aiming to preserve the long-term information. To incrementally enrich the Teacher's knowledge during training, we propose the Knowledge Incremental Assimilation Mechanism (KIAM), which evaluates the knowledge similarity between the STM and the already accumulated information as signals to expand the Teacher's capacity. Then we train a VAE as a Student module and propose a new Knowledge Distillation (KD) approach that gradually transfers generative knowledge from the Teacher to the Student module. To ensure the quality and diversity of knowledge in KD, we propose a new expert pruning approach that selectively removes the Teacher's redundant parameters, associated with unnecessary experts which have learnt overlapping information with other experts. This mechanism further reduces the complexity of the Teacher's module while ensuring the diversity of knowledge for the KD procedure. We show theoretically and empirically that the proposed framework can train a statistically diversified Teacher module for continual VAE learning which is applicable to learning infinite data streams.","https://ojs.aaai.org/index.php/AAAI/article/view/26294/26066"
"26295","Certifiable Out-of-Distribution Generalization","['Nanyang Ye', 'Lin Zhu', 'Jia Wang', 'Zhaoyu Zeng', 'Jiayao Shao', 'Chensheng Peng', 'Bikang Pan', 'Kaican Li', 'Jun Zhu']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'University of Cambridge', 'Shanghai Jiao Tong University', 'University of Warwick', 'Shanghai Jiao Tong University', 'ShanghaiTech University', ""Huawei Noah's Ark Lab"", 'Tsinghua University']","['ML: Representation Learning']","Ye, N., Zhu, L., Wang, J., Zeng, Z., Shao, J., Peng, C., Pan, B., Li, K., & Zhu, J. (2023). Certifiable Out-of-Distribution Generalization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10927-10935. https://doi.org/10.1609/aaai.v37i9.26295","Abstract 					Machine learning methods suffer from test-time performance degeneration when faced with out-of-distribution (OoD) data whose distribution is not necessarily the same as training data distribution. Although a plethora of algorithms have been proposed to mitigate this issue, it has been demonstrated that achieving better performance than ERM simultaneously on different types of distributional shift datasets is challenging for existing approaches. Besides, it is unknown how and to what extent these methods work on any OoD datum without theoretical guarantees. In this paper, we propose a certifiable out-of-distribution generalization method that provides provable OoD generalization performance guarantees via a functional optimization framework leveraging random distributions and max-margin learning for each input datum. With this approach, the proposed algorithmic scheme can provide certified accuracy for each input datum's prediction on the semantic space and achieves better performance simultaneously on OoD datasets dominated by correlation shifts or diversity shifts. Our code is available at https://github.com/ZlatanWilliams/StochasticDisturbanceLearning.","https://ojs.aaai.org/index.php/AAAI/article/view/26295/26067"
"26296","Random Walk Conformer: Learning Graph Representation from Long and Short Range","['Pei-Kai Yeh', 'Hsi-Wen Chen', 'Ming-Syan Chen']","['National Taiwan University', 'National Taiwan University', 'National Taiwan University']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Yeh, P.-K., Chen, H.-W., & Chen, M.-S. (2023). Random Walk Conformer: Learning Graph Representation from Long and Short Range. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10936-10944. https://doi.org/10.1609/aaai.v37i9.26296","Abstract 					While graph neural networks (GNNs) have achieved notable success in various graph mining tasks, conventional GNNs only model the pairwise correlation in 1-hop neighbors without considering the long-term relations and the high-order patterns, thus limiting their performances. Recently, several works have addressed these issues by exploring the motif, i.e., frequent subgraphs. However, these methods usually require an unacceptable computational time to enumerate all possible combinations of motifs. In this paper, we introduce a new GNN framework, namely Random Walk Conformer (RWC), to exploit global correlations and local patterns based on the random walk, which is a promising method to discover the graph structure. Besides, we propose random walk encoding to help RWC capture topological information, which is proven more expressive than conventional spatial encoding. Extensive experiment results manifest that RWC achieves state-of-the-art performance on graph classification and regression tasks. The source code of RWC is available at https://github.com/b05901024/RandomWalkConformer.","https://ojs.aaai.org/index.php/AAAI/article/view/26296/26068"
"26297","Lottery Pools: Winning More by Interpolating Tickets without Increasing Training or Inference Cost","['Lu Yin', 'Shiwei Liu', 'Meng Fang', 'Tianjin Huang', 'Vlado Menkovski', 'Mykola Pechenizkiy']","['Eindhoven University of Technology', 'Eindhoven University of Technology\nUniversity of Texas at Austin', 'University of Liverpool', 'Eindhoven University of Technology', 'Eindhoven University of Technology', 'Eindhoven University of Technology']","['ML: Learning on the Edge & Model Compression', 'ML: Deep Neural Network Algorithms', 'ML: Ensemble Methods']","Yin, L., Liu, S., Fang, M., Huang, T., Menkovski, V., & Pechenizkiy, M. (2023). Lottery Pools: Winning More by Interpolating Tickets without Increasing Training or Inference Cost. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10945-10953. https://doi.org/10.1609/aaai.v37i9.26297","Abstract 					Lottery tickets (LTs) is able to discover accurate and sparse subnetworks that could be trained in isolation to match the performance of dense networks. Ensemble, in parallel, is one of the oldest time-proven tricks in machine learning to improve performance by combining the output of multiple independent models. However, the benefits of ensemble in the context of LTs will be diluted since ensemble does not directly lead to stronger sparse subnetworks, but leverages their predictions for a better decision. In this work, we first observe that directly averaging the weights of the adjacent learned subnetworks significantly boosts the performance of LTs. Encouraged by this observation, we further propose an alternative way to perform an ""ensemble'' over the subnetworks identified by iterative magnitude pruning via a simple interpolating strategy. We call our method Lottery Pools. In contrast to the naive ensemble which brings no performance gains to each single subnetwork, Lottery Pools yields much stronger sparse subnetworks than the original LTs without requiring any extra training or inference cost. Across various modern architectures on CIFAR-10/100 and ImageNet, we show that our method achieves significant performance gains in both, in-distribution and out-of-distribution scenarios. Impressively, evaluated with VGG-16 and ResNet-18, the produced sparse subnetworks outperform the original LTs by up to 1.88% on CIFAR-100 and 2.36% on CIFAR-100-C; the resulting dense network surpasses the pre-trained dense-model up to   2.22% on CIFAR-100 and 2.38% on CIFAR-100-C. Our source code can be found at https://github.com/luuyin/Lottery-pools.","https://ojs.aaai.org/index.php/AAAI/article/view/26297/26069"
"26298","GOHSP: A Unified Framework of Graph and Optimization-Based Heterogeneous Structured Pruning for Vision Transformer","['Miao Yin', 'Burak Uzkent', 'Yilin Shen', 'Hongxia Jin', 'Bo Yuan']","['Rutgers University', 'Samsung Research America', 'Samsung Research America', 'Samsung Research America', 'Rutgers university']","['ML: Applications', 'ML: Representation Learning', 'CV: Representation Learning for Vision']","Yin, M., Uzkent, B., Shen, Y., Jin, H., & Yuan, B. (2023). GOHSP: A Unified Framework of Graph and Optimization-Based Heterogeneous Structured Pruning for Vision Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10954-10962. https://doi.org/10.1609/aaai.v37i9.26298","Abstract 					The recently proposed Vision transformers (ViTs) have shown very impressive empirical performance in various computer vision tasks, and they are viewed as an important type of foundation model. However, ViTs are typically constructed with large-scale sizes, which then severely hinder their potential deployment in many practical resources constrained applications.  To mitigate this challenging problem, structured pruning is a promising solution to compress model size and enable practical efficiency. However, unlike its current popularity for CNNs and RNNs, structured pruning for ViT models is little explored. In this paper, we propose GOHSP, a unified framework of Graph and Optimization-based Structured Pruning for ViT models. We first develop a graph-based ranking for measuring the importance of attention heads, and the extracted importance information is further integrated to an optimization-based procedure to impose the heterogeneous structured sparsity patterns on the ViT models. Experimental results show that our proposed GOHSP demonstrates excellent compression performance. On CIFAR-10 dataset, our approach can bring 40% parameters reduction with no accuracy loss for ViT-Small model. On ImageNet dataset, with 30% and 35% sparsity ratio for DeiT-Tiny and DeiT-Small models, our approach achieves 1.65% and 0.76% accuracy increase over the existing structured pruning methods, respectively.","https://ojs.aaai.org/index.php/AAAI/article/view/26298/26070"
"26299","Policy-Based Primal-Dual Methods for Convex Constrained Markov Decision Processes","['Donghao Ying', 'Mengzi Amy Guo', 'Yuhao Ding', 'Javad Lavaei', 'Zuo-Jun Shen']","['UC Berkeley, Department of Industrial Engineering and Operations Research', 'UC Berkeley, Department of Industrial Engineering and Operations Research', 'UC Berkeley, Department of Industrial Engineering and Operations Research', 'UC Berkeley, Department of Industrial Engineering and Operations Research', 'UC Berkeley, Department of Industrial Engineering and Operations Research']","['ML: Reinforcement Learning Theory', 'ML: Learning Theory', 'ML: Optimization', 'ML: Reinforcement Learning Algorithms']","Ying, D., Guo, M. A., Ding, Y., Lavaei, J., & Shen, Z.-J. (2023). Policy-Based Primal-Dual Methods for Convex Constrained Markov Decision Processes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10963-10971. https://doi.org/10.1609/aaai.v37i9.26299","Abstract 					We study convex Constrained Markov Decision Processes (CMDPs) in which the objective is concave and the constraints are convex in the state-action occupancy measure. We propose a policy-based primal-dual algorithm that updates the primal variable via policy gradient ascent and updates the dual variable via projected sub-gradient descent. Despite the loss of additivity structure and the nonconvex nature, we establish the global convergence of the proposed algorithm by leveraging a hidden convexity in the problem, and prove the O(T^-1/3) convergence rate in terms of both optimality gap and constraint violation. When the objective is strongly concave in the occupancy measure, we prove an improved convergence rate of O(T^-1/2). By introducing a pessimistic term to the constraint, we further show that a zero constraint violation can be achieved while preserving the same convergence rate for the optimality gap. This work is the first one in the literature that establishes non-asymptotic convergence guarantees for policy-based primal-dual methods for solving infinite-horizon discounted convex CMDPs.","https://ojs.aaai.org/index.php/AAAI/article/view/26299/26071"
"26300","Priori Anchor Labels Supervised Scalable Multi-View Bipartite Graph Clustering","['Jiali You', 'Zhenwen Ren', 'Xiaojian You', 'Haoran Li', 'Yuancheng Yao']","['Southwest University of Science and Technology', 'Southwest University of Science and Technology\nKey Laboratory of System Control and Information Processing, Ministry of Education\nSongShan Laboratory', 'Southwest University of Science and Technology', 'Southwest University of Science and Technology\nSun Yat-sen University', 'Southwest University of Science and Technology']","['ML: Clustering', 'ML: Multi-Instance/Multi-View Learning']","You, J., Ren, Z., You, X., Li, H., & Yao, Y. (2023). Priori Anchor Labels Supervised Scalable Multi-View Bipartite Graph Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10972-10979. https://doi.org/10.1609/aaai.v37i9.26300","Abstract 					Although multi-view clustering (MVC) has achieved remarkable performance by integrating the complementary information of views, it is inefficient when facing scalable data. Proverbially, anchor strategy can mitigate such a challenge a certain extent. However, the unsupervised dynamic strategy usually cannot obtain the optimal anchors for MVC. The main reasons are that it does not consider the fairness of different views and lacks the priori supervised guidance. To completely solve these problems, we first propose the priori anchor graph regularization (PAGG) for scalable multi-view bipartite graph clustering, dubbed as SMGC method. Specifically, SMGC learns a few representative consensus anchors to simulate the numerous view data well, and constructs a bipartite graph to bridge the affinities between the anchors and original data points. In order to largely improve the quality of anchors, PAGG predefines prior anchor labels to constrain the anchors with discriminative cluster structure and fair view allocation, such that a better bipartite graph can be obtained for fast clustering. Experimentally, abundant of experiments are accomplished on six scalable benchmark datasets, and the experimental results fully demonstrate the effectiveness and efficiency of our SMGC.","https://ojs.aaai.org/index.php/AAAI/article/view/26300/26072"
"26301","STARS: Spatial-Temporal Active Re-sampling for Label-Efficient Learning from Noisy Annotations","['Dayou Yu', 'Weishi Shi', 'Qi Yu']","['Rochester Institute of Technology', 'University of North Texas', 'Rochester Institute of Technology']","['ML: Active Learning']","Yu, D., Shi, W., & Yu, Q. (2023). STARS: Spatial-Temporal Active Re-sampling for Label-Efficient Learning from Noisy Annotations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10980-10988. https://doi.org/10.1609/aaai.v37i9.26301","Abstract 					Active learning (AL) aims to sample the most informative data instances for labeling, which makes the model fitting data efficient while significantly reducing the annotation cost. However, most existing AL models make a strong assumption that the annotated data instances are always assigned correct labels, which may not hold true in many practical settings.  In this paper, we develop a theoretical framework to formally analyze the impact of noisy annotations and show that systematically re-sampling guarantees to reduce the noise rate, which can lead to improved generalization capability. More importantly, the theoretical framework demonstrates the key benefit of conducting active re-sampling on label-efficient learning, which is critical for AL. The theoretical results also suggest essential properties of an active re-sampling function with a fast convergence speed and guaranteed error reduction. This inspires us to design a novel spatial-temporal active re-sampling function by leveraging the important spatial and temporal properties of maximum-margin classifiers. Extensive experiments conducted on both synthetic and real-world data clearly demonstrate the effectiveness of the proposed active re-sampling function.","https://ojs.aaai.org/index.php/AAAI/article/view/26301/26073"
"26302","Boosted Dynamic Neural Networks","['Haichao Yu', 'Haoxiang Li', 'Gang Hua', 'Gao Huang', 'Humphrey Shi']","['University of Illinois Urbana-Champaign', 'Wormpex AI Research', 'Wormpex AI Research', 'Tsinghua University', 'University of Illinois Urbana-Champaign\nUniversity of Oregon']","['ML: Deep Neural Architectures', 'ML: Learning on the Edge & Model Compression']","Yu, H., Li, H., Hua, G., Huang, G., & Shi, H. (2023). Boosted Dynamic Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10989-10997. https://doi.org/10.1609/aaai.v37i9.26302","Abstract 					Early-exiting dynamic neural networks (EDNN), as one type of dynamic neural networks, has been widely studied recently. A typical EDNN has multiple prediction heads at different layers of the network backbone. During inference, the model will exit at either the last prediction head or an intermediate prediction head where the prediction confidence is higher than a predefined threshold. To optimize the model, these prediction heads together with the network backbone are trained on every batch of training data. This brings a train-test mismatch problem that all the prediction heads are optimized on all types of data in training phase while the deeper heads will only see difficult inputs in testing phase. Treating training and testing inputs differently at the two phases will cause the mismatch between training and testing data distributions. To mitigate this problem, we formulate an EDNN as an additive model inspired by gradient boosting, and propose multiple training techniques to optimize the model effectively. We name our method BoostNet. Our experiments show it achieves the state-of-the-art performance on CIFAR100 and ImageNet datasets in both anytime and budgeted-batch prediction modes. Our code is released at https://github.com/SHI-Labs/Boosted-Dynamic-Networks.","https://ojs.aaai.org/index.php/AAAI/article/view/26302/26074"
"26303","Stable Learning via Sparse Variable Independence","['Han Yu', 'Peng Cui', 'Yue He', 'Zheyan Shen', 'Yong Lin', 'Renzhe Xu', 'Xingxuan Zhang']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Hong Kong University of Science and Technology', 'Tsinghua University', 'Tsinghua University']","['ML: Causal Learning', 'PEAI: Safety', 'Robustness & Trustworthiness']","Yu, H., Cui, P., He, Y., Shen, Z., Lin, Y., Xu, R., & Zhang, X. (2023). Stable Learning via Sparse Variable Independence. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 10998-11006. https://doi.org/10.1609/aaai.v37i9.26303","Abstract 					The problem of covariate-shift generalization has attracted intensive research attention. Previous stable learning algorithms employ sample reweighting schemes to decorrelate the covariates when there is no explicit domain information about training data. However, with finite samples, it is difficult to achieve the desirable weights that ensure perfect independence to get rid of the unstable variables. Besides, decorrelating within stable variables may bring about high variance of learned models because of the over-reduced effective sample size. A tremendous sample size is required for these algorithms to work. In this paper, with theoretical justification, we propose SVI (Sparse Variable Independence) for the covariate-shift generalization problem. We introduce sparsity constraint to compensate for the imperfectness of sample reweighting under the finite-sample setting in previous methods. Furthermore, we organically combine independence-based sample reweighting and sparsity-based variable selection in an iterative way to avoid decorrelating within stable variables, increasing the effective sample size to alleviate variance inflation. Experiments on both synthetic and real-world datasets demonstrate the improvement of covariate-shift generalization performance brought by SVI.","https://ojs.aaai.org/index.php/AAAI/article/view/26303/26075"
"26304","Compressing Transformers: Features Are Low-Rank, but Weights Are Not!","['Hao Yu', 'Jianxin Wu']","['Nanjing University', 'Nanjing University']","['ML: Learning on the Edge & Model Compression', 'CV: Representation Learning for Vision', 'ML: Deep Neural Network Algorithms', 'SNLP: Language Models']","Yu, H., & Wu, J. (2023). Compressing Transformers: Features Are Low-Rank, but Weights Are Not!. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11007-11015. https://doi.org/10.1609/aaai.v37i9.26304","Abstract 					Transformer and its variants achieve excellent results in various computer vision and natural language processing tasks,  but high computational costs and reliance on large training datasets restrict their deployment in resource-constrained settings. Low-rank approximation of model weights has been effective in compressing CNN models, but its application to transformers has been less explored and is less effective. Existing methods require the complete dataset to fine-tune compressed models, which are both time-consuming and data-hungry. This paper reveals that the features (i.e., activations) are low-rank, but model weights are surprisingly not low-rank. Hence, AAFM is proposed, which adaptively determines the compressed model structure and locally compresses each linear layer's output features rather than the model weights. A second stage, GFM, optimizes the entire compressed network holistically. Both AAFM and GFM only use few training samples without labels, that is, they are few-shot, unsupervised, fast and effective. For example, with only 2K images without labels, 33% of the parameters are removed in DeiT-B with 18.8% relative throughput increase, but only a 0.23% accuracy loss for ImageNet recognition. The proposed methods are successfully applied to the language modeling task in NLP, too. Besides, the few-shot compressed models generalize well in downstream tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26304/26076"
"26305","Offline Imitation Learning with Suboptimal Demonstrations via Relaxed Distribution Matching","['Lantao Yu', 'Tianhe Yu', 'Jiaming Song', 'Willie Neiswanger', 'Stefano Ermon']","['Computer Science Department, Stanford University', 'Computer Science Department, Stanford University', 'NVIDIA', 'Computer Science Department, Stanford University', 'Computer Science Department, Stanford University']","['ML: Imitation Learning & Inverse Reinforcement Learning']","Yu, L., Yu, T., Song, J., Neiswanger, W., & Ermon, S. (2023). Offline Imitation Learning with Suboptimal Demonstrations via Relaxed Distribution Matching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11016-11024. https://doi.org/10.1609/aaai.v37i9.26305","Abstract 					Offline imitation learning (IL) promises the ability to learn performant policies from pre-collected demonstrations without interactions with the environment. However, imitating behaviors fully offline typically requires numerous expert data. To tackle this issue, we study the setting where we have limited expert data and supplementary suboptimal data. In this case, a well-known issue is the distribution shift between the learned policy and the behavior policy that collects the offline data. Prior works mitigate this issue by regularizing the KL divergence between the stationary state-action distributions of the learned policy and the behavior policy. We argue that such constraints based on exact distribution matching can be overly conservative and hamper policy learning, especially when the imperfect offline data is highly suboptimal. To resolve this issue, we present RelaxDICE, which employs an asymmetrically-relaxed f-divergence for explicit support regularization. Specifically, instead of driving the learned policy to exactly match the behavior policy, we impose little penalty whenever the density ratio between their stationary state-action distributions is upper bounded by a constant. Note that such formulation leads to a nested min-max optimization problem, which causes instability in practice. RelaxDICE addresses this challenge by supporting a closed-form solution for the inner maximization problem. Extensive empirical study shows that our method significantly outperforms the best prior offline IL method in six standard continuous control environments with over 30% performance gain on average, across 22 settings where the imperfect dataset is highly suboptimal.","https://ojs.aaai.org/index.php/AAAI/article/view/26305/26077"
"26306","High-Level Semantic Feature Matters Few-Shot Unsupervised Domain Adaptation","['Lei Yu', 'Wanqi Yang', 'Shengqi Huang', 'Lei Wang', 'Ming Yang']","['Nanjing Normal University', 'Nanjing Normal University', 'Nanjing Normal University', 'University of Wollongong', 'Nanjing Normal University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Meta Learning']","Yu, L., Yang, W., Huang, S., Wang, L., & Yang, M. (2023). High-Level Semantic Feature Matters Few-Shot Unsupervised Domain Adaptation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11025-11033. https://doi.org/10.1609/aaai.v37i9.26306","Abstract 					In few-shot unsupervised domain adaptation (FS-UDA), most existing methods followed the few-shot learning (FSL) methods to leverage the low-level local features (learned from conventional convolutional models, e.g., ResNet) for classification. However, the goal of FS-UDA and FSL are relevant yet distinct, since FS-UDA aims to classify the samples in target domain rather than source domain. We found that the local features are insufficient to FS-UDA, which could introduce noise or bias against classification, and not be used to effectively align the domains. To address the above issues, we aim to refine the local features to be more discriminative and relevant to classification. Thus, we propose a novel task-specific semantic feature learning method (TSECS) for FS-UDA. TSECS learns high-level semantic features for image-to-class similarity measurement. Based on the high-level features, we design a cross-domain self-training strategy to leverage the few labeled samples in source domain to build the classifier in target domain. In addition, we minimize the KL divergence of the high-level feature distributions between source and target domains to shorten the distance of the samples between the two domains. Extensive experiments on DomainNet show that the proposed method significantly outperforms SOTA methods in FS-UDA by a large margin (i.e., ~10%).","https://ojs.aaai.org/index.php/AAAI/article/view/26306/26078"
"26307","Coordinate Descent Methods for DC Minimization: Optimality Conditions and Global Convergence","['Ganzhao Yuan']","['Peng Cheng Laboratory, China']","['ML: Optimization', 'CSO: Mixed Discrete/Continuous Optimization']","Yuan, G. (2023). Coordinate Descent Methods for DC Minimization: Optimality Conditions and Global Convergence. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11034-11042. https://doi.org/10.1609/aaai.v37i9.26307","Abstract 					Difference-of-Convex (DC) minimization, referring to the problem of minimizing the difference of two convex functions, has been found rich applications in statistical learning and studied extensively for decades. However, existing methods are primarily based on multi-stage convex relaxation, only leading to weak optimality of critical points. This paper proposes a coordinate descent method for minimizing a class of DC functions based on sequential nonconvex approximation. Our approach iteratively solves a nonconvex one-dimensional subproblem globally, and it is guaranteed to converge to a coordinate-wise stationary point. We prove that this new optimality condition is always stronger than the standard critical point condition and directional point condition under a mildlocally bounded nonconvexity assumption. For comparisons, we also include a naive variant of coordinate descent methods based on sequential convex approximation in our study. When the objective function satisfies a globally bounded nonconvexity assumption and Luo-Tseng error bound assumption, coordinate descent methods achieve Q-linear convergence rate. Also, for many applications of interest, we show that the nonconvex one-dimensional subproblem can be computed exactly and efficiently using a breakpoint searching method. Finally, we have conducted extensive experiments on several statistical learning tasks to show the superiority of our approach.","https://ojs.aaai.org/index.php/AAAI/article/view/26307/26079"
"26308","CEMA – Cost-Efficient Machine-Assisted Document Annotations","['Guowen Yuan', 'Ben Kao', 'Tien-Hsuan Wu']","['University of Hong Kong', 'University of Hong Kong', 'University of Hong Kong']","['ML: Active Learning', 'SNLP: Syntax -- Tagging', 'Chunking & Parsing']","Yuan, G., Kao, B., & Wu, T.-H. (2023). CEMA – Cost-Efficient Machine-Assisted Document Annotations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11043-11050. https://doi.org/10.1609/aaai.v37i9.26308","Abstract 					We study the problem of semantically annotating textual documents that are complex in the sense that the documents are long, feature rich, and domain specific. Due to their complexity, such annotation tasks require trained human workers, which are very expensive in both time and money. We propose CEMA, a method for deploying machine learning to assist humans in complex document annotation. CEMA estimates the human cost of annotating each document and selects the set of documents to be annotated that strike the best balance between model accuracy and human cost. We conduct experiments on complex annotation tasks in which we compare CEMA against other document selection and annotation strategies. Our results show that CEMA is the most cost-efficient solution for those tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26308/26080"
"26309","Joint Multimodal Entity-Relation Extraction Based on Edge-Enhanced Graph Alignment Network and Word-Pair Relation Tagging","['Li Yuan', 'Yi Cai', 'Jin Wang', 'Qing Li']","['School of Software Engineering, South China University of Technology, Guangzhou, China\nKey Laboratory of Big Data and Intelligent Robot (SCUT), MOE of China', 'School of Software Engineering, South China University of Technology, Guangzhou, China\nKey Laboratory of Big Data and Intelligent Robot (SCUT), MOE of China\nThe Peng Cheng Laboratory, Shenzhen, China', 'School of Information Science and Engineering, Yunnan University, Yunnan, P.R. China', 'Department of Computing, The Hong Kong Polytechnic University, Hong Kong, China']","['ML: Multimodal Learning', 'SNLP: Information Extraction', 'SNLP: Speech and Multimodality', 'SNLP: Sentiment Analysis and Stylistic Analysis', 'CV: Multi-modal Vision']","Yuan, L., Cai, Y., Wang, J., & Li, Q. (2023). Joint Multimodal Entity-Relation Extraction Based on Edge-Enhanced Graph Alignment Network and Word-Pair Relation Tagging. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11051-11059. https://doi.org/10.1609/aaai.v37i9.26309","Abstract 					Multimodal named entity recognition (MNER) and multimodal relation extraction (MRE) are two fundamental subtasks in the multimodal knowledge graph construction task. However, the existing methods usually handle two tasks independently, which ignores the bidirectional interaction between them. This paper is the first to propose jointly performing MNER and MRE as a joint multimodal entity-relation extraction (JMERE) task . Besides, the current MNER and MRE models only consider aligning the visual objects with textual entities in visual and textual graphs but ignore the entity-entity relationships and object-object relationships. To address the above challenges, we propose an edge-enhanced graph alignment network and a word-pair relation tagging (EEGA) for the JMERE task. Specifically, we first design a word-pair relation tagging to exploit the bidirectional interaction between MNER and MRE and avoid error propagation. Then, we propose an edge-enhanced graph alignment network to enhance the JMERE task by aligning nodes and edges in the cross-graph. Compared with previous methods, the proposed method can leverage the edge information to auxiliary alignment between objects and entities and find the correlations between entity-entity relationships and object-object relationships. Experiments are conducted to show the effectiveness of our model.","https://ojs.aaai.org/index.php/AAAI/article/view/26309/26081"
"26310","ODE-RSSM: Learning Stochastic Recurrent State Space Model from Irregularly Sampled Data","['Zhaolin Yuan', 'Xiaojuan Ban', 'Zixuan Zhang', 'Xiaorui Li', 'Hong-Ning Dai']","['University of Science and Technology Beijing', 'University of Science and Technology Beijing', 'University of Science and Technology Beijing', 'University of Science and Technology Beijing', 'Hong Kong Baptist University']","['ML: Deep Generative Models & Autoencoders', 'ROB: Behavior Learning & Control', 'ML: Bayesian Learning', 'ML: Probabilistic Methods', 'ML: Representation Learning', 'PRS: Planning With Markov Models (MDPs', 'POMDPs)', 'RU: Stochastic Models & Probabilistic Inference', 'RU: Uncertainty Representations']","Yuan, Z., Ban, X., Zhang, Z., Li, X., & Dai, H.-N. (2023). ODE-RSSM: Learning Stochastic Recurrent State Space Model from Irregularly Sampled Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11060-11068. https://doi.org/10.1609/aaai.v37i9.26310","Abstract 					For the complicated input-output systems with nonlinearity and stochasticity, Deep State Space Models (SSMs) are effective for identifying systems in the latent state space, which are of great significance for representation, forecasting, and planning in online scenarios. However, most SSMs are designed for discrete-time sequences and inapplicable when the observations are irregular in time. To solve the problem, we propose a novel continuous-time SSM named Ordinary Differential Equation Recurrent State Space Model (ODE-RSSM). ODE-RSSM incorporates an ordinary differential equation (ODE) network (ODE-Net) to model the continuous-time evolution of latent states between adjacent time points. Inspired from the equivalent linear transformation on integration limits, we propose an efficient reparameterization method for solving batched ODEs with non-uniform time spans in parallel for efficiently training the ODE-RSSM with irregularly sampled sequences. We also conduct extensive experiments to evaluate the proposed ODE-RSSM and the baselines on three input-output datasets, one of which is a rollout of a private industrial dataset with strong long-term delay and stochasticity. The results demonstrate that the ODE-RSSM achieves better performance than other baselines in open loop prediction even if the time spans of predicted points are uneven and the distribution of length is changeable. Code is availiable at https://github.com/yuanzhaolin/ODE-RSSM.","https://ojs.aaai.org/index.php/AAAI/article/view/26310/26082"
"26311","Value-Consistent Representation Learning for Data-Efficient Reinforcement Learning","['Yang Yue', 'Bingyi Kang', 'Zhongwen Xu', 'Gao Huang', 'Shuicheng Yan']","['Tsinghua University\nSEA AI Lab', 'SEA AI Lab', 'SEA AI Lab', 'Tsinghua University', 'SEA AI Lab']","['ML: Reinforcement Learning Algorithms']","Yue, Y., Kang, B., Xu, Z., Huang, G., & Yan, S. (2023). Value-Consistent Representation Learning for Data-Efficient Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11069-11077. https://doi.org/10.1609/aaai.v37i9.26311","Abstract 					Deep reinforcement learning (RL) algorithms suffer severe performance degradation when the interaction data is scarce, which limits their real-world application. Recently, visual representation learning has been shown to be effective and promising for boosting sample efficiency in RL. These methods usually rely on contrastive learning and data augmentation to train a transition model, which is different from how the model is used in RL---performing value-based planning.  Accordingly, the learned representation by these visual methods may be good for recognition but not optimal for estimating state value and solving the decision problem. To address this issue, we propose a novel method, called value-consistent representation learning (VCR), to learn representations that are directly related to decision-making. More specifically, VCR trains a model to predict the future state (also referred to as the ""imagined state'') based on the current one and a sequence of actions. Instead of aligning this imagined state with a real state returned by the environment, VCR applies a Q value head on both of the states and obtains two distributions of action values. Then a distance is computed and minimized to force the imagined state to produce a similar action value prediction as that by the real state. We develop two implementations of the above idea for the discrete and continuous action spaces  respectively. We conduct experiments on Atari 100k and DeepMind Control Suite benchmarks to validate their effectiveness for improving sample efficiency. It has been demonstrated that our methods achieve new state-of-the-art performance for search-free RL algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26311/26083"
"26312","Learning Conflict-Noticed Architecture for Multi-Task Learning","['Zhixiong Yue', 'Yu Zhang', 'Jie Liang']","['Southern University of Science and Technology\nUniversity of Technology Sydney', 'Southern University of Science and Technology\nPeng Cheng Laboratory, Shenzhen, China', 'University of Technology Sydney']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'ML: Auto ML and Hyperparameter Tuning', 'ML: Deep Neural Architectures', 'CV: Learning & Optimization for CV']","Yue, Z., Zhang, Y., & Liang, J. (2023). Learning Conflict-Noticed Architecture for Multi-Task Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11078-11086. https://doi.org/10.1609/aaai.v37i9.26312","Abstract 					Multi-task learning has been widely used in many applications to enable more efficient learning by sharing part of the architecture across multiple tasks. However, a major challenge is the gradient conflict when optimizing the shared parameters, where the gradients of different tasks could have opposite directions. Directly averaging those gradients will impair the performance of some tasks and cause negative transfer. Different from most existing works that manipulate gradients to mitigate the gradient conflict, in this paper, we address this problem from the perspective of architecture learning and propose a Conflict-Noticed Architecture Learning (CoNAL) method to alleviate the gradient conflict by learning architectures. By introducing purely-specific modules specific to each task in the search space, the CoNAL method can automatically learn when to switch to purely-specific modules in the tree-structured network architectures when the gradient conflict occurs. To handle multi-task problems with a large number of tasks, we propose a progressive extension of the CoNAL method. Extensive experiments on computer vision, natural language processing, and reinforcement learning benchmarks demonstrate the effectiveness of the proposed methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26312/26084"
"26313","Quantum Multi-Agent Meta Reinforcement Learning","['Won Joon Yun', 'Jihong Park', 'Joongheon Kim']","['Korea University', 'Deakin University', 'Korea University']","['ML: Quantum Machine Learning', 'ML: Lifelong and Continual Learning', 'ML: Meta Learning', 'ML: Reinforcement Learning Algorithms', 'ML: Reinforcement Learning Theory']","Yun, W. J., Park, J., & Kim, J. (2023). Quantum Multi-Agent Meta Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11087-11095. https://doi.org/10.1609/aaai.v37i9.26313","Abstract 					Although quantum supremacy is yet to come, there has recently been an increasing interest in identifying the potential of quantum machine learning (QML) in the looming era of practical quantum computing. Motivated by this, in this article we re-design multi-agent reinforcement learning (MARL) based on the unique characteristics of quantum neural networks (QNNs) having two separate dimensions of trainable parameters: angle parameters affecting the output qubit states, and pole parameters associated with the output measurement basis. Exploiting this dyadic trainability as meta-learning capability, we propose quantum meta MARL (QM2ARL) that first applies angle training for meta-QNN learning, followed by pole training for few-shot or local-QNN training. To avoid overfitting, we develop an angle-to-pole regularization technique injecting noise into the pole domain during angle training. Furthermore, by exploiting the pole as the memory address of each trained QNN, we introduce the concept of pole memory allowing one to save and load trained QNNs using only two-parameter pole values. We theoretically prove the convergence of angle training under the angle-to-pole regularization, and by simulation corroborate the effectiveness of QM2ARL in achieving high reward and fast convergence, as well as of the pole memory in fast adaptation to a time-varying environment.","https://ojs.aaai.org/index.php/AAAI/article/view/26313/26085"
"26314","Linking Sketch Patches by Learning Synonymous Proximity for Graphic Sketch Representation","['Sicong Zang', 'Shikui Tu', 'Lei Xu']","['Shanghai Jiao Tong University, Shanghai, China', 'Shanghai Jiao Tong University, Shanghai, China', 'Shanghai Jiao Tong University, Shanghai, China']","['ML: Representation Learning', 'CV: Representation Learning for Vision', 'ML: Deep Generative Models & Autoencoders']","Zang, S., Tu, S., & Xu, L. (2023). Linking Sketch Patches by Learning Synonymous Proximity for Graphic Sketch Representation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11096-11103. https://doi.org/10.1609/aaai.v37i9.26314","Abstract 					Graphic sketch representations are effective for representing sketches. Existing methods take the patches cropped from sketches as the graph nodes, and construct the edges based on sketch's drawing order or Euclidean distances on the canvas. However, the drawing order of a sketch may not be unique, while the patches from semantically related parts of a sketch may be far away from each other on the canvas. In this paper, we propose an order-invariant, semantics-aware method for graphic sketch representations. The cropped sketch patches are linked according to their global semantics or local geometric shapes, namely the synonymous proximity, by computing the cosine similarity between the captured patch embeddings. Such constructed edges are learnable to adapt to the variation of sketch drawings, which enable the message passing among synonymous patches. Aggregating the messages from synonymous patches by graph convolutional networks plays a role of denoising, which is beneficial to produce robust patch embeddings and accurate sketch representations. Furthermore, we enforce a clustering constraint over the embeddings jointly with the network learning. The synonymous patches are self-organized as compact clusters, and their embeddings are guided to move towards their assigned cluster centroids. It raises the accuracy of the computed synonymous proximity. Experimental results show that our method significantly improves the performance on both controllable sketch synthesis and sketch healing.","https://ojs.aaai.org/index.php/AAAI/article/view/26314/26086"
"26315","Neural Integro-Differential Equations","['Emanuele Zappala', 'Antonio H. de O. Fonseca', 'Andrew H. Moberly', 'Michael J. Higley', 'Chadi Abdallah', 'Jessica A. Cardin', 'David van Dijk']","['Yale University', 'Yale University', 'Yale University', 'Yale University', 'Baylor College of Medicine', 'Yale University', 'Yale University']","['ML: Deep Neural Network Algorithms', 'CSO: Other Foundations of Constraint Satisfaction & Optimization', 'CSO: Solvers and Tools', 'ML: Applications', 'ML: Deep Neural Architectures']","Zappala, E., O. Fonseca, A. H. de, Moberly, A. H., Higley, M. J., Abdallah, C., Cardin, J. A., & van Dijk, D. (2023). Neural Integro-Differential Equations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11104-11112. https://doi.org/10.1609/aaai.v37i9.26315","Abstract 					Modeling continuous dynamical systems from discretely sampled observations is a fundamental problem in data science. Often, such dynamics are the result of non-local processes that present an integral over time. As such, these systems are modeled with Integro-Differential Equations (IDEs); generalizations of differential equations that comprise both an integral and a differential component. For example, brain dynamics are not accurately modeled by differential equations since their behavior is non-Markovian, i.e. dynamics are in part dictated by history. Here, we introduce the Neural IDE (NIDE), a novel deep learning framework based on the theory of IDEs where integral operators are learned using neural networks.       We test NIDE on several toy and brain activity datasets and demonstrate that NIDE outperforms other models. These tasks include time extrapolation as well as predicting dynamics from unseen initial conditions, which we test on whole-cortex activity recordings in freely behaving mice. Further, we show that NIDE can decompose dynamics into their Markovian and non-Markovian constituents, via the learned integral operator, which we test on fMRI brain activity recordings of people on ketamine. Finally, the integrand of the integral operator provides a latent space that gives insight into the underlying dynamics, which we demonstrate on wide-field brain imaging recordings. Altogether, NIDE is a novel approach that enables modeling of complex non-local dynamics with neural networks.","https://ojs.aaai.org/index.php/AAAI/article/view/26315/26087"
"26316","Leveraging Structure for Improved Classification of Grouped Biased Data","['Daniel Zeiberg', 'Shantanu Jain', 'Predrag Radivojac']","['Northeastern University', 'Northeastern University', 'Northeastern University']","['ML: Semi-Supervised Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Zeiberg, D., Jain, S., & Radivojac, P. (2023). Leveraging Structure for Improved Classification of Grouped Biased Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11113-11120. https://doi.org/10.1609/aaai.v37i9.26316","Abstract 					We consider semi-supervised binary classification for applications in which data points are naturally grouped (e.g., survey responses grouped by state) and the labeled data is biased (e.g., survey respondents are not representative of the population). The groups overlap in the feature space and consequently the input-output patterns are related across the groups. To model the inherent structure in such data, we assume the partition-projected class-conditional invariance across groups, defined in terms of the group-agnostic feature space. We demonstrate that under this assumption, the group carries additional information about the class, over the group-agnostic features, with provably improved area under the ROC curve. Further assuming invariance of partition-projected class-conditional distributions across both labeled and unlabeled data, we derive a semi-supervised algorithm that explicitly leverages the structure to learn an optimal, group-aware, probability-calibrated classifier, despite the bias in the labeled data. Experiments on synthetic and real data demonstrate the efficacy of our algorithm over suitable baselines and ablative models, spanning standard supervised and semi-supervised learning approaches, with and without incorporating the group directly as a feature.","https://ojs.aaai.org/index.php/AAAI/article/view/26316/26088"
"26317","Are Transformers Effective for Time Series Forecasting?","['Ailing Zeng', 'Muxi Chen', 'Lei Zhang', 'Qiang Xu']","['The Chinese University of Hong Kong,\nInternational Digital Economy Academy (IDEA)', 'The Chinese University of Hong Kong', 'International Digital Economy Academy (IDEA)', 'The Chinese University of Hong Kong']","['ML: Time-Series/Data Streams']","Zeng, A., Chen, M., Zhang, L., & Xu, Q. (2023). Are Transformers Effective for Time Series Forecasting?. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11121-11128. https://doi.org/10.1609/aaai.v37i9.26317","Abstract 					Recently, there has been a surge of Transformer-based solutions for the long-term time series forecasting (LTSF) task. Despite the growing performance over the past few years, we question the validity of this line of research in this work. Specifically, Transformers is arguably the most successful solution to extract the semantic correlations among the elements in a long sequence. However, in time series modeling, we are to extract the temporal relations in an ordered set of continuous points. While employing positional encoding and using tokens to embed sub-series in Transformers facilitate preserving some ordering information, the nature of the permutation-invariant self-attention mechanism inevitably results in temporal information loss.  To validate our claim, we introduce a set of embarrassingly simple one-layer linear models named LTSF-Linear for comparison. Experimental results on nine real-life datasets show that LTSF-Linear surprisingly outperforms existing sophisticated Transformer-based LTSF models in all cases, and often by a large margin. Moreover, we conduct comprehensive empirical studies to explore the impacts of various design elements of LTSF models on their temporal relation extraction capability. We hope this surprising finding opens up new research directions for the LTSF task. We also advocate revisiting the validity of Transformer-based solutions for other time series analysis tasks (e.g., anomaly detection) in the future.","https://ojs.aaai.org/index.php/AAAI/article/view/26317/26089"
"26318","Substructure Aware Graph Neural Networks","['DingYi Zeng', 'Wanlong Liu', 'Wenyu Chen', 'Li Zhou', 'Malu Zhang', 'Hong Qu']","['University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Representation Learning']","Zeng, D., Liu, W., Chen, W., Zhou, L., Zhang, M., & Qu, H. (2023). Substructure Aware Graph Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11129-11137. https://doi.org/10.1609/aaai.v37i9.26318","Abstract 					Despite the great achievements of Graph Neural Networks (GNNs) in graph learning, conventional GNNs struggle to break through the upper limit of the expressiveness of first-order Weisfeiler-Leman graph isomorphism test algorithm (1-WL) due to the consistency of the propagation paradigm of GNNs with the 1-WL.Based on the fact that it is easier to distinguish the original graph through subgraphs, we propose a  novel framework neural network framework called Substructure Aware Graph Neural Networks (SAGNN) to address these issues. We first propose a  Cut subgraph  which can be obtained from the original graph by continuously and selectively removing edges. Then we extend the random walk encoding paradigm to the return probability of the rooted node on the subgraph to capture the structural information and use it as a node feature to improve the expressiveness of GNNs. We theoretically prove that our framework is more powerful than 1-WL, and is superior in structure perception. Our extensive experiments demonstrate the effectiveness of our framework,  achieving state-of-the-art performance on a variety of well-proven graph tasks, and GNNs equipped with our framework perform flawlessly even in 3-WL failed graphs. Specifically, our framework achieves a maximum performance improvement of 83% compared to the base models and  32% compared to the previous state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26318/26090"
"26319","ImGCL: Revisiting Graph Contrastive Learning on Imbalanced Node Classification","['Liang Zeng', 'Lanqing Li', 'Ziqi Gao', 'Peilin Zhao', 'Jian Li']","['Tsinghua University', 'Tencent AI Lab', 'Hong Kong University of Science and Technology', 'Tencent AI Lab', 'Tsinghua University']","['ML: Graph-based Machine Learning']","Zeng, L., Li, L., Gao, Z., Zhao, P., & Li, J. (2023). ImGCL: Revisiting Graph Contrastive Learning on Imbalanced Node Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11138-11146. https://doi.org/10.1609/aaai.v37i9.26319","Abstract 					Graph contrastive learning (GCL) has attracted a surge of attention due to its superior performance for learning node/graph representations without labels. However, in practice, the underlying class distribution of unlabeled nodes for the given graph is usually imbalanced. This highly imbalanced class distribution inevitably deteriorates the quality of learned node representations in GCL. Indeed, we empirically find that most state-of-the-art GCL methods cannot obtain discriminative representations and exhibit poor performance on imbalanced node classification. Motivated by this observation, we propose a principled GCL framework on Imbalanced node classification (ImGCL), which automatically and adaptively balances the representations learned from GCL without labels. Specifically, we first introduce the online clustering based progressively balanced sampling (PBS) method with theoretical rationale, which balances the training sets based on pseudo-labels obtained from learned representations in GCL. We then develop the node centrality based PBS method to better preserve the intrinsic structure of graphs, by upweighting the important nodes of the given graph. Extensive experiments on multiple imbalanced graph datasets and imbalanced settings demonstrate the effectiveness of our proposed framework, which significantly improves the performance of the recent state-of-the-art GCL methods. Further experimental ablations and analyses show that the ImGCL framework consistently improves the representation quality of nodes in under-represented (tail) classes.","https://ojs.aaai.org/index.php/AAAI/article/view/26319/26091"
"26320","Foresee What You Will Learn: Data Augmentation for Domain Generalization in Non-stationary Environment","['Qiuhao Zeng', 'Wei Wang', 'Fan Zhou', 'Charles Ling', 'Boyu Wang']","['University of Western Ontario', 'University of Western Ontario', 'Beihang University', 'University of Western Ontario', 'University of Western Ontario']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Zeng, Q., Wang, W., Zhou, F., Ling, C., & Wang, B. (2023). Foresee What You Will Learn: Data Augmentation for Domain Generalization in Non-stationary Environment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11147-11155. https://doi.org/10.1609/aaai.v37i9.26320","Abstract 					Existing domain generalization aims to learn a generalizable model to perform well even on unseen domains. For many real-world machine learning applications, the data distribution often shifts gradually along domain indices. For example, a self-driving car with a vision system drives from dawn to dusk, with the sky gradually darkening. Therefore, the system must be able to adapt to changes in ambient illuminations and continue to drive safely on the road. In this paper, we formulate such problems as Evolving Domain Generalization, where a model aims to generalize well on a target domain by discovering and leveraging the evolving pattern of the environment. We then propose Directional Domain Augmentation (DDA), which simulates the unseen target features by mapping source data as augmentations through a domain transformer. Specifically, we formulate DDA as a bi-level optimization problem and solve it through a novel meta-learning approach in the representation space. We evaluate the proposed method on both synthetic datasets and real-world datasets, and empirical results show that our approach can outperform other existing methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26320/26092"
"26321","Acceleration of Large Transformer Model Training by Sensitivity-Based Layer Dropping","['Yujie Zeng', 'Wenlong He', 'Ihor Vasyltsov', 'Jiali Pang', 'Lin Chen']","['Samsung, SRCX', 'Samsung, SRCX', 'Samsung, SAIT', 'Samsung, SRCX', 'Samsung, SRCX']","['ML: Distributed Machine Learning & Federated Learning', 'ML: Optimization', 'SNLP: Language Models', 'SNLP: Learning & Optimization for SNLP']","Zeng, Y., He, W., Vasyltsov, I., Pang, J., & Chen, L. (2023). Acceleration of Large Transformer Model Training by Sensitivity-Based Layer Dropping. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11156-11163. https://doi.org/10.1609/aaai.v37i9.26321","Abstract 					Transformer models are widely used in AI applications such as Natural Language Processing (NLP), Computer Vision (CV), etc. However, enormous computation workload be-comes an obstacle to train large transformer models efficiently. Recently, some methods focus on reducing the computation workload during the training by skipping some layers. How-ever, these methods use simple probability distribution and coarse-grained probability calculation, which significantly affect the model accuracy. To address the issue, in this paper we propose a novel method to accelerate training—Sensitivity-Based Layer Dropping (SBLD). SBLD uses lay-er-wise sensitivity data to switch on/off transformer layers in proper order to keep high accuracy. Besides, we adjust the probability of skipping transformer layers with a scheduler to accelerate training speed and get faster convergence. Our results show that SBLD solves the accuracy drop issue com-pared with prior layer dropping methods. Our SBLD method can decrease end-to-end training time by 19.67% during training of GPT-3 Medium model, the same time increasing the accuracy by 1.65% w.r.t. baseline. Furthermore, for SwinV2-L model the obtained Top-1 and Top-5 accuracies are also higher vs. the baseline. Thus, the proposed method is efficient and practical to improve the large transformer model training.","https://ojs.aaai.org/index.php/AAAI/article/view/26321/26093"
"26322","Interventional SHAP Values and Interaction Values for Piecewise Linear Regression Trees","['Artjom Zern', 'Klaus Broelemann', 'Gjergji Kasneci']","['SCHUFA Holding AG, Germany', 'SCHUFA Holding AG, Germany', 'University of Tuebingen, Germany']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'GTEP: Cooperative Game Theory', 'ML: Classification and Regression', 'PEAI: Interpretability and Explainability']","Zern, A., Broelemann, K., & Kasneci, G. (2023). Interventional SHAP Values and Interaction Values for Piecewise Linear Regression Trees. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11164-11173. https://doi.org/10.1609/aaai.v37i9.26322","Abstract 					In recent years, game-theoretic Shapley values have gained increasing attention with respect to local model explanation by feature attributions. While the approach using Shapley values is model-independent, their (exact) computation is usually intractable, so efficient model-specific algorithms have been devised including approaches for decision trees or their ensembles in general. Our work goes further in this direction by extending the interventional TreeSHAP algorithm to piecewise linear regression trees, which gained more attention in the past few years. To this end, we introduce a decomposition of the contribution function based on decision paths, which allows a more comprehensible formulation of SHAP algorithms for tree-based models. Our algorithm can also be readily applied to computing SHAP interaction values of these models. In particular, as the main contribution of this paper, we provide a more efficient approach of interventional SHAP for tree-based models by precomputing statistics of the background data based on the tree structure.","https://ojs.aaai.org/index.php/AAAI/article/view/26322/26094"
"26323","Enhanced Tensor Low-Rank and Sparse Representation Recovery for Incomplete Multi-View Clustering","['Chao Zhang', 'Huaxiong Li', 'Wei Lv', 'Zizheng Huang', 'Yang Gao', 'Chunlin Chen']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University']","['ML: Multi-Instance/Multi-View Learning', 'ML: Clustering', 'ML: Graph-based Machine Learning', 'ML: Multimodal Learning', 'ML: Unsupervised & Self-Supervised Learning']","Zhang, C., Li, H., Lv, W., Huang, Z., Gao, Y., & Chen, C. (2023). Enhanced Tensor Low-Rank and Sparse Representation Recovery for Incomplete Multi-View Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11174-11182. https://doi.org/10.1609/aaai.v37i9.26323","Abstract 					Incomplete multi-view clustering (IMVC) has attracted remarkable attention due to the emergence of multi-view data with missing views in real applications. Recent methods attempt to recover the missing information to address the IMVC problem. However, they generally cannot fully explore the underlying properties and correlations of data similarities across views. This paper proposes a novel Enhanced Tensor Low-rank and Sparse Representation Recovery (ETLSRR) method, which reformulates the IMVC problem as a joint incomplete similarity graphs learning and complete tensor representation recovery problem. Specifically, ETLSRR learns the intra-view similarity graphs and constructs a 3-way tensor by stacking the graphs to explore the inter-view correlations. To alleviate the negative influence of missing views and data noise, ETLSRR decomposes the tensor into two parts: a sparse tensor and an intrinsic tensor, which models the noise and underlying true data similarities, respectively. Both global low-rank and local structured sparse characteristics of the intrinsic tensor are considered, which enhances the discrimination of similarity matrix. Moreover, instead of using the convex tensor nuclear norm, ETLSRR introduces a generalized non-convex tensor low-rank regularization to alleviate the biased approximation. Experiments on several datasets demonstrate the effectiveness of our method compared with the state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26323/26095"
"26324","Denoising Multi-Similarity Formulation: A Self-Paced Curriculum-Driven Approach for Robust Metric Learning","['Chenkang Zhang', 'Lei Luo', 'Bin Gu']","['Nanjing University of Information Science and Technology', 'Nanjing University of Science and Technology', 'Nanjing University of Information Science and Technology\nMBZUAI']","['ML: Representation Learning', 'ML: Deep Neural Network Algorithms']","Zhang, C., Luo, L., & Gu, B. (2023). Denoising Multi-Similarity Formulation: A Self-Paced Curriculum-Driven Approach for Robust Metric Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11183-11191. https://doi.org/10.1609/aaai.v37i9.26324","Abstract 					Deep Metric Learning (DML) is a group of techniques that aim to measure the similarity between objects through the neural network. Although the number of DML methods has rapidly increased in recent years,  most previous studies cannot effectively handle noisy data, which commonly exists in practical applications and often leads to serious performance deterioration. To overcome this limitation, in this paper, we build a connection between noisy samples and hard samples in the framework of self-paced learning, and propose a Balanced Self-Paced Metric Learning (BSPML) algorithm with a denoising multi-similarity formulation, where noisy samples are treated as extremely hard samples and adaptively excluded from the model training by  sample weighting. Especially, due to the pairwise relationship  and a new balance regularization term, the sub-problem  w.r.t.  sample weights is a  nonconvex  quadratic function.  To efficiently solve this nonconvex  quadratic problem, we propose a doubly stochastic projection coordinate gradient algorithm. Importantly, we  theoretically prove  the convergence  not only for the doubly stochastic projection coordinate gradient algorithm, but also for our BSPML algorithm. Experimental results on several standard  data sets demonstrate that our BSPML algorithm has   better generalization ability and robustness  than  the state-of-the-art   robust DML approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/26324/26096"
"26325","Rethinking Alignment and Uniformity in Unsupervised Image Semantic Segmentation","['Daoan Zhang', 'Chenming Li', 'Haoquan Li', 'Wenjian Huang', 'Lingyun Huang', 'Jianguo Zhang']","['Southern University of Science and Technology\nPing An Technology (Shenzhen) Co., Ltd.', 'Southern University of Science and Technology', 'Southern University of Science and Technology', 'Southern University of Science and Technology', 'Ping An Technology (Shenzhen) Co., Ltd.', 'Southern University of Science and Technology\nPeng Cheng Laboratory']","['ML: Unsupervised & Self-Supervised Learning', 'CV: Segmentation']","Zhang, D., Li, C., Li, H., Huang, W., Huang, L., & Zhang, J. (2023). Rethinking Alignment and Uniformity in Unsupervised Image Semantic Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11192-11200. https://doi.org/10.1609/aaai.v37i9.26325","Abstract 					Unsupervised image segmentation aims to match low-level visual features with semantic-level representations without outer supervision. In this paper, we address the critical properties from the view of feature alignments and feature uniformity for UISS models. We also make a comparison between UISS and image-wise representation learning. Based on the analysis, we argue that the existing MI-based methods in UISS suffer from representation collapse. By this, we proposed a robust network called Semantic Attention Network(SAN), in which a new module Semantic Attention(SEAT) is proposed to generate pixel-wise and semantic features dynamically. Experimental results on multiple semantic segmentation benchmarks show that our unsupervised segmentation framework specializes in catching semantic representations, which outperforms all the unpretrained and even several pretrained methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26325/26097"
"26326","Behavior Estimation from Multi-Source Data for Offline Reinforcement Learning","['Guoxi Zhang', 'Hisashi Kashima']","['Graduate School of Informatics, Kyoto University', 'Graduate School of Informatics, Kyoto University\nRIKEN Guardian Robot Project']","['ML: Reinforcement Learning Algorithms', 'ROB: Behavior Learning & Control', 'ROB: Learning & Optimization for ROB']","Zhang, G., & Kashima, H. (2023). Behavior Estimation from Multi-Source Data for Offline Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11201-11209. https://doi.org/10.1609/aaai.v37i9.26326","Abstract 					Offline reinforcement learning (RL) have received rising interest due to its appealing data efficiency. The present study addresses behavior estimation, a task that aims at estimating the data-generating policy. In particular, this work considers a scenario where data are collected from multiple sources. Neglecting data heterogeneity, existing approaches cannot provide good estimates and impede policy learning. To overcome this drawback, the present study proposes a latent variable model and a model-learning algorithm to infer a set of policies from data, which allows an agent to use as behavior policy the policy that best describes a particular trajectory. To illustrate the benefit of such a fine-grained characterization for multi-source data, this work showcases how the proposed model can be incorporated into an existing offline RL algorithm. Lastly, with extensive empirical evaluation this work confirms the risks of neglecting data heterogeneity and the efficacy of the proposed model.","https://ojs.aaai.org/index.php/AAAI/article/view/26326/26098"
"26327","DARL: Distance-Aware Uncertainty Estimation for Offline Reinforcement Learning","['Hongchang Zhang', 'Jianzhun Shao', 'Shuncheng He', 'Yuhang Jiang', 'Xiangyang Ji']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University']","['ML: Reinforcement Learning Algorithms']","Zhang, H., Shao, J., He, S., Jiang, Y., & Ji, X. (2023). DARL: Distance-Aware Uncertainty Estimation for Offline Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11210-11218. https://doi.org/10.1609/aaai.v37i9.26327","Abstract 					To facilitate offline reinforcement learning, uncertainty estimation is commonly used to detect out-of-distribution data. By inspecting, we show that current explicit uncertainty estimators such as Monte Carlo Dropout and model ensemble are not competent to provide trustworthy uncertainty estimation in offline reinforcement learning. Accordingly, we propose a non-parametric distance-aware uncertainty estimator which is sensitive to the change in the input space for offline reinforcement learning. Based on our new estimator, adaptive truncated quantile critics are proposed to underestimate the out-of-distribution samples. We show that the proposed distance-aware uncertainty estimator is able to offer better uncertainty estimation compared to previous methods. Experimental results demonstrate that our proposed DARL method is competitive to the state-of-the-art methods in offline evaluation tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26327/26099"
"26328","When Neural Networks Fail to Generalize? A Model Sensitivity Perspective","['Jiajin Zhang', 'Hanqing Chao', 'Amit Dhurandhar', 'Pin-Yu Chen', 'Ali Tajer', 'Yangyang Xu', 'Pingkun Yan']","['Rensselaer Polytechnic Institute', 'Rensselaer Polytechnic Institute', 'IBM Research', 'IBM Research', 'Rensselaer Polytechnic Institute', 'Rensselaer Polytechnic Institute', 'Rensselaer Polytechnic Institute']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'CV: Adversarial Attacks & Robustness', 'CV: Representation Learning for Vision', 'ML: Adversarial Learning & Robustness', 'ML: Classification and Regression', 'ML: Representation Learning']","Zhang, J., Chao, H., Dhurandhar, A., Chen, P.-Y., Tajer, A., Xu, Y., & Yan, P. (2023). When Neural Networks Fail to Generalize? A Model Sensitivity Perspective. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11219-11227. https://doi.org/10.1609/aaai.v37i9.26328","Abstract 					Domain generalization (DG) aims to train a model to perform well in unseen domains under different distributions. This paper considers a more realistic yet more challenging scenario, namely Single Domain Generalization (Single-DG), where only a single source domain is available for training. To tackle this challenge, we first try to understand when neural networks fail to generalize? We empirically ascertain a property of a model that correlates strongly with its generalization that we coin as ""model sensitivity"". Based on our analysis, we propose a novel strategy of Spectral Adversarial Data Augmentation (SADA) to generate augmented images targeted at the highly sensitive frequencies. Models trained with these hard-to-learn samples can effectively suppress the sensitivity in the frequency space, which leads to improved generalization performance. Extensive experiments on multiple public datasets demonstrate the superiority of our approach, which surpasses the state-of-the-art single-DG methods by up to 2.55%. The source code is available at https://github.com/DIAL-RPI/Spectral-Adversarial-Data-Augmentation.","https://ojs.aaai.org/index.php/AAAI/article/view/26328/26100"
"26329","Memorization Weights for Instance Reweighting in Adversarial Training","['Jianfu Zhang', 'Yan Hong', 'Qibin Zhao']","['RIKEN AIP', 'Shanghai Jiao Tong University', 'RIKEN AIP']","['ML: Adversarial Learning & Robustness']","Zhang, J., Hong, Y., & Zhao, Q. (2023). Memorization Weights for Instance Reweighting in Adversarial Training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11228-11236. https://doi.org/10.1609/aaai.v37i9.26329","Abstract 					Adversarial training is an effective way to defend deep neural networks (DNN) against adversarial examples. However, there are atypical samples that are rare and hard to learn, or even hurt DNNs' generalization performance on test data. In this paper, we propose a novel algorithm to reweight the training samples based on self-supervised techniques to mitigate the negative effects of the atypical samples.  Specifically, a memory bank is built to record the popular samples as prototypes and calculate the memorization weight for each sample, evaluating the ""typicalness"" of a sample. All the training samples are reweigthed based on the proposed memorization weights to reduce the negative effects of atypical samples. Experimental results show the proposed method is flexible to boost state-of-the-art adversarial training methods, improving both robustness and standard accuracy of DNNs.","https://ojs.aaai.org/index.php/AAAI/article/view/26329/26101"
"26330","FedALA: Adaptive Local Aggregation for Personalized Federated Learning","['Jianqing Zhang', 'Yang Hua', 'Hao Wang', 'Tao Song', 'Zhengui Xue', 'Ruhui Ma', 'Haibing Guan']","['Shanghai Jiao Tong University', ""Queen's University Belfast"", 'Louisiana State University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['ML: Distributed Machine Learning & Federated Learning']","Zhang, J., Hua, Y., Wang, H., Song, T., Xue, Z., Ma, R., & Guan, H. (2023). FedALA: Adaptive Local Aggregation for Personalized Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11237-11244. https://doi.org/10.1609/aaai.v37i9.26330","Abstract 					A key challenge in federated learning (FL) is the statistical heterogeneity that impairs the generalization of the global model on each client. To address this, we propose a  method Federated learning with Adaptive Local Aggregation (FedALA) by capturing the desired information in the global model for client models in personalized FL. The key component of FedALA is an Adaptive Local Aggregation (ALA)  module, which can adaptively aggregate the downloaded global model and local model towards the local objective on each client to initialize the local model before training in each iteration.  To evaluate the effectiveness of FedALA, we conduct extensive experiments with five benchmark datasets in computer vision and natural language processing domains. FedALA outperforms eleven state-of-the-art baselines by up to 3.27% in test accuracy.  Furthermore, we also apply ALA  module to other federated learning methods and achieve up to 24.19% improvement in test accuracy. Code is available at https://github.com/TsingZ0/FedALA.","https://ojs.aaai.org/index.php/AAAI/article/view/26330/26102"
"26331","Delving into the Adversarial Robustness of Federated Learning","['Jie Zhang', 'Bo Li', 'Chen Chen', 'Lingjuan Lyu', 'Shuang Wu', 'Shouhong Ding', 'Chao Wu']","['Zhejiang University', 'Youtu Lab, Tencent', 'Sony AI', 'Sony AI', 'Youtu Lab, Tencent', 'Youtu Lab, Tencent', 'Zhejiang University']","['ML: Distributed Machine Learning & Federated Learning']","Zhang, J., Li, B., Chen, C., Lyu, L., Wu, S., Ding, S., & Wu, C. (2023). Delving into the Adversarial Robustness of Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11245-11253. https://doi.org/10.1609/aaai.v37i9.26331","Abstract 					In Federated Learning (FL), models are as fragile as centrally trained models against adversarial examples. However, the adversarial robustness of federated learning remains largely unexplored. This paper casts light on the challenge of adversarial robustness of federated learning. To facilitate a better understanding of the adversarial vulnerability of the existing FL methods, we conduct comprehensive robustness evaluations on various attacks and adversarial training methods. Moreover, we reveal the negative impacts induced by directly adopting adversarial training in FL, which seriously hurts the test accuracy, especially in non-IID settings. In this work, we propose a novel algorithm called Decision Boundary based Federated Adversarial Training (DBFAT), which consists of two components (local re-weighting and global regularization) to improve both accuracy and robustness of FL systems. Extensive experiments on multiple datasets demonstrate that DBFAT consistently outperforms other baselines under both IID and non-IID settings.","https://ojs.aaai.org/index.php/AAAI/article/view/26331/26103"
"26332","DRGCN: Dynamic Evolving Initial Residual for Deep Graph Convolutional Networks","['Lei Zhang', 'Xiaodong Yan', 'Jianshan He', 'Ruopeng Li', 'Wei Chu']","['Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group']","['ML: Graph-based Machine Learning', 'ML: Deep Neural Network Algorithms', 'ML: Representation Learning', 'ML: Semi-Supervised Learning']","Zhang, L., Yan, X., He, J., Li, R., & Chu, W. (2023). DRGCN: Dynamic Evolving Initial Residual for Deep Graph Convolutional Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11254-11261. https://doi.org/10.1609/aaai.v37i9.26332","Abstract 					Graph convolutional networks (GCNs) have been proved to be very practical to handle various graph-related tasks. It has attracted considerable research interest to study deep GCNs, due to their potential superior performance compared with shallow ones. However, simply increasing network depth will, on the contrary, hurt the performance due to the over-smoothing problem. Adding residual connection is proved to be effective for learning deep convolutional neural networks (deep CNNs), it is not trivial when applied to deep GCNs. Recent works proposed an initial residual mechanism that did alleviate the over-smoothing problem in deep GCNs. However, according to our study, their algorithms are quite sensitive to different datasets. In their setting, the personalization (dynamic) and correlation (evolving) of how residual applies are ignored. To this end, we propose a novel model called Dynamic evolving initial Residual Graph Convolutional Network (DRGCN). Firstly, we use a dynamic block for each node to adaptively fetch information from the initial representation. Secondly, we use an evolving block to model the residual evolving pattern between layers. Our experimental results show that our model effectively relieves the problem of over-smoothing in deep GCNs and outperforms the state-of-the-art (SOTA) methods on various benchmark datasets. Moreover, we develop a mini-batch version of DRGCN which can be applied to large-scale data. Coupling with several fair training techniques, our model reaches new SOTA results on the large-scale ogbn-arxiv dataset of Open Graph Benchmark (OGB). Our reproducible code is available on GitHub.","https://ojs.aaai.org/index.php/AAAI/article/view/26332/26104"
"26333","Let the Data Choose: Flexible and Diverse Anchor Graph Fusion for Scalable Multi-View Clustering","['Pei Zhang', 'Siwei Wang', 'Liang Li', 'Changwang Zhang', 'Xinwang Liu', 'En Zhu', 'Zhe Liu', 'Lu Zhou', 'Lei Luo']","['National University of Defense Technology', 'National University of Defense Technology', 'National University of Defense Technology', 'Huawei Poisson Lab', 'National University of Defense Technology', 'National University of Defense Technology', 'Nanjing University of Aeronautics and Astronautics', 'Nanjing University of aeronautics and astronautics', 'National University of Defense Technology']","['ML: Multi-Instance/Multi-View Learning', 'ML: Clustering', 'ML: Graph-based Machine Learning']","Zhang, P., Wang, S., Li, L., Zhang, C., Liu, X., Zhu, E., Liu, Z., Zhou, L., & Luo, L. (2023). Let the Data Choose: Flexible and Diverse Anchor Graph Fusion for Scalable Multi-View Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11262-11269. https://doi.org/10.1609/aaai.v37i9.26333","Abstract 					In the past few years, numerous multi-view graph clustering algorithms have been proposed to enhance the clustering performance by exploring information from multiple views. Despite the superior performance, the high time and space expenditures limit their scalability. Accordingly, anchor graph learning has been introduced to alleviate the computational complexity. However, existing approaches can be further improved by the following considerations: (i) Existing anchor-based methods share the same number of anchors across views. This strategy violates the diversity and flexibility of multi-view data distribution. (ii) Searching for the optimal anchor number within hyper-parameters takes much extra tuning time, which makes existing methods impractical. (iii) How to flexibly fuse multi-view anchor graphs of diverse sizes has not been well explored in existing literature. To address the above issues, we propose a novel anchor-based method termed Flexible and Diverse Anchor Graph Fusion for Scalable Multi-view Clustering (FDAGF) in this paper. Instead of manually tuning optimal anchor with massive hyper-parameters, we propose to optimize the contribution weights of a group of pre-defined anchor numbers to avoid extra time expenditure among views. Most importantly, we propose a novel hybrid fusion strategy for multi-size anchor graphs with theoretical proof, which allows flexible and diverse anchor graph fusion. Then, an efficient linear optimization algorithm is proposed to solve the resultant problem. Comprehensive experimental results demonstrate the effectiveness and efficiency of our proposed framework. The source code is available at https://github.com/Jeaninezpp/FDAGF.","https://ojs.aaai.org/index.php/AAAI/article/view/26333/26105"
"26334","Optimal Sparse Regression Trees","['Rui Zhang', 'Rui Xin', 'Margo Seltzer', 'Cynthia Rudin']","['Duke University', 'Duke University', 'University of British Columbia', 'Duke University']","['ML: Transparent', 'Interpretable', 'Explainable ML', 'ML: Classification and Regression', 'ML: Optimization', 'ML: Clustering']","Zhang, R., Xin, R., Seltzer, M., & Rudin, C. (2023). Optimal Sparse Regression Trees. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11270-11279. https://doi.org/10.1609/aaai.v37i9.26334","Abstract 					Regression trees are one of the oldest forms of AI models, and their predictions can be made without a calculator, which makes them broadly useful, particularly for high-stakes applications. Within the large literature on regression trees, there has been little effort towards full provable optimization, mainly due to the computational hardness of the problem. This work proposes a dynamic programming-with-bounds approach to the construction of provably-optimal sparse regression trees. We leverage a novel lower bound based on an optimal solution to the k-Means clustering algorithm on one dimensional data. We are often able to find optimal sparse trees in seconds, even for challenging datasets that involve large numbers of samples and highly-correlated features.","https://ojs.aaai.org/index.php/AAAI/article/view/26334/26106"
"26335","High-Dimensional Dueling Optimization with Preference Embedding","['Yangwenhui Zhang', 'Hong Qian', 'Xiang Shu', 'Aimin Zhou']","['East China Normal University', 'East China Normal University', 'East China Normal University', 'East China Normal University']","['ML: Optimization', 'SO: Evolutionary Computation', 'SO: Other Foundations of Search & Optimization']","Zhang, Y., Qian, H., Shu, X., & Zhou, A. (2023). High-Dimensional Dueling Optimization with Preference Embedding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11280-11288. https://doi.org/10.1609/aaai.v37i9.26335","Abstract 					In many scenarios of black-box optimization, evaluating the objective function values of solutions is expensive, while comparing a pair of solutions is relatively cheap, which yields the dueling black-box optimization. The side effect of dueling optimization is that it doubles the dimension of solution space and exacerbates the dimensionality scalability issue of black-box optimization, e.g., Bayesian optimization. To address this issue, the existing dueling optimization methods fix one solution when dueling throughout the optimization process, but it may reduce their efficacy. Fortunately, it has been observed that, in recommendation systems, the dueling results are mainly determined by the latent human preferences. In this paper, we abstract this phenomenon as the preferential intrinsic dimension and inject it into the dueling Bayesian optimization, resulting in the preferential embedding dueling Bayesian optimization (PE-DBO). PE-DBO decouples optimization and pairwise comparison via the preferential embedding matrix. Optimization is performed in the preferential intrinsic subspace with much lower dimensionality, while pairwise comparison is completed in the original dueling solution space. Theoretically, we disclose that the preference function can be approximately preserved in the lower-dimensional preferential intrinsic subspace. Experiment results verify that, on molecule discovery and web page recommendation dueling optimization tasks, the preferential intrinsic dimension exists and PE-DBO is superior in scalability compared with that of the state-of-the-art (SOTA) methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26335/26107"
"26336","Spectral Feature Augmentation for Graph Contrastive Learning and Beyond","['Yifei Zhang', 'Hao Zhu', 'Zixing Song', 'Piotr Koniusz', 'Irwin King']","['The Chinese University of Hong Kong', 'Australian National University\nData61/CSIRO', 'The Chinese University of Hong Kong', 'Data61/CSIRO\nAustralian National University', 'The Chinese University of Hong Kong']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'ML: Representation Learning', 'ML: Semi-Supervised Learning', 'ML: Unsupervised & Self-Supervised Learning']","Zhang, Y., Zhu, H., Song, Z., Koniusz, P., & King, I. (2023). Spectral Feature Augmentation for Graph Contrastive Learning and Beyond. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11289-11297. https://doi.org/10.1609/aaai.v37i9.26336","Abstract 					Although  augmentations (e.g., perturbation of graph edges, image crops)  boost the efficiency of Contrastive Learning (CL), feature level augmentation is another plausible, complementary yet not well researched strategy. Thus, we present a novel spectral feature argumentation for contrastive learning on graphs (and images). To this end, for each data view, we estimate a low-rank approximation per feature map and  subtract that approximation from the map to obtain its complement. This is achieved by the proposed herein  incomplete power iteration, a non-standard power iteration regime which enjoys two valuable byproducts (under mere one or two iterations): (i) it partially balances spectrum of the feature map, and (ii) it injects the noise into rebalanced singular values of the feature map (spectral augmentation). For two views, we align these rebalanced feature maps as such an improved alignment step can focus more on less dominant singular values of matrices of both views, whereas the spectral augmentation does not affect the spectral angle alignment (singular vectors are not perturbed). We derive the analytical form for: (i) the incomplete power iteration to capture its spectrum-balancing effect, and (ii) the variance of singular values  augmented implicitly by the noise. We also show that the spectral augmentation improves the generalization bound. Experiments on graph/image datasets show that our spectral feature augmentation  outperforms baselines, and is complementary with other  augmentation strategies and compatible with various contrastive losses.","https://ojs.aaai.org/index.php/AAAI/article/view/26336/26108"
"26337","Scalable Bayesian Meta-Learning through Generalized Implicit Gradients","['Yilang Zhang', 'Bingcong Li', 'Shijian Gao', 'Georgios B. Giannakis']","['University of Minnesota', 'University of Minnesota', 'University of Minnesota', 'University of Minnesota']","['ML: Meta Learning', 'ML: Bayesian Learning', 'ML: Optimization']","Zhang, Y., Li, B., Gao, S., & Giannakis, G. B. (2023). Scalable Bayesian Meta-Learning through Generalized Implicit Gradients. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11298-11306. https://doi.org/10.1609/aaai.v37i9.26337","Abstract 					Meta-learning owns unique effectiveness and swiftness in tackling emerging tasks with limited data. Its broad applicability is revealed by viewing it as a bi-level optimization problem. The resultant algorithmic viewpoint however, faces scalability issues when the inner-level optimization relies on gradient-based iterations. Implicit differentiation has been considered to alleviate this challenge, but it is restricted to an isotropic Gaussian prior, and only favors deterministic meta-learning approaches. This work markedly mitigates the scalability bottleneck by cross-fertilizing the benefits of implicit differentiation to probabilistic Bayesian meta-learning. The novel implicit Bayesian meta-learning (iBaML) method not only broadens the scope of learnable priors, but also quantifies the associated uncertainty. Furthermore, the ultimate complexity is well controlled regardless of the inner-level optimization trajectory. Analytical error bounds are established to demonstrate the precision and efficiency of the generalized implicit gradient over the explicit one. Extensive numerical tests are also carried out to empirically validate the performance of the proposed method.","https://ojs.aaai.org/index.php/AAAI/article/view/26337/26109"
"26338","Dynamic Heterogeneous Graph Attention Neural Architecture Search","['Zeyang Zhang', 'Ziwei Zhang', 'Xin Wang', 'Yijian Qin', 'Zhou Qin', 'Wenwu Zhu']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Alibaba Group', 'Tsinghua University']","['ML: Graph-based Machine Learning', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'ML: Auto ML and Hyperparameter Tuning']","Zhang, Z., Zhang, Z., Wang, X., Qin, Y., Qin, Z., & Zhu, W. (2023). Dynamic Heterogeneous Graph Attention Neural Architecture Search. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11307-11315. https://doi.org/10.1609/aaai.v37i9.26338","Abstract 					Dynamic heterogeneous graph neural networks (DHGNNs) have been shown to be effective in handling the ubiquitous dynamic heterogeneous graphs. However, the existing DHGNNs are hand-designed, requiring extensive human efforts and failing to adapt to diverse dynamic heterogeneous graph scenarios. In this paper, we propose to automate the design of DHGNN, which faces two major challenges: 1) how to design the search space to jointly consider the spatial-temporal dependencies and heterogeneous interactions in graphs; 2) how to design an efficient search algorithm in the potentially large and complex search space. To tackle these challenges, we propose a novel Dynamic Heterogeneous Graph Attention Search (DHGAS) method. Our proposed method can automatically discover the optimal DHGNN architecture and adapt to various dynamic heterogeneous graph scenarios without human guidance. In particular, we first propose a unified dynamic heterogeneous graph attention (DHGA) framework, which enables each node to jointly attend its heterogeneous and dynamic neighbors. Based on the framework, we design a localization space to determine where the attention should be applied and a parameterization space to determine how the attention should be parameterized. Lastly, we design a multi-stage differentiable search algorithm to efficiently explore the search space. Extensive experiments on real-world dynamic heterogeneous graph datasets demonstrate that our proposed method significantly outperforms state-of-the-art baselines for tasks including link prediction, node classification and node regression. To the best of our knowledge, DHGAS is the first dynamic heterogeneous graph neural architecture search method.","https://ojs.aaai.org/index.php/AAAI/article/view/26338/26110"
"26339","Dynamic Ensemble of Low-Fidelity Experts: Mitigating NAS “Cold-Start”","['Junbo Zhao', 'Xuefei Ning', 'Enshu Liu', 'Binxin Ru', 'Zixuan Zhou', 'Tianchen Zhao', 'Chen Chen', 'Jiajin Zhang', 'Qingmin Liao', 'Yu Wang']","['Department of Electronic Engineering, Tsinghua University\nTsinghua Shenzhen International Graduate School', 'Department of Electronic Engineering, Tsinghua University', 'Department of Electronic Engineering, Tsinghua University', 'SailYond Technology & Research Institute of Tsinghua University in Shenzhen', 'Department of Electronic Engineering, Tsinghua University', 'Department of Electronic Engineering, Tsinghua University', 'Huawei Technologies Co., Ltd', 'Huawei Technologies Co., Ltd', 'Tsinghua Shenzhen International Graduate School', 'Department of Electronic Engineering, Tsinghua University']","['ML: Auto ML and Hyperparameter Tuning', 'ML: Deep Neural Architectures', 'ML: Deep Neural Network Algorithms', 'ML: Ensemble Methods']","Zhao, J., Ning, X., Liu, E., Ru, B., Zhou, Z., Zhao, T., Chen, C., Zhang, J., Liao, Q., & Wang, Y. (2023). Dynamic Ensemble of Low-Fidelity Experts: Mitigating NAS “Cold-Start”. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11316-11326. https://doi.org/10.1609/aaai.v37i9.26339","Abstract 					Predictor-based Neural Architecture Search (NAS) employs an architecture performance predictor to improve the sample efficiency. However, predictor-based NAS suffers from the severe ``cold-start'' problem, since a large amount of architecture-performance data is required to get a working predictor. In this paper, we focus on exploiting information in cheaper-to-obtain performance estimations (i.e., low-fidelity information) to mitigate the large data requirements of predictor training. Despite the intuitiveness of this idea, we observe that using inappropriate low-fidelity information even damages the prediction ability and different search spaces have different preferences for low-fidelity information types. To solve the problem and better fuse beneficial information provided by different types of low-fidelity information, we propose a novel dynamic ensemble predictor framework that comprises two steps. In the first step, we train different sub-predictors on different types of available low-fidelity information to extract beneficial knowledge as low-fidelity experts. In the second step, we learn a gating network to dynamically output a set of weighting coefficients conditioned on each input neural architecture, which will be used to combine the predictions of different low-fidelity experts in a weighted sum. The overall predictor is optimized on a small set of actual architecture-performance data to fuse the knowledge from different low-fidelity experts to make the final prediction. We conduct extensive experiments across five search spaces with different architecture encoders under various experimental settings. For example, our methods can improve the Kendall's Tau correlation coefficient between actual performance and predicted scores from 0.2549 to 0.7064 with only 25 actual architecture-performance data on NDS-ResNet. Our method can easily be incorporated into existing predictor-based NAS frameworks to discover better architectures. Our method will be implemented in Mindspore (Huawei 2020), and the example code is published at https://github.com/A-LinCui/DELE.","https://ojs.aaai.org/index.php/AAAI/article/view/26339/26111"
"26340","Tensorized Incomplete Multi-View Clustering with Intrinsic Graph Completion","['Shuping Zhao', 'Jie Wen', 'Lunke Fei', 'Bob Zhang']","['University of Macau', 'Harbin Institute of Technology, Shenzhen', 'Guangdong University of Technology', 'University of Macau']","['ML: Multi-Instance/Multi-View Learning', 'CV: Learning & Optimization for CV', 'ML: Clustering', 'ML: Optimization']","Zhao, S., Wen, J., Fei, L., & Zhang, B. (2023). Tensorized Incomplete Multi-View Clustering with Intrinsic Graph Completion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11327-11335. https://doi.org/10.1609/aaai.v37i9.26340","Abstract 					Most of the existing incomplete multi-view clustering (IMVC) methods focus on attaining a consensus representation from different views but ignore the important information hidden in the missing views and the latent intrinsic structures in each view. To tackle these issues, in this paper, a unified and novel framework, named tensorized incomplete multi-view clustering with intrinsic graph completion (TIMVC_IGC) is proposed. Firstly, owing to the effectiveness of the low-rank representation in revealing the inherent structure of the data, we exploit it to infer the missing instances and construct the complete graph for each view. Afterwards, inspired by the structural consistency, a between-view consistency constraint is imposed to guarantee the similarity of the graphs from different views. More importantly, the TIMVC_IGC simultaneously learns the low-rank structures of the different views and explores the correlations of the different graphs in a latent manifold sub-space using a low-rank tensor constraint, such that the intrinsic graphs of the different views can be obtained. Finally, a consensus representation for each sample is gained with a co-regularization term for final clustering.  Experimental results on several real-world databases illustrates that the proposed method can outperform the other state-of-the-art related methods for incomplete multi-view clustering.","https://ojs.aaai.org/index.php/AAAI/article/view/26340/26112"
"26341","Imbalanced Label Distribution Learning","['Xingyu Zhao', 'Yuexuan An', 'Ning Xu', 'Jing Wang', 'Xin Geng']","['School of Computer Science and Engineering, Southeast University, Nanjing 211189, China\nKey Laboratory of Computer Network and Information Integration (Ministry of Education), Southeast University, Nanjing 211189, China', 'School of Computer Science and Engineering, Southeast University, Nanjing 211189, China\nKey Laboratory of Computer Network and Information Integration (Ministry of Education), Southeast University, Nanjing 211189, China', 'School of Computer Science and Engineering, Southeast University, Nanjing 211189, China\nKey Laboratory of Computer Network and Information Integration (Ministry of Education), Southeast University, Nanjing 211189, China', 'School of Computer Science and Engineering, Southeast University, Nanjing 211189, China\nKey Laboratory of Computer Network and Information Integration (Ministry of Education), Southeast University, Nanjing 211189, China', 'School of Computer Science and Engineering, Southeast University, Nanjing 211189, China\nKey Laboratory of Computer Network and Information Integration (Ministry of Education), Southeast University, Nanjing 211189, China']","['ML: Multi-Class/Multi-Label Learning & Extreme Classification']","Zhao, X., An, Y., Xu, N., Wang, J., & Geng, X. (2023). Imbalanced Label Distribution Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11336-11344. https://doi.org/10.1609/aaai.v37i9.26341","Abstract 					Label distribution covers a certain number of labels, representing the degree to which each label describes an instance. The learning process on the instances labeled by label distributions is called Label Distribution Learning (LDL). Although LDL has been applied successfully to many practical applications, one problem with existing LDL methods is that they are limited to data with balanced label information. However, annotation information in real-world data often exhibits imbalanced distributions, which significantly degrades the performance of existing methods. In this paper, we investigate the Imbalanced Label Distribution Learning (ILDL) problem. To handle this challenging problem, we delve into the characteristics of ILDL and empirically find that the representation distribution shift is the underlying reason for the performance degradation of existing methods. Inspired by this finding, we present a novel method named Representation Distribution Alignment (RDA). RDA aligns the distributions of feature representations and label representations to alleviate the impact of the distribution gap between the training set and the test set caused by the imbalance issue. Extensive experiments verify the superior performance of RDA. Our work fills the gap in benchmarks and techniques for practical ILDL problems.","https://ojs.aaai.org/index.php/AAAI/article/view/26341/26113"
"26342","CoopInit: Initializing Generative Adversarial Networks via Cooperative Learning","['Yang Zhao', 'Jianwen Xie', 'Ping Li']","['Baidu Research', 'Baidu Research', 'Baidu Research']","['ML: Deep Generative Models & Autoencoders', 'CV: Computational Photography', 'Image & Video Synthesis']","Zhao, Y., Xie, J., & Li, P. (2023). CoopInit: Initializing Generative Adversarial Networks via Cooperative Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11345-11353. https://doi.org/10.1609/aaai.v37i9.26342","Abstract 					Numerous research efforts have been made to stabilize the training of the Generative Adversarial Networks (GANs), such as through regularization and architecture design. However, we identify the instability can also arise from the fragile balance at the early stage of adversarial learning. This paper proposes the CoopInit, a simple yet effective cooperative learning-based initialization strategy that can quickly learn a good starting point for GANs, with a very small computation overhead during training. The proposed algorithm consists of two learning stages: (i) Cooperative initialization stage: The discriminator of GAN is treated as an energy-based model (EBM) and is optimized via maximum likelihood estimation (MLE), with the help of the GAN's generator to provide synthetic data to approximate the learning gradients. The EBM also guides the MLE learning of the generator via MCMC teaching; (ii) Adversarial finalization stage: After a few iterations of initialization, the algorithm seamlessly transits to the regular mini-max adversarial training until convergence. The motivation is that the MLE-based initialization stage drives the model towards mode coverage, which is helpful in alleviating the issue of mode dropping during the adversarial learning stage. We demonstrate the effectiveness of the proposed approach on image generation and one-sided unpaired image-to-image translation tasks through extensive experiments.","https://ojs.aaai.org/index.php/AAAI/article/view/26342/26114"
"26343","AutoGraph: Optimizing DNN Computation Graph for Parallel GPU Kernel Execution","['Yuxuan Zhao', 'Qi Sun', 'Zhuolun He', 'Yang Bai', 'Bei Yu']","['The Chinese University of Hong Kong', 'The Chinese University of Hong Kong', 'The Chinese University of Hong Kong', 'The Chinese University of Hong Kong\nSmartMore', 'The Chinese University of Hong Kong']","['ML: Scalability of ML Systems', 'APP: Design']","Zhao, Y., Sun, Q., He, Z., Bai, Y., & Yu, B. (2023). AutoGraph: Optimizing DNN Computation Graph for Parallel GPU Kernel Execution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11354-11362. https://doi.org/10.1609/aaai.v37i9.26343","Abstract 					Deep learning frameworks optimize the computation graphs and intra-operator computations to boost the inference performance on GPUs,  while inter-operator parallelism is usually ignored.  In this paper, a unified framework, AutoGraph, is proposed to obtain highly optimized computation graphs in favor of parallel executions of GPU kernels.  A novel dynamic programming algorithm, combined with backtracking search, is adopted to explore the optimal graph optimization solution, with the fast performance estimation from the mixed critical path cost. Accurate runtime information based on GPU Multi-Stream launched with CUDA Graph is utilized to determine the convergence of the optimization. Experimental results demonstrate that our method achieves up to 3.47x speedup over existing graph optimization methods. Moreover, AutoGraph outperforms state-of-the-art parallel kernel launch frameworks by up to 1.26x.","https://ojs.aaai.org/index.php/AAAI/article/view/26343/26115"
"26344","Fairness and Explainability: Bridging the Gap towards Fair Model Explanations","['Yuying Zhao', 'Yu Wang', 'Tyler Derr']","['Vanderbilt University', 'Vanderbilt University', 'Vanderbilt University']","['ML: Bias and Fairness', 'ML: Transparent', 'Interpretable', 'Explainable ML', 'PEAI: Bias', 'Fairness & Equity', 'ML: Representation Learning', 'PEAI: Interpretability and Explainability', 'PEAI: Societal Impact of AI']","Zhao, Y., Wang, Y., & Derr, T. (2023). Fairness and Explainability: Bridging the Gap towards Fair Model Explanations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11363-11371. https://doi.org/10.1609/aaai.v37i9.26344","Abstract 					While machine learning models have achieved unprecedented success in real-world applications, they might make biased/unfair decisions for specific demographic groups and hence result in discriminative outcomes. Although research efforts have been devoted to measuring and mitigating bias, they mainly study bias from the result-oriented perspective while neglecting the bias encoded in the decision-making procedure. This results in their inability to capture procedure-oriented bias, which therefore limits the ability to have a fully debiasing method. Fortunately, with the rapid development of explainable machine learning, explanations for predictions are now available to gain insights into the procedure. In this work, we bridge the gap between fairness and explainability by presenting a novel perspective of procedure-oriented fairness based on explanations. We identify the procedure-based bias by measuring the gap of explanation quality between different groups with Ratio-based and Value-based Explanation Fairness.  The new metrics further motivate us to design an optimization objective to mitigate the procedure-based bias where we observe that it will also mitigate bias from the prediction. Based on our designed optimization objective, we propose a Comprehensive Fairness Algorithm (CFA), which simultaneously fulfills multiple objectives - improving traditional fairness, satisfying explanation fairness, and maintaining the utility performance. Extensive experiments on real-world datasets demonstrate the effectiveness of our proposed CFA and highlight the importance of considering fairness from the explainability perspective. Our code: https://github.com/YuyingZhao/FairExplanations-CFA.","https://ojs.aaai.org/index.php/AAAI/article/view/26344/26116"
"26345","Adaptive Policy Learning for Offline-to-Online Reinforcement Learning","['Han Zheng', 'Xufang Luo', 'Pengfei Wei', 'Xuan Song', 'Dongsheng Li', 'Jing Jiang']","['University of Technology Sydney', 'Microsoft Research Asia', 'National University of Singapore', 'Southern University of Science and Technology', 'Microsoft Research Asia', 'University of Technology Sydney']","['ML: Reinforcement Learning Algorithms']","Zheng, H., Luo, X., Wei, P., Song, X., Li, D., & Jiang, J. (2023). Adaptive Policy Learning for Offline-to-Online Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11372-11380. https://doi.org/10.1609/aaai.v37i9.26345","Abstract 					Conventional reinforcement learning (RL) needs an environment to collect fresh data, which is impractical when online interactions are costly. Offline RL provides an alternative solution by directly learning from the previously collected dataset. However, it will yield unsatisfactory performance if the quality of the offline datasets is poor. In this paper, we consider an offline-to-online setting where the agent is first learned from the offline dataset and then trained online, and propose a framework called Adaptive Policy Learning for effectively taking advantage of offline and online data. Specifically, we explicitly consider the difference between the online and offline data and apply an adaptive update scheme accordingly, that is, a pessimistic update strategy for the offline dataset and an optimistic/greedy update scheme for the online dataset. Such a simple and effective method provides a way to mix the offline and online RL and achieve the best of both worlds. We further provide two detailed algorithms for implementing the framework through embedding value or policy-based RL algorithms into it. Finally, we conduct extensive experiments on popular continuous control tasks, and results show that our algorithm can learn the expert policy with high sample efficiency even when the quality of offline dataset is poor, e.g., random dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/26345/26117"
"26346","Multi-Level Confidence Learning for Trustworthy Multimodal Classification","['Xiao Zheng', 'Chang Tang', 'Zhiguo Wan', 'Chengyu Hu', 'Wei Zhang']","['National University of Defense Technology', 'China University of Geosciences', 'Zhejiang Lab', 'China University of Geosciences', 'Shandong Computer Science Center (National Supercomputing\nCenter in Jinan)']","['ML: Clustering', 'APP: Bioinformatics', 'ML: Classification and Regression', 'ML: Dimensionality Reduction/Feature Selection', 'ML: Multi-Instance/Multi-View Learning', 'ML: Multimodal Learning']","Zheng, X., Tang, C., Wan, Z., Hu, C., & Zhang, W. (2023). Multi-Level Confidence Learning for Trustworthy Multimodal Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11381-11389. https://doi.org/10.1609/aaai.v37i9.26346","Abstract 					With the rapid development of various data acquisition technologies, more and more multimodal data come into being. It is important to integrate different modalities which are with high-dimensional features for boosting final multimodal data classification task. However, existing multimodal classification methods mainly focus on exploiting the complementary information of different modalities, while ignoring the learning confidence during information fusion. In this paper, we propose a trustworthy multimodal classification network via multi-level confidence learning, referred to as MLCLNet. Considering that a large number of feature dimensions could not contribute to final classification performance but disturb the discriminability of different samples, we propose a feature confidence learning mechanism to suppress some redundant features, as well as enhancing the expression of discriminative feature dimensions in each modality. In order to capture the inherent sample structure information implied in each modality, we design a graph convolutional network branch to learn the corresponding structure preserved feature representation and generate modal-specific initial classification labels. Since samples from different modalities should share consistent labels, a cross-modal label fusion module is deployed to capture the label correlations of different modalities. In addition, motivated the ideally orthogonality of final fused label matrix, we design a label confidence loss to supervise the network for learning more separable data representations. To the best of our knowledge, MLCLNet is the first work which integrates both feature and label-level confidence learning for multimodal classification. Extensive experiments on four multimodal medical datasets are conducted to validate superior performance of MLCLNet when compared to other state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26346/26118"
"26347","CowClip: Reducing CTR Prediction Model Training Time from 12 Hours to 10 Minutes on 1 GPU","['Zangwei Zheng', 'Pengtai Xu', 'Xuan Zou', 'Da Tang', 'Zhen Li', 'Chenguang Xi', 'Peng Wu', 'Leqi Zou', 'Yijie Zhu', 'Ming Chen', 'Xiangzhuo Ding', 'Fuzhao Xue', 'Ziheng Qin', 'Youlong Cheng', 'Yang You']","['National University of Singapore', 'National University of Singapore', 'ByteDance', 'ByteDance', 'ByteDance', 'ByteDance', 'ByteDance', 'ByteDance', 'ByteDance', 'ByteDance', 'ByteDance', 'National University of Singapore', 'National University of Singapore', 'ByteDance', 'National University of Singapore']","['ML: Applications', 'APP: Business/Marketing/Advertising/E-Commerce', 'ML: Optimization']","Zheng, Z., Xu, P., Zou, X., Tang, D., Li, Z., Xi, C., Wu, P., Zou, L., Zhu, Y., Chen, M., Ding, X., Xue, F., Qin, Z., Cheng, Y., & You, Y. (2023). CowClip: Reducing CTR Prediction Model Training Time from 12 Hours to 10 Minutes on 1 GPU. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11390-11398. https://doi.org/10.1609/aaai.v37i9.26347","Abstract 					The click-through rate (CTR) prediction task is to predict whether a user will click on the recommended item. As mind-boggling amounts of data are produced online daily, accelerating CTR prediction model training is critical to ensuring an up-to-date model and reducing the training cost. One approach to increase the training speed is to apply large batch training. However, as shown in computer vision and natural language processing tasks, training with a large batch easily suffers from the loss of accuracy. Our experiments show that previous scaling rules fail in the training of CTR prediction neural networks. To tackle this problem, we first theoretically show that different frequencies of ids make it challenging to scale hyperparameters when scaling the batch size. To stabilize the training process in a large batch size setting, we develop the adaptive Column-wise Clipping (CowClip). It enables an easy and effective scaling rule for the embeddings, which keeps the learning rate unchanged and scales the L2 loss. We conduct extensive experiments with four CTR prediction networks on two real-world datasets and successfully scaled 128 times the original batch size without accuracy loss. In particular, for CTR prediction model DeepFM training on the Criteo dataset, our optimization framework enlarges the batch size from 1K to 128K with over 0.1% AUC improvement and reduces training time from 12 hours to 10 minutes on a single V100 GPU. Our code locates at github.com/bytedance/LargeBatchCTR.","https://ojs.aaai.org/index.php/AAAI/article/view/26347/26119"
"26348","Data Imputation with Iterative Graph Reconstruction","['Jiajun Zhong', 'Ning Gui', 'Weiwei Ye']","['Central South University', 'Central South University', 'Central South University']","['ML: Graph-based Machine Learning', 'ML: Relational Learning', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning']","Zhong, J., Gui, N., & Ye, W. (2023). Data Imputation with Iterative Graph Reconstruction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11399-11407. https://doi.org/10.1609/aaai.v37i9.26348","Abstract 					Effective data imputation demands rich latent ``structure"" discovery capabilities from ``plain"" tabular data. Recent advances in graph neural networks-based data imputation solutions show their structure learning potentials by translating tabular data as bipartite graphs. However, due to a lack of relations between samples, they treat all samples equally which is against one important observation: ``similar sample should give more information about missing values.""  This paper presents a novel Iterative graph Generation and Reconstruction framework for Missing data imputation(IGRM). Instead of treating all samples equally, we introduce the concept: ``friend networks"" to represent different relations among samples. To generate an accurate friend network with missing data, an end-to-end friend network reconstruction solution is designed to allow for continuous friend network optimization during imputation learning. The representation of the optimized friend network, in turn, is used to further optimize the data imputation process with differentiated message passing. Experiment results on eight benchmark datasets show that IGRM yields 39.13% lower mean absolute error compared with nine baselines and 9.04% lower than the second-best. Our code is available at https://github.com/G-AILab/IGRM.","https://ojs.aaai.org/index.php/AAAI/article/view/26348/26120"
"26349","Does It Pay to Optimize AUC?","['Baojian Zhou', 'Steven Skiena']","['Fudan University', 'Stony Brook University']","['ML: Learning Preferences or Rankings', 'CSO: Mixed Discrete/Continuous Optimization', 'ML: Classification and Regression', 'ML: Optimization', 'SO: Evaluation and Analysis']","Zhou, B., & Skiena, S. (2023). Does It Pay to Optimize AUC?. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11408-11416. https://doi.org/10.1609/aaai.v37i9.26349","Abstract 					The Area Under the ROC Curve (AUC) is an important model metric for evaluating binary classifiers, and many algorithms have been proposed to optimize AUC approximately. It raises the question of whether the generally insignificant gains observed by previous studies are due to inherent limitations of the metric or the inadequate quality of optimization.  To better understand the value of optimizing for AUC, we present an efficient algorithm, namely AUC-opt, to find the provably optimal AUC linear classifier in R2, which runs in O(n+n- log n+n-) where n+ and n- are the number of positive and negative samples respectively. Furthermore, it can be naturally extended to Rd in O(n+n-d-1 log (n+n-)) by recursively calling AUC-opt in lower-dimensional spaces. We prove the problem is NP-complete when d is not fixed, reducing from the open hemisphere problem.  Compared with other methods, experiments show that AUC-opt achieves statistically significant improvements between 17 to 40 in R2 and 4 to 42 in R3 of 50 t-SNE training datasets. However, generally, the gain proves insignificant on most testing datasets compared to the best standard classifiers. Similar observations are found for nonlinear AUC methods under real-world datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26349/26121"
"26350","SLOTH: Structured Learning and Task-Based Optimization for Time Series Forecasting on Hierarchies","['Fan Zhou', 'Chen Pan', 'Lintao Ma', 'Yu Liu', 'Shiyu Wang', 'James Zhang', 'Xinxin Zhu', 'Xuanwei Hu', 'Yunhua Hu', 'Yangfei Zheng', 'Lei Lei', 'Hu Yun']","['Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group']","['ML: Time-Series/Data Streams', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data']","Zhou, F., Pan, C., Ma, L., Liu, Y., Wang, S., Zhang, J., Zhu, X., Hu, X., Hu, Y., Zheng, Y., Lei, L., & Yun, H. (2023). SLOTH: Structured Learning and Task-Based Optimization for Time Series Forecasting on Hierarchies. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11417-11425. https://doi.org/10.1609/aaai.v37i9.26350","Abstract 					Multivariate time series forecasting with hierarchical structure is widely used in real-world applications, e.g., sales predictions for the geographical hierarchy formed by cities, states, and countries. The hierarchical time series (HTS) forecasting includes two sub-tasks, i.e., forecasting and reconciliation. In the previous works, hierarchical information is only integrated in the reconciliation step to maintain coherency, but not in forecasting step for accuracy improvement. In this paper, we propose two novel tree-based feature integration mechanisms, i.e., top-down convolution and bottom-up attention to leverage the information of the hierarchical structure to improve the forecasting performance. Moreover, unlike most previous reconciliation methods which either rely on strong assumptions or focus on coherent constraints only, we utilize deep neural optimization networks, which not only achieve coherency without any assumptions, but also allow more flexible and realistic constraints to achieve task-based targets, e.g., lower under-estimation penalty and meaningful decision-making loss to facilitate the subsequent downstream tasks. Experiments on real-world datasets demonstrate that our tree-based feature integration mechanism achieves superior performances on hierarchical forecasting tasks compared to the state-of-the-art methods, and our neural optimization networks can be applied to real-world tasks effectively without any additional effort under coherence and task-based constraints.","https://ojs.aaai.org/index.php/AAAI/article/view/26350/26122"
"26351","Robust Temporal Smoothness in Multi-Task Learning","['Menghui Zhou', 'Yu Zhang', 'Yun Yang', 'Tong Liu', 'Po Yang']","['Department of Software, Yunnan University', 'Department of Computer Science, Sheffield University', 'Department of Software, Yunnan University', 'Department of Computer Science, Sheffield University', 'Department of Computer Science, Sheffield University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'DMKM: Data Stream Mining', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'ML: Optimization', 'ML: Transparent', 'Interpretable', 'Explainable ML']","Zhou, M., Zhang, Y., Yang, Y., Liu, T., & Yang, P. (2023). Robust Temporal Smoothness in Multi-Task Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11426-11434. https://doi.org/10.1609/aaai.v37i9.26351","Abstract 					Multi-task learning models based on temporal smoothness assumption, in which each time point of a sequence of time points concerns a task of prediction, assume the adjacent tasks are similar to each other. However, the effect of outliers is not taken into account.  In this paper, we show that even only one outlier task will destroy the performance of the entire model.  To solve this problem, we propose two Robust Temporal Smoothness (RoTS) frameworks. Compared with the existing models based on temporal relation, our methods not only chase the temporal smoothness information but identify outlier tasks, however, without increasing the computational complexity.  Detailed theoretical analyses are presented to evaluate the performance of our methods.  Experimental results on synthetic and real-life datasets demonstrate the effectiveness of our frameworks. We also discuss several potential specific applications and extensions of our RoTS frameworks.","https://ojs.aaai.org/index.php/AAAI/article/view/26351/26123"
"26352","Combining Adversaries with Anti-adversaries in Training","['Xiaoling Zhou', 'Nan Yang', 'Ou Wu']","['Tianjin University, Tianjin', 'Tianjin University, Tianjin', 'Tianjin University, Tianjin']","['ML: Adversarial Learning & Robustness', 'ML: Bias and Fairness', 'ML: Classification and Regression', 'ML: Deep Learning Theory', 'ML: Meta Learning']","Zhou, X., Yang, N., & Wu, O. (2023). Combining Adversaries with Anti-adversaries in Training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11435-11442. https://doi.org/10.1609/aaai.v37i9.26352","Abstract 					Adversarial training is an effective learning technique to improve the robustness of deep neural networks. In this study, the influence of adversarial training on deep learning models in terms of fairness, robustness, and generalization is theoretically investigated under more general perturbation scope that different samples can have different perturbation directions (the adversarial and anti-adversarial directions) and varied perturbation bounds. Our theoretical explorations suggest that the combination of adversaries and anti-adversaries (samples with anti-adversarial perturbations) in training can be more effective in achieving better fairness between classes and a better tradeoff between robustness and generalization in some typical learning scenarios (e.g., noisy label learning and imbalance learning) compared with standard adversarial training. On the basis of our theoretical findings, a more general learning objective that combines adversaries and anti-adversaries with varied bounds on each training sample is presented. Meta learning is utilized to optimize the combination weights. Experiments on benchmark datasets under different learning scenarios verify our theoretical findings and the effectiveness of the proposed methodology.","https://ojs.aaai.org/index.php/AAAI/article/view/26352/26124"
"26353","Gradient-Adaptive Pareto Optimization for Constrained Reinforcement Learning","['Zixian Zhou', 'Mengda Huang', 'Feiyang Pan', 'Jia He', 'Xiang Ao', 'Dandan Tu', 'Qing He']","['Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS\nUniversity of Chinese Academy of Sciences', 'Institute of Computing Technology, Chinese Academy of Science', 'Huawei EI Innovation Lab', 'Huawei EI Innovation Lab', 'Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS\nUniversity of Chinese Academy of Sciences\nInstitute of Intelligent Computing Technology, Suzhou, CAS', 'Huawei EI Innovation Lab', 'Key Lab of Intelligent Information Processing of Chinese Academy of Sciences (CAS), Institute of Computing Technology, CAS\nUniversity of Chinese Academy of Sciences']","['ML: Reinforcement Learning Algorithms', 'ML: Applications', 'ML: Deep Learning Theory', 'ML: Optimization', 'ML: Reinforcement Learning Theory']","Zhou, Z., Huang, M., Pan, F., He, J., Ao, X., Tu, D., & He, Q. (2023). Gradient-Adaptive Pareto Optimization for Constrained Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11443-11451. https://doi.org/10.1609/aaai.v37i9.26353","Abstract 					Constrained Reinforcement Learning (CRL) burgeons broad interest in recent years, which pursues maximizing long-term returns while constraining costs. Although CRL can be cast as a multi-objective optimization problem, it is still facing the key challenge that gradient-based Pareto optimization methods tend to stick to known Pareto-optimal solutions even when they yield poor returns (e.g., the safest self-driving car that never moves) or violate the constraints (e.g., the record-breaking racer that crashes the car). In this paper, we propose Gradient-adaptive Constrained Policy Optimization (GCPO for short), a novel Pareto optimization method for CRL with two adaptive gradient recalibration techniques. First, to find Pareto-optimal solutions with balanced performance over all targets, we propose gradient rebalancing which forces the agent to improve more on under-optimized objectives at every policy iteration. Second, to guarantee that the cost constraints are satisfied, we propose gradient perturbation that can temporarily sacrifice the returns for costs. Experiments on the SafetyGym benchmarks show that our method consistently outperforms previous CRL methods in reward while satisfying the constraints.","https://ojs.aaai.org/index.php/AAAI/article/view/26353/26125"
"26354","Quantized Feature Distillation for Network Quantization","['Ke Zhu', 'Yin-Yin He', 'Jianxin Wu']","['Nanjing University', 'Nanjing University', 'Nanjing University']","['ML: Learning on the Edge & Model Compression', 'CV: Object Detection & Categorization']","Zhu, K., He, Y.-Y., & Wu, J. (2023). Quantized Feature Distillation for Network Quantization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11452-11460. https://doi.org/10.1609/aaai.v37i9.26354","Abstract 					Neural network quantization aims to accelerate and trim full-precision neural network models by using low bit approximations. Methods adopting the quantization aware training (QAT) paradigm have recently seen a rapid growth, but are often conceptually complicated. This paper proposes a novel and highly effective QAT method, quantized feature distillation (QFD). QFD first trains a quantized (or binarized) representation as the teacher, then quantize the network using knowledge distillation (KD). Quantitative results show that QFD is more flexible and effective (i.e., quantization friendly) than previous quantization methods. QFD surpasses existing methods by a noticeable margin on not only image classification but also object detection, albeit being much simpler. Furthermore, QFD quantizes ViT and Swin-Transformer on MS-COCO detection and segmentation, which verifies its potential in real world deployment. To the best of our knowledge, this is the first time that vision transformers have been quantized in object detection and image segmentation tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26354/26126"
"26355","Bayesian Cross-Modal Alignment Learning for Few-Shot Out-of-Distribution Generalization","['Lin Zhu', 'Xinbing Wang', 'Chenghu Zhou', 'Nanyang Ye']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'CV: Applications', 'CV: Language and Vision', 'CV: Multi-modal Vision', 'CV: Representation Learning for Vision', 'ML: Applications', 'ML: Deep Neural Network Algorithms', 'ML: Meta Learning', 'ML: Multimodal Learning', 'ML: Other Foundations of Machine Learning', 'ML: Representation Learning']","Zhu, L., Wang, X., Zhou, C., & Ye, N. (2023). Bayesian Cross-Modal Alignment Learning for Few-Shot Out-of-Distribution Generalization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11461-11469. https://doi.org/10.1609/aaai.v37i9.26355","Abstract 					Recent advances in large pre-trained models showed promising results in few-shot learning. However, their generalization ability on two-dimensional Out-of-Distribution (OoD) data, i.e., correlation shift and diversity shift, has not been thoroughly investigated. Researches have shown that even with a significant amount of training data, few methods can achieve better performance than the standard empirical risk minimization method (ERM) in OoD generalization. This few-shot OoD generalization dilemma emerges as a challenging direction in deep neural network generalization research, where the performance suffers from overfitting on few-shot examples and OoD generalization errors. In this paper, leveraging a broader supervision source, we explore a novel Bayesian cross-modal image-text alignment learning method (Bayes-CAL) to address this issue. Specifically, the model is designed as only text representations are fine-tuned via a Bayesian modelling approach with gradient orthogonalization loss and invariant risk minimization (IRM) loss. The Bayesian approach is essentially introduced to avoid overfitting the base classes observed during training and improve generalization to broader unseen classes. The dedicated loss is introduced to achieve better image-text alignment by disentangling the causal and non-casual parts of image features. Numerical experiments demonstrate that Bayes-CAL achieved state-of-the-art OoD generalization performances on two-dimensional distribution shifts. Moreover, compared with CLIP-like models, Bayes-CAL yields more stable generalization performances on unseen classes. Our code is available at https://github.com/LinLLLL/BayesCAL.","https://ojs.aaai.org/index.php/AAAI/article/view/26355/26127"
"26356","ContraFeat: Contrasting Deep Features for Semantic Discovery","['Xinqi Zhu', 'Chang Xu', 'Dacheng Tao']","['University of Sydney', 'University of Sydney', 'University of Sydney']","['ML: Deep Generative Models & Autoencoders', 'CV: Representation Learning for Vision', 'ML: Representation Learning', 'ML: Unsupervised & Self-Supervised Learning']","Zhu, X., Xu, C., & Tao, D. (2023). ContraFeat: Contrasting Deep Features for Semantic Discovery. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11470-11478. https://doi.org/10.1609/aaai.v37i9.26356","Abstract 					StyleGAN has shown strong potential for disentangled semantic control, thanks to its special design of multi-layer intermediate latent variables. However, existing semantic discovery methods on StyleGAN rely on manual selection of modified latent layers to obtain satisfactory manipulation results, which is tedious and demanding. In this paper, we propose a model that automates this process and achieves state-of-the-art semantic discovery performance. The model consists of an attention-equipped navigator module and losses contrasting deep-feature changes. We propose two model variants, with one contrasting samples in a binary manner, and another one contrasting samples with learned prototype variation patterns. The proposed losses are computed with pretrained deep features, based on our assumption that the features implicitly possess the desired semantic variation structure including consistency and orthogonality. Additionally, we design two metrics to quantitatively evaluate the performance of semantic discovery methods on FFHQ dataset, and also show that disentangled representations can be derived via a simple training process. Experimentally, we show that our models achieve state-of-the-art semantic discovery results without relying on layer-wise manual selection, and these discovered semantics can be used to manipulate real-world images.","https://ojs.aaai.org/index.php/AAAI/article/view/26356/26128"
"26357","Locate Then Generate: Bridging Vision and Language with Bounding Box for Scene-Text VQA","['Yongxin Zhu', 'Zhen Liu', 'Yukang Liang', 'Xin Li', 'Hao Liu', 'Changcun Bao', 'Linli Xu']","['University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'Tencent', 'Tencent', 'Tencent', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence']","['ML: Multimodal Learning', 'CV: Applications', 'CV: Language and Vision', 'CV: Multi-modal Vision', 'CV: Object Detection & Categorization', 'CV: Scene Analysis & Understanding', 'SNLP: Applications', 'SNLP: Generation', 'SNLP: Language Grounding', 'SNLP: Question Answering']","Zhu, Y., Liu, Z., Liang, Y., Li, X., Liu, H., Bao, C., & Xu, L. (2023). Locate Then Generate: Bridging Vision and Language with Bounding Box for Scene-Text VQA. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11479-11487. https://doi.org/10.1609/aaai.v37i9.26357","Abstract 					In this paper, we propose a novel multi-modal framework for Scene Text Visual Question Answering (STVQA), which requires models to read scene text in images for question answering. Apart from text or visual objects, which could exist independently, scene text naturally links text and visual modalities together by conveying linguistic semantics while being a visual object in an image simultaneously. Different to conventional STVQA models which take the linguistic semantics and visual semantics in scene text as two separate features, in this paper, we propose a paradigm of ""Locate Then Generate"" (LTG), which explicitly unifies this two semantics with the spatial bounding box as a bridge connecting them. Specifically, at first, LTG locates the region in an image that may contain the answer words with an answer location module (ALM) consisting of a region proposal network and a language refinement network, both of which can transform to each other with one-to-one mapping via the scene text bounding box. Next, given the answer words selected by ALM, LTG generates a readable answer sequence with an answer generation module (AGM) based on a pre-trained language model. As a benefit of the explicit alignment of the visual and linguistic semantics, even without any scene text based pre-training tasks, LTG can boost the absolute accuracy by +6.06% and +6.92% on the TextVQA dataset and the ST-VQA dataset respectively, compared with a non-pre-training baseline. We further demonstrate that LTG effectively unifies visual and text modalities through the spatial bounding box connection, which is underappreciated in previous methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26357/26129"
"26358","ILSGAN: Independent Layer Synthesis for Unsupervised Foreground-Background Segmentation","['Qiran Zou', 'Yu Yang', 'Wing Yin Cheung', 'Chang Liu', 'Xiangyang Ji']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University']","['ML: Unsupervised & Self-Supervised Learning', 'CV: Segmentation']","Zou, Q., Yang, Y., Cheung, W. Y., Liu, C., & Ji, X. (2023). ILSGAN: Independent Layer Synthesis for Unsupervised Foreground-Background Segmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11488-11496. https://doi.org/10.1609/aaai.v37i9.26358","Abstract 					Unsupervised foreground-background segmentation aims at extracting salient objects from cluttered backgrounds, where Generative Adversarial Network (GAN) approaches, especially layered GANs, show great promise. However, without human annotations, they are typically prone to produce foreground and background layers with non-negligible semantic and visual confusion, dubbed ""information leakage"", resulting in notable degeneration of the generated segmentation mask. To alleviate this issue, we propose a simple-yet-effective explicit layer independence modeling approach, termed Independent Layer Synthesis GAN (ILSGAN), pursuing independent foreground-background layer generation by encouraging their discrepancy. Specifically, it targets minimizing the mutual information between visible and invisible regions of the foreground and background to spur interlayer independence. Through in-depth theoretical and experimental analyses, we justify that explicit layer independence modeling is critical to suppressing information leakage and contributes to impressive segmentation performance gains. Also, our ILSGAN achieves strong state-of-the-art generation quality and segmentation performance on complex real-world data.","https://ojs.aaai.org/index.php/AAAI/article/view/26358/26130"
"26359","SVP-T: A Shape-Level Variable-Position Transformer for Multivariate Time Series Classification","['Rundong Zuo', 'Guozhong Li', 'Byron Choi', 'Sourav S Bhowmick', 'Daphne Ngar-yin Mah', 'Grace L.H. Wong']","['Hong Kong Baptist University', 'Hong Kong Baptist University', 'Hong Kong Baptist University', 'Nanyang Technological University', 'Hong Kong Baptist University', 'Department of Medicine and Therapeutics, The Chinese University of Hong Kong']","['ML: Time-Series/Data Streams', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data']","Zuo, R., Li, G., Choi, B., S Bhowmick, S., Mah, D. N.- yin, & Wong, G. L. (2023). SVP-T: A Shape-Level Variable-Position Transformer for Multivariate Time Series Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11497-11505. https://doi.org/10.1609/aaai.v37i9.26359","Abstract 					Multivariate time series classiﬁcation (MTSC), one of the most fundamental time series applications, has not only gained substantial research attentions but has also emerged in many real-life applications. Recently, using transformers to solve MTSC has been reported. However, current transformer-based methods take data points of individual timestamps as inputs (timestamp-level), which only capture the temporal dependencies, not the dependencies among variables. In this paper, we propose a novel method, called SVP-T. Specifically, we ﬁrst propose to take time series subsequences, which can be from different variables and positions (time interval), as the inputs (shape-level). The temporal and variable dependencies are both handled by capturing the long- and short-term dependencies among shapes. Second, we propose a variable-position encoding layer (VP-layer) to utilize both the variable and position information of each shape. Third, we introduce a novel VP-based (Variable-Position) self-attention mechanism to allow the enhancing the attention weights of overlapping shapes. We evaluate our method on all UEA MTS datasets. SVP-T achieves the best accuracy rank when compared with several competitive state-of-the-art methods. Furthermore, we demonstrate the effectiveness of the VP-layer and the VP-based self-attention mechanism. Finally, we present one case study to interpret the result of SVP-T.","https://ojs.aaai.org/index.php/AAAI/article/view/26359/26131"
"26360","Mixed-Variable Black-Box Optimisation Using Value Proposal Trees","['Yan Zuo', 'Vu Nguyen', 'Amir Dezfouli', 'David Alexander', 'Benjamin Ward Muir', 'Iadine Chades']","['Amazon', 'Amazon', 'CSIRO', 'CSIRO', 'CSIRO', 'CSIRO']","['ML: Auto ML and Hyperparameter Tuning', 'ML: Probabilistic Methods']","Zuo, Y., Nguyen, V., Dezfouli, A., Alexander, D., Muir, B. W., & Chades, I. (2023). Mixed-Variable Black-Box Optimisation Using Value Proposal Trees. Proceedings of the AAAI Conference on Artificial Intelligence, 37(9), 11506-11514. https://doi.org/10.1609/aaai.v37i9.26360","Abstract 					Many real-world optimisation problems are defined over both categorical and continuous variables, yet efficient optimisation methods such as Bayesian Optimisation (BO) are ill-equipped to handle such mixed-variable search spaces. The optimisation breadth introduced by categorical variables in the mixed-input setting has seen recent approaches operating on local trust regions, but these methods can be greedy in suboptimal regions of the search space. In this paper, we adopt a holistic view and aim to consolidate optimisation of the categorical and continuous sub-spaces under a single acquisition metric. We develop a tree-based method which retains a global view of the optimisation spaces by identifying regions in the search space with high potential candidates which we call value proposals. Our method uses these proposals to make selections on both the categorical and continuous components of the input. We show that this approach significantly outperforms existing mixed-variable optimisation approaches across several mixed-variable black-box optimisation tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26360/26132"
"26361","Synchronization and Diversity of Solutions","['Emmanuel Arrighi', 'Henning Fernau', 'Mateus de Oliveira Oliveira', 'Petra Wolf']","['University of Bergen', 'University of Trier', 'University of Bergen\nStockholm University', 'University of Bergen\nUniversity of Trier']","['MAS: Coordination and Collaboration', 'MAS: Multiagent Planning']","Arrighi, E., Fernau, H., de Oliveira Oliveira, M., & Wolf, P. (2023). Synchronization and Diversity of Solutions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11516-11524. https://doi.org/10.1609/aaai.v37i10.26361","Abstract 					A central computational problem in the realm of automata theory is the problem of determining whether a finite automaton A has a synchronizing word. This problem has found applications in a variety of subfields of artificial intelligence, including planning, robotics, and multi-agent systems. In this work, we study this problem within the framework of diversity of solutions, an up-and-coming trend in the field of artificial intelligence where the goal is to compute a set of solutions that are sufficiently distinct from one another. We define a notion of diversity of solutions that is suitable for contexts were solutions are strings that may have distinct lengths. Using our notion of diversity, we show that for each fixed r ∈ N, each fixed finite automaton A, and each finite automaton B given at the input, the problem of determining the existence of a diverse set {w1,w2, . . . ,wr} ⊆ L(B) of words that are synchronizing for A can be solved in polynomial time. Finally, we generalize this result to the realm of conformant planning, where the goal is to devise plans that achieve a goal irrespectively of initial conditions and of nondeterminism that may occur during their execution.","https://ojs.aaai.org/index.php/AAAI/article/view/26361/26133"
"26362","The Multi-Agent Transportation Problem","['Pascal Bachor', 'Rolf-David Bergdoll', 'Bernhard Nebel']","['University of Freiburg', 'University of Freiburg', 'University of Freiburg']","['MAS: Multiagent Planning', 'ROB: Motion and Path Planning', 'PRS: Optimization of Spatio-Temporal Systems', 'PRS: Routing']","Bachor, P., Bergdoll, R.-D., & Nebel, B. (2023). The Multi-Agent Transportation Problem. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11525-11532. https://doi.org/10.1609/aaai.v37i10.26362","Abstract 					We introduce the multi-agent transportation (MAT) problem, where agents have to transport containers from their starting positions to their designated goal positions. Movement takes place in a common environment where collisions between agents and between containers must be avoided. In contrast to other frameworks such as multi-agent pathfinding (MAPF) or multi-agent pickup and delivery (MAPD), the agents are allowed to separate from the containers at any time, which can reduce the makespan and also allows for plans in scenarios that are unsolvable otherwise. We present a complexity analysis establishing the problem's NP-completeness and show how the problem can be reduced to a sequence of SAT problems when optimizing for makespan. A MAT solver is empirically evaluated with regard to varying input characteristics and movement constraints and compared to a MAPD solver that utilizes conflict-based search (CBS).","https://ojs.aaai.org/index.php/AAAI/article/view/26362/26134"
"26363","Emergent Quantized Communication","['Boaz Carmeli', 'Ron Meir', 'Yonatan Belinkov']","['Technion – Israel Institute of Technology', 'Technion – Israel Institute of Technology', 'Technion – Israel Institute of Technology']","['MAS: Agent Communication', 'ML: Applications', 'ML: Deep Neural Architectures', 'ML: Representation Learning', 'MAS: Agent-Based Simulation and Emergent Behavior', 'MAS: Coordination and Collaboration', 'MAS: Distributed Problem Solving']","Carmeli, B., Meir, R., & Belinkov, Y. (2023). Emergent Quantized Communication. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11533-11541. https://doi.org/10.1609/aaai.v37i10.26363","Abstract 					The field of emergent communication aims to understand the characteristics of communication as it emerges from artificial agents solving tasks that require information exchange. Communication with discrete messages is considered a desired characteristic, for scientific and applied reasons. However,  training a multi-agent system with discrete communication is not straightforward, requiring either reinforcement learning algorithms or relaxing the discreteness requirement via a continuous approximation such as the Gumbel-softmax. Both these solutions result in poor performance compared to fully continuous communication. In this work, we propose an alternative approach to achieve discrete communication -- quantization of communicated message. Using message quantization allows us to train the model end-to-end, achieving superior performance in multiple setups. Moreover, quantization is a natural framework that runs the gamut from continuous to discrete communication. Thus,  it sets the ground for a broader view of multi-agent communication in the deep learning era.","https://ojs.aaai.org/index.php/AAAI/article/view/26363/26135"
"26364","Learning Explicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning via Polarization Policy Gradient","['Wubing Chen', 'Wenbin Li', 'Xiao Liu', 'Shangdong Yang', 'Yang Gao']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University of Posts and Telecommunications\nNanjing University', 'Nanjing University']","['MAS: Multiagent Learning', 'MAS: Coordination and Collaboration', 'ML: Reinforcement Learning Algorithms', 'GTEP: Cooperative Game Theory']","Chen, W., Li, W., Liu, X., Yang, S., & Gao, Y. (2023). Learning Explicit Credit Assignment for Cooperative Multi-Agent Reinforcement Learning via Polarization Policy Gradient. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11542-11550. https://doi.org/10.1609/aaai.v37i10.26364","Abstract 					Cooperative multi-agent policy gradient (MAPG) algorithms have recently attracted wide attention and are regarded as a general scheme for the multi-agent system. Credit assignment plays an important role in MAPG and can induce cooperation among multiple agents. However, most MAPG algorithms cannot achieve good credit assignment because of the game-theoretic pathology known as centralized-decentralized mismatch. To address this issue, this paper presents a novel method, Multi-Agent Polarization Policy Gradient (MAPPG). MAPPG takes a simple but efficient polarization function to transform the optimal consistency of joint and individual actions into easily realized constraints, thus enabling efficient credit assignment in MAPPG. Theoretically, we prove that individual policies of MAPPG can converge to the global optimum. Empirically, we evaluate MAPPG on the well-known matrix game and differential game, and verify that MAPPG can converge to the global optimum for both discrete and continuous action spaces. We also evaluate MAPPG on a set of StarCraft II micromanagement tasks and demonstrate that MAPPG outperforms the state-of-the-art MAPG algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26364/26136"
"26365","Zero-Shot Assistance in Sequential Decision Problems","['Sebastiaan De Peuter', 'Samuel Kaski']","['Aalto University', 'Aalto University\nUniversity of Manchester']","['MAS: Multiagent Learning', 'ML: Imitation Learning & Inverse Reinforcement Learning', 'HAI: Human-in-the-Loop Machine Learning', 'ML: Bayesian Learning']","De Peuter, S., & Kaski, S. (2023). Zero-Shot Assistance in Sequential Decision Problems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11551-11559. https://doi.org/10.1609/aaai.v37i10.26365","Abstract 					We consider the problem of creating assistants that can help agents solve new sequential decision problems, assuming the agent is not able to specify the reward function explicitly to the assistant. Instead of acting in place of the agent as in current automation-based approaches, we give the assistant an advisory role and keep the agent in the loop as the main decision maker. The difficulty is that we must account for potential biases of the agent which may cause it to seemingly irrationally reject advice. To do this we introduce a novel formalization of assistance that models these biases, allowing the assistant to infer and adapt to them. We then introduce a new method for planning the assistant's actions which can scale to large decision making problems. We show experimentally that our approach adapts to these agent biases, and results in higher cumulative reward for the agent than automation-based alternatives. Lastly, we show that an approach combining advice and automation outperforms advice alone at the cost of losing some safety guarantees.","https://ojs.aaai.org/index.php/AAAI/article/view/26365/26137"
"26366","Multi-Unit Auctions for Allocating Chance-Constrained Resources","['Anna Gautier', 'Bruno Lacerda', 'Nick Hawes', 'Michael Wooldridge']","['University of Oxford\nOxford Robotics Institute', 'University of Oxford\nOxford Robotics Institute', 'University of Oxford\nOxford Robotics Institute', 'University of Oxford']","['MAS: Multiagent Planning', 'MAS: Multiagent Systems Under Uncertainty', 'GTEP: Auctions and Market-Based Systems', 'PRS: Planning Under Uncertainty', 'PRS: Planning With Markov Models (MDPs', 'POMDPs)']","Gautier, A., Lacerda, B., Hawes, N., & Wooldridge, M. (2023). Multi-Unit Auctions for Allocating Chance-Constrained Resources. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11560-11568. https://doi.org/10.1609/aaai.v37i10.26366","Abstract 					Sharing scarce resources is a key challenge in multi-agent interaction, especially when individual agents are uncertain about their future consumption.  We present a new auction mechanism for preallocating multi-unit resources among agents, while limiting the chance of resource violations. By planning for a chance constraint, we strike a balance between worst-case approaches, which under-utilise resources, and expected-case approaches, which lack formal guarantees. We also present an algorithm that allows agents to generate bids via multi-objective reasoning, which are then submitted to the auction. We then discuss how the auction can be extended to non-cooperative scenarios. Finally, we demonstrate empirically that our auction outperforms state-of-the-art  techniques for chance-constrained multi-agent resource allocation in complex settings with up to hundreds of agents.","https://ojs.aaai.org/index.php/AAAI/article/view/26366/26138"
"26367","Reward-Based Negotiating Agent Strategies","['Ryota Higa', 'Katsuhide Fujita', 'Toki Takahashi', 'Takumu Shimizu', 'Shinji Nakadai']","['NEC Corporation, Japan\nNational Institute of Advanced Industrial Science and Technology(AIST), Japan', 'Tokyo University of Agriculture and Technology, Japan\nNational Institute of Advanced Industrial Science and Technology(AIST), Japan', 'Tokyo University of Agriculture and Technology, Japan\nNational Institute of Advanced Industrial Science and Technology(AIST), Japan', 'Tokyo University of Agriculture and Technology, Japan\nNational Institute of Advanced Industrial Science and Technology(AIST), Japan', 'NEC Corporation, Japan\nNational Institute of Advanced Industrial Science and Technology(AIST), Japan']","['MAS: Agreement', 'Argumentation & Negotiation', 'GTEP: Negotiation and Contract-Based Systems', 'ML: Applications', 'ML: Reinforcement Learning Algorithms', 'MAS: Agent/AI Theories and Architectures', 'MAS: Coordination and Collaboration']","Higa, R., Fujita, K., Takahashi, T., Shimizu, T., & Nakadai, S. (2023). Reward-Based Negotiating Agent Strategies. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11569-11577. https://doi.org/10.1609/aaai.v37i10.26367","Abstract 					This study proposed a novel reward-based negotiating agent strategy using an issue-based represented deep policy network. We compared the negotiation strategies with reinforcement learning (RL) by the tournaments toward heuristics-based champion agents in multi-issue negotiation. A bilateral multi-issue negotiation in which the two agents exchange offers in turn was considered. Existing RL architectures for a negotiation strategy incorporate rich utility function that provides concrete information even though the rewards of RL are considered as generalized signals in practice. Additionally, in existing reinforcement learning architectures for negotiation strategies, both the issue-based representations of the negotiation problems and the policy network to improve the scalability of negotiation domains are yet to be considered. This study proposed a novel reward-based negotiation strategy through deep RL by considering an issue-based represented deep policy network for multi-issue negotiation. Comparative studies analyzed the significant properties of negotiation strategies with RL. The results revealed that the policy-based learning agents with issue-based representations achieved comparable or higher utility than the state-of-the-art baselines with RL and heuristics, especially in the large-sized domains. Additionally, negotiation strategies with RL based on the policy network can achieve agreements by effectively using each step.","https://ojs.aaai.org/index.php/AAAI/article/view/26367/26139"
"26368","Intersection Coordination with Priority-Based Search for Autonomous Vehicles","['Jiaoyang Li', 'The Anh Hoang', 'Eugene Lin', 'Hai L. Vu', 'Sven Koenig']","['Carnegie Mellon University', 'Monash University', 'University of Southern California', 'Monash University', 'University of Southern California']","['MAS: Multiagent Planning', 'APP: Transportation', 'ROB: Motion and Path Planning', 'ROB: Multi-Robot Systems', 'MAS: Applications', 'SO: Heuristic Search']","Li, J., Hoang, T. A., Lin, E., Vu, H. L., & Koenig, S. (2023). Intersection Coordination with Priority-Based Search for Autonomous Vehicles. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11578-11585. https://doi.org/10.1609/aaai.v37i10.26368","Abstract 					The development of connected and autonomous vehicles opens an opportunity to manage intersections without signals. One promising approach is to use a central autonomous intersection manager to optimize the movement of the vehicles in the intersection. Existing work uses Mixed Integer Linear Programming (MILP) to find optimal solutions for this problem but is time-consuming and cannot be applied in real-time. On the other hand, the coordination of the vehicles is essentially a Multi-Agent Path Finding (MAPF) problem, for which dozens of efficient algorithms have been proposed in recent years. Inspired by these MAPF algorithms, we propose a three-level algorithm called PSL to solve the intersection coordination problem. Theoretically, PSL is complete and polynomial-time in the number of vehicles. Empirically, PSL runs significantly faster with only a slight compromise in the solution quality than the optimal MILP method. It also generates significantly better solutions with a slightly larger runtime than the traditional First-Come-First-Served strategy.","https://ojs.aaai.org/index.php/AAAI/article/view/26368/26140"
"26369","Solving Large-Scale Pursuit-Evasion Games Using Pre-trained Strategies","['Shuxin Li', 'Xinrun Wang', 'Youzhi Zhang', 'Wanqi Xue', 'Jakub Černý', 'Bo An']","['Nanyang Technological University', 'Nanyang Technological University', 'Centre for Artificial Intelligence and Robotics, Hong Kong Institute of Science & Innovation, Chinese Academy of Sciences', 'Nanyang Technological University', 'Nanyang Technological University', 'Nanyang Technological University']","['MAS: Multiagent Learning', 'APP: Energy', 'Environment & Sustainability', 'APP: Security', 'ML: Representation Learning']","Li, S., Wang, X., Zhang, Y., Xue, W., Černý, J., & An, B. (2023). Solving Large-Scale Pursuit-Evasion Games Using Pre-trained Strategies. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11586-11594. https://doi.org/10.1609/aaai.v37i10.26369","Abstract 					Pursuit-evasion games on graphs model the coordination of police forces chasing a fleeing felon in real-world urban settings, using the standard framework of imperfect-information extensive-form games (EFGs). In recent years, solving EFGs has been largely dominated by the Policy-Space Response Oracle (PSRO) methods due to their modularity, scalability, and favorable convergence properties. However, even these methods quickly reach their limits when facing large combinatorial strategy spaces of the pursuit-evasion games. To improve their efficiency, we integrate the pre-training and fine-tuning paradigm into the core module of PSRO -- the repeated computation of the best response. First, we pre-train the pursuer's policy base model against many different strategies of the evader. Then we proceed with the PSRO loop and fine-tune the pre-trained policy to attain the pursuer's best responses. The empirical evaluation shows that our approach significantly outperforms the baselines in terms of speed and scalability, and can solve even games on street maps of megalopolises with tens of thousands of crossroads -- a scale beyond the effective reach of previous methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26369/26141"
"26370","Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition","['Shunyu Liu', 'Yihe Zhou', 'Jie Song', 'Tongya Zheng', 'Kaixuan Chen', 'Tongtian Zhu', 'Zunlei Feng', 'Mingli Song']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University']","['MAS: Multiagent Learning', 'ML: Reinforcement Learning Algorithms', 'MAS: Agent-Based Simulation and Emergent Behavior', 'MAS: Coordination and Collaboration']","Liu, S., Zhou, Y., Song, J., Zheng, T., Chen, K., Zhu, T., Feng, Z., & Song, M. (2023). Contrastive Identity-Aware Learning for Multi-Agent Value Decomposition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11595-11603. https://doi.org/10.1609/aaai.v37i10.26370","Abstract 					Value Decomposition (VD) aims to deduce the contributions of agents for decentralized policies in the presence of only global rewards, and has recently emerged as a powerful credit assignment paradigm for tackling cooperative Multi-Agent Reinforcement Learning (MARL) problems. One of the main challenges in VD is to promote diverse behaviors among agents, while existing methods directly encourage the diversity of learned agent networks with various strategies. However, we argue that these dedicated designs for agent networks are still limited by the indistinguishable VD network, leading to homogeneous agent behaviors and thus downgrading the cooperation capability. In this paper, we propose a novel Contrastive Identity-Aware learning (CIA) method, explicitly boosting the credit-level distinguishability of the VD network to break the bottleneck of multi-agent diversity. Specifically, our approach leverages contrastive learning to maximize the mutual information between the temporal credits and identity representations of different agents, encouraging the full expressiveness of credit assignment and further the emergence of individualities. The algorithm implementation of the proposed CIA module is simple yet effective that can be readily incorporated into various VD architectures. Experiments on the SMAC benchmarks and across different VD backbones demonstrate that the proposed method yields results superior to the state-of-the-art counterparts. Our code is available at https://github.com/liushunyu/CIA.","https://ojs.aaai.org/index.php/AAAI/article/view/26370/26142"
"26371","Learning to Shape Rewards Using a Game of Two Partners","['David Mguni', 'Taher Jafferjee', 'Jianhong Wang', 'Nicolas Perez-Nieves', 'Wenbin Song', 'Feifei Tong', 'Matthew Taylor', 'Tianpei Yang', 'Zipeng Dai', 'Hui Chen', 'Jiangcheng Zhu', 'Kun Shao', 'Jun Wang', 'Yaodong Yang']","['Huawei', 'Huawei', 'University of Manchester', 'Imperial College London', 'ShanghaiTech University', 'Huawei', 'University of Alberta\nAlberta Machine Intelligence Institute', 'University of Alberta\nAlberta Machine Intelligence Institute', 'Huawei', 'UCL', 'Huawei', 'Huawei', 'UCL', 'Peking University']","['MAS: Multiagent Learning', 'MAS: Coordination and Collaboration', 'MAS: Distributed Problem Solving']","Mguni, D., Jafferjee, T., Wang, J., Perez-Nieves, N., Song, W., Tong, F., Taylor, M., Yang, T., Dai, Z., Chen, H., Zhu, J., Shao, K., Wang, J., & Yang, Y. (2023). Learning to Shape Rewards Using a Game of Two Partners. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11604-11612. https://doi.org/10.1609/aaai.v37i10.26371","Abstract 					Reward shaping (RS) is a powerful method in reinforcement learning (RL) for overcoming the problem of sparse or uninformative rewards. However, RS typically relies on manually engineered shaping-reward functions whose construc- tion is time-consuming and error-prone. It also requires domain knowledge which runs contrary to the goal of autonomous learning. We introduce Reinforcement Learning Optimising Shaping Algorithm (ROSA), an automated reward shaping framework in which the shaping-reward function is constructed in a Markov game between two agents. A reward-shaping agent (Shaper) uses switching controls to determine which states to add shaping rewards for more efficient learning while the other agent (Controller) learns the optimal policy for the task using these shaped rewards. We prove that ROSA, which adopts existing RL algorithms, learns to construct a shaping-reward function that is beneficial to the task thus ensuring efficient convergence to high performance policies. We demonstrate ROSA’s properties in three didactic experiments and show its superior performance against state-of-the-art RS algorithms in challenging sparse reward environments.","https://ojs.aaai.org/index.php/AAAI/article/view/26371/26143"
"26372","Reconstructing an Epidemic Outbreak Using Steiner Connectivity","['Ritwick Mishra', 'Jack Heavey', 'Gursharn Kaur', 'Abhijin Adiga', 'Anil Vullikanti']","['Biocomplexity Institute and Dept of Computer Science, University of Virginia', 'Biocomplexity Institute and Dept of Computer Science, University of Virginia', 'Biocomplexity Institute & Initiative, University of Virginia', 'Biocomplexity Institute & Initiative, University of Virginia', 'Biocomplexity Institute and Dept of Computer Science, University of Virginia']","['MAS: Agent-Based Simulation and Emergent Behavior', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining']","Mishra, R., Heavey, J., Kaur, G., Adiga, A., & Vullikanti, A. (2023). Reconstructing an Epidemic Outbreak Using Steiner Connectivity. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11613-11620. https://doi.org/10.1609/aaai.v37i10.26372","Abstract 					Only a subset of infections is actually observed in an outbreak, due to multiple reasons such as asymptomatic cases and under-reporting. Therefore, reconstructing an epidemic cascade given some observed cases is an important step in responding to such an outbreak. A maximum likelihood solution to this problem ( referred to as CascadeMLE ) can be shown to be a variation of the classical Steiner subgraph problem, which connects a subset of observed infections. In contrast to prior works on epidemic reconstruction, which consider the standard Steiner tree objective, we show that a solution to CascadeMLE, based on the actual MLE objective, has a very different structure. We design a logarithmic approximation algorithm for CascadeMLE, and evaluate it on multiple synthetic and social contact networks, including a contact network constructed for a hospital. Our algorithm has significantly better performance compared to a prior baseline.","https://ojs.aaai.org/index.php/AAAI/article/view/26372/26144"
"26373","Formal Verification of Bayesian Mechanisms","['Munyque Mittelmann', 'Bastien Maubert', 'Aniello Murano', 'Laurent Perrussel']","[""Università degli Studi di Napoli ``Federico II'', Italy"", ""Università degli Studi di Napoli ``Federico II'', Italy"", ""Università degli Studi di Napoli ``Federico II'', Italy"", 'IRIT - Université Toulouse Capitole, France']","['MAS: Multiagent Systems Under Uncertainty', 'KRR: Applications', 'MAS: Mechanism Design']","Mittelmann, M., Maubert, B., Murano, A., & Perrussel, L. (2023). Formal Verification of Bayesian Mechanisms. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11621-11629. https://doi.org/10.1609/aaai.v37i10.26373","Abstract 					In this paper, for the first time, we study the formal verification of Bayesian mechanisms through strategic reasoning. We rely on the framework of Probabilistic Strategy Logic (PSL), which is well-suited for representing and verifying multi-agent systems with incomplete information. We take advantage of the recent results on the decidability of PSL model checking under memoryless strategies, and reduce the problem of formally verifying Bayesian mechanisms to PSL model checking. We show how to encode Bayesian-Nash equilibrium and economical properties, and illustrate our approach with different kinds of mechanisms.","https://ojs.aaai.org/index.php/AAAI/article/view/26373/26145"
"26374","Memory-Augmented Theory of Mind Network","['Dung Nguyen', 'Phuoc Nguyen', 'Hung Le', 'Kien Do', 'Svetha Venkatesh', 'Truyen Tran']","['Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, Australia', 'Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, Australia', 'Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, Australia', 'Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, Australia', 'Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, Australia', 'Applied Artificial Intelligence Institute (A2I2), Deakin University, Geelong, Australia']","['MAS: Modeling Other Agents', 'ML: Deep Neural Architectures', 'CMS: Memory Storage and Retrieval', 'CMS: Social Cognition and Interaction']","Nguyen, D., Nguyen, P., Le, H., Do, K., Venkatesh, S., & Tran, T. (2023). Memory-Augmented Theory of Mind Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11630-11637. https://doi.org/10.1609/aaai.v37i10.26374","Abstract 					Social reasoning necessitates the capacity of theory of mind (ToM), the ability to contextualise and attribute mental states to others without having access to their internal cognitive structure. Recent machine learning approaches to ToM have demonstrated that we can train the observer to read the past and present behaviours of other agents and infer their beliefs (including false beliefs about things that no longer exist), goals, intentions and future actions. The challenges arise when the behavioural space is complex, demanding skilful space navigation for rapidly changing contexts for an extended period. We tackle the challenges by equipping the observer with novel neural memory mechanisms to encode, and hierarchical attention to selectively retrieve information about others. The memories allow rapid, selective querying of distal related past behaviours of others to deliberatively reason about their current mental state, beliefs and future behaviours. This results in ToMMY, a theory of mind model that learns to reason while making little assumptions about the underlying mental processes. We also construct a new suite of experiments to demonstrate that memories facilitate the learning process and achieve better theory of mind performance, especially for high-demand false-belief tasks that require inferring through multiple steps of changes.","https://ojs.aaai.org/index.php/AAAI/article/view/26374/26146"
"26375","Socially Optimal Non-discriminatory Restrictions for Continuous-Action Games","['Michael Oesterle', 'Guni Sharon']","['Institute for Enterprise Systems (InES), University of Mannheim', 'Texas A&M University']","['MAS: Mechanism Design', 'ML: Bias and Fairness', 'MAS: Adversarial Agents', 'MAS: Agent-Based Simulation and Emergent Behavior', 'MAS: Applications', 'MAS: Coordination and Collaboration', 'PEAI: Bias', 'Fairness & Equity']","Oesterle, M., & Sharon, G. (2023). Socially Optimal Non-discriminatory Restrictions for Continuous-Action Games. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11638-11646. https://doi.org/10.1609/aaai.v37i10.26375","Abstract 					We address the following mechanism design problem: Given a multi-player Normal-Form Game (NFG) with a continuous action space, find a non-discriminatory (i.e., identical for all players) restriction of the action space which maximizes the resulting Nash Equilibrium with respect to a fixed social utility function. First, we propose a formal model of a Restricted Game and the corresponding restriction optimization problem. We then present an algorithm to find optimal non-discriminatory restrictions under some assumptions. Our experimental results with Braess' Paradox and the Cournot Game show that this method leads to an optimized social utility of the Nash Equilibria, even when the assumptions are not guaranteed to hold. Finally, we outline a generalization of our approach to the much wider scope of Stochastic Games.","https://ojs.aaai.org/index.php/AAAI/article/view/26375/26147"
"26376","Fault-Tolerant Offline Multi-Agent Path Planning","['Keisuke Okumura', 'Sébastien Tixeuil']","['Tokyo Institute of Technology', 'Sorbonne University']","['MAS: Multiagent Planning', 'ROB: Motion and Path Planning', 'ROB: Multi-Robot Systems', 'MAS: Coordination and Collaboration', 'PRS: Plan Execution and Monitoring', 'SO: Heuristic Search']","Okumura, K., & Tixeuil, S. (2023). Fault-Tolerant Offline Multi-Agent Path Planning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11647-11654. https://doi.org/10.1609/aaai.v37i10.26376","Abstract 					We study a novel graph path planning problem for multiple agents that may crash at runtime, and block part of the workspace. In our setting, agents can detect neighboring crashed agents, and change followed paths at runtime. The objective is then to prepare a set of paths and switching rules for each agent, ensuring that all correct agents reach their destinations without collisions or deadlocks, despite unforeseen crashes of other agents. Such planning is attractive to build reliable multi-robot systems. We present problem formalization, theoretical analysis such as computational complexities, and how to solve this offline planning problem.","https://ojs.aaai.org/index.php/AAAI/article/view/26376/26148"
"26377","LaCAM: Search-Based Algorithm for Quick Multi-Agent Pathfinding","['Keisuke Okumura']","['Tokyo Institute of Technology']","['MAS: Multiagent Planning', 'ROB: Motion and Path Planning', 'ROB: Multi-Robot Systems', 'PRS: Deterministic Planning', 'SO: Heuristic Search']","Okumura, K. (2023). LaCAM: Search-Based Algorithm for Quick Multi-Agent Pathfinding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11655-11662. https://doi.org/10.1609/aaai.v37i10.26377","Abstract 					We propose a novel complete algorithm for multi-agent pathfinding (MAPF) called lazy constraints addition search for MAPF (LaCAM). MAPF is a problem of finding collision-free paths for multiple agents on graphs and is the foundation of multi-robot coordination. LaCAM uses a two-level search to find solutions quickly, even with hundreds of agents or more. At the low-level, it searches constraints about agents' locations. At the high-level, it searches a sequence of all agents' locations, following the constraints specified by the low-level. Our exhaustive experiments reveal that LaCAM is comparable to or outperforms state-of-the-art sub-optimal MAPF algorithms in a variety of scenarios, regarding success rate, planning time, and solution quality of sum-of-costs.","https://ojs.aaai.org/index.php/AAAI/article/view/26377/26149"
"26378","Networked Anti-coordination Games Meet Graphical Dynamical Systems: Equilibria and Convergence","['Zirou Qiu', 'Chen Chen', 'Madhav V. Marathe', 'S. S. Ravi', 'Daniel J. Rosenkrantz', 'Richard E. Stearns', 'Anil Vullikanti']","['Biocomplexity Institute and Dept of Computer Science, University of Virginia', 'Biocomplexity Institute, University of Virginia', 'Biocomplexity Institute and Dept of Computer Science, University of Virginia', 'Biocomplexity Institute, University of Virginia\nUniversity at Albany - SUNY', 'Biocomplexity Institute, University of Virginia\nUniversity at Albany - SUNY', 'Biocomplexity Institute, University of Virginia\nUniversity at Albany - SUNY', 'Biocomplexity Institute and Dept of Computer Science, University of Virginia']","['MAS: Agent/AI Theories and Architectures', 'MAS: Coordination and Collaboration', 'MAS: Other Foundations of Multiagent Systems']","Qiu, Z., Chen, C., Marathe, M. V., Ravi, S. S., Rosenkrantz, D. J., Stearns, R. E., & Vullikanti, A. (2023). Networked Anti-coordination Games Meet Graphical Dynamical Systems: Equilibria and Convergence. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11663-11671. https://doi.org/10.1609/aaai.v37i10.26378","Abstract 					Evolutionary anti-coordination games on networks capture real-world strategic situations such as traffic routing and market competition. Two key problems concerning evolutionary games are the existence of a pure Nash equilibrium (NE) and the convergence time. In this work, we study these two problems for anti-coordination games under sequential and synchronous update schemes. For each update scheme, we examine two decision modes based on whether an agent considers its own previous action (self essential) or not (self non-essential) in choosing its next action. Using a relationship between games and dynamical systems, we show that for both update schemes, finding an NE can be done efficiently under the self non-essential mode but is computationally intractable under the self essential mode. We then identify special cases for which an NE can be obtained efficiently. For convergence time, we show that the dynamics converges in a polynomial number of steps under the synchronous scheme; for the sequential scheme, the convergence time is polynomial only under the self non-essential mode. Through experiments, we empirically examine the convergence time and the equilibria for both synthetic and real-world networks.","https://ojs.aaai.org/index.php/AAAI/article/view/26378/26150"
"26379","Learning from Good Trajectories in Offline Multi-Agent Reinforcement Learning","['Qi Tian', 'Kun Kuang', 'Furui Liu', 'Baoxiang Wang']","['Zhejiang Univerisity', 'Zhejiang University', ""Huawei Noah's Ark Lab"", 'The Chinese University of Hong Kong, Shenzhen']","['MAS: Multiagent Learning', 'MAS: Coordination and Collaboration']","Tian, Q., Kuang, K., Liu, F., & Wang, B. (2023). Learning from Good Trajectories in Offline Multi-Agent Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11672-11680. https://doi.org/10.1609/aaai.v37i10.26379","Abstract 					Offline multi-agent reinforcement learning (MARL) aims to learn effective multi-agent policies from pre-collected datasets, which is an important step toward the deployment of multi-agent systems in real-world applications. However, in practice, each individual behavior policy that generates multi-agent joint trajectories usually has a different level of how well it performs. e.g., an agent is a random policy while other agents are medium policies. In the cooperative game with global reward, one agent learned by existing offline MARL often inherits this random policy, jeopardizing the utility of the entire team. In this paper, we investigate offline MARL with explicit consideration on the diversity of agent-wise trajectories and propose a novel framework called Shared Individual Trajectories (SIT) to address this problem. Specifically, an attention-based reward decomposition network assigns the credit to each agent through a differentiable key-value memory mechanism in an offline manner. These decomposed credits are then used to reconstruct the joint offline datasets into prioritized experience replay with individual trajectories, thereafter agents can share their good trajectories and conservatively train their policies with a graph attention network (GAT) based critic. We evaluate our method in both discrete control (i.e., StarCraft II and multi-agent particle environment) and continuous control (i.e., multi-agent mujoco). The results indicate that our method achieves significantly better results in complex and mixed offline multi-agent datasets, especially when the difference of data quality between individual trajectories is large.","https://ojs.aaai.org/index.php/AAAI/article/view/26379/26151"
"26380","Resource Sharing through Multi-Round Matchings","['Yohai Trabelsi', 'Abhijin Adiga', 'Sarit Kraus', 'S. S. Ravi', 'Daniel J. Rosenkrantz']","['Bar-Ilan University', 'Biocomplexity Institute and Initiative, Univ. of Virginia', 'Bar-Ilan University', 'Biocomplexity Institute and Initiative, Univ. of Virginia\nUniversity at Albany – SUNY', 'Biocomplexity Institute and Initiative, Univ. of Virginia\nUniversity at Albany – SUNY']","['MAS: Other Foundations of Multiagent Systems', 'MAS: Coordination and Collaboration']","Trabelsi, Y., Adiga, A., Kraus, S., Ravi, S. S., & Rosenkrantz, D. J. (2023). Resource Sharing through Multi-Round Matchings. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11681-11690. https://doi.org/10.1609/aaai.v37i10.26380","Abstract 					Applications such as employees sharing office spaces over a workweek can be modeled as problems where agents are matched to resources over multiple rounds. Agents' requirements limit the set of compatible resources and the rounds in which they want to be matched.  Viewing such an application as a multi-round matching problem on a bipartite compatibility graph between agents and resources, we show that a  solution  (i.e., a set of matchings, with one matching per round) can be found efficiently if one exists.  To cope with situations where a solution does not exist, we consider two extensions. In the first extension, a benefit function is defined for each agent and the objective is to find a multi-round matching to maximize the total benefit.  For a general class of benefit functions satisfying certain properties (including diminishing returns), we show that this multi-round matching problem is efficiently solvable.  This class includes utilitarian and Rawlsian welfare functions.   For another benefit function, we show that the maximization problem is NP-hard.   In the second extension, the objective is to generate advice to each agent (i.e., a subset of requirements to be relaxed) subject to a budget constraint so that the agent can be matched. We show that this budget-constrained advice generation problem is NP-hard. For this problem, we develop an integer linear programming formulation  as well as a heuristic based on local search.  We experimentally evaluate our algorithms on synthetic networks and apply them to two real-world situations: shared office spaces and matching courses to classrooms.","https://ojs.aaai.org/index.php/AAAI/article/view/26380/26152"
"26381","Effective Integration of Weighted Cost-to-Go and Conflict Heuristic within Suboptimal CBS","['Rishi Veerapaneni', 'Tushar Kusnur', 'Maxim Likhachev']","['Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University']","['MAS: Multiagent Planning', 'ROB: Motion and Path Planning', 'ROB: Multi-Robot Systems', 'SO: Heuristic Search']","Veerapaneni, R., Kusnur, T., & Likhachev, M. (2023). Effective Integration of Weighted Cost-to-Go and Conflict Heuristic within Suboptimal CBS. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11691-11698. https://doi.org/10.1609/aaai.v37i10.26381","Abstract 					Conflict-Based Search (CBS) is a popular multi-agent path finding (MAPF) solver that employs a low-level single agent planner and a high-level constraint tree to resolve conflicts. The vast majority of modern MAPF solvers focus on improving CBS by reducing the size of this tree through various strategies with few methods modifying the low level planner. Typically low level planners in existing CBS methods use an unweighted cost-to-go heuristic, with suboptimal CBS methods also using a conflict heuristic to help the high level search. In this paper, we show that, contrary to prevailing CBS beliefs, a weighted cost-to-go heuristic can be used effectively alongside the conflict heuristic in two possible variants. In particular, one of these variants can obtain large speedups, 2-100x, across several  scenarios and suboptimal CBS methods. Importantly, we discover that performance is related not to the weighted cost-to-go heuristic but rather to the relative conflict heuristic weight's ability to effectively balance low-level and high-level work. Additionally, to the best of our knowledge, we show the first theoretical relation of prioritized planning and bounded suboptimal CBS and demonstrate that our methods are their natural generalization.","https://ojs.aaai.org/index.php/AAAI/article/view/26381/26153"
"26382","DM²: Decentralized Multi-Agent Reinforcement Learning via Distribution Matching","['Caroline Wang', 'Ishan Durugkar', 'Elad Liebman', 'Peter Stone']","['The University of Texas at Austin', 'The University of Texas at Austin', 'SparkCognition', 'The University of Texas at Austin\nSony AI']","['MAS: Coordination and Collaboration', 'MAS: Multiagent Learning', 'MAS: Distributed Problem Solving', 'ML: Reinforcement Learning Algorithms', 'ML: Imitation Learning & Inverse Reinforcement Learning']","Wang, C., Durugkar, I., Liebman, E., & Stone, P. (2023). DM²: Decentralized Multi-Agent Reinforcement Learning via Distribution Matching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11699-11707. https://doi.org/10.1609/aaai.v37i10.26382","Abstract 					Current approaches to multi-agent cooperation rely heavily on centralized mechanisms or explicit communication protocols to ensure convergence. This paper studies the problem of distributed multi-agent learning without resorting to centralized components or explicit communication. It examines the use of distribution matching to facilitate the coordination of independent agents. In the proposed scheme, each agent independently minimizes the distribution mismatch to the corresponding component of a target visitation distribution. The theoretical  analysis shows that under certain conditions, each agent minimizing its individual  distribution mismatch allows the convergence to the joint policy that generated the target distribution. Further, if the target distribution is from a joint policy that optimizes a cooperative task, the optimal policy for a combination of this task reward and the distribution matching reward is the same joint policy. This insight is used to formulate a practical algorithm (DM^2), in which each individual agent matches a target distribution derived from concurrently sampled trajectories from a joint expert policy. Experimental validation on the StarCraft domain shows that combining (1) a task reward, and (2) a distribution matching reward for expert demonstrations for the same task, allows agents to outperform a naive distributed baseline. Additional experiments probe the conditions under which expert demonstrations need to be sampled to obtain the learning benefits.","https://ojs.aaai.org/index.php/AAAI/article/view/26382/26154"
"26383","Emergence of Punishment in Social Dilemma with Environmental Feedback","['Zhen Wang', 'Zhao Song', 'Chen Shen', 'Shuyue Hu']","['Northwestern Polytechnical University', 'Northwestern Polytechnical University', 'Kyushu University', 'Shanghai Artificial Intelligence Laboratory']","['MAS: Agent-Based Simulation and Emergent Behavior', 'GTEP: Game Theory', 'MAS: Mechanism Design']","Wang, Z., Song, Z., Shen, C., & Hu, S. (2023). Emergence of Punishment in Social Dilemma with Environmental Feedback. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11708-11716. https://doi.org/10.1609/aaai.v37i10.26383","Abstract 					Altruistic punishment (or punishment) has been extensively shown as an important mechanism for promoting cooperation in human societies. In AI, the emergence of punishment has received much recent interest. In this paper, we contribute with a novel evolutionary game theoretic model to study the impacts of environmental feedback. Whereas a population of agents plays public goods games, there exists a third-party population whose payoffs depend not only on whether to punish or not, but also on the state of the environment (e.g., how cooperative the agents in a social dilemma are). Focusing on one-shot public goods games, we show that environmental feedback, by itself, can lead to the emergence of punishment. We analyze the co-evolution of punishment and cooperation, and derive conditions for their co-presence, co-dominance and co-extinction. Moreover, we show that the system can exhibit bistability as well as cyclic dynamics. Our findings provide a new explanation for the emergence of punishment.  On the other hand, our results also alert the need for careful design of implementing punishment in multi-agent systems, as the resulting evolutionary dynamics can be somewhat complex.","https://ojs.aaai.org/index.php/AAAI/article/view/26383/26155"
"26384","Subspace-Aware Exploration for Sparse-Reward Multi-Agent Tasks","['Pei Xu', 'Junge Zhang', 'Qiyue Yin', 'Chao Yu', 'Yaodong Yang', 'Kaiqi Huang']","['School of Artificial Intelligence, University of Chinese Academy of Sciences\nCRISE, Institute of Automation, Chinese Academy of Sciences', 'CRISE, Institute of Automation, Chinese Academy of Sciences', 'CRISE, Institute of Automation, Chinese Academy of Sciences', 'School of Computer Science and Engineering, Sun Yat-sen University', 'Beijing Institute for General AI\nInstitute for AI, Peking University', 'School of Artificial Intelligence, University of Chinese Academy of Sciences\nCRISE, Institute of Automation, Chinese Academy of Sciences\nCAS, Center for Excellence in Brain Science and Intelligence Technology']","['MAS: Multiagent Learning', 'ML: Reinforcement Learning Algorithms']","Xu, P., Zhang, J., Yin, Q., Yu, C., Yang, Y., & Huang, K. (2023). Subspace-Aware Exploration for Sparse-Reward Multi-Agent Tasks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11717-11725. https://doi.org/10.1609/aaai.v37i10.26384","Abstract 					Exploration under sparse rewards is a key challenge for multi-agent reinforcement learning problems. One possible solution to this issue is to exploit inherent task structures for an acceleration of exploration. In this paper, we present a novel exploration approach, which encodes a special structural prior on the reward function into exploration, for sparse-reward multi-agent tasks. Specifically, a novel entropic exploration objective which encodes the structural prior is proposed to accelerate the discovery of rewards. By maximizing the lower bound of this objective, we then propose an algorithm with moderate computational cost, which can be applied to practical tasks. Under the sparse-reward setting, we show that the proposed algorithm significantly outperforms the state-of-the-art algorithms in the multiple-particle environment, the Google Research Football and StarCraft II micromanagement tasks. To the best of our knowledge, on some hard tasks (such as 27m_vs_30m}) which have relatively larger number of agents and need non-trivial strategies to defeat enemies, our method is the first to learn winning strategies under the sparse-reward setting.","https://ojs.aaai.org/index.php/AAAI/article/view/26384/26156"
"26385","Consensus Learning for Cooperative Multi-Agent Reinforcement Learning","['Zhiwei Xu', 'Bin Zhang', 'Dapeng Li', 'Zeren Zhang', 'Guangchong Zhou', 'Hao Chen', 'Guoliang Fan']","['Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation,Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation,Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation,Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Science\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Science\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences']","['MAS: Multiagent Learning']","Xu, Z., Zhang, B., Li, D., Zhang, Z., Zhou, G., Chen, H., & Fan, G. (2023). Consensus Learning for Cooperative Multi-Agent Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11726-11734. https://doi.org/10.1609/aaai.v37i10.26385","Abstract 					Almost all multi-agent reinforcement learning algorithms without communication follow the principle of centralized training with decentralized execution. During the centralized training, agents can be guided by the same signals, such as the global state. However, agents lack the shared signal and choose actions given local observations during execution. Inspired by viewpoint invariance and contrastive learning, we propose consensus learning for cooperative multi-agent reinforcement learning in this study. Although based on local observations, different agents can infer the same consensus in discrete spaces without communication. We feed the inferred one-hot consensus to the network of agents as an explicit input in a decentralized way, thereby fostering their cooperative spirit. With minor model modifications, our suggested framework can be extended to a variety of multi-agent reinforcement learning algorithms. Moreover, we carry out these variants on some fully cooperative tasks and get convincing results.","https://ojs.aaai.org/index.php/AAAI/article/view/26385/26157"
"26386","HAVEN: Hierarchical Cooperative Multi-Agent Reinforcement Learning with Dual Coordination Mechanism","['Zhiwei Xu', 'Yunpeng Bai', 'Bin Zhang', 'Dapeng Li', 'Guoliang Fan']","['Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation,Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation,Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences\nSchool of Artificial Intelligence, University of Chinese Academy of Sciences']","['MAS: Multiagent Learning']","Xu, Z., Bai, Y., Zhang, B., Li, D., & Fan, G. (2023). HAVEN: Hierarchical Cooperative Multi-Agent Reinforcement Learning with Dual Coordination Mechanism. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11735-11743. https://doi.org/10.1609/aaai.v37i10.26386","Abstract 					Recently, some challenging tasks in multi-agent systems have been solved by some hierarchical reinforcement learning methods. Inspired by the intra-level and inter-level coordination in the human nervous system, we propose a novel value decomposition framework HAVEN based on hierarchical reinforcement learning for fully cooperative multi-agent problems. To address the instability arising from the concurrent optimization of policies between various levels and agents, we introduce the dual coordination mechanism of inter-level and inter-agent strategies by designing reward functions in a two-level hierarchy. HAVEN does not require domain knowledge and pre-training, and can be applied to any value decomposition variant. Our method achieves desirable results on different decentralized partially observable Markov decision process domains and outperforms other popular multi-agent hierarchical reinforcement learning algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26386/26158"
"26387","Hierarchical Mean-Field Deep Reinforcement Learning for Large-Scale Multiagent Systems","['Chao Yu']","['Sun Yat-sen University, Guangzhou, China\nPengcheng Laboratory, Shenzhen, China']","['MAS: Multiagent Learning', 'ML: Reinforcement Learning Algorithms']","Yu, C. (2023). Hierarchical Mean-Field Deep Reinforcement Learning for Large-Scale Multiagent Systems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11744-11752. https://doi.org/10.1609/aaai.v37i10.26387","Abstract 					Learning for efficient coordination in large-scale multiagent systems suffers from the problem of the curse of dimensionality due to the exponential growth of agent interactions. Mean-Field (MF)-based methods address this issue by transforming the interactions within the whole system into a single agent played with the average effect of its neighbors. However, considering the neighbors merely by their average may ignore the varying influences of each neighbor, and learning with this kind of local average effect would likely lead to inferior system performance due to lack of an efficient coordination mechanism in the whole population level. In this work, we propose a Hierarchical Mean-Field (HMF) learning framework to further improve the performance of existing MF methods. The basic idea is to approximate the average effect for a sub-group of agents by considering their different influences within the sub-group, and realize population-level coordination through the interactions among different sub-groups. Empirical studies show that HMF significantly outperforms existing baselines on both challenging cooperative and mixed cooperative-competitive tasks with different scales of agent populations.","https://ojs.aaai.org/index.php/AAAI/article/view/26387/26159"
"26388","Robust Multi-Agent Coordination via Evolutionary Generation of Auxiliary Adversarial Attackers","['Lei Yuan', 'Ziqian Zhang', 'Ke Xue', 'Hao Yin', 'Feng Chen', 'Cong Guan', 'Lihe Li', 'Chao Qian', 'Yang Yu']","['Nanjing University\nPolixir Technologies', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University\nPolixir Technologies']","['MAS: Coordination and Collaboration', 'MAS: Adversarial Agents', 'MAS: Agent-Based Simulation and Emergent Behavior', 'MAS: Agreement', 'Argumentation & Negotiation', 'MAS: Mechanism Design', 'MAS: Multiagent Learning', 'MAS: Multiagent Planning', 'MAS: Multiagent Systems Under Uncertainty']","Yuan, L., Zhang, Z., Xue, K., Yin, H., Chen, F., Guan, C., Li, L., Qian, C., & Yu, Y. (2023). Robust Multi-Agent Coordination via Evolutionary Generation of Auxiliary Adversarial Attackers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11753-11762. https://doi.org/10.1609/aaai.v37i10.26388","Abstract 					Cooperative Multi-agent Reinforcement Learning (CMARL) has shown to be promising for many real-world applications. Previous works mainly focus on improving coordination ability via solving MARL-specific challenges (e.g., non-stationarity, credit assignment, scalability), but ignore the policy perturbation issue when testing in a different environment. This issue hasn't been considered in problem formulation or efficient algorithm design. To address this issue, we firstly model the problem as a Limited Policy Adversary Dec-POMDP (LPA-Dec-POMDP), where some coordinators from a team might accidentally and unpredictably encounter a limited number of malicious action attacks, but the regular coordinators still strive for the intended goal. Then, we propose Robust Multi-Agent Coordination via Evolutionary Generation of Auxiliary Adversarial Attackers (ROMANCE), which enables the trained policy to encounter diversified and strong auxiliary adversarial attacks during training, thus achieving high robustness under various  policy perturbations. Concretely, to avoid the ego-system overfitting to a specific attacker, we maintain a set of attackers, which is optimized to guarantee the attackers high attacking quality and behavior diversity. The goal of quality is to minimize the ego-system coordination effect, and a novel diversity regularizer based on sparse action is applied to diversify the behaviors among attackers. The ego-system is then paired with a population of attackers selected from the maintained attacker set, and alternately trained against the constantly evolving attackers. Extensive experiments on multiple scenarios from SMAC indicate our ROMANCE provides comparable or better robustness and generalization ability than other baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/26388/26160"
"26389","DACOM: Learning Delay-Aware Communication for Multi-Agent Reinforcement Learning","['Tingting Yuan', 'Hwei-Ming Chung', 'Jie Yuan', 'Xiaoming Fu']","['University oft Göettingen', 'University of Oslo\nNOOT Tech. Co., Ltd.', 'Beijing University of Posts and Telecommunications', 'University of Göettingen']","['MAS: Agent Communication', 'ML: Reinforcement Learning Algorithms', 'ML: Reinforcement Learning Theory', 'MAS: Multiagent Learning']","Yuan, T., Chung, H.-M., Yuan, J., & Fu, X. (2023). DACOM: Learning Delay-Aware Communication for Multi-Agent Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11763-11771. https://doi.org/10.1609/aaai.v37i10.26389","Abstract 					Communication is supposed to improve multi-agent collaboration and overall performance in cooperative Multi-agent reinforcement learning (MARL). However, such improvements are prevalently limited in practice since most existing communication schemes ignore communication overheads (e.g., communication delays). In this paper, we demonstrate that ignoring communication delays has detrimental effects on collaborations, especially in delay-sensitive tasks such as autonomous driving. To mitigate this impact, we design a delay-aware multi-agent communication model (DACOM) to adapt communication to delays. Specifically, DACOM introduces a component, TimeNet, that is responsible for adjusting the waiting time of an agent to receive messages from other agents such that the uncertainty associated with delay can be addressed. Our experiments reveal that DACOM has a non-negligible performance improvement over other mechanisms by making a better trade-off between the benefits of communication and the costs of waiting for messages.","https://ojs.aaai.org/index.php/AAAI/article/view/26389/26161"
"26390","Effective and Stable Role-Based Multi-Agent Collaboration by Structural Information Principles","['Xianghua Zeng', 'Hao Peng', 'Angsheng Li']","['Beihang University, Beijing, China', 'Beihang University, Beijing, China', 'Beihang University, Beijing, China\nZhongguancun Laboratory, Beijing, China']","['MAS: Multiagent Learning', 'ML: Reinforcement Learning Algorithms']","Zeng, X., Peng, H., & Li, A. (2023). Effective and Stable Role-Based Multi-Agent Collaboration by Structural Information Principles. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11772-11780. https://doi.org/10.1609/aaai.v37i10.26390","Abstract 					Role-based learning is a promising approach to improving the performance of Multi-Agent Reinforcement Learning (MARL). Nevertheless, without manual assistance, current role-based methods cannot guarantee stably discovering a set of roles to effectively decompose a complex task, as they assume either a predefined role structure or practical experience for selecting hyperparameters. In this article, we propose a mathematical Structural Information principles-based Role Discovery method, namely SIRD, and then present a SIRD optimizing MARL framework, namely SR-MARL, for multi-agent collaboration. The SIRD transforms role discovery into a hierarchical action space clustering. Specifically, the SIRD consists of structuralization, sparsification, and optimization modules, where an optimal encoding tree is generated to perform abstracting to discover roles. The SIRD is agnostic to specific MARL algorithms and flexibly integrated with various value function factorization approaches. Empirical evaluations on the StarCraft II micromanagement benchmark demonstrate that, compared with state-of-the-art MARL algorithms, the SR-MARL framework improves the average test win rate by 0.17%, 6.08%, and 3.24%, and reduces the deviation by 16.67%, 30.80%, and 66.30%, under easy, hard, and super hard scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/26390/26162"
"26391","Learning to Play General-Sum Games against Multiple Boundedly Rational Agents","['Eric Zhao', 'Alexander R. Trott', 'Caiming Xiong', 'Stephan Zheng']","['University of California, Berkeley\nSalesforce Research', 'Mosaic ML', 'Salesforce Research', 'Salesforce Research']","['MAS: Multiagent Learning', 'MAS: Mechanism Design']","Zhao, E., Trott, A. R., Xiong, C., & Zheng, S. (2023). Learning to Play General-Sum Games against Multiple Boundedly Rational Agents. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11781-11789. https://doi.org/10.1609/aaai.v37i10.26391","Abstract 					We study the problem of training a principal in a multi-agent general-sum game using reinforcement learning (RL). Learning a robust principal policy requires anticipating the worst possible strategic responses of other agents, which is generally NP-hard. However, we show that no-regret dynamics can identify these worst-case responses in poly-time in smooth games. We propose a framework that uses this policy evaluation method for efficiently learning a robust principal policy using RL. This framework can be extended to provide robustness to boundedly rational agents too. Our motivating application is automated mechanism design: we empirically demonstrate our framework learns robust mechanisms in both matrix games and complex spatiotemporal games. In particular, we learn a dynamic tax policy that improves the welfare of a simulated trade-and-barter economy by 15%, even when facing previously unseen boundedly rational RL taxpayers.","https://ojs.aaai.org/index.php/AAAI/article/view/26391/26163"
"26392","Towards Robust Metrics for Concept Representation Evaluation","['Mateo Espinosa Zarlenga', 'Pietro Barbiero', 'Zohreh Shams', 'Dmitry Kazhdan', 'Umang Bhatt', 'Adrian Weller', 'Mateja Jamnik']","['University of Cambridge', 'University of Cambridge', 'University of Cambridge\nBabylon Health', 'University of Cambridge', 'University of Cambridge\nThe Alan Turing Institute', 'University of Cambridge\nThe Alan Turing Institute', 'University of Cambridge']","['PEAI: Interpretability and Explainability', 'PEAI: Safety', 'Robustness & Trustworthiness', 'ML: Representation Learning', 'ML: Deep Generative Models & Autoencoders']","Espinosa Zarlenga, M., Barbiero, P., Shams, Z., Kazhdan, D., Bhatt, U., Weller, A., & Jamnik, M. (2023). Towards Robust Metrics for Concept Representation Evaluation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11791-11799. https://doi.org/10.1609/aaai.v37i10.26392","Abstract 					Recent work on interpretability has focused on concept-based explanations, where deep learning models are explained in terms of high-level units of information, referred to as concepts. Concept learning models, however, have been shown to be prone to encoding impurities in their representations, failing to fully capture meaningful features of their inputs. While concept learning lacks metrics to measure such phenomena, the field of disentanglement learning has explored the related notion of underlying factors of variation in the data, with plenty of metrics to measure the purity of such factors. In this paper, we show that such metrics are not appropriate for concept learning and propose novel metrics for evaluating the purity of concept representations in both approaches. We show the advantage of these metrics over existing ones and demonstrate their utility in evaluating the robustness of concept representations and interventions performed on them. In addition, we show their utility for benchmarking state-of-the-art methods from both families and find that, contrary to common assumptions, supervision alone may not be sufficient for pure concept representations.","https://ojs.aaai.org/index.php/AAAI/article/view/26392/26164"
"26393","On the Vulnerability of Backdoor Defenses for Federated Learning","['Pei Fang', 'Jinghui Chen']","['Tongji University', 'Penn State University']","['PEAI: Safety', 'Robustness & Trustworthiness', 'ML: Adversarial Learning & Robustness']","Fang, P., & Chen, J. (2023). On the Vulnerability of Backdoor Defenses for Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11800-11808. https://doi.org/10.1609/aaai.v37i10.26393","Abstract 					Federated learning (FL) is a popular distributed machine learning paradigm which enables jointly training a global model without sharing clients' data. However, its repetitive server-client communication gives room for possible backdoor attacks which aims to mislead the global model into a targeted misprediction when a specific trigger pattern is presented. In response to such backdoor threats on federated learning, various defense measures have been proposed. In this paper, we study whether the current defense mechanisms truly neutralize the backdoor threats from federated learning in a practical setting by proposing a new federated backdoor attack framework for possible countermeasures. Different from traditional training (on triggered data) and rescaling (the malicious client model) based backdoor injection, the proposed backdoor attack framework (1) directly modifies (a small proportion of) local model weights to inject the backdoor trigger via sign flips; (2) jointly optimize the trigger pattern with the client model,  thus is more persistent and stealthy for circumventing existing defenses. In a case study, we examine the strength and weaknesses of several recent federated backdoor defenses from three major categories and provide suggestions to the practitioners when training federated models in practice.","https://ojs.aaai.org/index.php/AAAI/article/view/26393/26165"
"26394","Distributionally Robust Optimization with Probabilistic Group","['Soumya Suvra Ghosal', 'Yixuan Li']","['University of Wisconsin-Madison', 'University of Wisconsin-Madison']","['PEAI: Safety', 'Robustness & Trustworthiness']","Ghosal, S. S., & Li, Y. (2023). Distributionally Robust Optimization with Probabilistic Group. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11809-11817. https://doi.org/10.1609/aaai.v37i10.26394","Abstract 					Modern machine learning models may be susceptible to learning spurious correlations that hold on average but not for the atypical group of samples. To address the problem, previous approaches minimize the empirical worst-group risk. Despite the promise, they often assume that each sample belongs to one and only one group, which does not allow expressing the uncertainty in group labeling. In this paper, we propose a novel framework PG-DRO, which explores the idea of probabilistic group membership for distributionally robust optimization. Key to our framework, we consider soft group membership instead of hard group annotations. The group probabilities can be flexibly generated using either supervised learning or zero-shot approaches. Our framework accommodates samples with group membership ambiguity, offering stronger flexibility and generality than the prior art. We comprehensively evaluate PG-DRO on both image classification and natural language processing benchmarks, establishing superior performance.","https://ojs.aaai.org/index.php/AAAI/article/view/26394/26166"
"26395","Correct for Whom? Subjectivity and the Evaluation of Personalized Image Aesthetics Assessment Models","['Samuel Goree', 'Weslie Khoo', 'David J. Crandall']","['Indiana University', 'Indiana University', 'Indiana University']","['PEAI: Philosophical Foundations of AI', 'CV: Image and Video Retrieval', 'APP: Art/Music/Creativity', 'APP: Humanities & Computational Social Science', 'PEAI: Morality and Value-Based AI', 'PEAI: Societal Impact of AI']","Goree, S., Khoo, W., & Crandall, D. J. (2023). Correct for Whom? Subjectivity and the Evaluation of Personalized Image Aesthetics Assessment Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11818-11827. https://doi.org/10.1609/aaai.v37i10.26395","Abstract 					The problem of image aesthetic quality assessment is surprisingly difficult to define precisely. Most early work attempted to estimate the average aesthetic rating of a group of observers, while some recent work has shifted to an approach based on few-shot personalization. In this paper, we connect few-shot personalization, via Immanuel Kant's concept of disinterested judgment, to an argument from feminist aesthetics about the biased tendencies of objective standards for subjective pleasures. To empirically investigate this philosophical debate, we introduce PR-AADB, a relabeling of the existing AADB dataset with labels for pairs of images, and measure how well the existing groundtruth predicts our new pairwise labels. We find, consistent with the feminist critique, that both the existing groundtruth and few-shot personalized predictions represent some users' preferences significantly better than others, but that it is difficult to predict when and for whom the existing groundtruth will be correct. We thus advise against using benchmark datasets to evaluate models for personalized IAQA, and recommend caution when attempting to account for subjective difference using machine learning more generally.","https://ojs.aaai.org/index.php/AAAI/article/view/26395/26167"
"26396","Covariate-Shift Generalization via Random Sample Weighting","['Yue He', 'Xinwei Shen', 'Renzhe Xu', 'Tong Zhang', 'Yong Jiang', 'Wenchao Zou', 'Peng Cui']","['Tsinghua University', 'ETH Zurich', 'Tsinghua University', 'The Hong Kong University of Science and Technology', 'Tsinghua University', 'Siemens China', 'Tsinghua University']","['PEAI: Safety', 'Robustness & Trustworthiness', 'ML: Bias and Fairness']","He, Y., Shen, X., Xu, R., Zhang, T., Jiang, Y., Zou, W., & Cui, P. (2023). Covariate-Shift Generalization via Random Sample Weighting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11828-11836. https://doi.org/10.1609/aaai.v37i10.26396","Abstract 					Shifts in the marginal distribution of covariates from training to the test phase, named covariate-shifts, often lead to unstable prediction performance across agnostic testing data, especially under model misspecification. Recent literature on invariant learning attempts to learn an invariant predictor from heterogeneous environments. However, the performance of the learned predictor depends heavily on the availability and quality of provided environments. In this paper, we propose a simple and effective non-parametric method for generating heterogeneous environments via Random Sample Weighting (RSW). Given the training dataset from a single source environment, we randomly generate a set of covariate-determining sample weights and use each weighted training distribution to simulate an environment. We theoretically show that under appropriate conditions, such random sample weighting can produce sufficient heterogeneity to be exploited by common invariance constraints to find the invariant variables for stable prediction under covariate shifts. Extensive experiments on both simulated and real-world datasets clearly validate the effectiveness of our method.","https://ojs.aaai.org/index.php/AAAI/article/view/26396/26168"
"26397","Fairness in Contextual Resource Allocation Systems: Metrics and Incompatibility Results","['Nathanael Jo', 'Bill Tang', 'Kathryn Dullerud', 'Sina Aghaei', 'Eric Rice', 'Phebe Vayanos']","['University of Southern California', 'University of Southern California', 'University of Southern California', 'University of Southern California', 'University of Southern California', 'University of Southern California']","['PEAI: Bias', 'Fairness & Equity', 'PEAI: Societal Impact of AI']","Jo, N., Tang, B., Dullerud, K., Aghaei, S., Rice, E., & Vayanos, P. (2023). Fairness in Contextual Resource Allocation Systems: Metrics and Incompatibility Results. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11837-11846. https://doi.org/10.1609/aaai.v37i10.26397","Abstract 					We study critical systems that allocate scarce resources to satisfy basic needs, such as homeless services that provide housing. These systems often support communities disproportionately affected by systemic racial, gender, or other injustices, so it is crucial to design these systems with fairness considerations in mind. To address this problem, we propose a framework for evaluating fairness in contextual resource allocation systems that is inspired by fairness metrics in machine learning. This framework can be applied to evaluate the fairness properties of a historical policy, as well as to impose constraints in the design of new (counterfactual) allocation policies. Our work culminates with a set of incompatibility results that investigate the interplay between the different fairness metrics we propose. Notably, we demonstrate that: 1) fairness in allocation and fairness in outcomes are usually incompatible; 2) policies that prioritize based on a vulnerability score will usually result in unequal outcomes across groups, even if the score is perfectly calibrated; 3) policies using contextual information beyond what is needed to characterize baseline risk and treatment effects can be fairer in their outcomes than those using just baseline risk and treatment effects; and 4) policies using group status in addition to baseline risk and treatment effects are as fair as possible given all available information. Our framework can help guide the discussion among stakeholders in deciding which fairness metrics to impose when allocating scarce resources.","https://ojs.aaai.org/index.php/AAAI/article/view/26397/26169"
"26398","Improvement-Focused Causal Recourse (ICR)","['Gunnar König', 'Timo Freiesleben', 'Moritz Grosse-Wentrup']","['Research Group Neuroinformatics, University of Vienna\nMunich Center for Machine Learning (MCML), LMU Munich', 'Munich Center for Mathematical Philosophy (MCMP), LMU Munich\nCluster of Excellence Machine Learning, University of Tübingen\nGraduate School of Systemic Neurosciences, LMU Munich', 'Research Group Neuroinformatics, University of Vienna\nData Science @ Uni Vienna, Vienna CogSciHub']","['PEAI: Interpretability and Explainability', 'ML: Causal Learning', 'PEAI: Philosophical Foundations of AI', 'RU: Causality', 'RU: Graphical Model']","König, G., Freiesleben, T., & Grosse-Wentrup, M. (2023). Improvement-Focused Causal Recourse (ICR). Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11847-11855. https://doi.org/10.1609/aaai.v37i10.26398","Abstract 					Algorithmic recourse recommendations inform stakeholders of how to act to revert unfavorable decisions. However, existing methods may recommend actions that lead to acceptance (i.e., revert the model's decision) but do not lead to improvement (i.e., may not revert the underlying real-world state). To recommend such actions is to recommend fooling the predictor. We introduce a novel method, Improvement-Focused Causal Recourse (ICR), which involves a conceptual shift: Firstly, we require ICR recommendations to guide toward improvement. Secondly, we do not tailor the recommendations to be accepted by a specific predictor.  Instead, we leverage causal knowledge to design decision systems that predict accurately pre- and post-recourse, such that improvement guarantees translate into acceptance guarantees. Curiously, optimal pre-recourse classifiers are robust to ICR actions and thus suitable post-recourse. In semi-synthetic experiments, we demonstrate that given correct causal knowledge ICR, in contrast to existing approaches, guides toward both acceptance and improvement.","https://ojs.aaai.org/index.php/AAAI/article/view/26398/26170"
"26399","Explaining Model Confidence Using Counterfactuals","['Thao Le', 'Tim Miller', 'Ronal Singh', 'Liz Sonenberg']","['The University of Melbourne', 'The University of Melbourne', 'The University of Melbourne', 'The University of Melbourne']","['PEAI: Interpretability and Explainability', 'HAI: Human-Computer Interaction']","Le, T., Miller, T., Singh, R., & Sonenberg, L. (2023). Explaining Model Confidence Using Counterfactuals. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11856-11864. https://doi.org/10.1609/aaai.v37i10.26399","Abstract 					Displaying confidence scores in human-AI interaction has been shown to help build trust between humans and AI systems. However, most existing research uses only the confidence score as a form of communication. As confidence scores are just another model output, users may want to understand why the algorithm is confident to determine whether to accept the confidence score. In this paper, we show that counterfactual explanations of confidence scores help study participants to better understand and better trust a machine learning model's prediction. We present two methods for understanding model confidence using counterfactual explanation: (1) based on counterfactual examples; and (2) based on visualisation of the counterfactual space. Both increase understanding and trust for study participants over a baseline of no explanation, but qualitative results show that they are used quite differently, leading to recommendations of when to use each one and directions of designing better explanations.","https://ojs.aaai.org/index.php/AAAI/article/view/26399/26171"
"26400","Echo of Neighbors: Privacy Amplification for Personalized Private Federated Learning with Shuffle Model","['Yixuan Liu', 'Suyun Zhao', 'Li Xiong', 'Yuhan Liu', 'Hong Chen']","['Key Laboratory of Data Engineering and Knowledge Engineering of Ministry of Education, Renmin University of China\nEngineering Research Center of Ministry of Education on Database and BI\nInformation School, Renmin University of China', 'Key Laboratory of Data Engineering and Knowledge Engineering of Ministry of Education, Renmin University of China\nEngineering Research Center of Ministry of Education on Database and BI\nInformation School, Renmin University of China', 'Department of Computer Science, Emory University', 'Key Laboratory of Data Engineering and Knowledge Engineering of Ministry of Education, Renmin University of China\nEngineering Research Center of Ministry of Education on Database and BI\nInformation School, Renmin University of China', 'Key Laboratory of Data Engineering and Knowledge Engineering of Ministry of Education, Renmin University of China\nEngineering Research Center of Ministry of Education on Database and BI\nInformation School, Renmin University of China']","['PEAI: Privacy and Security', 'ML: Distributed Machine Learning & Federated Learning', 'ML: Privacy-Aware ML']","Liu, Y., Zhao, S., Xiong, L., Liu, Y., & Chen, H. (2023). Echo of Neighbors: Privacy Amplification for Personalized Private Federated Learning with Shuffle Model. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11865-11872. https://doi.org/10.1609/aaai.v37i10.26400","Abstract 					Federated Learning, as a popular paradigm for collaborative training, is vulnerable against privacy attacks. Different privacy levels regarding users' attitudes need to be satisfied locally, while a strict privacy guarantee for the global model is also required centrally. Personalized Local Differential Privacy (PLDP) is suitable for preserving users' varying local privacy, yet only provides a central privacy guarantee equivalent to the worst-case local privacy level. Thus, achieving strong central privacy as well as personalized local privacy with a utility-promising model is a challenging problem. In this work, a general framework (APES) is built up to strengthen model privacy under personalized local privacy by leveraging the privacy amplification effect of the shuffle model.  To tighten the privacy bound, we quantify the heterogeneous contributions to the central privacy user by user. The contributions are characterized by the ability of generating “echos” from the perturbation of each user,  which is carefully measured by proposed methods Neighbor Divergence and Clip-Laplace Mechanism. Furthermore, we propose a refined framework (S-APES) with the post-sparsification technique to reduce privacy loss in high-dimension scenarios. To the best of our knowledge, the impact of shuffling on personalized local privacy is considered for the first time. We provide a strong privacy amplification effect, and the bound is tighter than the baseline result based on existing methods for uniform local privacy. Experiments demonstrate that our frameworks ensure comparable or higher accuracy for the global model.","https://ojs.aaai.org/index.php/AAAI/article/view/26400/26172"
"26401","XRand: Differentially Private Defense against Explanation-Guided Attacks","['Truc Nguyen', 'Phung Lai', 'Hai Phan', 'My T. Thai']","['University of Florida', 'New Jersey Institute of Technology', 'New Jersey Institute of Technology', 'University of Florida']","['PEAI: Privacy and Security', 'PEAI: Safety', 'Robustness & Trustworthiness']","Nguyen, T., Lai, P., Phan, H., & Thai, M. T. (2023). XRand: Differentially Private Defense against Explanation-Guided Attacks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11873-11881. https://doi.org/10.1609/aaai.v37i10.26401","Abstract 					Recent development in the field of explainable artificial intelligence (XAI) has helped improve trust in Machine-Learning-as-a-Service (MLaaS) systems, in which an explanation is provided together with the model prediction in response to each query. However, XAI also opens a door for adversaries to gain insights into the black-box models in MLaaS, thereby making the models more vulnerable to several attacks. For example, feature-based explanations (e.g., SHAP) could expose the top important features that a black-box model focuses on. Such disclosure has been exploited to craft effective backdoor triggers against malware classifiers. To address this trade-off, we introduce a new concept of achieving local differential privacy (LDP) in the explanations, and from that we establish a defense, called XRand, against such attacks. We show that our mechanism restricts the information that the adversary can learn about the top important features, while maintaining the faithfulness of the explanations.","https://ojs.aaai.org/index.php/AAAI/article/view/26401/26173"
"26402","Mitigating Adversarial Norm Training with Moral Axioms","['Taylor Olson', 'Kenneth D. Forbus']","['Northwestern University', 'Northwestern University']","['PEAI: Morality and Value-Based AI', 'ML: Adversarial Learning & Robustness', 'PEAI: Safety', 'Robustness & Trustworthiness', 'KRR: Reasoning with Beliefs', 'PEAI: AI and Epistemology', 'KRR: Belief Change', 'CMS: Social Cognition and Interaction', 'RU: Uncertainty Representations']","Olson, T., & Forbus, K. D. (2023). Mitigating Adversarial Norm Training with Moral Axioms. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11882-11889. https://doi.org/10.1609/aaai.v37i10.26402","Abstract 					This paper addresses the issue of adversarial attacks on ethical AI systems. We investigate using moral axioms and rules of deontic logic in a norm learning framework to mitigate adversarial norm training. This model of moral intuition and construction provides AI systems with moral guard rails yet still allows for learning conventions. We evaluate our approach by drawing inspiration from a study commonly used in moral development research. This questionnaire aims to test an agent's ability to reason to moral conclusions despite opposed testimony. Our findings suggest that our model can still correctly evaluate moral situations and learn conventions in an adversarial training environment. We conclude that adding axiomatic moral prohibitions and deontic inference rules to a norm learning model makes it less vulnerable to adversarial attacks.","https://ojs.aaai.org/index.php/AAAI/article/view/26402/26174"
"26403","Equity Promotion in Public Transportation","['Anik Pramanik', 'Pan Xu', 'Yifan Xu']","['New Jersey Institute of Technology', 'New Jersey Institute of Technology', 'Southeast University']","['PEAI: Bias', 'Fairness & Equity', 'APP: Transportation', 'PRS: Optimization of Spatio-Temporal Systems', 'PRS: Scheduling']","Pramanik, A., Xu, P., & Xu, Y. (2023). Equity Promotion in Public Transportation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11890-11898. https://doi.org/10.1609/aaai.v37i10.26403","Abstract 					There are many news articles reporting the obstacles confronting poverty-stricken households in access to public transits. These barriers create a great deal of inconveniences for these impoverished families and more importantly, they contribute a lot of social inequalities. A typical approach addressing the issue is to build more transport infrastructure to offer more opportunities to access the public transits especially for those deprived communities. Examples include adding more bus lines connecting needy residents to railways systems and extending existing bus lines to areas with low socioeconomic status. Recently, a new strategy is proposed, which is to harness the ubiquitous ride-hailing services to connect disadvantaged households with the nearest public transportations. Compared with the former infrastructure-based solution, the ride-hailing-based strategy enjoys a few exclusive benefits such as higher effectiveness and more flexibility.  In this paper, we propose an optimization model to study how to integrate the two approaches together for equity-promotion purposes. Specifically, we aim to design a strategy of allocating a given limited budget to different candidate programs such that the overall social equity is maximized, which is defined as the minimum covering ratio among all pre-specified protected groups of households (based on race, income, etc.). We have designed a linear-programming (LP) based rounding algorithm, which proves to achieve an optimal approximation ratio of 1-1/e. Additionally, we test our algorithm against a few baselines on real data assembled by outsourcing multiple public datasets collected in the city of Chicago. Experimental results confirm our theoretical predictions and demonstrate the effectiveness of our LP-based strategy in promoting social equity, especially when the budget is insufficient.","https://ojs.aaai.org/index.php/AAAI/article/view/26403/26175"
"26404","Online Platforms and the Fair Exposure Problem under Homophily","['Jakob Schoeffer', 'Alexander Ritchie', 'Keziah Naggita', 'Faidra Monachou', 'Jessica Finocchiaro', 'Marc Juarez']","['Karlsruhe Institute of Technology (KIT)', 'University of Michigan', 'Toyota Technological Institute at Chicago', 'Harvard University', 'Harvard University\nCenter for Research on Computation and Society (CRCS)', 'University of Edinburgh']","['PEAI: Societal Impact of AI', 'PEAI: Bias', 'Fairness & Equity', 'GTEP: Applications', 'GTEP: Other Foundations of Game Theory & Economic Paradigms', 'MAS: Other Foundations of Multiagent Systems']","Schoeffer, J., Ritchie, A., Naggita, K., Monachou, F., Finocchiaro, J., & Juarez, M. (2023). Online Platforms and the Fair Exposure Problem under Homophily. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11899-11908. https://doi.org/10.1609/aaai.v37i10.26404","Abstract 					In the wake of increasing political extremism, online platforms have been criticized for contributing to polarization. One line of criticism has focused on echo chambers and the recommended content served to users by these platforms. In this work, we introduce the fair exposure problem: given limited intervention power of the platform, the goal is to enforce balance in the spread of content (e.g., news articles) among two groups of users through constraints similar to those imposed by the Fairness Doctrine in the United States in the past. Groups are characterized by different affiliations (e.g., political views) and have different preferences for content. We develop a stylized framework that models intra- and inter-group content propagation under homophily, and we formulate the platform's decision as an optimization problem that aims at maximizing user engagement, potentially under fairness constraints. Our main notion of fairness requires that each group see a mixture of their preferred and non-preferred content, encouraging information diversity. Promoting such information diversity is often viewed as desirable and a potential means for breaking out of harmful echo chambers. We study the solutions to both the fairness-agnostic and fairness-aware problems. We prove that a fairness-agnostic approach inevitably leads to group-homogeneous targeting  by the platform. This is only partially mitigated by imposing fairness constraints: we show that there exist optimal fairness-aware solutions which target one group with different types of content and the other group with only one type that is not necessarily the group's most preferred. Finally, using simulations with real-world data, we study the system dynamics and quantify the price of fairness.","https://ojs.aaai.org/index.php/AAAI/article/view/26404/26176"
"26405","Minimax AUC Fairness: Efficient Algorithm with Provable Convergence","['Zhenhuan Yang', 'Yan Lok Ko', 'Kush R. Varshney', 'Yiming Ying']","['Etsy, Inc', 'University at Albany, State University of New York', 'IBM Research', 'University at Albany, State University of New York']","['PEAI: Bias', 'Fairness & Equity', 'ML: Optimization']","Yang, Z., Ko, Y. L., Varshney, K. R., & Ying, Y. (2023). Minimax AUC Fairness: Efficient Algorithm with Provable Convergence. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11909-11917. https://doi.org/10.1609/aaai.v37i10.26405","Abstract 					The use of machine learning models in consequential decision making often exacerbates societal inequity, in particular yielding disparate impact on members of marginalized groups defined by race and gender. The area under the ROC curve (AUC) is widely used to evaluate the performance of a scoring function in machine learning, but is studied in algorithmic fairness less than other performance metrics. Due to the pairwise nature of the AUC, defining an AUC-based group fairness metric is pairwise-dependent and may involve both intra-group and inter-group AUCs. Importantly, considering only one category of AUCs is not sufficient to mitigate unfairness in AUC optimization. In this paper, we propose a minimax learning and bias mitigation framework that incorporates both intra-group and inter-group AUCs while maintaining utility. Based on this Rawlsian framework, we design an efficient stochastic optimization algorithm and prove its convergence to the minimum group-level AUC. We conduct numerical experiments on both synthetic and real-world datasets to validate the effectiveness of the minimax framework and the proposed optimization algorithm.","https://ojs.aaai.org/index.php/AAAI/article/view/26405/26177"
"26406","Faster Fair Machine via Transferring Fairness Constraints to Virtual Samples","['Zhou Zhai', 'Lei Luo', 'Heng Huang', 'Bin Gu']","['Nanjing University of Information Science and Technology', 'Nanjing University of Science and Technology', 'University of Pittsburgh', 'Nanjing University of Information Science and Technology\nMBZUAI']","['PEAI: Bias', 'Fairness & Equity']","Zhai, Z., Luo, L., Huang, H., & Gu, B. (2023). Faster Fair Machine via Transferring Fairness Constraints to Virtual Samples. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11918-11925. https://doi.org/10.1609/aaai.v37i10.26406","Abstract 					Fair classification is an emerging and important research topic in machine learning community. Existing methods usually formulate the fairness metrics as additional inequality constraints, and then embed them into the original objective. This makes fair classification problems unable to be effectively tackled by some solvers specific to unconstrained optimization. Although many new tailored algorithms have been designed to attempt to overcome this limitation, they often increase additional computation burden and cannot cope with all types of fairness metrics. To address these challenging issues, in this paper, we propose a novel method for fair classification.  Specifically, we theoretically demonstrate that all types of fairness with linear and non-linear covariance functions can be transferred to two virtual samples, which makes the existing state-of-the-art classification solvers be applicable to these cases. Meanwhile, we  generalize the proposed method to multiple fairness constraints. We take SVM as an example to show the effectiveness of our new idea.  Empirically, we test the proposed method on real-world datasets and all results confirm its excellent performance.","https://ojs.aaai.org/index.php/AAAI/article/view/26406/26178"
"26407","Learning Control Policies for Stochastic Systems with Reach-Avoid Guarantees","['Đorđe Žikelić', 'Mathias Lechner', 'Thomas A. Henzinger', 'Krishnendu Chatterjee']","['IST Austria', 'MIT CSAIL', 'IST Austria', 'IST Austria']","['PEAI: Safety', 'Robustness & Trustworthiness', 'ML: Adversarial Learning & Robustness', 'ML: Calibration & Uncertainty Quantification', 'ML: Probabilistic Methods', 'RU: Other Foundations of Reasoning Under Uncertainty']","Žikelić, Đorđe, Lechner, M., Henzinger, T. A., & Chatterjee, K. (2023). Learning Control Policies for Stochastic Systems with Reach-Avoid Guarantees. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11926-11935. https://doi.org/10.1609/aaai.v37i10.26407","Abstract 					We study the problem of learning controllers for discrete-time non-linear stochastic dynamical systems with formal reach-avoid guarantees. This work presents the first method for providing formal reach-avoid guarantees, which combine and generalize stability and safety guarantees, with a tolerable probability threshold p in [0,1] over the infinite time horizon. Our method leverages advances in machine learning literature and it represents formal certificates as neural networks. In particular, we learn a certificate in the form of a reach-avoid supermartingale (RASM), a novel notion that we introduce in this work. Our RASMs provide reachability and avoidance guarantees by imposing constraints on what can be viewed as a stochastic extension of level sets of Lyapunov functions for deterministic systems. Our approach solves several important problems -- it can be used to learn a control policy from scratch, to verify a reach-avoid specification for a fixed control policy, or to fine-tune a pre-trained policy if it does not satisfy the reach-avoid specification. We validate our approach on 3 stochastic non-linear reinforcement learning tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26407/26179"
"26408","Robust Neuro-Symbolic Goal and Plan Recognition","['Leonardo Amado', 'Ramon Fraga Pereira', 'Felipe Meneguzzi']","['Pontifical Catholic University of Rio Grande do Sul, Brazil', 'University of Manchester, England, UK\nSapienza University of Rome, Italy', 'University of Aberdeen, Scotland, UK\nPontifical Catholic University of Rio Grande do Sul, Brazil']","['PRS: Activity and Plan Recognition', 'ML: Applications']","Amado, L., Fraga Pereira, R., & Meneguzzi, F. (2023). Robust Neuro-Symbolic Goal and Plan Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11937-11944. https://doi.org/10.1609/aaai.v37i10.26408","Abstract 					Goal Recognition is the task of discerning the intended goal of an agent given a sequence of observations, whereas Plan Recognition consists of identifying the plan to achieve such intended goal. Regardless of the underlying techniques, most recognition approaches are directly affected by the quality of the available observations. In this paper, we develop neuro-symbolic recognition approaches that can combine learning and planning techniques, compensating for noise and missing observations using prior data. We evaluate our approaches in standard human-designed planning domains as well as domain models automatically learned from real-world data. Empirical experimentation shows that our approaches reliably infer goals and compute correct plans in the experimental datasets. An ablation study shows that outperform approaches that rely exclusively on the domain model, or exclusively on machine learning in problems with both noisy observations and low observability.","https://ojs.aaai.org/index.php/AAAI/article/view/26408/26180"
"26409","Heuristic Search for Multi-Objective Probabilistic Planning","['Dillon Z. Chen', 'Felipe Trevizan', 'Sylvie Thiébaux']","['The Australian National University', 'The Australian National University', 'The Australian National University\nUniversité de Toulouse']","['PRS: Planning Under Uncertainty', 'PRS: Planning With Markov Models (MDPs', 'POMDPs)']","Chen, D. Z., Trevizan, F., & Thiébaux, S. (2023). Heuristic Search for Multi-Objective Probabilistic Planning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11945-11954. https://doi.org/10.1609/aaai.v37i10.26409","Abstract 					Heuristic search is a powerful approach that has successfully been applied to a broad class of planning problems, including classical planning, multi-objective planning, and probabilistic planning modelled as a stochastic shortest path (SSP) problem. Here, we extend the reach of heuristic search to a more expressive class of problems, namely multi-objective stochastic shortest paths (MOSSPs), which require computing a coverage set of non-dominated policies. We design new heuristic search algorithms MOLAO* and MOLRTDP, which extend well-known SSP algorithms to the multi-objective case. We further construct a spectrum of domain-independent heuristic functions differing in their ability to take into account the stochastic and multi-objective features of the problem to guide the search. Our experiments demonstrate the benefits of these algorithms and the relative merits of the heuristics.","https://ojs.aaai.org/index.php/AAAI/article/view/26409/26181"
"26410","Zero-Knowledge Proofs for Classical Planning Problems","['Augusto B. Corrêa', 'Clemens Büchner', 'Remo Christen']","['University of Basel', 'University of Basel', 'University of Basel']","['PRS: Other Foundations of Planning', 'Routing & Scheduling', 'PRS: Deterministic Planning']","Corrêa, A. B., Büchner, C., & Christen, R. (2023). Zero-Knowledge Proofs for Classical Planning Problems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11955-11962. https://doi.org/10.1609/aaai.v37i10.26410","Abstract 					In classical planning, the aim is to find a sequence of deterministic actions leading from the initial to a goal state. In this work, we consider the scenario where a party who knows the solution to a planning task, called the prover, wants to convince a second party, the verifier, that it has the solution without revealing any information about the solution itself. This is relevant in domains where privacy is important, for example when plans contain sensitive information or when the solution should not be revealed upfront.  We achieve this by introducing a zero-knowledge protocol for plan existence. By restricting ourselves to tasks with polynomially-bounded plan length, we are able to construct a protocol that can be run efficiently by both the prover and verifier. The resulting protocol does not rely on any reduction, has a constant number of rounds, and runs in time polynomial in the size of the task.","https://ojs.aaai.org/index.php/AAAI/article/view/26410/26182"
"26411","Planning with Hidden Parameter Polynomial MDPs","['Clarissa Costen', 'Marc Rigter', 'Bruno Lacerda', 'Nick Hawes']","['University of Oxford', 'University of Oxford', 'University of Oxford', 'University of Oxford']","['PRS: Planning With Markov Models (MDPs', 'POMDPs)', 'PRS: Model-Based Reasoning', 'PRS: Planning Under Uncertainty', 'RU: Sequential Decision Making', 'RU: Stochastic Models & Probabilistic Inference']","Costen, C., Rigter, M., Lacerda, B., & Hawes, N. (2023). Planning with Hidden Parameter Polynomial MDPs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11963-11971. https://doi.org/10.1609/aaai.v37i10.26411","Abstract 					For many applications of Markov Decision Processes (MDPs), the transition function cannot be specified exactly. Bayes-Adaptive MDPs (BAMDPs) extend MDPs to consider transition probabilities governed by latent parameters. To act optimally in BAMDPs, one must maintain a belief distribution over the latent parameters. Typically, this distribution is described by a set of sample (particle) MDPs, and associated weights which represent the likelihood of a sample MDP being the true underlying MDP. However, as the number of dimensions of the latent parameter space increases, the number of sample MDPs required to sufficiently represent the belief distribution grows exponentially. Thus, maintaining an accurate belief in the form of a set of sample MDPs over complex latent spaces is computationally intensive, which in turn affects the performance of planning for these models. In this paper, we propose an alternative approach for maintaining the belief over the latent parameters. We consider a class of BAMDPs where the transition probabilities can be expressed in closed form as a polynomial of the latent parameters, and outline a method to maintain a closed-form belief distribution for the latent parameters which results in an accurate belief representation. Furthermore, the closed-form representation does away with the need to tune the number of sample MDPs required to represent the belief. We evaluate two domains and empirically show that the polynomial, closed-form, belief representation results in better plans than a sampling-based belief representation.","https://ojs.aaai.org/index.php/AAAI/article/view/26411/26183"
"26412","Privacy Attacks on Schedule-Driven Data","['Stephan A. Fahrenkrog-Petersen', 'Arik Senderovich', 'Alexandra Tichauer', 'Ali Kaan Tutak', 'J. Christopher Beck', 'Matthias Weidlich']","['Humboldt-Universität zu Berlin', 'York University', 'Humboldt-Universität zu Berlin', 'Humboldt-Universität zu Berlin', 'University of Toronto', 'Humboldt-Universität zu Berlin']","['PRS: Scheduling', 'PRS: Applications', 'PRS: Planning/Scheduling and Learning']","Fahrenkrog-Petersen, S. A., Senderovich, A., Tichauer, A., Tutak, A. K., Beck, J. C., & Weidlich, M. (2023). Privacy Attacks on Schedule-Driven Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11972-11979. https://doi.org/10.1609/aaai.v37i10.26412","Abstract 					Schedules define how resources process jobs in diverse domains, reaching from healthcare to transportation, and, therefore, denote a valuable starting point for analysis of the underlying system. However, publishing a schedule may disclose private information on the considered jobs. In this paper, we provide a first threat model for published schedules, thereby defining a completely new class of data privacy problems. We then propose distance-based measures to assess the privacy loss incurred by a published schedule, and show their theoretical properties for an uninformed adversary, which can be used as a benchmark for informed attacks. We show how an informed attack on a published schedule can be phrased as an inverse scheduling problem. We instantiate this idea by formulating the inverse of a well-studied single-machine scheduling problem, namely minimizing the total weighted completion times. An empirical evaluation for synthetic scheduling problems shows the effectiveness of informed privacy attacks and compares the results to theoretical bounds on uninformed attacks.","https://ojs.aaai.org/index.php/AAAI/article/view/26412/26184"
"26413","Markov Decision Processes with Time-Varying Geometric Discounting","['Jiarui Gan', 'Annika Hennes', 'Rupak Majumdar', 'Debmalya Mandal', 'Goran Radanovic']","['University of Oxford', 'Heinrich-Heine-University Düsseldorf', 'Max Planck Institute for Software Systems', 'Max Planck Institute for Software Systems', 'Max Planck Institute for Software Systems']","['PRS: Planning With Markov Models (MDPs', 'POMDPs)', 'GTEP: Game Theory', 'RU: Sequential Decision Making']","Gan, J., Hennes, A., Majumdar, R., Mandal, D., & Radanovic, G. (2023). Markov Decision Processes with Time-Varying Geometric Discounting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11980-11988. https://doi.org/10.1609/aaai.v37i10.26413","Abstract 					Canonical models of Markov decision processes (MDPs) usually consider geometric discounting based on a constant discount factor. While this standard modeling approach has led to many elegant results, some recent studies indicate the necessity of modeling time-varying discounting in certain applications. This paper studies a model of infinite-horizon MDPs with time-varying discount factors. We take a game-theoretic perspective – whereby each time step is treated as an independent decision maker with their own (fixed) discount factor – and we study the subgame perfect equilibrium (SPE) of the resulting game as well as the related algorithmic problems. We present a constructive proof of the existence of an SPE and demonstrate the EXPTIME-hardness of computing an SPE. We also turn to the approximate notion of epsilon-SPE and show that an epsilon-SPE exists under milder assumptions. An algorithm is presented to compute an epsilon-SPE, of which an upper bound of the time complexity, as a function of the convergence property of the time-varying discount factor, is provided.","https://ojs.aaai.org/index.php/AAAI/article/view/26413/26185"
"26414","Learning-Augmented Algorithms for Online TSP on the Line","['Themistoklis Gouleakis', 'Konstantinos Lakis', 'Golnoosh Shahkarami']","['National University of Singapore', 'ETH Zurich', 'Max Planck Institute for Informatics, Universitat des Saarlandes']","['PRS: Routing', 'PRS: Optimization of Spatio-Temporal Systems', 'PRS: Planning Under Uncertainty', 'PRS: Temporal Planning', 'RU: Sequential Decision Making']","Gouleakis, T., Lakis, K., & Shahkarami, G. (2023). Learning-Augmented Algorithms for Online TSP on the Line. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11989-11996. https://doi.org/10.1609/aaai.v37i10.26414","Abstract 					We study the online Traveling Salesman Problem (TSP) on the line augmented with machine-learned predictions. In the classical problem, there is a stream of requests released over time along the real line. The goal is to minimize the makespan of the algorithm. We distinguish between the open variant and the closed one, in which we additionally require the algorithm to return to the origin after serving all requests. The state of the art is a 1.64-competitive algorithm and a 2.04-competitive algorithm for the closed and open variants, respectively. In both cases, a tight lower bound is known.  In both variants, our primary prediction model involves predicted positions of the requests. We introduce algorithms that (i) obtain a tight 1.5 competitive ratio for the closed variant and a 1.66 competitive ratio for the open variant in the case of perfect predictions, (ii) are robust against unbounded prediction error, and (iii) are smooth, i.e., their performance degrades gracefully as the prediction error increases.  Moreover, we further investigate the learning-augmented setting in the open variant by additionally considering a prediction for the last request served by the optimal offline algorithm. Our algorithm for this enhanced setting obtains a 1.33 competitive ratio with perfect predictions while also being smooth and robust, beating the lower bound of 1.44 we show for our original prediction setting for the open variant. Also, we provide a lower bound of 1.25 for this enhanced setting.","https://ojs.aaai.org/index.php/AAAI/article/view/26414/26186"
"26415","Networked Restless Bandits with Positive Externalities","['Christine Herlihy', 'John P. Dickerson']","['University of Maryland, College Park', 'University of Maryland, College Park']","['PRS: Planning With Markov Models (MDPs', 'POMDPs)', 'PRS: Planning Under Uncertainty']","Herlihy, C., & Dickerson, J. P. (2023). Networked Restless Bandits with Positive Externalities. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 11997-12004. https://doi.org/10.1609/aaai.v37i10.26415","Abstract 					Restless multi-armed bandits are often used to model budget-constrained resource allocation tasks where receipt of the resource is associated with an increased probability of a favorable state transition. Prior work assumes that individual arms only benefit if they receive the resource directly. However, many allocation tasks occur within communities and can be characterized by positive externalities that allow arms to derive partial benefit when their neighbor(s) receive the resource. We thus introduce networked restless bandits, a novel multi-armed bandit setting in which arms are both restless and embedded within a directed graph. We then present Greta, a graph-aware, Whittle index-based heuristic algorithm that can be used to efficiently construct a constrained reward-maximizing action vector at each timestep. Our empirical results demonstrate that Greta outperforms comparison policies across a range of hyperparameter values and graph topologies. Code and appendices are available at https://github.com/crherlihy/networked_restless_bandits.","https://ojs.aaai.org/index.php/AAAI/article/view/26415/26187"
"26416","Planning for Learning Object Properties","['Leonardo Lamanna', 'Luciano Serafini', 'Mohamadreza Faridghasemnia', 'Alessandro Saffiotti', 'Alessandro Saetti', 'Alfonso Gerevini', 'Paolo Traverso']","['Fondazione Bruno Kessler\nUniversity of Brescia', 'Fondazione Bruno Kessler', 'University of Örebro', 'University of Örebro', 'University of Brescia', 'University of Brescia', 'Fondazione Bruno Kessler']","['PRS: Planning/Scheduling and Learning', 'ROB: Cognitive Robotics', 'KRR: Knowledge Acquisition', 'PRS: Applications']","Lamanna, L., Serafini, L., Faridghasemnia, M., Saffiotti, A., Saetti, A., Gerevini, A., & Traverso, P. (2023). Planning for Learning Object Properties. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12005-12013. https://doi.org/10.1609/aaai.v37i10.26416","Abstract 					Autonomous agents embedded in a physical environment need the ability to recognize objects and their properties from sensory data. Such a perceptual ability is often implemented by supervised machine learning models, which are pre-trained using a set of labelled data. In real-world, open-ended deployments, however, it is unrealistic to assume to have a pre-trained model for all possible environments. Therefore, agents need to dynamically learn/adapt/extend their perceptual abilities online, in an autonomous way, by exploring and interacting with the environment where they operate. This paper describes a way to do so, by exploiting symbolic planning. Specifically, we formalize the problem of automatically training a neural network to recognize object properties as a symbolic planning problem (using PDDL). We use planning techniques to produce a strategy for automating the training dataset creation and the learning process. Finally, we provide an experimental evaluation in both a simulated and a real environment, which shows that the proposed approach is able to successfully learn how to recognize new object properties.","https://ojs.aaai.org/index.php/AAAI/article/view/26416/26188"
"26417","Fully Online Matching with Stochastic Arrivals and Departures","['Zihao Li', 'Hao Wang', 'Zhenzhen Yan']","['Nanyang Technological University', 'Nanyang Technological University', 'Nanyang Technological University']","['PRS: Applications', 'CSO: Applications', 'ML: Applications', 'ML: Online Learning & Bandits', 'ML: Optimization', 'PRS: Planning Under Uncertainty', 'PRS: Planning/Scheduling and Learning', 'PRS: Scheduling']","Li, Z., Wang, H., & Yan, Z. (2023). Fully Online Matching with Stochastic Arrivals and Departures. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12014-12021. https://doi.org/10.1609/aaai.v37i10.26417","Abstract 					We study a fully online matching problem with stochastic arrivals and departures. In this model, each online arrival follows a known identical and independent distribution over a fixed set of agent types. Its sojourn time is unknown in advance and follows type-specific distributions with known expectations. The goal is to maximize the weighted reward from successful matches. To solve this problem, we first propose a linear program (LP)-based algorithm whose competitive ratio is lower bounded by 0.155 under mild conditions. We further achieve better ratios in some special cases. To demonstrate the challenges of the problem, we further establish several hardness results. In particular, we show that no online algorithm can achieve a competitive ratio better than 2/3 in this model and there is no LP-based algorithm (with respect to our proposed LP) with a competitive ratio better than 1/3. Finally, we demonstrate the effectiveness and efficiency of our algorithm numerically.","https://ojs.aaai.org/index.php/AAAI/article/view/26417/26189"
"26418","Towards Automated Modeling Assistance: An Efficient Approach for Repairing Flawed Planning Domains","['Songtuan Lin', 'Alban Grastien', 'Pascal Bercher']","['The Australian National University', 'Australian National University', 'The Australian National University']","['PRS: Deterministic Planning', 'HAI: Human-Computer Interaction', 'PRS: Planning/Scheduling and Learning']","Lin, S., Grastien, A., & Bercher, P. (2023). Towards Automated Modeling Assistance: An Efficient Approach for Repairing Flawed Planning Domains. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12022-12031. https://doi.org/10.1609/aaai.v37i10.26418","Abstract 					Designing a planning domain is a difficult task in AI planning. Assisting tools are thus required if we want planning to be used more broadly. In this paper, we are interested in automatically correcting a flawed domain. In particular, we are concerned with the scenario where a domain contradicts a plan that is known to be valid. Our goal is to repair the domain so as to turn the plan into a solution. Specifically, we consider both grounded and lifted representations support for negative preconditions and show how to explore the space of repairs to find the optimal one efficiently. As an evidence of the efficiency of our approach, the experiment results show that all flawed domains except one in the benchmark set can be repaired optimally by our approach within one second.","https://ojs.aaai.org/index.php/AAAI/article/view/26418/26190"
"26419","Was Fixing This Really That Hard? On the Complexity of Correcting HTN Domains","['Songtuan Lin', 'Pascal Bercher']","['The Australian National University', 'The Australian National University']","['PRS: Deterministic Planning', 'HAI: Human-Computer Interaction', 'PRS: Other Foundations of Planning', 'Routing & Scheduling']","Lin, S., & Bercher, P. (2023). Was Fixing This Really That Hard? On the Complexity of Correcting HTN Domains. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12032-12040. https://doi.org/10.1609/aaai.v37i10.26419","Abstract 					Automated modeling assistance is indispensable to the AI planning being deployed in practice, notably in industry and other non-academic contexts. Yet, little progress has been made that goes beyond smart interfaces like programming environments. They focus on autocompletion, but lack intelligent support for guiding the modeler. As a theoretical foundation of a first step towards this direction, we study the computational complexity of correcting a flawed Hierarchical Task Network (HTN) planning domain. Specifically, a modeler provides a (white) list of plans that are supposed to be solutions, and likewise a (black) list of plans that shall not be solutions. We investigate the complexity of finding a set of (optimal or suboptimal) model corrections so that those plans are (resp. not) solutions to the corrected model. More specifically, we factor out each hardness source that contributes towards NP-hardness, including one that we deem important for many other complexity investigations that go beyond our specific context of application. All complexities range between NP and Sigma-2-p, rising the hope for efficient practical tools in the future.","https://ojs.aaai.org/index.php/AAAI/article/view/26419/26191"
"26420","On Total-Order HTN Plan Verification with Method Preconditions – An Extension of the CYK Parsing Algorithm","['Songtuan Lin', 'Gregor Behnke', 'Simona Ondrčková', 'Roman Barták', 'Pascal Bercher']","['The Australian National University', 'University of Amsterdam', 'Charles University', 'Charles University', 'The Australian National University']","['PRS: Deterministic Planning']","Lin, S., Behnke, G., Ondrčková, S., Barták, R., & Bercher, P. (2023). On Total-Order HTN Plan Verification with Method Preconditions – An Extension of the CYK Parsing Algorithm. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12041-12048. https://doi.org/10.1609/aaai.v37i10.26420","Abstract 					In this paper, we consider the plan verification problem for totally ordered (TO) HTN planning. The problem is proved to be solvable in polynomial time by recognizing its connection to the membership decision problem for context-free grammars. Currently, most HTN plan verification approaches do not have special treatments for the TO configuration, and the only one features such an optimization still relies on an exhaustive search. Hence, we will develop a new TOHTN plan verification approach in this paper by extending the standard CYK parsing algorithm which acts as the best decision procedure in general.","https://ojs.aaai.org/index.php/AAAI/article/view/26420/26192"
"26421","A Dynamics and Task Decoupled Reinforcement Learning Architecture for High-Efficiency Dynamic Target Intercept","['Dora D. Liu', 'Liang Hu', 'Qi Zhang', 'Tangwei Ye', 'Usman Naseem', 'Zhong Yuan Lai']","['DeepBlue Academy of Sciences\nBirenTech Research', 'Tongji University\nDeepBlue Academy of Sciences', 'University of Technology Sydney\nDeepBlue Academy of Sciences', 'DeepBlue Academy of Sciences', 'University of Sydney', 'DeepBlue Academy of Sciences']","['PRS: Applications', 'ROB: Motion and Path Planning', 'ML: Reinforcement Learning Algorithms', 'PRS: Optimization of Spatio-Temporal Systems', 'PRS: Other Foundations of Planning', 'Routing & Scheduling', 'PRS: Planning Under Uncertainty']","Liu, D. D., Hu, L., Zhang, Q., Ye, T., Naseem, U., & Lai, Z. Y. (2023). A Dynamics and Task Decoupled Reinforcement Learning Architecture for High-Efficiency Dynamic Target Intercept. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12049-12057. https://doi.org/10.1609/aaai.v37i10.26421","Abstract 					Due to the flexibility and ease of control, unmanned aerial vehicles (UAVs) have been increasingly used in various scenarios and applications in recent years. Training UAVs with reinforcement learning (RL) for a specific task is often expensive in terms of time and computation. However, it is known that the main effort of the learning process is made to fit the low-level physical dynamics systems instead of the high-level task itself. In this paper, we study to apply UAVs in the dynamic target intercept (DTI) task, where the dynamics systems equipped by different UAV models are correspondingly distinct. To this end, we propose a dynamics and task decoupled RL architecture to address the inefficient learning procedure, where the RL module focuses on modeling the DTI task without involving physical dynamics, and the design of states, actions, and rewards are completely task-oriented while the dynamics control module can adaptively convert actions from the RL module to dynamics signals to control different UAVs without retraining the RL module. We show the efficiency and efficacy of our results in comparison and ablation experiments against state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26421/26193"
"26422","AlphaRoute: Large-Scale Coordinated Route Planning via Monte Carlo Tree Search","['Guiyang Luo', 'Yantao Wang', 'Hui Zhang', 'Quan Yuan', 'Jinglin Li']","['Beijing University of Posts and Telecommunications\nState Key Laboratory of Integrated Services Networks (Xidian University)', 'Beijing University of Posts and Telecommunications', 'Beijing Jiaotong University', 'Beijing University of Posts and Telecommunications\nState Key Laboratory of Integrated Services Networks (Xidian University)', 'Beijing University of Posts and Telecommunications']","['PRS: Routing']","Luo, G., Wang, Y., Zhang, H., Yuan, Q., & Li, J. (2023). AlphaRoute: Large-Scale Coordinated Route Planning via Monte Carlo Tree Search. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12058-12067. https://doi.org/10.1609/aaai.v37i10.26422","Abstract 					This paper proposes AlphaRoute, an AlphaGo inspired algorithm for coordinating large-scale routes, built upon graph attention reinforcement learning and Monte Carlo Tree Search (MCTS). We first partition the road network into regions and model large-scale coordinated route planning as a Markov game, where each partitioned region is treated as a player instead of each driver. Then, AlphaRoute applies a bilevel optimization framework, consisting of several region planners and a global planner, where the region planner coordinates the route choices for vehicles located in the region and generates several strategies, and the global planner evaluates the combination of strategies.  	AlphaRoute is built on graph  attention network for evaluating each state  and MCTS algorithm for dynamically visiting and simulating the future state for narrowing down the search space. AlphaRoute is capable of 1) bridging user fairness and system efficiency, 2) achieving higher search efficiency by alleviating the curse of dimensionality problems, and 3) making an effective and informed route planning by simulating over the future to capture traffic dynamics.  	Comprehensive experiments are conducted on two real-world road networks as compared with several baselines to evaluate the performance, and results show that AlphaRoute achieves the lowest travel time, and is efficient and effective for coordinating large-scale routes and alleviating the traffic congestion problem. The code will be publicly available.","https://ojs.aaai.org/index.php/AAAI/article/view/26422/26194"
"26423","Learning Rational Subgoals from Demonstrations and Instructions","['Zhezheng Luo', 'Jiayuan Mao', 'Jiajun Wu', 'Tomás Lozano-Pérez', 'Joshua B. Tenenbaum', 'Leslie Pack Kaelbling']","['MIT', 'MIT', 'Stanford University', 'MIT', 'MIT', 'MIT']","['PRS: Planning/Scheduling and Learning', 'ROB: Cognitive Robotics']","Luo, Z., Mao, J., Wu, J., Lozano-Pérez, T., Tenenbaum, J. B., & Kaelbling, L. P. (2023). Learning Rational Subgoals from Demonstrations and Instructions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12068-12078. https://doi.org/10.1609/aaai.v37i10.26423","Abstract 					We present a framework for learning useful subgoals that support efficient long-term planning to achieve novel goals. At the core of our framework is a collection of rational subgoals (RSGs), which are essentially binary classifiers over the environmental states. RSGs can be learned from weakly-annotated data, in the form of unsegmented demonstration trajectories, paired with abstract task descriptions, which are composed of terms initially unknown to the agent (e.g., collect-wood then craft-boat then go-across-river). Our framework also discovers dependencies between RSGs, e.g., the task collect-wood is a helpful subgoal for the task craft-boat. Given a goal description, the learned subgoals and the derived dependencies facilitate off-the-shelf planning algorithms, such as A* and RRT, by setting helpful subgoals as waypoints to the planner, which significantly improves performance-time efficiency. Project page: https://rsg.csail.mit.edu","https://ojs.aaai.org/index.php/AAAI/article/view/26423/26195"
"26424","Learning Safe Numeric Action Models","['Argaman Mordoch', 'Brendan Juba', 'Roni Stern']","['Ben Gurion University', 'Washington University in St Louis', 'Ben Gurion University']","['PRS: Planning/Scheduling and Learning', 'ML: Learning Theory', 'PRS: Mixed Discrete/Continuous Planning']","Mordoch, A., Juba, B., & Stern, R. (2023). Learning Safe Numeric Action Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12079-12086. https://doi.org/10.1609/aaai.v37i10.26424","Abstract 					Powerful domain-independent planners have been developed to solve various types of planning problems.  These planners often require a model of the acting agent's actions, given in some planning domain description language.  Yet obtaining such an action model is a notoriously hard task.  This task is even more challenging in mission-critical domains, where a trial-and-error approach to learning how to act is not an option.  In such domains, the action model used to generate plans must be safe, in the sense that plans generated with it must be applicable and achieve their goals.  Learning safe action models for planning has been recently explored for domains in which states are sufficiently described with Boolean variables.  In this work, we go beyond this limitation and propose the NSAM algorithm.  NSAM runs in time that is polynomial in the number of observations and, under certain conditions, is guaranteed to return safe action models.  We analyze its worst-case sample complexity, which may be intractable for some domains. Empirically, however, NSAM can quickly learn a safe action model that can solve most problems in the domain.","https://ojs.aaai.org/index.php/AAAI/article/view/26424/26196"
"26425","Automated Verification of Social Laws in Numeric Settings","['Ronen Nir', 'Alexander Shleyfman', 'Erez Karpas']","['Technion - Israel Institute of Technology', 'Bar-Ilan University', 'Technion - Israel Institute of Technology']","['PRS: Mixed Discrete/Continuous Planning', 'PRS: Deterministic Planning']","Nir, R., Shleyfman, A., & Karpas, E. (2023). Automated Verification of Social Laws in Numeric Settings. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12087-12094. https://doi.org/10.1609/aaai.v37i10.26425","Abstract 					It is possible for agents operating in a shared environment to interfere with one another. One mechanism of coordination is called Social Law. Enacting such a law in a multi-agent setting restricts agents' behaviors. Robustness, in this case, ensures that the agents do not harmfully interfere with each other and that each agent achieves its goals regardless of what other agents do. Previous work on social law verification examined only the case of boolean state variables. However, many real-world problems require reasoning with numeric variables. Moreover, numeric fluents allow a more compact representation of multiple planning problems.  In this paper, we develop a method to verify whether a given social law is robust via compilation to numeric planning. A solution to this compilation constitutes a counterexample to the robustness of the problem, i.e., evidence of cross-agent conflict. Thus, the social law is robust if and only if the proposed compilation is unsolvable. We empirically verify robustness in multiple domains using state-of-the-art numeric planners. Additionally, this compilation raises a challenge by generating a set of non-trivial numeric domains where unsolvability should be either proved or disproved.","https://ojs.aaai.org/index.php/AAAI/article/view/26425/26197"
"26426","Expressive Optimal Temporal Planning via Optimization Modulo Theory","['Stefan Panjkovic', 'Andrea Micheli']","['Fondazione Bruno Kessler\nUniversity of Trento', 'Fondazione Bruno Kessler']","['PRS: Temporal Planning', 'CSO: Constraint Optimization', 'CSO: Mixed Discrete/Continuous Optimization']","Panjkovic, S., & Micheli, A. (2023). Expressive Optimal Temporal Planning via Optimization Modulo Theory. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12095-12102. https://doi.org/10.1609/aaai.v37i10.26426","Abstract 					Temporal Planning is the problem of synthesizing a course of actions given a predictive model of a system subject to temporal constraints. This kind of planning finds natural applications in the automation of industrial processes and in robotics when the timing and deadlines are important. Finding any plan in temporal planning is often not enough as it is sometimes needed to optimize a certain objective function: particularly interesting are the minimization of the makespan and the optimization of the costs of actions. Despite the importance of the problem, only few works in the literature tackled the problem of optimal temporal planning because of the complicated intermix of planning and scheduling. In this paper, we address the problem of optimal temporal planning for a very expressive class of problems using a reduction of the bounded planning problem to Optimization Modulo Theory (OMT) a powerful discrete/continuous optimization framework. We theoretically and empirically show the expressive power of this approach and we set a baseline for future research in this area.","https://ojs.aaai.org/index.php/AAAI/article/view/26426/26198"
"26427","Flexible Budgets in Restless Bandits: A Primal-Dual Algorithm for Efficient Budget Allocation","['Paula Rodriguez Diaz', 'Jackson A. Killian', 'Lily Xu', 'Arun Sai Suggala', 'Aparna Taneja', 'Milind Tambe']","['Harvard University', 'Harvard University', 'Harvard University', 'Google Research', 'Google Research', 'Harvard University\nGoogle Research']","['PRS: Planning With Markov Models (MDPs', 'POMDPs)', 'MAS: Multiagent Planning']","Rodriguez Diaz, P., Killian, J. A., Xu, L., Suggala, A. S., Taneja, A., & Tambe, M. (2023). Flexible Budgets in Restless Bandits: A Primal-Dual Algorithm for Efficient Budget Allocation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12103-12111. https://doi.org/10.1609/aaai.v37i10.26427","Abstract 					Restless multi-armed bandits (RMABs) are an important model to optimize allocation of limited resources in sequential decision-making settings. Typical RMABs assume the budget --- the number of arms pulled --- to be fixed for each step in the planning horizon. However, for realistic real-world planning, resources are not necessarily limited at each planning step; we may be able to distribute surplus resources in one round to an earlier or later round. In real-world planning settings, this flexibility in budget is often constrained to within a subset of consecutive planning steps, e.g., weekly planning of a monthly budget. In this paper we define a general class of RMABs with flexible budget, which we term F-RMABs, and provide an algorithm to optimally solve for them. We derive a min-max formulation to find optimal policies for F-RMABs and leverage gradient primal-dual algorithms to solve for reward-maximizing policies with flexible budgets. We introduce a scheme to sample expected gradients to apply primal-dual algorithms to the F-RMAB setting and make an otherwise computationally expensive approach tractable. Additionally, we provide heuristics that trade off solution quality for efficiency and present experimental comparisons of different F-RMAB solution approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/26427/26199"
"26428","Structurally Restricted Fragments of Numeric Planning – a Complexity Analysis","['Alexander Shleyfman', 'Daniel Gnad', 'Peter Jonsson']","['Bar-Ilan University', 'Linköping University', 'Linköping University']","['PRS: Mixed Discrete/Continuous Planning', 'PRS: Deterministic Planning']","Shleyfman, A., Gnad, D., & Jonsson, P. (2023). Structurally Restricted Fragments of Numeric Planning – a Complexity Analysis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12112-12119. https://doi.org/10.1609/aaai.v37i10.26428","Abstract 					Numeric planning is known to be undecidable even under severe restrictions. Prior work has investigated the decidability boundaries by restricting the expressiveness of the planning formalism in terms of the numeric functions allowed in conditions and effects. We study a well-known restricted form of Hoffmann's simple numeric planning, which is undecidable. We analyze the complexity by imposing restrictions on the causal structure, exploiting a novel method for bounding variable domain sizes. First, we show that plan existence for tasks where all numeric variables are root nodes in the causal graph is in PSPACE. Second, we show that for tasks with only numeric leaf variables the problem is decidable, and that it is in PSPACE if the propositional state space has a fixed size. Our work lays a strong foundation for future investigations of structurally more complex tasks. From a practical perspective, our method allows to employ heuristics and methods that are geared towards finite variable domains (such as pattern database heuristics or decoupled search) to solve non-trivial families of numeric planning problems.","https://ojs.aaai.org/index.php/AAAI/article/view/26428/26200"
"26429","Predicate Invention for Bilevel Planning","['Tom Silver', 'Rohan Chitnis', 'Nishanth Kumar', 'Willie McClinton', 'Tomás Lozano-Pérez', 'Leslie Kaelbling', 'Joshua B. Tenenbaum']","['MIT', 'Meta AI', 'MIT', 'MIT', 'MIT', 'MIT', 'MIT']","['PRS: Planning/Scheduling and Learning', 'ML: Relational Learning', 'PRS: Mixed Discrete/Continuous Planning']","Silver, T., Chitnis, R., Kumar, N., McClinton, W., Lozano-Pérez, T., Kaelbling, L., & Tenenbaum, J. B. (2023). Predicate Invention for Bilevel Planning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12120-12129. https://doi.org/10.1609/aaai.v37i10.26429","Abstract 					Efficient planning in continuous state and action spaces is fundamentally hard, even when the transition model is deterministic and known. One way to alleviate this challenge is to perform bilevel planning with abstractions, where a high-level search for abstract plans is used to guide planning in the original transition space. Previous work has shown that when state abstractions in the form of symbolic predicates are hand-designed, operators and samplers for bilevel planning can be learned from demonstrations. In this work, we propose an algorithm for learning predicates from demonstrations, eliminating the need for manually specified state abstractions. Our key idea is to learn predicates by optimizing a surrogate objective that is tractable but faithful to our real efficient-planning objective. We use this surrogate objective in a hill-climbing search over predicate sets drawn from a grammar. Experimentally, we show across four robotic planning environments that our learned abstractions are able to quickly solve held-out tasks, outperforming six baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/26429/26201"
"26430","Smoothed Online Combinatorial Optimization Using Imperfect Predictions","['Kai Wang', 'Zhao Song', 'Georgios Theocharous', 'Sridhar Mahadevan']","['Harvard University', 'Adobe Research', 'Adobe Research', 'Adobe Research']","['PRS: Planning Under Uncertainty']","Wang, K., Song, Z., Theocharous, G., & Mahadevan, S. (2023). Smoothed Online Combinatorial Optimization Using Imperfect Predictions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12130-12137. https://doi.org/10.1609/aaai.v37i10.26430","Abstract 					Smoothed online combinatorial optimization considers a learner who repeatedly chooses a combinatorial decision to minimize an unknown changing cost function with a penalty on switching decisions in consecutive rounds. We study smoothed online combinatorial optimization problems when an imperfect predictive model is available, where the model can forecast the future cost functions with uncertainty. We show that using predictions to plan for a finite time horizon leads to regret dependent on the total predictive uncertainty and an additional switching cost. This observation suggests choosing a suitable planning window to balance between uncertainty and switching cost, which leads to an online algorithm with guarantees on the upper and lower bounds of the cumulative regret. Empirically, our algorithm shows a significant improvement in cumulative regret compared to other baselines in synthetic online distributed streaming problems.","https://ojs.aaai.org/index.php/AAAI/article/view/26430/26202"
"26431","Scalable Decision-Focused Learning in Restless Multi-Armed Bandits with Application to Maternal and Child Health","['Kai Wang', 'Shresth Verma', 'Aditya Mate', 'Sanket Shah', 'Aparna Taneja', 'Neha Madhiwalla', 'Aparna Hegde', 'Milind Tambe']","['Harvard University', 'Google Research, India', 'Harvard University', 'Harvard University', 'Google Research, India', 'ARMMAN', 'ARMMAN', 'Harvard University\nGoogle Research, India']","['PRS: Planning Under Uncertainty', 'PEAI: Societal Impact of AI', 'PRS: Planning With Markov Models (MDPs', 'POMDPs)', 'PRS: Scheduling Under Uncertainty']","Wang, K., Verma, S., Mate, A., Shah, S., Taneja, A., Madhiwalla, N., Hegde, A., & Tambe, M. (2023). Scalable Decision-Focused Learning in Restless Multi-Armed Bandits with Application to Maternal and Child Health. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12138-12146. https://doi.org/10.1609/aaai.v37i10.26431","Abstract 					This paper studies restless multi-armed bandit (RMAB) problems with unknown arm transition dynamics but with known correlated arm features. The goal is to learn a model to predict transition dynamics given features, where the Whittle index policy solves the RMAB problems using predicted transitions. However, prior works often learn the model by maximizing the predictive accuracy instead of final RMAB solution quality, causing a mismatch between training and evaluation objectives. To address this shortcoming, we propose a novel approach for decision-focused learning in RMAB that directly trains the predictive model to maximize the Whittle index solution quality. We present three key contributions: (i) we establish differentiability of the Whittle index policy to support decision-focused learning; (ii) we significantly improve the scalability of decision-focused learning approaches in sequential problems, specifically RMAB problems; (iii) we apply our algorithm to a previously collected  dataset of maternal and child health to demonstrate its performance. Indeed, our algorithm is the first for decision-focused learning in RMAB that scales to real-world problem sizes.","https://ojs.aaai.org/index.php/AAAI/article/view/26431/26203"
"26432","Neural TSP Solver with Progressive Distillation","['Dongxiang Zhang', 'Ziyang Xiao', 'Yuan Wang', 'Mingli Song', 'Gang Chen']","['Zhejiang University', 'Zhejiang University', 'Singapore University of Social Sciences', 'Zhejiang University', 'Zhejiang University']","['PRS: Planning/Scheduling and Learning', 'ML: Reinforcement Learning Algorithms']","Zhang, D., Xiao, Z., Wang, Y., Song, M., & Chen, G. (2023). Neural TSP Solver with Progressive Distillation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12147-12154. https://doi.org/10.1609/aaai.v37i10.26432","Abstract 					Travelling salesman problem (TSP) is NP-Hard with exponential search space. Recently, the adoption of encoder-decoder models as neural TSP  solvers has emerged as an attractive topic because they can instantly obtain near-optimal results for small-scale instances. Nevertheless, their training efficiency and solution quality degrade dramatically when dealing with large-scale problems. To address the issue, we propose a novel progressive distillation framework, by adopting curriculum learning to train TSP samples in increasing order of their problem size and progressively distilling high-level knowledge from small models to large models via a distillation loss. In other words, the trained small models are used as the teacher network to guide action selection when training large models. To accelerate training speed, we also propose a Delaunary-graph based action mask and a new attention-based decoder to reduce decoding cost. Experimental results show that our approach  establishes clear advantages over existing encoder-decoder models in terms of training effectiveness and solution quality. In addition, we validate its usefulness as an initial solution generator for the state-of-the-art TSP solvers, whose probability of obtaining the optimal solution can be further improved in such a hybrid manner.","https://ojs.aaai.org/index.php/AAAI/article/view/26432/26204"
"26433","The Linear Distance Traveling Tournament Problem Allows an EPTAS","['Jingyang Zhao', 'Mingyu Xiao']","['University of Electronic Science and Technology of China', 'University of Electronic Science and Technology of China']","['PRS: Scheduling', 'PRS: Other Foundations of Planning', 'Routing & Scheduling', 'PRS: Routing']","Zhao, J., & Xiao, M. (2023). The Linear Distance Traveling Tournament Problem Allows an EPTAS. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12155-12162. https://doi.org/10.1609/aaai.v37i10.26433","Abstract 					The Traveling Tournament Problem (TTP-k) is a well-known benchmark problem in tournament timetabling and has been extensively studied in the field of AI. In this problem, we are going to design a double round-robin schedule such that each pair of teams plays one game in each other's home venue, minimizing the total distance traveled by all n teams (n is even) under the constraint that each team can have at most k-consecutive home games or away games. The Linear Distance Traveling Tournament Problem (LDTTP-k), where all teams are located on a line, was introduced by Hoshino and Kawarabayashi (AAAI 2012). For LDTTP-3, they gave a 4/3-approximation algorithm for n≡4 (mod 6) teams. In this paper, we show that for any 3≤k=o(∛n), LDTTP-k allows an efficient polynomial-time approximation scheme (EPTAS).","https://ojs.aaai.org/index.php/AAAI/article/view/26433/26205"
"26434","Learning Relational Causal Models with Cycles through Relational Acyclification","['Ragib Ahsan', 'David Arbour', 'Elena Zheleva']","['University of Illinois at Chicago', 'Adobe Research', 'University of Illinois at Chicago']","['RU: Relational Probabilistic Models', 'RU: Causality']","Ahsan, R., Arbour, D., & Zheleva, E. (2023). Learning Relational Causal Models with Cycles through Relational Acyclification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12164-12171. https://doi.org/10.1609/aaai.v37i10.26434","Abstract 					In real-world phenomena which involve mutual influence or causal effects between interconnected units, equilibrium states are typically represented with cycles in graphical models. An expressive class of graphical models, relational causal models, can represent and reason about complex dynamic systems exhibiting such cycles or feedback loops. Existing cyclic causal discovery algorithms for learning causal models from observational data assume that the data instances are independent and identically distributed which makes them unsuitable for relational causal models. At the same time, causal discovery algorithms for relational causal models assume acyclicity. In this work, we examine the necessary and sufficient conditions under which a constraint-based relational causal discovery algorithm is sound and complete for cyclic relational causal models. We introduce relational acyclification, an operation specifically designed for relational models that enables reasoning about the identifiability of cyclic relational causal models. We show that under the assumptions of relational acyclification and sigma-faithfulness, the relational causal discovery algorithm RCD is sound and complete for cyclic relational models. We present experimental results to support our claim.","https://ojs.aaai.org/index.php/AAAI/article/view/26434/26206"
"26435","Causal Effect Identification in Cluster DAGs","['Tara V. Anand', 'Adele H. Ribeiro', 'Jin Tian', 'Elias Bareinboim']","['Columbia University', 'Columbia University', 'Iowa State University', 'Columbia University']","['RU: Causality', 'RU: Graphical Model']","Anand, T. V., Ribeiro, A. H., Tian, J., & Bareinboim, E. (2023). Causal Effect Identification in Cluster DAGs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12172-12179. https://doi.org/10.1609/aaai.v37i10.26435","Abstract 					Reasoning about the effect of interventions and counterfactuals is a fundamental task found throughout the data sciences. A collection of principles, algorithms, and tools has been developed for performing such tasks in the last decades.  One of the pervasive requirements found throughout this literature is the articulation of assumptions, which commonly appear in the form of causal diagrams. Despite the power of this approach, there are significant settings where the knowledge necessary to specify a causal diagram over all variables is not available, particularly in complex, high-dimensional domains. In this paper, we introduce a new graphical modeling tool called cluster DAGs (for short, C-DAGs) that allows for the partial specification of relationships among variables based on limited prior knowledge, alleviating the stringent requirement of specifying a full causal diagram. A C-DAG specifies relationships between clusters of variables, while the relationships between the variables within a cluster are left unspecified, and can be seen as a graphical representation of an equivalence class of causal diagrams that share the relationships among the clusters. We develop the foundations and machinery for valid inferences over C-DAGs about the clusters of variables at each layer of Pearl's Causal Hierarchy - L1 (probabilistic), L2 (interventional), and L3 (counterfactual).  In particular, we prove the soundness and completeness of d-separation for probabilistic inference in C-DAGs.  Further, we demonstrate the validity of Pearl's do-calculus rules over C-DAGs and show that the standard ID identification algorithm is sound and complete to systematically compute causal effects from observational data given a C-DAG. Finally, we show that C-DAGs are valid for performing counterfactual inferences about clusters of variables.","https://ojs.aaai.org/index.php/AAAI/article/view/26435/26207"
"26436","A Simple Unified Approach to Testing High-Dimensional Conditional Independences for Categorical and Ordinal Data","['Ankur Ankan', 'Johannes Textor']","['Radboud University, Nijmegen', 'Radboud University, Nijmegen']","['RU: Causality', 'RU: Bayesian Networks']","Ankan, A., & Textor, J. (2023). A Simple Unified Approach to Testing High-Dimensional Conditional Independences for Categorical and Ordinal Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12180-12188. https://doi.org/10.1609/aaai.v37i10.26436","Abstract 					Conditional independence (CI) tests underlie many approaches to model testing and structure learning in causal inference. Most existing CI tests for categorical and ordinal data stratify the sample by the conditioning variables, perform simple independence tests in each stratum, and combine the results. Unfortunately, the statistical power of this approach degrades rapidly as the number of conditioning variables increases. Here we propose a simple unified CI test for ordinal and categorical data that maintains reasonable calibration and power in high dimensions. We show that our test outperforms existing baselines in model testing and structure learning for dense directed graphical models while being comparable for sparse models. Our approach could be attractive for causal model testing because it is easy to implement, can be used with non-parametric or parametric probability models, has the symmetry property, and has reasonable computational requirements.","https://ojs.aaai.org/index.php/AAAI/article/view/26436/26208"
"26437","Score-Based Learning of Graphical Event Models with Background Knowledge Augmentation","['Debarun Bhattacharjya', 'Tian Gao', 'Dharmashankar Subramanian', 'Xiao Shou']","['IBM T. J. Watson Research Center', 'IBM T. J. Watson Research Center', 'IBM T. J. Watson Research Center', 'Rensselaer Polytechnic Institute']","['RU: Graphical Model', 'DMKM: Mining of Spatial', 'Temporal or Spatio-Temporal Data', 'ML: Bayesian Learning', 'ML: Graph-based Machine Learning', 'ML: Time-Series/Data Streams']","Bhattacharjya, D., Gao, T., Subramanian, D., & Shou, X. (2023). Score-Based Learning of Graphical Event Models with Background Knowledge Augmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12189-12197. https://doi.org/10.1609/aaai.v37i10.26437","Abstract 					Graphical event models (GEMs) are representations of temporal point process dynamics between different event types. Many real-world applications however involve limited event stream data, making it challenging to learn GEMs from data alone. In this paper, we introduce approaches that can work together in a score-based learning paradigm, to augment data with potentially different types of background knowledge. We propose novel scores for learning an important parametric class of GEMs; in particular, we propose a Bayesian score for leveraging prior information as well as a more practical simplification that involves fewer parameters, analogous to Bayesian networks. We also introduce a framework for incorporating easily assessed qualitative background knowledge from domain experts, in the form of statements such as `event X depends on event Y' or `event Y makes event X more likely'. The proposed framework has Bayesian interpretations and can be deployed by any score-based learner. Through an extensive empirical investigation, we demonstrate the practical benefits of background knowledge augmentation while learning GEMs for applications in the low-data regime.","https://ojs.aaai.org/index.php/AAAI/article/view/26437/26209"
"26438","Entropy Regularization for Population Estimation","['Ben Chugg', 'Peter Henderson', 'Jacob Goldin', 'Daniel E. Ho']","['Carnegie Mellon University', 'Stanford University', 'University of Chicago', 'Stanford University']","['RU: Sequential Decision Making', 'ML: Active Learning', 'ML: Online Learning & Bandits']","Chugg, B., Henderson, P., Goldin, J., & Ho, D. E. (2023). Entropy Regularization for Population Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12198-12204. https://doi.org/10.1609/aaai.v37i10.26438","Abstract 					Entropy regularization is known to improve exploration in sequential decision-making problems. We show that this same mechanism can also lead to nearly unbiased and lower-variance estimates of the mean reward in the optimize-and-estimate structured bandit setting. Mean reward estimation (i.e., population estimation) tasks have recently been shown to be essential for public policy settings where legal constraints often require precise estimates of population metrics. We show that leveraging entropy and KL divergence can yield a better trade-off between reward and estimator variance than existing baselines, all while remaining nearly unbiased. These properties of entropy regularization illustrate an exciting potential for bringing together the optimal exploration and estimation literature.","https://ojs.aaai.org/index.php/AAAI/article/view/26438/26210"
"26439","Principled and Efficient Motif Finding for Structure Learning of Lifted Graphical Models","['Jonathan Feldstein', 'Dominic Phillips', 'Efthymia Tsamoura']","['University of Edinburgh\nBENNU.AI', 'University of Edinburgh', 'Samsung AI Research']","['RU: Relational Probabilistic Models', 'KRR: Logic Programming', 'RU: Graphical Model']","Feldstein, J., Phillips, D., & Tsamoura, E. (2023). Principled and Efficient Motif Finding for Structure Learning of Lifted Graphical Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12205-12215. https://doi.org/10.1609/aaai.v37i10.26439","Abstract 					Structure learning is a core problem in AI central to the fields of neuro-symbolic AI and statistical relational learning. It consists in automatically learning a logical theory from data. The basis for structure learning is mining repeating patterns in the data, known as structural motifs. Finding these patterns reduces the exponential search space and therefore guides the learning of formulas. Despite the importance of motif learning, it is still not well understood. We present the first principled approach for mining structural motifs in lifted graphical models, languages that blend first-order logic with probabilistic models,  which uses a stochastic process to measure the similarity of entities in the data.   Our first contribution is an algorithm, which depends on two intuitive hyperparameters: one controlling the uncertainty in the entity similarity measure, and one controlling the softness of the resulting rules. Our second contribution is a preprocessing step where we perform hierarchical clustering on the data to reduce the search space to the most relevant data. Our third contribution is to introduce an O(n ln(n)) (in the size of the entities in the data) algorithm for clustering structurally-related data. We evaluate our approach using standard benchmarks and show that we outperform state-of-the-art structure learning approaches by up to 6% in terms of accuracy and up to 80% in terms of runtime.","https://ojs.aaai.org/index.php/AAAI/article/view/26439/26211"
"26440","A Faster Practical Approximation Scheme for the Permanent","['Juha Harviainen', 'Mikko Koivisto']","['University of Helsinki', 'University of Helsinki']","['RU: Stochastic Models & Probabilistic Inference', 'CSO: Search', 'SO: Evaluation and Analysis', 'SO: Sampling/Simulation-Based Search']","Harviainen, J., & Koivisto, M. (2023). A Faster Practical Approximation Scheme for the Permanent. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12216-12224. https://doi.org/10.1609/aaai.v37i10.26440","Abstract 					The permanent of a matrix has numerous applications but is notoriously hard to compute. While nonnegative matrices admit polynomial approximation schemes based on rapidly mixing Markov chains, the known practical estimators of the permanent rely on importance or rejection sampling. We advance the rejection sampling approach, which provides probabilistic accuracy guarantees, unlike importance sampling. Specifically, we give a novel class of nesting upper bounds and a simple preprocessing method that, in comparison to previous works, enable faster sampling with better acceptance rate; we demonstrate order-of-magnitude improvements with both theoretical and empirical analyses. In addition, we display instances on which our approximation scheme is competitive against state-of-the-art importance sampling based estimators.","https://ojs.aaai.org/index.php/AAAI/article/view/26440/26212"
"26441","Neural Diffeomorphic Non-uniform B-spline Flows","['Seongmin Hong', 'Se Young Chun']","['Seoul National University', 'Seoul National University']","['RU: Stochastic Models & Probabilistic Inference', 'ML: Probabilistic Methods', 'RU: Uncertainty Representations']","Hong, S., & Chun, S. Y. (2023). Neural Diffeomorphic Non-uniform B-spline Flows. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12225-12233. https://doi.org/10.1609/aaai.v37i10.26441","Abstract 					Normalizing flows have been successfully modeling a complex probability distribution as an invertible transformation of a simple base distribution. However, there are often applications that require more than invertibility. For instance, the computation of energies and forces in physics requires the second derivatives of the transformation to be well-defined and continuous. Smooth normalizing flows employ infinitely differentiable transformation, but with the price of slow non-analytic inverse transforms. In this work, we propose diffeomorphic non-uniform B-spline flows that are at least twice continuously differentiable while bi-Lipschitz continuous, enabling efficient parametrization while retaining analytic inverse transforms based on a sufficient condition for diffeomorphism. Firstly, we investigate the sufficient condition for C(k-2)-diffeomorphic non-uniform kth-order B-spline transformations. Then, we derive an analytic inverse transformation of the non-uniform cubic B-spline transformation for neural diffeomorphic non-uniform B-spline flows. Lastly, we performed experiments on solving the force matching problem in Boltzmann generators, demonstrating that our C2-diffeomorphic non-uniform B-spline flows yielded solutions better than previous spline flows and faster than smooth normalizing flows. Our source code is publicly available at https://github.com/smhongok/Non-uniform-B-spline-Flow.","https://ojs.aaai.org/index.php/AAAI/article/view/26441/26213"
"26442","Identification and Estimation of the Probabilities of Potential Outcome Types Using Covariate Information in Studies with Non-compliance","['Yuta Kawakami', 'Ryusei Shingaki', 'Manabu Kuroki']","['Yokohama National University', 'Yokohama National University', 'Yokohama National University']","['RU: Causality']","Kawakami, Y., Shingaki, R., & Kuroki, M. (2023). Identification and Estimation of the Probabilities of Potential Outcome Types Using Covariate Information in Studies with Non-compliance. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12234-12242. https://doi.org/10.1609/aaai.v37i10.26442","Abstract 					We propose novel identification conditions and a statistical estimation method for the probabilities of potential outcome types using covariate information in randomized trials in which the treatment assignment is randomized but subject compliance is not perfect. Different from existing studies, the proposed identification conditions do not require strict assumptions such as the assumption of monotonicity. When the probabilities of potential outcome types are identifiable through the proposed conditions, the problem of estimating the probabilities of potential outcome types is reduced to that of singular models. Thus, the probabilities cannot be evaluated using standard statistical likelihood-based estimation methods. Rather, the proposed identification conditions show that we can derive consistent estimators of the probabilities of potential outcome types via the method of moments, which leads to the asymptotic normality of the proposed estimators through the delta method under regular conditions. We also propose a new statistical estimation method based on the bounded constrained augmented Lagrangian method to derive more efficient estimators than can be derived through the method of moments.","https://ojs.aaai.org/index.php/AAAI/article/view/26442/26214"
"26443","Computing Divergences between Discrete Decomposable Models","['Loong Kuan Lee', 'Nico Piatkowski', 'François Petitjean', 'Geoffrey I. Webb']","['Monash University', 'Fraunhofer IAIS', 'Monash University', 'Monash University']","['RU: Graphical Model', 'RU: Stochastic Models & Probabilistic Inference']","Lee, L. K., Piatkowski, N., Petitjean, F., & Webb, G. I. (2023). Computing Divergences between Discrete Decomposable Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12243-12251. https://doi.org/10.1609/aaai.v37i10.26443","Abstract 					There are many applications that benefit from computing the exact divergence between 2 discrete probability measures, including machine learning. Unfortunately, in the absence of any assumptions on the structure or independencies within these distributions, computing the divergence between them is an intractable problem in high dimensions. We show that we are able to compute a wide family of functionals and divergences, such as the alpha-beta divergence, between two decomposable models, i.e. chordal Markov networks, in time exponential to the treewidth of these models. The alpha-beta divergence is a family of divergences that include popular divergences such as the Kullback-Leibler divergence, the Hellinger distance, and the chi-squared divergence. Thus, we can accurately compute the exact values of any of this broad class of divergences to the extent to which we can accurately model the two distributions using decomposable models.","https://ojs.aaai.org/index.php/AAAI/article/view/26443/26215"
"26444","Out-of-Distribution Generalization by Neural-Symbolic Joint Training","['Anji Liu', 'Hongming Xu', 'Guy Van den Broeck', 'Yitao Liang']","['Computer Science Department, University of California, Los Angeles', 'Beijing Institute of General Artificial Intelligence (BIGAI)', 'Computer Science Department, University of California, Los Angeles', 'Institute for Artificial Intelligence, Peking University\nBeijing Institute of General Artificial Intelligence (BIGAI)']","['RU: Graphical Model', 'KRR: Automated Reasoning and Theorem Proving', 'KRR: Logic Programming']","Liu, A., Xu, H., Van den Broeck, G., & Liang, Y. (2023). Out-of-Distribution Generalization by Neural-Symbolic Joint Training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12252-12259. https://doi.org/10.1609/aaai.v37i10.26444","Abstract 					This paper develops a novel methodology to simultaneously learn a neural network and extract generalized logic rules. Different from prior neural-symbolic methods that require background knowledge and candidate logical rules to be provided, we aim to induce task semantics with minimal priors. This is achieved by a two-step learning framework that iterates between optimizing neural predictions of task labels and searching for a more accurate representation of the hidden task semantics. Notably, supervision works in both directions: (partially) induced task semantics guide the learning of the neural network and induced neural predictions admit an improved semantic representation. We demonstrate that our proposed framework is capable of achieving superior out-of-distribution generalization performance on two tasks: (i) learning multi-digit addition, where it is trained on short sequences of digits and tested on long sequences of digits; (ii) predicting the optimal action in the Tower of Hanoi, where the model is challenged to discover a policy independent of the number of disks in the puzzle.","https://ojs.aaai.org/index.php/AAAI/article/view/26444/26216"
"26445","Novel Ordering-Based Approaches for Causal Structure Learning in the Presence of Unobserved Variables","['Ehsan Mokhtarian', 'Mohmmadsadegh Khorasani', 'Jalal Etesami', 'Negar Kiyavash']","['EPFL, Switzerland', 'EPFL, Switzerland', 'EPFL, Switzerland', 'EPFL, Switzerland']","['RU: Causality', 'ML: Causal Learning', 'ML: Representation Learning', 'RU: Graphical Model']","Mokhtarian, E., Khorasani, M., Etesami, J., & Kiyavash, N. (2023). Novel Ordering-Based Approaches for Causal Structure Learning in the Presence of Unobserved Variables. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12260-12268. https://doi.org/10.1609/aaai.v37i10.26445","Abstract 					We propose ordering-based approaches for learning the maximal ancestral graph (MAG) of a structural equation model (SEM) up to its Markov equivalence class (MEC) in the presence of unobserved variables. Existing ordering-based methods in the literature recover a graph through learning a causal order (c-order). We advocate for a novel order called removable order (r-order) as they are advantageous over c-orders for structure learning. This is because r-orders are the minimizers of an appropriately defined optimization problem that could be either solved exactly (using a reinforcement learning approach) or approximately (using a hill-climbing search). Moreover, the r-orders (unlike c-orders) are invariant among all the graphs in a MEC and include c-orders as a subset. Given that set of r-orders is often significantly larger than the set of c-orders, it is easier for the optimization problem to find an r-order instead of a c-order. We evaluate the performance and the scalability of our proposed approaches on both real-world and randomly generated networks.","https://ojs.aaai.org/index.php/AAAI/article/view/26445/26217"
"26446","Maximizing the Probability of Fixation in the Positional Voter Model","['Petros Petsinis', 'Andreas Pavlogiannis', 'Panagiotis Karras']","['Aarhus University', 'Aarhus University', 'Aarhus University']","['RU: Stochastic Optimization', 'CSO: Constraint Optimization', 'DMKM: Graph Mining', 'Social Network Analysis & Community Mining', 'APP: Bioinformatics', 'APP: Social Networks', 'MAS: Multiagent Systems Under Uncertainty', 'RU: Stochastic Models & Probabilistic Inference', 'SO: Evolutionary Computation', 'SO: Other Foundations of Search & Optimization']","Petsinis, P., Pavlogiannis, A., & Karras, P. (2023). Maximizing the Probability of Fixation in the Positional Voter Model. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12269-12277. https://doi.org/10.1609/aaai.v37i10.26446","Abstract 					The Voter model is a well-studied stochastic process that models the invasion of a novel trait A (e.g., a new opinion, social meme, genetic mutation, magnetic spin) in a network of individuals (agents, people, genes, particles) carrying an existing resident trait B. Individuals change traits by occasionally sampling the trait of a neighbor, while an invasion bias δ ≥ 0 expresses the stochastic preference to adopt the novel trait A over the resident trait B. The strength of an invasion is measured by the probability that eventually the whole population adopts trait A, i.e., the fixation probability. In more realistic settings, however, the invasion bias is not ubiquitous, but rather manifested only in parts of the network. For instance, when modeling the spread of a social trait, the invasion bias represents localized incentives. In this paper, we generalize the standard biased Voter model to the positional Voter model, in which the invasion bias is effectuated only on an arbitrary subset of the network nodes, called biased nodes. We study the ensuing optimization problem, which is, given a budget k, to choose k biased nodes so as to maximize the fixation probability of a randomly occurring invasion. We show that the problem is NP-hard both for finite δ and when δ → ∞ (strong bias), while the objective function is not submodular in either setting, indicating strong computational hardness. On the other hand, we show that, when δ → 0 (weak bias), we can obtain a tight approximation in O(n^2ω ) time, where ω is the matrix-multiplication exponent. We complement our theoretical results with an experimental evaluation of some proposed heuristics.","https://ojs.aaai.org/index.php/AAAI/article/view/26446/26218"
"26447","Certifying Fairness of Probabilistic Circuits","['Nikil Roashan Selvam', 'Guy Van den Broeck', 'YooJung Choi']","['University of California, Los Angeles', 'University of California, Los Angeles', 'Arizona State University']","['RU: Stochastic Models & Probabilistic Inference', 'ML: Bias and Fairness']","Selvam, N. R., Van den Broeck, G., & Choi, Y. (2023). Certifying Fairness of Probabilistic Circuits. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12278-12286. https://doi.org/10.1609/aaai.v37i10.26447","Abstract 					With the increased use of machine learning systems for decision making, questions about the fairness properties of such systems start to take center stage. Most existing work on algorithmic fairness assume complete observation of features at prediction time, as is the case for popular notions like statistical parity and equal opportunity. However, this is not sufficient for models that can make predictions with partial observation as we could miss patterns of bias and incorrectly certify a model to be fair. To address this, a recently introduced notion of fairness asks whether the model exhibits any discrimination pattern, in which an individual—characterized by (partial) feature observations—receives vastly different decisions merely by disclosing one or more sensitive attributes such as gender and race. By explicitly accounting for partial observations, this provides a much more fine-grained notion of fairness.  In this paper, we propose an algorithm to search for discrimination patterns in a general class of probabilistic models, namely probabilistic circuits. Previously, such algorithms were limited to naive Bayes classifiers which make strong independence assumptions; by contrast, probabilistic circuits provide a unifying framework for a wide range of tractable probabilistic models and can even be compiled from certain classes of Bayesian networks and probabilistic programs, making our method much more broadly applicable. Furthermore, for an unfair model, it may be useful to quickly find discrimination patterns and distill them for better interpretability. As such, we also propose a sampling-based approach to more efficiently mine discrimination patterns, and introduce new classes of patterns such as minimal, maximal, and Pareto optimal patterns that can effectively summarize exponentially many discrimination patterns.","https://ojs.aaai.org/index.php/AAAI/article/view/26447/26219"
"26448","Probabilities of Potential Outcome Types in Experimental Studies: Identification and Estimation Based on Proxy Covariate Information","['Ryusei Shingaki', 'Manabu Kuroki']","['Yokohama National University', 'Yokohama National University']","['RU: Causality']","Shingaki, R., & Kuroki, M. (2023). Probabilities of Potential Outcome Types in Experimental Studies: Identification and Estimation Based on Proxy Covariate Information. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12287-12294. https://doi.org/10.1609/aaai.v37i10.26448","Abstract 					The concept of potential outcome types is one of the fundamental components of causal inference. However, even in randomized experiments, assumptions on the data generating process, such as monotonicity, are required to evaluate the probabilities of the potential outcome types. To solve the problem without such assumptions in experimental studies, a novel identification condition based on proxy covariate information is proposed in this paper. In addition, the estimation problem of the probabilities of the potential outcome types reduces to that of singular models when they are identifiable through the proposed condition. Thus, they cannot be evaluated by standard statistical estimation methods. To overcome this difficulty, new plug-in estimators of these probabilities are presented, and the asymptotic normality of the proposed estimators is shown.","https://ojs.aaai.org/index.php/AAAI/article/view/26448/26220"
"26449","Lifted Inference with Linear Order Axiom","['Jan Tóth', 'Ondřej Kuželka']","['Czech Technical University in Prague', 'Czech Technical University in Prague']","['RU: Relational Probabilistic Models']","Tóth, J., & Kuželka, O. (2023). Lifted Inference with Linear Order Axiom. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12295-12304. https://doi.org/10.1609/aaai.v37i10.26449","Abstract 					We consider the task of weighted first-order model counting (WFOMC) used for probabilistic inference in the area of statistical relational learning. Given a formula φ, domain size n and a pair of weight functions, what is the weighted sum of all models of φ over a domain of size n? It was shown that computing WFOMC of any logical sentence with at most two logical variables can be done in time polynomial in n. However, it was also shown that the task is #P1-complete once we add the third variable, which inspired the search for extensions of the two-variable fragment that would still permit a running time polynomial in n. One of such extension is the two-variable fragment with counting quantifiers. In this paper, we prove that adding a linear order axiom (which forces one of the predicates in φ to introduce a linear ordering of the domain elements in each model of φ) on top of the counting quantifiers still permits a computation time polynomial in the domain size. We present a new dynamic programming-based algorithm which can compute WFOMC with linear order in time polynomial in n, thus proving our primary claim.","https://ojs.aaai.org/index.php/AAAI/article/view/26449/26221"
"26450","Vector Causal Inference between Two Groups of Variables","['Jonas Wahl', 'Urmi Ninad', 'Jakob Runge']","['Technische Universität Berlin\nDLR Institut für Datenwissenschaften Jena', 'Technische Universität Berlin\nDLR Institut für Datenwissenschaften Jena', 'Technische Universität Berlin\nDLR Institut für Datenwissenschaften Jena']","['RU: Causality', 'KRR: Action', 'Change', 'and Causality', 'ML: Causal Learning', 'RU: Graphical Model']","Wahl, J., Ninad, U., & Runge, J. (2023). Vector Causal Inference between Two Groups of Variables. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12305-12312. https://doi.org/10.1609/aaai.v37i10.26450","Abstract 					Methods to identify cause-effect relationships currently mostly assume the variables to be scalar random variables. However, in many fields the objects of interest are vectors or groups of scalar variables. We present a new constraint-based non-parametric approach for inferring the causal relationship between two vector-valued random variables from observational data. Our method employs sparsity estimates of directed and undirected graphs and is based on two new principles for groupwise causal reasoning that we justify theoretically in Pearl's graphical model-based causality framework. Our theoretical considerations are complemented by two new causal discovery algorithms for causal interactions between two random vectors which find the correct causal direction reliably in simulations even if interactions are nonlinear. We evaluate our methods empirically and compare them to other state-of-the-art techniques.","https://ojs.aaai.org/index.php/AAAI/article/view/26450/26222"
"26451","Efficient Enumeration of Markov Equivalent DAGs","['Marcel Wienöbst', 'Malte Luttermann', 'Max Bannach', 'Maciej Liskiewicz']","['Universität zu Lübeck', 'Universität zu Lübeck', 'Universität zu Lübeck', 'Universität zu Lübeck']","['RU: Causality', 'ML: Causal Learning', 'RU: Bayesian Networks', 'RU: Graphical Model']","Wienöbst, M., Luttermann, M., Bannach, M., & Liskiewicz, M. (2023). Efficient Enumeration of Markov Equivalent DAGs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12313-12320. https://doi.org/10.1609/aaai.v37i10.26451","Abstract 					Enumerating the directed acyclic graphs (DAGs) of a Markov equivalence class (MEC) is an important primitive in causal analysis. The central resource from the perspective of computational complexity is the delay, that is, the time an algorithm that lists all members of the class requires between two consecutive outputs. Commonly used algorithms for this task utilize the rules proposed by Meek (1995) or the transformational characterization by Chickering (1995), both resulting in superlinear delay. In this paper, we present the first linear-time delay algorithm. On the theoretical side, we show that our algorithm can be generalized to enumerate DAGs represented by models that incorporate background knowledge, such as MPDAGs; on the practical side, we provide an efficient implementation and evaluate it in a series of experiments. Complementary to the linear-time delay algorithm, we also provide intriguing insights into Markov equivalence itself: All members of an MEC can be enumerated such that two successive DAGs have structural Hamming distance at most three.","https://ojs.aaai.org/index.php/AAAI/article/view/26451/26223"
"26452","Differentially Private Nonlinear Causal Discovery from Numerical Data","['Hao Zhang', 'Yewei Xia', 'Yixin Ren', 'Jihong Guan', 'Shuigeng Zhou']","['Fudan University', 'Fudan University', 'Fudan University', 'Tongji University', 'Fudan University']","['RU: Causality', 'ML: Causal Learning', 'ML: Privacy-Aware ML']","Zhang, H., Xia, Y., Ren, Y., Guan, J., & Zhou, S. (2023). Differentially Private Nonlinear Causal Discovery from Numerical Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12321-12328. https://doi.org/10.1609/aaai.v37i10.26452","Abstract 					Recently, several methods such as private ANM, EM-PC and Priv-PC have been proposed to perform differentially private causal discovery in various scenarios including bivariate, multivariate Gaussian and categorical cases. However, there is little effort on how to conduct private nonlinear causal discovery from numerical data. This work tries to challenge this problem. To this end, we propose a method to infer nonlinear causal relations from observed numerical data by using regression-based conditional independence test (RCIT) that consists of kernel ridge regression (KRR) and Hilbert-Schmidt independence criterion (HSIC) with permutation approximation. Sensitivity analysis for RCIT is given and a private constraint-based causal discovery framework with differential privacy guarantee is developed. Extensive simulations and real-world experiments for both conditional independence test and causal discovery are conducted, which show that our method is effective in handling nonlinear numerical cases and easy to implement. The source code of our method and data are available at https://github.com/Causality-Inference/PCD.","https://ojs.aaai.org/index.php/AAAI/article/view/26452/26224"
"26453","Safe Interval Path Planning with Kinodynamic Constraints","['Zain Alabedeen Ali', 'Konstantin Yakovlev']","['Moscow Institute of Physics and Technology', 'Federal Research Center for Computer Science and Control RAS\nAIRI']","['SO: Heuristic Search', 'ROB: Motion and Path Planning']","Ali, Z. A., & Yakovlev, K. (2023). Safe Interval Path Planning with Kinodynamic Constraints. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12330-12337. https://doi.org/10.1609/aaai.v37i10.26453","Abstract 					Safe Interval Path Planning (SIPP) is a powerful algorithm for solving a single-agent pathfinding problem where the agent is confined to a graph and certain vertices/edges of this graph are blocked at certain time intervals due to dynamic obstacles that populate the environment. The original SIPP algorithm relies on the assumption that the agent is able to stop instantaneously. However, this assumption often does not hold in practice, e.g. a mobile robot moving at a cruising speed cannot stop immediately but rather requires gradual deceleration to a full stop that takes time. In other words, the robot is subject to kinodynamic constraints. Unfortunately, as we show in this work, in such a case, the original SIPP is incomplete. To this end, we introduce a novel variant of SIPP that is provably complete and optimal for planning with acceleration/deceleration. In the experimental evaluation, we show that the key property of the original SIPP still holds for the modified version: it performs much fewer expansions compared to A* and, as a result, is notably faster.","https://ojs.aaai.org/index.php/AAAI/article/view/26453/26225"
"26454","Diversity Maximization in the Presence of Outliers","['Daichi Amagata']","['Osaka University']","['SO: Other Foundations of Search & Optimization', 'CSO: Constraint Optimization', 'DMKM: Scalability', 'Parallel & Distributed Systems']","Amagata, D. (2023). Diversity Maximization in the Presence of Outliers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12338-12345. https://doi.org/10.1609/aaai.v37i10.26454","Abstract 					Given a set X of n points in a metric space, the problem of diversity maximization is to extract a set S of k points from X so that the diversity of S is maximized. This problem is essential in AI-related fields, such as web search, databases, recommender systems, and data mining. Although there have been extensive studies of this problem, these studies assume that X is clean. This usually does not hold, because real-world datasets usually contain outliers. The state-of-the-art algorithm for the diversity maximization problem is based on furthest point retrieval, which is too sensitive to outliers. We therefore address the problem of diversity maximization with outliers and propose two algorithms with performance guarantee. The first algorithm runs in O((k+z)n) time, guarantees 1/2-approximation, and returns no outliers, where z is the number of outliers. The second algorithm runs in O(kz) time (which is independent of n), guarantees 1/6(1+epsilon)-approximation, and returns no outliers with constant probability. We conduct experiments on real datasets to demonstrate the effectiveness and efficiency of our algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26454/26226"
"26455","Fair Short Paths in Vertex-Colored Graphs","['Matthias Bentert', 'Leon Kellerhals', 'Rolf Niedermeier']","['Technische Universität Berlin', 'Technische Universität Berlin', 'Technische Universität Berlin']","['SO: Mixed Discrete/Continuous Search', 'GTEP: Coordination and Collaboration']","Bentert, M., Kellerhals, L., & Niedermeier, R. (2023). Fair Short Paths in Vertex-Colored Graphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12346-12354. https://doi.org/10.1609/aaai.v37i10.26455","Abstract 					The computation of short paths in graphs with arc lengths is a pillar of graph algorithmics and network science. In a more diverse world, however, not every short path is equally valuable. For the setting where each vertex is assigned to a group (color), we provide a framework to model multiple natural fairness aspects. We seek to find short paths in which the number of occurrences of each color is within some given lower and upper bounds. Among other results, we prove the introduced problems to be computationally intractable (NP-hard and parameterized hard with respect to the number of colors) even in very restricted settings (such as each color should appear with exactly the same frequency), while also presenting an encouraging algorithmic result (""fixed-parameter tractability"") related to the length of the sought solution path for the general problem.","https://ojs.aaai.org/index.php/AAAI/article/view/26455/26227"
"26456","AC-Band: A Combinatorial Bandit-Based Approach to Algorithm Configuration","['Jasmin Brandt', 'Elias Schede', 'Björn Haddenhorst', 'Viktor Bengs', 'Eyke Hüllermeier', 'Kevin Tierney']","['Department of Computer Science, Paderborn University, Germany', 'Decision and Operation Technologies Group, Bielefeld University, Germany', 'Department of Computer Science, Paderborn University, Germany', 'Institute of Informatics, LMU Munich, Germany\nMunich Center for Machine Learning (MCML), Germany', 'Institute of Informatics, LMU Munich, Germany\nMunich Center for Machine Learning (MCML), Germany', 'Decision and Operation Technologies Group, Bielefeld University, Germany']","['SO: Algorithm Configuration', 'ML: Online Learning & Bandits']","Brandt, J., Schede, E., Haddenhorst, B., Bengs, V., Hüllermeier, E., & Tierney, K. (2023). AC-Band: A Combinatorial Bandit-Based Approach to Algorithm Configuration. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12355-12363. https://doi.org/10.1609/aaai.v37i10.26456","Abstract 					We study the algorithm configuration (AC) problem, in which one seeks to find an optimal parameter configuration of a given target algorithm in an automated way. Although this field of research has experienced much progress recently regarding approaches satisfying strong theoretical guarantees, there is still a gap between the practical performance of these approaches and the heuristic state-of-the-art approaches. Recently, there has been significant progress in designing AC approaches that satisfy strong theoretical guarantees. However, a significant gap still remains between the practical performance of these approaches and state-of-the-art heuristic methods. To this end, we introduce AC-Band, a general approach for the AC problem based on multi-armed bandits that provides theoretical guarantees while exhibiting strong practical performance. We show that AC-Band requires significantly less computation time than other AC approaches providing theoretical guarantees while still yielding high-quality configurations.","https://ojs.aaai.org/index.php/AAAI/article/view/26456/26228"
"26457","GRASMOS: Graph Signage Model Selection for Gene Regulatory Networks","['Angelina Brilliantova', 'Hannah Miller', 'Ivona Bezáková']","['Rochester Institute of Technology', 'Rochester Institute of Technology', 'Rochester Institute of Technology']","['SO: Sampling/Simulation-Based Search', 'APP: Bioinformatics', 'ML: Graph-based Machine Learning']","Brilliantova, A., Miller, H., & Bezáková, I. (2023). GRASMOS: Graph Signage Model Selection for Gene Regulatory Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12364-12372. https://doi.org/10.1609/aaai.v37i10.26457","Abstract 					Signed networks (networks with positive and negative edges) commonly arise in various domains from molecular biology to social media.  The edge signs -- i.e., the graph signage -- represent the interaction pattern between the vertices and can provide insights into the underlying system formation process. Generative models considering signage formation are essential for testing hypotheses about the emergence of interactions and for creating synthetic datasets for algorithm benchmarking (especially in areas where obtaining real-world datasets is difficult).  In this work, we pose a novel Maximum-Likelihood-based optimization problem for modeling signages given their topology and showcase it in the context of gene regulation. Regulatory interactions of genes play a key role in the process of organism development, and when broken can lead to serious organism abnormalities and diseases.  Our contributions are threefold: First, we design a new class of signage models for a given topology, and, based on the parameter setting, we discuss its biological interpretations for gene regulatory networks (GRNs). Second, we design algorithms computing the Maximum Likelihood -- depending on the parameter setting, our algorithms range from closed-form expressions to MCMC sampling. Third, we evaluated the results of our algorithms on synthetic datasets and real-world large GRNs. Our work can lead to the prediction of unknown gene regulations, novel biological hypotheses, and realistic benchmark datasets in the realm of gene regulation.","https://ojs.aaai.org/index.php/AAAI/article/view/26457/26229"
"26458","Optimal Pathfinding on Weighted Grid Maps","['Mark Carlson', 'Sajjad K. Moghadam', 'Daniel D. Harabor', 'Peter J. Stuckey', 'Morteza Ebrahimi']","['Monash University', 'University of Tehran', 'Monash University', 'Monash University', 'University of Tehran']","['SO: Heuristic Search', 'ROB: Motion and Path Planning', 'PRS: Routing']","Carlson, M., Moghadam, S. K., Harabor, D. D., Stuckey, P. J., & Ebrahimi, M. (2023). Optimal Pathfinding on Weighted Grid Maps. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12373-12380. https://doi.org/10.1609/aaai.v37i10.26458","Abstract 					In many computer games up to hundreds of agents navigate in real-time across a dynamically changing weighted grid map. Pathfinding in these situations is challenging because the grids are large, traversal costs are not uniform, and because each shortest path has many symmetric permutations, all of which must be considered by an optimal online search. In this work we introduce Weighted Jump Point Search (JPSW), a new type of pathfinding algorithm which breaks weighted grid symmetries by introducing a tiebreaking policy that allows us to apply effective pruning rules in symmetric regions. We show that these pruning rules preserve at least one optimal path to every grid cell and that their application can yield large performance improvements for optimal pathfinding. We give a complete theoretical description of the new algorithm, including pseudo-code. We also conduct a wide-ranging experimental evaluation, including data from real games. Results indicate JPSW is up to orders of magnitude faster than the nearest baseline, online search using A*.","https://ojs.aaai.org/index.php/AAAI/article/view/26458/26230"
"26459","Warm-Starting Nested Rollout Policy Adaptation with Optimal Stopping","['Chen Dang', 'Cristina Bazgan', 'Tristan Cazenave', 'Morgan Chopin', 'Pierre-Henri Wuillemin']","['Orange Labs, Châtillon, France\nUniversité Paris-Dauphine, PSL Research University, CNRS, UMR 7243, LAMSADE, F-75016 Paris, France', 'Université Paris-Dauphine, PSL Research University, CNRS, UMR 7243, LAMSADE, F-75016 Paris, France', 'Université Paris-Dauphine, PSL Research University, CNRS, UMR 7243, LAMSADE, F-75016 Paris, France', 'Orange Labs, Châtillon, France', 'Sorbonne Université, CNRS, UMR 7606, LIP6, F-75005 Paris, France']","['SO: Sampling/Simulation-Based Search', 'PRS: Routing']","Dang, C., Bazgan, C., Cazenave, T., Chopin, M., & Wuillemin, P.-H. (2023). Warm-Starting Nested Rollout Policy Adaptation with Optimal Stopping. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12381-12389. https://doi.org/10.1609/aaai.v37i10.26459","Abstract 					Nested Rollout Policy Adaptation (NRPA) is an approach using online learning policies in a nested structure. It has achieved a great result in a variety of difficult combinatorial optimization problems. In this paper, we propose Meta-NRPA, which combines optimal stopping theory with NRPA for warm-starting and significantly improves the performance of NRPA. We also present several exploratory techniques for NRPA which enable it to perform better exploration. We establish this for three notoriously difficult problems ranging from telecommunication, transportation and coding theory namely Minimum Congestion Shortest Path Routing,  Traveling Salesman Problem with Time Windows and Snake-in-the-Box. We also improve the lower bounds of the Snake-in-the-Box problem for multiple dimensions.","https://ojs.aaai.org/index.php/AAAI/article/view/26459/26231"
"26460","A Proof That Using Crossover Can Guarantee Exponential Speed-Ups in Evolutionary Multi-Objective Optimisation","['Duc-Cuong Dang', 'Andre Opris', 'Bahare Salehi', 'Dirk Sudholt']","['University of Passau', 'University of Passau', 'University of Passau\nShiraz University', 'University of Passau']","['SO: Evolutionary Computation', 'SO: Evaluation and Analysis']","Dang, D.-C., Opris, A., Salehi, B., & Sudholt, D. (2023). A Proof That Using Crossover Can Guarantee Exponential Speed-Ups in Evolutionary Multi-Objective Optimisation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12390-12398. https://doi.org/10.1609/aaai.v37i10.26460","Abstract 					Evolutionary algorithms are popular algorithms for multiobjective optimisation (also called Pareto optimisation) as they use a population to store trade-offs between different objectives. Despite their popularity, the theoretical foundation of multiobjective evolutionary optimisation (EMO) is still in its early development. Fundamental questions such as the benefits of the crossover operator are still not fully understood.  We provide a theoretical analysis of well-known EMO algorithms GSEMO and NSGA-II to showcase the possible advantages of crossover. We propose a class of problems on which these EMO algorithms using crossover find the Pareto set in expected polynomial time. In sharp contrast, they and many other EMO algorithms without crossover require exponential time to even find a single Pareto-optimal point. This is the first example of an exponential performance gap through the use of crossover for the widely used NSGA-II algorithm.","https://ojs.aaai.org/index.php/AAAI/article/view/26460/26232"
"26461","Runtime Analysis for the NSGA-II: Provable Speed-Ups from Crossover","['Benjamin Doerr', 'Zhongdi Qu']","['Laboratoire d’Informatique (LIX)\nEcole Polytechnique\nCNRS\nInstitut Polytechnique de Paris', 'Laboratoire d’Informatique (LIX)\nEcole Polytechnique\nCNRS\nInstitut Polytechnique de Paris']","['SO: Evolutionary Computation', 'SO: Heuristic Search']","Doerr, B., & Qu, Z. (2023). Runtime Analysis for the NSGA-II: Provable Speed-Ups from Crossover. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12399-12407. https://doi.org/10.1609/aaai.v37i10.26461","Abstract 					Very recently, the first mathematical runtime analyses for the NSGA-II, the most common multi-objective evolutionary algorithm, have been conducted. Continuing this research direction, we prove that the NSGA-II optimizes the OneJumpZeroJump benchmark asymptotically faster when crossover is employed. Together with a parallel independent work by Dang, Opris, Salehi, and Sudholt, this is the first time such an advantage of crossover is proven for the NSGA-II. Our arguments can be transferred to single-objective optimization. They then prove that crossover can speed up the (mu+1) genetic algorithm in a different way and more pronounced than known before. Our experiments confirm the added value of crossover and show that the observed advantages are even larger than what our proofs can guarantee.","https://ojs.aaai.org/index.php/AAAI/article/view/26461/26233"
"26462","From Understanding the Population Dynamics of the NSGA-II to the First Proven Lower Bounds","['Benjamin Doerr', 'Zhongdi Qu']","[""Laboratoire d'Informatique (LIX), CNRS, École Polytechnique, Institut Polytechnique de Paris"", ""Laboratoire d'Informatique (LIX), CNRS, École Polytechnique, Institut Polytechnique de Paris""]","['SO: Evolutionary Computation', 'SO: Heuristic Search']","Doerr, B., & Qu, Z. (2023). From Understanding the Population Dynamics of the NSGA-II to the First Proven Lower Bounds. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12408-12416. https://doi.org/10.1609/aaai.v37i10.26462","Abstract 					Due to the more complicated population dynamics of the NSGA-II, none of the existing runtime guarantees for this algorithm is accompanied by a non-trivial lower bound. Via a first mathematical understanding of the population dynamics of the NSGA-II, that is, by estimating the expected number of individuals having a certain objective value, we prove that the NSGA-II with suitable population size needs Omega(Nn log n) function evaluations to find the Pareto front of the OneMinMax problem and Omega(Nn^k)  evaluations on the OneJumpZeroJump problem with jump size k. These bounds are asymptotically tight (that is, they match previously shown upper bounds) and show that the NSGA-II here does not even in terms of the parallel runtime (number of iterations) profit from larger population sizes. For the OneJumpZeroJump problem and when the same sorting is used for the computation of the crowding distance contributions of the two objectives, we even obtain a runtime estimate that is tight including the leading constant.","https://ojs.aaai.org/index.php/AAAI/article/view/26462/26234"
"26463","Ultrafast Euclidean Shortest Path Computation Using Hub Labeling","['Jinchun Du', 'Bojie Shen', 'Muhammad Aamir Cheema']","['Monash University', 'Monash university', 'Monash University']","['SO: Heuristic Search', 'ROB: Motion and Path Planning', 'PRS: Routing']","Du, J., Shen, B., & Cheema, M. A. (2023). Ultrafast Euclidean Shortest Path Computation Using Hub Labeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12417-12426. https://doi.org/10.1609/aaai.v37i10.26463","Abstract 					Finding shortest paths in a Euclidean plane containing polygonal obstacles is a well-studied problem motivated by a variety of real-world applications.  The state-of-the-art algorithms require finding obstacle corners visible to the source and target, and need to consider potentially a large number of candidate paths. This adversely affects their query processing cost. We address these limitations by proposing a novel adaptation of hub labeling which is the state-of-the-art approach for  shortest distance computation in road networks. Our experimental study conducted on the widely used benchmark maps shows that our approach is typically 1-2  orders of magnitude faster than two state-of-the-art algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26463/26235"
"26464","A Formal Metareasoning Model of Concurrent Planning and Execution","['Amihay Elboher', 'Ava Bensoussan', 'Erez Karpas', 'Wheeler Ruml', 'Shahaf S. Shperberg', 'Eyal Shimony']","['Ben-Gurion University of the Negev', 'Ben Gurion University of the Negev', 'Technion', 'University of New Hampshire', 'Ben-Gurion University of the Negev', 'Ben-Gurion University of the Negev']","['SO: Metareasoning and Metaheuristics', 'SO: Heuristic Search']","Elboher, A., Bensoussan, A., Karpas, E., Ruml, W., Shperberg, S. S., & Shimony, E. (2023). A Formal Metareasoning Model of Concurrent Planning and Execution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12427-12435. https://doi.org/10.1609/aaai.v37i10.26464","Abstract 					Agents that plan and act in the real world must deal with the fact that time passes as they are planning. When timing is tight, there may be insufficient time to complete the search for a plan before it is time to act.  By commencing execution before search concludes, one gains time to search by making planning and execution concurrent. However, this incurs the risk of making incorrect action choices, especially if actions are irreversible. This tradeoff between opportunity and risk is the problem addressed in this paper. Our main contribution is to formally define this setting as an abstract metareasoning problem. We find that the abstract problem is intractable.  However, we identify special cases that are solvable in polynomial time, develop greedy solution algorithms, and, through tests on instances derived from search problems, find several methods that achieve promising practical performance.  This work lays the foundation for a principled time-aware executive that concurrently plans and executes.","https://ojs.aaai.org/index.php/AAAI/article/view/26464/26236"
"26465","TransPath: Learning Heuristics for Grid-Based Pathfinding via Transformers","['Daniil Kirilenko', 'Anton Andreychuk', 'Aleksandr Panov', 'Konstantin Yakovlev']","['Federal Research Center for Computer Science and Control RAS', 'AIRI', 'AIRI\nFederal Research Center for Computer Science and Control RAS', 'Federal Research Center for Computer Science and Control RAS\nAIRI']","['SO: Heuristic Search', 'ML: Deep Generative Models & Autoencoders', 'PRS: Planning/Scheduling and Learning']","Kirilenko, D., Andreychuk, A., Panov, A., & Yakovlev, K. (2023). TransPath: Learning Heuristics for Grid-Based Pathfinding via Transformers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12436-12443. https://doi.org/10.1609/aaai.v37i10.26465","Abstract 					Heuristic search algorithms, e.g. A*, are the commonly used tools for pathfinding on grids, i.e. graphs of regular structure that are widely employed to represent environments in robotics, video games, etc. Instance-independent heuristics for grid graphs, e.g. Manhattan distance, do not take the obstacles into account, and thus the search led by such heuristics performs poorly in obstacle-rich environments. To this end, we suggest learning the instance-dependent heuristic proxies that are supposed to notably increase the efficiency of the search. The first heuristic proxy we suggest to learn is the correction factor, i.e. the ratio between the instance-independent cost-to-go estimate and the perfect one (computed offline at the training phase). Unlike learning the absolute values of the cost-to-go heuristic function, which was known before, learning the correction factor utilizes the knowledge of the instance-independent heuristic. The second heuristic proxy is the path probability, which indicates how likely the grid cell is lying on the shortest path. This heuristic can be employed in the Focal Search framework as the secondary heuristic, allowing us to preserve the guarantees on the bounded sub-optimality of the solution. We learn both suggested heuristics in a supervised fashion with the state-of-the-art neural networks containing attention blocks (transformers). We conduct a thorough empirical evaluation on a comprehensive dataset of planning tasks, showing that the suggested techniques i) reduce the computational effort of the A* up to a factor of 4x while producing the solutions, whose costs exceed those of the optimal solutions by less than 0.3% on average; ii) outperform the competitors, which include the conventional techniques from the heuristic search, i.e. weighted A*, as well as the state-of-the-art learnable planners.  The project web-page is: https://airi-institute.github.io/TransPath/.","https://ojs.aaai.org/index.php/AAAI/article/view/26465/26237"
"26466","Large-State Reinforcement Learning for Hyper-Heuristics","['Lucas Kletzander', 'Nysret Musliu']","['TU Wien', 'TU Wien']","['SO: Metareasoning and Metaheuristics', 'ML: Reinforcement Learning Algorithms', 'PRS: Applications', 'SO: Heuristic Search']","Kletzander, L., & Musliu, N. (2023). Large-State Reinforcement Learning for Hyper-Heuristics. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12444-12452. https://doi.org/10.1609/aaai.v37i10.26466","Abstract 					Hyper-heuristics are a domain-independent problem solving approach where the main task is to select effective chains of problem-specific low-level heuristics on the fly for an unseen instance. This task can be seen as a reinforcement learning problem, however, the information available to the hyper-heuristic is very limited, usually leading to very limited state representations. In this work, for the first time we use the trajectory of solution changes for a larger set of features for reinforcement learning in the novel hyper-heuristic LAST-RL (Large-State Reinforcement Learning). Further, we introduce a probability distribution for the exploration case in our epsilon-greedy policy that is based on the idea of Iterated Local Search to increase the chance to sample good chains of low-level heuristics. The benefit of the collaboration of our novel components is shown on the academic benchmark of the Cross Domain Heuristic Challenge 2011 consisting of six different problem domains. Our approach can provide state-of-the-art results on this benchmark where it outperforms recent hyper-heuristics based on reinforcement learning, and also demonstrates high performance on a benchmark of complex real-life personnel scheduling domains.","https://ojs.aaai.org/index.php/AAAI/article/view/26466/26238"
"26467","Human Assisted Learning by Evolutionary Multi-Objective Optimization","['Dan-Xuan Liu', 'Xin Mu', 'Chao Qian']","['Nanjing University', 'Peng Cheng Laboratory', 'Nanjing University']","['SO: Evolutionary Computation', 'ML: Evolutionary Learning', 'SO: Heuristic Search']","Liu, D.-X., Mu, X., & Qian, C. (2023). Human Assisted Learning by Evolutionary Multi-Objective Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12453-12461. https://doi.org/10.1609/aaai.v37i10.26467","Abstract 					Machine learning models have liberated manpower greatly in many real-world tasks, but their predictions are still worse than humans on some specific instances. To improve the performance, it is natural to optimize machine learning models to take decisions for most instances while delivering a few tricky instances to humans, resulting in the problem of Human Assisted Learning (HAL). Previous works mainly formulated HAL as a constrained optimization problem that tries to find a limited subset of instances for human decision such that the sum of model and human errors can be minimized; and employed the greedy algorithms, whose performance, however, may be limited due to the greedy nature. In this paper, we propose a new framework HAL-EMO based on Evolutionary Multi-objective Optimization, which reformulates HAL as a bi-objective optimization problem that minimizes the number of selected instances for human decision and the total errors simultaneously, and employs a Multi-Objective Evolutionary Algorithm (MOEA) to solve it. We implement HAL-EMO using two MOEAs, the popular NSGA-II as well as the theoretically grounded GSEMO. We also propose a specific MOEA, called BSEMO, with biased selection and balanced mutation for HAL-EMO, and prove that for human assisted regression and classification, HAL-EMO using BSEMO can achieve better and same theoretical guarantees than previous greedy algorithms, respectively. Experiments on the tasks of medical diagnosis and content moderation show the superiority of HAL-EMO (with either NSGA-II, GSEMO or BSEMO) over previous algorithms, and that using BSEMO leads to the best performance of HAL-EMO.","https://ojs.aaai.org/index.php/AAAI/article/view/26467/26239"
"26468","OPT-GAN: A Broad-Spectrum Global Optimizer for Black-Box Problems by Learning Distribution","['Minfang Lu', 'Shuai Ning', 'Shuangrong Liu', 'Fengyang Sun', 'Bo Zhang', 'Bo Yang', 'Lin Wang']","['University of Jinan\nCainiao Network', 'University of Jinan\nQuan Cheng Laboratory', 'University of Suwon', 'Victoria University of Wellington', 'University of Jinan\nQuan Cheng Laboratory', 'Quan Cheng Laboratory', 'University of Jinan']","['SO: Evolutionary Computation', 'ML: Adversarial Learning & Robustness', 'ML: Deep Generative Models & Autoencoders', 'ML: Optimization', 'SO: Heuristic Search']","Lu, M., Ning, S., Liu, S., Sun, F., Zhang, B., Yang, B., & Wang, L. (2023). OPT-GAN: A Broad-Spectrum Global Optimizer for Black-Box Problems by Learning Distribution. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12462-12472. https://doi.org/10.1609/aaai.v37i10.26468","Abstract 					Black-box optimization (BBO) algorithms are concerned with finding the best solutions for problems with missing analytical details. Most classical methods for such problems are based on strong and fixed a priori assumptions, such as Gaussianity. However, the complex real-world problems, especially when the global optimum is desired, could be very far from the a priori assumptions because of their diversities, causing unexpected obstacles.   In this study, we propose a generative adversarial net-based broad-spectrum global optimizer (OPT-GAN) which estimates the distribution of optimum gradually, with strategies to balance exploration-exploitation trade-off. It has potential to better adapt to the regularity and structure of diversified landscapes than other methods with fixed prior, e.g., Gaussian assumption or separability.  Experiments on diverse BBO benchmarks and high dimensional real world applications exhibit that OPT-GAN outperforms other traditional and neural net-based BBO algorithms. The code and Appendix are available at https://github.com/NBICLAB/OPT-GAN","https://ojs.aaai.org/index.php/AAAI/article/view/26468/26240"
"26469","Analyzing and Improving the Use of the FastMap Embedding in Pathfinding Tasks","['Reza Mashayekhi', 'Dor Atzmon', 'Nathan R. Sturtevant']","['University of Alberta', 'Ben-Gurion University of the Negev\nRoyal Holloway, University of London', 'University of Alberta\nAlberta Machine Intelligence Institute']","['SO: Heuristic Search']","Mashayekhi, R., Atzmon, D., & Sturtevant, N. R. (2023). Analyzing and Improving the Use of the FastMap Embedding in Pathfinding Tasks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12473-12481. https://doi.org/10.1609/aaai.v37i10.26469","Abstract 					The FastMap algorithm has been proposed as an inexpensive metric embedding which provides admissible distance estimates between all vertices in an embedding. As an embedding, it also supports additional operations such as taking the median location of two vertices, which is important in some problems. This paper studies several aspects of FastMap embeddings, showing the relationship of FastMap to general additive heuristics. As an admissible heuristic, FastMap is not as strong as previous suggested. However, by combining FastMap with the ideas of differential heuristics, we can significantly improve the performance of FastMap heuristics. We show the impact of these ideas in both single-agent pathfinding and the Multi-Agent Meeting problem, where the performance of algorithms using our improved FastMap embedding is improved by up to a factor of two.","https://ojs.aaai.org/index.php/AAAI/article/view/26469/26241"
"26470","Fully Computer-Assisted Proofs in Extremal Combinatorics","['Olaf Parczyk', 'Sebastian Pokutta', 'Christoph Spiegel', 'Tibor Szabó']","['Freie Universität Berlin', 'Zuse Institute Berlin\nTechnische Universit ̈at Berlin', 'Zuse Institute Berlin', 'Freie Universität Berlin']","['SO: Metareasoning and Metaheuristics', 'ML: Optimization', 'SO: Heuristic Search', 'SO: Local Search']","Parczyk, O., Pokutta, S., Spiegel, C., & Szabó, T. (2023). Fully Computer-Assisted Proofs in Extremal Combinatorics. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12482-12490. https://doi.org/10.1609/aaai.v37i10.26470","Abstract 					We present a fully computer-assisted proof system for solving a particular family of problems in Extremal Combinatorics. Existing techniques using Flag Algebras have proven powerful in the past, but have so far lacked a computational counterpart to derive matching constructive bounds. We demonstrate that common search heuristics are capable of finding constructions far beyond the reach of human intuition. Additionally, the most obvious downside of such heuristics, namely a missing guarantee of global optimality, can often be fully eliminated in this case through lower bounds and stability results coming from the Flag Algebra approach.  To illustrate the potential of this approach, we study two related and well-known problems in Extremal Graph Theory that go back to questions of Erdős from the 60s. Most notably, we present the first major improvement in the upper bound of the Ramsey multiplicity of K_4 in 25 years, precisely determine the first off-diagonal Ramsey multiplicity number, and settle the minimum number of independent sets of size four in graphs with clique number strictly less than five.","https://ojs.aaai.org/index.php/AAAI/article/view/26470/26242"
"26471","Electrophysiological Brain Source Imaging via Combinatorial Search with Provable Optimality","['Guihong Wan', 'Meng Jiao', 'Xinglong Ju', 'Yu Zhang', 'Haim Schweitzer', 'Feng Liu']","['Massachusetts General Hospital, Harvard Medical School', 'School of Systems and Enterprises, Stevens Institute of Technology', 'Division of Management Information Systems, The University of Oklahoma', 'Department of Bioengineering, Lehigh University', 'Department of Computer Science, The University of Texas at Dallas', 'School of Systems and Enterprises, Stevens Institute of Technology']","['SO: Heuristic Search', 'CMS: Brain Modeling', 'APP: Healthcare', 'Medicine & Wellness', 'HAI: Brain-Sensing and Analysis']","Wan, G., Jiao, M., Ju, X., Zhang, Y., Schweitzer, H., & Liu, F. (2023). Electrophysiological Brain Source Imaging via Combinatorial Search with Provable Optimality. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12491-12499. https://doi.org/10.1609/aaai.v37i10.26471","Abstract 					Electrophysiological Source Imaging (ESI) refers to reconstructing the underlying brain source activation from non-invasive Electroencephalography (EEG) and Magnetoencephalography (MEG) measurements on the scalp. Estimating the source locations and their extents is a fundamental tool in clinical and neuroscience applications. However, the estimation is challenging because of the ill-posedness and high coherence in the leadfield matrix as well as the noise in the EEG/MEG data. In this work, we proposed a combinatorial search framework to address the ESI problem with a provable optimality guarantee. Specifically, by exploiting the graph neighborhood information in the brain source space, we converted the ESI problem into a graph search problem and designed a combinatorial search algorithm under the framework of A* to solve it. The proposed algorithm is guaranteed to give an optimal solution to the ESI problem. Experimental results on both synthetic data and real epilepsy EEG data demonstrated that the proposed algorithm could faithfully reconstruct the source activation in the brain.","https://ojs.aaai.org/index.php/AAAI/article/view/26471/26243"
"26472","Improved Algorithm for Regret Ratio Minimization in Multi-Objective Submodular Maximization","['Yanhao Wang', 'Jiping Zheng', 'Fanxu Meng']","['East China Normal University, Shanghai, China', 'Nanjing University of Aeronautics and Astronautics, Nanjing, China\nNanjing University, Nanjing, China', 'Nanjing University of Aeronautics and Astronautics, Nanjing, China']","['SO: Other Foundations of Search & Optimization', 'ML: Optimization', 'ML: Other Foundations of Machine Learning']","Wang, Y., Zheng, J., & Meng, F. (2023). Improved Algorithm for Regret Ratio Minimization in Multi-Objective Submodular Maximization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12500-12508. https://doi.org/10.1609/aaai.v37i10.26472","Abstract 					Submodular maximization has attracted extensive attention due to its numerous applications in machine learning and artificial intelligence. Many real-world problems require maximizing multiple submodular objective functions at the same time. In such cases, a common approach is to select a representative subset of Pareto optimal solutions with different trade-offs among multiple objectives. To this end, in this paper, we investigate the regret ratio minimization (RRM) problem in multi-objective submodular maximization, which aims to find at most k solutions to best approximate all Pareto optimal solutions w.r.t. any linear combination of objective functions. We propose a novel HS-RRM algorithm by transforming RRM into HittingSet problems based on the notions of ε-kernel and δ-net, where any α-approximation algorithm for single-objective submodular maximization is used as an oracle. We improve upon the previous best-known bound on the maximum regret ratio (MRR) of the output of HS-RRM and show that the new bound is nearly asymptotically optimal for any fixed number d of objective functions. Experiments on real-world and synthetic data confirm that HS-RRM achieves lower MRRs than existing algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26472/26244"
"26473","Efficient Gradient Approximation Method for Constrained Bilevel Optimization","['Siyuan Xu', 'Minghui Zhu']","['The Pennsylvania State University', 'The Pennsylvania State University']","['SO: Evaluation and Analysis', 'SO: Applications']","Xu, S., & Zhu, M. (2023). Efficient Gradient Approximation Method for Constrained Bilevel Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12509-12517. https://doi.org/10.1609/aaai.v37i10.26473","Abstract 					Bilevel optimization has been developed for many machine learning tasks with large-scale and high-dimensional data. This paper considers a constrained bilevel optimization problem, where the lower-level optimization problem is convex with equality and inequality constraints and the upper-level optimization problem is non-convex. The overall objective function is non-convex and non-differentiable. To solve the problem, we develop a gradient-based approach, called gradient approximation method, which determines the descent direction by computing several representative gradients of the objective function inside a neighborhood of the current estimate. We show that the algorithm asymptotically converges to the set of Clarke stationary points, and demonstrate the efficacy of the algorithm by the experiments on hyperparameter optimization and meta-learning.","https://ojs.aaai.org/index.php/AAAI/article/view/26473/26245"
"26474","A Generalized Scalarization Method for Evolutionary Multi-Objective Optimization","['Ruihao Zheng', 'Zhenkun Wang']","['Southern University of Science and Technology', 'Southern University of Science and Technology']","['SO: Evolutionary Computation']","Zheng, R., & Wang, Z. (2023). A Generalized Scalarization Method for Evolutionary Multi-Objective Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(10), 12518-12525. https://doi.org/10.1609/aaai.v37i10.26474","Abstract 					The decomposition-based multi-objective evolutionary algorithm (MOEA/D) transforms a multi-objective optimization problem (MOP) into a set of single-objective subproblems for collaborative optimization. Mismatches between subproblems and solutions can lead to severe performance degradation of MOEA/D. Most existing mismatch coping strategies only work when the L∞ scalarization is used. A mismatch coping strategy that can use any Lp scalarization, even when facing MOPs with non-convex Pareto fronts, is of great significance for MOEA/D. This paper uses the global replacement (GR) as the backbone. We analyze how GR can no longer avoid mismatches when L∞ is replaced by another Lp with p ∈ [1, ∞), and find that the Lp-based (1 ≤ p < ∞) subproblems having inconsistently large preference regions. When p is set to a small value, some middle subproblems have very small preference regions so that their direction vectors cannot pass through their corresponding preference regions. Therefore, we propose a generalized Lp (GLp) scalarization to ensure that the subproblem’s direction vector passes through its preference region. Our theoretical analysis shows that GR can always avoid mismatches when using the GLp scalarization for any p ≥ 1. The experimental studies on various MOPs conform to the theoretical analysis.","https://ojs.aaai.org/index.php/AAAI/article/view/26474/26246"
"26475","Generalized Category Discovery with Decoupled Prototypical Network","['Wenbin An', 'Feng Tian', 'Qinghua Zheng', 'Wei Ding', 'Qianying Wang', 'Ping Chen']","[""School of Automation Science and Engineering, Xi'an Jiaotong University\nNational Engineering Laboratory for Big Data Analytics"", ""School of Computer Science and Technology, Xi'an Jiaotong University\nNational Engineering Laboratory for Big Data Analytics"", ""School of Computer Science and Technology, Xi'an Jiaotong University\nNational Engineering Laboratory for Big Data Analytics"", 'Department of Computer Science, University of Massachusetts Boston', 'Lenovo Research', 'Department of Engineering, University of Massachusetts Boston']","['SNLP: Text Mining', 'SNLP: Text Classification']","An, W., Tian, F., Zheng, Q., Ding, W., Wang, Q., & Chen, P. (2023). Generalized Category Discovery with Decoupled Prototypical Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12527-12535. https://doi.org/10.1609/aaai.v37i11.26475","Abstract 					Generalized Category Discovery (GCD) aims to recognize both known and novel categories from a set of unlabeled data, based on another dataset labeled with only known categories. Without considering differences between known and novel categories, current methods learn about them in a coupled manner, which can hurt model's generalization and discriminative ability. Furthermore, the coupled training approach prevents these models transferring category-specific knowledge explicitly from labeled data to unlabeled data, which can lose high-level semantic information and impair model performance. To mitigate above limitations, we present a novel model called Decoupled Prototypical Network (DPN). By formulating a bipartite matching problem for category prototypes, DPN can not only decouple known and novel categories to achieve different training targets effectively, but also align known categories in labeled and unlabeled data to transfer category-specific knowledge explicitly and capture high-level semantics. Furthermore, DPN can learn more discriminative features for both known and novel categories through our proposed Semantic-aware Prototypical Learning (SPL). Besides capturing meaningful semantic information, SPL can also alleviate the noise of hard pseudo labels through semantic-weighted soft assignment. Extensive experiments show that DPN outperforms state-of-the-art models by a large margin on all evaluation metrics across multiple benchmark datasets. Code and data are available at https://github.com/Lackel/DPN.","https://ojs.aaai.org/index.php/AAAI/article/view/26475/26247"
"26476","Structured Case-Based Reasoning for Inference-Time Adaptation of Text-to-SQL Parsers","['Abhijeet Awasthi', 'Soumen Chakrabarti', 'Sunita Sarawagi']","['IIT Bombay', 'IIT Bombay', 'Indian Institute of Technology']","['SNLP: Lexical & Frame Semantics', 'Semantic Parsing', 'SNLP: Question Answering']","Awasthi, A., Chakrabarti, S., & Sarawagi, S. (2023). Structured Case-Based Reasoning for Inference-Time Adaptation of Text-to-SQL Parsers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12536-12544. https://doi.org/10.1609/aaai.v37i11.26476","Abstract 					Inference-time adaptation methods for semantic parsing are useful for leveraging examples from newly-observed domains without repeated fine-tuning. Existing approaches typically bias the decoder by simply concatenating input-output example pairs (cases) from the new domain at the encoder’s input in a Seq-to-Seq model. Such methods cannot adequately leverage the structure of logical forms in the case examples. We propose StructCBR, a structured case-based reasoning approach, which leverages subtree-level similarity between logical forms of cases and candidate outputs, resulting in better decoder decisions. For the task of adapting Text-to-SQL models to unseen schemas, we show that exploiting case examples in a structured manner via StructCBR offers consistent performance improvements over prior inference-time adaptation methods across five different databases. To the best of our knowledge, we are the first to attempt inference-time adaptation of Text-to-SQL models, and harness trainable structured similarity between subqueries.","https://ojs.aaai.org/index.php/AAAI/article/view/26476/26248"
"26477","SegFormer: A Topic Segmentation Model with Controllable Range of Attention","['Haitao Bai', 'Pinghui Wang', 'Ruofei Zhang', 'Zhou Su']","['Xi’an Jiaotong University', ""Xi'an Jiaotong University"", 'Xian Jiaotong University', ""Xi'an Jiaotong University""]","['SNLP: Applications', 'SNLP: Information Extraction', 'SNLP: Language Models', 'SNLP: Machine Translation & Multilinguality', 'SNLP: Sentence-Level Semantics and Textual Inference', 'SNLP: Summarization', 'SNLP: Text Classification', 'SNLP: Text Mining']","Bai, H., Wang, P., Zhang, R., & Su, Z. (2023). SegFormer: A Topic Segmentation Model with Controllable Range of Attention. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12545-12552. https://doi.org/10.1609/aaai.v37i11.26477","Abstract 					Topic segmentation aims to reveal the latent structure of a document and divide it into multiple parts. However, current neural solutions are limited in the context modeling of sentences and feature representation of candidate boundaries. This causes the model to suffer from inefficient sentence context encoding and noise information interference. In this paper, we design a new text segmentation model SegFormer with unidirectional attention blocks to better model sentence representations. To alleviate the problem of noise information interference, SegFormer uses a novel additional context aggregator and a topic classification loss to guide the model to aggregate the information within the appropriate range.  In addition, SegFormer applies an iterative prediction algorithm to search for optimal boundaries progressively. We evaluate SegFormer's generalization ability, multilingual ability, and application ability on multiple challenging real-world datasets. Experiments show that our model significantly improves the performance by 7.5% on the benchmark WIKI-SECTION compared to several strong baselines. The application of SegFormer to a real-world dataset to separate normal and advertisement segments in product marketing essays also achieves superior performance in the evaluation with other cutting-edge models.","https://ojs.aaai.org/index.php/AAAI/article/view/26477/26249"
"26478","Rich Event Modeling for Script Event Prediction","['Long Bai', 'Saiping Guan', 'Zixuan Li', 'Jiafeng Guo', 'Xiaolong Jin', 'Xueqi Cheng']","['CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences (CAS)\nSchool of Computer Science and Technology, University of Chinese Academy of Sciences', 'CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences (CAS)\nSchool of Computer Science and Technology, University of Chinese Academy of Sciences', 'CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences (CAS)\nSchool of Computer Science and Technology, University of Chinese Academy of Sciences', 'CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences (CAS)\nSchool of Computer Science and Technology, University of Chinese Academy of Sciences', 'CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences (CAS)\nSchool of Computer Science and Technology, University of Chinese Academy of Sciences', 'CAS Key Lab of Network Data Science and Technology, Institute of Computing Technology, Chinese Academy of Sciences (CAS)\nSchool of Computer Science and Technology, University of Chinese Academy of Sciences']","['SNLP: Sentence-Level Semantics and Textual Inference', 'SNLP: Information Extraction']","Bai, L., Guan, S., Li, Z., Guo, J., Jin, X., & Cheng, X. (2023). Rich Event Modeling for Script Event Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12553-12561. https://doi.org/10.1609/aaai.v37i11.26478","Abstract 					Script is a kind of structured knowledge extracted from texts, which contains a sequence of events. Based on such knowledge, script event prediction aims to predict the subsequent event. To do so, two aspects should be considered for events, namely, event description (i.e., what the events should contain) and event encoding (i.e., how they should be encoded). Most existing methods describe an event by a verb together with a few core arguments (i.e., subject, object, and indirect object), which are not precise enough. In addition, existing event encoders are limited to a fixed number of arguments, which are not flexible enough to deal with extra information. Thus, in this paper, we propose the Rich Event Prediction (REP) framework for script event prediction. Fundamentally, it is based on the proposed rich event description, which enriches the existing ones with three kinds of important information, namely, the senses of verbs, extra semantic roles, and types of participants. REP contains an event extractor to extract such information from texts. Based on the extracted rich information, a predictor then selects the most probable subsequent event. The core component of the predictor is a transformer-based event encoder that integrates the above information flexibly. Experimental results on the widely used Gigaword Corpus show the effectiveness of the proposed framework.","https://ojs.aaai.org/index.php/AAAI/article/view/26478/26250"
"26479","Avocodo: Generative Adversarial Network for Artifact-Free Vocoder","['Taejun Bak', 'Junmo Lee', 'Hanbin Bae', 'Jinhyeok Yang', 'Jae-Sung Bae', 'Young-Sun Joo']","['AI Center, NCSOFT, Seongnam, Korea', 'SK Telecom, Seoul, Korea', 'Samsung Research, Seoul, Korea', 'Supertone Inc., Seoul, Korea', 'Samsung Research, Seoul, Korea', 'AI Center, NCSOFT, Seongnam, Korea']","['SNLP: Speech and Multimodality', 'SNLP: Generation']","Bak, T., Lee, J., Bae, H., Yang, J., Bae, J.-S., & Joo, Y.-S. (2023). Avocodo: Generative Adversarial Network for Artifact-Free Vocoder. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12562-12570. https://doi.org/10.1609/aaai.v37i11.26479","Abstract 					Neural vocoders based on the generative adversarial neural network (GAN) have been widely used due to their fast inference speed and lightweight networks while generating high-quality speech waveforms. Since the perceptually important speech components are primarily concentrated in the low-frequency bands, most GAN-based vocoders perform multi-scale analysis that evaluates downsampled speech waveforms. This multi-scale analysis helps the generator improve speech intelligibility. However, in preliminary experiments, we discovered that the multi-scale analysis which focuses on the low-frequency bands causes unintended artifacts, e.g., aliasing and imaging artifacts, which degrade the synthesized speech waveform quality. Therefore, in this paper, we investigate the relationship between these artifacts and GAN-based vocoders and propose a GAN-based vocoder, called Avocodo, that allows the synthesis of high-fidelity speech with reduced artifacts. We introduce two kinds of discriminators to evaluate speech waveforms in various perspectives: a collaborative multi-band discriminator and a sub-band discriminator. We also utilize a pseudo quadrature mirror filter bank to obtain downsampled multi-band speech waveforms while avoiding aliasing. According to experimental results, Avocodo outperforms baseline GAN-based vocoders, both objectively and subjectively, while reproducing speech with fewer artifacts.","https://ojs.aaai.org/index.php/AAAI/article/view/26479/26251"
"26480","End-to-End Deep Reinforcement Learning for Conversation Disentanglement","['Karan Bhukar', 'Harshit Kumar', 'Dinesh Raghu', 'Ajay Gupta']","['IBM Research', 'IBM Research', 'IBM Research', 'Meta']","['SNLP: Conversational AI/Dialogue Systems', 'ML: Reinforcement Learning Algorithms']","Bhukar, K., Kumar, H., Raghu, D., & Gupta, A. (2023). End-to-End Deep Reinforcement Learning for Conversation Disentanglement. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12571-12579. https://doi.org/10.1609/aaai.v37i11.26480","Abstract 					Collaborative Communication platforms (e.g., Slack) support multi-party conversations which contain a large number of messages on shared channels. Multiple conversations intermingle within these messages. The task of conversation disentanglement is to cluster these intermingled messages into conversations. Existing approaches are trained using loss functions that optimize only local decisions, i.e. predicting reply-to links for each message and thereby creating clusters of conversations. In this work, we propose an end-to-end reinforcement learning (RL) approach that directly optimizes a global metric. We observe that using existing global metrics such as variation of information and adjusted rand index as a reward for the RL agent deteriorates its performance. This behaviour is because these metrics completely ignore the reply-to links between messages (local decisions) during reward computation. Therefore, we propose a novel thread-level reward function that captures the global metric without ignoring the local decisions. Through experiments on the Ubuntu IRC dataset, we demonstrate that the proposed RL model improves the performance on both link-level and conversation-level metrics.","https://ojs.aaai.org/index.php/AAAI/article/view/26480/26252"
"26481","Self-Supervised Logic Induction for Explainable Fuzzy Temporal Commonsense Reasoning","['Bibo Cai', 'Xiao Ding', 'Zhouhao Sun', 'Bing Qin', 'Ting Liu', 'Baojun wang', 'Lifeng Shang']","['Harbin Institute of Technology', 'Harbin Institute of Technology', 'Harbin Institude of Technology', 'Harbin Institute of Technology', 'Harbin Institute of Technology', ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab""]","['SNLP: Applications', 'SNLP: Sentence-Level Semantics and Textual Inference']","Cai, B., Ding, X., Sun, Z., Qin, B., Liu, T., wang, B., & Shang, L. (2023). Self-Supervised Logic Induction for Explainable Fuzzy Temporal Commonsense Reasoning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12580-12588. https://doi.org/10.1609/aaai.v37i11.26481","Abstract 					Understanding temporal commonsense concepts, such as times of occurrence and durations is crucial for event-centric language understanding. Reasoning about such temporal concepts in a complex context requires reasoning over both the stated context and the world knowledge that underlines it. A recent study shows massive pre-trained LM still struggle with such temporal reasoning under complex contexts (e.g., dialog) because they only implicitly encode the relevant contexts and fail to explicitly uncover the underlying logical compositions for complex inference, thus may not be robust enough. In this work, we propose to augment LMs with the temporal logic induction ability, which frames the temporal reasoning by defining three modular components: temporal dependency inducer and temporal concept defuzzifier and logic validator. The former two components disentangle the explicit/implicit dependency between temporal concepts across context (before, after, ...) and the specific meaning of fuzzy temporal concepts, respectively, while the validator combines the intermediate reasoning clues for robust contextual reasoning about the temporal concepts. Extensive experimental results on TIMEDIAL, a challenging dataset for temporal reasoning over dialog, show that our method, Logic Induction Enhanced Contextualized TEmporal Reasoning (LECTER), can yield great improvements over the traditional language model for temporal reasoning.","https://ojs.aaai.org/index.php/AAAI/article/view/26481/26253"
"26482","Zero-Shot Cross-Lingual Event Argument Extraction with Language-Oriented Prefix-Tuning","['Pengfei Cao', 'Zhuoran Jin', 'Yubo Chen', 'Kang Liu', 'Jun Zhao']","['Institute of Automation, Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences', 'Institute of Automation, Chinese Academy of Sciences']","['SNLP: Information Extraction']","Cao, P., Jin, Z., Chen, Y., Liu, K., & Zhao, J. (2023). Zero-Shot Cross-Lingual Event Argument Extraction with Language-Oriented Prefix-Tuning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12589-12597. https://doi.org/10.1609/aaai.v37i11.26482","Abstract 					Event argument extraction (EAE) aims to identify the arguments of a given event, and classify the roles that those arguments play. Due to high data demands of training EAE models, zero-shot cross-lingual EAE has attracted increasing attention, as it greatly reduces human annotation effort. Some prior works indicate that generation-based methods have achieved promising performance for monolingual EAE. However, when applying existing generation-based methods to zero-shot cross-lingual EAE, we find two critical challenges, including Language Discrepancy and Template Construction. In this paper, we propose a novel method termed as Language-oriented Prefix-tuning Network (LAPIN) to address the above challenges. Specifically, we devise a Language-oriented Prefix Generator module to handle the discrepancies between source and target languages. Moreover, we leverage a Language-agnostic Template Constructor module to design templates that can be adapted to any language. Extensive experiments demonstrate that our proposed method achieves the best performance, outperforming the previous state-of-the-art model by 4.8% and 2.3% of the average F1-score on two multilingual EAE datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26482/26254"
"26483","RPA: Reasoning Path Augmentation in Iterative Retrieving for Multi-Hop QA","['Ziyi Cao', 'Bingquan Liu', 'Shaobo Li']","['Harbin Institute of Technology', 'Harbin Institute of Technology', 'Harbin Institute of Technology']","['SNLP: Question Answering', 'SNLP: Sentence-Level Semantics and Textual Inference']","Cao, Z., Liu, B., & Li, S. (2023). RPA: Reasoning Path Augmentation in Iterative Retrieving for Multi-Hop QA. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12598-12606. https://doi.org/10.1609/aaai.v37i11.26483","Abstract 					Multi-hop questions are associated with a series of justifications, and one needs to obtain the answers by following the reasoning path (RP) that orders the justifications adequately. So reasoning path retrieval becomes a critical preliminary stage for multi-hop Question Answering (QA). Within the RP, two fundamental challenges emerge for better performance: (i) what the order of the justifications in the RP should be, and (ii) what if the wrong justification has been in the path. In this paper, we propose Reasoning Path Augmentation (RPA), which uses reasoning path reordering and augmentation to handle the above two challenges, respectively. Reasoning path reordering restructures the reasoning by targeting the easier justification first but difficult one later, in which the difficulty is determined by the overlap between query and justifications since the higher overlap means more lexical relevance and easier searchable. Reasoning path augmentation automatically generates artificial RPs, in which the distracted justifications are inserted to aid the model recover from the wrong justification. We build RPA with a naive pre-trained model and evaluate RPA on the QASC and MultiRC datasets. The evaluation results demonstrate that RPA outperforms previously published reasoning path retrieval methods, showing the effectiveness of the proposed methods. Moreover, we present detailed experiments on how the orders of justifications and the percent of augmented paths affect the question- answering performance, revealing the importance of polishing RPs and the necessity of augmentation.","https://ojs.aaai.org/index.php/AAAI/article/view/26483/26255"
"26484","Leveraging Modality-Specific Representations for Audio-Visual Speech Recognition via Reinforcement Learning","['Chen Chen', 'Yuchen Hu', 'Qiang Zhang', 'Heqing Zou', 'Beier Zhu', 'Eng Siong Chng']","['Nanyang Technological University', 'Nanyang Technological University', 'ZJU-Hangzhou Global Scientific and Technological Innovation Center\nZhejiang University', 'Nanyang Technological University', 'Nanyang Technological University', 'Nanyang Technological University']","['SNLP: Speech and Multimodality', 'SNLP: Applications']","Chen, C., Hu, Y., Zhang, Q., Zou, H., Zhu, B., & Chng, E. S. (2023). Leveraging Modality-Specific Representations for Audio-Visual Speech Recognition via Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12607-12615. https://doi.org/10.1609/aaai.v37i11.26484","Abstract 					Audio-visual speech recognition (AVSR) has gained remarkable success for ameliorating the noise-robustness of speech recognition. Mainstream methods focus on fusing audio and visual inputs to obtain modality-invariant representations. However, such representations are prone to over-reliance on audio modality as it is much easier to recognize than video modality in clean conditions. As a result, the AVSR model underestimates the importance of visual stream in face of noise corruption. To this end, we leverage visual modality-specific representations to provide stable complementary information for the AVSR task. Specifically, we propose a reinforcement learning (RL) based framework called MSRL, where the agent dynamically harmonizes modality-invariant and modality-specific representations in the auto-regressive decoding process. We customize a reward function directly related to task-specific metrics (i.e., word error rate), which encourages the MSRL to effectively explore the optimal integration strategy. Experimental results on the LRS3 dataset show that the proposed method achieves state-of-the-art in both clean and various noisy conditions. Furthermore, we demonstrate the better generality of MSRL system than other baselines when test set contains unseen noises.","https://ojs.aaai.org/index.php/AAAI/article/view/26484/26256"
"26485","Converge to the Truth: Factual Error Correction via Iterative Constrained Editing","['Jiangjie Chen', 'Rui Xu', 'Wenxuan Zeng', 'Changzhi Sun', 'Lei Li', 'Yanghua Xiao']","['Fudan University', 'Fudan University', 'University of Electronic Science and Technology of China', 'Bytedance', 'University of California Santa Barbara', 'Fudan University\nFudan-Aishu Cognitive Intelligence Joint Research Center']","['SNLP: Applications', 'APP: Misinformation & Fake News', 'SNLP: Generation', 'SNLP: Sentence-Level Semantics and Textual Inference']","Chen, J., Xu, R., Zeng, W., Sun, C., Li, L., & Xiao, Y. (2023). Converge to the Truth: Factual Error Correction via Iterative Constrained Editing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12616-12625. https://doi.org/10.1609/aaai.v37i11.26485","Abstract 					Given a possibly false claim sentence, how can we automatically correct it with minimal editing? Existing methods either require a large number of pairs of false and corrected claims for supervised training or do not handle well errors spanning over multiple tokens within an utterance. In this paper, we propose VENCE, a novel method for factual error correction (FEC) with minimal edits. VENCE formulates the FEC problem as iterative sampling editing actions with respect to a target density function. We carefully design the target function with predicted truthfulness scores from an offline trained fact verification model. VENCE samples the most probable editing positions based on back-calculated gradients of the truthfulness score concerning input tokens and the editing actions using a distantly-supervised language model (T5). Experiments on a public dataset show that VENCE improves the well-adopted SARI metric by 5.3 (or a relative improvement of 11.8%) over the previous best distantly-supervised methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26485/26257"
"26486","Adversarial Word Dilution as Text Data Augmentation in Low-Resource Regime","['Junfan Chen', 'Richong Zhang', 'Zheyan Luo', 'Chunming Hu', 'Yongyi Mao']","['Beihang University', 'Beihang University', 'Beihang University', 'Beihang University', 'University of Ottawa']","['SNLP: Text Classification', 'SNLP: Adversarial Attacks & Robustness']","Chen, J., Zhang, R., Luo, Z., Hu, C., & Mao, Y. (2023). Adversarial Word Dilution as Text Data Augmentation in Low-Resource Regime. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12626-12634. https://doi.org/10.1609/aaai.v37i11.26486","Abstract 					Data augmentation is widely used in text classification, especially in the low-resource regime where a few examples for each class are available during training. Despite the success, generating data augmentations as hard positive examples that may increase their effectiveness is under-explored. This paper proposes an Adversarial Word Dilution (AWD) method that can generate hard positive examples as text data augmentations to train the low-resource text classification model efficiently. Our idea of augmenting the text data is to dilute the embedding of strong positive words by weighted mixing with unknown-word embedding, making the augmented inputs hard to be recognized as positive by the classification model. We adversarially learn the dilution weights through a constrained min-max optimization process with the guidance of the labels. Empirical studies on three benchmark datasets show that AWD can generate more effective data augmentations and outperform the state-of-the-art text data augmentation methods. The additional analysis demonstrates that the data augmentations generated by AWD are interpretable and can flexibly extend to new examples without further training.","https://ojs.aaai.org/index.php/AAAI/article/view/26486/26258"
"26487","CP-Rec: Contextual Prompting for Conversational Recommender Systems","['Keyu Chen', 'Shiliang Sun']","['East China Normal University', 'East China Normal University']","['SNLP: Conversational AI/Dialogue Systems']","Chen, K., & Sun, S. (2023). CP-Rec: Contextual Prompting for Conversational Recommender Systems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12635-12643. https://doi.org/10.1609/aaai.v37i11.26487","Abstract 					The conversational recommender system (CRS) aims to provide high-quality recommendations through interactive dialogues. However, previous CRS models have no effective mechanisms for task planning and topic elaboration, and thus they hardly maintain coherence in multi-task recommendation dialogues. Inspired by recent advances in prompt-based learning, we propose a novel contextual prompting framework for dialogue management, which optimizes prompts based on context, topics, and user profiles. Specifically, we develop a topic controller to sequentially plan the subtasks, and a prompt search module to construct context-aware prompts. We further adopt external knowledge to enrich user profiles and make knowledge-aware recommendations. Incorporating these techniques, we propose a conversational recommender system with contextual prompting, namely CP-Rec. Experimental results demonstrate that it achieves state-of-the-art recommendation accuracy and generates more coherent and informative conversations.","https://ojs.aaai.org/index.php/AAAI/article/view/26487/26259"
"26488","A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech","['Li-Wei Chen', 'Shinji Watanabe', 'Alexander Rudnicky']","['Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University']","['SNLP: Generation', 'SNLP: Speech and Multimodality', 'ML: Deep Neural Architectures', 'SNLP: Applications', 'ML: Applications']","Chen, L.-W., Watanabe, S., & Rudnicky, A. (2023). A Vector Quantized Approach for Text to Speech Synthesis on Real-World Spontaneous Speech. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12644-12652. https://doi.org/10.1609/aaai.v37i11.26488","Abstract 					Recent Text-to-Speech (TTS) systems trained on reading or acted corpora have achieved near human-level naturalness. The diversity of human speech, however, often goes beyond the coverage of these corpora. We believe the ability to handle such diversity is crucial for AI systems to achieve human-level communication. Our work explores the use of more abundant real-world data for building speech synthesizers. We train TTS systems using real-world speech from YouTube and podcasts. We observe the mismatch between training and inference alignments in mel-spectrogram based autoregressive models, leading to unintelligible synthesis, and demonstrate that learned discrete codes within multiple code groups effectively resolves this issue. We introduce our MQTTS system whose architecture is designed for multiple code generation and monotonic alignment, along with the use of a clean silence prompt to improve synthesis quality. We conduct ablation analyses to identify the efficacy of our methods. We show that MQTTS outperforms existing TTS systems in several objective and subjective measures.","https://ojs.aaai.org/index.php/AAAI/article/view/26488/26260"
"26489","Learning to Memorize Entailment and Discourse Relations for Persona-Consistent Dialogues","['Ruijun Chen', 'Jin Wang', 'Liang-Chih Yu', 'Xuejie Zhang']","['Yunnan University', 'Yunnan University', 'Yuan Ze University', 'Yunnan University']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Generation', 'SNLP: Question Answering']","Chen, R., Wang, J., Yu, L.-C., & Zhang, X. (2023). Learning to Memorize Entailment and Discourse Relations for Persona-Consistent Dialogues. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12653-12661. https://doi.org/10.1609/aaai.v37i11.26489","Abstract 					Maintaining engagement and consistency is particularly important in dialogue systems. Existing works have improved the performance of dialogue systems by intentionally learning interlocutor personas with sophisticated network structures. One issue with this approach is that it requires more personal corpora with annotations. Additionally, these models typically perform the next utterance prediction to generate a response but neglect the discourse coherence in the entire conversation. To address these issues, this study proposes a method of learning to memorize entailment and discourse relations for persona-consistent dialogue tasks. Entailment text pairs in natural language inference dataset were applied to learn latent entailment relations as external memories by premise-to-hypothesis generation task. Furthermore, an internal memory with a similar architecture was applied to the discourse information in the dialogue. Placing orthogonality restrictions on these two memory spaces ensures that the latent entailment relations remain dialogue-independent. Both memories collaborate to obtain entailment and discourse representation for the generation, allowing a deeper understanding of both consistency and coherence. Experiments on two large public datasets, PersonaChat and DSTC7-AVSD, demonstrated the effectiveness of the proposed method. Both automatic and human evaluations indicate that the proposed model outperforms several strong baselines in terms of both persona consistency and response coherence. Our source code is availabled at https://github.com/Chenrj233/LMEDR.","https://ojs.aaai.org/index.php/AAAI/article/view/26489/26261"
"26490","Preference-Controlled Multi-Objective Reinforcement Learning for Conditional Text Generation","['Wenqing Chen', 'Jidong Tian', 'Caoyun Fan', 'Yitian Li', 'Hao He', 'Yaohui Jin']","['Sun Yat-sen University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['SNLP: Generation', 'SNLP: Applications']","Chen, W., Tian, J., Fan, C., Li, Y., He, H., & Jin, Y. (2023). Preference-Controlled Multi-Objective Reinforcement Learning for Conditional Text Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12662-12672. https://doi.org/10.1609/aaai.v37i11.26490","Abstract 					Conditional text generation is to generate text sequences conditioning on linguistic or non-linguistic data. The main line of existing work proposed deterministic models to improve the fidelity of the generated text but often ignored the diversity. Another line relied on conditional variational auto-encoders (CVAEs), which increased the diversity over their deterministic backbones. However, CVAEs regard diversity as an implicit objective and may not be optimal. In this paper, we raise two questions:  i) Can diversity be further improved with an explicit objective? ii) Since fidelity and diversity are two conflicting objectives, how can we obtain different multi-objective optimal solutions according to user preferences? To answer question i), we propose a multi-objective reinforcement learning (MORL) method which explicitly takes CIDEr and Self-CIDEr scores as the fidelity-oriented and diversity-oriented rewards respectively. To answer question ii), we propose a preference-controlled MORL method, which can obtain infinite multi-objective optimal solutions by tuning the preference variable. We conduct extensive experiments on paraphrasing and image captioning tasks, which show that in the fidelity-diversity trade-off space, our model outperforms both deterministic and CVAE-based baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/26490/26262"
"26491","Learning towards Selective Data Augmentation for Dialogue Generation","['Xiuying Chen', 'Mingzhe Li', 'Jiayi Zhang', 'Xiaoqiang Xia', 'Chen Wei', 'Jianwei Cui', 'Xin Gao', 'Xiangliang Zhang', 'Rui Yan']","['Computational Bioscience Research Center, KAUST', 'Ant Group', 'Xiaomi AI Lab', 'Xiaomi AI Lab', 'Xiaomi AI Lab', 'Xiaomi AI Lab', 'Computational Bioscience Research Center, KAUST', 'University of Notre Dame', 'Gaoling School of Artificial Intelligence, Renmin University of China']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Generation']","Chen, X., Li, M., Zhang, J., Xia, X., Wei, C., Cui, J., Gao, X., Zhang, X., & Yan, R. (2023). Learning towards Selective Data Augmentation for Dialogue Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12673-12681. https://doi.org/10.1609/aaai.v37i11.26491","Abstract 					As it is cumbersome and expensive to acquire a huge amount of data for training neural dialog models, data augmentation is proposed to effectively utilize existing training samples. However, current data augmentation techniques on the dialog generation task mostly augment all cases in the training dataset without considering the intrinsic attributes between different cases. We argue that not all cases are beneficial for augmentation task, and the cases suitable for augmentation should obey the following two attributes:  (1) low-quality (the dialog model cannot generate a high-quality response for the case), (2) representative (the case should represent the property of the whole dataset). Herein, we explore this idea by proposing a Selective Data Augmentation framework (SDA) for the response generation task. SDA employs a dual adversarial network to select the lowest quality and most representative data points for augmentation in one stage.  Extensive experiments conducted on two publicly available datasets, i.e., DailyDialog and OpenSubtitles, show that our framework can improve the response generation performance with respect to various metrics","https://ojs.aaai.org/index.php/AAAI/article/view/26491/26263"
"26492","Learn from Yesterday: A Semi-supervised Continual Learning Method for Supervision-Limited Text-to-SQL Task Streams","['Yongrui Chen', 'Xinnan Guo', 'Tongtong Wu', 'Guilin Qi', 'Yang Li', 'Yang Dong']","['Southeast University', 'Southeast University', 'Southeast University\nSchool of Computer Science and Engineering', 'Southeast University', 'Alibaba Group', 'Ant Group']","['SNLP: Lexical & Frame Semantics', 'Semantic Parsing', 'ML: Lifelong and Continual Learning', 'ML: Semi-Supervised Learning', 'SNLP: Question Answering']","Chen, Y., Guo, X., Wu, T., Qi, G., Li, Y., & Dong, Y. (2023). Learn from Yesterday: A Semi-supervised Continual Learning Method for Supervision-Limited Text-to-SQL Task Streams. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12682-12690. https://doi.org/10.1609/aaai.v37i11.26492","Abstract 					Conventional text-to-SQL studies are limited to a single task with a fixed-size training and test set. When confronted with a stream of tasks common in real-world applications, existing methods struggle with the problems of insufficient supervised data and high retraining costs. The former tends to cause overfitting on unseen databases for the new task, while the latter makes a full review of instances from past tasks impractical for the model, resulting in forgetting of learned SQL structures and database schemas. To address the problems, this paper proposes integrating semi-supervised learning (SSL) and continual learning (CL) in a stream of text-to-SQL tasks and offers two promising solutions in turn. The first solution Vanilla is to perform self-training, augmenting the supervised training data with predicted pseudo-labeled instances of the current task, while replacing the full volume retraining with episodic memory replay to balance the training efficiency with the performance of previous tasks. The improved solution SFNet takes advantage of the intrinsic connection between CL and SSL. It uses in-memory past information to help current SSL, while adding high-quality pseudo instances in memory to improve future replay.  The experiments on two datasets shows that SFNet outperforms the widely-used SSL-only and CL-only baselines on multiple metrics.","https://ojs.aaai.org/index.php/AAAI/article/view/26492/26264"
"26493","A Scope Sensitive and Result Attentive Model for Multi-Intent Spoken Language Understanding","['Lizhi Cheng', 'Wenmian Yang', 'Weijia Jia']","['Shanghai Jiao Tong University', 'Nanyang Technological University', 'BNU-UIC Institute of Artificial Intelligence and Future Networks, Beijing Normal University (Zhuhai), Guangdong Key Lab\nof AI and Multi-Modal Data Processing, BNU-HKBU United International College, Zhuhai, Guang Dong, PR China']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Speech and Multimodality']","Cheng, L., Yang, W., & Jia, W. (2023). A Scope Sensitive and Result Attentive Model for Multi-Intent Spoken Language Understanding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12691-12699. https://doi.org/10.1609/aaai.v37i11.26493","Abstract 					Multi-Intent Spoken Language Understanding (SLU), a novel and more complex scenario of SLU, is attracting increasing attention. Unlike traditional SLU, each intent in this scenario has its specific scope. Semantic information outside the scope even hinders the prediction, which tremendously increases the difficulty of intent detection. More seriously, guiding slot filling with these inaccurate intent labels suffers error propagation problems, resulting in unsatisfied overall performance. To solve these challenges, in this paper, we propose a novel Scope-Sensitive Result Attention Network (SSRAN) based on Transformer, which contains a Scope Recognizer (SR) and a Result Attention Network (RAN). SR assignments scope information to each token, reducing the distraction of out-of-scope tokens. RAN effectively utilizes the bidirectional interaction between SF and ID results, mitigating the error propagation problem. Experiments on two public datasets indicate that our model significantly improves SLU performance (5.4% and 2.1% on Overall accuracy) over the state-of-the-art baseline.","https://ojs.aaai.org/index.php/AAAI/article/view/26493/26265"
"26494","Unsupervised Explanation Generation via Correct Instantiations","['Sijie Cheng', 'Zhiyong Wu', 'Jiangjie Chen', 'Zhixing Li', 'Yang Liu', 'Lingpeng Kong']","['Shanghai Artificial Intelligence Laboratory\nFudan University', 'Shanghai Artificial Intelligence Laboratory', 'Fudan University', 'Full Truck Alliance', 'Institute for AI Industry Research, Tsinghua University\nDepartment of Computer Science and Technology, Tsinghua University', 'Shanghai Artificial Intelligence Laboratory\nThe University of Hong Kong']","['SNLP: Interpretability & Analysis of NLP Models']","Cheng, S., Wu, Z., Chen, J., Li, Z., Liu, Y., & Kong, L. (2023). Unsupervised Explanation Generation via Correct Instantiations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12700-12708. https://doi.org/10.1609/aaai.v37i11.26494","Abstract 					While large pre-trained language models (PLM) have shown their great skills at solving discriminative tasks, a significant gap remains when compared with humans for explanation-related tasks. Among them, explaining the reason why a statement is wrong (e.g., against commonsense) is incredibly challenging.  The major difficulty is finding the conflict point, where the statement contradicts our real world. This paper proposes Neon, a two-phrase, unsupervised explanation generation framework. Neon first generates corrected instantiations of the statement (phase I), then uses them to prompt large PLMs to find the conflict point and complete the explanation (phase II). We conduct extensive experiments on two standard explanation benchmarks, i.e., ComVE and e-SNLI. According to both automatic and human evaluations, Neon outperforms baselines, even for those with human-annotated instantiations. In addition to explaining a negative prediction, we further demonstrate that Neon remains effective when generalizing to different scenarios. The resources of Neon are available at: https://github.com/Shark-NLP/Neon.","https://ojs.aaai.org/index.php/AAAI/article/view/26494/26266"
"26495","Prompt-Augmented Linear Probing: Scaling beyond the Limit of Few-Shot In-Context Learners","['Hyunsoo Cho', 'Hyuhng Joon Kim', 'Junyeob Kim', 'Sang-Woo Lee', 'Sang-goo Lee', 'Kang Min Yoo', 'Taeuk Kim']","['Seoul National University', 'Seoul National University', 'Seoul National University', 'Naver Cloud\nKAIST', 'Seoul National University', 'Seoul National University\nNaver Cloud', 'Hanyang University']","['SNLP: Language Models', 'SNLP: Text Classification']","Cho, H., Kim, H. J., Kim, J., Lee, S.-W., Lee, S.- goo, Yoo, K. M., & Kim, T. (2023). Prompt-Augmented Linear Probing: Scaling beyond the Limit of Few-Shot In-Context Learners. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12709-12718. https://doi.org/10.1609/aaai.v37i11.26495","Abstract 					Through in-context learning (ICL), large-scale language models are effective few-shot learners without additional model fine-tuning.  However, the ICL performance does not scale well with the number of available training sample as it is limited by the inherent input length constraint of the underlying language model. Meanwhile, many studies have revealed that language models are also powerful feature extractors, allowing them to be utilized in a black-box manner and enabling the linear probing paradigm, where lightweight discriminators are trained on top of the pre-extracted input representations. This paper proposes prompt-augmented linear probing (PALP), a hybrid of linear probing and ICL, which leverages the best of both worlds. PALP inherits the scalability of linear probing and the capability of enforcing language models to derive more meaningful representations via tailoring input into a more conceivable form. Throughout in-depth investigations on various datasets, we verified that PALP significantly closes the gap between ICL in the data-hungry scenario and fine-tuning in the data-abundant scenario with little training overhead, potentially making PALP a strong alternative in a black-box scenario.","https://ojs.aaai.org/index.php/AAAI/article/view/26495/26267"
"26496","Neural Dynamic Focused Topic Model","['Kostadin Cvejoski', 'Ramsés J. Sánchez', 'César Ojeda']","['Fraunhofer IAIS', 'BIT University of Bonn', 'University of Potsdam']","['SNLP: Text Mining', 'ML: Deep Generative Models & Autoencoders', 'ML: Probabilistic Methods', 'SNLP: Applications']","Cvejoski, K., Sánchez, R. J., & Ojeda, C. (2023). Neural Dynamic Focused Topic Model. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12719-12727. https://doi.org/10.1609/aaai.v37i11.26496","Abstract 					Topic models and all their variants analyse text by learning meaningful representations through word co-occurrences. As pointed out by previous work, such models implicitly assume that the probability of a topic to be active and its proportion within each document are positively correlated. This correlation can be strongly detrimental in the case of documents created over time, simply because recent documents are likely better described by new and hence rare topics. In this work we leverage recent advances in neural variational inference and present an alternative neural approach to the dynamic Focused Topic Model. Indeed, we develop a neural model for topic evolution which exploits sequences of Bernoulli random variables in order to track the appearances of topics, thereby decoupling their activities from their proportions. We evaluate our model on three different datasets (the UN general debates, the collection of NeurIPS papers, and the ACL Anthology dataset) and show that it (i) outperforms state-of-the-art topic models in generalization tasks and (ii) performs comparably to them on prediction tasks, while employing roughly the same number of parameters, and converging about two times faster.","https://ojs.aaai.org/index.php/AAAI/article/view/26496/26268"
"26497","Improving Simultaneous Machine Translation with Monolingual Data","['Hexuan Deng', 'Liang Ding', 'Xuebo Liu', 'Meishan Zhang', 'Dacheng Tao', 'Min Zhang']","['Institute of Computing and Intelligence, Harbin Institute of Technology, Shenzhen, China', 'JD Explore Academy', 'Institute of Computing and Intelligence, Harbin Institute of Technology, Shenzhen, China', 'Institute of Computing and Intelligence, Harbin Institute of Technology, Shenzhen, China', 'JD Explore Academy', 'Institute of Computing and Intelligence, Harbin Institute of Technology, Shenzhen, China']","['SNLP: Machine Translation & Multilinguality']","Deng, H., Ding, L., Liu, X., Zhang, M., Tao, D., & Zhang, M. (2023). Improving Simultaneous Machine Translation with Monolingual Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12728-12736. https://doi.org/10.1609/aaai.v37i11.26497","Abstract 					Simultaneous machine translation (SiMT) is usually done via sequence-level knowledge distillation (Seq-KD) from a full-sentence neural machine translation (NMT) model. However, there is still a significant performance gap between NMT and SiMT. In this work, we propose to leverage monolingual data to improve SiMT, which trains a SiMT student on the combination of bilingual data and external monolingual data distilled by Seq-KD. Preliminary experiments on En-Zh and En-Ja news domain corpora demonstrate that monolingual data can significantly improve translation quality (e.g., +3.15 BLEU on En-Zh). Inspired by the behavior of human simultaneous interpreters, we propose a novel monolingual sampling strategy for SiMT, considering both chunk length and monotonicity. Experimental results show that our sampling strategy consistently outperforms the random sampling strategy (and other conventional typical NMT monolingual sampling strategies) by avoiding the key problem of SiMT -- hallucination, and has better scalability. We achieve +0.72 BLEU improvements on average against random sampling on En-Zh and En-Ja. Data and codes can be found at https://github.com/hexuandeng/Mono4SiMT.","https://ojs.aaai.org/index.php/AAAI/article/view/26497/26269"
"26498","Domain-Adapted Dependency Parsing for Cross-Domain Named Entity Recognition","['Chenxiao Dou', 'Xianghui Sun', 'Yaoshu Wang', 'Yunjie Ji', 'Baochang Ma', 'Xiangang Li']","['Nanhu Academy of Electronics and Information Technology', 'BeiKe', 'Shenzhen Institute of Computing Sciences, Shenzhen University', 'Beike', 'Beike', 'Beike']","['SNLP: Syntax -- Tagging', 'Chunking & Parsing', 'SNLP: Lexical & Frame Semantics', 'Semantic Parsing', 'SNLP: Other Foundations of Speech & Natural Language Processing', 'SNLP: Phonology', 'Morphology', 'Word Segmentation', 'SNLP: Text Mining']","Dou, C., Sun, X., Wang, Y., Ji, Y., Ma, B., & Li, X. (2023). Domain-Adapted Dependency Parsing for Cross-Domain Named Entity Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12737-12744. https://doi.org/10.1609/aaai.v37i11.26498","Abstract 					In recent years, many researchers have leveraged structural information from dependency trees to improve Named Entity Recognition (NER). Most of their methods take dependency-tree labels as input features for NER model training. However, such dependency information is not inherently provided in most NER corpora, making the methods with low usability in practice. To effectively exploit the potential of word-dependency knowledge, motivated by the success of Multi-Task Learning on cross-domain NER, we investigate a novel NER learning method incorporating cross-domain Dependency Parsing (DP) as its auxiliary learning task. Then, considering the high consistency of word-dependency relations across domains, we present an unsupervised domain-adapted method to transfer word-dependency knowledge from high-resource domains to low-resource ones. With the help of cross-domain DP to bridge different domains, both useful cross-domain and cross-task knowledge can be learned by our model to considerably benefit cross-domain NER. To make better use of the cross-task knowledge between NER and DP, we unify both tasks in a shared network architecture for joint learning, using Maximum Mean Discrepancy(MMD). Finally, through extensive experiments, we show our proposed method can not only effectively take advantage of word-dependency knowledge, but also significantly outperform other Multi-Task Learning methods on cross-domain NER. Our code is open-source and available at https://github.com/xianghuisun/DADP.","https://ojs.aaai.org/index.php/AAAI/article/view/26498/26270"
"26499","MultiSpider: Towards Benchmarking Multilingual Text-to-SQL Semantic Parsing","['Longxu Dou', 'Yan Gao', 'Mingyang Pan', 'Dingzirui Wang', 'Wanxiang Che', 'Dechen Zhan', 'Jian-Guang Lou']","['Harbin Institute of Technology', 'Microsoft Research Asia', 'Harbin Institute of Technology', 'Harbin Institute of Technology', 'Harbin Institute of Technology', 'Harbin Institute of Technology', 'Microsoft Research Asia']","['SNLP: Lexical & Frame Semantics', 'Semantic Parsing', 'SNLP: Question Answering', 'SNLP: Sentence-Level Semantics and Textual Inference', 'SNLP: Syntax -- Tagging', 'Chunking & Parsing']","Dou, L., Gao, Y., Pan, M., Wang, D., Che, W., Zhan, D., & Lou, J.-G. (2023). MultiSpider: Towards Benchmarking Multilingual Text-to-SQL Semantic Parsing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12745-12753. https://doi.org/10.1609/aaai.v37i11.26499","Abstract 					Text-to-SQL semantic parsing is an important NLP task, which facilitates the interaction between users and the database. Much recent progress in text-to-SQL has been driven by large-scale datasets, but most of them are centered on English. In this work, we present MultiSpider, the largest multilingual text-to-SQL semantic parsing dataset which covers seven languages (English, German, French, Spanish, Japanese, Chinese, and Vietnamese). Upon MultiSpider we further identify the lexical and structural challenges of text-to-SQL  (caused by specific language properties and dialect sayings) and their intensity across different languages. Experimental results under various settings (zero-shot, monolingual and multilingual) reveal a 6.1% absolute drop in accuracy in non-English languages. Qualitative and quantitative analyses are conducted to understand the reason for the performance drop of each language. Besides the dataset, we also propose a simple schema augmentation framework SAVe (Schema-Augmentation-with-Verification), which significantly boosts the overall performance by about 1.8% and closes the 29.5% performance gap across languages.","https://ojs.aaai.org/index.php/AAAI/article/view/26499/26271"
"26500","Learning to Select from Multiple Options","['Jiangshu Du', 'Wenpeng Yin', 'Congying Xia', 'Philip S. Yu']","['University of Illinois at Chicago', 'Penn State University', 'Salesforce Research', 'University of Illinois at Chicago']","['SNLP: Applications', 'SNLP: Sentence-Level Semantics and Textual Inference', 'SNLP: Text Classification']","Du, J., Yin, W., Xia, C., & Yu, P. S. (2023). Learning to Select from Multiple Options. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12754-12762. https://doi.org/10.1609/aaai.v37i11.26500","Abstract 					Many NLP tasks can be regarded as a selection problem from a set of options, such as classification tasks, multi-choice question answering, etc. Textual entailment (TE) has been shown as the state-of-the-art (SOTA) approach to dealing with those selection problems. TE treats input texts as premises (P), options as hypotheses (H), then handles the selection problem by modeling (P, H) pairwise. Two limitations: first, the pairwise modeling is unaware of other options, which is less intuitive since humans often determine the best options by comparing competing candidates; second, the inference process of pairwise TE is time-consuming, especially when the option space is large. To deal with the two issues, this work first proposes a contextualized TE model (Context-TE) by appending other k options as the context of the current (P, H) modeling. Context-TE is able to learn more reliable decision for the H since it considers various context. Second, we speed up Context-TE by coming up with Parallel-TE, which learns the decisions of multiple options simultaneously. Parallel-TE significantly improves the inference speed while keeping comparable performance with Context-TE. Our methods are evaluated on three tasks (ultra-fine entity typing, intent detection and multi-choice QA) that are typical selection problems with different sizes of options. Experiments show our models set new SOTA performance; particularly, Parallel-TE is faster than the pairwise TE by k times in inference.","https://ojs.aaai.org/index.php/AAAI/article/view/26500/26272"
"26501","Real or Fake Text?: Investigating Human Ability to Detect Boundaries between Human-Written and Machine-Generated Text","['Liam Dugan', 'Daphne Ippolito', 'Arun Kirubarajan', 'Sherry Shi', 'Chris Callison-Burch']","['University of Pennsylvania', 'University of Pennsylvania', 'University of Pennsylvania', 'University of Pennsylvania', 'University of Pennsylvania']","['SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Language Models', 'HAI: Learning Human Values and Preferences', 'SNLP: Generation', 'SNLP: Bias', 'Fairness', 'Transparency & Privacy']","Dugan, L., Ippolito, D., Kirubarajan, A., Shi, S., & Callison-Burch, C. (2023). Real or Fake Text?: Investigating Human Ability to Detect Boundaries between Human-Written and Machine-Generated Text. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12763-12771. https://doi.org/10.1609/aaai.v37i11.26501","Abstract 					As text generated by large language models proliferates, it becomes vital to understand how humans engage with such text, and whether or not they are able to detect when the text they are reading did not originate with a human writer. Prior work on human detection of generated text focuses on the case where an entire passage is either human-written or machine-generated. In this paper, we study a more realistic setting where text begins as human-written and transitions to being generated by state-of-the-art neural language models. We show that, while annotators often struggle at this task, there is substantial variance in annotator skill and that given proper incentives, annotators can improve at this task over time. Furthermore, we conduct a detailed comparison study and analyze how a variety of variables (model size, decoding strategy, fine-tuning, prompt genre, etc.) affect human detection performance. Finally, we collect error annotations from our participants and use them to show that certain textual genres influence models to make different types of errors and that certain sentence-level features correlate highly with annotator selection. We release the RoFT dataset: a collection of over 21,000 human annotations paired with error classifications to encourage future work in human detection and evaluation of generated text.","https://ojs.aaai.org/index.php/AAAI/article/view/26501/26273"
"26502","Diffuser: Efficient Transformers with Multi-Hop Attention Diffusion for Long Sequences","['Aosong Feng', 'Irene Li', 'Yuang Jiang', 'Rex Ying']","['Yale University', 'Yale University', 'Yale University', 'Yale University']","['SNLP: Language Models', 'ML: Classification and Regression', 'ML: Deep Neural Network Algorithms', 'ML: Graph-based Machine Learning', 'SNLP: Question Answering', 'SNLP: Text Classification']","Feng, A., Li, I., Jiang, Y., & Ying, R. (2023). Diffuser: Efficient Transformers with Multi-Hop Attention Diffusion for Long Sequences. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12772-12780. https://doi.org/10.1609/aaai.v37i11.26502","Abstract 					Efficient Transformers have been developed for long sequence modeling, due to their subquadratic memory and time complexity. Sparse Transformer is a popular approach to improving the efficiency of Transformers by restricting self-attention to locations specified by the predefined sparse patterns. However, leveraging sparsity may sacrifice expressiveness compared to full-attention, when important token correlations are multiple hops away. To combine advantages of both the efficiency of sparse transformer and the expressiveness of full-attention Transformer, we propose Diffuser, a new state-of-the-art efficient Transformer. Diffuser incorporates all token interactions within one attention layer while maintaining low computation and memory costs. The key idea is to expand the receptive field of sparse attention using Attention Diffusion, which computes multi-hop token correlations based on all paths between corresponding disconnected tokens, besides attention among neighboring tokens. Theoretically, we show the expressiveness of Diffuser as a universal sequence approximator for sequence-to-sequence modeling, and investigate its ability to approximate full-attention by analyzing the graph expander property from the spectral perspective. Experimentally, we investigate the effectiveness of Diffuser with extensive evaluations, including language modeling, image modeling, and Long Range Arena (LRA).  Evaluation results show that Diffuser achieves improvements by an average of 0.94% on text classification tasks and 2.30% on LRA, with 1.67x memory savings compared to state-of-the-art benchmarks, which demonstrates superior performance of Diffuser in both expressiveness and efficiency aspects.","https://ojs.aaai.org/index.php/AAAI/article/view/26502/26274"
"26503","Cogito Ergo Summ: Abstractive Summarization of Biomedical Papers via Semantic Parsing Graphs and Consistency Rewards","['Giacomo Frisoni', 'Paolo Italiani', 'Stefano Salvatori', 'Gianluca Moro']","['University of Bologna, Italy', 'University of Bologna, Italy', 'University of Bologna, Italy', 'University of Bologna, Italy']","['SNLP: Summarization', 'APP: Bioinformatics', 'ML: Deep Neural Architectures', 'ML: Reinforcement Learning Algorithms', 'SNLP: Generation', 'SNLP: Language Grounding', 'SNLP: Language Models', 'SNLP: Learning & Optimization for SNLP', 'SNLP: Lexical & Frame Semantics', 'Semantic Parsing', 'SNLP: Sentence-Level Semantics and Textual Inference', 'KRR: Other Foundations of Knowledge Representation & Reasoning']","Frisoni, G., Italiani, P., Salvatori, S., & Moro, G. (2023). Cogito Ergo Summ: Abstractive Summarization of Biomedical Papers via Semantic Parsing Graphs and Consistency Rewards. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12781-12789. https://doi.org/10.1609/aaai.v37i11.26503","Abstract 					The automatic synthesis of biomedical publications catalyzes a profound research interest elicited by literature congestion. Current sequence-to-sequence models mainly rely on the lexical surface and seldom consider the deep semantic interconnections between the entities mentioned in the source document. Such superficiality translates into fabricated, poorly informative, redundant, and near-extractive summaries that severely restrict their real-world application in biomedicine, where the specialized jargon and the convoluted facts further emphasize task complexity. To fill this gap, we argue that the summarizer should acquire semantic interpretation over input, exploiting structured and unambiguous representations to capture and conserve the most relevant parts of the text content. This paper presents CogitoErgoSumm, the first framework for biomedical abstractive summarization equipping large pre-trained language models with rich semantic graphs. Precisely, we infuse graphs from two complementary semantic parsing techniques with different goals and granularities—Event Extraction and Abstract Meaning Representation, also designing a reward signal to maximize information content preservation through reinforcement learning. Extensive quantitative and qualitative evaluations on the CDSR dataset show that our solution achieves competitive performance according to multiple metrics, despite using 2.5x fewer parameters. Results and ablation studies indicate that our joint text-graph model generates more enlightening, readable, and consistent summaries. Code available at: https://github.com/disi-unibo-nlp/cogito-ergo-summ.","https://ojs.aaai.org/index.php/AAAI/article/view/26503/26275"
"26504","MIGA: A Unified Multi-Task Generation Framework for Conversational Text-to-SQL","['Yingwen Fu', 'Wenjie Ou', 'Zhou Yu', 'Yue Lin']","['Guangdong University of Foreign Studies, Guangzhou, China\nNetEase Games AI Lab, Guangzhou, China', 'NetEase Games AI Lab, Guangzhou, China', 'Columbia University', 'NetEase Games AI Lab, Guangzhou, China']","['SNLP: Generation', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'SNLP: Conversational AI/Dialogue Systems', 'SNLP: Language Models']","Fu, Y., Ou, W., Yu, Z., & Lin, Y. (2023). MIGA: A Unified Multi-Task Generation Framework for Conversational Text-to-SQL. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12790-12798. https://doi.org/10.1609/aaai.v37i11.26504","Abstract 					Conversational text-to-SQL is designed to translate multi-turn natural language questions into their corresponding SQL queries. Most advanced conversational text-to-SQL methods are incompatible with generative pre-trained language models (PLMs), such as T5. In this paper, we present a two-stage unified MultI-task Generation frAmework (MIGA) that leverages PLMs’ ability to tackle conversational text-to-SQL. In the pre-training stage, MIGA first decomposes the main task into several related sub-tasks and then unifies them into the same sequence-to-sequence (Seq2Seq) paradigm with task-specific natural language prompts to boost the main task from multi-task training. Later in the fine-tuning stage, we propose four SQL perturbations to alleviate the error propagation problem. MIGA tends to achieve state-of-the-art performance on two benchmarks (SparC and CoSQL). We also provide extensive analyses and discussions to shed light on some new perspectives for conversational text-to-SQL.","https://ojs.aaai.org/index.php/AAAI/article/view/26504/26276"
"26505","On the Effectiveness of Parameter-Efficient Fine-Tuning","['Zihao Fu', 'Haoran Yang', 'Anthony Man-Cho So', 'Wai Lam', 'Lidong Bing', 'Nigel Collier']","['University of Cambridge', 'The Chinese University of Hong Kong', 'The Chinese University of Hong Kong', 'The Chinese University of Hong Kong', 'DAMO Academy, Alibaba Group', 'University of Cambridge']","['SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Adversarial Attacks & Robustness', 'SNLP: Other Foundations of Speech & Natural Language Processing']","Fu, Z., Yang, H., So, A. M.-C., Lam, W., Bing, L., & Collier, N. (2023). On the Effectiveness of Parameter-Efficient Fine-Tuning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12799-12807. https://doi.org/10.1609/aaai.v37i11.26505","Abstract 					Fine-tuning pre-trained models has been ubiquitously proven to be effective in a wide range of NLP tasks. However, fine-tuning the whole model is parameter inefficient as it always yields an entirely new model for each task. Currently, many research works propose to only fine-tune a small portion of the parameters while keeping most of the parameters shared across different tasks. These methods achieve surprisingly good performance and are shown to be more stable than their corresponding fully fine-tuned counterparts. However, such kind of methods is still not well understood. Some natural questions arise: How does the parameter sparsity lead to promising performance? Why is the model more stable than the fully fine-tuned models? How to choose the tunable parameters? In this paper, we first categorize the existing methods into random approaches, rule-based approaches, and projection-based approaches based on how they choose which parameters to tune. Then, we show that all of the methods are actually sparse fine-tuned models and conduct a novel theoretical analysis of them. We indicate that the sparsity is actually imposing a regularization on the original model by controlling the upper bound of the stability. Such stability leads to better generalization capability which has been empirically observed in a lot of recent research works. Despite the effectiveness of sparsity grounded by our theory, it still remains an open problem of how to choose the tunable parameters. Currently, the random and rule-based methods do not utilize task-specific data information while the projection-based approaches suffer from the projection discontinuity problem. To better choose the tunable parameters, we propose a novel Second-order Approximation Method (SAM) which approximates the original problem with an analytically solvable optimization function. The tunable parameters are determined by directly optimizing the approximation function. We conduct extensive experiments on several tasks. The experimental results show that our proposed SAM model outperforms many strong baseline models and it also verifies our theoretical analysis. The source code of this paper can be obtained from https://github.com/fuzihaofzh/AnalyzeParameterEff\/icientFinetune .","https://ojs.aaai.org/index.php/AAAI/article/view/26505/26277"
"26506","SumREN: Summarizing Reported Speech about Events in News","['Revanth Gangi Reddy', 'Heba Elfardy', 'Hou Pong Chan', 'Kevin Small', 'Heng Ji']","['University of Illinois at Urbana-Champaign', 'Amazon Alexa', 'University of Macau', 'Amazon Alexa', 'Amazon Alexa']","['SNLP: Summarization', 'SNLP: Applications', 'SNLP: Generation', 'SNLP: Question Answering']","Gangi Reddy, R., Elfardy, H., Chan, H. P., Small, K., & Ji, H. (2023). SumREN: Summarizing Reported Speech about Events in News. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12808-12817. https://doi.org/10.1609/aaai.v37i11.26506","Abstract 					A primary objective of news articles is to establish the factual record for an event, frequently achieved by conveying both the details of the specified event (i.e., the 5 Ws; Who, What, Where, When and Why regarding the event) and how people reacted to it (i.e., reported statements). However, existing work on news summarization almost exclusively focuses on the event details. In this work, we propose the novel task of summarizing the reactions of different speakers, as expressed by their reported statements, to a given event. To this end, we create a new multi-document summarization benchmark, SumREN, comprising 745 summaries of reported statements from various public figures obtained from 633 news articles discussing 132 events. We propose an automatic silver-training data generation approach for our task, which helps smaller models like BART achieve GPT-3 level performance on this task. Finally, we introduce a pipeline-based framework for summarizing reported speech, which we empirically show to generate summaries that are more abstractive and factual than baseline query-focused summarization approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/26506/26278"
"26507","ProKD: An Unsupervised Prototypical Knowledge Distillation Network for Zero-Resource Cross-Lingual Named Entity Recognition","['Ling Ge', 'Chunming Hu', 'Guanghui Ma', 'Hong Zhang', 'Jihong Liu']","['Beihang University', 'Beihang University', 'Beihang University', 'National Computer Network Emergency Response Technical Team / Coordination Center of China', 'Beihang University']","['SNLP: Applications', 'SNLP: Information Extraction']","Ge, L., Hu, C., Ma, G., Zhang, H., & Liu, J. (2023). ProKD: An Unsupervised Prototypical Knowledge Distillation Network for Zero-Resource Cross-Lingual Named Entity Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12818-12826. https://doi.org/10.1609/aaai.v37i11.26507","Abstract 					For named entity recognition (NER) in zero-resource languages, utilizing knowledge distillation methods to transfer language-independent knowledge from the rich-resource source languages to zero-resource languages is an effective means. Typically, these approaches adopt a teacher-student architecture, where the teacher network is trained in the source language, and the student network seeks to learn knowledge from the teacher network and is expected to perform well in the target language. Despite the impressive performance achieved by these methods, we argue that they have two limitations. Firstly, the teacher network fails to effectively learn language-independent knowledge shared across languages due to the differences in the feature distribution between the source and target languages. Secondly,  the student network acquires all of its knowledge from the teacher network and ignores the learning of target language-specific knowledge. Undesirably, these limitations would hinder the model's performance in the target language. This paper proposes an unsupervised prototype knowledge distillation network (ProKD) to address these issues. Specifically, ProKD presents a contrastive learning-based prototype alignment method to achieve class feature alignment by adjusting the prototypes' distance from the source and target languages, boosting the teacher network's capacity to acquire language-independent knowledge. In addition, ProKD introduces a prototype self-training method to learn the intrinsic structure of the language by retraining the student network on the target data using samples' distance information from prototypes, thereby enhancing the student network's ability to acquire language-specific knowledge. Extensive experiments on three benchmark cross-lingual NER datasets demonstrate the effectiveness of our approach.","https://ojs.aaai.org/index.php/AAAI/article/view/26507/26279"
"26508","Denoising Pre-training for Machine Translation Quality Estimation with Curriculum Learning","['Xiang Geng', 'Yu Zhang', 'Jiahuan Li', 'Shujian Huang', 'Hao Yang', 'Shimin Tao', 'Yimeng Chen', 'Ning Xie', 'Jiajun Chen']","['National Key Laboratory for Novel Software Technology, Nanjing University', 'National Key Laboratory for Novel Software Technology, Nanjing University', 'National Key Laboratory for Novel Software Technology, Nanjing University', 'National Key Laboratory for Novel Software Technology, Nanjing University', 'Huawei', 'Huawei', 'Huawei', 'Huawei', 'National Key Laboratory for Novel Software Technology, Nanjing University']","['SNLP: Machine Translation & Multilinguality']","Geng, X., Zhang, Y., Li, J., Huang, S., Yang, H., Tao, S., Chen, Y., Xie, N., & Chen, J. (2023). Denoising Pre-training for Machine Translation Quality Estimation with Curriculum Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12827-12835. https://doi.org/10.1609/aaai.v37i11.26508","Abstract 					Quality estimation (QE) aims to assess the quality of machine translations when reference translations are unavailable. QE plays a crucial role in many real-world applications of machine translation. Because labeled QE data are usually limited in scale, recent research, such as DirectQE, pre-trains QE models with pseudo QE data and obtains remarkable performance. However, there tends to be inevitable noise in the pseudo data, hindering models from learning QE accurately. Our study shows that the noise mainly comes from the differences between pseudo and real translation outputs. To handle this problem, we propose CLQE, a denoising pre-training framework for QE based on curriculum learning. More specifically, we propose to measure the degree of noise in the pseudo QE data with some metrics based on statistical or distributional features. With the guidance of these metrics, CLQE gradually pre-trains the QE model using data from cleaner to noisier. Experiments on various benchmarks reveal that CLQE outperforms DirectQE and other strong baselines. We also show that with our framework, pre-training converges faster than directly using the pseudo data. We make our CLQE code available (https://github.com/NJUNLP/njuqe).","https://ojs.aaai.org/index.php/AAAI/article/view/26508/26280"
"26509","Generating Coherent Narratives by Learning Dynamic and Discrete Entity States with a Contrastive Framework","['Jian Guan', 'Zhenyu Yang', 'Rongsheng Zhang', 'Zhipeng Hu', 'Minlie Huang']","['The CoAI group, DCST\nInstitute for Artificial Intelligence\nState Key Lab of Intelligent Technology and Systems\nBeijing National Research Center for Information Science and Technology\nTsinghua University, Beijing 100084, China', 'Guangdong OPPO Mobile Telecommunications Corp., Ltd.', 'Fuxi AI Lab, NetEase Inc., Hangzhou, China', 'Fuxi AI Lab, NetEase Inc., Hangzhou, China', 'The CoAI group, DCST\nInstitute for Artificial Intelligence\nState Key Lab of Intelligent Technology and Systems\nBeijing National Research Center for Information Science and Technology\nTsinghua University, Beijing 100084, China']","['SNLP: Generation']","Guan, J., Yang, Z., Zhang, R., Hu, Z., & Huang, M. (2023). Generating Coherent Narratives by Learning Dynamic and Discrete Entity States with a Contrastive Framework. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12836-12844. https://doi.org/10.1609/aaai.v37i11.26509","Abstract 					Despite advances in generating fluent texts, existing pretraining models tend to attach incoherent event sequences to involved entities when generating narratives such as stories and news. We conjecture that such issues result from representing entities as static embeddings of superficial words, while neglecting to model their ever-changing states, i.e., the information they carry, as the text unfolds. Therefore, we extend the Transformer model to dynamically conduct entity state updates and sentence realization for narrative generation. We propose a contrastive framework to learn the state representations in a discrete space, and insert additional attention layers into the decoder to better exploit these states. Experiments on two narrative datasets show that our model can generate more coherent and diverse narratives than strong baselines with the guidance of meaningful entity states.","https://ojs.aaai.org/index.php/AAAI/article/view/26509/26281"
"26510","Learning to Imagine: Distillation-Based Interactive Context Exploitation for Dialogue State Tracking","['Jinyu Guo', 'Kai Shuang', 'Kaihang Zhang', 'Yixuan Liu', 'Jijie Li', 'Zihan Wang']","['State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications\nSchool of Computer Science, Beijing University of Posts and Telecommunications', 'State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications\nSchool of Computer Science, Beijing University of Posts and Telecommunications', 'State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications\nSchool of Computer Science, Beijing University of Posts and Telecommunications', 'State Key Laboratory of Networking and Switching Technology, Beijing University of Posts and Telecommunications\nSchool of Computer Science, Beijing University of Posts and Telecommunications', 'Beijing Academy of Artificial Intelligence, Beijing, China', 'Graduate School of Information Science and Technology, The University of Tokyo']","['SNLP: Conversational AI/Dialogue Systems']","Guo, J., Shuang, K., Zhang, K., Liu, Y., Li, J., & Wang, Z. (2023). Learning to Imagine: Distillation-Based Interactive Context Exploitation for Dialogue State Tracking. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12845-12853. https://doi.org/10.1609/aaai.v37i11.26510","Abstract 					In dialogue state tracking (DST), the exploitation of dialogue history is a crucial research direction, and the existing DST models can be divided into two categories: full-history models and partial-history models. Since the “select first, use later” mechanism explicitly filters the distracting information being passed to the downstream state prediction, the partial-history models have recently achieved a performance advantage over the full-history models. However, besides the redundant information, some critical dialogue context information was inevitably filtered out by the partial-history models simultaneously. To reconcile the contextual consideration with avoiding the introduction of redundant information, we propose DICE-DST, a model-agnostic module widely applicable to the partial-history DST models, which aims to strengthen the ability of context exploitation for the encoder of each DST model. Specifically, we first construct a teacher encoder and devise two contextual reasoning tasks to train it to acquire extensive dialogue contextual knowledge. Then we transfer the contextual knowledge from the teacher encoder to the student encoder via a novel turn-level attention-alignment distillation. Experimental results show that our approach extensively improves the performance of partial-history DST models and thereby achieves new state-of-the-art performance on multiple mainstream datasets while keeping high efficiency.","https://ojs.aaai.org/index.php/AAAI/article/view/26510/26282"
"26511","RenewNAT: Renewing Potential Translation for Non-autoregressive Transformer","['Pei Guo', 'Yisheng Xiao', 'Juntao Li', 'Min Zhang']","['Soochow University', 'Soochow University', 'Soochow University', 'Soochow University']","['SNLP: Machine Translation & Multilinguality', 'SNLP: Generation']","Guo, P., Xiao, Y., Li, J., & Zhang, M. (2023). RenewNAT: Renewing Potential Translation for Non-autoregressive Transformer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12854-12862. https://doi.org/10.1609/aaai.v37i11.26511","Abstract 					Non-autoregressive neural machine translation (NAT) models are proposed to accelerate the inference process while maintaining relatively high performance. However, existing NAT models are difficult to achieve the desired efficiency-quality trade-off. For one thing, fully NAT models with efficient inference perform inferior to their autoregressive counterparts. For another, iterative NAT models can, though, achieve comparable performance while diminishing the advantage of speed. In this paper, we propose RenewNAT, a flexible framework with high efficiency and effectiveness, to incorporate the merits of fully and iterative NAT models. RenewNAT first generates the potential translation results and then renews them in a single pass. It can achieve significant performance improvements at the same expense as traditional NAT models (without introducing additional model parameters and decoding latency). Experimental results on various translation benchmarks (e.g., 4 WMT) show that our framework consistently improves the performance of strong fully NAT methods (e.g., GLAT and DSLP) without additional speed overhead.","https://ojs.aaai.org/index.php/AAAI/article/view/26511/26283"
"26512","Instance Smoothed Contrastive Learning for Unsupervised Sentence Embedding","['Hongliang He', 'Junlei Zhang', 'Zhenzhong Lan', 'Yue Zhang']","['Zhejiang University, China\nSchool of Engineering, Westlake University, China', 'Zhejiang University, China\nSchool of Engineering, Westlake University, China', 'School of Engineering, Westlake University, China\nInstitute of Advanced Technology, Westlake Institute for Advanced Study, China', 'School of Engineering, Westlake University, China\nInstitute of Advanced Technology, Westlake Institute for Advanced Study, China']","['SNLP: Text Classification']","He, H., Zhang, J., Lan, Z., & Zhang, Y. (2023). Instance Smoothed Contrastive Learning for Unsupervised Sentence Embedding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12863-12871. https://doi.org/10.1609/aaai.v37i11.26512","Abstract 					Contrastive learning-based methods, such as unsup-SimCSE, have achieved state-of-the-art (SOTA) performances in learning unsupervised sentence embeddings. However, in previous studies, each embedding used for contrastive learning only derived from one sentence instance, and we call these embeddings instance-level embeddings. In other words, each embedding is regarded as a unique class of its own, which may hurt the generalization performance. In this study, we propose IS-CSE (instance smoothing contrastive sentence embedding) to smooth the boundaries of embeddings in the feature space. Specifically, we retrieve embeddings from a dynamic memory buffer according to the semantic similarity to get a positive embedding group. Then embeddings in the group are aggregated by a self-attention operation to produce a smoothed instance embedding for further analysis. We evaluate our method on standard semantic text similarity (STS) tasks and achieve an average of 78.30%, 79.47%, 77.73%, and 79.42% Spearman’s correlation on the base of BERT-base, BERT-large, RoBERTa-base, and RoBERTa-large respectively, a 2.05%, 1.06%, 1.16% and 0.52% improvement compared to unsup-SimCSE.","https://ojs.aaai.org/index.php/AAAI/article/view/26512/26284"
"26513","Competition or Cooperation? Exploring Unlabeled Data via Challenging Minimax Game for Semi-supervised Relation Extraction","['Yu Hong', 'Jiahang Li', 'Jianchuan Feng', 'Chenghua Huang', 'Zhixu Li', 'JIanfeng Qu', 'Yanghua Xiao', 'Wei Wang']","['Fudan University', 'Fudan University', 'Fudan University', 'Fudan University', 'Fudan University', 'Soochow University', 'Fudan University', 'Fudan University']","['SNLP: Information Extraction', 'ML: Semi-Supervised Learning']","Hong, Y., Li, J., Feng, J., Huang, C., Li, Z., Qu, J., Xiao, Y., & Wang, W. (2023). Competition or Cooperation? Exploring Unlabeled Data via Challenging Minimax Game for Semi-supervised Relation Extraction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12872-12880. https://doi.org/10.1609/aaai.v37i11.26513","Abstract 					Semi-Supervised Relation Extraction aims at learning well-performed RE models with limited labeled and large-scale unlabeled data. Existing methods mainly suffer from semantic drift and insufficient supervision, which severely limit the performance. To address these problems, recent work tends to design dual modules to work cooperatively for mutual enhancement. However, the consensus of two modules greatly restricts the model from exploring diverse relation expressions in unlabeled set, which hinders the performance as well as model generalization. To tackle this problem, in this paper, we propose a novel competition-based method AdvSRE. We set up a challenging minimax game on unlabeled data between two modules, Generator and Discriminator, and assign them with conflicting objectives. During the competition game, one module may find any possible chance to beat the other, which develops two modules' abilities until relation expressions cannot be further explored. To exploit label information, Discriminator is further asked to predict specific relation for each sentence. Experiment results on two benchmarks show new state-of-the-art performance over baselines, demonstrating the effectiveness of proposed AdvSRE.","https://ojs.aaai.org/index.php/AAAI/article/view/26513/26285"
"26514","Feature Normalization and Cartography-Based Demonstrations for Prompt-Based Fine-Tuning on Emotion-Related Tasks","['Mahshid Hosseini', 'Cornelia Caragea']","['Computer Science, University of Illinois Chicago', 'Computer Science, University of Illinois Chicago']","['SNLP: Applications', 'SNLP: Text Classification']","Hosseini, M., & Caragea, C. (2023). Feature Normalization and Cartography-Based Demonstrations for Prompt-Based Fine-Tuning on Emotion-Related Tasks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12881-12889. https://doi.org/10.1609/aaai.v37i11.26514","Abstract 					To train a model in a traditional supervised learning classification system for natural language processing (NLP) tasks, it is essential to have labeled data, which is not present in large amounts for many tasks. Prompt-based learning methods attempt to combat the supervised learning need for labeled data by directly adapting pre-trained language models and modeling the probability of text itself. In this paper, we propose a novel data-agnostic strategy for prompt-based fine-tuning that leverages feature moments (a.k.a., mean and standard deviation) as a data augmentation technique and employs training dynamics (i.e., confidence and variability) to allow more informative samples to be concatenated for generating demonstrations as input context. Our approach is a strong method for few-shot learning that forces the language model to pay special attention to the feature moments and allows more informative samples to be concatenated for generating demonstrations as input context by selecting high confidence and low variance samples. To demonstrate its effectiveness given limited training data, we conduct extensive experiments in different few-shot settings on three empathy and emotion classification datasets (from various domains).  We further evaluate our method's robustness by introducing noise to our few-shot input data and labels and show that exchanging moments between samples and incorporating cartography-based demonstrations are beneficial when the available data is limited and noisy.","https://ojs.aaai.org/index.php/AAAI/article/view/26514/26286"
"26515","A Simple Yet Effective Subsequence-Enhanced Approach for Cross-Domain NER","['Jinpeng Hu', 'DanDan Guo', 'Yang Liu', 'Zhuo Li', 'Zhihong Chen', 'Xiang Wan', 'Tsung-Hui Chang']","['Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, Guangdong, China', 'The Chinese University of Hong Kong, Shenzhen', 'Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, Guangdong, China', 'Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, Guangdong, China', 'Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, Guangdong, China', 'Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, Guangdong, China\nPazhou Lab, Guangzhou, 510330, China', 'Shenzhen Research Institute of Big Data, The Chinese University of Hong Kong, Shenzhen, Guangdong, China\nThe Chinese University of Hong Kong, Shenzhen']","['SNLP: Information Extraction', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning']","Hu, J., Guo, D., Liu, Y., Li, Z., Chen, Z., Wan, X., & Chang, T.-H. (2023). A Simple Yet Effective Subsequence-Enhanced Approach for Cross-Domain NER. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12890-12898. https://doi.org/10.1609/aaai.v37i11.26515","Abstract 					Cross-domain named entity recognition (NER), aiming to address the limitation of labeled resources in the target domain, is a challenging yet important task. Most existing studies alleviate the data discrepancy across different domains at the coarse level via combing NER with language modelings or introducing domain-adaptive pre-training (DAPT). Notably, source and target domains tend to share more fine-grained local information within denser subsequences than global information within the whole sequence, such that subsequence features are easier to transfer, which has not been explored well. Besides, compared to token-level representation, subsequence-level information can help the model distinguish different meanings of the same word in different domains. In this paper, we propose to incorporate subsequence-level features for promoting the cross-domain NER. In detail, we first utilize a pre-trained encoder to extract the global information. Then, we re-express each sentence as a group of subsequences and propose a novel bidirectional memory recurrent unit (BMRU) to capture features from the subsequences. Finally, an adaptive coupling unit (ACU) is proposed to combine global information and subsequence features for predicting entity labels. Experimental results on several benchmark datasets illustrate the effectiveness of our model, which achieves considerable improvements.","https://ojs.aaai.org/index.php/AAAI/article/view/26515/26287"
"26516","A Question-Answering Approach to Key Value Pair Extraction from Form-Like Document Images","['Kai Hu', 'Zhuoyuan Wu', 'Zhuoyao Zhong', 'Weihong Lin', 'Lei Sun', 'Qiang Huo']","['University of Science and Technology of China\nMicrosoft Research Asia', 'Peking University Shenzhen Graduate School\nMicrosoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia']","['SNLP: Information Extraction']","Hu, K., Wu, Z., Zhong, Z., Lin, W., Sun, L., & Huo, Q. (2023). A Question-Answering Approach to Key Value Pair Extraction from Form-Like Document Images. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12899-12906. https://doi.org/10.1609/aaai.v37i11.26516","Abstract 					In this paper, we present a new question-answering (QA) based key-value pair extraction approach, called KVPFormer, to robustly extracting key-value relationships between entities from form-like document images. Specifically, KVPFormer first identifies key entities from all entities in an image with a Transformer encoder, then takes these key entities as questions and feeds them into a Transformer decoder to predict their corresponding answers (i.e., value entities) in parallel. To achieve higher answer prediction accuracy, we propose a coarse-to-fine answer prediction approach further, which first extracts multiple answer candidates for each identified question in the coarse stage and then selects the most likely one among these candidates in the fine stage. In this way, the learning difficulty of answer prediction can be effectively reduced so that the prediction accuracy can be improved. Moreover, we introduce a spatial compatibility attention bias into the self-attention/cross-attention mechanism for KVPFormer to better model the spatial interactions between entities. With these new techniques, our proposed KVPFormer achieves state-of-the-art results on FUNSD and XFUND datasets, outperforming the previous best-performing method by 7.2% and 13.2% in F1 score, respectively.","https://ojs.aaai.org/index.php/AAAI/article/view/26516/26288"
"26517","SEAT: Stable and Explainable Attention","['Lijie Hu', 'Yixin Liu', 'Ninghao Liu', 'Mengdi Huai', 'Lichao Sun', 'Di Wang']","['King Abdullah University of Science and Technology', 'Lehigh University', 'University of Georgia', 'Iowa Sate University', 'Lehigh University', 'King Abdullah University of Science and Technology\nComputational Bioscience Research Center\nSDAIA-KAUST Center of Excellence in Data Science and Artificial Intelligence']","['SNLP: Interpretability & Analysis of NLP Models', 'ML: Transparent', 'Interpretable', 'Explainable ML']","Hu, L., Liu, Y., Liu, N., Huai, M., Sun, L., & Wang, D. (2023). SEAT: Stable and Explainable Attention. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12907-12915. https://doi.org/10.1609/aaai.v37i11.26517","Abstract 					Attention mechanism has become a standard fixture in many state-of-the-art natural language processing (NLP) models, not only due to its outstanding performance, but also because it provides plausible innate explanations for neural architectures. However, recent studies show that attention is unstable against randomness and perturbations during training or testing, such as random seeds and slight perturbation of embeddings, which impedes it from being a faithful explanation tool. Thus, a natural question is whether we can find an alternative to vanilla attention, which is more stable and could keep the key characteristics of the explanation. In this paper, we provide a rigorous definition of such an attention method named SEAT (Stable and Explainable ATtention). Specifically, SEAT has the following three properties: (1) Its prediction distribution is close to the prediction of the vanilla attention; (2) Its top-k indices largely overlap with those of the vanilla attention; (3) It is robust w.r.t perturbations, i.e., any slight perturbation on SEAT will not change the attention and prediction distribution too much, which implicitly indicates that it is stable to randomness and perturbations. Furthermore, we propose an optimization method for obtaining SEAT, which could be considered as revising the vanilla attention. Finally, through intensive experiments on various datasets, we compare our SEAT with other baseline methods using RNN, BiLSTM and BERT architectures, with different evaluation metrics on model interpretation, stability and accuracy. Results show that, besides preserving the original explainability and model performance, SEAT is more stable against input perturbations and training randomness, which indicates it is a more faithful explanation.","https://ojs.aaai.org/index.php/AAAI/article/view/26517/26289"
"26518","Personalized Dialogue Generation with Persona-Adaptive Attention","['Qiushi Huang', 'Yu Zhang', 'Tom Ko', 'Xubo Liu', 'Bo Wu', 'Wenwu Wang', 'H Tang']","['University of Surrey\nSouthern University of Science and Technology', 'Southern University of Science and Technology', 'ByteDance AI Lab', 'University of Surrey', 'MIT-IBM Watson AI Lab', 'University of Surrey', 'University of Surrey']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Applications']","Huang, Q., Zhang, Y., Ko, T., Liu, X., Wu, B., Wang, W., & Tang, H. (2023). Personalized Dialogue Generation with Persona-Adaptive Attention. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12916-12923. https://doi.org/10.1609/aaai.v37i11.26518","Abstract 					Persona-based dialogue systems aim to generate consistent responses based on historical context and predefined persona. Unlike conventional dialogue generation, the persona-based dialogue needs to consider both dialogue context and persona, posing a challenge for coherent training. Specifically, this requires a delicate weight balance between context and persona. To achieve that, in this paper, we propose an effective framework with Persona-Adaptive Attention (PAA), which adaptively integrates the weights from the persona and context information via our designed attention. In addition, a dynamic masking mechanism is applied to the PAA to not only drop redundant information in context and persona but also serve as a regularization mechanism to avoid overfitting. Experimental results demonstrate the superiority of the proposed PAA framework compared to the strong baselines in both automatic and human evaluation. Moreover, the proposed PAA approach can perform equivalently well in a low-resource regime compared to models trained in a full-data setting, which achieve a similar result with only 20% to 30% of data compared to the larger models trained in the full-data setting. To fully exploit the effectiveness of our design, we designed several variants for handling the weighted information in different ways, showing the necessity and sufficiency of our weighting and masking designs.","https://ojs.aaai.org/index.php/AAAI/article/view/26518/26290"
"26519","Question Decomposition Tree for Answering Complex Questions over Knowledge Bases","['Xiang Huang', 'Sitao Cheng', 'Yiheng Shu', 'Yuheng Bao', 'Yuzhong Qu']","['State Key Laboratory for Novel Software Technology, Nanjing University, China', 'State Key Laboratory for Novel Software Technology, Nanjing University, China', 'State Key Laboratory for Novel Software Technology, Nanjing University, China', 'State Key Laboratory for Novel Software Technology, Nanjing University, China', 'State Key Laboratory for Novel Software Technology, Nanjing University, China']","['SNLP: Question Answering', 'KRR: Ontologies and Semantic Web', 'SNLP: Syntax -- Tagging', 'Chunking & Parsing']","Huang, X., Cheng, S., Shu, Y., Bao, Y., & Qu, Y. (2023). Question Decomposition Tree for Answering Complex Questions over Knowledge Bases. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12924-12932. https://doi.org/10.1609/aaai.v37i11.26519","Abstract 					Knowledge base question answering (KBQA) has attracted a lot of interest in recent years, especially for complex questions which require multiple facts to answer. Question decomposition is a promising way to answer complex questions. Existing decomposition methods split the question into sub-questions according to a single compositionality type, which is not sufficient for questions involving multiple compositionality types. In this paper, we propose Question Decomposition Tree (QDT) to represent the structure of complex questions. Inspired by recent advances in natural language generation (NLG), we present a two-staged method called Clue-Decipher to generate QDT. It can leverage the strong ability of NLG model and simultaneously preserve the original questions. To verify that QDT can enhance KBQA task, we design a decomposition-based KBQA system called QDTQA. Extensive experiments show that QDTQA outperforms previous state-of-the-art methods on ComplexWebQuestions dataset. Besides, our decomposition method improves an existing KBQA system by 12% and sets a new state-of-the-art on LC-QuAD 1.0.","https://ojs.aaai.org/index.php/AAAI/article/view/26519/26291"
"26520","Hierarchical Text Classification as Sub-hierarchy Sequence Generation","['SangHun Im', 'GiBaeg Kim', 'Heung-Seon Oh', 'Seongung Jo', 'Dong Hwan Kim']","['School of Computer Science and Engineering, Korea University of Technology and Education (KOREATECH)', 'School of Computer Science and Engineering, Korea University of Technology and Education (KOREATECH)', 'School of Computer Science and Engineering, Korea University of Technology and Education (KOREATECH)', 'School of Computer Science and Engineering, Korea University of Technology and Education (KOREATECH)', 'School of Computer Science and Engineering, Korea University of Technology and Education (KOREATECH)']","['SNLP: Text Classification', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'SNLP: Information Extraction', 'SNLP: Text Mining']","Im, S., Kim, G., Oh, H.-S., Jo, S., & Kim, D. H. (2023). Hierarchical Text Classification as Sub-hierarchy Sequence Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12933-12941. https://doi.org/10.1609/aaai.v37i11.26520","Abstract 					Hierarchical text classification (HTC) is essential for various real applications. However, HTC models are challenging to develop because they often require processing a large volume of documents and labels with hierarchical taxonomy. Recent HTC models based on deep learning have attempted to incorporate hierarchy information into a model structure. Consequently, these models are challenging to implement when the model parameters increase for a large-scale hierarchy because the model structure depends on the hierarchy size. To solve this problem, we formulate HTC as a sub-hierarchy sequence generation to incorporate hierarchy information into a target label sequence instead of the model structure. Subsequently, we propose the Hierarchy DECoder (HiDEC), which decodes a text sequence into a sub-hierarchy sequence using recursive hierarchy decoding, classifying all parents at the same level into children at once. In addition, HiDEC is trained to use hierarchical path information from a root to each leaf in a sub-hierarchy composed of the labels of a target document via an attention mechanism and hierarchy-aware masking. HiDEC achieved state-of-the-art performance with significantly fewer model parameters than existing models on benchmark datasets, such as RCV1-v2, NYT, and EURLEX57K.","https://ojs.aaai.org/index.php/AAAI/article/view/26520/26292"
"26521","IndicSUPERB: A Speech Processing Universal Performance Benchmark for Indian Languages","['Tahir Javed', 'Kaushal Bhogale', 'Abhigyan Raman', 'Pratyush Kumar', 'Anoop Kunchukuttan', 'Mitesh M. Khapra']","['Indian Institute of Technology Madras\nAI4Bharat', 'Indian Institute of Technology, Madras\nAI4Bharat', 'AI4Bharat', 'AI4Bharat\nMicrosoft', 'AI4Bharat\nMicrosoft', 'Indian Institute of Technology Madras\nAI4Bharat']","['SNLP: Applications', 'SNLP: Speech and Multimodality']","Javed, T., Bhogale, K., Raman, A., Kumar, P., Kunchukuttan, A., & Khapra, M. M. (2023). IndicSUPERB: A Speech Processing Universal Performance Benchmark for Indian Languages. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12942-12950. https://doi.org/10.1609/aaai.v37i11.26521","Abstract 					A cornerstone in AI research has been the creation and adoption of standardized training and test datasets to earmark the progress of state-of-the-art models. A particularly successful example is the GLUE dataset for training and evaluating Natural Language Understanding (NLU) models for English. The large body of research around self-supervised BERT-based language models revolved around performance improvements on NLU tasks in GLUE. To evaluate language models in other languages, several language-specific GLUE datasets were created. The area of speech language understanding (SLU) has followed a similar trajectory. The success of large self-supervised models such as wav2vec2 enable creation of speech models with relatively easy to access unlabelled data. These models can then be evaluated on SLU tasks, such as the SUPERB benchmark. In this work, we extend this to Indic languages by releasing the IndicSUPERB benchmark. Specifically, we make the following three contributions. (i) We collect Kathbath containing 1,684 hours of labelled speech data across 12 Indian languages from 1,218 contributors located in 203 districts in India. (ii) Using Kathbath, we create benchmarks across 6 speech tasks: Automatic Speech Recognition, Speaker Verification, Speaker Identification (mono/multi), Language Identification, Query By Example, and Keyword Spotting for 12 languages. (iii) On the released benchmarks, we train and evaluate different self-supervised models alongside the a commonly used baseline FBANK. We show that language-specific fine-tuned models are more accurate than baseline on most of the tasks, including a large gap of 76% for Language Identification task. However, for speaker identification, self-supervised models trained on large datasets demonstrate an advantage. We hope IndicSUPERB contributes to the progress of developing speech language understanding models for Indian languages.","https://ojs.aaai.org/index.php/AAAI/article/view/26521/26293"
"26522","SheetPT: Spreadsheet Pre-training Based on Hierarchical Attention Network","['Ran Jia', 'Qiyu Li', 'Zihan Xu', 'Xiaoyuan Jin', 'Lun Du', 'Haoyu Dong', 'Xiao Lv', 'Shi Han', 'Dongmei Zhang']","['Microsoft Research Asia', 'Peking University', 'Peking University', 'Peking University', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia']","['SNLP: Applications', 'APP: Business/Marketing/Advertising/E-Commerce', 'ML: Unsupervised & Self-Supervised Learning']","Jia, R., Li, Q., Xu, Z., Jin, X., Du, L., Dong, H., Lv, X., Han, S., & Zhang, D. (2023). SheetPT: Spreadsheet Pre-training Based on Hierarchical Attention Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12951-12958. https://doi.org/10.1609/aaai.v37i11.26522","Abstract 					Spreadsheets are an important and unique type of business document for data storage, analysis and presentation. The distinction between spreadsheets and most other types of digital documents lies in that spreadsheets provide users with high flexibility of data organization on the grid. Existing related techniques mainly focus on the tabular data and are incompetent in understanding the entire sheet. On the one hand, spreadsheets have no explicit separation across tabular data and other information, leaving a gap for the deployment of such techniques. On the other hand, pervasive data dependence and semantic relations across the sheet require comprehensive modeling of all the information rather than only the tables. In this paper, we propose SheetPT, the first pre-training technique on spreadsheets to enable effective representation learning under this scenario. For computational effectiveness and efficiency, we propose the coherent chunk, an intermediate semantic unit of sheet structure; and we accordingly devise a hierarchical attention-based architecture to capture contextual information across different structural granularities. Three pre-training objectives are also designed to ensure sufficient training against millions of spreadsheets. Two representative downstream tasks, formula prediction and sheet structure recognition are utilized to evaluate its capability and the prominent results reveal its superiority over existing state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26522/26294"
"26523","SeDepTTS: Enhancing the Naturalness via Semantic Dependency and Local Convolution for Text-to-Speech Synthesis","['Chenglong Jiang', 'Ying Gao', 'Wing W.Y. Ng', 'Jiyong Zhou', 'Jinghui Zhong', 'Hongzhong Zhen']","['South China University of Technology', 'South China University of Technology', 'South China University of Technology', 'South China University of Technology', 'South China University of Technology', 'South China University of Technology']","['SNLP: Other Foundations of Speech & Natural Language Processing', 'SNLP: Speech and Multimodality']","Jiang, C., Gao, Y., Ng, W. W., Zhou, J., Zhong, J., & Zhen, H. (2023). SeDepTTS: Enhancing the Naturalness via Semantic Dependency and Local Convolution for Text-to-Speech Synthesis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12959-12967. https://doi.org/10.1609/aaai.v37i11.26523","Abstract 					Self-attention-based networks have obtained impressive performance in parallel training and global context modeling. However, it is weak in local dependency capturing, especially for data with strong local correlations such as utterances. Therefore, we will mine linguistic information of the original text based on a semantic dependency and the semantic relationship between nodes is regarded as prior knowledge to revise the distribution of self-attention. On the other hand, given the strong correlation between input characters, we introduce a one-dimensional (1-D) convolution neural network (CNN) producing query(Q) and value(V) in the self-attention mechanism for a better fusion of local contextual information. Then, we migrate this variant of the self-attention networks to speech synthesis tasks and propose a non-autoregressive (NAR) neural Text-to-Speech (TTS): SeDepTTS. Experimental results show that our model yields good performance in speech synthesis. Specifically, the proposed method yields significant improvement for the processing of pause, stress, and intonation in speech.","https://ojs.aaai.org/index.php/AAAI/article/view/26523/26295"
"26524","Prototypical Fine-Tuning: Towards Robust Performance under Varying Data Sizes","['Yiqiao Jin', 'Xiting Wang', 'Yaru Hao', 'Yizhou Sun', 'Xing Xie']","['Georgia Institute of Technology', 'Microsoft Research Asia', 'Microsoft Research Asia', 'University of California, Los Angeles', 'Microsoft Research Asia']","['SNLP: Text Classification', 'SNLP: Bias', 'Fairness', 'Transparency & Privacy', 'SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Language Models']","Jin, Y., Wang, X., Hao, Y., Sun, Y., & Xie, X. (2023). Prototypical Fine-Tuning: Towards Robust Performance under Varying Data Sizes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12968-12976. https://doi.org/10.1609/aaai.v37i11.26524","Abstract 					In this paper, we move towards combining large parametric models with non-parametric prototypical networks. We propose prototypical fine-tuning, a novel prototypical framework for fine-tuning pretrained language models (LM), which automatically learns a bias to improve predictive performance for varying data sizes, especially low-resource settings. Our prototypical fine-tuning approach can automatically adjust the model capacity according to the number of data points and the model's inherent attributes. Moreover, we propose four principles for effective prototype fine-tuning towards the optimal solution. Experimental results across various datasets show that our work achieves significant performance improvements under various low-resource settings, as well as comparable and usually better performances in high-resource scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/26524/26296"
"26525","Cross-Modal Distillation for Speaker Recognition","['Yufeng Jin', 'Guosheng Hu', 'Haonan Chen', 'Duoqian Miao', 'Liang Hu', 'Cairong Zhao']","['Tongji University', 'Oosto', 'Alibaba Group', 'Tongji University', 'Tongji University', 'Tongji University']","['SNLP: Speech and Multimodality', 'CV: Biometrics', 'Face', 'Gesture & Pose', 'CV: Multi-modal Vision', 'APP: Biometrics', 'ML: Multimodal Learning', 'ML: Representation Learning']","Jin, Y., Hu, G., Chen, H., Miao, D., Hu, L., & Zhao, C. (2023). Cross-Modal Distillation for Speaker Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12977-12985. https://doi.org/10.1609/aaai.v37i11.26525","Abstract 					Speaker recognition achieved great progress recently, however, it is not easy or efficient to further improve its performance via traditional solutions: collecting more data and designing new neural networks. Aiming at the fundamental challenge of speech data, i.e. low information density, multimodal learning can mitigate this challenge by introducing richer and more discriminative information as input for identity recognition. Specifically, since the face image is more discriminative than the speech for identity recognition, we conduct multimodal learning by introducing a face recognition model (teacher) to transfer discriminative knowledge to a speaker recognition model (student) during training. However, this knowledge transfer via distillation is not trivial because the big domain gap between face and speech can easily lead to overfitting. In this work, we introduce a multimodal learning framework, VGSR (Vision-Guided Speaker Recognition). Specifically, we propose a MKD (Margin-based Knowledge Distillation) strategy for cross-modality distillation by introducing a loose constrain to align the teacher and student, greatly reducing overfitting. Our MKD strategy can easily adapt to various existing knowledge distillation methods. In addition, we propose a QAW (Quality-based Adaptive Weights) module to weight input samples via quantified data quality, leading to a robust model training. Experimental results on the VoxCeleb1 and CN-Celeb datasets show our proposed strategies can effectively improve the accuracy of speaker recognition by a margin of 10% ∼ 15%, and our methods are very robust to different noises.","https://ojs.aaai.org/index.php/AAAI/article/view/26525/26297"
"26526","Explaining (Sarcastic) Utterances to Enhance Affect Understanding in Multimodal Dialogues","['Shivani Kumar', 'Ishani Mondal', 'Md Shad Akhtar', 'Tanmoy Chakraborty']","['Indraprastha Institute of Information Technology Delhi, India', 'University of Maryland, College Park', 'Indraprastha Institute of Information Technology Delhi, India', 'Indian Institute of Technology Delhi, India']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Applications', 'SNLP: Discourse', 'Pragmatics & Argument Mining', 'SNLP: Generation', 'SNLP: Information Extraction', 'SNLP: Speech and Multimodality', 'SNLP: Summarization', 'SNLP: Text Classification']","Kumar, S., Mondal, I., Akhtar, M. S., & Chakraborty, T. (2023). Explaining (Sarcastic) Utterances to Enhance Affect Understanding in Multimodal Dialogues. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12986-12994. https://doi.org/10.1609/aaai.v37i11.26526","Abstract 					Conversations emerge as the primary media for exchanging ideas and conceptions. From the listener’s perspective, identifying various affective qualities, such as sarcasm, humour, and emotions, is paramount for comprehending the true connotation of the emitted utterance. However, one of the major hurdles faced in learning these affect dimensions is the presence of figurative language, viz. irony, metaphor, or sarcasm. We hypothesize that any detection system constituting the exhaustive and explicit presentation of the emitted utterance would improve the overall comprehension of the dialogue. To this end, we explore the task of Sarcasm Explanation in Dialogues, which aims to unfold the hidden irony behind sarcastic utterances. We propose MOSES, a deep neural network which takes a multimodal (sarcastic) dialogue instance as an input and generates a natural language sentence as its explanation. Subsequently, we leverage the generated explanation for various natural language understanding tasks in a conversational dialogue setup, such as sarcasm detection, humour identification, and emotion recognition. Our evaluation shows that MOSES outperforms the state-of-the-art system for SED by an average of ∼2% on different evaluation metrics, such as ROUGE, BLEU, and METEOR. Further, we observe that leveraging the generated explanation advances three downstream tasks for affect classification – an average improvement of ~14% F1-score in the sarcasm detection task and ∼2% in the humour identification and emotion recognition task. We also perform extensive analyses to assess the quality of the results.","https://ojs.aaai.org/index.php/AAAI/article/view/26526/26298"
"26527","COCA: COllaborative CAusal Regularization for Audio-Visual Question Answering","['Mingrui Lao', 'Nan Pu', 'Yu Liu', 'Kai He', 'Erwin M. Bakker', 'Michael S. Lew']","['Leiden University', 'Leiden University', 'Dalian University of Technology', 'Leiden University', 'Leiden University', 'Leiden University']","['SNLP: Speech and Multimodality', 'CV: Language and Vision', 'CV: Multi-modal Vision']","Lao, M., Pu, N., Liu, Y., He, K., Bakker, E. M., & Lew, M. S. (2023). COCA: COllaborative CAusal Regularization for Audio-Visual Question Answering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 12995-13003. https://doi.org/10.1609/aaai.v37i11.26527","Abstract 					Audio-Visual Question Answering (AVQA) is a sophisticated QA task, which aims at answering textual questions over given video-audio pairs with comprehensive multimodal reasoning. Through detailed causal-graph analyses and careful inspections of their learning processes, we reveal that AVQA models are not only prone to over-exploit prevalent language bias, but also suffer from additional joint-modal biases caused by the shortcut relations between textual-auditory/visual co-occurrences and dominated answers. In this paper, we propose a COllabrative CAusal (COCA) Regularization to remedy this more challenging issue of data biases. Specifically, a novel Bias-centered Causal Regularization (BCR) is proposed to alleviate specific shortcut biases by intervening bias-irrelevant causal effects, and further introspect the predictions of AVQA models in counterfactual and factual scenarios. Based on the fact that the dominated bias impairing model robustness for different samples tends to be different, we introduce a Multi-shortcut Collaborative Debiasing (MCD) to measure how each sample suffers from different biases, and dynamically adjust their debiasing concentration to different shortcut correlations. Extensive experiments demonstrate the effectiveness as well as backbone-agnostic ability of our COCA strategy, and it achieves state-of-the-art performance on the large-scale MUSIC-AVQA dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/26527/26299"
"26528","Script, Language, and Labels: Overcoming Three Discrepancies for Low-Resource Language Specialization","['Jaeseong Lee', 'Dohyeon Lee', 'Seung-won Hwang']","['Seoul National University', 'Seoul National University', 'Seoul National University']","['SNLP: Machine Translation & Multilinguality', 'SNLP: Language Models', 'SNLP: Learning & Optimization for SNLP', 'SNLP: Syntax -- Tagging', 'Chunking & Parsing']","Lee, J., Lee, D., & Hwang, S.- won. (2023). Script, Language, and Labels: Overcoming Three Discrepancies for Low-Resource Language Specialization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13004-13013. https://doi.org/10.1609/aaai.v37i11.26528","Abstract 					Although multilingual pretrained models (mPLMs) enabled support of various natural language processing in diverse languages, its limited coverage of 100+ languages lets 6500+ languages remain ‘unseen’. One common approach for an unseen language is specializing the model for it as target, by performing additional masked language modeling (MLM) with the target language corpus. However, we argue that, due to the discrepancy from multilingual MLM pretraining, a naive specialization as such can be suboptimal. Specifically, we pose three discrepancies to overcome. Script and linguistic discrepancy of the target language from the related seen languages, hinder a positive transfer, for which we propose to maximize representation similarity, unlike existing approaches maximizing overlaps. In addition, label space for MLM prediction can vary across languages, for which we propose to reinitialize top layers for a more effective adaptation. Experiments over four different language families and three tasks shows that our method improves the task performance of unseen languages with statistical significance, while previous approach fails to.","https://ojs.aaai.org/index.php/AAAI/article/view/26528/26300"
"26529","LIQUID: A Framework for List Question Answering Dataset Generation","['Seongyun Lee', 'Hyunjae Kim', 'Jaewoo Kang']","['Korea University', 'Korea University', 'Korea University\nAIGEN Sciences']","['SNLP: Question Answering']","Lee, S., Kim, H., & Kang, J. (2023). LIQUID: A Framework for List Question Answering Dataset Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13014-13024. https://doi.org/10.1609/aaai.v37i11.26529","Abstract 					Question answering (QA) models often rely on large-scale training datasets, which necessitates the development of a data generation framework to reduce the cost of manual annotations. Although several recent studies have aimed to generate synthetic questions with single-span answers, no study has been conducted on the creation of list questions with multiple, non-contiguous spans as answers. To address this gap, we propose LIQUID, an automated framework for generating list QA datasets from unlabeled corpora. We first convert a passage from Wikipedia or PubMed into a summary and extract named entities from the summarized text as candidate answers. This allows us to select answers that are semantically correlated in context and is, therefore, suitable for constructing list questions. We then create questions using an off-the-shelf question generator with the extracted entities and original passage. Finally, iterative filtering and answer expansion are performed to ensure the accuracy and completeness of the answers. Using our synthetic data, we significantly improve the performance of the previous best list QA models by exact-match F1 scores of 5.0 on MultiSpanQA, 1.9 on Quoref, and 2.8 averaged across three BioASQ benchmarks.","https://ojs.aaai.org/index.php/AAAI/article/view/26529/26301"
"26530","UniSyn: An End-to-End Unified Model for Text-to-Speech and Singing Voice Synthesis","['Yi Lei', 'Shan Yang', 'Xinsheng Wang', 'Qicong Xie', 'Jixun Yao', 'Lei Xie', 'Dan Su']","['Northwestern Polytechnical University', 'Tencent AI Lab', 'Northwestern Polytechnical University', 'Northwestern Polytechnical University', 'Northwestern Polytechnical University', 'Northwestern Polytechnical University', 'Tencent AI Lab']","['SNLP: Speech and Multimodality', 'SNLP: Generation']","Lei, Y., Yang, S., Wang, X., Xie, Q., Yao, J., Xie, L., & Su, D. (2023). UniSyn: An End-to-End Unified Model for Text-to-Speech and Singing Voice Synthesis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13025-13033. https://doi.org/10.1609/aaai.v37i11.26530","Abstract 					Text-to-speech (TTS) and singing voice synthesis (SVS) aim at generating high-quality speaking and singing voice according to textual input and music scores, respectively. Unifying TTS and SVS into a single system is crucial to the applications requiring both of them. Existing methods usually suffer from some limitations, which rely on either both singing and speaking data from the same person or cascaded models of multiple tasks. To address these problems, a simplified elegant framework for TTS and SVS, named UniSyn, is proposed in this paper. It is an end-to-end unified model that can make a voice speak and sing with only singing or speaking data from this person. To be specific, a multi-conditional variational autoencoder (MC-VAE), which constructs two independent latent sub-spaces with the speaker- and style-related (i.e. speak or sing) conditions for flexible control, is proposed in UniSyn. Moreover, supervised guided-VAE and timbre perturbation with the Wasserstein distance constraint are leveraged to further disentangle the speaker timbre and style. Experiments conducted on two speakers and two singers demonstrate that UniSyn can generate natural speaking and singing voice without corresponding training data. The proposed approach outperforms the state-of-the-art end-to-end voice generation work, which proves the effectiveness and advantages of UniSyn.","https://ojs.aaai.org/index.php/AAAI/article/view/26530/26302"
"26531","SoftCorrect: Error Correction with Soft Detection for Automatic Speech Recognition","['Yichong Leng', 'Xu Tan', 'Wenjie Liu', 'Kaitao Song', 'Rui Wang', 'Xiang-Yang Li', 'Tao Qin', 'Ed Lin', 'Tie-Yan Liu']","['University of Science and Technology of China', 'Microsoft Research Asia', 'Microsoft Azure Speech', 'Microsoft Research Asia', 'Microsoft Research Asia', 'University of Science and Technology of China', 'Microsoft Research Asia', 'Microsoft Azure Speech', 'Microsoft Research Asia']","['SNLP: Speech and Multimodality', 'SNLP: Applications']","Leng, Y., Tan, X., Liu, W., Song, K., Wang, R., Li, X.-Y., Qin, T., Lin, E., & Liu, T.-Y. (2023). SoftCorrect: Error Correction with Soft Detection for Automatic Speech Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13034-13042. https://doi.org/10.1609/aaai.v37i11.26531","Abstract 					Error correction in automatic speech recognition (ASR) aims to correct those incorrect words in sentences generated by ASR models. Since recent ASR models usually have low word error rate (WER), to avoid affecting originally correct tokens, error correction models should only modify incorrect words, and therefore detecting incorrect words is important for error correction. Previous works on error correction either implicitly detect error words through target-source attention or CTC (connectionist temporal classification) loss, or explicitly locate specific deletion/substitution/insertion errors. However, implicit error detection does not provide clear signal about which tokens are incorrect and explicit error detection suffers from low detection accuracy. In this paper, we propose SoftCorrect with a soft error detection mechanism to avoid the limitations of both explicit and implicit error detection. Specifically, we first detect whether a token is correct or not through a probability produced by a dedicatedly designed language model, and then design a constrained CTC loss that only duplicates the detected incorrect tokens to let the decoder focus on the correction of error tokens. Compared with implicit error detection with CTC loss, SoftCorrect provides explicit signal about which words are incorrect and thus does not need to duplicate every token but only incorrect tokens; compared with explicit error detection, SoftCorrect does not detect specific deletion/substitution/insertion errors but just leaves it to CTC loss. Experiments on AISHELL-1 and Aidatatang datasets show that SoftCorrect achieves 26.1% and 9.4% CER reduction respectively, outperforming previous works by a large margin, while still enjoying fast speed of parallel generation.","https://ojs.aaai.org/index.php/AAAI/article/view/26531/26303"
"26532","Sequence Generation with Label Augmentation for Relation Extraction","['Bo Li', 'Dingyao Yu', 'Wei Ye', 'Jinglei Zhang', 'Shikun Zhang']","['Peking University', 'Peking University', 'Peking University', 'Peking University', 'Peking University']","['SNLP: Information Extraction']","Li, B., Yu, D., Ye, W., Zhang, J., & Zhang, S. (2023). Sequence Generation with Label Augmentation for Relation Extraction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13043-13050. https://doi.org/10.1609/aaai.v37i11.26532","Abstract 					Sequence generation demonstrates promising performance in recent information extraction efforts, by incorporating large-scale pre-trained Seq2Seq models. This paper investigates the merits of employing sequence generation in relation extraction, finding that with relation names or synonyms as generation targets, their textual semantics and the correlation (in terms of word sequence pattern) among them affect model performance. We then propose Relation Extraction with Label Augmentation (RELA), a Seq2Seq model with automatic label augmentation for RE. By saying label augmentation, we mean prod semantically synonyms for each relation name as the generation target. Besides, we present an in-depth analysis of the Seq2Seq model's behavior when dealing with RE. Experimental results show that RELA achieves competitive results compared with previous methods on four RE datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26532/26304"
"26533","Reviewing Labels: Label Graph Network with Top-k Prediction Set for Relation Extraction","['Bo Li', 'Wei Ye', 'Jinglei Zhang', 'Shikun Zhang']","['Peking University', 'Peking University', 'Peking University', 'Peking University']","['SNLP: Information Extraction']","Li, B., Ye, W., Zhang, J., & Zhang, S. (2023). Reviewing Labels: Label Graph Network with Top-k Prediction Set for Relation Extraction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13051-13058. https://doi.org/10.1609/aaai.v37i11.26533","Abstract 					The typical way for relation extraction is fine-tuning large pre-trained language models on task-specific datasets, then selecting the label with the highest probability of the output distribution as the final prediction. However, the usage of the Top-k prediction set for a given sample is commonly overlooked. In this paper, we first reveal that the Top-k prediction set of a given sample contains useful information for predicting the correct label. To effectively utilizes the Top-k prediction set, we propose Label Graph Network with Top-k Prediction Set, termed as KLG. Specifically, for a given sample, we build a label graph to review candidate labels in the Top-k prediction set and learn the connections between them. We also design a dynamic k selection mechanism to learn more powerful and discriminative relation representation. Our experiments show that KLG achieves the best performances on three relation extraction datasets. Moreover, we observe thatKLG is more effective in dealing with long-tailed classes.","https://ojs.aaai.org/index.php/AAAI/article/view/26533/26305"
"26534","Online Noisy Continual Relation Learning","['Guozheng Li', 'Peng Wang', 'Qiqing Luo', 'Yanhe Liu', 'Wenjun Ke']","['Southeast University', 'Southeast University', 'Southeast University', 'Southeast University', 'Southeast University\nBeijing Institute of Computer Technology and Application']","['SNLP: Information Extraction']","Li, G., Wang, P., Luo, Q., Liu, Y., & Ke, W. (2023). Online Noisy Continual Relation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13059-13066. https://doi.org/10.1609/aaai.v37i11.26534","Abstract 					Recent work for continual relation learning has achieved remarkable progress. However, most existing methods only focus on tackling catastrophic forgetting to improve performance in the existing setup, while continually learning relations in the real-world must overcome many other challenges. One is that the data possibly comes in an online streaming fashion with data distributions gradually changing and without distinct task boundaries. Another is that noisy labels are inevitable in real-world, as relation samples may be contaminated by label inconsistencies or labeled with distant supervision. In this work, therefore, we propose a novel continual relation learning framework that simultaneously addresses both online and noisy relation learning challenges. Our framework contains three key modules: (i) a sample separated online purifying module that divides the online data stream into clean and noisy samples, (ii) a self-supervised online learning module that circumvents inferior training signals caused by noisy data, and (iii) a semi-supervised offline finetuning module that ensures the participation of both clean and noisy samples. Experimental results on FewRel, TACRED and NYT-H with real-world noise demonstrate that our framework greatly outperforms the combinations of the state-of-the-art online continual learning and noisy label learning methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26534/26306"
"26535","RESDSQL: Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL","['Haoyang Li', 'Jing Zhang', 'Cuiping Li', 'Hong Chen']","['Renmin University of China', 'Renmin University of China', 'Renmin University of China', 'Renmin University of China']","['SNLP: Lexical & Frame Semantics', 'Semantic Parsing', 'SNLP: Language Models']","Li, H., Zhang, J., Li, C., & Chen, H. (2023). RESDSQL: Decoupling Schema Linking and Skeleton Parsing for Text-to-SQL. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13067-13075. https://doi.org/10.1609/aaai.v37i11.26535","Abstract 					One of the recent best attempts at Text-to-SQL is the pre-trained language model. Due to the structural property of the SQL queries, the seq2seq model takes the responsibility of parsing both the schema items (i.e., tables and columns) and the skeleton (i.e., SQL keywords). Such coupled targets increase the difficulty of parsing the correct SQL queries especially when they involve many schema items and logic operators. This paper proposes a ranking-enhanced encoding and skeleton-aware decoding framework to decouple the schema linking and the skeleton parsing. Specifically, for a seq2seq encoder-decode model, its encoder is injected by the most relevant schema items instead of the whole unordered ones, which could alleviate the schema linking effort during SQL parsing, and its decoder first generates the skeleton and then the actual SQL query, which could implicitly constrain the SQL parsing. We evaluate our proposed framework on Spider and its three robustness variants: Spider-DK, Spider-Syn, and Spider-Realistic. The experimental results show that our framework delivers promising performance and robustness. Our code is available at https://github.com/RUCKBReasoning/RESDSQL.","https://ojs.aaai.org/index.php/AAAI/article/view/26535/26307"
"26536","Graphix-T5: Mixing Pre-trained Transformers with Graph-Aware Layers for Text-to-SQL Parsing","['Jinyang Li', 'Binyuan Hui', 'Reynold Cheng', 'Bowen Qin', 'Chenhao Ma', 'Nan Huo', 'Fei Huang', 'Wenyu Du', 'Luo Si', 'Yongbin Li']","['The University of Hong Kong\nDAMO Academy, Alibaba Group', 'DAMO Academy, Alibaba Group', 'The University of Hong Kong\nGuangdong–Hong Kong-Macau Joint Laboratory', 'Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences', 'The Chinese University of Hong Kong (Shenzhen)', 'The University of Hong Kong', 'DAMO Academy, Alibaba Group', 'The University of Hong Kong', 'DAMO Academy, Alibaba Group', 'DAMO Academy, Alibaba Group']","['SNLP: Lexical & Frame Semantics', 'Semantic Parsing']","Li, J., Hui, B., Cheng, R., Qin, B., Ma, C., Huo, N., Huang, F., Du, W., Si, L., & Li, Y. (2023). Graphix-T5: Mixing Pre-trained Transformers with Graph-Aware Layers for Text-to-SQL Parsing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13076-13084. https://doi.org/10.1609/aaai.v37i11.26536","Abstract 					The task of text-to-SQL parsing, which aims at converting natural language questions into executable SQL queries, has garnered increasing attention in recent years. One of the major challenges in text-to-SQL parsing is domain generalization, i.e., how to generalize well to unseen databases. Recently, the pre-trained text-to-text transformer model, namely T5, though not specialized for text-to-SQL parsing, has achieved state-of-the-art performance on standard benchmarks targeting domain generalization. In this work, we explore ways to further augment the pre-trained T5 model with specialized components for text-to-SQL parsing. Such components are expected to introduce structural inductive bias into text-to-SQL parsers thus improving the model’s capacity on (potentially multi-hop) reasoning, which is critical for generating structure-rich SQLs. To this end, we propose a new architecture GRAPHIX-T5, a mixed model with the standard pre-trained transformer model augmented by specially-designed graph-aware layers. Extensive experiments and analysis demonstrate the effectiveness of GRAPHIX-T5 across four text-to-SQL benchmarks: SPIDER, SYN, REALISTIC and DK. GRAPHIX-T5 surpasses all other T5-based parsers with a significant margin, achieving new state-of-the-art performance. Notably, GRAPHIX-T5-large reaches performance superior to the original T5-large by 5.7% on exact match (EM) accuracy and 6.6% on execution accuracy (EX). This even outperforms the T5-3B by 1.2% on EM and 1.5% on EX","https://ojs.aaai.org/index.php/AAAI/article/view/26536/26308"
"26537","Compressed Heterogeneous Graph for Abstractive Multi-Document Summarization","['Miao Li', 'Jianzhong Qi', 'Jey Han Lau']","['School of Computing and Information Systems, The University of Melbourne', 'School of Computing and Information Systems, The University of Melbourne', 'School of Computing and Information Systems, The University of Melbourne']","['SNLP: Summarization', 'ML: Graph-based Machine Learning', 'ML: Transfer', 'Domain Adaptation', 'Multi-Task Learning', 'SNLP: Generation']","Li, M., Qi, J., & Lau, J. H. (2023). Compressed Heterogeneous Graph for Abstractive Multi-Document Summarization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13085-13093. https://doi.org/10.1609/aaai.v37i11.26537","Abstract 					Multi-document summarization (MDS) aims to generate a summary for a number of related documents. We propose HGSum — an MDS model that extends an encoder-decoder architecture to incorporate a heterogeneous graph to represent different semantic units (e.g., words and sentences) of the documents. This contrasts with existing MDS models which do not consider different edge types of graphs and as such do not capture the diversity of relationships in the documents. To preserve only key information and relationships of the documents in the heterogeneous graph, HGSum uses graph pooling to compress the input graph. And to guide HGSum to learn the compression, we introduce an additional objective that maximizes the similarity between the compressed graph and the graph constructed from the ground-truth summary during training. HGSum is trained end-to-end with the graph similarity and standard cross-entropy objectives. Experimental results over Multi-News, WCEP-100, and Arxiv show that HGSum outperforms state-of-the-art MDS models. The code for our model and experiments is available at: https://github.com/oaimli/HGSum.","https://ojs.aaai.org/index.php/AAAI/article/view/26537/26309"
"26538","TrOCR: Transformer-Based Optical Character Recognition with Pre-trained Models","['Minghao Li', 'Tengchao Lv', 'Jingye Chen', 'Lei Cui', 'Yijuan Lu', 'Dinei Florencio', 'Cha Zhang', 'Zhoujun Li', 'Furu Wei']","['Beihang University', 'Microsoft Corporation', 'Microsoft Corporation', 'Microsoft Corporation', 'Microsoft Corporation', 'Microsoft Corporation', 'Microsoft Corporation', 'Beihang University', 'Microsoft Corporation']","['SNLP: Applications', 'CV: Language and Vision']","Li, M., Lv, T., Chen, J., Cui, L., Lu, Y., Florencio, D., Zhang, C., Li, Z., & Wei, F. (2023). TrOCR: Transformer-Based Optical Character Recognition with Pre-trained Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13094-13102. https://doi.org/10.1609/aaai.v37i11.26538","Abstract 					Text recognition is a long-standing research problem for document digitalization. Existing approaches are usually built based on CNN for image understanding and RNN for char-level text generation. In addition, another language model is usually needed to improve the overall accuracy as a post-processing step. In this paper, we propose an end-to-end text recognition approach with pre-trained image Transformer and text Transformer models, namely TrOCR, which leverages the Transformer architecture for both image understanding and wordpiece-level text generation. The TrOCR model is simple but effective, and can be pre-trained with large-scale synthetic data and fine-tuned with human-labeled datasets. Experiments show that the TrOCR model outperforms the current state-of-the-art models on the printed, handwritten and scene text recognition tasks. The TrOCR models and code are publicly available at https://aka.ms/trocr.","https://ojs.aaai.org/index.php/AAAI/article/view/26538/26310"
"26539","Mitigating Negative Style Transfer in Hybrid Dialogue System","['Shimin Li', 'Qinyuan Cheng', 'Linyang Li', 'Xipeng Qiu']","['Fudan University', 'Fudan University', 'Fudan University', 'Fudan University']","['SNLP: Conversational AI/Dialogue Systems']","Li, S., Cheng, Q., Li, L., & Qiu, X. (2023). Mitigating Negative Style Transfer in Hybrid Dialogue System. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13103-13111. https://doi.org/10.1609/aaai.v37i11.26539","Abstract 					As the functionality of dialogue systems evolves, hybrid dialogue systems that accomplish user-specific goals and participate in open-topic chitchat with users are attracting growing attention. Existing research learns both tasks concurrently utilizing a multi-task fusion technique but ignores the negative transfer phenomenon induced by the unique textual style differences. Therefore, contrastive learning based on the latent variable model is used to decouple the various textual genres in the latent space. We devise supervised and self-supervised positive and negative sample constructions for diverse datasets. In addition, to capitalize on the style information contained in the decoupled latent variables, we employ a style prefix that incorporates latent variables further to control the generation of responses with varying styles. We performed extensive experiments on three dialogue datasets, including a hybrid dialogue dataset and two task-oriented dialogue datasets. The experimental results demonstrate that our method can mitigate the negative style transfer issue and achieves state-of-the-art performance on multiple dialogue datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26539/26311"
"26540","Low Resource Quantitative Information Extraction via Structure Searching and Prefix-Based Text Generation","['Tongliang Li', 'Zixiang Wang', 'Zhoujun Li']","['Beihang University', 'Beihang University', 'Beihang University']","['SNLP: Information Extraction', 'SNLP: Generation']","Li, T., Wang, Z., & Li, Z. (2023). Low Resource Quantitative Information Extraction via Structure Searching and Prefix-Based Text Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13112-13120. https://doi.org/10.1609/aaai.v37i11.26540","Abstract 					Quantitative information plays an important part in the financial and data analysis areas. Prior work relied on pattern-matching methods and complex hand-crafted rules to extract quantitative information due to the lack of labeled data. Such methods can be unstable and difficult to scale to the open domain. In this paper, we study quantitative information extraction in the low-resource setting. We propose a search-based approach by searching from the syntactic structures to acquire basic training data. The search process is simple yet effective. Then, a prefix-based text-to-text generation method is employed to extract the quantitative information. The prefix design can fully leverage pre-trained language models for text generation to serve the information extraction purpose. Experimental results show that our approaches achieves high performance with a limited amount of labeled data. The extraction result could further boost the performance of other tasks such as quantitative reasoning.","https://ojs.aaai.org/index.php/AAAI/article/view/26540/26312"
"26541","SKIER: A Symbolic Knowledge Integrated Model for Conversational Emotion Recognition","['Wei Li', 'Luyao Zhu', 'Rui Mao', 'Erik Cambria']","['Nanyang Technological University, Singapore', 'Nanyang Technological University, Singapore', 'Nanyang Technological University, Singapore', 'Nanyang Technological University, Singapore']","['SNLP: Applications', 'SNLP: Sentiment Analysis and Stylistic Analysis']","Li, W., Zhu, L., Mao, R., & Cambria, E. (2023). SKIER: A Symbolic Knowledge Integrated Model for Conversational Emotion Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13121-13129. https://doi.org/10.1609/aaai.v37i11.26541","Abstract 					Emotion recognition in conversation (ERC) has received increasing attention from the research community. However, the ERC task is challenging, largely due to the complex and unstructured properties of multi-party conversations. Besides, the majority of daily dialogues take place in a specific context or circumstance, which requires rich external knowledge to understand the background of a certain dialogue. In this paper, we address these challenges by explicitly modeling the discourse relations between utterances and incorporating symbolic knowledge into multi-party conversations. We first introduce a dialogue parsing algorithm into ERC and further improve the algorithm through a transfer learning method. Moreover, we leverage different symbolic knowledge graph relations to learn knowledge-enhanced features for the ERC task. Extensive experiments on three benchmarks demonstrate that both dialogue structure graphs and symbolic knowledge are beneficial to the model performance on the task. Additionally, experimental results indicate that the proposed model surpasses baseline models on several indices.","https://ojs.aaai.org/index.php/AAAI/article/view/26541/26313"
"26542","PGSS: Pitch-Guided Speech Separation","['Xiang Li', 'Yiwen Wang', 'Yifan Sun', 'Xihong Wu', 'Jing Chen']","['Peking University', 'Peking University', 'Peking University', 'Peking University', 'Peking University']","['SNLP: Speech and Multimodality', 'SNLP: Applications', 'SNLP: Other Foundations of Speech & Natural Language Processing']","Li, X., Wang, Y., Sun, Y., Wu, X., & Chen, J. (2023). PGSS: Pitch-Guided Speech Separation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13130-13138. https://doi.org/10.1609/aaai.v37i11.26542","Abstract 					Monaural speech separation aims to separate concurrent speakers from a single-microphone mixture recording. Inspired by the effect of pitch priming in auditory scene analysis (ASA) mechanisms, a novel pitch-guided speech separation framework is proposed in this work. The prominent advantage of this framework is that both the permutation problem and the unknown speaker number problem existing in general models can be avoided by using pitch contours as the primary means to guide the target speaker. In addition, adversarial training is applied, instead of a traditional time-frequency mask, to improve the perceptual quality of separated speech. Specifically, the proposed framework can be divided into two phases: pitch extraction and speech separation. The former aims to extract pitch contour candidates for each speaker from the mixture, modeling the bottom-up process in ASA mechanisms. Any pitch contour can be selected as the condition in the second phase to separate the corresponding speaker, where a conditional generative adversarial network (CGAN) is applied. The second phase models the effect of pitch priming in ASA. Experiments on the WSJ0-2mix corpus reveal that the proposed approaches can achieve higher pitch extraction accuracy and better separation performance, compared to the baseline models, and have the potential to be applied to SOTA architectures.","https://ojs.aaai.org/index.php/AAAI/article/view/26542/26314"
"26543","DyRRen: A Dynamic Retriever-Reranker-Generator Model for Numerical Reasoning over Tabular and Textual Data","['Xiao Li', 'Yin Zhu', 'Sichen Liu', 'Jiangzhou Ju', 'Yuzhong Qu', 'Gong Cheng']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University']","['SNLP: Question Answering']","Li, X., Zhu, Y., Liu, S., Ju, J., Qu, Y., & Cheng, G. (2023). DyRRen: A Dynamic Retriever-Reranker-Generator Model for Numerical Reasoning over Tabular and Textual Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13139-13147. https://doi.org/10.1609/aaai.v37i11.26543","Abstract 					Numerical reasoning over hybrid data containing tables and long texts has recently received research attention from the AI community. To generate an executable reasoning program consisting of math and table operations to answer a question, state-of-the-art methods use a retriever-generator pipeline. However, their retrieval results are static, while different generation steps may rely on different sentences. To attend to the retrieved information that is relevant to each generation step, in this paper, we propose DyRRen, an extended retriever-reranker-generator framework where each generation step is enhanced by a dynamic reranking of retrieved sentences. It outperforms existing baselines on the FinQA dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/26543/26315"
"26544","Heterogeneous-Branch Collaborative Learning for Dialogue Generation","['Yiwei Li', 'Shaoxiong Feng', 'Bin Sun', 'Kan Li']","['Beijing Institute of Technology', 'Beijing Institute of Technology', 'Beijing Institute of Technology', 'Beijing Insitiute of Technology, China']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Generation']","Li, Y., Feng, S., Sun, B., & Li, K. (2023). Heterogeneous-Branch Collaborative Learning for Dialogue Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13148-13156. https://doi.org/10.1609/aaai.v37i11.26544","Abstract 					With the development of deep learning, advanced dialogue generation methods usually require a greater amount of computational resources. One promising approach to obtaining a high-performance and lightweight model is knowledge distillation, which relies heavily on the pre-trained powerful teacher. Collaborative learning, also known as online knowledge distillation, is an effective way to conduct one-stage group distillation in the absence of a well-trained large teacher model. However, previous work has a severe branch homogeneity problem due to the same training objective and the independent identical training sets.  To alleviate this problem, we consider the dialogue attributes in the training of network branches. Each branch learns the attribute-related features based on the selected subset. Furthermore, we propose a dual group-based knowledge distillation method, consisting of positive distillation and negative distillation, to further diversify the features of different branches in a steadily and interpretable way. The proposed approach significantly improves branch heterogeneity and outperforms state-of-the-art collaborative learning methods on two widely used open-domain dialogue datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26544/26316"
"26545","Learning to Know Myself: A Coarse-to-Fine Persona-Aware Training Framework for Personalized Dialogue Generation","['Yunpeng Li', 'Yue Hu', 'Yajing Sun', 'Luxi Xing', 'Ping Guo', 'Yuqiang Xie', 'Wei Peng']","['Institute of Information Engineering,Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering,Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering,Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering,Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Generation']","Li, Y., Hu, Y., Sun, Y., Xing, L., Guo, P., Xie, Y., & Peng, W. (2023). Learning to Know Myself: A Coarse-to-Fine Persona-Aware Training Framework for Personalized Dialogue Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13157-13165. https://doi.org/10.1609/aaai.v37i11.26545","Abstract 					A critical challenge for open-domain dialogue agents is to generate persona-relevant and consistent responses. Due to the nature of persona sparsity in conversation scenarios, previous persona-based dialogue agents trained with Maximum Likelihood Estimation tend to overlook the given personas and generate responses irrelevant or inconsistent with personas. To address this problem, we propose a two-stage coarse-to-fine persona-aware training framework to improve the persona consistency of a dialogue agent progressively. Specifically, our framework first trains the dialogue agent to answer the constructed persona-aware questions, making it highly sensitive to the personas to generate persona-relevant responses. Then the dialogue agent is further trained with a contrastive learning paradigm by explicitly perceiving the difference between the consistent and the generated inconsistent responses, forcing it to pay more attention to the key persona information to generate consistent responses. By applying our proposed training framework to several representative baseline models, experimental results show significant boosts on both automatic and human evaluation metrics, especially the consistency of generated responses.","https://ojs.aaai.org/index.php/AAAI/article/view/26545/26317"
"26546","WIERT: Web Information Extraction via Render Tree","['Zimeng Li', 'Bo Shao', 'Linjun Shou', 'Ming Gong', 'Gen Li', 'Daxin Jiang']","['Beihang University', 'Microsoft STCA', 'Microsoft STCA', 'Microsoft STCA', 'Microsoft STCA', 'Microsoft STCA']","['SNLP: Information Extraction', 'KRR: Knowledge Engineering', 'SNLP: Applications', 'SNLP: Language Models', 'SNLP: Question Answering', 'SNLP: Speech and Multimodality', 'SNLP: Text Mining']","Li, Z., Shao, B., Shou, L., Gong, M., Li, G., & Jiang, D. (2023). WIERT: Web Information Extraction via Render Tree. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13166-13173. https://doi.org/10.1609/aaai.v37i11.26546","Abstract 					Web information extraction (WIE) is a fundamental problem in web document understanding, with a significant impact on various applications. Visual information plays a crucial role in WIE tasks as the nodes containing relevant information are often visually distinct, such as being in a larger font size or having a brighter color, from the other nodes. However, rendering visual information of a web page can be computationally expensive. Previous works have mainly focused on the Document Object Model (DOM) tree, which lacks visual information. To efficiently exploit visual information, we propose leveraging the render tree, which combines the DOM tree and Cascading Style Sheets Object Model (CSSOM) tree, and contains not only content and layout information but also rich visual information at a little additional acquisition cost compared to the DOM tree. In this paper, we present WIERT, a method that effectively utilizes the render tree of a web page based on a pretrained language model. We evaluate WIERT on the Klarna product page dataset, a manually labeled dataset of renderable e-commerce web pages, demonstrating its effectiveness and robustness.","https://ojs.aaai.org/index.php/AAAI/article/view/26546/26318"
"26547","STAGE: Span Tagging and Greedy Inference Scheme for Aspect Sentiment Triplet Extraction","['Shuo Liang', 'Wei Wei', 'Xian-Ling Mao', 'Yuanyuan Fu', 'Rui Fang', 'Dangyang Chen']","['School of Computer Science and Technology, Huazhong University of Science and Technology\nJoint Laboratory of HUST and Pingan Property & Casualty Research (HPL)', 'School of Computer Science and Technology, Huazhong University of Science and Technology\nJoint Laboratory of HUST and Pingan Property & Casualty Research (HPL)', 'Department of Computer Science and Technology, Beijing Institute of Technology', 'Ping An Property & Casualty Insurance company of China, Ltd\nJoint Laboratory of HUST and Pingan Property & Casualty Research (HPL)', 'Ping An Property & Casualty Insurance company of China, Ltd\nJoint Laboratory of HUST and Pingan Property & Casualty Research (HPL)', 'Ping An Property & Casualty Insurance company of China, Ltd\nJoint Laboratory of HUST and Pingan Property & Casualty Research (HPL)']","['SNLP: Sentiment Analysis and Stylistic Analysis', 'SNLP: Information Extraction']","Liang, S., Wei, W., Mao, X.-L., Fu, Y., Fang, R., & Chen, D. (2023). STAGE: Span Tagging and Greedy Inference Scheme for Aspect Sentiment Triplet Extraction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13174-13182. https://doi.org/10.1609/aaai.v37i11.26547","Abstract 					Aspect Sentiment Triplet Extraction (ASTE) has become an emerging task in sentiment analysis research, aiming to extract triplets of the aspect term, its corresponding opinion term, and its associated sentiment polarity from a given sentence. Recently, many neural networks based models with different tagging schemes have been proposed, but almost all of them have their limitations: heavily relying on 1) prior assumption that each word is only associated with a single role (e.g., aspect term, or opinion term, etc. ) and 2) word-level interactions and treating each opinion/aspect as a set of independent words. Hence, they perform poorly on the complex ASTE task, such as a word associated with multiple roles or an aspect/opinion term with multiple words. Hence, we propose a novel approach, Span TAgging and Greedy infErence (STAGE), to extract sentiment triplets in span-level, where each span may consist of multiple words and play different roles simultaneously. To this end, this paper formulates the ASTE task as a multi-class span classification problem. Specifically, STAGE generates more accurate aspect sentiment triplet extractions via exploring span-level information and constraints, which consists of two components, namely, span tagging scheme and greedy inference strategy. The former tag all possible candidate spans based on a newly-defined tagging set. The latter retrieves the aspect/opinion term with the maximum length from the candidate sentiment snippet to output sentiment triplets. Furthermore, we propose a simple but effective model based on the STAGE, which outperforms the state-of-the-arts by a large margin on four widely-used datasets. Moreover, our STAGE can be easily generalized to other pair/triplet extraction tasks, which also demonstrates the superiority of the proposed scheme STAGE.","https://ojs.aaai.org/index.php/AAAI/article/view/26547/26319"
"26548","Generalizing Math Word Problem Solvers via Solution Diversification","['Zhenwen Liang', 'Jipeng Zhang', 'Lei Wang', 'Yan Wang', 'Jie Shao', 'Xiangliang Zhang']","['University of Notre Dame', 'Hong Kong University of Science and Technology', 'Singapore Management University', 'Tencent AI Lab', 'University of Electronic Science and Technology of China', 'University of Notre Dame']","['SNLP: Question Answering', 'KRR: Argumentation', 'ML: Applications', 'ML: Probabilistic Methods', 'SNLP: Applications']","Liang, Z., Zhang, J., Wang, L., Wang, Y., Shao, J., & Zhang, X. (2023). Generalizing Math Word Problem Solvers via Solution Diversification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13183-13191. https://doi.org/10.1609/aaai.v37i11.26548","Abstract 					Current math word problem (MWP) solvers are usually Seq2Seq models  trained by the (one-problem; one-solution) pairs, each of which is made of a problem description and a solution showing reasoning flow to get the correct answer. However, one MWP problem naturally has multiple solution equations. The training of an MWP solver with (one-problem; one-solution) pairs excludes other correct solutions, and thus limits the generalizability of the MWP solver. One feasible solution to this limitation is to augment multiple solutions to a given problem. However, it is difficult to collect diverse and accurate augment solutions through human efforts. In this paper, we design a new training framework for an MWP solver by introducing a solution buffer and a solution discriminator. The buffer includes solutions generated by an MWP solver to encourage  the training data diversity.  The discriminator controls the quality of buffered solutions to participate in training. Our framework is flexibly applicable to a wide setting of fully, semi-weakly and weakly supervised training for all Seq2Seq MWP solvers. We conduct extensive experiments on a benchmark dataset Math23k and a new dataset named Weak12k, and show that our framework improves the performance of various MWP solvers under different settings by generating correct and diverse solutions.","https://ojs.aaai.org/index.php/AAAI/article/view/26548/26320"
"26549","On Grounded Planning for Embodied Tasks with Language Models","['Bill Yuchen Lin', 'Chengsong Huang', 'Qian Liu', 'Wenda Gu', 'Sam Sommerer', 'Xiang Ren']","['University of Southern California', 'Fudan University', 'Sea AI Lab', 'University of Southern California', 'University of Southern California', 'University of Southern California']","['SNLP: Generation', 'SNLP: Language Grounding', 'ML: Applications', 'SNLP: Applications']","Lin, B. Y., Huang, C., Liu, Q., Gu, W., Sommerer, S., & Ren, X. (2023). On Grounded Planning for Embodied Tasks with Language Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13192-13200. https://doi.org/10.1609/aaai.v37i11.26549","Abstract 					Language models (LMs) have demonstrated their capability in possessing commonsense knowledge of the physical world, a crucial aspect of performing tasks in everyday life. However, it remains unclear whether they have the capacity to generate grounded, executable plans for embodied tasks. This is a challenging task as LMs lack the ability to perceive the environment through vision and feedback from the physical environment. In this paper, we address this important research question and present the first investigation into the topic. Our novel problem formulation, named G-PlanET, inputs a high-level goal and a data table about objects in a specific environment, and then outputs a step-by-step actionable plan for a robotic agent to follow. To facilitate the study, we establish an evaluation protocol and design a dedicated metric, KAS, to assess the quality of the plans. Our experiments demonstrate that the use of tables for encoding the environment and an iterative decoding strategy can significantly enhance the LMs' ability in grounded planning. Our analysis also reveals interesting and non-trivial findings.","https://ojs.aaai.org/index.php/AAAI/article/view/26549/26321"
"26550","DeAR: A Deep-Learning-Based Audio Re-recording Resilient Watermarking","['Chang Liu', 'Jie Zhang', 'Han Fang', 'Zehua Ma', 'Weiming Zhang', 'Nenghai Yu']","['University of Science and Technology of China', 'University of Science and Technology of China\nUniversity of Waterloo', 'National University of Singapore', 'University of Science and Technology of China', 'University of Science and Technology of China', 'University of Science and Technology of China']","['SNLP: Applications']","Liu, C., Zhang, J., Fang, H., Ma, Z., Zhang, W., & Yu, N. (2023). DeAR: A Deep-Learning-Based Audio Re-recording Resilient Watermarking. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13201-13209. https://doi.org/10.1609/aaai.v37i11.26550","Abstract 					Audio watermarking is widely used for leaking source tracing. The robustness of the watermark determines the traceability of the algorithm. With the development of digital technology, audio re-recording (AR) has become an efficient and covert means to steal secrets. AR process could drastically destroy the watermark signal while preserving the original information. This puts forward a new requirement for audio watermarking at this stage, that is, to be robust to AR distortions. Unfortunately, none of the existing algorithms can effectively resist AR attacks due to the complexity of the AR process. To address this limitation, this paper proposes DeAR, a deep-learning-based audio re-recording resistant watermarking. Inspired by DNN-based image watermarking, we pioneer a deep learning framework for audio carriers, based on which the watermark signal can be effectively embedded and extracted. Meanwhile, in order to resist the AR attack, we delicately analyze the distortions that occurred in the AR process and design the corresponding distortion layer to cooperate with the proposed watermarking framework. Extensive experiments show that the proposed algorithm can resist not only common electronic channel distortions but also AR distortions. Under the premise of high-quality embedding (SNR=25.86dB), in the case of a common re-recording distance (20cm), the algorithm can effectively achieve an average bit recovery accuracy of 98.55%.","https://ojs.aaai.org/index.php/AAAI/article/view/26550/26322"
"26551","Detecting and Grounding Important Characters in Visual Stories","['Danyang Liu', 'Frank Keller']","['University of Edinburgh', 'University of Edinburgh']","['SNLP: Language Grounding', 'CV: Language and Vision', 'HAI: Procedural Content Generation & Storytelling']","Liu, D., & Keller, F. (2023). Detecting and Grounding Important Characters in Visual Stories. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13210-13218. https://doi.org/10.1609/aaai.v37i11.26551","Abstract 					Characters are essential to the plot of any story. Establishing the characters before writing a story can improve the clarity of the plot and the overall flow of the narrative. However, previous work on visual storytelling tends to focus on detecting objects in images and discovering relationships between them. In this approach, characters are not distinguished from other objects when they are fed into the generation pipeline. The result is a coherent sequence of events rather than a character-centric story. In order to address this limitation, we introduce the VIST-Character dataset, which provides rich character-centric annotations, including visual and textual co-reference chains and importance ratings for characters. Based on this dataset, we propose two new tasks: important character detection and character grounding in visual stories. For both tasks, we develop simple, unsupervised models based on distributional similarity and pre-trained vision-and-language models. Our new dataset, together with these models, can serve as the foundation for subsequent work on analysing and generating stories from a character-centric perspective.","https://ojs.aaai.org/index.php/AAAI/article/view/26551/26323"
"26552","Boosting Few-Shot Text Classification via Distribution Estimation","['Han Liu', 'Feng Zhang', 'Xiaotong Zhang', 'Siyang Zhao', 'Fenglong Ma', 'Xiao-Ming Wu', 'Hongyang Chen', 'Hong Yu', 'Xianchao Zhang']","['Dalian University of Technology', 'Peking University', 'Dalian University of Technology', 'Dalian University of Technology', 'The Pennsylvania State University', 'The Hong Kong Polytechnic University', 'Zhejiang Lab', 'Dalian University of Technology', 'Dalian University of Technology']","['SNLP: Text Classification']","Liu, H., Zhang, F., Zhang, X., Zhao, S., Ma, F., Wu, X.-M., Chen, H., Yu, H., & Zhang, X. (2023). Boosting Few-Shot Text Classification via Distribution Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13219-13227. https://doi.org/10.1609/aaai.v37i11.26552","Abstract 					Distribution estimation has been demonstrated as one of the most effective approaches in dealing with few-shot image classification, as the low-level patterns and underlying representations can be easily transferred across different tasks in computer vision domain. However, directly applying this approach to few-shot text classification is challenging, since leveraging the statistics of known classes with sufficient samples to calibrate the distributions of novel classes may cause negative effects due to serious category difference in text domain. To alleviate this issue, we propose two simple yet effective strategies to estimate the distributions of the novel classes by utilizing unlabeled query samples, thus avoiding the potential negative transfer issue. Specifically, we first assume a class or sample follows the Gaussian distribution, and use the original support set and the nearest few query samples to estimate the corresponding mean and covariance. Then, we augment the labeled samples by sampling from the estimated distribution, which can provide sufficient supervision for training the classification model. Extensive experiments on eight few-shot text classification datasets show that the proposed method outperforms state-of-the-art baselines significantly.","https://ojs.aaai.org/index.php/AAAI/article/view/26552/26324"
"26553","SSPAttack: A Simple and Sweet Paradigm for Black-Box Hard-Label Textual Adversarial Attack","['Han Liu', 'Zhi Xu', 'Xiaotong Zhang', 'Xiaoming Xu', 'Feng Zhang', 'Fenglong Ma', 'Hongyang Chen', 'Hong Yu', 'Xianchao Zhang']","['Dalian University of Technology', 'Dalian University of Technology', 'Dalian University of Technology', 'Dalian University of Technology', 'Peking University', 'The Pennsylvania State University', 'Zhejiang Lab', 'Dalian University of Technology', 'Dalian University of Technology']","['SNLP: Adversarial Attacks & Robustness']","Liu, H., Xu, Z., Zhang, X., Xu, X., Zhang, F., Ma, F., Chen, H., Yu, H., & Zhang, X. (2023). SSPAttack: A Simple and Sweet Paradigm for Black-Box Hard-Label Textual Adversarial Attack. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13228-13235. https://doi.org/10.1609/aaai.v37i11.26553","Abstract 					Hard-label textual adversarial attack is a challenging task, as only the predicted label information is available, and the text space is discrete and non-differentiable. Relevant research work is still in fancy and just a handful of methods are proposed. However, existing methods suffer from either the high complexity of genetic algorithms or inaccurate gradient estimation, thus are arduous to obtain adversarial examples with high semantic similarity and low perturbation rate under the tight-budget scenario. In this paper, we propose a simple and sweet paradigm for hard-label textual adversarial attack, named SSPAttack. Specifically, SSPAttack first utilizes initialization to generate an adversarial example, and removes unnecessary replacement words to reduce the number of changed words. Then it determines the replacement order and searches for an anchor synonym, thus avoiding going through all the synonyms. Finally, it pushes substitution words towards original words until an appropriate adversarial example is obtained. The core idea of SSPAttack is just swapping words whose mechanism is simple. Experimental results on eight benchmark datasets and two real-world APIs have shown that the performance of SSPAttack is sweet in terms of similarity, perturbation rate and query efficiency.","https://ojs.aaai.org/index.php/AAAI/article/view/26553/26325"
"26554","LADA-Trans-NER: Adaptive Efficient Transformer for Chinese Named Entity Recognition Using Lexicon-Attention and Data-Augmentation","['Jiguo Liu', 'Chao Liu', 'Nan Li', 'Shihao Gao', 'Mingqi Liu', 'Dali Zhu']","['Institute of Information Engineering, Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences', 'Institute of Information Engineering, Chinese Academy of Sciences\nSchool of Cyber Security, University of Chinese Academy of Sciences']","['SNLP: Information Extraction', 'KRR: Knowledge Acquisition', 'KRR: Knowledge Engineering', 'KRR: Knowledge Representation Languages', 'ML: Multi-Class/Multi-Label Learning & Extreme Classification', 'SNLP: Applications', 'SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Lexical & Frame Semantics', 'Semantic Parsing', 'SNLP: Ontology Induction From Text', 'SNLP: Text Classification', 'SNLP: Text Mining']","Liu, J., Liu, C., Li, N., Gao, S., Liu, M., & Zhu, D. (2023). LADA-Trans-NER: Adaptive Efficient Transformer for Chinese Named Entity Recognition Using Lexicon-Attention and Data-Augmentation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13236-13245. https://doi.org/10.1609/aaai.v37i11.26554","Abstract 					Recently, word enhancement has become very popular for Chinese Named Entity Recognition (NER), reducing segmentation errors and increasing the semantic and boundary information of Chinese words. However, these methods tend to ignore the semantic relationship before and after the sentence after integrating lexical information. Therefore, the regularity of word length information has not been fully explored in various word-character fusion methods. In this work, we propose a Lexicon-Attention and Data-Augmentation (LADA) method for Chinese NER. We discuss the challenges of using existing methods in incorporating word information for NER and show how our proposed methods could be leveraged to overcome those challenges. LADA is based on a Transformer Encoder that utilizes lexicon to construct a directed graph and fuses word information through updating the optimal edge of the graph. Specially, we introduce the advanced data augmentation method to obtain the optimal representation for the NER task. Experimental results show that the augmentation done using LADA can considerably boost the performance of our NER system and achieve significantly better results than previous state-of-the-art methods and variant models in the literature on four publicly available NER datasets, namely Resume, MSRA, Weibo, and OntoNotes v4. We also observe better generalization and application to a real-world setting from LADA on multi-source complex entities.","https://ojs.aaai.org/index.php/AAAI/article/view/26554/26326"
"26555","Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation","['Min Liu', 'Yu Bao', 'Chengqi Zhao', 'Shujian Huang']","['National Key Laboratory for Novel Software Technology, Nanjing University', 'ByteDance AI Lab', 'ByteDance AI Lab', 'National Key Laboratory for Novel Software Technology, Nanjing University\nCollaborative Innovation Center of Novel Software Technology and Industrialization']","['SNLP: Machine Translation & Multilinguality']","Liu, M., Bao, Y., Zhao, C., & Huang, S. (2023). Selective Knowledge Distillation for Non-Autoregressive Neural Machine Translation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13246-13254. https://doi.org/10.1609/aaai.v37i11.26555","Abstract 					Benefiting from the sequence-level knowledge distillation, the Non-Autoregressive Transformer (NAT) achieves great success in neural machine translation tasks.  However, existing knowledge distillation has side effects, such as propagating errors from the teacher to NAT students, which may limit further improvements of NAT models and are rarely discussed in existing research. In this paper, we introduce selective knowledge distillation by introducing an NAT evaluator to select NAT-friendly targets that are of high quality and easy to learn. In addition, we introduce a simple yet effective progressive distillation method to boost NAT performance.  Experiment results on multiple WMT language directions and several representative NAT models show that our approach can realize a flexible trade-off between the quality and complexity of training data for NAT models, achieving strong performances. Further analysis shows that distilling only 5% of the raw translations can help an NAT outperform its counterpart trained on raw data by about 2.4 BLEU.","https://ojs.aaai.org/index.php/AAAI/article/view/26555/26327"
"26556","A Disentangled-Attention Based Framework with Persona-Aware Prompt Learning for Dialogue Generation","['Pingsheng Liu', 'Zhengjie Huang', 'Xiechi Zhang', 'Linlin Wang', 'Gerard de Melo', 'Xin Lin', 'Liang Pang', 'Liang He']","['East China Normal University', 'East China Normal University', 'East China Normal University', 'East China Normal University', 'Hasso Plattner Institute, University of Potsdam', 'East China Normal University', 'Institute of Computing Technology, Chinese Academy of Sciences', 'East China Normal University']","['SNLP: Generation']","Liu, P., Huang, Z., Zhang, X., Wang, L., de Melo, G., Lin, X., Pang, L., & He, L. (2023). A Disentangled-Attention Based Framework with Persona-Aware Prompt Learning for Dialogue Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13255-13263. https://doi.org/10.1609/aaai.v37i11.26556","Abstract 					Endowing dialogue agents with personas is the key to delivering more human-like conversations. However, existing persona-grounded dialogue systems still lack informative details of human conversations and tend to reply with inconsistent and generic responses. One of the main underlying causes is that pre-defined persona sentences are generally short and merely superficial descriptions of personal attributes, making appropriate persona selection and understanding non-trivial. Another challenge is that it is crucial to consider the context and the conversation flow to dynamically determine when to invoke different types of persona signals. To address these problems, we propose a disentangled-attention based pre-training architecture, which incorporates persona-aware prompt learning to bridge the connection between the selected persona and response generation. Our model first exploits the conversation flow to select context-relevant personas, and subsequently enriches the superficial persona descriptions with extra personality traits through persona-aware prompting. Finally, the decoder leverages a disentangled-attention mechanism to flexibly control the reliance on personas and dialogue contexts, and incorporates A*-like keyword-based heuristic estimates for controllable generation. Extensive experiments show that our approach can outperform strong baselines and deliver more consistent and engaging responses on the PERSONA-CHAT dataset.","https://ojs.aaai.org/index.php/AAAI/article/view/26556/26328"
"26557","Towards Credible Human Evaluation of Open-Domain Dialog Systems Using Interactive Setup","['Sijia Liu', 'Patrick Lange', 'Behnam Hedayatnia', 'Alexandros Papangelis', 'Di Jin', 'Andrew Wirth', 'Yang Liu', 'Dilek Hakkani-Tur']","['Amazon Alexa AI', 'Amazon Alexa AI', 'Amazon Alexa AI', 'Amazon Alexa AI', 'Amazon Alexa AI', 'Amazon Alexa AI', 'Amazon Alexa AI', 'Amazon Alexa AI']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Interpretability & Analysis of NLP Models']","Liu, S., Lange, P., Hedayatnia, B., Papangelis, A., Jin, D., Wirth, A., Liu, Y., & Hakkani-Tur, D. (2023). Towards Credible Human Evaluation of Open-Domain Dialog Systems Using Interactive Setup. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13264-13272. https://doi.org/10.1609/aaai.v37i11.26557","Abstract 					Evaluating open-domain conversation models has been an open challenge due to the open-ended nature of conversations. In addition to static evaluations, recent work has started to explore a variety of per-turn and per-dialog interactive evaluation mechanisms and provide advice on the best setup. In this work, we adopt the interactive evaluation framework and further apply to multiple models with a focus on per-turn evaluation techniques. Apart from the widely used setting where participants select the best response among different candidates at each turn, one more novel per-turn evaluation setting is adopted, where participants can select all appropriate responses with different fallback strategies to continue the conversation when no response is selected. We evaluate these settings based on sensitivity and consistency using four GPT2-based models that differ in model sizes or fine-tuning data. To better generalize to any model groups with no prior assumptions on their rankings and control evaluation costs for all setups, we also propose a methodology to estimate the required sample size given a minimum performance gap of interest before running most experiments. Our comprehensive human evaluation results shed light on how to conduct credible human evaluations of open domain dialog systems using the interactive setup, and suggest additional future directions.","https://ojs.aaai.org/index.php/AAAI/article/view/26557/26329"
"26558","Unsupervised Paraphrasing under Syntax Knowledge","['Tianyuan Liu', 'Yuqing Sun', 'Jiaqi Wu', 'Xi Xu', 'Yuchen Han', 'Cheng Li', 'Bin Gong']","['Shandong University', 'Shandong University', 'Shandong University', 'Shandong University', 'Shandong University', 'Shandong University', 'Shandong University']","['SNLP: Generation', 'SNLP: Other Foundations of Speech & Natural Language Processing']","Liu, T., Sun, Y., Wu, J., Xu, X., Han, Y., Li, C., & Gong, B. (2023). Unsupervised Paraphrasing under Syntax Knowledge. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13273-13281. https://doi.org/10.1609/aaai.v37i11.26558","Abstract 					The soundness of syntax is an important issue for the paraphrase generation task.  Most methods control the syntax of paraphrases by embedding the syntax and semantics in the generation process, which cannot guarantee the syntactical correctness of the results.  Different from them, in this paper we investigate the structural patterns of word usages termed as the word composable knowledge and integrate it into the paraphrase generation to control the syntax in an explicit way. This syntax knowledge is pretrained on a large corpus with the dependency relationships and formed as the probabilistic functions on the word-level syntactical soundness. For the sentence-level correctness, we design a hierarchical syntax structure loss to quantitatively verify the syntactical soundness of the paraphrase against the given dependency template.  Thus, the generation process can select the appropriate words with consideration on both semantics and syntax.  The proposed method is evaluated on a few paraphrase datasets. The experimental results show that the quality of paraphrases by our proposed method outperforms the compared methods, especially in terms of syntax correctness.","https://ojs.aaai.org/index.php/AAAI/article/view/26558/26330"
"26559","Adjective Scale Probe: Can Language Models Encode Formal Semantics Information?","['Wei Liu', 'Ming Xiang', 'Nai Ding']","['College of Biomedical Engineering and Instrument Sciences, Zhejiang University', 'Department of Linguistics, The University of Chicago', 'College of Biomedical Engineering and Instrument Sciences, Zhejiang University']","['SNLP: Sentence-Level Semantics and Textual Inference', 'SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Lexical & Frame Semantics', 'Semantic Parsing']","Liu, W., Xiang, M., & Ding, N. (2023). Adjective Scale Probe: Can Language Models Encode Formal Semantics Information?. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13282-13290. https://doi.org/10.1609/aaai.v37i11.26559","Abstract 					It is an open question what semantic representations transformer-based language models can encode and whether they have access to more abstract aspects of semantic meaning. Here, we propose a diagnostic dataset to investigate how well language models understand the degree semantics of adjectives. In the dataset, referred as the Adjective Scale Probe (ASP), we semi-automatically generate 8 tests of Natural Language Inference (NLI) questions to test 8 key capabilities of adjective interpretation. We apply the ASP dataset to evaluate the performance of 3 language models, i.e., BERT, DeBERTa, and T0. It is found that language models perform below the majority baseline for most tests of the ASP, even when the models have been fine-tuned to achieve high performance on the large-scale MNLI dataset. But after we fine-tune the pre-trained models on a subset of the ASP, DeBERTa can achieve high performance on the untrained adjectives and untrained tests, suggesting that DeBERTa may have captured degree semantic information of adjectives through pre-training but it needs specific training data to learn how to apply such information to the current tasks. In sum, the ASP provides an easy-to-use method to test fine-grained formal semantic properties of adjectives, and reveals language models' abilities to access formal semantic information.","https://ojs.aaai.org/index.php/AAAI/article/view/26559/26331"
"26560","Effective Open Intent Classification with K-center Contrastive Learning and Adjustable Decision Boundary","['Xiaokang Liu', 'Jianquan Li', 'Jingjing Mu', 'Min Yang', 'Ruifeng Xu', 'Benyou Wang']","['China Automotive Technology and Research Center Co., Ltd.', 'Beijing Ultrapower Software Co.,Ltd.', 'Beijing Ultrapower Software Co.,Ltd.,', 'Chinese Academy of Sciences', 'Harbin Institute of Technology (Shenzhen)', 'The Chinese University of Hong Kong, Shenzhen']","['SNLP: Text Classification']","Liu, X., Li, J., Mu, J., Yang, M., Xu, R., & Wang, B. (2023). Effective Open Intent Classification with K-center Contrastive Learning and Adjustable Decision Boundary. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13291-13299. https://doi.org/10.1609/aaai.v37i11.26560","Abstract 					Open intent classification, which aims to correctly classify the known intents into their corresponding classes while identifying the new unknown (open) intents, is an essential but challenging task in dialogue systems. In this paper, we introduce novel K-center contrastive learning and adjustable decision boundary learning (CLAB) to improve the effectiveness of open intent classification. First, we pre-train a feature encoder on the labeled training instances, which transfers knowledge from known intents to unknown intents. Specifically, we devise a K-center contrastive learning algorithm to learn discriminative and balanced intent features, improving the generalization of the model for recognizing open intents. Second, we devise an adjustable decision boundary learning method with expanding and shrinking (ADBES) to determine the suitable decision conditions. Concretely, we learn a decision boundary for each known intent class, which consists of a decision center and the radius of the decision boundary. We then expand the radius of the decision boundary to accommodate more in-class instances if the out-of-class instances are far from the decision boundary; otherwise, we shrink the radius of the decision boundary. Extensive experiments on three benchmark datasets clearly demonstrate the effectiveness of our method for open intent classification.For reproducibility, we submit the code at: https://github.com/lxk00/CLAP","https://ojs.aaai.org/index.php/AAAI/article/view/26560/26332"
"26561","Learning Compositional Tasks from Language Instructions","['Lajanugen Logeswaran', 'Wilka Carvalho', 'Honglak Lee']","['LG AI Research', 'University of Michigan', 'LG AI Research\nUniversity of Michigan']","['SNLP: Language Grounding', 'ML: Representation Learning']","Logeswaran, L., Carvalho, W., & Lee, H. (2023). Learning Compositional Tasks from Language Instructions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13300-13308. https://doi.org/10.1609/aaai.v37i11.26561","Abstract 					The ability to combine learned knowledge and skills to solve novel tasks is a key aspect of generalization in humans that allows us to understand and perform tasks described by novel language utterances. While progress has been made in supervised learning settings, no work has yet studied compositional generalization of a reinforcement learning agent following natural language instructions in an embodied environment. We develop a set of tasks in a photo-realistic simulated kitchen environment that allow us to study the degree to which a behavioral policy captures the systematicity in language by studying its zero-shot generalization performance on held out natural language instructions. We show that our agent which leverages a novel additive action-value decomposition in tandem with attention based subgoal prediction is able to exploit composition in text instructions to generalize to unseen tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26561/26333"
"26562","SPRING: Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph","['Yuxing Long', 'Binyuan Hui', 'Fulong Ye', 'Yanyang Li', 'Zhuoxin Han', 'Caixia Yuan', 'Yongbin Li', 'Xiaojie Wang']","['Beijing University of Posts and Telecommunications', 'Independent Researcher', 'Beijing University of Posts and Telecommunications', 'Independent Researcher', 'Beijing University of Posts and Telecommunications', 'Beijing University of Posts and Telecommunications', 'Independent Researcher', 'Beijing University of Posts and Telecommunications']","['SNLP: Conversational AI/Dialogue Systems', 'CV: Multi-modal Vision', 'SNLP: Generation', 'SNLP: Language Models', 'SNLP: Question Answering']","Long, Y., Hui, B., Ye, F., Li, Y., Han, Z., Yuan, C., Li, Y., & Wang, X. (2023). SPRING: Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13309-13317. https://doi.org/10.1609/aaai.v37i11.26562","Abstract 					Existing multimodal conversation agents have shown impressive abilities to locate absolute positions or retrieve attributes in simple scenarios, but they fail to perform well when complex relative positions and information alignments are involved, which poses a bottleneck in response quality. In this paper, we propose a Situated Conversation Agent Pretrained with Multimodal Questions from Incremental Layout Graph (SPRING) with abilities of reasoning multi-hops spatial relations and connecting them with visual attributes in crowded situated scenarios. Specifically, we design two types of Multimodal Question Answering (MQA) tasks to pretrain the agent. All QA pairs utilized during pretraining are generated from novel Increment Layout Graphs (ILG). QA pair difficulty labels automatically annotated by ILG are used to promote MQA-based Curriculum Learning. Experimental results verify the SPRING's effectiveness, showing that it significantly outperforms state-of-the-art approaches on both SIMMC 1.0 and SIMMC 2.0 datasets. We release our code and data at https://github.com/LYX0501/SPRING.","https://ojs.aaai.org/index.php/AAAI/article/view/26562/26334"
"26563","Universal Information Extraction as Unified Semantic Matching","['Jie Lou', 'Yaojie Lu', 'Dai Dai', 'Wei Jia', 'Hongyu Lin', 'Xianpei Han', 'Le Sun', 'Hua Wu']","['Baidu, Inc.', 'Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences', 'Baidu, Inc.', 'Baidu, Inc.', 'Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences', 'Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences\nState Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences', 'Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences\nState Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences', 'Baidu, Inc.']","['SNLP: Information Extraction']","Lou, J., Lu, Y., Dai, D., Jia, W., Lin, H., Han, X., Sun, L., & Wu, H. (2023). Universal Information Extraction as Unified Semantic Matching. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13318-13326. https://doi.org/10.1609/aaai.v37i11.26563","Abstract 					The challenge of information extraction (IE) lies in the diversity of label schemas and the heterogeneity of structures. Traditional methods require task-specific model design and rely heavily on expensive supervision, making them difficult to generalize to new schemas. In this paper, we decouple IE into two basic abilities, structuring and conceptualizing, which are shared by different tasks and schemas. Based on this paradigm, we propose to universally model various IE tasks with Unified Semantic Matching (USM) framework, which introduces three unified token linking operations to model the abilities of structuring and conceptualizing. In this way, USM can jointly encode schema and input text, uniformly extract substructures in parallel, and controllably decode target structures on demand. Empirical evaluation on 4 IE tasks shows that the proposed method achieves state-of-the-art performance under the supervised experiments and shows strong generalization ability in zero/few-shot transfer settings.","https://ojs.aaai.org/index.php/AAAI/article/view/26563/26335"
"26564","PUnifiedNER: A Prompting-Based Unified NER System for Diverse Datasets","['Jinghui Lu', 'Rui Zhao', 'Brian Mac Namee', 'Fei Tan']","['SenseTime Group Limited', 'SenseTime Group Limited', 'University College Dublin', 'SenseTime Group Limited']","['SNLP: Information Extraction', 'SNLP: Applications', 'SNLP: Generation', 'SNLP: Language Models', 'SNLP: Text Mining']","Lu, J., Zhao, R., Mac Namee, B., & Tan, F. (2023). PUnifiedNER: A Prompting-Based Unified NER System for Diverse Datasets. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13327-13335. https://doi.org/10.1609/aaai.v37i11.26564","Abstract 					Much of named entity recognition (NER) research focuses on developing dataset-specific models based on data from the domain of interest, and a limited set of related entity types. This is frustrating as each new dataset requires a new model to be trained and stored. In this work, we present a ``versatile'' model---the Prompting-based Unified NER system (PUnifiedNER)---that works with data from different domains and can recognise up to 37 entity types simultaneously, and theoretically it could be as many as possible. By using prompt learning, PUnifiedNER is a novel approach that is able to jointly train across multiple corpora, implementing intelligent on-demand entity recognition. Experimental results show that PUnifiedNER leads to significant prediction benefits compared to dataset-specific models with impressively reduced model deployment costs. Furthermore, the performance of PUnifiedNER can achieve competitive or even better performance than state-of-the-art domain-specific methods for some datasets. We also perform comprehensive pilot and ablation studies to support in-depth analysis of each component in PUnifiedNER.","https://ojs.aaai.org/index.php/AAAI/article/view/26564/26336"
"26565","KICE: A Knowledge Consolidation and Expansion Framework for Relation Extraction","['Yilin Lu', 'Xiaoqiang Wang', 'Haofeng Yang', 'Siliang Tang']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University']","['SNLP: Information Extraction', 'DMKM: Rule Mining & Pattern Mining', 'HAI: Human-in-the-Loop Machine Learning', 'ML: Classification and Regression']","Lu, Y., Wang, X., Yang, H., & Tang, S. (2023). KICE: A Knowledge Consolidation and Expansion Framework for Relation Extraction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13336-13343. https://doi.org/10.1609/aaai.v37i11.26565","Abstract 					Machine Learning is often challenged by insufficient labeled data. Previous methods employing implicit commonsense knowledge of pre-trained language models (PLMs) or pattern-based symbolic knowledge have achieved great success in mitigating manual annotation efforts. In this paper, we focus on the collaboration among different knowledge sources and present KICE, a Knowledge-evolving framework by Iterative Consolidation and Expansion with the guidance of PLMs and rule-based patterns. Specifically, starting with limited labeled data as seeds, KICE first builds a Rule Generator by prompt-tuning to stimulate the rich knowledge distributed in PLMs, generate seed rules, and initialize the rules set. Afterwards, based on the rule-labeled data, the task model is trained in a self-training pipeline where the knowledge in rules set is consolidated with self-learned high-confidence rules. Finally, for the low-confidence rules, KICE solicits human-enlightened understanding and expands the knowledge coverage for better task model training. Our framework is verified on relation extraction (RE) task, and the experiments on TACRED show that the model performance (F1) grows from 33.24% to 79.84% with the enrichment of knowledge, outperforming all the baselines including other knowledgeable methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26565/26337"
"26566","Zero-Shot Slot Filling with Slot-Prefix Prompting and Attention Relationship Descriptor","['Qiaoyang Luo', 'Lingqiao Liu']","['University of Adelaide', 'University of Adelaide']","['SNLP: Information Extraction', 'SNLP: Language Models']","Luo, Q., & Liu, L. (2023). Zero-Shot Slot Filling with Slot-Prefix Prompting and Attention Relationship Descriptor. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13344-13352. https://doi.org/10.1609/aaai.v37i11.26566","Abstract 					This paper addresses zero-shot slot filling, which tries to build a system that can generalize to unseen slot types without any training data. The key to zero-shot slot-filling is to match the tokens from the utterance with the semantic definition of the slot without training data in the target domain. This paper tackles this problem by devising a scheme to fully leverage pre-trained language models (PLMs). To this end, we propose a new prompting scheme that utilizes both learnable tokens and slot names to guide the model to focus on the relevant text spans for a given slot. Furthermore, we use attention values between tokens to form a feature descriptor for each token, which is motivated by the fact that the attention value in a PLM naturally characterizes various relationships, e.g., syntactic or semantic, between tokens. By further consolidating those features with an additional transformer-based aggregation module, we create a simple-but-effective zero-shot slot filling system that can achieve significantly better performance than the previous methods, as demonstrated by our experimental studies.","https://ojs.aaai.org/index.php/AAAI/article/view/26566/26338"
"26567","Feature-Level Debiased Natural Language Understanding","['Yougang Lyu', 'Piji Li', 'Yechang Yang', 'Maarten de Rijke', 'Pengjie Ren', 'Yukun Zhao', 'Dawei Yin', 'Zhaochun Ren']","['Shandong University', 'Nanjing University of Aeronautics and Astronautics', 'Shandong University', 'University of Amsterdam', 'Shandong University', 'Baidu\nShandong University', 'Baidu', 'Shandong University']","['SNLP: Adversarial Attacks & Robustness', 'SNLP: Sentence-Level Semantics and Textual Inference', 'SNLP: Text Classification']","Lyu, Y., Li, P., Yang, Y., de Rijke, M., Ren, P., Zhao, Y., Yin, D., & Ren, Z. (2023). Feature-Level Debiased Natural Language Understanding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13353-13361. https://doi.org/10.1609/aaai.v37i11.26567","Abstract 					Natural language understanding (NLU) models often rely on dataset biases rather than intended task-relevant features to achieve high performance on specific datasets. As a result, these models perform poorly on datasets outside the training distribution. Some recent studies address this issue by reducing the weights of biased samples during the training process. However, these methods still encode biased latent features in representations and neglect the dynamic nature of bias, which hinders model prediction. We propose an NLU debiasing method, named debiasing contrastive learning (DCT), to simultaneously alleviate the above problems based on contrastive learning. We devise a debiasing, positive sampling strategy to mitigate biased latent features by selecting the least similar biased positive samples. We also propose a dynamic negative sampling strategy to capture the dynamic influence of biases by employing a bias-only model to dynamically select the most similar biased negative samples. We conduct experiments on three NLU benchmark datasets. Experimental results show that DCT outperforms state-of-the-art baselines on out-of-distribution datasets while maintaining in-distribution performance. We also verify that DCT can reduce biased latent features from the model's representation.","https://ojs.aaai.org/index.php/AAAI/article/view/26567/26339"
"26568","Graph Component Contrastive Learning for Concept Relatedness Estimation","['Yueen Ma', 'Zixing Song', 'Xuming Hu', 'Jingjing Li', 'Yifei Zhang', 'Irwin King']","['The Chinese University of Hong Kong', 'The Chinese University of Hong Kong', 'Tsinghua University', 'The Chinese University of Hong Kong', 'The Chinese University of Hong Kong', 'The Chinese University of Hong Kong']","['SNLP: Text Classification', 'SNLP: Sentence-Level Semantics and Textual Inference']","Ma, Y., Song, Z., Hu, X., Li, J., Zhang, Y., & King, I. (2023). Graph Component Contrastive Learning for Concept Relatedness Estimation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13362-13370. https://doi.org/10.1609/aaai.v37i11.26568","Abstract 					Concept relatedness estimation (CRE) aims to determine whether two given concepts are related. Existing methods only consider the pairwise relationship between concepts, while overlooking the higher-order relationship that could be encoded in a concept-level graph structure. We discover that this underlying graph satisfies a set of intrinsic properties of CRE, including reflexivity, commutativity, and transitivity. In this paper, we formalize the CRE properties and introduce a graph structure named ConcreteGraph. To address the data scarcity issue in CRE, we introduce a novel data augmentation approach to sample new concept pairs from the graph. As it is intractable for data augmentation to fully capture the structural information of the ConcreteGraph due to a large amount of potential concept pairs, we further introduce a novel Graph Component Contrastive Learning framework to implicitly learn the complete structure of the ConcreteGraph. Empirical results on three datasets show significant improvement over the state-of-the-art model. Detailed ablation studies demonstrate that our proposed approach can effectively capture the high-order relationship among concepts.","https://ojs.aaai.org/index.php/AAAI/article/view/26568/26340"
"26569","HybridPrompt: Bridging Language Models and Human Priors in Prompt Tuning for Visual Question Answering","['Zhiyuan Ma', 'Zhihuan Yu', 'Jianjun Li', 'Guohui Li']","['School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China', 'School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China', 'School of Computer Science and Technology, Huazhong University of Science and Technology, Wuhan, China', 'School of Software Engineering, Huazhong University of Science and Technology, Wuhan, China']","['SNLP: Question Answering']","Ma, Z., Yu, Z., Li, J., & Li, G. (2023). HybridPrompt: Bridging Language Models and Human Priors in Prompt Tuning for Visual Question Answering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13371-13379. https://doi.org/10.1609/aaai.v37i11.26569","Abstract 					Visual Question Answering (VQA) aims to answer the natural language question about a given image by understanding multimodal content. However, the answer quality of most existing visual-language pre-training (VLP) methods is still limited, mainly due to: (1) Incompatibility. Upstream pre-training tasks are generally incompatible with downstream question answering tasks, which makes the knowledge from the language model not well transferable to downstream tasks, and greatly limits their performance in few-shot scenarios; (2) Under-fitting. They generally do not integrate human priors to compensate for universal knowledge from language models, so as to fit the challenging VQA problem and generate reliable answers. To address these issues, we propose HybridPrompt, a cloze- and verify-style hybrid prompt framework with bridging language models and human priors in prompt tuning for VQA. Specifically, we first modify the input questions into the cloze-style prompts to narrow the gap between upstream pre-training tasks and downstream VQA task, which ensures that the universal knowledge in the language model can be better transferred to subsequent human prior-guided prompt tuning. Then, we imitate the cognitive process of human brain to introduce topic and sample related priors to construct a dynamic learnable prompt template for human prior-guided prompt learning. Finally, we add fixed-length learnable free-parameters to further enhance the generalizability and scalability of prompt learning in the VQA model. Experimental results verify the effectiveness of HybridPrompt, showing that it achieves competitive performance against previous methods on widely-used VQAv2 dataset and obtains new state-of-the-art results. Our code is released at: https://github.com/zhizhi111/hybrid.","https://ojs.aaai.org/index.php/AAAI/article/view/26569/26341"
"26570","Inferential Knowledge-Enhanced Integrated Reasoning for Video Question Answering","['Jianguo Mao', 'Wenbin Jiang', 'Hong Liu', 'Xiangdong Wang', 'Yajuan Lyu']","['University of Chinese Academy of Sciences\nBeijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences', 'Baidu Inc.', 'Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences', 'Beijing Key Laboratory of Mobile Computing and Pervasive Device, Institute of Computing Technology, Chinese Academy of Sciences', 'Baidu Inc.']","['SNLP: Question Answering']","Mao, J., Jiang, W., Liu, H., Wang, X., & Lyu, Y. (2023). Inferential Knowledge-Enhanced Integrated Reasoning for Video Question Answering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13380-13388. https://doi.org/10.1609/aaai.v37i11.26570","Abstract 					Recently, video question answering has attracted growing attention. It involves answering a question based on a fine-grained understanding of video multi-modal information. Most existing methods have successfully explored the deep understanding of visual modality. We argue that a deep understanding of linguistic modality is also essential for answer reasoning, especially for videos that contain character dialogues. To this end, we propose an Inferential Knowledge-Enhanced Integrated Reasoning method. Our method consists of two main components: 1) an Inferential Knowledge Reasoner to generate inferential knowledge for linguistic modality inputs that reveals deeper semantics, including the implicit causes, effects, mental states, etc. 2) an Integrated Reasoning Mechanism to enhance video content understanding and answer reasoning by leveraging the generated inferential knowledge. Experimental results show that our method achieves significant improvement on two mainstream datasets. The ablation study further demonstrates the effectiveness of each component of our approach.","https://ojs.aaai.org/index.php/AAAI/article/view/26570/26342"
"26571","AUC Maximization for Low-Resource Named Entity Recognition","['Ngoc Dang Nguyen', 'Wei Tan', 'Lan Du', 'Wray Buntine', 'RIchard Beare', 'Changyou Chen']","['Monash University', 'Monash University', 'Monash University', 'VinUniversity', 'Monash University', 'University at Buffalo']","['SNLP: Syntax -- Tagging', 'Chunking & Parsing', 'SNLP: Learning & Optimization for SNLP']","Nguyen, N. D., Tan, W., Du, L., Buntine, W., Beare, R., & Chen, C. (2023). AUC Maximization for Low-Resource Named Entity Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13389-13399. https://doi.org/10.1609/aaai.v37i11.26571","Abstract 					Current work in named entity recognition (NER) uses either cross entropy (CE) or conditional random fields (CRF) as the objective/loss functions to optimize the underlying NER model. Both of these traditional objective functions for the NER problem generally produce adequate performance when the data distribution is balanced and there are sufficient annotated training examples. But since NER is inherently an imbalanced tagging problem, the model performance under the low-resource settings could suffer using these standard objective functions. Based on  recent advances in area under the ROC curve (AUC) maximization, we propose to optimize the NER model by maximizing the AUC score. We give evidence that by simply combining two binary-classifiers that maximize the AUC score, significant performance improvement over traditional loss functions is achieved under low-resource NER settings. We also conduct extensive experiments to demonstrate the advantages of our method under the low-resource and highly-imbalanced data distribution settings. To the best of our knowledge, this is the first work that brings AUC maximization to the NER setting. Furthermore, we show that our method is agnostic to different types of NER embeddings, models and domains. The code of this work is available at https://github.com/dngu0061/NER-AUC-2T.","https://ojs.aaai.org/index.php/AAAI/article/view/26571/26343"
"26572","Unveiling the Black Box of PLMs with Semantic Anchors: Towards Interpretable Neural Semantic Parsing","['Lunyiu Nie', 'Jiuding Sun', 'Yanlin Wang', 'Lun Du', 'Shi Han', 'Dongmei Zhang', 'Lei Hou', 'Juanzi Li', 'Jidong Zhai']","['Tsinghua University', 'Tsinghua University', 'Sun Yat-sen University', 'Microsoft Research', 'Microsoft Research', 'Microsoft Research Asia', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University']","['SNLP: Lexical & Frame Semantics', 'Semantic Parsing', 'SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Language Models', 'SNLP: Question Answering']","Nie, L., Sun, J., Wang, Y., Du, L., Han, S., Zhang, D., Hou, L., Li, J., & Zhai, J. (2023). Unveiling the Black Box of PLMs with Semantic Anchors: Towards Interpretable Neural Semantic Parsing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13400-13408. https://doi.org/10.1609/aaai.v37i11.26572","Abstract 					The recent prevalence of pretrained language models (PLMs) has dramatically shifted the paradigm of semantic parsing, where the mapping from natural language utterances to structured logical forms is now formulated as a Seq2Seq task. Despite the promising performance, previous PLM-based approaches often suffer from hallucination problems due to their negligence of the structural information contained in the sentence, which essentially constitutes the key semantics of the logical forms. Furthermore, most works treat PLM as a black box in which the generation process of the target logical form is hidden beneath the decoder modules, which greatly hinders the model's intrinsic interpretability. To address these two issues, we propose to incorporate the current PLMs with a hierarchical decoder network. By taking the first-principle structures as the semantic anchors, we propose two novel intermediate supervision tasks, namely Semantic Anchor Extraction and Semantic Anchor Alignment, for training the hierarchical decoders and probing the model intermediate representations in a self-adaptive manner alongside the fine-tuning process. We conduct intensive experiments on several semantic parsing benchmarks and demonstrate that our approach can consistently outperform the baselines. More importantly, by analyzing the intermediate representations of the hierarchical decoders, our approach also makes a huge step toward the interpretability of PLMs in the domain of semantic parsing.","https://ojs.aaai.org/index.php/AAAI/article/view/26572/26344"
"26573","Towards a Holistic Understanding of Mathematical Questions with Contrastive Pre-training","['Yuting Ning', 'Zhenya Huang', 'Xin Lin', 'Enhong Chen', 'Shiwei Tong', 'Zheng Gong', 'Shijin Wang']","['University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'University of Science and Technology of China\nState Key Laboratory of Cognitive Intelligence', 'State Key Laboratory of Cognitive Intelligence\niFLYTEK AI Research (Central China), iFLYTEK Co., Ltd.']","['SNLP: Applications', 'APP: Education']","Ning, Y., Huang, Z., Lin, X., Chen, E., Tong, S., Gong, Z., & Wang, S. (2023). Towards a Holistic Understanding of Mathematical Questions with Contrastive Pre-training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13409-13418. https://doi.org/10.1609/aaai.v37i11.26573","Abstract 					Understanding mathematical questions effectively is a crucial task, which can benefit many applications, such as difficulty estimation. Researchers have drawn much attention to designing pre-training models for question representations due to the scarcity of human annotations (e.g., labeling difficulty). However, unlike general free-format texts (e.g., user comments), mathematical questions are generally designed with explicit purposes and mathematical logic, and usually consist of more complex content, such as formulas, and related mathematical knowledge (e.g., Function). Therefore, the problem of holistically representing mathematical questions remains underexplored. To this end, in this paper, we propose a novel contrastive pre-training approach for mathematical question representations, namely QuesCo, which attempts to bring questions with more similar purposes closer. Specifically, we first design two-level question augmentations, including content-level and structure-level, which generate literally diverse question pairs with similar purposes. Then, to fully exploit hierarchical information of knowledge concepts, we propose a knowledge hierarchy-aware rank strategy (KHAR), which ranks the similarities between questions in a fine-grained manner. Next, we adopt a ranking contrastive learning task to optimize our model based on the augmented and ranked questions. We conduct extensive experiments on two real-world mathematical datasets. The experimental results demonstrate the effectiveness of our model.","https://ojs.aaai.org/index.php/AAAI/article/view/26573/26345"
"26574","Improving the Cross-Lingual Generalisation in Visual Question Answering","['Farhad Nooralahzadeh', 'Rico Sennrich']","['University of Zurich', 'University of Zurich']","['SNLP: Question Answering', 'CV: Language and Vision', 'SNLP: Language Grounding', 'SNLP: Machine Translation & Multilinguality']","Nooralahzadeh, F., & Sennrich, R. (2023). Improving the Cross-Lingual Generalisation in Visual Question Answering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13419-13427. https://doi.org/10.1609/aaai.v37i11.26574","Abstract 					While several benefits were realized for multilingual vision-language pretrained models, recent benchmarks across various tasks and languages showed poor cross-lingual generalisation when multilingually pre-trained vision-language models are applied to non-English data, with a large gap between (supervised) English performance and (zero-shot) cross-lingual transfer. In this work, we explore the poor performance of these models on a zero-shot cross-lingual visual question answering (VQA) task, where models are fine-tuned on English visual-question data and evaluated on 7 typologically diverse languages. We improve cross-lingual transfer with three strategies: (1) we introduce a linguistic prior objective to augment the cross-entropy loss with a similarity-based loss to guide the model during training, (2) we learn a task-specific subnetwork that improves cross-lingual generalisation and reduces variance without model modification, (3) we augment training examples using synthetic code-mixing to promote alignment of embeddings between source and target languages. Our experiments on xGQA using the pretrained multilingual multimodal transformers UC2 and M3P demonstrates the consistent effectiveness of the proposed fine-tuning strategy for 7 languages, outperforming existing transfer methods with sparse models.","https://ojs.aaai.org/index.php/AAAI/article/view/26574/26346"
"26575","RWEN-TTS: Relation-Aware Word Encoding Network for Natural Text-to-Speech Synthesis","['Shinhyeok Oh', 'HyeongRae Noh', 'Yoonseok Hong', 'Insoo Oh']","['Netmarble AI Center', 'Netmarble AI Center', 'Netmarble AI Center', 'Netmarble AI Center']","['SNLP: Speech and Multimodality', 'SNLP: Generation', 'SNLP: Language Models', 'SNLP: Sentence-Level Semantics and Textual Inference', 'SNLP: Syntax -- Tagging', 'Chunking & Parsing']","Oh, S., Noh, H., Hong, Y., & Oh, I. (2023). RWEN-TTS: Relation-Aware Word Encoding Network for Natural Text-to-Speech Synthesis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13428-13436. https://doi.org/10.1609/aaai.v37i11.26575","Abstract 					With the advent of deep learning, a huge number of text-to-speech (TTS) models which produce human-like speech have emerged. Recently, by introducing syntactic and semantic information w.r.t the input text, various approaches have been proposed to enrich the naturalness and expressiveness of TTS models. Although these strategies showed impressive results, they still have some limitations in utilizing language information. First, most approaches only use graph networks to utilize syntactic and semantic information without considering linguistic features. Second, most previous works do not explicitly consider adjacent words when encoding syntactic and semantic information, even though it is obvious that adjacent words are usually meaningful when encoding the current word. To address these issues, we propose Relation-aware Word Encoding Network (RWEN), which effectively allows syntactic and semantic information based on two modules (i.e., Semantic-level Relation Encoding and Adjacent Word Relation Encoding). Experimental results show substantial improvements compared to previous works.","https://ojs.aaai.org/index.php/AAAI/article/view/26575/26347"
"26576","Hierarchical Event Grounding","['Jiefu Ou', 'Adithya Pratapa', 'Rishubh Gupta', 'Teruko Mitamura']","['Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University']","['SNLP: Information Extraction']","Ou, J., Pratapa, A., Gupta, R., & Mitamura, T. (2023). Hierarchical Event Grounding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13437-13445. https://doi.org/10.1609/aaai.v37i11.26576","Abstract 					Event grounding aims at linking mention references in text corpora to events from a knowledge base (KB). Previous work on this task focused primarily on linking to a single KB event, thereby overlooking the hierarchical aspects of events. Events in documents are typically described at various levels of spatio-temporal granularity. These hierarchical relations are utilized in downstream tasks of narrative understanding and schema construction. In this work, we present an extension to the event grounding task that requires tackling hierarchical event structures from the KB. Our proposed task involves linking a mention reference to a set of event labels from a subevent hierarchy in the KB. We propose a retrieval methodology that leverages event hierarchy through an auxiliary hierarchical loss. On an automatically created multilingual dataset from Wikipedia and Wikidata, our experiments demonstrate the effectiveness of the hierarchical loss against retrieve and re-rank baselines. Furthermore, we demonstrate the systems' ability to aid hierarchical discovery among unseen events. Code is available at https://github.com/JefferyO/Hierarchical-Event-Grounding","https://ojs.aaai.org/index.php/AAAI/article/view/26576/26348"
"26577","RINK: Reader-Inherited Evidence Reranker for Table-and-Text Open Domain Question Answering","['Eunhwan Park', 'Sung-Min Lee', 'Dearyong Seo', 'Seonhoon Kim', 'Inho Kang', 'Seung-Hoon Na']","['Jeonbuk National University', 'Jeonbuk National University', 'Naver Corporation', 'Coupang', 'Naver Corporation', 'Jeonbuk National University']","['SNLP: Question Answering', 'SNLP: Applications']","Park, E., Lee, S.-M., Seo, D., Kim, S., Kang, I., & Na, S.-H. (2023). RINK: Reader-Inherited Evidence Reranker for Table-and-Text Open Domain Question Answering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13446-13456. https://doi.org/10.1609/aaai.v37i11.26577","Abstract 					Most approaches used in open-domain question answering on hybrid data that comprises both tabular-and-textual contents are based on a Retrieval-Reader pipeline in which the retrieval module finds relevant “heterogenous” evidence for a given question and the reader module generates an answer from the retrieved evidence. In this paper, we present a Retriever-Reranker-Reader framework by newly proposing a Reader-INherited evidence reranKer (RINK) where a reranker module is designed by finetuning the reader’s neural architecture based on a simple prompting method. Our underlying assumption of reusing the reader’s module for the reranker is that the reader’s ability to generating an answer from evidence contains the knowledge required for the reranking, because the reranker needs to “read” in-depth a question and evidences more carefully and elaborately than a baseline retriever. Furthermore, we present a simple and effective pretraining method by extensively deploying the commonly used data augmentation methods of cell corruption and cell reordering based on the pretraining tasks - tabular-and-textual entailment and cross-modal masked language modeling. Experimental results on OTT-QA, a large-scale table-and-text open-domain question answering dataset, show that the proposed RINK armed with our pretraining procedure makes improvements over the baseline reranking method and leads to state-of-the-art performance.","https://ojs.aaai.org/index.php/AAAI/article/view/26577/26349"
"26578","Relation-Aware Language-Graph Transformer for Question Answering","['Jinyoung Park', 'Hyeong Kyu Choi', 'Juyeon Ko', 'Hyeonjin Park', 'Ji-Hoon Kim', 'Jisu Jeong', 'Kyungmin Kim', 'Hyunwoo Kim']","['Korea University', 'Korea University', 'Korea University', 'NAVER', 'NAVER, NAVER Cloud, NAVER AI Lab', 'NAVER\nNAVER Cloud\nNAVER AI Lab', 'NAVER\nNAVER Cloud\nNAVER AI Lab', 'Korea University']","['SNLP: Question Answering', 'KRR: Common-Sense Reasoning', 'ML: Graph-based Machine Learning']","Park, J., Choi, H. K., Ko, J., Park, H., Kim, J.-H., Jeong, J., Kim, K., & Kim, H. (2023). Relation-Aware Language-Graph Transformer for Question Answering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13457-13464. https://doi.org/10.1609/aaai.v37i11.26578","Abstract 					Question Answering (QA) is a task that entails reasoning over natural language contexts, and many relevant works augment language models (LMs) with graph neural networks (GNNs) to encode the Knowledge Graph (KG) information. However, most existing GNN-based modules for QA do not take advantage of rich relational information of KGs and depend on limited information interaction between the LM and the KG. To address these issues, we propose Question Answering Transformer (QAT), which is designed to jointly reason over language and graphs with respect to entity relations in a unified manner. Specifically, QAT constructs Meta-Path tokens, which learn relation-centric embeddings based on diverse structural and semantic relations. Then, our Relation-Aware Self-Attention module comprehensively integrates different modalities via the Cross-Modal Relative Position Bias, which guides information exchange between relevant entities of different modalities. We validate the effectiveness of QAT on commonsense question answering datasets like CommonsenseQA and OpenBookQA, and on a medical question answering dataset, MedQA-USMLE. On all the datasets, our method achieves state-of-the-art performance. Our code is available at http://github.com/mlvlab/QAT.","https://ojs.aaai.org/index.php/AAAI/article/view/26578/26350"
"26579","Multi-Mask Label Mapping for Prompt-Based Learning","['Jirui Qi', 'Richong Zhang', 'Jaein Kim', 'Junfan Chen', 'Wenyi Qin', 'Yongyi Mao']","['Beihang University', 'Beihang University', 'Beihang University', 'Beihang University', 'Beihang University', 'University of Ottawa']","['SNLP: Text Classification', 'SNLP: Applications', 'SNLP: Language Models']","Qi, J., Zhang, R., Kim, J., Chen, J., Qin, W., & Mao, Y. (2023). Multi-Mask Label Mapping for Prompt-Based Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13465-13473. https://doi.org/10.1609/aaai.v37i11.26579","Abstract 					Prompt-based Learning has shown significant success in few-shot classification. The mainstream approach is to concatenate a template for the input text to transform the classification task into a cloze-type task where label mapping plays an important role in finding the ground-truth labels.  While current label mapping methods only use the contexts in one single input, it could be crucial if wrong information is contained in the text. Specifically, it is proved in recent work that even the large language models like BERT/RoBERTa make classification decisions heavily dependent on a specific keyword regardless of the task or the context. Such a word is referred to as a lexical cue and if a misleading lexical cue is included in the instance it will lead the model to make a wrong prediction. We propose a multi-mask prompt-based approach with Multi-Mask Label Mapping (MMLM) to reduce the impact of misleading lexical cues by allowing the model to exploit multiple lexical cues. To satisfy the conditions of few-shot learning, an instance augmentation approach for the cloze-type model is proposed and the misleading cues are gradually excluded through training. We demonstrate the effectiveness of MMLM by both theoretical analysis and empirical studies, and show that MMLM outperforms other existing label mapping approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/26579/26351"
"26580","SSMI: Semantic Similarity and Mutual Information Maximization Based Enhancement for Chinese NER","['Pengnian Qi', 'Biao Qin']","['Renmin University of China', 'Renmin University of China']","['SNLP: Syntax -- Tagging', 'Chunking & Parsing', 'SNLP: Text Classification']","Qi, P., & Qin, B. (2023). SSMI: Semantic Similarity and Mutual Information Maximization Based Enhancement for Chinese NER. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13474-13482. https://doi.org/10.1609/aaai.v37i11.26580","Abstract 					The Chinese NER task consists of two steps, first determining entity boundaries and then labeling them. Some previous work incorporating related words from pre-trained vocabulary into character-based models has been demonstrated to be effective. However, the number of words that characters can match in the vocabulary is large, and their meanings vary widely. It is unreasonable to concatenate all the matched words into the character's representation without making semantic distinctions. This is because words with different semantics also have distinct vectors by the distributed representation. Moreover, mutual information maximization (MIM) provides a unified way to characterize the correction between different granularity of embeddings, we find it can be used to enhance the features in our task. Consequently, this paper introduces a novel Chinese NER model named SSMI based on semantic similarity and MIM. We first match all the potential word boundaries of the input characters from the pre-trained vocabulary and employ BERT to segment the input sentence to get the segmentation containing these characters. After computing their cosine similarity, we obtain the word boundary with the highest similarity and the word group with similarity score larger than a specific threshold. Then, we concatenate the most relevant word boundaries with character vectors. We further calculate the mutual information maximization of group, character and sentence, respectively. Finally, we feed the result from the above steps to our novel network. The results on four Chinese public NER datasets show that our SSMI achieves state-of-the-art performance.","https://ojs.aaai.org/index.php/AAAI/article/view/26580/26352"
"26581","Towards Complex Scenarios: Building End-to-End Task-Oriented Dialogue System across Multiple Knowledge Bases","['Libo Qin', 'Zhouyang Li', 'Qiying Yu', 'Lehan Wang', 'Wanxiang Che']","['School of Computer Science and Engineering, Central South University', 'Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology', 'Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology', 'Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology', 'Research Center for Social Computing and Information Retrieval, Harbin Institute of Technology']","['SNLP: Conversational AI/Dialogue Systems']","Qin, L., Li, Z., Yu, Q., Wang, L., & Che, W. (2023). Towards Complex Scenarios: Building End-to-End Task-Oriented Dialogue System across Multiple Knowledge Bases. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13483-13491. https://doi.org/10.1609/aaai.v37i11.26581","Abstract 					With the success of the sequence-to-sequence model, end-to-end task-oriented dialogue systems (EToDs) have obtained remarkable progress. However, most existing EToDs are limited to single KB settings where dialogues can be supported by a single KB, which is still far from satisfying the requirements of some complex applications (multi-KBs setting). In this work, we first empirically show that the existing single-KB EToDs fail to work on multi-KB settings that require models to reason across various KBs. To solve this issue, we take the first step to consider the multi-KBs scenario in EToDs and introduce a KB-over-KB Heterogeneous Graph Attention Network (KoK-HAN) to facilitate model to reason over multiple KBs. The core module is a triple-connection graph interaction layer that can model different granularity levels of interaction information across different KBs (i.e., intra-KB connection, inter-KB connection and dialogue-KB connection). Experimental results confirm the superiority of our model for multiple KBs reasoning.","https://ojs.aaai.org/index.php/AAAI/article/view/26581/26353"
"26582","BERT-ERC: Fine-Tuning BERT Is Enough for Emotion Recognition in Conversation","['Xiangyu Qin', 'Zhiyu Wu', 'Tingting Zhang', 'Yanran Li', 'Jian Luan', 'Bin Wang', 'Li Wang', 'Jinshi Cui']","['School of Intelligence Science and Technology, Peking University\nXiaomi AI Lab', 'School of Intelligence Science and Technology, Peking University', 'School of Intelligence Science and Technology, Peking University', 'Xiaomi AI Lab', 'Xiaomi AI Lab', 'Xiaomi AI Lab', 'School of Psychological and Cognitive Sciences and Beijing Key Laboratory of Behavior and Mental Health, Peking University', 'School of Intelligence Science and Technology, Peking University']","['SNLP: Sentiment Analysis and Stylistic Analysis', 'SNLP: Conversational AI/Dialogue Systems', 'SNLP: Language Models', 'SNLP: Text Classification']","Qin, X., Wu, Z., Zhang, T., Li, Y., Luan, J., Wang, B., Wang, L., & Cui, J. (2023). BERT-ERC: Fine-Tuning BERT Is Enough for Emotion Recognition in Conversation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13492-13500. https://doi.org/10.1609/aaai.v37i11.26582","Abstract 					Previous works on emotion recognition in conversation (ERC) follow a two-step paradigm, which can be summarized as first producing context-independent features via fine-tuning pretrained language models (PLMs) and then analyzing contextual information and dialogue structure information among the extracted features. However, we discover that this paradigm has several limitations. Accordingly, we propose a novel paradigm, i.e., exploring contextual information and dialogue structure information in the fine-tuning step, and adapting the PLM to the ERC task in terms of input text, classification structure, and training strategy. Furthermore, we develop our model BERT-ERC according to the proposed paradigm, which improves ERC performance in three aspects, namely suggestive text, fine-grained classification module, and two-stage training. Compared to existing methods, BERT-ERC achieves substantial improvement on four datasets, indicating its effectiveness and generalization capability. Besides, we also set up the limited resources scenario and the online prediction scenario to approximate real-world scenarios. Extensive experiments demonstrate that the proposed paradigm significantly outperforms the previous one and can be adapted to various scenes.","https://ojs.aaai.org/index.php/AAAI/article/view/26582/26354"
"26583","Distantly-Supervised Named Entity Recognition with Adaptive Teacher Learning and Fine-Grained Student Ensemble","['Xiaoye Qu', 'Jun Zeng', 'Daizong Liu', 'Zhefeng Wang', 'Baoxing Huai', 'Pan Zhou']","['Huawei Cloud', 'Huazhong University of Science and Technology', 'Peking University', 'Huawei Cloud', 'Huawei Cloud', 'Huazhong University of Science and Technology']","['SNLP: Information Extraction']","Qu, X., Zeng, J., Liu, D., Wang, Z., Huai, B., & Zhou, P. (2023). Distantly-Supervised Named Entity Recognition with Adaptive Teacher Learning and Fine-Grained Student Ensemble. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13501-13509. https://doi.org/10.1609/aaai.v37i11.26583","Abstract 					Distantly-Supervised Named Entity Recognition (DS-NER) effectively alleviates the data scarcity problem in NER by automatically generating training samples. Unfortunately, the distant supervision may induce noisy labels, thus undermining the robustness of the learned models and restricting the practical application.  To relieve this problem, recent works adopt self-training teacher-student frameworks to gradually refine the training labels and improve the generalization ability of NER models. However, we argue that the performance of the current self-training frameworks for DS-NER is severely underestimated by their plain designs, including both inadequate student learning and coarse-grained teacher updating. Therefore, in this paper, we make the first attempt to alleviate these issues by proposing:   (1) adaptive teacher learning comprised of joint training of two teacher-student networks and considering both consistent and inconsistent predictions between two teachers, thus promoting comprehensive student learning.  (2) fine-grained student ensemble that updates each fragment of the teacher model with a temporal moving average of the corresponding fragment of the student, which enhances consistent predictions on each model fragment against noise.  To verify the effectiveness of our proposed method, we conduct experiments on four DS-NER datasets. The experimental results demonstrate that our method significantly surpasses previous SOTA methods. The code is available at https://github.com/zenhjunpro/ATSEN.","https://ojs.aaai.org/index.php/AAAI/article/view/26583/26355"
"26584","Unsupervised Cross-Domain Rumor Detection with Contrastive Learning and Cross-Attention","['Hongyan Ran', 'Caiyan Jia']","['School of Computer and Information Technology & Beijing Key Lab of Traffic Data Analysis and Mining', 'School of Computer and Information Technology & Beijing Key Lab of Traffic Data Analysis and Mining,']","['SNLP: Text Mining', 'SNLP: Information Extraction', 'SNLP: Language Models', 'SNLP: Text Classification']","Ran, H., & Jia, C. (2023). Unsupervised Cross-Domain Rumor Detection with Contrastive Learning and Cross-Attention. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13510-13518. https://doi.org/10.1609/aaai.v37i11.26584","Abstract 					Massive rumors usually appear along with breaking news or trending topics, seriously hindering the truth. Existing rumor detection methods are mostly focused on the same domain, thus have poor performance in cross-domain scenarios due to domain shift. In this work, we propose an end-to-end instance-wise and prototype-wise contrastive learning model with cross-attention mechanism for cross-domain rumor detection. The model not only performs cross-domain feature alignment, but also enforces target samples to align with the corresponding prototypes of a given source domain. Since target labels in a target domain are unavailable, we use a clustering-based approach with carefully initialized centers by a batch of source domain samples to produce pseudo labels. Moreover, we use a cross-attention mechanism on a pair of source data and target data with the same labels to learn domain-invariant representations. Because the samples in a domain pair tend to express similar semantic patterns especially on the people’s attitudes (e.g., supporting or denying) towards the same category of rumors, the discrepancy between a pair of source domain and target domain will be decreased. We conduct experiments on four groups of cross-domain datasets and show that our proposed model achieves state-of-the-art performance.","https://ojs.aaai.org/index.php/AAAI/article/view/26584/26356"
"26585","Prompting Neural Machine Translation with Translation Memories","['Abudurexiti Reheman', 'Tao Zhou', 'Yingfeng Luo', 'Di Yang', 'Tong Xiao', 'Jingbo Zhu']","['Northeastern University, Shenyang, China', 'Northeastern University, Shenyang, China', 'Northeastern University, Shenyang, China', 'NiuTrans Reasearch, Shenyang, China', 'Northeastern University, Shenyang, China\nNiuTrans Reasearch, Shenyang, China', 'Northeastern University, Shenyang, China\nNiuTrans Reasearch, Shenyang, China']","['SNLP: Machine Translation & Multilinguality', 'SNLP: Generation', 'SNLP: Other Foundations of Speech & Natural Language Processing']","Reheman, A., Zhou, T., Luo, Y., Yang, D., Xiao, T., & Zhu, J. (2023). Prompting Neural Machine Translation with Translation Memories. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13519-13527. https://doi.org/10.1609/aaai.v37i11.26585","Abstract 					Improving machine translation (MT) systems with translation memories (TMs) is of great interest to practitioners in the MT community. However, previous approaches require either a significant update of the model architecture and/or additional training efforts to make the models well-behaved when TMs are taken as additional input. In this paper, we present a simple but effective method to introduce TMs into neural machine translation (NMT) systems. Specifically, we treat TMs as prompts to the NMT model at test time, but leave the training process unchanged. The result is a slight update of an existing NMT system, which can be implemented in a few hours by anyone who is familiar with NMT. Experimental results on several datasets demonstrate that our system significantly outperforms strong baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/26585/26357"
"26586","Improving Interpretability via Explicit Word Interaction Graph Layer","['Arshdeep Sekhon', 'Hanjie Chen', 'Aman Shrivastava', 'Zhe Wang', 'Yangfeng Ji', 'Yanjun Qi']","['University of Virginia', 'University of Virginia', 'University of Virginia', 'University of Virginia', 'University of Virginia', 'University of Virginia']","['SNLP: Interpretability & Analysis of NLP Models', 'ML: Graph-based Machine Learning']","Sekhon, A., Chen, H., Shrivastava, A., Wang, Z., Ji, Y., & Qi, Y. (2023). Improving Interpretability via Explicit Word Interaction Graph Layer. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13528-13537. https://doi.org/10.1609/aaai.v37i11.26586","Abstract 					Recent NLP literature has seen growing interest in improving model interpretability. Along this direction, we propose a trainable neural network layer that learns a global interaction graph between words and then selects more informative words using the learned word interactions. Our layer, we call WIGRAPH, can plug into any neural network-based NLP text classifiers right after its word embedding layer. Across multiple SOTA NLP models and various NLP datasets, we demonstrate that adding the WIGRAPH layer substantially improves NLP models' interpretability and enhances models' prediction performance at the same time.","https://ojs.aaai.org/index.php/AAAI/article/view/26586/26358"
"26587","Rephrasing the Reference for Non-autoregressive Machine Translation","['Chenze Shao', 'Jinchao Zhang', 'Jie Zhou', 'Yang Feng']","['Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Tencent', 'Tencent', 'Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences']","['SNLP: Machine Translation & Multilinguality', 'SNLP: Generation']","Shao, C., Zhang, J., Zhou, J., & Feng, Y. (2023). Rephrasing the Reference for Non-autoregressive Machine Translation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13538-13546. https://doi.org/10.1609/aaai.v37i11.26587","Abstract 					Non-autoregressive neural machine translation (NAT) models suffer from the multi-modality problem that there may exist multiple possible translations of a source sentence, so the reference sentence may be inappropriate for the training when the NAT output is closer to other translations. In response to this problem, we introduce a rephraser to provide a better training target for NAT by rephrasing the reference sentence according to the NAT output. As we train NAT based on the rephraser output rather than the reference sentence, the rephraser output should fit well with the NAT output and not deviate too far from the reference, which can be quantified as reward functions and optimized by reinforcement learning. Experiments on major WMT benchmarks and NAT baselines show that our approach consistently improves the translation quality of NAT. Specifically, our best variant achieves comparable performance to the autoregressive Transformer, while being 14.7 times more efficient in inference.","https://ojs.aaai.org/index.php/AAAI/article/view/26587/26359"
"26588","Drop Clause: Enhancing Performance, Robustness and Pattern Recognition Capabilities of the Tsetlin Machine","['Jivitesh Sharma', 'Rohan Yadav', 'Ole-Christoffer Granmo', 'Lei Jiao']","['University of Agder', 'University of Agder', 'University of Agder', 'University of Agder']","['SNLP: Interpretability & Analysis of NLP Models', 'KRR: Logic Programming', 'ML: Adversarial Learning & Robustness', 'ML: Distributed Machine Learning & Federated Learning', 'ML: Ensemble Methods', 'ML: Optimization', 'SNLP: Sentence-Level Semantics and Textual Inference']","Sharma, J., Yadav, R., Granmo, O.-C., & Jiao, L. (2023). Drop Clause: Enhancing Performance, Robustness and Pattern Recognition Capabilities of the Tsetlin Machine. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13547-13555. https://doi.org/10.1609/aaai.v37i11.26588","Abstract 					Logic-based machine learning has the crucial advantage of transparency. However, despite significant recent progress, further research is needed to close the accuracy gap between logic-based architectures and deep neural network ones. This paper introduces a novel variant of the Tsetlin machine (TM) that randomly drops clauses, the logical learning element of TMs. In effect, TM with Drop Clause ignores a random selection of the clauses in each epoch, selected according to a predefined probability. In this way, the TM learning phase becomes more diverse. To explore the effects that Drop Clause has on accuracy, training time and robustness, we conduct extensive experiments on nine benchmark datasets in natural language processing (IMDb, R8, R52, MR, and TREC) and image classification (MNIST, Fashion MNIST, CIFAR-10, and CIFAR-100). Our proposed model outperforms baseline machine learning algorithms by a wide margin and achieves competitive performance compared with recent deep learning models, such as BERT-Large and AlexNet-DFA. In brief, we observe up to +10% increase in accuracy and 2x to 4x faster learning than for the standard TM. We visualize the patterns learnt by Drop Clause TM in the form of heatmaps and show evidence of the ability of drop clause to learn more unique and discriminative patterns. We finally evaluate how Drop Clause affects learning robustness by introducing corruptions and alterations in the image/language test data, which exposes increased learning robustness.","https://ojs.aaai.org/index.php/AAAI/article/view/26588/26360"
"26589","CoP: Factual Inconsistency Detection by Controlling the Preference","['Shuaijie She', 'Xiang Geng', 'Shujian Huang', 'Jiajun Chen']","['National Key Laboratory for Novel Software Technology, Nanjing University', 'National Key Laboratory for Novel Software Technology, Nanjing University', 'National Key Laboratory for Novel Software Technology, Nanjing University', 'National Key Laboratory for Novel Software Technology, Nanjing University']","['SNLP: Summarization']","She, S., Geng, X., Huang, S., & Chen, J. (2023). CoP: Factual Inconsistency Detection by Controlling the Preference. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13556-13563. https://doi.org/10.1609/aaai.v37i11.26589","Abstract 					Abstractive summarization is the process of generating a summary given a document as input. Although significant progress has been made, the factual inconsistency between the document and the generated summary still limits its practical applications. Previous work found that the probabilities assigned by the generation model reflect its preferences for the generated summary, including the preference for factual consistency, and the preference for the language or knowledge prior as well. To separate the preference for factual consistency, we propose an unsupervised framework named CoP by controlling the preference of the generation model with the help of prompt. More specifically, the framework performs an extra inference step in which a text prompt is introduced as an additional input. In this way, another preference is described by the generation probability of this extra inference process. The difference between the above two preferences, i.e. the difference between the probabilities, could be used as measurements for detecting factual inconsistencies. Interestingly, we found that with the properly designed prompt, our framework could evaluate specific preferences and serve as measurements for fine-grained categories of inconsistency, such as entity-related inconsistency, coreference-related inconsistency, etc. Moreover, our framework could also be extended to the supervised setting to learn better prompt from the labeled data as well. Experiments show that our framework achieves new SOTA results on three factual inconsisency detection tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26589/26361"
"26590","Which Shortcut Solution Do Question Answering Models Prefer to Learn?","['Kazutoshi Shinoda', 'Saku Sugawara', 'Akiko Aizawa']","['The University of Tokyo\nNational Institute of Informatics', 'National Institute of Informatics', 'The University of Tokyo\nNational Institute of Informatics']","['SNLP: Question Answering', 'SNLP: Adversarial Attacks & Robustness', 'SNLP: Bias', 'Fairness', 'Transparency & Privacy', 'SNLP: Interpretability & Analysis of NLP Models']","Shinoda, K., Sugawara, S., & Aizawa, A. (2023). Which Shortcut Solution Do Question Answering Models Prefer to Learn?. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13564-13572. https://doi.org/10.1609/aaai.v37i11.26590","Abstract 					Question answering (QA) models for reading comprehension tend to exploit spurious correlations in training sets and thus learn shortcut solutions rather than the solutions intended by QA datasets. QA models that have learned shortcut solutions can achieve human-level performance in shortcut examples where shortcuts are valid, but these same behaviors degrade generalization potential on anti-shortcut examples where shortcuts are invalid. Various methods have been proposed to mitigate this problem, but they do not fully take the characteristics of shortcuts themselves into account. We assume that the learnability of shortcuts, i.e., how easy it is to learn a shortcut, is useful to mitigate the problem. Thus, we first examine the learnability of the representative shortcuts on extractive and multiple-choice QA datasets. Behavioral tests using biased training sets reveal that shortcuts that exploit answer positions and word-label correlations are preferentially learned for extractive and multiple-choice QA, respectively. We find that the more learnable a shortcut is, the flatter and deeper the loss landscape is around the shortcut solution in the parameter space. We also find that the availability of the preferred shortcuts tends to make the task easier to perform from an information-theoretic viewpoint. Lastly, we experimentally show that the learnability of shortcuts can be utilized to construct an effective QA training set; the more learnable a shortcut is, the smaller the proportion of anti-shortcut examples required to achieve comparable performance on shortcut and anti-shortcut examples. We claim that the learnability of shortcuts should be considered when designing mitigation methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26590/26362"
"26591","Exploring Faithful Rationale for Multi-Hop Fact Verification via Salience-Aware Graph Learning","['Jiasheng Si', 'Yingjie Zhu', 'Deyu Zhou']","['Southeast University', 'Southeast University', 'Southeast University']","['SNLP: Discourse', 'Pragmatics & Argument Mining', 'SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Sentence-Level Semantics and Textual Inference', 'SNLP: Sentiment Analysis and Stylistic Analysis', 'SNLP: Text Classification']","Si, J., Zhu, Y., & Zhou, D. (2023). Exploring Faithful Rationale for Multi-Hop Fact Verification via Salience-Aware Graph Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13573-13581. https://doi.org/10.1609/aaai.v37i11.26591","Abstract 					The opaqueness of the multi-hop fact verification model imposes imperative requirements for explainability. One feasible way is to extract rationales, a subset of inputs, where the performance of prediction drops dramatically when being removed. Though being explainable, most rationale extraction methods for multi-hop fact verification explore the semantic information within each piece of evidence individually, while ignoring the topological information interaction among different pieces of evidence. Intuitively, a faithful rationale bears complementary information being able to extract other rationales through the multi-hop reasoning process. To tackle such disadvantages, we cast explainable multi-hop fact verification as subgraph extraction, which can be solved based on graph convolutional network (GCN) with salience-aware graph learning. In specific, GCN is utilized to incorporate the topological interaction information among multiple pieces of evidence for learning evidence representation. Meanwhile, to alleviate the influence of noisy evidence, the salience-aware graph perturbation is induced into the message passing of GCN. Moreover, the multi-task model with three diagnostic properties of rationale is elaborately designed to improve the quality of an explanation without any explicit annotations. Experimental results on the FEVEROUS benchmark show significant gains over previous state-of-the-art methods for both rationale extraction and fact verification.","https://ojs.aaai.org/index.php/AAAI/article/view/26591/26363"
"26592","A Speaker Turn-Aware Multi-Task Adversarial Network for Joint User Satisfaction Estimation and Sentiment Analysis","['Kaisong Song', 'Yangyang Kang', 'Jiawei Liu', 'Xurui Li', 'Changlong Sun', 'Xiaozhong Liu']","['Alibaba Group\nNortheastern University', 'Alibaba Group', 'Wuhan University', 'Alibaba Group', 'Alibaba Group', 'Worcester Polytechnic Institute']","['SNLP: Sentiment Analysis and Stylistic Analysis', 'SNLP: Text Classification']","Song, K., Kang, Y., Liu, J., Li, X., Sun, C., & Liu, X. (2023). A Speaker Turn-Aware Multi-Task Adversarial Network for Joint User Satisfaction Estimation and Sentiment Analysis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13582-13590. https://doi.org/10.1609/aaai.v37i11.26592","Abstract 					User Satisfaction Estimation is an important task and increasingly being applied in goal-oriented dialogue systems to estimate whether the user is satisfied with the service. It is observed that whether the user’s needs are met often triggers various sentiments, which can be pertinent to the successful estimation of user satisfaction, and vice versa. Thus, User Satisfaction Estimation (USE) and Sentiment Analysis (SA) should be treated as a joint, collaborative effort, considering the strong connections between the sentiment states of speakers and the user satisfaction. Existing joint learning frameworks mainly unify the two highly pertinent tasks over cascade or shared-bottom implementations, however they fail to distinguish task-specific and common features, which will produce sub-optimal utterance representations for downstream tasks. In this paper, we propose a novel Speaker Turn-Aware Multi-Task Adversarial Network (STMAN) for dialogue-level USE and utterance-level SA. Specifically, we first introduce a multi-task adversarial strategy which trains a task discriminator to make utterance representation more task-specific, and then utilize a speaker-turn aware multi-task interaction strategy to extract the common features which are complementary to each task. Extensive experiments conducted on two real-world service dialogue datasets show that our model outperforms several state-of-the-art methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26592/26364"
"26593","A Latent-Variable Model for Intrinsic Probing","['Karolina Stańczak', 'Lucas Torroba Hennigen', 'Adina Williams', 'Ryan Cotterell', 'Isabelle Augenstein']","['University of Copenhagen', 'Massachusetts Institute of Technology', 'Meta AI Research', 'ETH Zürich', 'University of Copenhagen']","['SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Machine Translation & Multilinguality']","Stańczak, K., Torroba Hennigen, L., Williams, A., Cotterell, R., & Augenstein, I. (2023). A Latent-Variable Model for Intrinsic Probing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13591-13599. https://doi.org/10.1609/aaai.v37i11.26593","Abstract 					The success of pre-trained contextualized representations has prompted researchers to analyze them for the presence of linguistic information.  Indeed, it is natural to assume that these pre-trained representations do encode some level of linguistic knowledge as they have brought about large empirical improvements on a wide variety of NLP tasks, which suggests they are learning true linguistic generalization. In this work, we focus on intrinsic probing, an analysis technique where the goal is not only to identify whether a representation encodes a linguistic attribute but also to pinpoint where this attribute is encoded. We propose a novel latent-variable formulation for constructing intrinsic probes and derive a tractable variational approximation to the log-likelihood. Our results show that our model is versatile and yields tighter mutual information estimates than two intrinsic probes previously proposed in the literature. Finally, we find empirical evidence that pre-trained representations  develop a cross-lingually entangled notion of morphosyntax.","https://ojs.aaai.org/index.php/AAAI/article/view/26593/26365"
"26594","Towards Diverse, Relevant and Coherent Open-Domain Dialogue Generation via Hybrid Latent Variables","['Bin Sun', 'Yitong Li', 'Fei Mi', 'Weichao Wang', 'Yiwei Li', 'Kan Li']","['Beijing Institute of Technology, China', ""Huawei Technologies Co., Ltd.\nHuawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", 'Beijing Institute of Technology, China', 'Beijing Insitiute of Technology, China']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Generation']","Sun, B., Li, Y., Mi, F., Wang, W., Li, Y., & Li, K. (2023). Towards Diverse, Relevant and Coherent Open-Domain Dialogue Generation via Hybrid Latent Variables. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13600-13608. https://doi.org/10.1609/aaai.v37i11.26594","Abstract 					Conditional variational models, using either continuous or discrete latent variables, are powerful for open-domain dialogue response generation. However, previous works show that continuous latent variables tend to reduce the coherence of generated responses. In this paper, we also found that discrete latent variables have difficulty capturing more diverse expressions. To tackle these problems, we combine the merits of both continuous and discrete latent variables and propose a Hybrid Latent Variable (HLV) method. Specifically, HLV constrains the global semantics of responses through discrete latent variables and enriches responses with continuous latent variables. Thus, we diversify the generated responses while maintaining relevance and coherence. In addition, we propose Conditional Hybrid Variational Transformer (CHVT) to construct and to utilize HLV with transformers for dialogue generation. Through fine-grained symbolic-level semantic information and additive Gaussian mixing, we construct the distribution of continuous variables, prompting the generation of diverse expressions. Meanwhile, to maintain the relevance and coherence, the discrete latent variable is optimized by self-separation training. Experimental results on two dialogue generation datasets (DailyDialog and Opensubtitles) show that CHVT is superior to traditional transformer-based variational mechanism w.r.t. diversity, relevance and coherence metrics. Moreover, we also demonstrate the benefit of applying HLV to fine-tuning two pre-trained dialogue models (PLATO and BART-base).","https://ojs.aaai.org/index.php/AAAI/article/view/26594/26366"
"26595","ConvNTM: Conversational Neural Topic Model","['Hongda Sun', 'Quan Tu', 'Jinpeng Li', 'Rui Yan']","['Gaoling School of Artificial Intelligence, Renmin University of China', 'Gaoling School of Artificial Intelligence, Renmin University of China', 'Wangxuan Institute of Computer Technology, Peking University', 'Gaoling School of Artificial Intelligence, Renmin University of China\nEngineering Research Center of Next-Generation Intelligent Search and Recommendation, Ministry of Education']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Text Mining']","Sun, H., Tu, Q., Li, J., & Yan, R. (2023). ConvNTM: Conversational Neural Topic Model. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13609-13617. https://doi.org/10.1609/aaai.v37i11.26595","Abstract 					Topic models have been thoroughly investigated for multiple years due to their great potential in analyzing and understanding texts. Recently, researchers combine the study of topic models with deep learning techniques, known as Neural Topic Models (NTMs). However, existing NTMs are mainly tested based on general document modeling without considering different textual analysis scenarios. We assume that there are different characteristics to model topics in different textual analysis tasks. In this paper, we propose a Conversational Neural Topic Model (ConvNTM) designed in particular for the conversational scenario. Unlike the general document topic modeling, a conversation session lasts for multiple turns: each short-text utterance complies with a single topic distribution and these topic distributions are dependent across turns. Moreover, there are roles in conversations, a.k.a., speakers and addressees. Topic distributions are partially determined by such roles in conversations. We take these factors into account to model topics in conversations via the multi-turn and multi-role formulation. We also leverage the word co-occurrence relationship as a new training objective to further improve topic quality. Comprehensive experimental results based on the benchmark datasets demonstrate that our proposed ConvNTM achieves the best performance both in topic modeling and in typical downstream tasks within conversational research (i.e., dialogue act classification and dialogue response generation).","https://ojs.aaai.org/index.php/AAAI/article/view/26595/26367"
"26596","Contrastive Learning Reduces Hallucination in Conversations","['Weiwei Sun', 'Zhengliang Shi', 'Shen Gao', 'Pengjie Ren', 'Maarten de Rijke', 'Zhaochun Ren']","['Shandong University', 'Shandong University', 'Shandong University', 'Shandong University', 'University of Amsterdam', 'Shandong University']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Applications', 'SNLP: Generation', 'SNLP: Language Models']","Sun, W., Shi, Z., Gao, S., Ren, P., de Rijke, M., & Ren, Z. (2023). Contrastive Learning Reduces Hallucination in Conversations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13618-13626. https://doi.org/10.1609/aaai.v37i11.26596","Abstract 					Pre-trained language models (LMs) store knowledge in their parameters and can generate informative responses when used in conversational systems. However, LMs suffer from the problem of “hallucination:” they may generate plausible-looking statements that are irrelevant or factually incorrect. To address this problem, we propose a contrastive learning scheme, named MixCL. A novel mixed contrastive objective is proposed to explicitly optimize the implicit knowledge elicitation process of LMs, and thus reduce their hallucination in conversations. We also examine negative sampling strategies of retrieved hard negatives and model-generated negatives. We conduct experiments on Wizard-of-Wikipedia, a public, open-domain knowledge-grounded dialogue benchmark, and assess the effectiveness of MixCL. MixCL effectively reduces the hallucination of LMs in conversations and achieves the highest performance among LM-based dialogue agents in terms of relevancy and factuality. We show that MixCL achieves comparable performance to state-of-the-art KB-based approaches while enjoying notable advantages in terms of efficiency and scalability.","https://ojs.aaai.org/index.php/AAAI/article/view/26596/26368"
"26597","Revisiting Denoising Diffusion Probabilistic Models for Speech Enhancement: Condition Collapse, Efficiency and Refinement","['Wenxin Tai', 'Fan Zhou', 'Goce Trajcevski', 'Ting Zhong']","['University of Electronic Science and Technology of China', 'School of Information and Software Engineering, University of Electronic Science and Technology of China', 'Iowa State University', 'School of Information and Software Engineering, University of Electronic Science and Technology of China']","['SNLP: Speech and Multimodality', 'SNLP: Other Foundations of Speech & Natural Language Processing']","Tai, W., Zhou, F., Trajcevski, G., & Zhong, T. (2023). Revisiting Denoising Diffusion Probabilistic Models for Speech Enhancement: Condition Collapse, Efficiency and Refinement. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13627-13635. https://doi.org/10.1609/aaai.v37i11.26597","Abstract 					Recent literature has shown that denoising diffusion probabilistic models (DDPMs) can be used to synthesize high-fidelity samples with a competitive (or sometimes better) quality than previous state-of-the-art approaches. However, few attempts have been made to apply DDPM for the speech enhancement task. The reported performance of the existing works is relatively poor and significantly inferior to other generative methods. In this work, we first reveal the difficulties in applying existing diffusion models to the field of speech enhancement. Then we introduce DR-DiffuSE, a simple and effective framework for speech enhancement using conditional diffusion models. We present three strategies (two in diffusion training and one in reverse sampling) to tackle the condition collapse and guarantee the sufficient use of condition information. For efficiency, we introduce the fast sampling technique to reduce the sampling process into several steps and exploit a refinement network to calibrate the defective speech. Our proposed method achieves the state-of-the-art performance to the GAN-based model and shows a significant improvement over existing DDPM-based algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26597/26369"
"26598","SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images","['Ryota Tanaka', 'Kyosuke Nishida', 'Kosuke Nishida', 'Taku Hasegawa', 'Itsumi Saito', 'Kuniko Saito']","['NTT Human Informatics Laboratories', 'NTT Human Informatics Laboratories', 'NTT Human Informatics Laboratories', 'NTT Human Informatics Laboratories', 'NTT Human Informatics Laboratories', 'NTT Human Informatics Laboratories']","['SNLP: Question Answering', 'CV: Language and Vision']","Tanaka, R., Nishida, K., Nishida, K., Hasegawa, T., Saito, I., & Saito, K. (2023). SlideVQA: A Dataset for Document Visual Question Answering on Multiple Images. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13636-13645. https://doi.org/10.1609/aaai.v37i11.26598","Abstract 					Visual question answering on document images that contain textual, visual, and layout information, called document VQA, has received much attention recently. Although many datasets have been proposed for developing document VQA systems, most of the existing datasets focus on understanding the content relationships within a single image and not across multiple images. In this study, we propose a new multi-image document VQA dataset, SlideVQA, containing 2.6k+ slide decks composed of 52k+ slide images and 14.5k questions about a slide deck. SlideVQA requires complex reasoning, including single-hop, multi-hop, and numerical reasoning, and also provides annotated arithmetic expressions of numerical answers for enhancing the ability of numerical reasoning. Moreover, we developed a new end-to-end document VQA model that treats evidence selection and question answering as a unified sequence-to-sequence format. Experiments on SlideVQA show that our model outperformed existing state-of-the-art QA models, but that it still has a large gap behind human performance. We believe that our dataset will facilitate research on document VQA.","https://ojs.aaai.org/index.php/AAAI/article/view/26598/26370"
"26599","Reducing Sentiment Bias in Pre-trained Sentiment Classification via Adaptive Gumbel Attack","['Jiachen Tian', 'Shizhan Chen', 'Xiaowang Zhang', 'Xin Wang', 'Zhiyong Feng']","['Tianjin University', 'Tianjin University', 'Tianjin University', 'Tianjin University', 'Tianjin University']","['SNLP: Sentiment Analysis and Stylistic Analysis', 'SNLP: Language Models']","Tian, J., Chen, S., Zhang, X., Wang, X., & Feng, Z. (2023). Reducing Sentiment Bias in Pre-trained Sentiment Classification via Adaptive Gumbel Attack. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13646-13654. https://doi.org/10.1609/aaai.v37i11.26599","Abstract 					Pre-trained language models (PLMs) have recently enabled rapid progress on sentiment classification under the pre-train and fine-tune paradigm, where the fine-tuning phase aims to transfer the factual knowledge learned by PLMs to sentiment classification. However, current fine-tuning methods ignore the risk that PLMs cause the problem of sentiment bias, that is, PLMs tend to inject positive or negative sentiment from the contextual information of certain entities (or aspects) into their word embeddings, leading them to establish spurious correlations with labels. In this paper, we propose an adaptive Gumbel-attacked classifier that immunes sentiment bias from an adversarial-attack perspective. Due to the complexity and diversity of sentiment bias, we construct multiple Gumbel-attack expert networks to generate various noises from mixed Gumbel distribution constrained by mutual information minimization, and design an adaptive training framework to synthesize complex noise by confidence-guided controlling the number of expert networks. Finally, we capture these noises that effectively simulate sentiment bias based on the feedback of the classifier, and then propose a multi-channel parameter updating algorithm to strengthen the classifier to recognize these noises by fusing the parameters between the classifier and each expert network. Experimental results illustrate that our method significantly reduced sentiment bias and improved the performance of sentiment classification.","https://ojs.aaai.org/index.php/AAAI/article/view/26599/26371"
"26600","Latent Constraints on Unsupervised Text-Graph Alignment with Information Asymmetry","['Jidong Tian', 'Wenqing Chen', 'Yitian Li', 'Caoyun Fan', 'Hao He', 'Yaohui Jin']","['Shanghai Jiao Tong University', 'Sun Yat-sen University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['SNLP: Generation', 'SNLP: Other Foundations of Speech & Natural Language Processing']","Tian, J., Chen, W., Li, Y., Fan, C., He, H., & Jin, Y. (2023). Latent Constraints on Unsupervised Text-Graph Alignment with Information Asymmetry. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13655-13663. https://doi.org/10.1609/aaai.v37i11.26600","Abstract 					Unsupervised text-graph alignment (UTGA) is a fundamental task that bidirectionally generates texts and graphs without parallel data. Most available models of UTGA suffer from information asymmetry, a common phenomenon that texts and graphs include additional information invisible to each other. On the one hand, these models fail to supplement asymmetric information effectively due to the lack of ground truths. On the other hand, it is challenging to indicate asymmetric information with explicit indicators because it cannot be decoupled from the data directly. To address the challenge posed by information asymmetry, we propose the assumption that asymmetric information is encoded in unobservable latent variables and only affects the one-way generation processes. These latent variables corresponding to asymmetric information should obey prior distributions recovered approximately from original data. Therefore, we first propose a taxonomy of the latent variable that classifies the latent variable into transferrable (TV) and non-transferable (NTV) variables and further distinguish NTV as the dependent variable (DV) and the independent variable (IV). Next, we propose three latent VAE-based regularizations on TV, DV, and IV to constrain their distributions to well-designed prior distributions to introduce asymmetric information into models and enhance the preservation of shared contents. Finally, we impose the three proposed constraints on a cycle-consistent learning framework, back-translation (BT), named ConstrainedBT. Experimental results on three UTGA tasks demonstrate the effectiveness of ConstrainedBT on the information-asymmetric challenge.","https://ojs.aaai.org/index.php/AAAI/article/view/26600/26372"
"26601","M-sense: Modeling Narrative Structure in Short Personal Narratives Using Protagonist’s Mental Representations","['Prashanth Vijayaraghavan', 'Deb Roy']","['MIT Media Lab', 'MIT Media Lab']","['SNLP: Sentence-Level Semantics and Textual Inference', 'SNLP: Discourse', 'Pragmatics & Argument Mining', 'SNLP: Text Classification', 'KRR: Reasoning with Beliefs', 'SNLP: Psycholinguistics and Language Learning']","Vijayaraghavan, P., & Roy, D. (2023). M-sense: Modeling Narrative Structure in Short Personal Narratives Using Protagonist’s Mental Representations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13664-13672. https://doi.org/10.1609/aaai.v37i11.26601","Abstract 					Narrative is a ubiquitous component of human communication. Understanding its structure plays a critical role in a wide variety of applications, ranging from simple comparative analyses to enhanced narrative retrieval, comprehension, or reasoning capabilities. Prior research in narratology has highlighted the importance of studying the links between cognitive and linguistic aspects of narratives for effective comprehension. This interdependence is related to the textual semantics and mental language in narratives, referring to characters' motivations, feelings or emotions, and beliefs. However, this interdependence is hardly explored for modeling narratives. In this work, we propose the task of automatically detecting prominent elements of the narrative structure by analyzing the role of characters' inferred mental state along with linguistic information at the syntactic and semantic levels. We introduce a STORIES dataset of short personal narratives containing manual annotations of key elements of narrative structure, specifically climax and resolution. To this end, we implement a computational model that leverages the protagonist's mental state information obtained from a pre-trained model trained on social commonsense knowledge and integrates their representations with contextual semantic embed-dings using a multi-feature fusion approach. Evaluating against prior zero-shot and supervised baselines, we find that our model is able to achieve significant improvements in the task of identifying climax and resolution.","https://ojs.aaai.org/index.php/AAAI/article/view/26601/26373"
"26602","Taming Continuous Posteriors for Latent Variational Dialogue Policies","['Marin Vlastelica', 'Patrick Ernst', 'Gyuri Szarvas']","['Max Planck Institute for Intelligent Systems', 'Amazon', 'Amazon']","['SNLP: Conversational AI/Dialogue Systems', 'ML: Reinforcement Learning Algorithms', 'ML: Deep Generative Models & Autoencoders']","Vlastelica, M., Ernst, P., & Szarvas, G. (2023). Taming Continuous Posteriors for Latent Variational Dialogue Policies. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13673-13681. https://doi.org/10.1609/aaai.v37i11.26602","Abstract 					Utilizing amortized variational inference for latent-action reinforcement learning (RL) has been shown to be an effective approach in Task-oriented Dialogue (ToD) systems for optimizing dialogue success.Until now, categorical posteriors have been argued to be one of the main drivers of performance. In this work we revisit Gaussian variational posteriors for latent-action RL and show that they can yield even better performance than categoricals. We achieve this by introducing an improved variational inference objective for learning continuous representations without auxiliary learning objectives, which streamlines the training procedure. Moreover, we propose ways to regularize the latent dialogue policy, which helps to retain good response coherence. Using continuous latent representations our model achieves state of the art dialogue success rate on the MultiWOZ benchmark, and also compares well to categorical latent methods in response coherence.","https://ojs.aaai.org/index.php/AAAI/article/view/26602/26374"
"26603","Uncertainty-Aware Self-Training for Low-Resource Neural Sequence Labeling","['Jianing Wang', 'Chengyu Wang', 'Jun Huang', 'Ming Gao', 'Aoying Zhou']","['East China Normal University, Shanghai, China', 'Alibaba Group, Hangzhou, China', 'Alibaba Group, Hangzhou, China', 'East China Normal University, Shanghai, China', 'East China Normal University, Shanghai, China']","['SNLP: Information Extraction', 'SNLP: Applications', 'SNLP: Language Models', 'SNLP: Text Mining']","Wang, J., Wang, C., Huang, J., Gao, M., & Zhou, A. (2023). Uncertainty-Aware Self-Training for Low-Resource Neural Sequence Labeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13682-13690. https://doi.org/10.1609/aaai.v37i11.26603","Abstract 					Neural sequence labeling (NSL) aims at assigning labels for input language tokens, which covers a broad range of applications, such as named entity recognition (NER) and slot filling, etc. However, the satisfying results achieved by traditional supervised-based approaches heavily depend on the large amounts of human annotation data, which may not be feasible in real-world scenarios due to data privacy and computation efficiency issues. This paper presents SeqUST, a novel uncertain-aware self-training framework for NSL to address the labeled data scarcity issue and to effectively utilize unlabeled data. Specifically, we incorporate Monte Carlo (MC) dropout in Bayesian neural network (BNN) to perform uncertainty estimation at the token level and then select reliable language tokens from unlabeled data based on the model confidence and certainty. A well-designed masked sequence labeling task with a noise-robust loss supports robust training, which aims to suppress the problem of noisy pseudo labels. In addition, we develop a Gaussian-based consistency regularization technique to further improve the model robustness on Gaussian-distributed perturbed representations. This effectively alleviates the over-fitting dilemma originating from pseudo-labeled augmented data. Extensive experiments over six benchmarks demonstrate that our SeqUST framework effectively improves the performance of self-training, and consistently outperforms strong baselines by a large margin in low-resource scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/26603/26375"
"26604","Disentangled CVAEs with Contrastive Learning for Explainable Recommendation","['Linlin Wang', 'Zefeng Cai', 'Gerard de Melo', 'Zhu Cao', 'Liang He']","['East China Normal University', 'East China Normal University', 'Hasso Plattner Institute, University of Potsdam', 'East China University of Science and Technology', 'East China Normal University']","['SNLP: Generation']","Wang, L., Cai, Z., de Melo, G., Cao, Z., & He, L. (2023). Disentangled CVAEs with Contrastive Learning for Explainable Recommendation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13691-13699. https://doi.org/10.1609/aaai.v37i11.26604","Abstract 					Modern recommender systems are increasingly expected to provide informative explanations that enable users to understand the reason for particular recommendations. However, previous methods struggle to interpret the input IDs of user--item pairs in real-world datasets, failing to extract adequate characteristics for controllable generation. To address this issue, we propose disentangled conditional variational autoencoders (CVAEs) for explainable recommendation, which leverage disentangled latent preference factors and guide the explanation generation with the refined condition of CVAEs via a self-regularization contrastive learning loss. Extensive experiments demonstrate that our method generates high-quality explanations and achieves new state-of-the-art results in diverse domains.","https://ojs.aaai.org/index.php/AAAI/article/view/26604/26376"
"26605","fmLRE: A Low-Resource Relation Extraction Model Based on Feature Mapping Similarity Calculation","['Peng Wang', 'Tong Shao', 'Ke Ji', 'Guozheng Li', 'Wenjun Ke']","['Southeast University', 'Southeast University', 'Southeast University', 'Southeast University', 'Southeast University\nBeijing Institute of Computer Technology and Application']","['SNLP: Information Extraction', 'DMKM: Linked Open Data', 'Knowledge Graphs & KB Completion']","Wang, P., Shao, T., Ji, K., Li, G., & Ke, W. (2023). fmLRE: A Low-Resource Relation Extraction Model Based on Feature Mapping Similarity Calculation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13700-13708. https://doi.org/10.1609/aaai.v37i11.26605","Abstract 					Low-resource relation extraction (LRE) aims to extract relations from limited labeled corpora.  Existing work takes advantages of self-training or distant supervision to expand the limited labeled data in the data-driven approaches, while the selection bias of pseudo labels may cause the error accumulation in subsequent relation classification. To address this issue, this paper proposes fmLRE, an iterative feedback method based on feature mapping similarity calculation to improve the accuracy of pseudo labels. First, it calculates the similarities between pseudo-label and real-label data of the same category in a feature mapping space based on semantic features of labeled dataset after feature projection. Then, it fine-tunes initial model according to the iterative process of reinforcement learning. Finally, the similarity is used as a threshold for screening high-precision pseudo-labels and the basis for setting different rewards, which also acts as a penalty term for the loss function of relation classifier. Experimental results demonstrate that fmLRE achieves the state-of-the-art performance compared with strong baselines on two public datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26605/26377"
"26606","Towards Reliable Neural Machine Translation with Consistency-Aware Meta-Learning","['Rongxiang Weng', 'Qiang Wang', 'Wensen Cheng', 'Changfeng Zhu', 'Min Zhang']","['Soochow University, Suzhou, China\nmiHoYo AI, Shanghai, China', 'Zhejiang University, Hangzhou, China\nHithink RoyalFlush AI Research Institute, Hangzhou, China', 'miHoYo AI, Shanghai, China', 'miHoYo AI, Shanghai, China', 'Soochow University, Suzhou, China']","['SNLP: Machine Translation & Multilinguality', 'SNLP: Generation']","Weng, R., Wang, Q., Cheng, W., Zhu, C., & Zhang, M. (2023). Towards Reliable Neural Machine Translation with Consistency-Aware Meta-Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13709-13717. https://doi.org/10.1609/aaai.v37i11.26606","Abstract 					Neural machine translation (NMT) has achieved remarkable success in producing high-quality translations. However, current NMT systems suffer from a lack of reliability, as their outputs that are often affected by lexical or syntactic changes in inputs, resulting in large variations in quality. This limitation hinders the practicality and trustworthiness of NMT. A contributing factor to this problem is that NMT models trained with the one-to-one paradigm struggle to handle the source diversity phenomenon, where inputs with the same meaning can be expressed differently. In this work, we treat this problem as a bilevel optimization problem and present a consistency-aware meta-learning (CAML) framework derived from the model-agnostic meta-learning (MAML) algorithm to address it. Specifically, the NMT model with CAML (named CoNMT) first learns a consistent meta representation of semantically equivalent sentences in the outer loop. Subsequently, a mapping from the meta representation to the output sentence is learned in the inner loop, allowing the NMT model to translate semantically equivalent sentences to the same target sentence. We conduct experiments on the NIST Chinese to English task, three WMT translation tasks, and the TED M2O task. The results demonstrate that CoNMT effectively improves overall translation quality and reliably handles diverse inputs.","https://ojs.aaai.org/index.php/AAAI/article/view/26606/26378"
"26607","Zero-Shot Face-Based Voice Conversion: Bottleneck-Free Speech Disentanglement in the Real-World Scenario","['Shao-En Weng', 'Hong-Han Shuai', 'Wen-Huang Cheng']","['National Yang Ming Chiao Tung University, Hsinchu, Taiwan', 'National Yang Ming Chiao Tung University, Hsinchu, Taiwan', 'National Yang Ming Chiao Tung University, Hsinchu, Taiwan']","['SNLP: Generation', 'SNLP: Speech and Multimodality', 'ML: Multimodal Learning']","Weng, S.-E., Shuai, H.-H., & Cheng, W.-H. (2023). Zero-Shot Face-Based Voice Conversion: Bottleneck-Free Speech Disentanglement in the Real-World Scenario. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13718-13726. https://doi.org/10.1609/aaai.v37i11.26607","Abstract 					Often a face has a voice. Appearance sometimes has a strong relationship with one's voice. In this work, we study how a face can be converted to a voice, which is a face-based voice conversion. Since there is no clean dataset that contains face and speech, voice conversion faces difficult learning and low-quality problems caused by background noise or echo. Too much redundant information for face-to-voice also causes synthesis of a general style of speech. Furthermore, previous work tried to disentangle speech with bottleneck adjustment. However, it is hard to decide on the size of the bottleneck. Therefore, we propose a bottleneck-free strategy for speech disentanglement. To avoid synthesizing the general style of speech, we utilize framewise facial embedding. It applied adversarial learning with a multi-scale discriminator for the model to achieve better quality. In addition, the self-attention module is added to focus on content-related features for in-the-wild data. Quantitative experiments show that our method outperforms previous work.","https://ojs.aaai.org/index.php/AAAI/article/view/26607/26379"
"26608","Adversarial Self-Attention for Language Understanding","['Hongqiu Wu', 'Ruixue Ding', 'Hai Zhao', 'Pengjun Xie', 'Fei Huang', 'Min Zhang']","['Shanghai Jiao Tong University', 'Alibaba Group', 'Shanghai Jiao Tong University', 'Alibaba Group', 'Alibaba Group', 'Soochow University']","['SNLP: Adversarial Attacks & Robustness', 'SNLP: Language Models']","Wu, H., Ding, R., Zhao, H., Xie, P., Huang, F., & Zhang, M. (2023). Adversarial Self-Attention for Language Understanding. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13727-13735. https://doi.org/10.1609/aaai.v37i11.26608","Abstract 					Deep neural models (e.g. Transformer) naturally learn spurious features, which create a ``shortcut'' between the labels and inputs, thus impairing the generalization and robustness. This paper advances self-attention mechanism to its robust variant for Transformer-based pre-trained language models (e.g. BERT). We propose Adversarial Self-Attention mechanism (ASA), which adversarially biases the attentions to effectively suppress the model reliance on features (e.g. specific keywords) and encourage its exploration of broader semantics. We conduct comprehensive evaluation across a wide range of tasks for both pre-training and fine-tuning stages. For pre-training, ASA unfolds remarkable performance gain compared to naive training for longer steps. For fine-tuning, ASA-empowered models outweigh naive models by a large margin considering both generalization and robustness.","https://ojs.aaai.org/index.php/AAAI/article/view/26608/26380"
"26609","See How You Read? Multi-Reading Habits Fusion Reasoning for Multi-Modal Fake News Detection","['Lianwei Wu', 'Pusheng Liu', 'Yanning Zhang']","['National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, China\nResearch & Development Institute of Northwestern Polytechnical University in Shenzhen, China\nChongqing Science and Technology Innovation Center of Northwestern Polytechnical University, China', 'National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, China', 'National Engineering Laboratory for Integrated Aero-Space-Ground-Ocean Big Data Application Technology, School of Computer Science, Northwestern Polytechnical University, China']","['SNLP: Applications', 'APP: Humanities & Computational Social Science', 'SNLP: Sentence-Level Semantics and Textual Inference', 'SNLP: Text Mining']","Wu, L., Liu, P., & Zhang, Y. (2023). See How You Read? Multi-Reading Habits Fusion Reasoning for Multi-Modal Fake News Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13736-13744. https://doi.org/10.1609/aaai.v37i11.26609","Abstract 					The existing approaches based on different neural networks automatically capture and fuse the multimodal semantics of news, which have achieved great success for fake news detection. However, they still suffer from the limitations of both shallow fusion of multimodal features and less attention to the inconsistency between different modalities. To overcome them, we propose multi-reading habits fusion reasoning networks (MRHFR) for multi-modal fake news detection. In MRHFR, inspired by people's different reading habits for multimodal news, we summarize three basic cognitive reading habits and put forward cognition-aware fusion layer to learn the dependencies between multimodal features of news, so as to deepen their semantic-level integration. To explore the inconsistency of different modalities of news, we develop coherence constraint reasoning layer from two perspectives, which first measures the semantic consistency between the comments and different modal features of the news, and then probes the semantic deviation caused by unimodal features to the multimodal news content through constraint strategy. Experiments on two public datasets not only demonstrate that MRHFR not only achieves the excellent performance but also provides a new paradigm for capturing inconsistencies between multi-modal news.","https://ojs.aaai.org/index.php/AAAI/article/view/26609/26381"
"26610","Identify Event Causality with Knowledge and Analogy","['Sifan Wu', 'Ruihui Zhao', 'Yefeng Zheng', 'Jian Pei', 'Bang Liu']","['RALI & Mila, University of Montreal', 'Tencent Jarvis Lab', 'Tencent Jarvis Lab', 'Duke University', 'RALI & Mila, University of Montreal']","['SNLP: Applications', 'KRR: Applications']","Wu, S., Zhao, R., Zheng, Y., Pei, J., & Liu, B. (2023). Identify Event Causality with Knowledge and Analogy. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13745-13753. https://doi.org/10.1609/aaai.v37i11.26610","Abstract 					Event causality identification (ECI) aims to identify the causal relationship between events, which plays a crucial role in deep text understanding. Due to the diversity of real-world causality events and difficulty in obtaining sufficient training data, existing ECI approaches have poor generalizability and struggle to identify the relation between seldom seen events. In this paper, we propose to utilize both external knowledge and internal analogy to improve ECI. On the one hand, we utilize a commonsense knowledge graph called ConceptNet to enrich the description of an event sample and reveal the commonalities or associations between different events. On the other hand, we retrieve similar events as analogy exam- ples and glean useful experiences from such analogous neigh- bors to better identify the relationship between a new event pair. By better understanding different events through exter- nal knowledge and making an analogy with similar events, we can alleviate the data sparsity issue and improve model gener- alizability. Extensive evaluations on two benchmark datasets show that our model outperforms other baseline methods by around 18% on the F1-value on average","https://ojs.aaai.org/index.php/AAAI/article/view/26610/26382"
"26611","Continual Graph Convolutional Network for Text Classification","['Tiandeng Wu', 'Qijiong Liu', 'Yi Cao', 'Yao Huang', 'Xiao-Ming Wu', 'Jiandong Ding']","['Huawei Technolologies Co., Ltd', 'The Hong Kong Polytechnic University', 'Huawei Technolologies Co., Ltd', 'Huawei Technolologies Co., Ltd', 'The Hong Kong Polytechnic University', 'Huawei Technolologies Co., Ltd']","['SNLP: Text Classification', 'SNLP: Information Extraction', 'SNLP: Learning & Optimization for SNLP', 'SNLP: Ontology Induction From Text', 'SNLP: Sentence-Level Semantics and Textual Inference']","Wu, T., Liu, Q., Cao, Y., Huang, Y., Wu, X.-M., & Ding, J. (2023). Continual Graph Convolutional Network for Text Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13754-13762. https://doi.org/10.1609/aaai.v37i11.26611","Abstract 					Graph convolutional network (GCN) has been successfully applied to capture global non-consecutive and long-distance semantic information for text classification. However, while GCN-based methods have shown promising results in offline evaluations, they commonly follow a seen-token-seen-document paradigm by constructing a fixed document-token graph and cannot make inferences on new documents. It is a challenge to deploy them in online systems to infer steaming text data. In this work, we present a continual GCN model (ContGCN) to generalize inferences from observed documents to unobserved documents. Concretely, we propose a new all-token-any-document paradigm to dynamically update the document-token graph in every batch during both the training and testing phases of an online system. Moreover, we design an occurrence memory module and a self-supervised contrastive learning objective to update ContGCN in a label-free manner. A 3-month A/B test on Huawei public opinion analysis system shows ContGCN achieves 8.86% performance gain compared with state-of-the-art methods. Offline experiments on five public datasets also show ContGCN can improve inference quality. The source code will be released at https://github.com/Jyonn/ContGCN.","https://ojs.aaai.org/index.php/AAAI/article/view/26611/26383"
"26612","InfoCTM: A Mutual Information Maximization Perspective of Cross-Lingual Topic Modeling","['Xiaobao Wu', 'Xinshuai Dong', 'Thong Nguyen', 'Chaoqun Liu', 'Liang-Ming Pan', 'Anh Tuan Luu']","['Nanyang Technological University, Singapore', 'Carnegie Mellon University, USA', 'National University of Singapore, Singapore', 'Nanyang Technological University, Singapore\nDAMO Academy, Alibaba Group, Singapore', 'National University of Singapore, Singapore', 'Nanyang Technological University, Singapore']","['SNLP: Text Mining', 'SNLP: Text Classification', 'SNLP: Machine Translation & Multilinguality']","Wu, X., Dong, X., Nguyen, T., Liu, C., Pan, L.-M., & Luu, A. T. (2023). InfoCTM: A Mutual Information Maximization Perspective of Cross-Lingual Topic Modeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13763-13771. https://doi.org/10.1609/aaai.v37i11.26612","Abstract 					Cross-lingual topic models have been prevalent for cross-lingual text analysis by revealing aligned latent topics. However, most existing methods suffer from producing repetitive topics that hinder further analysis and performance decline caused by low-coverage dictionaries. In this paper, we propose the Cross-lingual Topic Modeling with Mutual Information (InfoCTM). Instead of the direct alignment in previous work, we propose a topic alignment with mutual information method. This works as a regularization to properly align topics and prevent degenerate topic representations of words, which mitigates the repetitive topic issue. To address the low-coverage dictionary issue, we further propose a cross-lingual vocabulary linking method that finds more linked cross-lingual words for topic alignment beyond the translations of a given dictionary. Extensive experiments on English, Chinese, and Japanese datasets demonstrate that our method outperforms state-of-the-art baselines, producing more coherent, diverse, and well-aligned topics and showing better transferability for cross-lingual classification tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26612/26384"
"26613","VideoDubber: Machine Translation with Speech-Aware Length Control for Video Dubbing","['Yihan Wu', 'Junliang Guo', 'Xu Tan', 'Chen Zhang', 'Bohan Li', 'Ruihua Song', 'Lei He', 'Sheng Zhao', 'Arul Menezes', 'Jiang Bian']","['Gaoling School of Artificial Intelligence, Renmin University of China', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Azure Speech', 'Microsoft Azure Speech', 'Gaoling School of Artificial Intelligence, Renmin University of China', 'Microsoft Azure Speech', 'Microsoft Azure Speech', 'Microsoft Azure Translation', 'Microsoft Research Asia']","['SNLP: Machine Translation & Multilinguality', 'SNLP: Speech and Multimodality']","Wu, Y., Guo, J., Tan, X., Zhang, C., Li, B., Song, R., He, L., Zhao, S., Menezes, A., & Bian, J. (2023). VideoDubber: Machine Translation with Speech-Aware Length Control for Video Dubbing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13772-13779. https://doi.org/10.1609/aaai.v37i11.26613","Abstract 					Video dubbing aims to translate the original speech in a film or television program into the speech in a target language, which can be achieved with a cascaded system consisting of speech recognition, machine translation and speech synthesis. To ensure the translated speech to be well aligned with the corresponding video, the length/duration of the translated speech should be as close as possible to that of the original speech, which requires strict length control. Previous works usually control the number of words or characters generated by the machine translation model to be similar to the source sentence, without considering the isochronicity of speech as the speech duration of words/characters in different languages varies. In this paper, we propose VideoDubber, a machine translation system tailored for the task of video dubbing, which directly considers the speech duration of each token in translation, to match the length of source and target speech. Specifically, we control the speech length of generated sentence by guiding the prediction of each word with the duration information, including the speech duration of itself as well as how much duration is left for the remaining words. We design experiments on four language directions (German -> English, Spanish -> English, Chinese <-> English), and the results show that VideoDubber achieves better length control ability on the generated speech than baseline methods. To make up the lack of real-world datasets, we also construct a real-world test set collected from films to provide comprehensive evaluations on the video dubbing task.","https://ojs.aaai.org/index.php/AAAI/article/view/26613/26385"
"26614","Don’t Be So Sure! Boosting ASR Decoding via Confidence Relaxation","['Tomer Wullach', 'Shlomo E. Chazan']","['OriginAI', 'OriginAI']","['SNLP: Other Foundations of Speech & Natural Language Processing', 'SNLP: Applications', 'SNLP: Conversational AI/Dialogue Systems', 'SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Language Models']","Wullach, T., & Chazan, S. E. (2023). Don’t Be So Sure! Boosting ASR Decoding via Confidence Relaxation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13780-13788. https://doi.org/10.1609/aaai.v37i11.26614","Abstract 					Automatic Speech Recognition (ASR) systems frequently use a search-based decoding strategy aiming to find the best attainable transcript by considering multiple candidates. One prominent speech recognition decoding heuristic is beam search, which seeks the transcript with the greatest likelihood computed using the predicted distribution. While showing substantial performance gains in various tasks, beam search loses some of its effectiveness when the predicted probabilities are highly confident, i.e., the predicted distribution is massed for a single or very few classes. We show that recently proposed Self-Supervised Learning (SSL)-based ASR models tend to yield exceptionally confident predictions that may hamper beam search from truly considering a diverse set of candidates. We perform a layer analysis to reveal and visualize how predictions evolve, and propose a decoding procedure that improves the performance of fine-tuned ASR models. Our proposed approach does not require further training beyond the original fine-tuning, nor additional model parameters. In fact, we find that our proposed method requires significantly less inference computation than current approaches. We propose aggregating the top M layers, potentially leveraging useful information encoded in intermediate layers, and relaxing model confidence. We demonstrate the effectiveness of our approach by conducting an empirical study on varying amounts of labeled resources and different model sizes, showing consistent improvements in particular when applied to low-resource scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/26614/26386"
"26615","AMOM: Adaptive Masking over Masking for Conditional Masked Language Model","['Yisheng Xiao', 'Ruiyang Xu', 'Lijun Wu', 'Juntao Li', 'Tao Qin', 'Tie-Yan Liu', 'Min Zhang']","['Soochow University', 'Soochow University', 'Microsoft Research Asia', 'Soochow University', 'Microsoft Research Asia', 'Microsoft Research', 'Soochow University']","['SNLP: Generation', 'SNLP: Machine Translation & Multilinguality', 'SNLP: Summarization']","Xiao, Y., Xu, R., Wu, L., Li, J., Qin, T., Liu, T.-Y., & Zhang, M. (2023). AMOM: Adaptive Masking over Masking for Conditional Masked Language Model. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13789-13797. https://doi.org/10.1609/aaai.v37i11.26615","Abstract 					Transformer-based autoregressive (AR) methods have achieved appealing performance for varied sequence-to-sequence generation tasks, e.g., neural machine translation, summarization, and code generation, but suffer from low inference efficiency. To speed up the inference stage, many non-autoregressive (NAR) strategies have been proposed in the past few years. Among them, the conditional masked language model (CMLM) is one of the most versatile frameworks, as it can support many different sequence generation scenarios and achieve very competitive performance on these tasks. In this paper, we further introduce a simple yet effective adaptive masking over masking strategy to enhance the refinement capability of the decoder and make the encoder optimization easier. Experiments on 3 different tasks (neural machine translation, summarization, and code generation) with 15 datasets in total confirm that our proposed simple method achieves significant performance improvement over the strong CMLM model. Surprisingly, our proposed model yields state-of-the-art performance on neural machine translation (34.62 BLEU on WMT16 EN to RO, 34.82 BLEU on WMT16 RO to EN, and 34.84 BLEU on IWSLT De to En) and even better performance than the AR Transformer on 7 benchmark datasets with at least 2.2x speedup. Our code is available at GitHub.","https://ojs.aaai.org/index.php/AAAI/article/view/26615/26387"
"26616","Global Mixup: Eliminating Ambiguity with Clustering","['Xiangjin Xie', 'Li Yangning', 'Wang Chen', 'Kai Ouyang', 'Zuotong Xie', 'Hai-Tao Zheng']","['Shenzhen International Graduate School, Tsinghua University', 'Shenzhen International Graduate School, Tsinghua University\nPengcheng Laboratory', 'Google Inc.', 'Shenzhen International Graduate School, Tsinghua University', 'Shenzhen International Graduate School, Tsinghua University', 'Shenzhen International Graduate School, Tsinghua University\nPengcheng Laboratory']","['SNLP: Applications', 'SNLP: Text Classification']","Xie, X., Yangning, L., Chen, W., Ouyang, K., Xie, Z., & Zheng, H.-T. (2023). Global Mixup: Eliminating Ambiguity with Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13798-13806. https://doi.org/10.1609/aaai.v37i11.26616","Abstract 					Data augmentation with Mixup has been proven an effective method to regularize the current deep neural networks. Mixup generates virtual samples and corresponding labels simultaneously by linear interpolation. However, the one-stage generation paradigm and the use of linear interpolation have two defects: (1) The label of the generated sample is simply combined from the labels of the original sample pairs without reasonable judgment, resulting in ambiguous labels. (2) Linear combination significantly restricts the sampling space for generating samples. To address these issues, we propose a novel and effective augmentation method, Global Mixup, based on global clustering relationships. Specifically, we transform the previous one-stage augmentation process into two-stage by decoupling the process of generating virtual samples from the labeling. And for the labels of the generated samples, relabeling is performed based on clustering by calculating the global relationships of the generated samples. Furthermore, we are no longer restricted to linear relationships, which allows us to generate more reliable virtual samples in a larger sampling space. Extensive experiments for CNN, LSTM, and BERT on five tasks show that Global Mixup outperforms previous baselines. Further experiments also demonstrate the advantage of Global Mixup in low-resource scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/26616/26388"
"26617","MoEC: Mixture of Expert Clusters","['Yuan Xie', 'Shaohan Huang', 'Tianyu Chen', 'Furu Wei']","['Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia']","['SNLP: Machine Translation & Multilinguality', 'SNLP: Learning & Optimization for SNLP']","Xie, Y., Huang, S., Chen, T., & Wei, F. (2023). MoEC: Mixture of Expert Clusters. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13807-13815. https://doi.org/10.1609/aaai.v37i11.26617","Abstract 					Sparsely Mixture of Experts (MoE) has received great interest due to its promising scaling capability with affordable computational overhead. MoE models convert dense layers into sparse experts, and utilize a gated routing network to make experts conditionally activated. However, as the number of experts grows, MoE with outrageous parameters suffers from overfitting and sparse data allocation. Such problems are especially severe on tasks with limited data, thus hindering the progress towards improving performance by scaling up. We verify that there exists a performance upper bound of scaling up sparse MoE. In this work, we propose Mixture of Expert Clusters — a general approach to enable expert layers to learn more diverse and appropriate knowledge by imposing variance-based constraints on the routing stage. Given this, we could further propose a cluster-level expert dropout strategy specifically designed for the expert cluster structure. Our experiments reveal that MoEC could improve performance on machine translation and natural language understanding tasks. MoEC plays a positive role in mitigating overfitting and sparse data allocation problems, thus fully releasing the potential of large-scale sparse models.","https://ojs.aaai.org/index.php/AAAI/article/view/26617/26389"
"26618","Factual and Informative Review Generation for Explainable Recommendation","['Zhouhang Xie', 'Sameer Singh', 'Julian McAuley', 'Bodhisattwa Prasad Majumder']","['University of California, San Diego', 'University of California, Irvine', 'University of California, San Diego', 'University of California, San Diego']","['SNLP: Generation', 'DMKM: Recommender Systems', 'PEAI: Interpretability and Explainability', 'SNLP: Language Grounding']","Xie, Z., Singh, S., McAuley, J., & Majumder, B. P. (2023). Factual and Informative Review Generation for Explainable Recommendation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13816-13824. https://doi.org/10.1609/aaai.v37i11.26618","Abstract 					Recent models can generate fluent and grammatical synthetic reviews while accurately predicting user ratings. The generated reviews, expressing users' estimated opinions towards related products, are often viewed as natural language ‘rationales’ for the jointly predicted rating. However, previous studies found that existing models often generate repetitive, universally applicable, and generic explanations, resulting in uninformative rationales. Further, our analysis shows that previous models' generated content often contain factual hallucinations. These issues call for novel solutions that could generate both informative and factually grounded explanations. Inspired by recent success in using retrieved content in addition to parametric knowledge for generation, we propose to augment the generator with a personalized retriever, where the retriever's output serves as external knowledge for enhancing the generator. Experiments on Yelp, TripAdvisor, and Amazon Movie Reviews dataset show our model could generate explanations that more reliably entail existing reviews, are more diverse, and are rated more informative by human evaluators.","https://ojs.aaai.org/index.php/AAAI/article/view/26618/26390"
"26619","Dialogue Rewriting via Skeleton-Guided Generation","['Chunlei Xin', 'Hongyu Lin', 'Shan Wu', 'Xianpei Han', 'Bo Chen', 'Wen Dai', 'Shuai Chen', 'Bin Wang', 'Le Sun']","['Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences', 'Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences\nState Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences', 'Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences\nSchool of Information Engineering, Minzu University of China\nNational Language Resources Monitoring and Research Center for Minority Languages', 'Xiaomi AI Lab, Xiaomi Inc.', 'Xiaomi AI Lab, Xiaomi Inc.', 'Xiaomi AI Lab, Xiaomi Inc.', 'Chinese Information Processing Laboratory, Institute of Software, Chinese Academy of Sciences\nState Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences']","['SNLP: Conversational AI/Dialogue Systems']","Xin, C., Lin, H., Wu, S., Han, X., Chen, B., Dai, W., Chen, S., Wang, B., & Sun, L. (2023). Dialogue Rewriting via Skeleton-Guided Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13825-13833. https://doi.org/10.1609/aaai.v37i11.26619","Abstract 					Dialogue rewriting aims to transform multi-turn, context-dependent dialogues into well-formed, context-independent text for most NLP systems. Previous dialogue rewriting benchmarks and systems assume a fluent and informative utterance to rewrite. Unfortunately, dialogue utterances from real-world systems are frequently noisy and with various kinds of errors that can make them almost uninformative. In this paper, we first present Real-world Dialogue Rewriting Corpus (RealDia), a new benchmark to evaluate how well current dialogue rewriting systems can deal with real-world noisy and uninformative dialogue utterances. RealDia contains annotated multi-turn dialogues from real scenes with ASR errors, spelling errors, redundancies and other noises that are ignored by previous dialogue rewriting benchmarks. We show that previous dialogue rewriting approaches are neither effective nor data-efficient to resolve RealDia. Then this paper presents Skeleton-Guided Rewriter (SGR), which can resolve the task of dialogue rewriting via a skeleton-guided generation paradigm. Experiments show that RealDia is a much more challenging benchmark for real-world dialogue rewriting, and SGR can effectively resolve the task and outperform previous approaches by a large margin.","https://ojs.aaai.org/index.php/AAAI/article/view/26619/26391"
"26620","Dialogue State Distillation Network with Inter-slot Contrastive Learning for Dialogue State Tracking","['Jing Xu', 'Dandan Song', 'Chong Liu', 'Siu Cheung Hui', 'Fei Li', 'Qiang Ju', 'Xiaonan He', 'Jian Xie']","['Beijing Institute of Technology', 'Beijing Institute of Technology', 'Baidu Inc.', 'Nanyang Technological University', 'Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.', 'Baidu Inc.']","['SNLP: Conversational AI/Dialogue Systems']","Xu, J., Song, D., Liu, C., Hui, S. C., Li, F., Ju, Q., He, X., & Xie, J. (2023). Dialogue State Distillation Network with Inter-slot Contrastive Learning for Dialogue State Tracking. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13834-13842. https://doi.org/10.1609/aaai.v37i11.26620","Abstract 					In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to extract users' intentions from the dialogue history. Currently, most existing approaches suffer from error propagation and are unable to dynamically select relevant information when utilizing previous dialogue states. Moreover, the relations between the updates of different slots provide vital clues for DST. However, the existing approaches rely only on predefined graphs to indirectly capture the relations. In this paper, we propose a Dialogue State Distillation Network (DSDN) to utilize relevant information of previous dialogue states and migrate the gap of utilization between training and testing. Thus, it can dynamically exploit previous dialogue states and avoid introducing error propagation simultaneously. Further, we propose an inter-slot contrastive learning loss to effectively capture the slot co-update relations from dialogue context. Experiments are conducted on the widely used MultiWOZ 2.0 and MultiWOZ 2.1 datasets. The experimental results show that our proposed model achieves the state-of-the-art performance for DST.","https://ojs.aaai.org/index.php/AAAI/article/view/26620/26392"
"26621","Balanced Meta Learning and Diverse Sampling for Lifelong Task-Oriented Dialogue Systems","['Qiancheng Xu', 'Min Yang', 'Ruifeng Xu']","['Georgia Institute of Technology', 'Chinese Academy of Sciences', 'Harbin Institute of Technology (Shenzhen)']","['SNLP: Conversational AI/Dialogue Systems', 'ML: Lifelong and Continual Learning', 'ML: Meta Learning']","Xu, Q., Yang, M., & Xu, R. (2023). Balanced Meta Learning and Diverse Sampling for Lifelong Task-Oriented Dialogue Systems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13843-13852. https://doi.org/10.1609/aaai.v37i11.26621","Abstract 					In real-world scenarios, it is crucial to build a lifelong taskoriented dialogue system (TDS) that continually adapts to new knowledge without forgetting previously acquired experiences. Existing approaches mainly focus on mitigating the catastrophic forgetting in lifelong TDS. However, the transfer ability to generalize the accumulated old knowledge to new tasks is underexplored. In this paper, we propose a two-stage lifelong task-oriented dialogue generation method to mitigate catastrophic forgetting and encourage knowledge transfer simultaneously, inspired by the learning process. In the first stage, we learn task-specific masks which adaptively preserve the knowledge of each visited task so as to mitigate catastrophic forgetting. In this stage, we are expected to learn the task-specific knowledge which is tailored for each task. In the second stage, we bring the knowledge from the encountered tasks together and understand thoroughly. To this end, we devise a balanced meta learning strategy for both forward and backward knowledge transfer in the lifelong learning process. In particular, we perform meta-update with a meta-test set sampled from the current training data for forward knowledge transfer. In addition, we employ an uncertainty-based sampling strategy to select and store representative dialogue samples into episodic memory and perform meta-update with a meta-test set sampled from the memory for backward knowledge transfer. With extensive experiments on 29 tasks, we show that MetaLTDS outperforms the strong baselines in terms of both effectiveness and efficiency. For reproducibility, we submit our code at: https: //github.com/travis-xu/MetaLTDS.","https://ojs.aaai.org/index.php/AAAI/article/view/26621/26393"
"26622","Selector-Enhancer: Learning Dynamic Selection of Local and Non-local Attention Operation for Speech Enhancement","['Xinmeng Xu', 'Weiping Tu', 'Yuhong Yang']","['National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, China', 'National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, China\nHubei Luojia Laboratory, China', 'National Engineering Research Center for Multimedia Software, School of Computer Science, Wuhan University, China\nHubei Key Laboratory of Multimedia and Network Communication Engineering, Wuhan University, China']","['SNLP: Speech and Multimodality', 'ML: Reinforcement Learning Algorithms']","Xu, X., Tu, W., & Yang, Y. (2023). Selector-Enhancer: Learning Dynamic Selection of Local and Non-local Attention Operation for Speech Enhancement. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13853-13860. https://doi.org/10.1609/aaai.v37i11.26622","Abstract 					Attention mechanisms, such as local and non-local attention, play a fundamental role in recent deep learning based speech enhancement (SE) systems. However, a natural speech contains many fast-changing and relatively briefly acoustic events, therefore, capturing the most informative speech features by indiscriminately using local and non-local attention is challenged. We observe that the noise type and speech feature vary within a sequence of speech and the local and non-local can respectively process different types of corrupted speech regions. To leverage this, we propose Selector-Enhancer, a dual-attention based convolution neural network (CNN) with a feature-filter that can dynamically select regions from low-resolution speech features and feed them to local or non-local attention operations. In particular, the proposed feature-filter is trained by using reinforcement learning (RL) with a developed difficulty-regulated reward that related to network performance, model complexity and “the difficulty of the SE task”. The results show that our method achieves comparable or superior performance to existing approaches. In particular, Selector-Enhancer is effective for real-world denoising, where the number and types of noise are varies on a single noisy mixture.","https://ojs.aaai.org/index.php/AAAI/article/view/26622/26394"
"26623","A Graph Fusion Approach for Cross-Lingual Machine Reading Comprehension","['Zenan Xu', 'Linjun Shou', 'Jian Pei', 'Ming Gong', 'Qinliang Su', 'Xiaojun Quan', 'Daxin Jiang']","['School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China', 'Microsoft Search Technology Center Asia (STCA), Beijing, China', 'School of Computing Science, Simon Fraser University', 'Microsoft Search Technology Center Asia (STCA), Beijing, China', 'School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China\nGuangdong Key Laboratory of Big Data Analysis and Processing, Guangzhou, China', 'School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, China', 'Microsoft Search Technology Center Asia (STCA), Beijing, China']","['SNLP: Machine Translation & Multilinguality']","Xu, Z., Shou, L., Pei, J., Gong, M., Su, Q., Quan, X., & Jiang, D. (2023). A Graph Fusion Approach for Cross-Lingual Machine Reading Comprehension. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13861-13868. https://doi.org/10.1609/aaai.v37i11.26623","Abstract 					Although great progress has been made for Machine Reading Comprehension (MRC) in English, scaling out to a large number of languages remains a huge challenge due to the lack of large amounts of annotated training data in non-English languages. To address this challenge, some recent efforts of cross-lingual MRC employ machine translation to transfer knowledge from English to other languages, through either explicit alignment or implicit attention. For effective knowledge transition, it is beneficial to leverage both semantic and syntactic information. However, the existing methods fail to explicitly incorporate syntax information in model learning. Consequently, the models are not robust to errors in alignment and noises in attention. In this work, we propose a novel approach, which jointly models the cross-lingual alignment information and the mono-lingual syntax information using a graph. We develop a series of algorithms, including graph construction, learning, and pre-training. The experiments on two benchmark datasets for cross-lingual MRC show that our approach outperforms all strong baselines, which verifies the effectiveness of syntax information for cross-lingual MRC.","https://ojs.aaai.org/index.php/AAAI/article/view/26623/26395"
"26624","Improving Biomedical Entity Linking with Cross-Entity Interaction","['Zhenran Xu', 'Yulin Chen', 'Baotian Hu']","['Harbin Institute of Technology (Shenzhen)', 'Harbin Institute of Technology (Shenzhen)', 'Harbin Institute of Technology (Shenzhen)']","['SNLP: Information Extraction']","Xu, Z., Chen, Y., & Hu, B. (2023). Improving Biomedical Entity Linking with Cross-Entity Interaction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13869-13877. https://doi.org/10.1609/aaai.v37i11.26624","Abstract 					Biomedical entity linking (EL) is the task of linking mentions in a biomedical document to corresponding entities in a knowledge base (KB). The challenge in biomedical EL lies in leveraging mention context to select the most appropriate entity among possible candidates. Although some EL models achieve competitive results by retrieving candidate entities and then exploiting context to re-rank them, these re-ranking models concatenate mention context with one candidate at a time. They lack fine-grained interaction among candidates, and potentially cannot handle ambiguous mentions when facing candidates both with high lexical similarity. We cope with this issue using a re-ranking model based on prompt tuning, which represents mention context and all candidates at once, letting candidates in comparison attend to each other. We also propose a KB-enhanced self-supervised pretraining strategy. Instead of large-scale pretraining on biomedical EL data in previous work, we use masked language modeling with synonyms from KB. Our method achieves state-of-the-art results on 3 biomedical EL datasets: NCBI disease, BC5CDR and COMETA, showing the effectiveness of cross-entity interaction and KB-enhanced pretraining strategy. Code is available at https://github.com/HITsz-TMG/Prompt-BioEL.","https://ojs.aaai.org/index.php/AAAI/article/view/26624/26396"
"26625","Nested Named Entity Recognition as Building Local Hypergraphs","['Yukun Yan', 'Bingling Cai', 'Sen Song']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University']","['SNLP: Information Extraction', 'SNLP: Applications']","Yan, Y., Cai, B., & Song, S. (2023). Nested Named Entity Recognition as Building Local Hypergraphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13878-13886. https://doi.org/10.1609/aaai.v37i11.26625","Abstract 					Named entity recognition is a fundamental task in natural language processing. Based on the sequence labeling paradigm for flat named entity recognition, multiple methods have been developed to handle the nested structures. However, they either require fixed recognition order or introduce complex hypergraphs. To tackle this problem, we propose a novel model named Local Hypergraph Builder Network (LHBN) that builds multiple simpler local hypergraphs to capture named entities instead of a single complex full-size hypergraph. The proposed model has three main properties: (1) The named entities that share boundaries are captured in the same local hypergraph. (2) The boundary information is enhanced by building local hypergraphs. (3) The hypergraphs can be built bidirectionally to take advantage of the identification direction preference of different named entities. Experiments illustrate that our model outperforms previous state-of-the-art methods on four widely used nested named entity recognition datasets: ACE04, ACE05, GENIA, and KBP17. The code is available at https://github.com/yanyk13/local-hypergraph-building-network.git.","https://ojs.aaai.org/index.php/AAAI/article/view/26625/26397"
"26626","A Domain-Transfer Meta Task Design Paradigm for Few-Shot Slot Tagging","['Fengyi Yang', 'Xi Zhou', 'Yating Yang', 'Bo Ma', 'Rui Dong', 'Abibulla Atawulla']","['Xinjiang Technical Institute of Physics & Chemistry, Chinese Academy of Sciences, Urumqi 830011, China\nUniversity of Chinese Academy of Sciences, Beijing 100049, China\nXinjiang Laboratory of Minority Speech and Language Information Processing, Urumqi 830011, China', 'Xinjiang Technical Institute of Physics & Chemistry, Chinese Academy of Sciences, Urumqi 830011, China\nUniversity of Chinese Academy of Sciences, Beijing 100049, China\nXinjiang Laboratory of Minority Speech and Language Information Processing, Urumqi 830011, China', 'Xinjiang Technical Institute of Physics & Chemistry, Chinese Academy of Sciences, Urumqi 830011, China\nUniversity of Chinese Academy of Sciences, Beijing 100049, China\nXinjiang Laboratory of Minority Speech and Language Information Processing, Urumqi 830011, China', 'Xinjiang Technical Institute of Physics & Chemistry, Chinese Academy of Sciences, Urumqi 830011, China\nUniversity of Chinese Academy of Sciences, Beijing 100049, China\nXinjiang Laboratory of Minority Speech and Language Information Processing, Urumqi 830011, China', 'Xinjiang Technical Institute of Physics & Chemistry, Chinese Academy of Sciences, Urumqi 830011, China\nUniversity of Chinese Academy of Sciences, Beijing 100049, China\nXinjiang Laboratory of Minority Speech and Language Information Processing, Urumqi 830011, China', 'Xinjiang Technical Institute of Physics & Chemistry, Chinese Academy of Sciences, Urumqi 830011, China\nUniversity of Chinese Academy of Sciences, Beijing 100049, China\nXinjiang Laboratory of Minority Speech and Language Information Processing, Urumqi 830011, China']","['SNLP: Conversational AI/Dialogue Systems', 'ML: Meta Learning', 'SNLP: Text Mining']","Yang, F., Zhou, X., Yang, Y., Ma, B., Dong, R., & Atawulla, A. (2023). A Domain-Transfer Meta Task Design Paradigm for Few-Shot Slot Tagging. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13887-13895. https://doi.org/10.1609/aaai.v37i11.26626","Abstract 					Few-shot slot tagging is an important task in dialogue systems and attracts much attention of researchers. Most previous few-shot slot tagging methods utilize meta-learning procedure for training and strive to construct a large number of different meta tasks to simulate the testing situation of insufficient data. However, there is a widespread phenomenon of overlap slot between two domains in slot tagging. Traditional meta tasks ignore this special phenomenon and cannot simulate such realistic few-shot slot tagging scenarios. It violates the basic principle of meta-learning which the meta task is consistent with the real testing task, leading to historical information forgetting problem. In this paper, we introduce a novel domain-transfer meta task design paradigm to tackle this problem. We distribute a basic domain to each target domain based on the coincidence degree of slot labels between these two domains. Unlike classic meta tasks which only rely on small samples of target domain, our meta tasks aim to correctly infer the class of target domain query samples based on both abundant data in basic domain and scarce data in target domain. To accomplish our meta task, we propose a Task Adaptation Network to effectively transfer the historical information from the basic domain to the target domain. We carry out sufficient experiments on the benchmark slot tagging dataset SNIPS and the name entity recognition dataset NER. Results demonstrate that our proposed model outperforms previous methods and achieves the state-of-the-art performance.","https://ojs.aaai.org/index.php/AAAI/article/view/26626/26398"
"26627","Orders Are Unwanted: Dynamic Deep Graph Convolutional Network for Personality Detection","['Tao Yang', 'Jinghao Deng', 'Xiaojun Quan', 'Qifan Wang']","['Sun Yat-sen University', 'Sun Yat-sen University', 'Sun Yat-sen University', 'Meta AI']","['SNLP: Applications']","Yang, T., Deng, J., Quan, X., & Wang, Q. (2023). Orders Are Unwanted: Dynamic Deep Graph Convolutional Network for Personality Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13896-13904. https://doi.org/10.1609/aaai.v37i11.26627","Abstract 					Predicting personality traits based on online posts has emerged as an important task in many fields such as social network analysis. One of the challenges of this task is assembling information from various posts into an overall profile for each user. While many previous solutions simply concatenate the posts into a long text and then encode the text by sequential or hierarchical models, they introduce unwarranted orders for the posts, which may mislead the models. In this paper, we propose a dynamic deep graph convolutional network (D-DGCN) to overcome the above limitation. Specifically, we design a learn-to-connect approach that adopts a dynamic multi-hop structure instead of a deterministic structure, and combine it with the DGCN module to automatically learn the connections between posts. The modules of post encoder, learn-to-connect, and DGCN are jointly trained in an end-to-end manner. Experimental results on the Kaggle and Pandora datasets show the superior performance of D-DGCN to state-of-the-art baselines. Our code is available at https://github.com/djz233/D-DGCN.","https://ojs.aaai.org/index.php/AAAI/article/view/26627/26399"
"26628","What Does Your Face Sound Like? 3D Face Shape towards Voice","['Zhihan Yang', 'Zhiyong Wu', 'Ying Shan', 'Jia Jia']","['Shenzhen International Graduate School, Tsinghua University, Shenzhen 518055, China', 'Shenzhen International Graduate School, Tsinghua University, Shenzhen 518055, China', 'Applied Research Center (ARC), Tencent PCG, Shenzhen 518054, China', 'Department of Computer Science and Technology, Tsinghua University, Beijing 100084, China']","['SNLP: Speech and Multimodality', 'SNLP: Generation']","Yang, Z., Wu, Z., Shan, Y., & Jia, J. (2023). What Does Your Face Sound Like? 3D Face Shape towards Voice. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13905-13913. https://doi.org/10.1609/aaai.v37i11.26628","Abstract 					Face-based speech synthesis provides a practical solution to generate voices from human faces. However, directly using 2D face images leads to the problems of uninterpretability and entanglement. In this paper, to address the issues, we introduce 3D face shape which (1) has an anatomical relationship between voice characteristics, partaking in the ""bone conduction"" of human timbre production, and (2) is naturally independent of irrelevant factors by excluding the blending process. We devise a three-stage framework to generate speech from 3D face shapes. Fully considering timbre production in anatomical and acquired terms, our framework incorporates three additional relevant attributes including face texture, facial features, and demographics. Experiments and subjective tests demonstrate our method can generate utterances matching faces well, with good audio quality and voice diversity. We also explore and visualize how the voice changes with the face. Case studies show that our method upgrades the face-voice inference to personalized custom-made voice creating, revealing a promising prospect in virtual human and dubbing applications.","https://ojs.aaai.org/index.php/AAAI/article/view/26628/26400"
"26629","FiTs: Fine-Grained Two-Stage Training for Knowledge-Aware Question Answering","['Qichen Ye', 'Bowen Cao', 'Nuo Chen', 'Weiyuan Xu', 'Yuexian Zou']","['Peking University', 'Peking University', 'Hong Kong University of Science and Technology (Guangzhou)\nHong Kong University of Science and Technology', 'Peking University', 'Peking University\nPeng Cheng Laboratory']","['SNLP: Question Answering']","Ye, Q., Cao, B., Chen, N., Xu, W., & Zou, Y. (2023). FiTs: Fine-Grained Two-Stage Training for Knowledge-Aware Question Answering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13914-13922. https://doi.org/10.1609/aaai.v37i11.26629","Abstract 					Knowledge-aware question answering (KAQA) requires the model to answer questions over a knowledge base, which is essential for both open-domain QA and domain-specific QA, especially when language models alone cannot provide all the knowledge needed. Despite the promising result of recent KAQA systems which tend to integrate linguistic knowledge from pre-trained language models (PLM) and factual knowledge from knowledge graphs (KG) to answer complex questions, a bottleneck exists in effectively fusing the representations from PLMs and KGs because of (i) the semantic and distributional gaps between them, and (ii) the difficulties in joint reasoning over the provided knowledge from both modalities. To address the above two problems, we propose a Fine-grained Two-stage training framework (FiTs) to boost the KAQA system performance: The first stage aims at aligning representations from the PLM and the KG, thus bridging the modality gaps between them, named knowledge adaptive post-training. The second stage, called knowledge-aware fine-tuning, aims to improve the model's joint reasoning ability based on the aligned representations. In detail,  we fine-tune the post-trained model via two auxiliary self-supervised tasks in addition to the QA supervision. Extensive experiments demonstrate that our approach achieves state-of-the-art performance on three benchmarks in the commonsense reasoning (i.e., CommonsenseQA, OpenbookQA) and medical question answering (i.e., MedQA-USMILE) domains.","https://ojs.aaai.org/index.php/AAAI/article/view/26629/26401"
"26630","On the Calibration and Uncertainty with Pólya-Gamma Augmentation for Dialog Retrieval Models","['Tong Ye', 'Shijing Si', 'Jianzong Wang', 'Ning Cheng', 'Zhitao Li', 'Jing Xiao']","['Ping An Technology (Shenzhen) Co., Ltd.\nUniversity of Science and Technology of China', 'Ping An Technology (Shenzhen) Co., Ltd.', 'Ping An Technology (Shenzhen) Co., Ltd.', 'Ping An Technology (Shenzhen) Co., Ltd.', 'Ping An Technology (Shenzhen) Co., Ltd.', 'Ping An Technology (Shenzhen) Co., Ltd.']","['SNLP: Conversational AI/Dialogue Systems', 'ML: Calibration & Uncertainty Quantification', 'RU: Applications', 'SNLP: Question Answering']","Ye, T., Si, S., Wang, J., Cheng, N., Li, Z., & Xiao, J. (2023). On the Calibration and Uncertainty with Pólya-Gamma Augmentation for Dialog Retrieval Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13923-13931. https://doi.org/10.1609/aaai.v37i11.26630","Abstract 					Deep neural retrieval models have amply demonstrated their power but estimating the reliability of their predictions remains challenging. Most dialog response retrieval models output a single score for a response on how relevant it is to a given question. However, the bad calibration of deep neural network results in various uncertainty for the single score such that the unreliable predictions always misinform user decisions. To investigate these issues, we present an efficient calibration and uncertainty estimation framework PG-DRR for dialog response retrieval models which adds a Gaussian Process layer to a deterministic deep neural network and recovers conjugacy for tractable posterior inference by Pólya-Gamma augmentation. Finally, PG-DRR achieves the lowest empirical calibration error (ECE) in the in-domain datasets and the distributional shift task while keeping R10@1 and MAP performance.","https://ojs.aaai.org/index.php/AAAI/article/view/26630/26402"
"26631","Preserve Context Information for Extract-Generate Long-Input Summarization Framework","['Ruifeng Yuan', 'Zili Wang', 'Ziqiang Cao', 'Wenjie Li']","['The Hong Kong Polytechnic University', 'Xiaohongshu Inc', 'Institute of Artificial Intelligence, Soochow University, China', 'The Hong Kong Polytechnic University']","['SNLP: Summarization']","Yuan, R., Wang, Z., Cao, Z., & Li, W. (2023). Preserve Context Information for Extract-Generate Long-Input Summarization Framework. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13932-13939. https://doi.org/10.1609/aaai.v37i11.26631","Abstract 					The Extract-generate framework has been a classic approach for text summarization. As pretrained language models struggling with long-input summarization for their high memory cost, extract-generate framework regains researchers' interests. However, the cost of its effectiveness in dealing with long-input summarization is the loss of context information. In this paper, we present a context-aware extract-generate framework (CAEG) for long-input text summarization. It focuses on preserving both local and global context information in an extract-generate framework with little cost, and can be applied to most of existing extract-generate summarization models. CAEG generates a set of context-related text spans called context prompts for each text snippet and use them to transfer the context information from the extractor and generator. To find such context prompts, we propose to capture the context information based on the interpretation of the extractor, where the text spans having the highest contribution to the extraction decision are considered as containing the richest context information. We evaluate our approach on both long-document and long-dialogue summarization datasets: arXiv and QMSum. The experiment results show that CAEG achieves the-state-of-art result on QMSum and outperforms other extract-generate based models in arXiv.","https://ojs.aaai.org/index.php/AAAI/article/view/26631/26403"
"26632","Transferable Post-hoc Calibration on Pretrained Transformers in Noisy Text Classification","['Jun Zhang', 'Wen Yao', 'Xiaoqian Chen', 'Ling Feng']","['Tsinghua University\nNational Innovation Institute of Defense Technology, Chinese Academy of Military Science', 'National Innovation Institute of Defense Technology, Chinese Academy of Military Science', 'National Innovation Institute of Defense Technology, Chinese Academic of Military Science', 'Tsinghua University']","['SNLP: Adversarial Attacks & Robustness', 'SNLP: Text Classification']","Zhang, J., Yao, W., Chen, X., & Feng, L. (2023). Transferable Post-hoc Calibration on Pretrained Transformers in Noisy Text Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13940-13948. https://doi.org/10.1609/aaai.v37i11.26632","Abstract 					Recent work has demonstrated that pretrained transformers are overconfident in text classification tasks, which can be calibrated by the famous post-hoc calibration method temperature scaling (TS). Character or word spelling mistakes are frequently encountered in real applications and greatly threaten transformer model safety. Research on calibration under noisy settings is rare, and we focus on this direction. Based on a toy experiment, we discover that TS performs poorly when the datasets are perturbed by slight noise, such as swapping the characters, which results in distribution shift. We further utilize two metrics, predictive uncertainty and maximum mean discrepancy (MMD), to measure the distribution shift between clean and noisy datasets, based on which we propose a simple yet effective transferable TS method for calibrating models dynamically. To evaluate the performance of the proposed methods under noisy settings, we construct a benchmark consisting of four noise types and five shift intensities based on the QNLI, AG-News, and Emotion tasks. Experimental results on the noisy benchmark show that (1) the metrics are effective in measuring distribution shift and (2) transferable TS can significantly decrease the expected calibration error (ECE) compared with the competitive baseline ensemble TS by approximately 46.09%.","https://ojs.aaai.org/index.php/AAAI/article/view/26632/26404"
"26633","Quantum-Inspired Representation for Long-Tail Senses of Word Sense Disambiguation","['Junwei Zhang', 'Ruifang He', 'Fengyu Guo']","['Tianjin University', 'Tianjin University', 'Tianjin Normal University']","['SNLP: Other Foundations of Speech & Natural Language Processing', 'ML: Quantum Machine Learning', 'ML: Representation Learning', 'SNLP: Language Grounding']","Zhang, J., He, R., & Guo, F. (2023). Quantum-Inspired Representation for Long-Tail Senses of Word Sense Disambiguation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13949-13957. https://doi.org/10.1609/aaai.v37i11.26633","Abstract 					Data imbalance, also known as the long-tail distribution of data, is an important challenge for data-driven models. In the Word Sense Disambiguation (WSD) task, the long-tail phenomenon of word sense distribution is more common, making it difficult to effectively represent and identify Long-Tail Senses (LTSs). Therefore exploring representation methods that do not rely heavily on the training sample size is an important way to combat LTSs. Considering that many new states, namely superposition states, can be constructed from several known states in quantum mechanics, superposition states provide the possibility to obtain more accurate representations from inferior representations learned from a small sample size. Inspired by quantum superposition states, a representation method in Hilbert space is proposed to reduce the dependence on large sample sizes and thus combat LTSs. We theoretically prove the correctness of the method, and verify its effectiveness under the standard WSD evaluation framework and obtain state-of-the-art performance. Furthermore, we also test on the constructed LTS and the latest cross-lingual datasets, and achieve promising results.","https://ojs.aaai.org/index.php/AAAI/article/view/26633/26405"
"26634","MPMQA: Multimodal Question Answering on Product Manuals","['Liang Zhang', 'Anwen Hu', 'Jing Zhang', 'Shuo Hu', 'Qin Jin']","['Renmin University of China', 'Renming University of China', 'Samsung Research China - Beijing (SRC-B)', 'Samsung Research China - Beijing (SRC-B)', 'Renmin University of China']","['SNLP: Question Answering', 'CV: Language and Vision']","Zhang, L., Hu, A., Zhang, J., Hu, S., & Jin, Q. (2023). MPMQA: Multimodal Question Answering on Product Manuals. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13958-13966. https://doi.org/10.1609/aaai.v37i11.26634","Abstract 					Visual contents, such as illustrations and images, play a big role in product manual understanding. Existing Product Manual Question Answering (PMQA) datasets tend to ignore visual contents and only retain textual parts.  In this work, to emphasize the importance of multimodal contents, we propose a Multimodal Product Manual Question Answering (MPMQA) task. For each question, MPMQA requires the model not only to process multimodal contents but also to provide multimodal answers. To support MPMQA, a large-scale dataset PM209 is constructed with human annotations, which contains 209 product manuals from 27 well-known consumer electronic brands. Human annotations include 6 types of semantic regions for manual contents and 22,021 pairs of question and answer. Especially, each answer consists of a textual sentence and related visual regions from manuals. Taking into account the length of product manuals and the fact that a question is always related to a small number of pages, MPMQA can be naturally split into two subtasks: retrieving most related pages and then generating multimodal answers. We further propose a unified model that can perform these two subtasks all together and achieve comparable performance with multiple task-specific models. The PM209 dataset is available at https://github.com/AIM3-RUC/MPMQA.","https://ojs.aaai.org/index.php/AAAI/article/view/26634/26406"
"26635","Exploring Self-Distillation Based Relational Reasoning Training for Document-Level Relation Extraction","['Liang Zhang', 'Jinsong Su', 'Zijun Min', 'Zhongjian Miao', 'Qingguo Hu', 'Biao Fu', 'Xiaodong Shi', 'Yidong Chen']","['Xiamen University', 'Xiamen University', 'Xiamen University', 'Xiamen University', 'Xiamen University', 'Xiamen University', 'Xiamen university', 'Xiamen University']","['SNLP: Information Extraction', 'SNLP: Text Mining']","Zhang, L., Su, J., Min, Z., Miao, Z., Hu, Q., Fu, B., Shi, X., & Chen, Y. (2023). Exploring Self-Distillation Based Relational Reasoning Training for Document-Level Relation Extraction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13967-13975. https://doi.org/10.1609/aaai.v37i11.26635","Abstract 					Document-level relation extraction (RE) aims to extract relational triples from a document. One of its primary challenges is to predict implicit relations between entities, which are not explicitly expressed in the document but can usually be extracted through relational reasoning. Previous methods mainly implicitly model relational reasoning through the interaction among entities or entity pairs. However, they suffer from two deficiencies: 1) they often consider only one reasoning pattern, of which coverage on relational triples is limited; 2) they do not explicitly model the process of relational reasoning. In this paper, to deal with the first problem, we propose a document-level RE model with a reasoning module that contains a core unit, the reasoning multi-head self-attention unit. This unit is a variant of the conventional multi-head self-attention and utilizes four attention heads to model four common reasoning patterns, respectively, which can cover more relational triples than previous methods. Then, to address the second issue, we propose a self-distillation training framework, which contains two branches sharing parameters. In the first branch, we first randomly mask some entity pair feature vectors in the document, and then train our reasoning module to infer their relations  by exploiting the feature information of other related entity pairs. By doing so, we can explicitly model the process of relational reasoning. However, because the additional masking operation is not used during testing, it causes an input gap between training and testing scenarios, which would hurt the model performance. To reduce this gap, we perform conventional supervised training without masking operation in the second branch and utilize Kullback-Leibler divergence loss to minimize the difference between the predictions of the two branches. Finally, we conduct comprehensive experiments on three benchmark datasets, of which experimental results demonstrate that our model consistently outperforms all competitive baselines. Our source code is available at https://github.com/DeepLearnXMU/DocRE-SD","https://ojs.aaai.org/index.php/AAAI/article/view/26635/26407"
"26636","Multi-Action Dialog Policy Learning from Logged User Feedback","['Shuo Zhang', 'Junzhou Zhao', 'Pinghui Wang', 'Tianxiang Wang', 'Zi Liang', 'Jing Tao', 'Yi Huang', 'Junlan Feng']","[""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", ""Xi'an Jiaotong University"", 'China Mobile Research', 'China Mobile Research']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Applications']","Zhang, S., Zhao, J., Wang, P., Wang, T., Liang, Z., Tao, J., Huang, Y., & Feng, J. (2023). Multi-Action Dialog Policy Learning from Logged User Feedback. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13976-13983. https://doi.org/10.1609/aaai.v37i11.26636","Abstract 					Multi-action dialog policy (MADP), which generates multiple atomic dialog actions per turn, has been widely applied in task-oriented dialog systems to provide expressive and efficient system responses. Existing MADP models usually imitate action combinations from the labeled multi-action dialog samples. Due to data limitations, they generalize poorly toward unseen dialog flows. While reinforcement learning-based methods are proposed to incorporate the service ratings from real users and user simulators as external supervision signals, they suffer from sparse and less credible dialog-level rewards. To cope with this problem, we explore to improve MADPL with explicit and implicit turn-level user feedback received for historical predictions (i.e., logged user feedback) that are cost-efficient to collect and faithful to real-world scenarios. The task is challenging since the logged user feedback provides only partial label feedback limited to the particular historical dialog actions predicted by the agent. To fully exploit such feedback information, we propose BanditMatch, which addresses the task from a feedback-enhanced semi-supervised learning perspective with a hybrid learning objective of SSL and bandit learning. BanditMatch integrates pseudo-labeling methods to better explore the action space through constructing full label feedback. Extensive experiments show that our BanditMatch improves MADPL over the state-of-the-art methods by generating more concise and informative responses. The source code and the appendix of this paper can be obtained from https://github.com/ShuoZhangXJTU/BanditMatch.","https://ojs.aaai.org/index.php/AAAI/article/view/26636/26408"
"26637","Improving End-to-End Speech Translation by Leveraging Auxiliary Speech and Text Data","['Yuhao Zhang', 'Chen Xu', 'Bojie Hu', 'Chunliang Zhang', 'Tong Xiao', 'Jingbo Zhu']","['Northeastern University, China', 'Northeastern University, China', 'Tencent Minority-Mandarin Translation, China', 'Northeastern University, China\nNiuTrans Research, Shenyang, China', 'Northeastern University, China\nNiuTrans Research, Shenyang, China', 'Northeastern University, China\nNiuTrans Research, Shenyang, China']","['SNLP: Speech and Multimodality', 'SNLP: Machine Translation & Multilinguality']","Zhang, Y., Xu, C., Hu, B., Zhang, C., Xiao, T., & Zhu, J. (2023). Improving End-to-End Speech Translation by Leveraging Auxiliary Speech and Text Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13984-13992. https://doi.org/10.1609/aaai.v37i11.26637","Abstract 					We present a method for introducing a text encoder into pre-trained end-to-end speech translation systems. It enhances the ability of adapting one modality (i.e., source-language speech) to another (i.e., source-language text). Thus, the speech translation model can learn from both unlabeled and labeled data, especially when the source-language text data is abundant. Beyond this, we present a denoising method to build a robust text encoder that can deal with both normal and noisy text data. Our system sets new state-of-the-arts on the MuST-C En-De, En-Fr, and LibriSpeech En-Fr tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26637/26409"
"26638","A Neural Span-Based Continual Named Entity Recognition Model","['Yunan Zhang', 'Qingcai Chen']","['Harbin Institute of Technology, Shenzhen, China', 'Harbin Institute of Technology, Shenzhen, China\nPeng Cheng Laboratory, Shenzhen, China']","['SNLP: Information Extraction', 'ML: Lifelong and Continual Learning']","Zhang, Y., & Chen, Q. (2023). A Neural Span-Based Continual Named Entity Recognition Model. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 13993-14001. https://doi.org/10.1609/aaai.v37i11.26638","Abstract 					Named Entity Recognition (NER) models capable of Continual Learning (CL) are realistically valuable in areas where entity types continuously increase (e.g., personal assistants). Meanwhile the learning paradigm of NER advances to new patterns such as the span-based methods. However, its potential to CL has not been fully explored. In this paper, we propose SpanKL, a simple yet effective Span-based model with Knowledge distillation (KD) to preserve memories and multi-Label prediction to prevent conflicts in CL-NER. Unlike prior sequence labeling approaches, the inherently independent modeling in span and entity level with the designed coherent optimization on SpanKL promotes its learning at each incremental step and mitigates the forgetting. Experiments on synthetic CL datasets derived from OntoNotes and Few-NERD show that SpanKL significantly outperforms previous SoTA in many aspects, and obtains the smallest gap from CL to the upper bound revealing its high practiced value. The code is available at https://github.com/Qznan/SpanKL.","https://ojs.aaai.org/index.php/AAAI/article/view/26638/26410"
"26639","Language Model Pre-training on True Negatives","['Zhuosheng Zhang', 'Hai Zhao', 'Masao Utiyama', 'Eiichiro Sumita']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'National Institute of Information and Communications Technology', 'National Institute of Information and Communications Technology']","['SNLP: Language Models', 'SNLP: Interpretability & Analysis of NLP Models', 'SNLP: Question Answering', 'SNLP: Sentence-Level Semantics and Textual Inference']","Zhang, Z., Zhao, H., Utiyama, M., & Sumita, E. (2023). Language Model Pre-training on True Negatives. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 14002-14010. https://doi.org/10.1609/aaai.v37i11.26639","Abstract 					Discriminative pre-trained language models (PrLMs) learn to predict original texts from intentionally corrupted ones. Taking the former text as positive and the latter as negative samples, the PrLM can be trained effectively for contextualized representation. However, the training of such a type of PrLMs highly relies on the quality of the automatically constructed samples. Existing PrLMs simply treat all corrupted texts as equal negative without any examination, which actually lets the resulting model inevitably suffer from the false negative issue where training is carried out on pseudo-negative data and leads to less efficiency and less robustness in the resulting PrLMs. In this work, on the basis of defining the false negative issue in discriminative PrLMs that has been ignored for a long time, we design enhanced pre-training methods to counteract false negative predictions and encourage pre-training language models on true negatives by correcting the harmful gradient updates subject to false negative predictions. Experimental results on GLUE and SQuAD benchmarks show that our counter-false-negative pre-training methods indeed bring about better performance together with stronger robustness.","https://ojs.aaai.org/index.php/AAAI/article/view/26639/26411"
"26640","MCL: Multi-Granularity Contrastive Learning Framework for Chinese NER","['Shan Zhao', 'ChengYu Wang', 'Minghao Hu', 'Tianwei Yan', 'Meng Wang']","['Hefei University of Technology', 'Hefei University of Technology\nNational University of Defense Technology', 'Information Research Center of Military Science, PLA Academy of Military Science', 'National University of Defense Technology', 'Hefei University of Technology']","['SNLP: Applications', 'SNLP: Information Extraction']","Zhao, S., Wang, C., Hu, M., Yan, T., & Wang, M. (2023). MCL: Multi-Granularity Contrastive Learning Framework for Chinese NER. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 14011-14019. https://doi.org/10.1609/aaai.v37i11.26640","Abstract 					Recently, researchers have applied the word-character lattice framework to integrated word information, which has become very popular for  Chinese named entity recognition (NER). However, prior approaches  fuse word  information by different variants of encoders such as Lattice LSTM or Flat-Lattice Transformer, but are still not data-efficient indeed to fully  grasp the depth interaction of cross-granularity and important word information from the lexicon. In this paper, we go beyond the typical lattice structure and propose a novel  Multi-Granularity Contrastive Learning  framework (MCL), that aims to optimize the inter-granularity  distribution distance and emphasize the critical matched words in the lexicon. By carefully combining cross-granularity contrastive learning and bi-granularity contrastive learning, the network can explicitly leverage lexicon information  on the  initial lattice structure, and further provide more dense interactions of across-granularity, thus significantly improving model performance. Experiments on four Chinese NER datasets show that MCL obtains state-of-the-art results while considering model efficiency. The source code of the proposed method is publicly available at https://github.com/zs50910/MCL","https://ojs.aaai.org/index.php/AAAI/article/view/26640/26412"
"26641","Knowledge-Bridged Causal Interaction Network for Causal Emotion Entailment","['Weixiang Zhao', 'Yanyan Zhao', 'Zhuojun Li', 'Bing Qin']","['Harbin Institute of Technology', 'Harbin Institute of Technology', 'Harbin Institute of Technology', 'Harbin Institute of Technology']","['SNLP: Sentiment Analysis and Stylistic Analysis']","Zhao, W., Zhao, Y., Li, Z., & Qin, B. (2023). Knowledge-Bridged Causal Interaction Network for Causal Emotion Entailment. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 14020-14028. https://doi.org/10.1609/aaai.v37i11.26641","Abstract 					Causal Emotion Entailment aims to identify causal utterances that are responsible for the target utterance with a non-neutral emotion in conversations. Previous works are limited in thorough understanding of the conversational context and accurate reasoning of the emotion cause. To this end, we propose Knowledge-Bridged Causal Interaction Network (KBCIN) with commonsense knowledge (CSK) leveraged as three bridges. Specifically, we construct a conversational graph for each conversation and leverage the event-centered CSK as the semantics-level bridge (S-bridge) to capture the deep inter-utterance dependencies in the conversational context via the CSK-Enhanced Graph Attention module. Moreover, social-interaction CSK serves as emotion-level bridge (E-bridge) and action-level bridge (A-bridge) to connect candidate utterances with the target one, which provides explicit causal clues for the Emotional Interaction module and Actional Interaction module to reason the target emotion. Experimental results show that our model achieves better performance over most baseline models. Our source code is publicly available at https://github.com/circle-hit/KBCIN.","https://ojs.aaai.org/index.php/AAAI/article/view/26641/26413"
"26642","Query Your Model with Definitions in FrameNet: An Effective Method for Frame Semantic Role Labeling","['Ce Zheng', 'Yiming Wang', 'Baobao Chang']","['Peking University', 'Peking University', 'Peking University']","['SNLP: Lexical & Frame Semantics', 'Semantic Parsing', 'SNLP: Information Extraction', 'SNLP: Language Models']","Zheng, C., Wang, Y., & Chang, B. (2023). Query Your Model with Definitions in FrameNet: An Effective Method for Frame Semantic Role Labeling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 14029-14037. https://doi.org/10.1609/aaai.v37i11.26642","Abstract 					Frame Semantic Role Labeling (FSRL) identifies arguments and labels them with frame semantic roles defined in FrameNet. Previous researches tend to divide FSRL into argument identification and role classification. Such methods usually model role classification as naive multi-class classification and treat arguments individually, which neglects label semantics and interactions between arguments and thus hindering performance and generalization of models. In this paper, we propose a query-based framework named ArGument Extractor with Definitions in FrameNet (AGED) to mitigate these problems. Definitions of frames and frame elements (FEs) in FrameNet can be used to query arguments in text. Encoding text-definition pairs can guide models in learning label semantics and strengthening argument interactions. Experiments show that AGED outperforms previous state-of-the-art by up to 1.3 F1-score in two FrameNet datasets and the generalization power of AGED in zero-shot and fewshot scenarios. Our code and technical appendix is available at https://github.com/PKUnlp-icler/AGED.","https://ojs.aaai.org/index.php/AAAI/article/view/26642/26414"
"26643","Event Process Typing via Hierarchical Optimal Transport","['Bo Zhou', 'Yubo Chen', 'Kang Liu', 'Jun Zhao']","['School of Artificial Intelligence, University of Chinese Academy of Sciences\nNational Laboratory of Pattern Recognition, CASIA', 'School of Artificial Intelligence, University of Chinese Academy of Sciences\nNational Laboratory of Pattern Recognition, CASIA', 'School of Artificial Intelligence, University of Chinese Academy of Sciences\nNational Laboratory of Pattern Recognition, CASIA\nBeijing Academy of Artificial Intelligence', 'School of Artificial Intelligence, University of Chinese Academy of Sciences\nNational Laboratory of Pattern Recognition, CASIA']","['SNLP: Sentence-Level Semantics and Textual Inference']","Zhou, B., Chen, Y., Liu, K., & Zhao, J. (2023). Event Process Typing via Hierarchical Optimal Transport. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 14038-14046. https://doi.org/10.1609/aaai.v37i11.26643","Abstract 					Understanding intention behind event processes in texts is important to many applications. One challenging task in this line is event process typing, which aims to tag the process with one action label and one object label describing the overall action of the process and object the process likely affects respectively. To tackle this task, existing methods mainly rely on the matching of the event process level and label level representation, which ignores two important characteristics: Process Hierarchy and Label Hierarchy. In this paper, we propose a Hierarchical Optimal Transport (HOT) method to address the above problem. Specifically, we first explicitly extract the process hierarchy and label hierarchy. Then the HOT optimally matches the two types of hierarchy. Experimental results show that our model outperforms the baseline models, illustrating the effectiveness of our model.","https://ojs.aaai.org/index.php/AAAI/article/view/26643/26415"
"26644","Improving Distantly Supervised Relation Extraction by Natural Language Inference","['Kang Zhou', 'Qiao Qiao', 'Yuepei Li', 'Qi Li']","['Iowa State University', 'Iowa State University', 'Iowa State University', 'Iowa State University']","['SNLP: Information Extraction', 'SNLP: Text Mining']","Zhou, K., Qiao, Q., Li, Y., & Li, Q. (2023). Improving Distantly Supervised Relation Extraction by Natural Language Inference. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 14047-14055. https://doi.org/10.1609/aaai.v37i11.26644","Abstract 					To reduce human annotations for relation extraction (RE) tasks, distantly supervised approaches have been proposed, while struggling with low performance. In this work, we propose a novel DSRE-NLI framework, which considers both distant supervision from existing knowledge bases and indirect supervision from pretrained language models for other tasks. DSRE-NLI energizes an off-the-shelf natural language inference (NLI) engine with a semi-automatic relation verbalization (SARV) mechanism to provide indirect supervision and further consolidates the distant annotations to benefit multi-classification RE models. The NLI-based indirect supervision acquires only one relation verbalization template from humans as a semantically general template for each relationship, and then the template set is enriched by high-quality textual patterns automatically mined from the distantly annotated corpus. With two simple and effective data consolidation strategies, the quality of training data is substantially improved. Extensive experiments demonstrate that the proposed framework significantly improves the SOTA performance (up to 7.73% of F1) on distantly supervised RE benchmark datasets. Our code is available at https://github.com/kangISU/DSRE-NLI.","https://ojs.aaai.org/index.php/AAAI/article/view/26644/26416"
"26645","A Generative Approach for Script Event Prediction via Contrastive Fine-Tuning","['Fangqi Zhu', 'Jun Gao', 'Changlong Yu', 'Wei Wang', 'Chen Xu', 'Xin Mu', 'Min Yang', 'Ruifeng Xu']","['Harbin Institute of Technology, Shenzhen', 'Harbin Institute of Technology, Shenzhen', 'Independent Researcher', 'Independent Researcher', 'Beijing University of Technology', 'Peng Cheng Laboratory', 'Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences', 'Harbin Institute of Technology, Shenzhen\nPeng Cheng Laboratory\nGuangdong Provincial Key Laboratory of Novel Security Intelligence Technologies']","['SNLP: Sentence-Level Semantics and Textual Inference', 'SNLP: Applications']","Zhu, F., Gao, J., Yu, C., Wang, W., Xu, C., Mu, X., Yang, M., & Xu, R. (2023). A Generative Approach for Script Event Prediction via Contrastive Fine-Tuning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 14056-14064. https://doi.org/10.1609/aaai.v37i11.26645","Abstract 					Script event prediction aims to predict the subsequent event given the context. This requires the capability to infer the correlations between events. Recent works have attempted to improve event correlation reasoning by using pretrained language models and incorporating external knowledge (e.g., discourse relations). Though promising results have been achieved, some challenges still remain. First, the pretrained language models adopted by current works ignore event-level knowledge, resulting in an inability to capture the correlations between events well. Second, modeling correlations between events with discourse relations is limited because it can only capture explicit correlations between events with discourse markers, and cannot capture many implicit correlations. To this end, we propose a novel generative approach for this task, in which a pretrained language model is fine-tuned with an event-centric pretraining objective and predicts the next event within a generative paradigm. Specifically, we first introduce a novel event-level blank infilling strategy as the learning objective to inject event-level knowledge into the pretrained language model, and then design a likelihood-based contrastive loss for fine-tuning the generative model. Instead of using an additional prediction layer, we perform prediction by using sequence likelihoods generated by the generative model. Our approach models correlations between events in a soft way without any external knowledge. The likelihood-based prediction eliminates the need to use additional networks to make predictions and is somewhat interpretable since it scores each word in the event. Experimental results on the multi-choice narrative cloze (MCNC) task demonstrate that our approach achieves better results than other state-of-the-art baselines. Our code will be available at https://github.com/zhufq00/mcnc.","https://ojs.aaai.org/index.php/AAAI/article/view/26645/26417"
"26646","KPT: Keyword-Guided Pre-training for Grounded Dialog Generation","['Qi Zhu', 'Fei Mi', 'Zheng Zhang', 'Yasheng Wang', 'Yitong Li', 'Xin Jiang', 'Qun Liu', 'Xiaoyan Zhu', 'Minlie Huang']","['Tsinghua University', 'Huawei Noah’s Ark Lab', 'Tsinghua University', 'Huawei Noah’s Ark Lab', 'Huawei Technologies Co., Ltd.', ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", 'Tsinghua University', 'Tsinghua University']","['SNLP: Conversational AI/Dialogue Systems', 'SNLP: Generation']","Zhu, Q., Mi, F., Zhang, Z., Wang, Y., Li, Y., Jiang, X., Liu, Q., Zhu, X., & Huang, M. (2023). KPT: Keyword-Guided Pre-training for Grounded Dialog Generation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 14065-14073. https://doi.org/10.1609/aaai.v37i11.26646","Abstract 					Incorporating external knowledge into the response generation process is essential to building more helpful and reliable dialog agents. However, collecting knowledge-grounded conversations is often costly, calling for a better pre-trained model for grounded dialog generation that generalizes well w.r.t. different types of knowledge. In this work, we propose KPT (Keyword-guided Pre-Training), a novel self-supervised pre-training method for grounded dialog generation without relying on extra knowledge annotation. Specifically, we use a pre-trained language model to extract the most uncertain tokens in the dialog as keywords. With these keywords, we construct two kinds of knowledge and pre-train a knowledge-grounded response generation model, aiming at handling two different scenarios: (1) the knowledge should be faithfully grounded; (2) it can be selectively used. For the former, the grounding knowledge consists of keywords extracted from the response. For the latter, the grounding knowledge is additionally augmented with keywords extracted from other utterances in the same dialog. Since the knowledge is extracted from the dialog itself, KPT can be easily performed on a large volume and variety of dialogue data.  We considered three data sources (open-domain, task-oriented, conversational QA) with a total of 2.5M dialogues. We conduct extensive experiments on various few-shot knowledge-grounded generation tasks, including grounding on dialog acts, knowledge graphs, persona descriptions, and Wikipedia passages. Our comprehensive experiments and analyses demonstrate that KPT consistently outperforms state-of-the-art methods on these tasks with diverse grounding knowledge.","https://ojs.aaai.org/index.php/AAAI/article/view/26646/26418"
"26647","An Ensemble Distillation Framework for Sentence Embeddings with Multilingual Round-Trip Translation","['Tianyu Zong', 'Likun Zhang']","['University of Chinese Academy of Sciences', 'Institute of Information Engineering, CAS, China']","['SNLP: Language Models', 'SNLP: Applications', 'SNLP: Sentence-Level Semantics and Textual Inference']","Zong, T., & Zhang, L. (2023). An Ensemble Distillation Framework for Sentence Embeddings with Multilingual Round-Trip Translation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(11), 14074-14082. https://doi.org/10.1609/aaai.v37i11.26647","Abstract 					In this work, we propose a novel unsupervised contrastive learning framework to improve state-of-the-art sentence embeddings. First, we train a set of contrastive submodels which take multilingual round-trip translation(RTT) as data augmentation. The RTT naturally changes the length of the same sentence and replaces Synonyms simultaneously. Then we incorporate them into a single model through knowledge distillation. Specifically, it takes an input sentence and predicts the ensemble output of all submodels via a contrastive objective. Thus we preserve nearly the same semantic expressiveness as the ensemble model without increasing the test cost. We evaluate our framework on standard semantic textual similarity (STS) tasks. Experimental results show the advantage of our framework that we achieve an average of 79.27% Spearman's correlation, a 3.02% improvement compared to the previous best results using BERT-base.","https://ojs.aaai.org/index.php/AAAI/article/view/26647/26419"
"26648","COSMOS: Catching Out-of-Context Image Misuse Using Self-Supervised Learning","['Shivangi Aneja', 'Chris Bregler', 'Matthias Niessner']","['Technical University Of Munich', 'Google Research', 'Technical University of Munich']","['General']","Aneja, S., Bregler, C., & Niessner, M. (2023). COSMOS: Catching Out-of-Context Image Misuse Using Self-Supervised Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14084-14092. https://doi.org/10.1609/aaai.v37i12.26648","Abstract 					Despite the recent attention to DeepFakes, one of the most prevalent ways to mislead audiences on social media is the use of unaltered images in a new but false context. We propose a new method that automatically highlights out-of-context image and text pairs, for assisting fact-checkers. Our key insight is to leverage the grounding of images with text to distinguish out-of-context scenarios that cannot be disambiguated with language alone. We propose a self-supervised training strategy where we only need a set of captioned images. At train time, our method learns to selectively align individual objects in an image with textual claims, without explicit supervision. At test time, we check if both captions correspond to the same object(s) in the image but are semantically different, which allows us to make fairly accurate out-of-context predictions. Our method achieves 85% out-of-context detection accuracy. To facilitate benchmarking of this task, we create a large-scale dataset of 200K images with 450K textual captions from a variety of news websites, blogs, and social media posts","https://ojs.aaai.org/index.php/AAAI/article/view/26648/26420"
"26649","Med-EASi: Finely Annotated Dataset and Models for Controllable Simplification of Medical Texts","['Chandrayee Basu', 'Rosni Vasu', 'Michihiro Yasunaga', 'Qian Yang']","['Stanford University', 'University of Zurich', 'Stanford University', 'Cornell University']","['General']","Basu, C., Vasu, R., Yasunaga, M., & Yang, Q. (2023). Med-EASi: Finely Annotated Dataset and Models for Controllable Simplification of Medical Texts. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14093-14101. https://doi.org/10.1609/aaai.v37i12.26649","Abstract 					Automatic medical text simplification can assist providers with patient-friendly communication and make medical texts more accessible, thereby improving health literacy. But curating a quality corpus for this task requires the supervision of medical experts. In this work, we present Med-EASi (Medical dataset for Elaborative and Abstractive Simplification), a uniquely crowdsourced and finely annotated dataset for supervised simplification of short medical texts. Its expert-layman-AI collaborative annotations facilitate controllability over text simplification by marking four kinds of textual transformations: elaboration, replacement, deletion, and insertion. To learn medical text simplification, we fine-tune T5-large with four different styles of input-output combinations, leading to two control-free and two controllable versions of the model. We add two types of controllability into text simplification, by using a multi-angle training approach: position-aware, which uses in-place annotated inputs and outputs, and position-agnostic, where the model only knows the contents to be edited, but not their positions. Our results show that our fine-grained annotations improve learning compared to the unannotated baseline. Furthermore, our position-aware control enhances the model's ability to generate better simplification than the position-agnostic version. The data and code are available at https://github.com/Chandrayee/CTRL-SIMP.","https://ojs.aaai.org/index.php/AAAI/article/view/26649/26421"
"26650","On the Challenges of Using Reinforcement Learning in Precision Drug Dosing: Delay and Prolongedness of Action Effects","['Sumana Basu', 'Marc-André Legault', 'Adriana Romero-Soriano', 'Doina Precup']","['McGill University\nMila', 'McGill University\nMila', 'McGill University\nMila\nMeta AI', 'McGill University\nMila']","['General']","Basu, S., Legault, M.-A., Romero-Soriano, A., & Precup, D. (2023). On the Challenges of Using Reinforcement Learning in Precision Drug Dosing: Delay and Prolongedness of Action Effects. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14102-14109. https://doi.org/10.1609/aaai.v37i12.26650","Abstract 					Drug dosing is an important application of AI, which can be formulated as a Reinforcement Learning (RL) problem. In this paper, we identify two major challenges of using RL for drug dosing: delayed and prolonged effects of administering medications, which break the Markov assumption of the RL framework. We focus on prolongedness and define PAE-POMDP (Prolonged Action Effect-Partially Observable Markov Decision Process), a subclass of POMDPs in which the Markov assumption does not hold specifically due to prolonged effects of actions. Motivated by the pharmacology literature, we propose a simple and effective approach to converting drug dosing PAE-POMDPs into MDPs, enabling the use of the existing RL algorithms to solve such problems. We validate the proposed approach on a toy task, and a challenging glucose control task, for which we devise a clinically-inspired reward function. Our results demonstrate that: (1) the proposed method to restore the Markov assumption leads to significant improvements over a vanilla baseline; (2) the approach is competitive with recurrent policies which may inherently capture the prolonged affect of actions; (3) it is remarkably more time and memory efficient than the recurrent baseline and hence more suitable for real-time dosing control systems; and (4) it exhibits favourable qualitative behavior in our policy analysis.","https://ojs.aaai.org/index.php/AAAI/article/view/26650/26422"
"26651","On the Cost of Demographic Parity in Influence Maximization","['Ruben Becker', ""Gianlorenzo D'Angelo"", 'Sajjad Ghobadi']","['Ca’ Foscari University of Venice, Italy', 'Gran Sasso Science Institute, L’Aquila, Italy', 'Gran Sasso Science Institute, L’Aquila, Italy']","['General']","Becker, R., D’Angelo, G., & Ghobadi, S. (2023). On the Cost of Demographic Parity in Influence Maximization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14110-14118. https://doi.org/10.1609/aaai.v37i12.26651","Abstract 					Modeling and shaping how information spreads through a network is a major research topic in network analysis. While initially the focus has been mostly on efficiency, recently fairness criteria have been taken into account in this setting. Most work has focused on the maximin criteria however, and thus still different groups can receive very different shares of information. In this work we propose to consider fairness as a notion to be guaranteed by an algorithm rather than as a criterion to be maximized. To this end, we propose three optimization problems that aim at maximizing the overall spread while enforcing strict levels of demographic parity fairness via constraints (either ex-post or ex-ante). The level of fairness hence becomes a user choice rather than a property to be observed upon output. We study this setting from various perspectives. First, we prove that the cost of introducing demographic parity can be high in terms of both overall spread and computational complexity, i.e., the price of fairness may be unbounded for all three problems and optimal solutions are hard to compute, in some case even approximately or when fairness constraints may be violated.  For one of our problems, we still design an algorithm with both constant approximation factor and fairness violation. We also give two heuristics that allow the user to choose the tolerated fairness violation. By means of an extensive experimental study, we show that our algorithms perform well in practice, that is, they achieve the best demographic parity fairness values. For certain instances we additionally even obtain an overall spread comparable to the most efficient algorithms that come without any fairness guarantee, indicating that the empirical price of fairness may actually be small when using our algorithms.","https://ojs.aaai.org/index.php/AAAI/article/view/26651/26423"
"26652","Improving Fairness in Information Exposure by Adding Links","['Ruben Becker', ""Gianlorenzo D'Angelo"", 'Sajjad Ghobadi']","['Ca’ Foscari University of Venice, Italy', 'Gran Sasso Science Institute, L’Aquila, Italy', 'Gran Sasso Science Institute, L’Aquila, Italy']","['General']","Becker, R., D’Angelo, G., & Ghobadi, S. (2023). Improving Fairness in Information Exposure by Adding Links. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14119-14126. https://doi.org/10.1609/aaai.v37i12.26652","Abstract 					Fairness in influence maximization has been a very active research topic recently. Most works in this context study the question of how to find seeding strategies (deterministic or probabilistic) such that nodes or communities in the network get their fair share of coverage. Different fairness criteria have been used in this context. All these works assume that the entity that is spreading the information has an inherent interest in spreading the information fairly, otherwise why would they want to use the developed fair algorithms? This assumption may however be flawed in reality -- the spreading entity may be purely efficiency-oriented. In this paper we propose to study two optimization problems with the goal to modify the network structure by adding links in such a way that efficiency-oriented information spreading becomes automatically fair. We study the proposed optimization problems both from a theoretical and experimental perspective, that is, we give several hardness and hardness of approximation results, provide efficient algorithms for some special cases, and more importantly provide heuristics for solving one of the problems in practice. In our experimental study we then first compare the proposed heuristics against each other and establish the most successful one. In a second experiment, we then show that our approach can be very successful in practice. That is, we show that already after adding a few edges to the networks the greedy algorithm that purely maximizes spread surpasses all fairness-tailored algorithms in terms of ex-post fairness. Maybe surprisingly, we even show that our approach achieves ex-post fairness values that are comparable or even better than the ex-ante fairness values of the currently most efficient algorithms that optimize ex-ante fairness.","https://ojs.aaai.org/index.php/AAAI/article/view/26652/26424"
"26653","A Fair Incentive Scheme for Community Health Workers","['Avinandan Bose', 'Tracey Li', 'Arunesh Sinha', 'Tien Mai']","['University of Washington', 'D-tree International', 'Rutgers University', 'Singapore Management University']","['General']","Bose, A., Li, T., Sinha, A., & Mai, T. (2023). A Fair Incentive Scheme for Community Health Workers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14127-14135. https://doi.org/10.1609/aaai.v37i12.26653","Abstract 					Community health workers (CHWs) play a crucial role in the last mile delivery of essential health services to underserved populations in low-income countries. Many nongovernmental organizations (NGOs) provide training and support to enable CHWs to deliver health services to their communities, with no charge to the recipients of the services. This includes monetary compensation for the work that CHWs perform, which is broken down into a series of well defined tasks. In this work, we partner with a NGO D-Tree International to design a fair monetary compensation scheme for tasks performed by CHWs in the semi-autonomous region of Zanzibar in Tanzania, Africa. In consultation with stakeholders, we interpret fairness as the equal opportunity to earn, which means that each CHW has the opportunity to earn roughly the same total payment over a given T month period, if the CHW reacts to the incentive scheme almost rationally. We model this problem as a reward design problem for a Markov Decision Process (MDP) formulation for the CHWs’ earning. There is a need for the mechanism to be simple so that it is understood by the CHWs, thus, we explore linear and piecewise linear rewards in the CHWs’ measured units of work. We solve this design problem via a novel policy-reward gradient result. Our experiments using two real world parameters from the ground provide evidence of reasonable incentive output by our scheme.","https://ojs.aaai.org/index.php/AAAI/article/view/26653/26425"
"26654","Rehabilitating Homeless: Dataset and Key Insights","['Anna Bykova', 'Nikolay Filippov', 'Ivan P. Yamshchikov']","['LEYA Lab for Natural Language Processing, Higher School of Economics, Yandex, St. Petersburg, Russia', 'LEYA Lab for Natural Language Processing, Higher School of Economics, Yandex, St. Petersburg, Russia', 'Center for Artificial Intelligence and Robotics (CAIRO), THWS, Würzburg, Germany\nCEMAPRE, University of Lisbon, Portugal']","['General']","Bykova, A., Filippov, N., & Yamshchikov, I. P. (2023). Rehabilitating Homeless: Dataset and Key Insights. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14136-14143. https://doi.org/10.1609/aaai.v37i12.26654","Abstract 					This paper presents a large anonymized dataset of homelessness alongside insights into the data-driven rehabilitation of homeless people. The dataset was gathered by a large non-profit organization working on rehabilitating the homeless for twenty years. This is the first dataset that we know of that contains rich information on thousands of homeless individuals seeking rehabilitation. We show how data analysis can help to make the rehabilitation of homeless people more effective and successful. Thus, we hope this paper alerts the data science community to the problem of homelessness.","https://ojs.aaai.org/index.php/AAAI/article/view/26654/26426"
"26655","Counterfactuals for the Future","['Lucius E. J. Bynum', 'Joshua R. Loftus', 'Julia Stoyanovich']","['New York University', 'London School of Economics', 'New York University']","['General']","Bynum, L. E. J., Loftus, J. R., & Stoyanovich, J. (2023). Counterfactuals for the Future. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14144-14152. https://doi.org/10.1609/aaai.v37i12.26655","Abstract 					Counterfactuals are often described as 'retrospective,' focusing on hypothetical alternatives to a realized past. This description relates to an often implicit assumption about the structure and stability of exogenous variables in the system being modeled --- an assumption that is reasonable in many settings where counterfactuals are used. In this work, we consider cases where we might reasonably make a different assumption about exogenous variables; namely, that the exogenous noise terms of each unit do exhibit some unit-specific structure and/or stability. This leads us to a different use of counterfactuals --- a forward-looking rather than retrospective counterfactual. We introduce ""counterfactual treatment choice,"" a type of treatment choice problem that motivates using forward-looking counterfactuals. We then explore how mismatches between interventional versus forward-looking counterfactual approaches to treatment choice, consistent with different assumptions about exogenous noise, can lead to counterintuitive results.","https://ojs.aaai.org/index.php/AAAI/article/view/26655/26427"
"26656","Towards Learning to Discover Money Laundering Sub-network in Massive Transaction Network","['Ziwei Chai', 'Yang Yang', 'Jiawang Dan', 'Sheng Tian', 'Changhua Meng', 'Weiqiang Wang', 'Yifei Sun']","['Zhejiang University', 'Zhejiang University', 'Ant Group', 'Ant Group', 'Ant Group', 'Ant Group', 'Zhejiang University']","['General']","Chai, Z., Yang, Y., Dan, J., Tian, S., Meng, C., Wang, W., & Sun, Y. (2023). Towards Learning to Discover Money Laundering Sub-network in Massive Transaction Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14153-14160. https://doi.org/10.1609/aaai.v37i12.26656","Abstract 					Anti-money laundering (AML) systems play a critical role in safeguarding global economy. As money laundering is considered as one of the top group crimes, there is a crucial need to discover money laundering sub-network behind a particular money laundering transaction for a robust AML system. However, existing rule-based methods for money laundering sub-network discovery is heavily based on domain knowledge and may lag behind the modus operandi of launderers. Therefore, in this work, we first address the money laundering sub-network discovery problem with a neural network based approach, and propose an AML framework AMAP equipped with an adaptive sub-network proposer. In particular, we design an adaptive sub-network proposer guided by a supervised contrastive loss to discriminate money laundering transactions from massive benign transactions. We conduct extensive experiments on real-word datasets in AliPay of Ant Group. The result demonstrates the effectiveness of our AMAP in both money laundering transaction detection and money laundering sub-network discovering. The learned framework which yields money laundering sub-network from massive transaction network leads to a more comprehensive risk coverage and a deeper insight to money laundering strategies.","https://ojs.aaai.org/index.php/AAAI/article/view/26656/26428"
"26657","Estimating Geographic Spillover Effects of COVID-19 Policies from Large-Scale Mobility Networks","['Serina Chang', 'Damir Vrabac', 'Jure Leskovec', 'Johan Ugander']","['Stanford University', 'Stanford University', 'Stanford University', 'Stanford University']","['General']","Chang, S., Vrabac, D., Leskovec, J., & Ugander, J. (2023). Estimating Geographic Spillover Effects of COVID-19 Policies from Large-Scale Mobility Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14161-14169. https://doi.org/10.1609/aaai.v37i12.26657","Abstract 					Many policies in the US are determined locally, e.g., at the county-level. Local policy regimes provide flexibility between regions, but may become less effective in the presence of geographic spillovers, where populations circumvent local restrictions by traveling to less restricted regions nearby. Due to the endogenous nature of policymaking, there have been few opportunities to reliably estimate causal spillover effects or evaluate their impact on local policies. In this work, we identify a novel setting and develop a suitable methodology that allow us to make unconfounded estimates of spillover effects of local policies. Focusing on California’s Blueprint for a Safer Economy, we leverage how county-level mobility restrictions were deterministically set by public COVID-19 severity statistics, enabling a regression discontinuity design framework to estimate spillovers between counties. We estimate these effects using a mobility network with billions of timestamped edges and find significant spillover movement, with larger effects in retail, eating places, and gyms. Contrasting local and global policy regimes, our spillover estimates suggest that county-level restrictions are only 54% as effective as statewide restrictions at reducing mobility. However, an intermediate strategy of macro-county restrictions---where we optimize county partitions by solving a minimum k-cut problem on a graph weighted by our spillover estimates---can recover over 90% of statewide mobility reductions, while maintaining substantial flexibility between counties.","https://ojs.aaai.org/index.php/AAAI/article/view/26657/26429"
"26658","Seq2Seq Surrogates of Epidemic Models to Facilitate Bayesian Inference","['Giovanni Charles', 'Timothy M. Wolock', 'Peter Winskill', 'Azra Ghani', 'Samir Bhatt', 'Seth Flaxman']","['Imperial College London', 'Imperial College London', 'Imperial College London', 'Imperial College London', 'University of Copenhagen', 'Oxford University']","['General']","Charles, G., Wolock, T. M., Winskill, P., Ghani, A., Bhatt, S., & Flaxman, S. (2023). Seq2Seq Surrogates of Epidemic Models to Facilitate Bayesian Inference. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14170-14177. https://doi.org/10.1609/aaai.v37i12.26658","Abstract 					Epidemic models are powerful tools in understanding infectious disease. However, as they increase in size and complexity, they can quickly become computationally intractable. Recent progress in modelling methodology has shown that surrogate models can be used to emulate complex epidemic models with a high-dimensional parameter space. We show that deep sequence-to-sequence (seq2seq) models can serve as accurate surrogates for complex epidemic models with sequence based model parameters, effectively replicating seasonal and long-term transmission dynamics. Once trained, our surrogate can predict scenarios a several thousand times faster than the original model, making them ideal for policy exploration. We demonstrate that replacing a traditional epidemic model with a learned simulator facilitates robust Bayesian inference.","https://ojs.aaai.org/index.php/AAAI/article/view/26658/26430"
"26659","Leveraging Old Knowledge to Continually Learn New Classes in Medical Images","['Evelyn Chee', 'Mong Li Lee', 'Wynne Hsu']","['National University of Singapore', 'National University of Singapore', 'National University of Singapore']","['General']","Chee, E., Lee, M. L., & Hsu, W. (2023). Leveraging Old Knowledge to Continually Learn New Classes in Medical Images. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14178-14186. https://doi.org/10.1609/aaai.v37i12.26659","Abstract 					Class-incremental continual learning is a core step towards developing artificial intelligence systems that can continuously adapt to changes in the environment by learning new concepts without forgetting those previously learned. This is especially needed in the medical domain where continually learning from new incoming data is required to classify an expanded set of diseases. In this work, we focus on how old knowledge can be leveraged to learn new classes without catastrophic forgetting. We propose a framework that comprises of two main components: (1) a dynamic architecture with expanding representations to preserve previously learned features and accommodate new features; and (2) a training procedure alternating between two objectives to balance the learning of new features while maintaining the model’s performance on old classes. Experiment results on multiple medical datasets show that our solution is able to achieve superior performance over state-of-the-art baselines in terms of class accuracy and forgetting.","https://ojs.aaai.org/index.php/AAAI/article/view/26659/26431"
"26660","SARAS-Net: Scale and Relation Aware Siamese Network for Change Detection","['Chao-Peng Chen', 'Jun-Wei Hsieh', 'Ping-Yang Chen', 'YI-Kuan Hsieh', 'Bor-Shiun Wang']","['National Yang Ming Chiao Tung University', 'National Yang Ming Chiao Tung University', 'Department of Computer Science, National Yang Ming Chiao Tung University', 'National Yang Ming Chiao Tung University', 'National Yang Ming Chiao Tung University']","['General']","Chen, C.-P., Hsieh, J.-W., Chen, P.-Y., Hsieh, Y.-K., & Wang, B.-S. (2023). SARAS-Net: Scale and Relation Aware Siamese Network for Change Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14187-14195. https://doi.org/10.1609/aaai.v37i12.26660","Abstract 					Change detection (CD) aims to find the difference between two images at different times and output a change map to represent whether the region has changed or not. To achieve a better result in generating the change map, many State-of-The-Art (SoTA) methods design a deep learning model that has a powerful discriminative ability. However, these methods still get lower performance because they ignore spatial information and scaling changes between objects, giving rise to blurry boundaries. In addition to these, they also neglect the interactive information of two different images. To alleviate these problems, we propose our network, the Scale and Relation-Aware Siamese Network (SARAS-Net) to deal with this issue. In this paper, three modules are proposed that include relation-aware, scale-aware, and cross-transformer to tackle the problem of scene change detection more effectively.  To verify our model, we tested three public datasets, including LEVIR-CD, WHU-CD, and DSFIN, and obtained SoTA accuracy. Our code is available at https://github.com/f64051041/SARAS-Net.","https://ojs.aaai.org/index.php/AAAI/article/view/26660/26432"
"26661","Improving Interpretability of Deep Sequential Knowledge Tracing Models with Question-centric Cognitive Representations","['Jiahao Chen', 'Zitao Liu', 'Shuyan Huang', 'Qiongqiong Liu', 'Weiqi Luo']","['TAL Education Group', 'Jinan University', 'TAL Education Group', 'TAL Education Group', 'Jinan University']","['General']","Chen, J., Liu, Z., Huang, S., Liu, Q., & Luo, W. (2023). Improving Interpretability of Deep Sequential Knowledge Tracing Models with Question-centric Cognitive Representations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14196-14204. https://doi.org/10.1609/aaai.v37i12.26661","Abstract 					Knowledge tracing (KT) is a crucial technique to predict students’ future performance by observing their historical learning processes. Due to the powerful representation ability of deep neural networks, remarkable progress has been made by using deep learning techniques to solve the KT problem. The majority of existing approaches rely on the homogeneous question assumption that questions have equivalent contributions if they share the same set of knowledge components. Unfortunately, this assumption is inaccurate in real-world educational scenarios. Furthermore, it is very challenging to interpret the prediction results from the existing deep learning based KT models. Therefore, in this paper, we present QIKT, a question-centric interpretable KT model to address the above challenges. The proposed QIKT approach explicitly models students’ knowledge state variations at a ﬁne-grained level with question-sensitive cognitive representations that are jointly learned from a question-centric knowledge acquisition module and a question-centric problem solving module. Meanwhile, the QIKT utilizes an item response theory based prediction layer to generate interpretable prediction results. The proposed QIKT model is evaluated on three public real-world educational datasets. The results demonstrate that our approach is superior on the KT prediction task, and it outperforms a wide range of deep learning based KT models in terms of prediction accuracy with better model interpretability. To encourage reproducible results, we have provided all the datasets and code at https://pykt.org/.","https://ojs.aaai.org/index.php/AAAI/article/view/26661/26433"
"26662","Critical Firms Prediction for Stemming Contagion Risk in Networked-Loans through Graph-Based Deep Reinforcement Learning","['Dawei Cheng', 'Zhibin Niu', 'Jianfu Zhang', 'Yiyi Zhang', 'Changjun Jiang']","['Tongji University\nKey Laboratory of Artificial Intelligence, Ministry of Education\nShanghai Artificial Intelligence Laboratory', 'Tianjin University', 'Shanghai Jiao Tong University\nKey Laboratory of Artificial Intelligence, Ministry of Education', 'Shanghai Jiao Tong University\nKey Laboratory of Artificial Intelligence, Ministry of Education', 'Tongji University\nShanghai Artificial Intelligence Laboratory']","['General']","Cheng, D., Niu, Z., Zhang, J., Zhang, Y., & Jiang, C. (2023). Critical Firms Prediction for Stemming Contagion Risk in Networked-Loans through Graph-Based Deep Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14205-14213. https://doi.org/10.1609/aaai.v37i12.26662","Abstract 					The networked-loan is major financing support for Micro, Small and Medium-sized Enterprises (MSMEs) in some developing countries. But external shocks may weaken the financial networks' robustness; an accidental default may spread across the network and collapse the whole network. Thus, predicting the critical firms in networked-loans to stem contagion risk and prevent potential systemic financial crises is of crucial significance to the long-term health of inclusive finance and sustainable economic development. Existing approaches in the banking industry dismiss the contagion risk across loan networks and need extensive knowledge with sophisticated financial expertise. Regarding the issues, we propose a novel approach to predict critical firms for stemming contagion risk in the bank industry with deep reinforcement learning integrated with high-order graph message-passing networks. We demonstrate that our approach outperforms the state-of-the-art baselines significantly on the dataset from a large commercial bank. Moreover, we also conducted empirical studies on the real-world loan dataset for risk mitigation. The proposed approach enables financial regulators and risk managers to better track and understands contagion and systemic risk in networked-loans. The superior performance also represents a paradigm shift in addressing the modern challenges in financing support of MSMEs and sustainable economic development.","https://ojs.aaai.org/index.php/AAAI/article/view/26662/26434"
"26663","GAN-Based Domain Inference Attack","['Yuechun Gu', 'Keke Chen']","['Marquette University', 'Marquette University']","['General']","Gu, Y., & Chen, K. (2023). GAN-Based Domain Inference Attack. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14214-14222. https://doi.org/10.1609/aaai.v37i12.26663","Abstract 					Model-based attacks can infer training data information from deep neural network models. These attacks heavily depend on the attacker's knowledge of the application domain, e.g., using it to determine the auxiliary data for model-inversion attacks. However, attackers may not know what the model is used for in practice. We propose a generative adversarial network (GAN) based method to explore likely or similar domains of a target model -- the model domain inference (MDI) attack. For a given target (classification) model, we assume that the attacker knows nothing but the input and output formats and can use the model to derive the prediction for any input in the desired form. Our basic idea is to use the target model to affect a GAN training process for a candidate domain's dataset that is easy to obtain. We find that the target model may distort the training procedure less if the domain is more similar to the target domain. We then measure the distortion level with the distance between GAN-generated datasets, which can be used to rank candidate domains for the target model. Our experiments show that the auxiliary dataset from an MDI top-ranked domain can effectively boost the result of model-inversion attacks.","https://ojs.aaai.org/index.php/AAAI/article/view/26663/26435"
"26664","Physics Guided Neural Networks for Time-Aware Fairness: An Application in Crop Yield Prediction","['Erhu He', 'Yiqun Xie', 'Licheng Liu', 'Weiye Chen', 'Zhenong Jin', 'Xiaowei Jia']","['University of Pittsburgh', 'The University of Maryland, College Park', 'University of Minnesota', 'University of Maryland, College Park', 'University of Minnesota', 'University of Pittsburgh']","['General']","He, E., Xie, Y., Liu, L., Chen, W., Jin, Z., & Jia, X. (2023). Physics Guided Neural Networks for Time-Aware Fairness: An Application in Crop Yield Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14223-14231. https://doi.org/10.1609/aaai.v37i12.26664","Abstract 					This paper proposes a physics-guided neural network model to predict crop yield and maintain the fairness over space. Failures to preserve the spatial fairness in predicted maps of crop yields can result in biased policies and intervention strategies in the distribution of assistance or subsidies in supporting individuals at risk. Existing methods for fairness enforcement are not designed for capturing the complex physical processes that underlie the crop growing process, and thus are unable to produce good predictions over large regions under different weather conditions and soil properties. More importantly, the fairness is often degraded when existing methods are applied to different years due to the change of weather conditions and farming practices. To address these issues, we propose a physics-guided neural network model, which leverages the physical knowledge from existing physics-based models to guide the extraction of representative physical information and discover the temporal data shift across years. In particular, we use a reweighting strategy to discover the relationship between training years and testing years using the physics-aware representation. Then the physics-guided neural network will be refined via a bi-level optimization process based on the reweighted fairness objective. The proposed method has been evaluated using real county-level crop yield data and simulated data produced by a physics-based model. The results demonstrate that this method can significantly improve the predictive performance and preserve the spatial fairness when generalized to different years.","https://ojs.aaai.org/index.php/AAAI/article/view/26664/26436"
"26665","“Nothing Abnormal”: Disambiguating Medical Reports via Contrastive Knowledge Infusion","['Zexue He', 'An Yan', 'Amilcare Gentili', 'Julian McAuley', 'Chun-Nan Hsu']","['University of California, San Diego', 'University of California, San Diego', 'University of California, San Diego\nVA San Diego Healthcare System', 'University of California, San Diego', 'University of California, San Diego\nVA San Diego Healthcare System\nVA National AI Institute']","['General']","He, Z., Yan, A., Gentili, A., McAuley, J., & Hsu, C.-N. (2023). “Nothing Abnormal”: Disambiguating Medical Reports via Contrastive Knowledge Infusion. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14232-14240. https://doi.org/10.1609/aaai.v37i12.26665","Abstract 					Sharing medical reports is essential for patient-centered care. A recent line of work has focused on automatically generating reports with NLP methods. However, different audiences have different purposes when writing/reading medical reports – for example, healthcare professionals care more about pathology, whereas patients are more concerned with the diagnosis (""Is there any abnormality?""). The expectation gap results in a common situation where patients find their medical reports to be ambiguous and therefore unsure about the next steps. In this work, we explore the audience expectation gap in healthcare and summarize common ambiguities that lead patients to be confused about their diagnosis into three categories: medical jargon, contradictory findings, and misleading grammatical errors. Based on our analysis, we define a disambiguation rewriting task to regenerate an input to be unambiguous while preserving information about the original content. We further propose a rewriting algorithm based on contrastive pretraining and perturbation-based rewriting. In addition, we create two datasets, OpenI-Annotated based on chest reports and VA-Annotated based on general medical reports, with available binary labels for ambiguity and abnormality presence annotated by radiology specialists. Experimental results on these datasets show that our proposed algorithm effectively rewrites input sentences in a less ambiguous way with high content fidelity. Our code and annotated data will be released to facilitate future research.","https://ojs.aaai.org/index.php/AAAI/article/view/26665/26437"
"26666","MTDiag: An Effective Multi-Task Framework for Automatic Diagnosis","['Zhenyu Hou', 'Yukuo Cen', 'Ziding Liu', 'Dongxue Wu', 'Baoyan Wang', 'Xuanhe Li', 'Lei Hong', 'Jie Tang']","['Tsinghua University', 'Tsinghua University', 'Meituan', 'Meituan', 'Meituan', 'Meituan', 'Meituan', 'Tsinghua University']","['General']","Hou, Z., Cen, Y., Liu, Z., Wu, D., Wang, B., Li, X., Hong, L., & Tang, J. (2023). MTDiag: An Effective Multi-Task Framework for Automatic Diagnosis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14241-14248. https://doi.org/10.1609/aaai.v37i12.26666","Abstract 					Automatic diagnosis systems aim to probe for symptoms (i.e., symptom checking) and diagnose disease through multi-turn conversations with patients. Most previous works formulate it as a sequential decision process and use reinforcement learning (RL) to decide whether to inquire about symptoms or make a diagnosis. However, these RL-based methods heavily rely on the elaborate reward function and usually suffer from an unstable training process and low data efficiency. In this work, we propose an effective multi-task framework for automatic diagnosis called MTDiag. We first reformulate symptom checking as a multi-label classification task by direct supervision. Each medical dialogue is equivalently converted into multiple samples for classification, which can also help alleviate the data scarcity problem. Furthermore, we design a multi-task learning strategy to guide the symptom checking procedure with disease information and further utilize contrastive learning to better distinguish symptoms between diseases. Extensive experimental results show that our method achieves state-of-the-art performance on four public datasets with 1.7%~3.1% improvement in disease diagnosis, demonstrating the superiority of the proposed method. Additionally, our model is now deployed in an online medical consultant system as an assistant tool for real-life doctors.","https://ojs.aaai.org/index.php/AAAI/article/view/26666/26438"
"26667","Walkability Optimization: Formulations, Algorithms, and a Case Study of Toronto","['Weimin Huang', 'Elias B. Khalil']","['University of Toronto', 'University of Toronto']","['General']","Huang, W., & Khalil, E. B. (2023). Walkability Optimization: Formulations, Algorithms, and a Case Study of Toronto. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14249-14258. https://doi.org/10.1609/aaai.v37i12.26667","Abstract 					The concept of walkable urban development has gained increased attention due to its public health, economic, and environmental sustainability benefits. Unfortunately, land zoning and historic under-investment have resulted in spatial inequality in walkability and social inequality among residents. We tackle the problem of Walkability Optimization through the lens of combinatorial optimization. The task is to select locations in which additional amenities (e.g., grocery stores, schools, restaurants) can be allocated to improve resident access via walking while taking into account existing amenities and providing multiple options (e.g., for restaurants). To this end, we derive Mixed-Integer Linear Programming (MILP) and Constraint Programming (CP) models. Moreover, we show that the problem’s objective function is submodular in special cases, which motivates an efficient greedy heuristic. We conduct a case study on 31 underserved neighborhoods in the City of Toronto, Canada. MILP finds the best solutions in most scenarios but does not scale well with network size. The greedy algorithm scales well and finds high-quality solutions. Our empirical evaluation shows that neighbourhoods with low walkability have a great potential for transformation into pedestrian-friendly neighbourhoods by strategically placing new amenities. Allocating 3 additional grocery stores, schools, and restaurants can improve the “WalkScore” by more than 50 points (on a scale of 100) for 4 neighbourhoods and reduce the walking distances to amenities for 75% of all residential locations to 10 minutes for all amenity types. Our code and paper appendix are available at https://github.com/khalil-research/walkability.","https://ojs.aaai.org/index.php/AAAI/article/view/26667/26439"
"26668","Low Emission Building Control with Zero-Shot Reinforcement Learning","['Scott Jeen', 'Alessandro Abate', 'Jonathan M. Cullen']","['University of Cambridge\nAlan Turing Institute', 'University of Oxford\nAlan Turing Institute', 'University of Cambridge']","['General']","Jeen, S., Abate, A., & Cullen, J. M. (2023). Low Emission Building Control with Zero-Shot Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14259-14267. https://doi.org/10.1609/aaai.v37i12.26668","Abstract 					Heating and cooling systems in buildings account for 31% of global energy use, much of which are regulated by Rule Based Controllers (RBCs) that neither maximise energy efficiency nor minimise emissions by interacting optimally with the grid. Control via Reinforcement Learning (RL) has been shown to significantly improve building energy efficiency, but existing solutions require access to building-specific simulators or data that cannot be expected for every building in the world. In response, we show it is possible to obtain emission-reducing policies without such knowledge a priori–a paradigm we call zero-shot building control. We combine ideas from system identification and model-based RL to create PEARL (Probabilistic Emission-Abating Reinforcement Learning) and show that a short period of active exploration is all that is required to build a performant model. In experiments across three varied building energy simulations, we show PEARL outperforms an existing RBC once, and popular RL baselines in all cases, reducing building emissions by as much as 31% whilst maintaining thermal comfort. Our source code is available online via: https://enjeeneer.io/projects/pearl/.","https://ojs.aaai.org/index.php/AAAI/article/view/26668/26440"
"26669","Spatio-Temporal Graph Neural Point Process for Traffic Congestion Event Prediction","['Guangyin Jin', 'Lingbo Liu', 'Fuxian Li', 'Jincai Huang']","['College of Systems Engineering, National University of Defense Technology', 'Department of Computer Sciences, Hong Kong Polytechnic University', 'Department of Electronic Engineering, Tsinghua University', 'College of Systems Engineering, National University of Defense Technology']","['General']","Jin, G., Liu, L., Li, F., & Huang, J. (2023). Spatio-Temporal Graph Neural Point Process for Traffic Congestion Event Prediction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14268-14276. https://doi.org/10.1609/aaai.v37i12.26669","Abstract 					Traffic congestion event prediction is an important yet challenging task in intelligent transportation systems. Many existing works about traffic prediction integrate various temporal encoders and graph convolution networks (GCNs), called spatio-temporal graph-based neural networks, which focus on predicting dense variables such as flow, speed and demand in time snapshots, but they can hardly forecast the traffic congestion events that are sparsely distributed on the continuous time axis. In recent years, neural point process (NPP) has emerged as an appropriate framework for event prediction in continuous time scenarios. However, most conventional works about NPP cannot model the complex spatio-temporal dependencies and congestion evolution patterns. To address these limitations, we propose a spatio-temporal graph neural point process framework, named STGNPP for traffic congestion event prediction. Specifically, we first design the spatio-temporal graph learning module to fully capture the long-range spatio-temporal dependencies from the historical traffic state data along with the road network. The extracted spatio-temporal hidden representation and congestion event information are then fed into a continuous gated recurrent unit to model the congestion evolution patterns. In particular, to fully exploit the periodic information, we also improve the intensity function calculation of the point process with a periodic gated mechanism. Finally, our model simultaneously predicts the occurrence time and duration of the next congestion. Extensive experiments on two real-world datasets demonstrate that our method achieves superior performance in comparison to existing state-of-the-art approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/26669/26441"
"26670","Taxonomizing and Measuring Representational Harms: A Look at Image Tagging","['Jared Katzman', 'Angelina Wang', 'Morgan Scheuerman', 'Su Lin Blodgett', 'Kristen Laird', 'Hanna Wallach', 'Solon Barocas']","['University of Michigan', 'Princeton University', 'University of Colorado Boulder', 'Microsoft Research', 'Microsoft', 'Microsoft Research', 'Microsoft Research']","['General']","Katzman, J., Wang, A., Scheuerman, M., Blodgett, S. L., Laird, K., Wallach, H., & Barocas, S. (2023). Taxonomizing and Measuring Representational Harms: A Look at Image Tagging. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14277-14285. https://doi.org/10.1609/aaai.v37i12.26670","Abstract 					In this paper, we examine computational approaches for measuring the ""fairness"" of image tagging systems, finding that they cluster into five distinct categories, each with its own analytic foundation. We also identify a range of normative concerns that are often collapsed under the terms ""unfairness,"" ""bias,"" or even ""discrimination"" when discussing problematic cases of image tagging. Specifically, we identify four types of representational harms that can be caused by image tagging systems, providing concrete examples of each. We then consider how different computational measurement approaches map to each of these types, demonstrating that there is not a one-to-one mapping. Our findings emphasize that no single measurement approach will be definitive and that it is not possible to infer from the use of a particular measurement approach which type of harm was intended to be measured. Lastly, equipped with this more granular understanding of the types of representational harms that can be caused by image tagging systems, we show that attempts to mitigate some of these types of harms may be in tension with one another.","https://ojs.aaai.org/index.php/AAAI/article/view/26670/26442"
"26671","Winning the CityLearn Challenge: Adaptive Optimization with Evolutionary Search under Trajectory-Based Guidance","['Vanshaj Khattar', 'Ming Jin']","['Virginia Tech', 'Virginia Tech']","['General']","Khattar, V., & Jin, M. (2023). Winning the CityLearn Challenge: Adaptive Optimization with Evolutionary Search under Trajectory-Based Guidance. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14286-14294. https://doi.org/10.1609/aaai.v37i12.26671","Abstract 					Modern power systems will have to face difficult challenges in the years to come: frequent blackouts in urban areas caused by high peaks of electricity demand, grid instability exacerbated by the intermittency of renewable generation, and climate change on a global scale amplified by increasing carbon emissions. While current practices are growingly inadequate, the pathway of artificial intelligence (AI)-based methods to widespread adoption is hindered by missing aspects of trustworthiness. The CityLearn Challenge is an exemplary opportunity for researchers from multi-disciplinary fields to investigate the potential of AI to tackle these pressing issues within the energy domain, collectively modeled as a reinforcement learning (RL) task. Multiple real-world challenges faced by contemporary RL techniques are embodied in the problem formulation. In this paper, we present a novel method using the solution function of optimization as policies to compute the actions for sequential decision-making, while notably adapting the parameters of the optimization model from online observations. Algorithmically, this is achieved by an evolutionary algorithm under a novel trajectory-based guidance scheme. Formally, the global convergence property is established. Our agent ranked first in the latest 2021 CityLearn Challenge, being able to achieve superior performance in almost all metrics while maintaining some key aspects of interpretability.","https://ojs.aaai.org/index.php/AAAI/article/view/26671/26443"
"26672","Robust Planning over Restless Groups: Engagement Interventions for a Large-Scale Maternal Telehealth Program","['Jackson A. Killian', 'Arpita Biswas', 'Lily Xu', 'Shresth Verma', 'Vineet Nair', 'Aparna Taneja', 'Aparna Hegde', 'Neha Madhiwalla', 'Paula Rodriguez Diaz', 'Sonja Johnson-Yu', 'Milind Tambe']","['Harvard University', 'Harvard University', 'Harvard University', 'Google Research', 'Google Research', 'Google Research', 'ARMMAN', 'ARMMAN', 'Harvard University', 'Harvard University', 'Harvard University\nGoogle Research']","['General']","Killian, J. A., Biswas, A., Xu, L., Verma, S., Nair, V., Taneja, A., Hegde, A., Madhiwalla, N., Rodriguez Diaz, P., Johnson-Yu, S., & Tambe, M. (2023). Robust Planning over Restless Groups: Engagement Interventions for a Large-Scale Maternal Telehealth Program. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14295-14303. https://doi.org/10.1609/aaai.v37i12.26672","Abstract 					In 2020, maternal mortality in India was estimated to be as high as 130 deaths per 100K live births, nearly twice the UN's target. To improve health outcomes, the non-profit ARMMAN sends automated voice messages to expecting and new mothers across India. However, 38% of mothers stop listening to these calls, missing critical preventative care information. To improve engagement, ARMMAN employs health workers to intervene by making service calls, but workers can only call a fraction of the 100K enrolled mothers. Partnering with ARMMAN, we model the problem of allocating limited interventions across mothers as a restless multi-armed bandit (RMAB), where the realities of large scale and model uncertainty present key new technical challenges. We address these with GROUPS, a double oracle–based algorithm for robust planning in RMABs with scalable grouped arms. Robustness over grouped arms requires several methodological advances. First, to adversarially select stochastic group dynamics, we develop a new method to optimize Whittle indices over transition probability intervals. Second, to learn group-level RMAB policy best responses to these adversarial environments, we introduce a weighted index heuristic. Third, we prove a key theoretical result that planning over grouped arms achieves the same minimax regret--optimal strategy as planning over individual arms, under a technical condition. Finally, using real-world data from ARMMAN, we show that GROUPS produces robust policies that reduce minimax regret by up to 50%, halving the number of preventable missed voice messages to connect more mothers with life-saving maternal health information.","https://ojs.aaai.org/index.php/AAAI/article/view/26672/26444"
"26673","Equivariant Message Passing Neural Network for Crystal Material Discovery","['Astrid Klipfel', 'Zied Bouraoui', 'Olivier Peltre', 'Yaël Fregier', 'Najwa Harrati', 'Adlane Sayede']","['Univ. Artois, UMR 8188, Centre de Recherche en Informatique de Lens (CRIL), F-62300 Lens, France\nUniv. Artois, UMR 8181, Unité de Catalyse et de Chimie du Solide (UCCS), F-62300 Lens, France\nUniv. Artois, UR 2462, Laboratoire de Mathématiques de Lens (LML), F-62300 Lens, France', 'Univ. Artois, UMR 8188, Centre de Recherche en Informatique de Lens (CRIL), F-62300 Lens, France', 'Univ. Artois, UMR 8188, Centre de Recherche en Informatique de Lens (CRIL), F-62300 Lens, France\nUniv. Artois, UR 2462, Laboratoire de Mathématiques de Lens (LML), F-62300 Lens, France', 'Univ. Artois, UR 2462, Laboratoire de Mathématiques de Lens (LML), F-62300 Lens, France', 'Univ. Artois, UMR 8181, Unité de Catalyse et de Chimie du Solide (UCCS), F-62300 Lens, France', 'Univ. Artois, UMR 8181, Unité de Catalyse et de Chimie du Solide (UCCS), F-62300 Lens, France']","['General']","Klipfel, A., Bouraoui, Z., Peltre, O., Fregier, Y., Harrati, N., & Sayede, A. (2023). Equivariant Message Passing Neural Network for Crystal Material Discovery. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14304-14311. https://doi.org/10.1609/aaai.v37i12.26673","Abstract 					Automatic material discovery with desired properties is a fundamental challenge for material sciences. Considerable attention has recently been devoted to generating stable crystal structures. While existing work has shown impressive success on supervised tasks such as property prediction, the progress on unsupervised tasks such as material generation is still hampered by the limited extent to which the equivalent geometric representations of the same crystal are considered. To address this challenge, we propose EPGNN a periodic equivariant message-passing neural network that learns crystal lattice deformation in an unsupervised fashion. Our model equivalently acts on lattice according to the deformation action that must be performed, making it suitable for crystal generation, relaxation and optimisation. We present experimental evaluations that demonstrate the effectiveness of our approach.","https://ojs.aaai.org/index.php/AAAI/article/view/26673/26445"
"26674","Accurate Fairness: Improving Individual Fairness without Trading Accuracy","['Xuran Li', 'Peng Wu', 'Jing Su']","['State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences', 'State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences', 'State Key Laboratory of Computer Science, Institute of Software, Chinese Academy of Sciences']","['General']","Li, X., Wu, P., & Su, J. (2023). Accurate Fairness: Improving Individual Fairness without Trading Accuracy. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14312-14320. https://doi.org/10.1609/aaai.v37i12.26674","Abstract 					Accuracy and individual fairness are both crucial for trustworthy machine learning, but these two aspects are often incompatible with each other so that enhancing one aspect may sacrifice the other inevitably with side effects of true bias or false fairness. We propose in this paper a new fairness criterion, accurate fairness, to align individual fairness with accuracy. Informally, it requires the treatments of an individual and the individual's similar counterparts to conform to a uniform target, i.e., the ground truth of the individual. We prove that accurate fairness also implies typical group fairness criteria over a union of similar sub-populations. We then present a Siamese fairness in-processing approach to minimize the accuracy and fairness losses of a machine learning model under the accurate fairness constraints. To the best of our knowledge, this is the first time that a Siamese approach is adapted for bias mitigation. We also propose fairness confusion matrix-based metrics, fair-precision, fair-recall, and fair-F1 score, to quantify a trade-off between accuracy and individual fairness. Comparative case studies with popular fairness datasets show that our Siamese fairness approach can achieve on average 1.02%-8.78% higher individual fairness (in terms of fairness through awareness) and 8.38%-13.69% higher accuracy, as well as 10.09%-20.57% higher true fair rate, and 5.43%-10.01% higher fair-F1 score, than the state-of-the-art bias mitigation techniques. This demonstrates that our Siamese fairness approach can indeed improve individual fairness without trading accuracy. Finally, the accurate fairness criterion and Siamese fairness approach are applied to mitigate the possible service discrimination with a real Ctrip dataset, by on average fairly serving 112.33% more customers (specifically, 81.29% more customers in an accurately fair way) than baseline models.","https://ojs.aaai.org/index.php/AAAI/article/view/26674/26446"
"26675","Point-to-Region Co-learning for Poverty Mapping at High Resolution Using Satellite Imagery","['Zhili Li', 'Yiqun Xie', 'Xiaowei Jia', 'Kara Stuart', 'Caroline Delaire', 'Sergii Skakun']","['University of Maryland', 'University of Maryland', 'University of Pittsburgh', 'The Aquaya Institute', 'The Aquaya Institute', 'University of Maryland']","['General']","Li, Z., Xie, Y., Jia, X., Stuart, K., Delaire, C., & Skakun, S. (2023). Point-to-Region Co-learning for Poverty Mapping at High Resolution Using Satellite Imagery. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14321-14328. https://doi.org/10.1609/aaai.v37i12.26675","Abstract 					Despite improvements in safe water and sanitation services in low-income countries, a substantial proportion of the population in Africa still does not have access to these essential services. Up-to-date fine-scale maps of low-income settlements are urgently needed by authorities  to improve service provision. We aim to develop a cost-effective solution to generate fine-scale maps of these vulnerable populations using multi-source public information. The problem is challenging as ground-truth maps are available at only a limited number of cities, and the patterns are heterogeneous across cities. Recent attempts tackling the spatial heterogeneity issue focus on scenarios where true labels partially exist for each input region, which are unavailable for the present problem. We propose a dynamic point-to-region co-learning framework to learn heterogeneity patterns that cannot be reflected by point-level information and generalize deep learners to new areas with no labels. We also propose an attention-based correction layer to remove spurious signatures, and a region-gate to capture both region-invariant and variant patterns. Experiment results on real-world fine-scale data in three cities of Kenya show that the proposed approach can largely improve model performance on various base network architectures.","https://ojs.aaai.org/index.php/AAAI/article/view/26675/26447"
"26676","AirFormer: Predicting Nationwide Air Quality in China with Transformers","['Yuxuan Liang', 'Yutong Xia', 'Songyu Ke', 'Yiwei Wang', 'Qingsong Wen', 'Junbo Zhang', 'Yu Zheng', 'Roger Zimmermann']","['National University of Singapore, Singapore', 'National University of Singapore, Singapore', 'Shanghai Jiao Tong University, Shanghai, China\nJD Intelligent Cities Research & JD iCity, JD Technology, Beijing, China', 'National University of Singapore, Singapore', 'DAMO Academy, Alibaba Group, Hangzhou, China', 'JD Intelligent Cities Research & JD iCity, JD Technology, Beijing, China', 'JD Intelligent Cities Research & JD iCity, JD Technology, Beijing, China', 'National University of Singapore, Singapore']","['General']","Liang, Y., Xia, Y., Ke, S., Wang, Y., Wen, Q., Zhang, J., Zheng, Y., & Zimmermann, R. (2023). AirFormer: Predicting Nationwide Air Quality in China with Transformers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14329-14337. https://doi.org/10.1609/aaai.v37i12.26676","Abstract 					Air pollution is a crucial issue affecting human health and livelihoods, as well as one of the barriers to economic growth. Forecasting air quality has become an increasingly important endeavor with significant social impacts, especially in emerging countries. In this paper, we present a novel Transformer termed AirFormer to predict nationwide air quality in China, with an unprecedented fine spatial granularity covering thousands of locations. AirFormer decouples the learning process into two stages: 1) a bottom-up deterministic stage that contains two new types of self-attention mechanisms to efficiently learn spatio-temporal representations; 2) a top-down stochastic stage with latent variables to capture the intrinsic uncertainty of air quality data. We evaluate AirFormer with 4-year data from 1,085 stations in Chinese Mainland. Compared to prior models, AirFormer reduces prediction errors by 5%∼8% on 72-hour future predictions. Our source code is available at https://github.com/yoshall/airformer.","https://ojs.aaai.org/index.php/AAAI/article/view/26676/26448"
"26677","SimFair: A Unified Framework for Fairness-Aware Multi-Label Classification","['Tianci Liu', 'Haoyu Wang', 'Yaqing Wang', 'Xiaoqian Wang', 'Lu Su', 'Jing Gao']","['Purdue University', 'Purdue University', 'Purdue University', 'Purdue University', 'Purdue University', 'Purdue University']","['General']","Liu, T., Wang, H., Wang, Y., Wang, X., Su, L., & Gao, J. (2023). SimFair: A Unified Framework for Fairness-Aware Multi-Label Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14338-14346. https://doi.org/10.1609/aaai.v37i12.26677","Abstract 					Recent years have witnessed increasing concerns towards unfair decisions made by machine learning algorithms. To improve fairness in model decisions, various fairness notions have been proposed and many fairness-aware methods are developed. However, most of existing definitions and methods focus only on single-label classification. Fairness for multi-label classification, where each instance is associated with more than one labels, is still yet to establish. To fill this gap, we study fairness-aware multi-label classification in this paper. We start by extending Demographic Parity (DP) and Equalized Opportunity (EOp), two popular fairness notions, to multi-label classification scenarios. Through a systematic study, we show that on multi-label data, because of unevenly distributed labels, EOp usually fails to construct a reliable estimate on labels with few instances. We then propose a new framework named Similarity s-induced Fairness (sγ -SimFair). This new framework utilizes data that have similar labels when estimating fairness on a particular label group for better stability, and can unify DP and EOp. Theoretical analysis and experimental results on real-world datasets together demonstrate the advantage of sγ -SimFair over existing methods on multi-label classification tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26677/26449"
"26678","Human Mobility Modeling during the COVID-19 Pandemic via Deep Graph Diffusion Infomax","['Yang Liu', 'Yu Rong', 'Zhuoning Guo', 'Nuo Chen', 'Tingyang Xu', 'Fugee Tsung', 'Jia Li']","['The Hong Kong University of Science and Technology', 'Tencent AI Lab', 'The Hong Kong University of Science and Technology (Guangzhou)', 'The Hong Kong University of Science and Technology (Guangzhou)', 'Tencent AI Lab', 'Hong Kong University of Science and Technology', 'Hong Kong University of Science and Technology']","['General']","Liu, Y., Rong, Y., Guo, Z., Chen, N., Xu, T., Tsung, F., & Li, J. (2023). Human Mobility Modeling during the COVID-19 Pandemic via Deep Graph Diffusion Infomax. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14347-14355. https://doi.org/10.1609/aaai.v37i12.26678","Abstract 					Non-Pharmaceutical Interventions (NPIs), such as social gathering restrictions, have shown effectiveness to slow the transmission of COVID-19 by reducing the contact of people. To support policy-makers, multiple studies have first modelled human mobility via macro indicators (e.g., average daily travel distance) and then study the effectiveness of NPIs. In this work, we focus on mobility modelling and, from a micro perspective, aim to predict locations that will be visited by COVID-19 cases. Since NPIs generally cause economic and societal loss, such a prediction benefits governments when they design and evaluate them. However, in real-world situations, strict privacy data protection regulations result in severe data sparsity problems (i.e., limited case and location information). To address these challenges and jointly model variables including a geometric graph, a set of diffusions and a set of locations, we propose a model named Deep Graph Diffusion Infomax (DGDI). We show the maximization of DGDI can be bounded by two tractable components: a univariate Mutual Information (MI) between geometric graph and diffusion representation, and a univariate MI between diffusion representation and location representation. To facilitate the research of COVID-19 prediction, we present two benchmarks that contain geometric graphs and location histories of COVID-19 cases. Extensive experiments on the two benchmarks show that DGDI significantly outperforms other competing methods.","https://ojs.aaai.org/index.php/AAAI/article/view/26678/26450"
"26679","Interpretable Chirality-Aware Graph Neural Network for Quantitative Structure Activity Relationship Modeling in Drug Discovery","['Yunchao (Lance) Liu', 'Yu Wang', 'Oanh Vu', 'Rocco Moretti', 'Bobby Bodenheimer', 'Jens Meiler', 'Tyler Derr']","['Vanderbilt University', 'Vanderbilt University', 'Vanderbilt University', 'Vanderbilt University', 'Vanderbilt University', 'Vanderbilt University\nLeipzig University', 'Vanderbilt University']","['General']","Liu, Y. (Lance), Wang, Y., Vu, O., Moretti, R., Bodenheimer, B., Meiler, J., & Derr, T. (2023). Interpretable Chirality-Aware Graph Neural Network for Quantitative Structure Activity Relationship Modeling in Drug Discovery. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14356-14364. https://doi.org/10.1609/aaai.v37i12.26679","Abstract 					In computer-aided drug discovery, quantitative structure activity relation models are trained to predict biological activity from chemical structure. Despite the recent success of applying graph neural network to this task, important chemical information such as molecular chirality is ignored. To fill this crucial gap, we propose Molecular-Kernel Graph NeuralNetwork (MolKGNN) for molecular representation learning, which features SE(3)-/conformation invariance, chirality-awareness, and interpretability. For our MolKGNN, we first design a molecular graph convolution to capture the chemical pattern by comparing the atom's similarity with the learnable molecular kernels. Furthermore, we propagate the similarity score to capture the higher-order chemical pattern. To assess the method, we conduct a comprehensive evaluation with nine well-curated datasets spanning numerous important drug targets that feature realistic high class imbalance and it demonstrates the superiority of MolKGNN over other graph neural networks in computer-aided drug discovery. Meanwhile, the learned kernels identify patterns that agree with domain knowledge, confirming the pragmatic interpretability of this approach.  Our code and supplementary material are publicly available at https://github.com/meilerlab/MolKGNN.","https://ojs.aaai.org/index.php/AAAI/article/view/26679/26451"
"26680","Task-Adaptive Meta-Learning Framework for Advancing Spatial Generalizability","['Zhexiong Liu', 'Licheng Liu', 'Yiqun Xie', 'Zhenong Jin', 'Xiaowei Jia']","['University of Pittsburgh', 'University of Minnesota', 'University of Maryland', 'University of Minnesota', 'University of Pittsburgh']","['General']","Liu, Z., Liu, L., Xie, Y., Jin, Z., & Jia, X. (2023). Task-Adaptive Meta-Learning Framework for Advancing Spatial Generalizability. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14365-14373. https://doi.org/10.1609/aaai.v37i12.26680","Abstract 					Spatio-temporal machine learning is critically needed for a variety of societal applications, such as agricultural monitoring, hydrological forecast, and traffic management. These applications greatly rely on regional features that characterize spatial and temporal differences. However, spatio-temporal data often exhibit complex patterns and significant data variability across different locations. The labels in many real-world applications can also be limited, which makes it difficult to separately train independent models for different locations. Although meta learning has shown promise in model adaptation with small samples, existing meta learning methods remain limited in handling a large number of heterogeneous tasks, e.g., a large number of locations with varying data patterns. To bridge the gap, we propose task-adaptive formulations and a model-agnostic meta-learning framework that transforms regionally heterogeneous data into location-sensitive meta tasks. We conduct task adaptation following an easy-to-hard task hierarchy in which different meta models are adapted to tasks of different difficulty levels. One major advantage of our proposed method is that it improves the model adaptation to a large number of heterogeneous tasks. It also enhances the model generalization  by automatically adapting the meta model of the corresponding difficulty level to any new tasks. We demonstrate the superiority of our proposed framework over a diverse set of baselines and state-of-the-art meta-learning frameworks. Our extensive experiments on real crop yield data show the effectiveness of the proposed method in handling spatial-related heterogeneous tasks in real societal applications.","https://ojs.aaai.org/index.php/AAAI/article/view/26680/26452"
"26681","A Composite Multi-Attention Framework for Intraoperative Hypotension Early Warning","['Feng Lu', 'Wei Li', 'Zhiqiang Zhou', 'Cheng Song', 'Yifei Sun', 'Yuwei Zhang', 'Yufei Ren', 'Xiaofei Liao', 'Hai Jin', 'Ailin Luo', 'Albert Y. Zomaya']","['National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, China', 'The Australia-China Joint Research Centre for Energy Informatics and Demand Response Technologies, Centre for Distributed and High Performance Computing, School of Computer Science, The University of Sydney, Australia', 'Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology', 'National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, China', 'National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, China', 'National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, China', 'Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology', 'National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, China', 'National Engineering Research Center for Big Data Technology and System, Services Computing Technology and System Lab, Cluster and Grid Computing Lab, School of Computer Science and Technology, Huazhong University of Science and Technology, China', 'Tongji Hospital, Tongji Medical College, Huazhong University of Science and Technology', 'The Australia-China Joint Research Centre for Energy Informatics and Demand Response Technologies, Centre for Distributed and High Performance Computing, School of Computer Science, The University of Sydney, Australia']","['General']","Lu, F., Li, W., Zhou, Z., Song, C., Sun, Y., Zhang, Y., Ren, Y., Liao, X., Jin, H., Luo, A., & Zomaya, A. Y. (2023). A Composite Multi-Attention Framework for Intraoperative Hypotension Early Warning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14374-14381. https://doi.org/10.1609/aaai.v37i12.26681","Abstract 					Intraoperative hypotension (IOH) events warning plays a crucial role in preventing postoperative complications, such as postoperative delirium and mortality. Despite significant efforts, two fundamental problems limit its wide clinical use. The well-established IOH event warning systems are often built on proprietary medical devices that may not be available in all hospitals. The warnings are also triggered mainly through a predefined IOH event that might not be suitable for all patients. This work proposes a composite multi-attention (CMA) framework to tackle these problems by conducting short-term predictions on user-definable IOH events using vital signals in a low sampling rate with demographic characteristics. Our framework leverages a multi-modal fusion network to make four vital signals and three demographic characteristics as input modalities. For each modality, a multi-attention mechanism is used for feature extraction for better model training. Experiments on two large-scale real-world data sets show that our method can achieve up to 94.1% accuracy on IOH events early warning while the signals sampling rate is reduced by 3000 times. Our proposal CMA can achieve a mean absolute error of 4.50 mm Hg in the most challenging 15-minute mean arterial pressure prediction task and the error reduction by 42.9% compared to existing solutions.","https://ojs.aaai.org/index.php/AAAI/article/view/26681/26453"
"26682","Bugs in the Data: How ImageNet Misrepresents Biodiversity","['Alexandra Sasha Luccioni', 'David Rolnick']","['Hugging Face', 'McGill University, Mila']","['General']","Luccioni, A. S., & Rolnick, D. (2023). Bugs in the Data: How ImageNet Misrepresents Biodiversity. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14382-14390. https://doi.org/10.1609/aaai.v37i12.26682","Abstract 					ImageNet-1k is a dataset often used for benchmarking machine learning (ML) models and evaluating tasks such as image recognition and object detection. Wild animals make up 27% of ImageNet-1k but, unlike classes representing people and objects, these data have not been closely scrutinized. In the current paper, we analyze the 13,450 images from 269 classes that represent wild animals in the ImageNet-1k validation set, with the participation of expert ecologists. We find that many of the classes are ill-defined or overlapping, and that 12% of the images are incorrectly labeled, with some classes having >90% of images incorrect. We also find that both the wildlife-related labels and images included in ImageNet-1k present significant geographical and cultural biases, as well as ambiguities such as artificial animals, multiple species in the same image, or the presence of humans. Our findings highlight serious issues with the extensive use of this dataset for evaluating ML systems, the use of such algorithms in wildlife-related tasks, and more broadly the ways in which ML datasets are commonly created and curated.","https://ojs.aaai.org/index.php/AAAI/article/view/26682/26454"
"26683","LUCID: Exposing Algorithmic Bias through Inverse Design","['Carmen Mazijn', 'Carina Prunkl', 'Andres Algaba', 'Jan Danckaert', 'Vincent Ginis']","['Vrije Universiteit Brussel', 'University of Oxford', 'Vrije Universiteit Brussel', 'Vrije Universiteit Brussel', 'Vrije Universiteit Brussel\nHarvard University']","['General']","Mazijn, C., Prunkl, C., Algaba, A., Danckaert, J., & Ginis, V. (2023). LUCID: Exposing Algorithmic Bias through Inverse Design. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14391-14399. https://doi.org/10.1609/aaai.v37i12.26683","Abstract 					AI systems can create, propagate, support, and automate bias in decision-making processes. To mitigate biased decisions, we both need to understand the origin of the bias and define what it means for an algorithm to make fair decisions. Most group fairness notions assess a model's equality of outcome by computing statistical metrics on the outputs. We argue that these output metrics encounter intrinsic obstacles and present a complementary approach that aligns with the increasing focus on equality of treatment. By Locating Unfairness through Canonical Inverse Design (LUCID), we generate a canonical set that shows the desired inputs for a model given a preferred output. The canonical set reveals the model's internal logic and exposes potential unethical biases by repeatedly interrogating the decision-making process. We evaluate LUCID on the UCI Adult and COMPAS data sets and find that some biases detected by a canonical set differ from those of output metrics. The results show that by shifting the focus towards equality of treatment and looking into the algorithm's internal workings, the canonical sets are a valuable addition to the toolbox of algorithmic fairness evaluation.","https://ojs.aaai.org/index.php/AAAI/article/view/26683/26455"
"26684","Neighbor Auto-Grouping Graph Neural Networks for Handover Parameter Configuration in Cellular Network","['Mehrtash Mehrabi', 'Walid Masoudimansour', 'Yingxue Zhang', 'Jie Chuai', 'Zhitang Chen', 'Mark Coates', 'Jianye Hao', 'Yanhui Geng']","['Huawei Noah’s Ark Lab\nUniversity of Alberta', ""Huawei Noah's Ark Lab"", ""Huawei Noah's Ark Lab"", 'Huawei Noah’s Ark Lab', 'Huawei Noah’s Ark Lab', 'McGill University', ""Huawei Noah's Ark Lab\nTianjin University"", 'Huawei Noah’s Ark Lab']","['General']","Mehrabi, M., Masoudimansour, W., Zhang, Y., Chuai, J., Chen, Z., Coates, M., Hao, J., & Geng, Y. (2023). Neighbor Auto-Grouping Graph Neural Networks for Handover Parameter Configuration in Cellular Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14400-14407. https://doi.org/10.1609/aaai.v37i12.26684","Abstract 					The mobile communication enabled by cellular networks is the one of the main foundations of our modern society. Optimizing the performance of cellular networks and providing massive connectivity with improved coverage and user experience has a considerable social and economic impact on our daily life. This performance relies heavily on the configuration of the network parameters. However, with the massive increase in both the size and complexity of cellular networks, network management, especially parameter configuration, is becoming complicated. The current practice, which relies largely on experts' prior knowledge, is not adequate and will require lots of domain experts and high maintenance costs. In this work, we propose a learning-based framework for handover parameter configuration. The key challenge, in this case, is to tackle the complicated dependencies between neighboring cells and jointly optimize the whole network. Our framework addresses this challenge in two ways. First, we introduce a novel approach to imitate how the network responds to different network states and parameter values, called auto-grouping graph convolutional network (AG-GCN). During the parameter configuration stage, instead of solving the global optimization problem, we design a local multi-objective optimization strategy where each cell considers several local performance metrics to balance its own performance and its neighbors. We evaluate our proposed algorithm via a simulator constructed using real network data. We demonstrate that the handover parameters our model can find, achieve better average network throughput compared to those recommended by experts as well as alternative baselines, which can bring better network quality and stability. It has the potential to massively reduce costs arising from human expert intervention and maintenance.","https://ojs.aaai.org/index.php/AAAI/article/view/26684/26456"
"26685","Help Me Heal: A Reinforced Polite and Empathetic Mental Health and Legal Counseling Dialogue System for Crime Victims","['Kshitij Mishra', 'Priyanshu Priya', 'Asif Ekbal']","['Indian Institute of Technology Patna', 'Indian Institute of Technology Patna', 'Indian Institute of Technology Patna']","['General']","Mishra, K., Priya, P., & Ekbal, A. (2023). Help Me Heal: A Reinforced Polite and Empathetic Mental Health and Legal Counseling Dialogue System for Crime Victims. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14408-14416. https://doi.org/10.1609/aaai.v37i12.26685","Abstract 					The potential for conversational agents offering mental health and legal counseling in an autonomous, interactive, and vitally accessible environment is getting highlighted due to the increased access to information through the internet and mobile devices. A counseling conversational agent should be able to offer higher engagement mimicking the real-time counseling sessions. The ability to empathize or comprehend and feel another person’s emotions and experiences is a crucial quality that promotes effective therapeutic bonding and rapport-building. Further, the use of polite encoded language in the counseling reflects the nobility and creates a familiar, warm, and comfortable atmosphere to resolve human issues. Therefore, focusing on these two aspects, we propose a Polite and Empathetic Mental Health and Legal Counseling Dialogue System (Po-Em-MHLCDS) for the victims of crimes. To build Po-Em-MHLCDS, we first create a Mental Health and Legal Counseling Dataset (MHLCD) by recruiting six employees who are asked to converse with each other, acting as a victim and the agent interchangeably following a fixed stated guidelines. Second, the MHLCD dataset is annotated with three informative labels, viz. counseling strategies, politeness, and empathy. Lastly, we train the Po-Em-MHLCDS in a reinforcement learning framework by designing an efficient and effective reward function to reinforce correct counseling strategy, politeness and empathy while maintaining contextual-coherence and non-repetitiveness in the generated responses. Our extensive automatic and human evaluation demonstrate the strength of the proposed system. Codes and Data can be accessed at https://www.iitp.ac.in/ ai-nlp-ml/resources.html#MHLCD or https://github.com/Mishrakshitij/Po-Em-MHLCDS","https://ojs.aaai.org/index.php/AAAI/article/view/26685/26457"
"26686","Carburacy: Summarization Models Tuning and Comparison in Eco-Sustainable Regimes with a Novel Carbon-Aware Accuracy","['Gianluca Moro', 'Luca Ragazzi', 'Lorenzo Valgimigli']","['DISI - University of Bologna\nCNIT', 'DISI - University of Bologna', 'DISI - University of Bologna']","['General']","Moro, G., Ragazzi, L., & Valgimigli, L. (2023). Carburacy: Summarization Models Tuning and Comparison in Eco-Sustainable Regimes with a Novel Carbon-Aware Accuracy. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14417-14425. https://doi.org/10.1609/aaai.v37i12.26686","Abstract 					Generative transformer-based models have reached cutting-edge performance in long document summarization. Nevertheless, this task is witnessing a paradigm shift in developing ever-increasingly computationally-hungry solutions, focusing on effectiveness while ignoring the economic, environmental, and social costs of yielding such results. Accordingly, such extensive resources impact climate change and raise barriers to small and medium organizations distinguished by low-resource regimes of hardware and data. As a result, this unsustainable trend has lifted many concerns in the community, which directs the primary efforts on the proposal of tools to monitor models' energy costs. Despite their importance, no evaluation measure considering models' eco-sustainability exists yet. In this work, we propose Carburacy, the first carbon-aware accuracy measure that captures both model effectiveness and eco-sustainability. We perform a comprehensive benchmark for long document summarization, comparing multiple state-of-the-art quadratic and linear transformers on several datasets under eco-sustainable regimes. Finally, thanks to Carburacy, we found optimal combinations of hyperparameters that let models be competitive in effectiveness with significantly lower costs.","https://ojs.aaai.org/index.php/AAAI/article/view/26686/26458"
"26687","Joint Self-Supervised Image-Volume Representation Learning with Intra-inter Contrastive Clustering","['Duy M. H. Nguyen', 'Hoang Nguyen', 'Truong T. N. Mai', 'Tri Cao', 'Binh T. Nguyen', 'Nhat Ho', 'Paul Swoboda', 'Shadi Albarqouni', 'Pengtao Xie', 'Daniel Sonntag']","['German Research Centre for Artificial Intelligence\nUniversity of Stuttgart', 'University of Science, VNU-HCMUS', 'Dongguk University', 'University of Science, VNU-HCMUS', 'University of Science, VNU-HCMUS', 'University of Texas at Austin', 'Max Planck Institute for Informatics', 'Helmholtz AI, Helmholtz Munich\nUniversity of Bonn', 'University of California San Diego', 'German Research Center for Artificial Intelligence\nOldenburg University']","['General']","Nguyen, D. M. H., Nguyen, H., Mai, T. T. N., Cao, T., Nguyen, B. T., Ho, N., Swoboda, P., Albarqouni, S., Xie, P., & Sonntag, D. (2023). Joint Self-Supervised Image-Volume Representation Learning with Intra-inter Contrastive Clustering. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14426-14435. https://doi.org/10.1609/aaai.v37i12.26687","Abstract 					Collecting large-scale medical datasets with fully annotated samples for training of deep networks is prohibitively expensive, especially for 3D volume data. Recent breakthroughs in self-supervised learning (SSL) offer the ability to overcome the lack of labeled training samples by learning feature representations from unlabeled data. However, most current SSL techniques in the medical field have been designed for either 2D images or 3D volumes. In practice, this restricts the capability to fully leverage unlabeled data from numerous sources, which may include both 2D and 3D data. Additionally, the use of these pre-trained networks is constrained to downstream tasks with compatible data dimensions. In this paper, we propose a novel framework for unsupervised joint learning on 2D and 3D data modalities. Given a set of 2D images or 2D slices extracted from 3D volumes, we construct an SSL task based on a 2D contrastive clustering problem for distinct classes. The 3D volumes are exploited by computing vectored embedding at each slice and then assembling a holistic feature through deformable self-attention mechanisms in Transformer, allowing incorporating long-range dependencies between slices inside 3D volumes. These holistic features are further utilized to define a novel 3D clustering agreement-based SSL task and masking embedding prediction inspired by pre-trained language models. Experiments on downstream tasks, such as 3D brain segmentation, lung nodule detection, 3D heart structures segmentation, and abnormal chest X-ray detection, demonstrate the effectiveness of our joint 2D and 3D SSL approach. We improve plain 2D Deep-ClusterV2 and SwAV by a significant margin and also surpass various modern 2D and 3D SSL approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/26687/26459"
"26688","For the Underrepresented in Gender Bias Research: Chinese Name Gender Prediction with Heterogeneous Graph Attention Network","['Zihao Pan', 'Kai Peng', 'Shuai Ling', 'Haipeng Zhang']","['ShanghaiTech University', 'ShanghaiTech University', 'ShanghaiTech University', 'ShanghaiTech University']","['General']","Pan, Z., Peng, K., Ling, S., & Zhang, H. (2023). For the Underrepresented in Gender Bias Research: Chinese Name Gender Prediction with Heterogeneous Graph Attention Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14436-14443. https://doi.org/10.1609/aaai.v37i12.26688","Abstract 					Achieving gender equality is an important pillar for humankind’s sustainable future. Pioneering data-driven gender bias research is based on large-scale public records such as scientific papers, patents, and company registrations, covering female researchers, inventors and entrepreneurs, and so on. Since gender information is often missing in relevant datasets, studies rely on tools to infer genders from names. However, available open-sourced Chinese gender-guessing tools are not yet suitable for scientific purposes, which may be partially responsible for female Chinese being underrepresented in mainstream gender bias research and affect their universality. Specifically, these tools focus on character-level information while overlooking the fact that the combinations of Chinese characters in multi-character names, as well as the components and pronunciations of characters, convey important messages. As a first effort, we design a Chinese Heterogeneous Graph Attention (CHGAT) model to capture the heterogeneity in component relationships and incorporate the pronunciations of characters. Our model largely surpasses current tools and also outperforms the state-of-the-art algorithm. Last but not least, the most popular Chinese name-gender dataset is single-character based with far less female coverage from an unreliable source, naturally hindering relevant studies. We open-source a more balanced multi-character dataset from an official source together with our code, hoping to help future research promoting gender equality.","https://ojs.aaai.org/index.php/AAAI/article/view/26688/26460"
"26689","FakeSV: A Multimodal Benchmark with Rich Social Context for Fake News Detection on Short Video Platforms","['Peng Qi', 'Yuyan Bu', 'Juan Cao', 'Wei Ji', 'Ruihao Shui', 'Junbin Xiao', 'Danding Wang', 'Tat-Seng Chua']","['Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'National University of Singapore', 'National University of Singapore', 'National University of Singapore', 'Institute of Computing Technology, Chinese Academy of Sciences', 'National university of Singapore']","['General']","Qi, P., Bu, Y., Cao, J., Ji, W., Shui, R., Xiao, J., Wang, D., & Chua, T.-S. (2023). FakeSV: A Multimodal Benchmark with Rich Social Context for Fake News Detection on Short Video Platforms. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14444-14452. https://doi.org/10.1609/aaai.v37i12.26689","Abstract 					Short video platforms have become an important channel for news sharing, but also a new breeding ground for fake news. To mitigate this problem, research of fake news video detection has recently received a lot of attention. Existing works face two roadblocks: the scarcity of comprehensive and largescale datasets and insufficient utilization of multimodal information. Therefore, in this paper, we construct the largest Chinese short video dataset about fake news named FakeSV, which includes news content, user comments, and publisher profiles simultaneously. To understand the characteristics of fake news videos, we conduct exploratory analysis of FakeSV from different perspectives. Moreover, we provide a new multimodal detection model named SV-FEND, which exploits the cross-modal correlations to select the most informative features and utilizes the social context information for detection. Extensive experiments evaluate the superiority of the proposed method and provide detailed comparisons of different methods and modalities for future works. Our dataset and codes are available in https://github.com/ICTMCG/FakeSV.","https://ojs.aaai.org/index.php/AAAI/article/view/26689/26461"
"26690","EINNs: Epidemiologically-Informed Neural Networks","['Alexander Rodríguez', 'Jiaming Cui', 'Naren Ramakrishnan', 'Bijaya Adhikari', 'B. Aditya Prakash']","['Georgia Institute of Technology', 'Georgia Institute of Technology', 'Virginia Tech', 'University of Iowa', 'Georgia Institute of Technology']","['General']","Rodríguez, A., Cui, J., Ramakrishnan, N., Adhikari, B., & Prakash, B. A. (2023). EINNs: Epidemiologically-Informed Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14453-14460. https://doi.org/10.1609/aaai.v37i12.26690","Abstract 					We introduce EINNs, a framework crafted for epidemic forecasting that builds upon the theoretical grounds provided by mechanistic models as well as the data-driven expressibility afforded by AI models, and their capabilities to ingest heterogeneous information. Although neural forecasting models have been successful in multiple tasks, predictions well-correlated with epidemic trends and long-term predictions remain open challenges. Epidemiological ODE models contain mechanisms that can guide us in these two tasks; however, they have limited capability of ingesting data sources and modeling composite signals. Thus, we propose to leverage work in physics-informed neural networks to learn latent epidemic dynamics and transfer relevant knowledge to another neural network which ingests multiple data sources and has more appropriate inductive bias. In contrast with previous work, we do not assume the observability of complete dynamics and do not need to numerically solve the ODE equations during training. Our thorough experiments on all US states and HHS regions for COVID-19 and influenza forecasting showcase the clear benefits of our approach in both short-term and long-term forecasting as well as in learning the mechanistic dynamics over other non-trivial alternatives.","https://ojs.aaai.org/index.php/AAAI/article/view/26690/26462"
"26691","Counterfactual Fairness Is Basically Demographic Parity","['Lucas Rosenblatt', 'R. Teal Witter']","['New York University', 'New York University']","['General']","Rosenblatt, L., & Witter, R. T. (2023). Counterfactual Fairness Is Basically Demographic Parity. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14461-14469. https://doi.org/10.1609/aaai.v37i12.26691","Abstract 					Making fair decisions is crucial to ethically implementing machine learning algorithms in social settings. In this work, we consider the celebrated definition of counterfactual fairness. We begin by showing that an algorithm which satisfies counterfactual fairness also satisfies demographic parity, a far simpler fairness constraint. Similarly, we show that all algorithms satisfying demographic parity can be trivially modified to satisfy counterfactual fairness. Together, our results indicate that counterfactual fairness is basically equivalent to demographic parity, which has important implications for the growing body of work on counterfactual fairness. We then validate our theoretical findings empirically, analyzing three existing algorithms for counterfactual fairness against three simple benchmarks. We find that two simple benchmark algorithms outperform all three existing algorithms---in terms of fairness, accuracy, and efficiency---on several data sets. Our analysis leads us to formalize a concrete fairness goal: to preserve the order of individuals within protected groups. We believe transparency around the ordering of individuals within protected groups makes fair algorithms more trustworthy. By design, the two simple benchmark algorithms satisfy this goal while the existing algorithms do not.","https://ojs.aaai.org/index.php/AAAI/article/view/26691/26463"
"26692","Detecting Anomalous Networks of Opioid Prescribers and Dispensers in Prescription Drug Data","['Katie Rosman', 'Daniel B. Neill']","['New York University', 'New York University']","['General']","Rosman, K., & Neill, D. B. (2023). Detecting Anomalous Networks of Opioid Prescribers and Dispensers in Prescription Drug Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14470-14477. https://doi.org/10.1609/aaai.v37i12.26692","Abstract 					The opioid overdose epidemic represents a serious public health crisis, with fatality rates rising considerably over the past several years. To help address the abuse of prescription opioids, state governments collect data on dispensed prescriptions, yet the use of these data is typically limited to manual searches. In this paper, we propose a novel graph-based framework for detecting anomalous opioid prescribing patterns in state Prescription Drug Monitoring Program (PDMP) data, which could aid governments in deterring opioid diversion and abuse. Specifically, we seek to identify connected networks of opioid prescribers and dispensers who engage in high-risk and possibly illicit activity. We develop and apply a novel extension of the Non-Parametric Heterogeneous Graph Scan (NPHGS) to two years of de-identified PDMP data from the state of Kansas, and find that NPHGS identifies subgraphs that are significantly more anomalous than those detected by other graph-based methods. NPHGS also reveals clusters of potentially illicit activity, which may strengthen state law enforcement and regulatory capabilities. Our paper is the first to demonstrate how prescription data can systematically identify anomalous opioid prescribers and dispensers, as well as illustrating the efficacy of a network-based approach. Additionally, our technical extensions to NPHGS offer both improved flexibility and graph density reduction, enabling the framework to be replicated across jurisdictions and extended to other problem domains.","https://ojs.aaai.org/index.php/AAAI/article/view/26692/26464"
"26693","Practical Disruption of Image Translation Deepfake Networks","['Nataniel Ruiz', 'Sarah Adel Bargal', 'Cihang Xie', 'Stan Sclaroff']","['Boston University', 'Georgetown University', 'University of California, Santa Cruz', 'Boston University']","['General']","Ruiz, N., Bargal, S. A., Xie, C., & Sclaroff, S. (2023). Practical Disruption of Image Translation Deepfake Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14478-14486. https://doi.org/10.1609/aaai.v37i12.26693","Abstract 					By harnessing the latest advances in deep learning, image-to-image translation architectures have recently achieved impressive capabilities. Unfortunately, the growing representational power of these architectures has prominent unethical uses. Among these, the threats of (1) face manipulation (""DeepFakes"") used for misinformation or pornographic use (2) ""DeepNude"" manipulations of body images to remove clothes from individuals, etc. Several works tackle the task of disrupting such image translation networks by inserting imperceptible adversarial attacks into the input image. Nevertheless, these works have limitations that may result in disruptions that are not practical in the real world. Specifically, most works generate disruptions in a white-box scenario, assuming perfect knowledge about the image translation network. The few remaining works that assume a black-box scenario require a large number of queries to successfully disrupt the adversary's image translation network. In this work we propose Leaking Transferable Perturbations (LTP), an algorithm that significantly reduces the number of queries needed to disrupt an image translation network by dynamically re-purposing previous disruptions into new query efficient disruptions.","https://ojs.aaai.org/index.php/AAAI/article/view/26693/26465"
"26694","Daycare Matching in Japan: Transfers and Siblings","['Zhaohong Sun', 'Yoshihiro Takenami', 'Daisuke Moriwaki', 'Yoji Tomita', 'Makoto Yokoo']","['CyberAgent, Inc.', 'CyberAgent, Inc.', 'CyberAgent, Inc.', 'CyberAgent, Inc.', 'Kyushu University, Japan']","['General']","Sun, Z., Takenami, Y., Moriwaki, D., Tomita, Y., & Yokoo, M. (2023). Daycare Matching in Japan: Transfers and Siblings. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14487-14495. https://doi.org/10.1609/aaai.v37i12.26694","Abstract 					In this paper, we study a daycare matching problem in Japan and report the design and implementation of a new centralized algorithm, which is going to be deployed in one municipality in the Tokyo metropolis. There are two features that make this market different from the classical hospital-doctor matching problem: i) some children are initially enrolled and prefer to be transferred to other daycare centers; ii) one family may be associated with two or more children and is allowed to submit preferences over combinations of daycare centers. We revisit some well-studied properties including individual rationality, non-wastefulness, as well as stability, and generalize them to this new setting. We design an algorithm based on integer programming (IP) that captures these properties and conduct experiments on five real-life data sets provided by three municipalities. Experimental results show that i) our algorithm performs at least as well as currently used methods in terms of numbers of matched children and blocking coalition; ii) we can find a stable outcome for all instances, although the existence of such an outcome is not guaranteed in theory.","https://ojs.aaai.org/index.php/AAAI/article/view/26694/26466"
"26695","City-Scale Pollution Aware Traffic Routing by Sampling Max Flows Using MCMC","['Shreevignesh Suriyanarayanan', 'Praveen Paruchuri', 'Girish Varma']","['IIIT Hyderabad', 'IIIT Hyderabad', 'IIIT Hyderabad']","['General']","Suriyanarayanan, S., Paruchuri, P., & Varma, G. (2023). City-Scale Pollution Aware Traffic Routing by Sampling Max Flows Using MCMC. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14496-14503. https://doi.org/10.1609/aaai.v37i12.26695","Abstract 					A significant cause of air pollution in urban areas worldwide is the high volume of road traffic. Long-term exposure to severe pollution can cause serious health issues. One approach towards tackling this problem is to design a pollution-aware traffic routing policy that balances multiple objectives of i) avoiding extreme pollution in any area ii) enabling short transit times, and iii) making effective use of the road capacities. We propose a novel sampling-based approach for this problem. We give the first construction of a Markov Chain that can sample integer max flow solutions of a planar graph, with theoretical guarantees that the probabilities depend on the aggregate transit length. We designed a traffic policy using diverse samples and simulated traffic on real-world road maps using the SUMO traffic simulator. We observe a considerable decrease in areas with severe pollution when experimented with maps of large cities across the world compared to other approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/26695/26467"
"26696","Weather2vec: Representation Learning for Causal Inference with Non-local Confounding in Air Pollution and Climate Studies","['Mauricio Tec', 'James G. Scott', 'Corwin M. Zigler']","['Department of Biostatistics, Harvard University', 'Department of Statistics and Data Sciences, The University of Texas at Austin\nDepartment of Information, Risk, and Operations Management, The University of Texas at Austin', 'Department of Statistics and Data Sciences, The University of Texas at Austin']","['General']","Tec, M., Scott, J. G., & Zigler, C. M. (2023). Weather2vec: Representation Learning for Causal Inference with Non-local Confounding in Air Pollution and Climate Studies. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14504-14513. https://doi.org/10.1609/aaai.v37i12.26696","Abstract 					Estimating the causal effects of a spatially-varying intervention on a spatially-varying outcome may be subject to non-local confounding (NLC), a phenomenon that can bias estimates when the treatments and outcomes of a given unit are dictated in part by the covariates of other nearby units. In particular, NLC is a challenge for evaluating the effects of environmental policies and climate events on health-related outcomes such as air pollution exposure. This paper first formalizes NLC using the potential outcomes framework, providing a comparison with the related phenomenon of causal interference. Then, it proposes a broadly applicable framework, termed weather2vec, that uses the theory of balancing scores to learn representations of non-local information into a scalar or vector defined for each observational unit, which is subsequently used to adjust for confounding in conjunction with causal inference methods. The framework is evaluated in a simulation study and two case studies on air pollution where the weather is an (inherently regional) known confounder.","https://ojs.aaai.org/index.php/AAAI/article/view/26696/26468"
"26697","Evaluating Digital Agriculture Recommendations with Causal Inference","['Ilias Tsoumas', 'Georgios Giannarakis', 'Vasileios Sitokonstantinou', 'Alkiviadis Koukos', 'Dimitra Loka', 'Nikolaos Bartsotas', 'Charalampos Kontoes', 'Ioannis Athanasiadis']","['National Observatory of Athens\nWageningen University & Research', 'National Observatory of Athens', 'National Observatory of Athens', 'National Observatory of Athens', 'Hellenic Agricultural Organization ELGO DIMITRA', 'National Observatory of Athens', 'National Observatory of Athens', 'Wageningen University & Research']","['General']","Tsoumas, I., Giannarakis, G., Sitokonstantinou, V., Koukos, A., Loka, D., Bartsotas, N., Kontoes, C., & Athanasiadis, I. (2023). Evaluating Digital Agriculture Recommendations with Causal Inference. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14514-14522. https://doi.org/10.1609/aaai.v37i12.26697","Abstract 					In contrast to the rapid digitalization of several industries, agriculture suffers from low adoption of smart farming tools. Even though recent advancements in AI-driven digital agriculture can offer high-performing predictive functionalities, they lack tangible quantitative evidence on their benefits to the farmers. Field experiments can derive such evidence, but are often costly, time consuming and hence limited in scope and scale of application. To this end, we propose an observational causal inference framework for the empirical evaluation of the impact of digital tools on target farm performance indicators (e.g., yield in this case). This way, we can increase farmers' trust via enhancing the transparency of the digital agriculture market, and in turn accelerate the adoption of technologies that aim to secure farmer income resilience and global agricultural sustainability against a changing climate. As a case study, we designed and implemented a recommendation system for the optimal sowing time of cotton based on numerical weather predictions, which was used by a farmers' cooperative during the growing season of 2021. We then leverage agricultural knowledge, collected yield data, and environmental information to develop a causal graph of the farm system. Using the back-door criterion, we identify the impact of sowing recommendations on the yield and subsequently estimate it using linear regression, matching, inverse propensity score weighting and meta-learners. The results revealed that a field sown according to our recommendations exhibited a statistically significant yield increase that ranged from 12% to 17%, depending on the method. The effect estimates were robust, as indicated by the agreement among the estimation methods and four successful refutation tests. We argue that this approach can be implemented for decision support systems of other fields, extending their evaluation beyond a performance assessment of internal functionalities.","https://ojs.aaai.org/index.php/AAAI/article/view/26697/26469"
"26698","Everyone’s Voice Matters: Quantifying Annotation Disagreement Using Demographic Information","['Ruyuan Wan', 'Jaehyung Kim', 'Dongyeop Kang']","['University of Notre Dame', 'KAIST', 'University of Minnesota']","['General']","Wan, R., Kim, J., & Kang, D. (2023). Everyone’s Voice Matters: Quantifying Annotation Disagreement Using Demographic Information. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14523-14530. https://doi.org/10.1609/aaai.v37i12.26698","Abstract 					In NLP annotation, it is common to have multiple annotators label the text and then obtain the ground truth labels based on major annotators’ agreement. However, annotators are individuals with different backgrounds and various voices. When annotation tasks become subjective, such as detecting politeness, offense, and social norms, annotators’ voices differ and vary. Their diverse voices may represent the true distribution of people’s opinions on subjective matters. Therefore, it is crucial to study the disagreement from annotation to understand which content is controversial from the annotators. In our research, we extract disagreement labels from five subjective datasets, then fine-tune language models to predict annotators’ disagreement. Our results show that knowing annotators’ demographic information (e.g., gender, ethnicity, education level), in addition to the task text, helps predict the disagreement. To investigate the effect of annotators’ demographics on their disagreement level, we simulate different combinations of their artificial demographics and explore the variance of the prediction to distinguish the disagreement from the inherent controversy from text content and the disagreement in the annotators’ perspective. Overall, we propose an innovative disagreement prediction mechanism for better design of the annotation process that will achieve more accurate and inclusive results for NLP systems. Our code and dataset are publicly available.","https://ojs.aaai.org/index.php/AAAI/article/view/26698/26470"
"26699","MixFairFace: Towards Ultimate Fairness via MixFair Adapter in Face Recognition","['Fu-En Wang', 'Chien-Yi Wang', 'Min Sun', 'Shang-Hong Lai']","['Microsoft AI R&D Center, Taiwan\nNational Tsing Hua University, Taiwan', 'Microsoft AI R&D Center, Taiwan', 'National Tsing Hua University, Taiwan', 'Microsoft AI R&D Center, Taiwan\nNational Tsing Hua University, Taiwan']","['General']","Wang, F.-E., Wang, C.-Y., Sun, M., & Lai, S.-H. (2023). MixFairFace: Towards Ultimate Fairness via MixFair Adapter in Face Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14531-14538. https://doi.org/10.1609/aaai.v37i12.26699","Abstract 					Although significant progress has been made in face recognition, demographic bias still exists in face recognition systems. For instance, it usually happens that the face recognition performance for a certain demographic group is lower than the others. In this paper, we propose MixFairFace framework to improve the fairness in face recognition models. First of all, we argue that the commonly used attribute-based fairness metric is not appropriate for face recognition. A face recognition system can only be considered fair while every person has a close performance. Hence, we propose a new evaluation protocol to fairly evaluate the fairness performance of different approaches. Different from previous approaches that require sensitive attribute labels such as race and gender for reducing the demographic bias, we aim at addressing the identity bias in face representation, i.e., the performance inconsistency between different identities, without the need for sensitive attribute labels. To this end, we propose MixFair Adapter to determine and reduce the identity bias of training samples. Our extensive experiments demonstrate that our MixFairFace approach achieves state-of-the-art fairness performance on all benchmark datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26699/26471"
"26700","PateGail: A Privacy-Preserving Mobility Trajectory Generator with Imitation Learning","['Huandong Wang', 'Changzheng Gao', 'Yuchen Wu', 'Depeng Jin', 'Lina Yao', 'Yong Li']","['Tsinghua University', 'Tsinghua university', 'Carnegie Mellon University', 'Tsinghua University', ""CSIRO's Data61 and University of New South Wales"", 'Tsinghua University']","['General']","Wang, H., Gao, C., Wu, Y., Jin, D., Yao, L., & Li, Y. (2023). PateGail: A Privacy-Preserving Mobility Trajectory Generator with Imitation Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14539-14547. https://doi.org/10.1609/aaai.v37i12.26700","Abstract 					Generating human mobility trajectories is of great importance to solve the lack of large-scale trajectory data in numerous applications, which is caused by privacy concerns. However, existing mobility trajectory generation methods still require real-world human trajectories centrally collected as the training data, where there exists an inescapable risk of privacy leakage. To overcome this limitation, in this paper, we propose PateGail, a privacy-preserving imitation learning model to generate mobility trajectories, which utilizes the powerful generative adversary imitation learning model to simulate the decision-making process of humans. Further, in order to protect user privacy, we train this model collectively based on decentralized mobility data stored in user devices, where personal discriminators are trained locally to distinguish and reward the real and generated human trajectories. In the training process, only the generated trajectories and their rewards obtained based on personal discriminators are shared between the server and devices, whose privacy is further preserved by our proposed perturbation mechanisms with theoretical proof to satisfy differential privacy. Further, to better model the human decision-making process, we propose a novel aggregation mechanism of the rewards obtained from personal discriminators. We theoretically prove that under the reward obtained based on the aggregation mechanism, our proposed model maximizes the lower bound of the discounted total rewards of users. Extensive experiments show that the trajectories generated by our model are able to resemble real-world trajectories in terms of five key statistical metrics, outperforming state-of-the-art algorithms by over 48.03%. Furthermore, we demonstrate that the synthetic trajectories are able to efficiently support practical applications, including mobility prediction and location recommendation.","https://ojs.aaai.org/index.php/AAAI/article/view/26700/26472"
"26701","Noise Based Deepfake Detection via Multi-Head Relative-Interaction","['Tianyi Wang', 'Kam Pui Chow']","['The University of Hong Kong', 'The University of Hong Kong']","['General']","Wang, T., & Chow, K. P. (2023). Noise Based Deepfake Detection via Multi-Head Relative-Interaction. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14548-14556. https://doi.org/10.1609/aaai.v37i12.26701","Abstract 					Deepfake brings huge and potential negative impacts to our daily lives. As the real-life Deepfake videos circulated on the Internet become more authentic, most existing detection algorithms have failed since few visual differences can be observed between an authentic video and a Deepfake one. However, the forensic traces are always retained within the synthesized videos. In this study, we present a noise-based Deepfake detection model, NoiseDF for short, which focuses on the underlying forensic noise traces left behind the Deepfake videos. In particular, we enhance the RIDNet denoiser to extract noise traces and features from the cropped face and background squares of the video image frames. Meanwhile, we devise a novel Multi-Head Relative-Interaction method to evaluate the degree of interaction between the faces and backgrounds that plays a pivotal role in the Deepfake detection task. Besides outperforming the state-of-the-art models, the visualization of the extracted Deepfake forensic noise traces has further displayed the evidence and proved the robustness of our approach.","https://ojs.aaai.org/index.php/AAAI/article/view/26701/26473"
"26702","Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation","['Sheng Xiang', 'Mingzhi Zhu', 'Dawei Cheng', 'Enxia Li', 'Ruihui Zhao', 'Yi Ouyang', 'Ling Chen', 'Yefeng Zheng']","['University of Technology Sydney', 'Tongji University', 'Tongji University', 'University of Technology Sydney', 'Tencent Jarvis Laboratory', 'Tencent Jarvis Laboratory', 'University of Technology Sydney', 'Tencent Jarvis Laboratory']","['General']","Xiang, S., Zhu, M., Cheng, D., Li, E., Zhao, R., Ouyang, Y., Chen, L., & Zheng, Y. (2023). Semi-supervised Credit Card Fraud Detection via Attribute-Driven Graph Representation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14557-14565. https://doi.org/10.1609/aaai.v37i12.26702","Abstract 					Credit card fraud incurs a considerable cost for both cardholders and issuing banks. Contemporary methods apply machine learning-based classifiers to detect fraudulent behavior from labeled transaction records. But labeled data are usually a small proportion of billions of real transactions due to expensive labeling costs, which implies that they do not well exploit many natural features from unlabeled data. Therefore, we propose a semi-supervised graph neural network for fraud detection. Specifically, we leverage transaction records to construct a temporal transaction graph, which is composed of temporal transactions (nodes) and interactions (edges) among them. Then we pass messages among the nodes through a Gated Temporal Attention Network (GTAN) to learn the transaction representation. We further model the fraud patterns through risk propagation among transactions. The extensive experiments are conducted on a real-world transaction dataset and two publicly available fraud detection datasets. The result shows that our proposed method, namely GTAN, outperforms other state-of-the-art baselines on three fraud detection datasets. Semi-supervised experiments demonstrate the excellent fraud detection performance of our model with only a tiny proportion of labeled data.","https://ojs.aaai.org/index.php/AAAI/article/view/26702/26474"
"26703","Privacy-Preserved Evolutionary Graph Modeling via Gromov-Wasserstein Autoregression","['Yue Xiang', 'Dixin Luo', 'Hongteng Xu']","['School of Statistics, Renmin University of China', 'School of Computer Science and Technology, Beijing Institute of Technology', 'Gaoling School of Artificial Intelligence, Renmin University of China\nBeijing Key Laboratory of Big Data Management and Analysis Methods']","['General']","Xiang, Y., Luo, D., & Xu, H. (2023). Privacy-Preserved Evolutionary Graph Modeling via Gromov-Wasserstein Autoregression. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14566-14574. https://doi.org/10.1609/aaai.v37i12.26703","Abstract 					Real-world graphs like social networks are often evolutionary over time, whose observations at different timestamps lead to graph sequences. Modeling such evolutionary graphs is important for many applications, but solving this problem often requires the correspondence between the graphs at different timestamps, which may leak private node information, e.g., the temporal behavior patterns of the nodes. We proposed a Gromov-Wasserstein Autoregressive (GWAR) model to capture the generative mechanisms of evolutionary graphs, which does not require the correspondence information and thus preserves the privacy of the graphs' nodes. This model consists of two autoregressions, predicting the number of nodes and the probabilities of nodes and edges, respectively. The model takes observed graphs as its input and predicts future graphs via solving a joint graph alignment and merging task. This task leads to a fused Gromov-Wasserstein (FGW) barycenter problem, in which we approximate the alignment of the graphs based on a novel inductive fused Gromov-Wasserstein (IFGW) distance. The IFGW distance is parameterized by neural networks and can be learned under mild assumptions, thus, we can infer the FGW barycenters without iterative optimization and predict future graphs efficiently. Experiments show that our GWAR achieves encouraging performance in modeling evolutionary graphs in privacy-preserving scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/26703/26475"
"26704","Auto-CM: Unsupervised Deep Learning for Satellite Imagery Composition and Cloud Masking Using Spatio-Temporal Dynamics","['Yiqun Xie', 'Zhili Li', 'Han Bao', 'Xiaowei Jia', 'Dongkuan Xu', 'Xun Zhou', 'Sergii Skakun']","['University of Maryland', 'University of Maryland', 'University of Iowa', 'University of Pittsburgh', 'North Carolina State University', 'University of Iowa', 'University of Maryland']","['General']","Xie, Y., Li, Z., Bao, H., Jia, X., Xu, D., Zhou, X., & Skakun, S. (2023). Auto-CM: Unsupervised Deep Learning for Satellite Imagery Composition and Cloud Masking Using Spatio-Temporal Dynamics. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14575-14583. https://doi.org/10.1609/aaai.v37i12.26704","Abstract 					Cloud masking is both a fundamental and a critical task in the vast majority of Earth observation problems across social sectors, including agriculture, energy, water, etc. The sheer volume of satellite imagery to be processed has fast-climbed to a scale (e.g., >10 PBs/year) that is prohibitive for manual processing. Meanwhile, generating reliable cloud masks and image composite is increasingly challenging due to the continued distribution-shifts in the imagery collected by existing sensors and the ever-growing variety of sensors and platforms. Moreover, labeled samples are scarce and geographically limited compared to the needs in real large-scale applications. In related work, traditional remote sensing methods are often physics-based and rely on special spectral signatures from multi- or hyper-spectral bands, which are often not available in data collected by many -- and especially more recent -- high-resolution platforms. Machine learning and deep learning based methods, on the other hand, often require large volumes of up-to-date training data to be reliable and generalizable over space. We propose an autonomous image composition and masking (Auto-CM) framework to learn to solve the fundamental tasks in a label-free manner, by leveraging different dynamics of events in both geographic domains and time-series. Our experiments show that Auto-CM outperforms existing methods on a wide-range of data with different satellite platforms, geographic regions and bands.","https://ojs.aaai.org/index.php/AAAI/article/view/26704/26476"
"26705","ERASER: AdvERsArial Sensitive Element Remover for Image Privacy Preservation","['Guang Yang', 'Juan Cao', 'Danding Wang', 'Peng Qi', 'Jintao Li']","['Zhongguancun Laboratory\nKey Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences', 'Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences']","['General']","Yang, G., Cao, J., Wang, D., Qi, P., & Li, J. (2023). ERASER: AdvERsArial Sensitive Element Remover for Image Privacy Preservation. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14584-14592. https://doi.org/10.1609/aaai.v37i12.26705","Abstract 					The daily practice of online image sharing enriches our lives, but also raises a severe issue of privacy leakage. To mitigate the privacy risks during image sharing, some researchers modify the sensitive elements in images with visual obfuscation methods including traditional ones like blurring and pixelating, as well as generative ones based on deep learning. However, images processed by such methods may be recovered or recognized by models, which cannot guarantee privacy. Further, traditional methods make the images very unnatural with low image quality. Although generative methods produce better images, most of them suffer from insufficiency in the frequency domain, which influences image quality. Therefore, we propose the AdvERsArial Sensitive Element Remover (ERASER) to guarantee both image privacy and image quality. 1) To preserve image privacy, for the regions containing sensitive elements, ERASER guarantees enough difference after being modified in an adversarial way. Specifically, we take both the region and global content into consideration with a Prior Transformer and obtain the corresponding region prior and global prior. Based on the priors, ERASER is trained with an adversarial Difference Loss to make the content in the regions different. As a result, ERASER can reserve the main structure and change the texture of the target regions for image privacy preservation. 2) To guarantee the image quality, ERASER improves the frequency insufficiency of current generative methods. Specifically, the region prior and global prior are processed with Fast Fourier Convolution to capture characteristics and achieve consistency in both pixel and frequency domains. Quantitative analyses demonstrate that the proposed ERASER achieves a balance between image quality and image privacy preservation, while qualitative analyses demonstrate that ERASER indeed reduces the privacy risk from the visual perception aspect.","https://ojs.aaai.org/index.php/AAAI/article/view/26705/26477"
"26706","Deep Learning on a Healthy Data Diet: Finding Important Examples for Fairness","['Abdelrahman Zayed', 'Prasanna Parthasarathi', 'Gonçalo Mordido', 'Hamid Palangi', 'Samira Shabanian', 'Sarath Chandar']","['Mila - Quebec AI Institute\nPolytechnique Montreal', 'Mila - Quebec AI Institute\nMcGill University', 'Mila - Quebec AI Institute\nPolytechnique Montreal', 'Microsoft Research', 'Microsoft Research', 'Mila - Quebec AI Institute\nPolytechnique Montreal\nCanada CIFAR AI Chair']","['General']","Zayed, A., Parthasarathi, P., Mordido, G., Palangi, H., Shabanian, S., & Chandar, S. (2023). Deep Learning on a Healthy Data Diet: Finding Important Examples for Fairness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14593-14601. https://doi.org/10.1609/aaai.v37i12.26706","Abstract 					Data-driven predictive solutions predominant in commercial applications tend to suffer from biases and stereotypes, which raises equity concerns. Prediction models may discover, use, or amplify spurious correlations based on gender or other protected personal characteristics, thus discriminating against marginalized groups. Mitigating gender bias has become an important research focus in natural language processing (NLP) and is an area where annotated corpora are available. Data augmentation reduces gender bias by adding counterfactual examples to the training dataset. In this work, we show that some of the examples in the augmented dataset can be not important or even harmful to fairness. We hence propose a general method for pruning both the factual and counterfactual examples to maximize the model’s fairness as measured by the demographic parity, equality of opportunity, and equality of odds. The fairness achieved by our method surpasses that of data augmentation on three text classification datasets, using no more than half of the examples in the augmented dataset. Our experiments are conducted using models of varying sizes and pre-training settings. WARNING: This work uses language that is offensive in nature.","https://ojs.aaai.org/index.php/AAAI/article/view/26706/26478"
"26707","On the Effectiveness of Curriculum Learning in Educational Text Scoring","['Zijie Zeng', 'Dragan Gasevic', 'Guangliang Chen']","['Monash University', 'Monash University', 'Monash University']","['General']","Zeng, Z., Gasevic, D., & Chen, G. (2023). On the Effectiveness of Curriculum Learning in Educational Text Scoring. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14602-14610. https://doi.org/10.1609/aaai.v37i12.26707","Abstract 					Automatic Text Scoring (ATS) is a widely-investigated task in education. Existing approaches often stressed the structure design of an ATS model and neglected the training process of the model. Considering the difficult nature of this task, we argued that the performance of an ATS model could be potentially boosted by carefully selecting data of varying complexities in the training process. Therefore, we aimed to investigate the effectiveness of curriculum learning (CL) in scoring educational text. Specifically, we designed two types of difficulty measurers: (i) pre-defined, calculated by measuring a sample's readability, length, the number of grammatical errors or unique words it contains; and (ii) automatic, calculated based on whether a model in a training epoch can accurately score the samples. These measurers were tested in both the easy-to-hard to hard-to-easy training paradigms. Through extensive evaluations on two widely-used datasets (one for short answer scoring and the other for long essay scoring), we demonstrated that (a) CL indeed could boost the performance of state-of-the-art ATS models, and the maximum improvement could be up to 4.5%, but most improvements were achieved when assessing short and easy answers; (b) the pre-defined measurer calculated based on the number of grammatical errors contained in a text sample tended to outperform the other difficulty measurers across different training paradigms.","https://ojs.aaai.org/index.php/AAAI/article/view/26707/26479"
"26708","Censored Fairness through Awareness","['Wenbin Zhang', 'Tina Hernandez-Boussard', 'Jeremy Weiss']","['Michigan Technological University', 'Stanford University', 'National Institutes of Health']","['General']","Zhang, W., Hernandez-Boussard, T., & Weiss, J. (2023). Censored Fairness through Awareness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14611-14619. https://doi.org/10.1609/aaai.v37i12.26708","Abstract 					There has been increasing concern within the machine learning community and beyond that Artificial Intelligence (AI) faces a bias and discrimination crisis which needs AI fairness with urgency. As many have begun to work on this problem, most existing work depends on the availability of class label for the given fairness definition and algorithm which may not align with real-world usage. In this work, we study an AI fairness problem that stems from the gap between the design of a ""fair"" model in the lab and its deployment in the real-world. Specifically, we consider defining and mitigating individual unfairness amidst censorship, where the availability of class label is not always guaranteed due to censorship, which is broadly applicable in a diversity of real-world socially sensitive applications. We show that our method is able to quantify and mitigate individual unfairness in the presence of censorship across three benchmark tasks, which provides the first known results on individual fairness guarantee in analysis of censored data.","https://ojs.aaai.org/index.php/AAAI/article/view/26708/26480"
"26709","A Continual Pre-training Approach to Tele-Triaging Pregnant Women in Kenya","['Wenbo Zhang', 'Hangzhi Guo', 'Prerna Ranganathan', 'Jay Patel', 'Sathyanath Rajasekharan', 'Nidhi Danayak', 'Manan Gupta', 'Amulya Yadav']","['Pennsylvania State University', 'Pennsylvania State University', 'Pennsylvania State University', 'Jacaranda Health', 'Jacaranda Health', 'Pennsylvania State University', 'Pennsylvania State University', 'Pennsylvania State University']","['General']","Zhang, W., Guo, H., Ranganathan, P., Patel, J., Rajasekharan, S., Danayak, N., Gupta, M., & Yadav, A. (2023). A Continual Pre-training Approach to Tele-Triaging Pregnant Women in Kenya. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14620-14627. https://doi.org/10.1609/aaai.v37i12.26709","Abstract 					Access to high-quality maternal health care services is limited in Kenya, which resulted in ∼36,000 maternal and neonatal deaths in 2018. To tackle this challenge, Jacaranda Health (a non-profit organization working on maternal health in Kenya) developed PROMPTS, an SMS based tele-triage system for pregnant and puerperal women, which has more than 350,000 active users in Kenya. PROMPTS empowers pregnant women living far away from doctors and hospitals to send SMS messages to get quick answers (through human helpdesk agents) to questions about their medical symptoms and pregnancy status. Unfortunately, ∼1.1 million SMS messages are received by PROMPTS every month, which makes it challenging for helpdesk agents to ensure that these messages can be interpreted correctly and evaluated by their level of emergency to ensure timely responses and/or treatments for women in need. This paper reports on a collaborative effort with Jacaranda Health to develop a state-of-the-art natural language processing (NLP) framework, TRIM-AI (TRIage for Mothers using AI), which can automatically predict the emergency level (or severity of medical condition) of a pregnant mother based on the content of their SMS messages. TRIM-AI leverages recent advances in multi-lingual pre-training and continual pre-training to tackle code-mixed SMS messages (between English and Swahili), and achieves a weighted F1 score of 0.774 on real-world datasets. TRIM-AI has been successfully deployed in the field since June 2022, and is being used by Jacaranda Health to prioritize the provision of services and care to pregnant women with the most critical medical conditions. Our preliminary A/B tests in the field show that TRIM-AI is ∼17% more accurate at predicting high-risk medical conditions from SMS messages sent by pregnant Kenyan mothers, which reduces the helpdesk’s workload by ∼12%.","https://ojs.aaai.org/index.php/AAAI/article/view/26709/26481"
"26710","Future Aware Pricing and Matching for Sustainable On-Demand Ride Pooling","['Xianjie Zhang', 'Pradeep Varakantham', 'Hao Jiang']","['Key Laboratory for Ubiquitous Network and Service Software of Liaoning Province, School of Software, Dalian University of Technology\nSingapore Management University', 'Singapore Management University', 'Singapore Management University']","['General']","Zhang, X., Varakantham, P., & Jiang, H. (2023). Future Aware Pricing and Matching for Sustainable On-Demand Ride Pooling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14628-14636. https://doi.org/10.1609/aaai.v37i12.26710","Abstract 					The popularity of on-demand ride pooling is owing to the benefits offered to customers (lower prices), taxi drivers (higher revenue), environment (lower carbon footprint due to fewer vehicles) and aggregation companies like Uber (higher revenue). To achieve these benefits, two key interlinked challenges have to be solved effectively: (a) pricing -- setting prices to customer requests for taxis; and (b) matching -- assignment of customers (that accepted the prices) to taxis/cars. Traditionally, both these challenges have been studied individually and using myopic approaches (considering only current requests), without considering the impact of current matching on addressing future requests. In this paper, we develop a novel framework that handles the pricing and matching problems together, while also considering the future impact of the pricing and matching decisions. In our experimental results on a real-world taxi dataset, we demonstrate that our framework can significantly improve revenue (up to 17% and on average 6.4%) in a sustainable manner by reducing the number of vehicles  (up to 14% and on average 10.6%) required to obtain a given fixed revenue and the overall distance travelled by vehicles (up to 11.1% and on average 3.7%). That is to say, we are able to provide an ideal win-win scenario for all stakeholders (customers, drivers, aggregator, environment) involved by obtaining higher revenue for customers, drivers, aggregator (ride pooling company) while being good for the environment (due to fewer number of vehicles on the road and lesser fuel consumed).","https://ojs.aaai.org/index.php/AAAI/article/view/26710/26482"
"26711","A Crowd-AI Collaborative Duo Relational Graph Learning Framework towards Social Impact Aware Photo Classification","['Yang Zhang', 'Ziyi Kou', 'Lanyu Shang', 'Huimin Zeng', 'Zhenrui Yue', 'Dong Wang']","['University of Illinois Urbana-Champaign', 'University of Notre Dame', 'University of Illinois Urbana-Champaign', 'University of Illinois Urbana-Champaign', 'University of Illinois Urbana-Champaign', 'University of Illinois Urbana-Champaign']","['General']","Zhang, Y., Kou, Z., Shang, L., Zeng, H., Yue, Z., & Wang, D. (2023). A Crowd-AI Collaborative Duo Relational Graph Learning Framework towards Social Impact Aware Photo Classification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14637-14645. https://doi.org/10.1609/aaai.v37i12.26711","Abstract 					In artificial intelligence (AI), negative social impact (NSI) represents the negative effect on the society as a result of mistakes conducted by AI agents. While the photo classification problem has been widely studied in the AI community, the NSI made by photo misclassification is largely ignored due to the lack of quantitative measurements of the NSI and effective approaches to reduce it. In this paper, we focus on an NSI-aware photo classification problem where the goal is to develop a novel crowd-AI collaborative learning framework that leverages online crowd workers to quantitatively estimate and effectively reduce the NSI of misclassified photos. Our problem is motivated by the limitations of current NSI-aware photo classification approaches that either 1) cannot accurately estimate NSI because they simply model NSI as the semantic difference between true and misclassified categories or 2) require costly human annotations to estimate NSI of pairwise class categories. To address such limitations, we develop SocialCrowd, a crowdsourcing-based NSI-aware photo classification framework that explicitly reduces the NSI of photo misclassification by designing a duo relational NSI-aware graph with the NSI estimated by online crowd workers. The evaluation results on two large-scale image datasets show that SocialCrowd not only reduces the NSI of photo misclassification but also improves the classification accuracy on both datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26711/26483"
"26712","People Taking Photos That Faces Never Share: Privacy Protection and Fairness Enhancement from Camera to User","['Junjie Zhu', 'Lin Gu', 'Xiaoxiao Wu', 'Zheng Li', 'Tatsuya Harada', 'Yingying Zhu']","['Shenzhen University', 'RIKEN\nThe University of Tokyo', 'Shenzhen University', 'Stockton University', 'The University of Tokyo\nRIKEN', 'University of Texas Arlington']","['General']","Zhu, J., Gu, L., Wu, X., Li, Z., Harada, T., & Zhu, Y. (2023). People Taking Photos That Faces Never Share: Privacy Protection and Fairness Enhancement from Camera to User. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14646-14654. https://doi.org/10.1609/aaai.v37i12.26712","Abstract 					The soaring number of personal mobile devices and public cameras poses a threat to fundamental human rights and ethical principles. For example, the stolen of private information such as face image by malicious third parties will lead to catastrophic consequences. By manipulating appearance of face in the image, most of existing protection algorithms are effective but irreversible. Here, we propose a practical and systematic solution to invertiblely protect face information in the full-process pipeline from camera to final users. Specifically, We design a novel lightweight Flow-based Face Encryption Method (FFEM) on the local embedded system privately connected to the camera,  minimizing the risk of  eavesdropping during data transmission. FFEM uses a flow-based face encoder to encode each face to a Gaussian distribution and encrypts the encoded face feature by random rotating the Gaussian distribution with the rotation matrix is as the password. While encrypted latent-variable face  images  are sent to users through public but less reliable channels, password will be protected through more secure channels through technologies such as asymmetric encryption, blockchain, or other sophisticated security schemes. User could select to decode an image with fake faces from the encrypted image on the public channel. Only trusted users are able to recover the original face  using the encrypted matrix transmitted in secure channel. More interestingly, by  tuning Gaussian ball in latent space, we could control the fairness of the replaced face on attributes such as gender and race. Extensive experiments demonstrate that our solution could protect privacy and enhance fairness with minimal effect on high-level downstream task.","https://ojs.aaai.org/index.php/AAAI/article/view/26712/26484"
"26713","OpenMapFlow: A Library for Rapid Map Creation with Machine Learning and Remote Sensing Data","['Ivan Zvonkov', 'Gabriel Tseng', 'Catherine Nakalembe', 'Hannah Kerner']","['University of Maryland, College Park', 'McGill University and Mila – Quebec AI Institute', 'University of Maryland, College Park', 'Arizona State University']","['General']","Zvonkov, I., Tseng, G., Nakalembe, C., & Kerner, H. (2023). OpenMapFlow: A Library for Rapid Map Creation with Machine Learning and Remote Sensing Data. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14655-14663. https://doi.org/10.1609/aaai.v37i12.26713","Abstract 					The desired output for most real-world tasks using machine learning (ML) and remote sensing data is a set of dense predictions that form a predicted map for a geographic region. However, most prior work involving ML and remote sensing follows the traditional practice of reporting metrics on a set of independent, geographically-sparse samples and does not perform dense predictions. To reduce the labor of producing dense prediction maps, we present OpenMapFlow---an open-source python library for rapid map creation with ML and remote sensing data. OpenMapFlow provides 1) a data processing pipeline for users to create labeled datasets for any region, 2) code to train state-of-the-art deep learning models on custom or existing datasets, and 3) a cloud-based architecture to deploy models for efficient map prediction. We demonstrate the benefits of OpenMapFlow through experiments on three binary classification tasks: cropland, crop type (maize), and building mapping. We show that OpenMapFlow drastically reduces the time required for dense prediction compared to traditional workflows. We hope this library will stimulate novel research in areas such as domain shift, unsupervised learning, and societally-relevant applications and lessen the barrier to adopting research methods for real-world tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26713/26485"
"26714","Formally Verified SAT-Based AI Planning","['Mohammad Abdulaziz', 'Friedrich Kurz']","[""King's College London\nTechnische Universität München"", 'Technische Universität München']","['General']","Abdulaziz, M., & Kurz, F. (2023). Formally Verified SAT-Based AI Planning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14665-14673. https://doi.org/10.1609/aaai.v37i12.26714","Abstract 					We present an executable formally verified SAT encoding of ground classical AI planning problems. We use the theorem prover Isabelle/HOL to perform the verification. We experimentally test the verified encoding and show that it can be used for reasonably sized standard planning benchmarks. We also use it as a reference to test a state-of-the-art SAT-based planner, showing that it sometimes falsely claims that problems have no solutions of certain lengths.","https://ojs.aaai.org/index.php/AAAI/article/view/26714/26486"
"26715","Shielding in Resource-Constrained Goal POMDPs","['Michal Ajdarów', 'Šimon Brlej', 'Petr Novotný']","['Faculty of Informatics, Masaryk University', 'Faculty of Informatics, Masaryk University', 'Faculty of Informatics, Masaryk University']","['General']","Ajdarów, M., Brlej, Šimon, & Novotný, P. (2023). Shielding in Resource-Constrained Goal POMDPs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14674-14682. https://doi.org/10.1609/aaai.v37i12.26715","Abstract 					We consider partially observable Markov decision processes (POMDPs) modeling an agent that needs a supply of a certain resource (e.g., electricity stored in batteries) to operate correctly. The resource is consumed by the agent's actions and can be replenished only in certain states. The agent aims to minimize the expected cost of reaching some goal while preventing resource exhaustion, a problem we call resource-constrained goal optimization (RSGO). We take a two-step approach to the RSGO problem. First, using formal methods techniques, we design an algorithm computing a shield for a given scenario: a procedure that observes the agent and prevents it from using actions that might eventually lead to resource exhaustion. Second, we augment the POMCP heuristic search algorithm for POMDP planning with our shields to obtain an algorithm solving the RSGO problem. We implement our algorithm and present experiments showing its applicability to benchmarks from the literature.","https://ojs.aaai.org/index.php/AAAI/article/view/26715/26487"
"26716","Implicit Bilevel Optimization: Differentiating through Bilevel Optimization Programming","['Francesco Alesiani']","['NEC Laboratories Europe']","['General']","Alesiani, F. (2023). Implicit Bilevel Optimization: Differentiating through Bilevel Optimization Programming. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14683-14691. https://doi.org/10.1609/aaai.v37i12.26716","Abstract 					Bilevel Optimization Programming is used to model complex and conflicting interactions between agents, for example in Robust AI or Privacy preserving AI. Integrating bilevel mathematical programming within deep learning is thus an essential objective for the Machine Learning community.   Previously proposed approaches only consider single-level programming. In this paper, we extend existing single-level optimization programming approaches and thus propose Differentiating through Bilevel Optimization Programming (BiGrad) for end-to-end learning of models that use Bilevel Programming as a layer.  BiGrad has wide applicability and can be used in modern machine learning frameworks. BiGrad is applicable to both continuous and combinatorial Bilevel optimization problems. We describe a class of gradient estimators for the combinatorial case which reduces the requirements in terms of computation complexity; for the case of the continuous variable, the gradient computation takes advantage of the push-back approach (i.e. vector-jacobian product) for an efficient implementation. Experiments show that the BiGrad successfully extends existing single-level approaches to Bilevel Programming.","https://ojs.aaai.org/index.php/AAAI/article/view/26716/26488"
"26717","Query-Based Hard-Image Retrieval for Object Detection at Test Time","['Edward Ayers', 'Jonathan Sadeghi', 'John Redford', 'Romain Mueller', 'Puneet K. Dokania']","['Five AI Ltd.', 'Five AI Ltd.', 'Five AI Ltd.', 'Five AI Ltd.', 'Five AI Ltd.']","['General']","Ayers, E., Sadeghi, J., Redford, J., Mueller, R., & Dokania, P. K. (2023). Query-Based Hard-Image Retrieval for Object Detection at Test Time. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14692-14700. https://doi.org/10.1609/aaai.v37i12.26717","Abstract 					There is a longstanding interest in capturing the error behaviour of object detectors by finding images where their performance is likely to be unsatisfactory. In real-world applications such as autonomous driving, it is also crucial to characterise potential failures beyond simple requirements of detection performance. For example, a missed detection of a pedestrian close to an ego vehicle will generally require closer inspection than a missed detection of a car in the distance. The problem of predicting such potential failures at test time  has largely been overlooked in the literature and conventional approaches based on detection uncertainty fall short in that they are agnostic to such fine-grained characterisation of errors. In this work, we propose to reformulate the problem of finding ""hard"" images as a query-based hard image retrieval task, where queries are specific definitions of ""hardness"", and offer a simple and intuitive method that can solve this task for a large family of queries. Our method is entirely post-hoc, does not require ground-truth annotations, is independent of the choice of a detector, and relies on an efficient Monte Carlo estimation that uses a simple stochastic model in place of the ground-truth. We show experimentally that it can be applied successfully to a wide variety of queries for which it can reliably identify hard images for a given detector without any labelled data. We provide results on ranking and classification tasks using the widely used RetinaNet, Faster-RCNN, Mask-RCNN, and Cascade Mask-RCNN object detectors. The code for this project is available at https://github.com/fiveai/hardest.","https://ojs.aaai.org/index.php/AAAI/article/view/26717/26489"
"26718","Probabilities Are Not Enough: Formal Controller Synthesis for Stochastic Dynamical Models with Epistemic Uncertainty","['Thom Badings', 'Licio Romao', 'Alessandro Abate', 'Nils Jansen']","['Radboud University Nijmegen', 'University of Oxford', 'University of Oxford', 'Radboud University Nijmegen']","['General']","Badings, T., Romao, L., Abate, A., & Jansen, N. (2023). Probabilities Are Not Enough: Formal Controller Synthesis for Stochastic Dynamical Models with Epistemic Uncertainty. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14701-14710. https://doi.org/10.1609/aaai.v37i12.26718","Abstract 					Capturing uncertainty in models of complex dynamical systems is crucial to designing safe controllers. Stochastic noise causes aleatoric uncertainty, whereas imprecise knowledge of model parameters leads to epistemic uncertainty. Several approaches use formal abstractions to synthesize policies that satisfy temporal specifications related to safety and reachability. However, the underlying models exclusively capture aleatoric but not epistemic uncertainty, and thus require that model parameters are known precisely. Our contribution to overcoming this restriction is a novel abstraction-based controller synthesis method for continuous-state models with stochastic noise and uncertain parameters. By sampling techniques and robust analysis, we capture both aleatoric and epistemic uncertainty, with a user-specified confidence level, in the transition probability intervals of a so-called interval Markov decision process (iMDP). We synthesize an optimal policy on this iMDP, which translates (with the specified confidence level) to a feedback controller for the continuous model with the same performance guarantees. Our experimental benchmarks confirm that accounting for epistemic uncertainty leads to controllers that are more robust against variations in parameter values.","https://ojs.aaai.org/index.php/AAAI/article/view/26718/26490"
"26719","Accelerating Inverse Learning via Intelligent Localization with Exploratory Sampling","['Sirui Bi', 'Victor Fung', 'Jiaxin Zhang']","['Walmart Global Tech', 'Georgia Institute of Technology', 'Intuit AI Research']","['General']","Bi, S., Fung, V., & Zhang, J. (2023). Accelerating Inverse Learning via Intelligent Localization with Exploratory Sampling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14711-14719. https://doi.org/10.1609/aaai.v37i12.26719","Abstract 					In the scope of ""AI for Science"", solving inverse problems is a longstanding challenge in materials and drug discovery, where the goal is to determine the hidden structures given a set of desirable properties. Deep generative models are recently proposed to solve inverse problems, but these are currently struggling in expensive forward operators, precisely localizing the exact solutions and fully exploring the parameter spaces without missing solutions. In this work, we propose a novel approach (called iPage) to accelerate the inverse learning process by leveraging probabilistic inference from deep invertible models and deterministic optimization via fast gradient descent.  Given a target property, the learned invertible model provides a posterior over the parameter space; we identify these posterior samples as an intelligent prior initialization which enables us to narrow down the search space. We then perform gradient descent to calibrate the inverse solutions within a local region. Meanwhile, a space-filling sampling is imposed on the latent space to better explore and capture all possible solutions. We evaluate our approach on three benchmark tasks and create two datasets of real-world applications from quantum chemistry and additive manufacturing and find our method achieves superior performance compared to several state-of-the-art baseline methods. The iPage code is available at https://github.com/jxzhangjhu/MatDesINNe.","https://ojs.aaai.org/index.php/AAAI/article/view/26719/26491"
"26720","Attention-Conditioned Augmentations for Self-Supervised Anomaly Detection and Localization","['Behzad Bozorgtabar', 'Dwarikanath Mahapatra']","['EPFL\nCHUV', 'Inception Institute of Artificial Intelligence']","['General']","Bozorgtabar, B., & Mahapatra, D. (2023). Attention-Conditioned Augmentations for Self-Supervised Anomaly Detection and Localization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14720-14728. https://doi.org/10.1609/aaai.v37i12.26720","Abstract 					Self-supervised anomaly detection and localization are critical to real-world scenarios in which collecting anomalous samples and pixel-wise labeling is tedious or infeasible, even worse when a wide variety of unseen anomalies could surface at test time. Our approach involves a pretext task in the context of masked image modeling, where the goal is to impose agreement between cluster assignments obtained from the representation of an image view containing saliency-aware masked patches and the uncorrupted image view. We harness the self-attention map extracted from the transformer to mask non-salient image patches without destroying the crucial structure associated with the foreground object. Subsequently, the pre-trained model is fine-tuned to detect and localize simulated anomalies generated under the guidance of the transformer's self-attention map. We conducted extensive validation and ablations on the benchmark of industrial images and achieved superior performance against competing methods. We also show the adaptability of our method to the medical images of the chest X-rays benchmark.","https://ojs.aaai.org/index.php/AAAI/article/view/26720/26492"
"26721","Robust-by-Design Classification via Unitary-Gradient Neural Networks","['Fabio Brau', 'Giulio Rossolini', 'Alessandro Biondi', 'Giorgio Buttazzo']","[""Scuola Superiore Sant'Anna"", ""Scuola Superiore Sant'Anna"", ""Scuola Superiore Sant'Anna"", ""Scuola Superiore Sant'Anna""]","['General']","Brau, F., Rossolini, G., Biondi, A., & Buttazzo, G. (2023). Robust-by-Design Classification via Unitary-Gradient Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14729-14737. https://doi.org/10.1609/aaai.v37i12.26721","Abstract 					The use of neural networks in safety-critical systems requires safe and robust models, due to the existence of adversarial attacks. Knowing the minimal adversarial perturbation of any input x, or, equivalently, knowing the distance of x from the classification boundary, allows evaluating the classification robustness, providing certifiable predictions. Unfortunately, state-of-the-art techniques for computing such a distance are computationally expensive and hence not suited for online applications. This work proposes a novel family of classifiers, namely Signed Distance Classifiers (SDCs), that, from a theoretical perspective, directly output the exact distance of x from the classification boundary, rather than a probability score (e.g., SoftMax). SDCs represent a family of robust-by-design classifiers. To practically address the theoretical requirements of an SDC, a novel network architecture named Unitary-Gradient Neural Network is presented. Experimental results show that the proposed architecture approximates a signed distance classifier, hence allowing an online certifiable classification of x at the cost of a single inference.","https://ojs.aaai.org/index.php/AAAI/article/view/26721/26493"
"26722","Ensemble-in-One: Ensemble Learning within Random Gated Networks for Enhanced Adversarial Robustness","['Yi Cai', 'Xuefei Ning', 'Huazhong Yang', 'Yu Wang']","['Tsinghua University', 'Tsinghua University', 'Tsinghua University', 'Tsinghua University']","['General']","Cai, Y., Ning, X., Yang, H., & Wang, Y. (2023). Ensemble-in-One: Ensemble Learning within Random Gated Networks for Enhanced Adversarial Robustness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14738-14747. https://doi.org/10.1609/aaai.v37i12.26722","Abstract 					Adversarial attacks have threatened modern deep learning systems by crafting adversarial examples with small perturbations to fool the convolutional neural networks (CNNs). To alleviate that, ensemble training methods are proposed to facilitate better adversarial robustness by diversifying the vulnerabilities among the sub-models, simultaneously maintaining comparable natural accuracy as standard training. Previous practices also demonstrate that enlarging the ensemble can improve the robustness. However, conventional ensemble methods are with poor scalability, owing to the rapidly increasing complexity when containing more sub-models in the ensemble. Moreover, it is usually infeasible to train or deploy an ensemble with substantial sub-models, owing to the tight hardware resource budget and latency requirement. In this work, we propose Ensemble-in-One (EIO), a simple but effective method to efficiently enlarge the ensemble with a random gated network (RGN). EIO augments a candidate model by replacing the parametrized layers with multi-path random gated blocks (RGBs) to construct an RGN. The scalability is significantly boosted because the number of paths exponentially increases with the RGN depth. Then by learning from the vulnerabilities of numerous other paths within the RGN, every path obtains better adversarial robustness. Our experiments demonstrate that EIO consistently outperforms previous ensemble training methods with smaller computational overheads, simultaneously achieving better accuracy-robustness trade-offs than adversarial training methods under black-box transfer attacks. Code is available at https://github.com/cai-y13/Ensemble-in-One.git","https://ojs.aaai.org/index.php/AAAI/article/view/26722/26494"
"26723","Safe Reinforcement Learning via Shielding under Partial Observability","['Steven Carr', 'Nils Jansen', 'Sebastian Junges', 'Ufuk Topcu']","['University of Texas at Austin', 'Radboud University Nijmegen', 'Radboud University Nijmegen', 'University of Texas at Austin']","['General']","Carr, S., Jansen, N., Junges, S., & Topcu, U. (2023). Safe Reinforcement Learning via Shielding under Partial Observability. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14748-14756. https://doi.org/10.1609/aaai.v37i12.26723","Abstract 					Safe exploration is a common problem in reinforcement learning (RL) that aims to prevent agents from making disastrous decisions while exploring their environment. A family of approaches to this problem assume domain knowledge in the form of a (partial) model of this environment to decide upon the safety of an action. A so-called shield forces the RL agent to select only safe actions. However, for adoption in various applications, one must look beyond enforcing safety and also ensure the applicability of RL with good performance. We extend the applicability of shields via tight integration with state-of-the-art deep RL, and provide an extensive, empirical study in challenging, sparse-reward environments under partial observability. We show that a carefully integrated shield ensures safety and can improve the convergence rate and final performance of RL agents. We furthermore show that a shield can be used to bootstrap state-of-the-art RL agents: they remain safe after initial learning in a shielded setting, allowing us to disable a potentially too conservative shield eventually.","https://ojs.aaai.org/index.php/AAAI/article/view/26723/26495"
"26724","PowRL: A Reinforcement Learning Framework for Robust Management of Power Networks","['Anandsingh Chauhan', 'Mayank Baranwal', 'Ansuma Basumatary']","['TCS Research', 'TCS Research', 'Salesken']","['General']","Chauhan, A., Baranwal, M., & Basumatary, A. (2023). PowRL: A Reinforcement Learning Framework for Robust Management of Power Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14757-14764. https://doi.org/10.1609/aaai.v37i12.26724","Abstract 					Power grids, across the world, play an important societal and economical role by providing uninterrupted, reliable and transient-free power to several industries, businesses and household consumers. With the advent of renewable power resources and EVs resulting into uncertain generation and highly dynamic load demands, it has become ever so important to ensure robust operation of power networks through suitable management of transient stability issues and localize the events of blackouts. In the light of ever increasing stress on the modern grid infrastructure and the grid operators, this paper presents a reinforcement learning (RL) framework, PowRL, to mitigate the effects of unexpected network events, as well as reliably maintain electricity everywhere on the network at all times. The PowRL leverages a novel heuristic for overload management, along with the RL-guided decision making on optimal topology selection to ensure that the grid is operated safely and reliably (with no overloads). PowRL is benchmarked on a variety of competition datasets hosted by the L2RPN (Learning to Run a Power Network). Even with its reduced action space, PowRL tops the leaderboard in the L2RPN NeurIPS 2020 challenge (Robustness track) at an aggregate level, while also being the top performing agent in the L2RPN WCCI 2020 challenge. Moreover, detailed analysis depicts state-of-the-art performances by the PowRL agent in some of the test scenarios.","https://ojs.aaai.org/index.php/AAAI/article/view/26724/26496"
"26725","Two Wrongs Don’t Make a Right: Combating Confirmation Bias in Learning with Label Noise","['Mingcai Chen', 'Hao Cheng', 'Yuntao Du', 'Ming Xu', 'Wenyu Jiang', 'Chongjun Wang']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing University']","['General']","Chen, M., Cheng, H., Du, Y., Xu, M., Jiang, W., & Wang, C. (2023). Two Wrongs Don’t Make a Right: Combating Confirmation Bias in Learning with Label Noise. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14765-14773. https://doi.org/10.1609/aaai.v37i12.26725","Abstract 					Noisy labels damage the performance of deep networks.  For robust learning, a prominent two-stage pipeline alternates between eliminating possible incorrect labels and semi-supervised training. However, discarding part of noisy labels could result in a loss of information, especially when the corruption has a dependency on data, e.g., class-dependent or instance-dependent. Moreover, from the training dynamics of a representative two-stage method DivideMix, we identify the domination of confirmation bias: pseudo-labels fail to correct a considerable amount of noisy labels, and consequently, the errors accumulate. To sufficiently exploit information from noisy labels and mitigate wrong corrections, we propose Robust Label Refurbishment (Robust LR)—a new hybrid method that integrates pseudo-labeling and confidence estimation techniques to refurbish noisy labels. We show that our method successfully alleviates the damage of both label noise and confirmation bias. As a result, it achieves state-of-the-art performance across datasets and noise types, namely CIFAR under different levels of synthetic noise and mini-WebVision and ANIMAL-10N with real-world noise.","https://ojs.aaai.org/index.php/AAAI/article/view/26725/26497"
"26726","Testing the Channels of Convolutional Neural Networks","['Kang Choi', 'Donghyun Son', 'Younghoon Kim', 'Jiwon Seo']","['Hanyang University', 'Hanyang University', 'Hanyang University', 'Hanyang University']","['General']","Choi, K., Son, D., Kim, Y., & Seo, J. (2023). Testing the Channels of Convolutional Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14774-14782. https://doi.org/10.1609/aaai.v37i12.26726","Abstract 					Neural networks have complex structures, and thus it is hard to understand their inner workings and ensure correctness. To understand and debug convolutional neural networks (CNNs) we propose techniques for testing the channels of CNNs. We design FtGAN, an extension to GAN, that can generate test data with varying the intensity (i.e., sum of the neurons) of a channel of a target CNN. We also proposed a channel selection algorithm to find representative channels for testing. To efficiently inspect the target CNN’s inference computations, we define unexpectedness score, which estimates how similar the inference computation of the test data is to that of the training data. We evaluated FtGAN with five public datasets and showed that our techniques successfully identify defective channels in five different CNN models.","https://ojs.aaai.org/index.php/AAAI/article/view/26726/26498"
"26727","Feature-Space Bayesian Adversarial Learning Improved Malware Detector Robustness","['Bao Gia Doan', 'Shuiqiao Yang', 'Paul Montague', 'Olivier De Vel', 'Tamas Abraham', 'Seyit Camtepe', 'Salil S. Kanhere', 'Ehsan Abbasnejad', 'Damith C. Ranashinghe']","['The University of Adelaide', 'UNSW', 'DST', 'CSIRO Data61', 'DST', 'CSIRO Data61', 'UNSW Sydney', 'The University of Adelaide', 'The University of Adelaide']","['General']","Doan, B. G., Yang, S., Montague, P., De Vel, O., Abraham, T., Camtepe, S., Kanhere, S. S., Abbasnejad, E., & Ranashinghe, D. C. (2023). Feature-Space Bayesian Adversarial Learning Improved Malware Detector Robustness. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14783-14791. https://doi.org/10.1609/aaai.v37i12.26727","Abstract 					We present a new algorithm to train a robust malware detector. Malware is a prolific problem and malware detectors are a front-line defense. Modern detectors rely on machine learning algorithms. Now, the adversarial objective is to devise alterations to the malware code to decrease the chance of being detected whilst preserving the functionality and realism of the malware. Adversarial learning is effective in improving robustness but generating functional and realistic adversarial malware samples is non-trivial. Because: i) in contrast to tasks capable of using gradient-based feedback, adversarial learning in a domain without a differentiable mapping function from the problem space (malware code inputs) to the feature space is hard; and ii) it is difficult to ensure the adversarial malware is realistic and functional.  This presents a challenge for developing scalable adversarial machine learning algorithms for large datasets at a production or commercial scale to realize robust malware detectors. We propose an alternative; perform adversarial learning in the feature space in contrast to the problem space. We prove the projection of perturbed, yet valid malware, in the problem space into feature space will always be a subset of adversarials generated in the feature space. Hence, by generating a robust network against feature-space adversarial examples, we inherently achieve robustness against problem-space adversarial examples. We formulate a Bayesian adversarial learning objective that captures the distribution of models for improved robustness.  To explain the robustness of the Bayesian adversarial learning algorithm, we prove that our learning method bounds the difference between the adversarial risk and empirical risk and improves robustness. We show that Bayesian neural networks (BNNs) achieve state-of-the-art results; especially in the False Positive Rate (FPR) regime. Adversarially trained BNNs achieve state-of-the-art robustness. Notably, adversarially trained BNNs are robust against stronger attacks with larger attack budgets by a margin of up to 15% on a recent production-scale malware dataset of more than 20 million samples. Importantly, our efforts create a benchmark for future defenses in the malware domain.","https://ojs.aaai.org/index.php/AAAI/article/view/26727/26499"
"26728","Correct-by-Construction Reinforcement Learning of Cardiac Pacemakers from Duration Calculus Requirements","['Kalyani Dole', 'Ashutosh Gupta', 'John Komp', 'Shankaranarayanan Krishna', 'Ashutosh Trivedi']","['IIT Bombay', 'IIT Bombay', 'University of Colorado', 'IIT Bombay', 'CU Boulder']","['General']","Dole, K., Gupta, A., Komp, J., Krishna, S., & Trivedi, A. (2023). Correct-by-Construction Reinforcement Learning of Cardiac Pacemakers from Duration Calculus Requirements. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14792-14800. https://doi.org/10.1609/aaai.v37i12.26728","Abstract 					As the complexity of pacemaker devices continues to grow, the importance of capturing its functional correctness requirement formally cannot be overestimated. The pacemaker system specification document by \emph{Boston Scientific} provides a widely accepted set of specifications for pacemakers.  As these specifications are written in a natural language, they are not amenable for automated verification, synthesis, or reinforcement learning of pacemaker systems. This paper presents a formalization of these requirements for a dual-chamber pacemaker in \emph{duration calculus} (DC), a highly expressive real-time specification language. The proposed formalization allows us to automatically translate pacemaker requirements into executable specifications as stopwatch automata, which can be used to enable simulation, monitoring, validation, verification and automatic synthesis of pacemaker systems.  The cyclic nature of the pacemaker-heart closed-loop system results in DC requirements that compile to a decidable subclass of stopwatch automata. We present shield reinforcement learning (shield RL),  a shield synthesis based reinforcement learning algorithm, by automatically constructing safety envelopes from DC specifications.","https://ojs.aaai.org/index.php/AAAI/article/view/26728/26500"
"26729","SafeLight: A Reinforcement Learning Method toward Collision-Free Traffic Signal Control","['Wenlu Du', 'Junyi Ye', 'Jingyi Gu', 'Jing Li', 'Hua Wei', 'Guiling Wang']","['New Jersey Institute of Technology', 'New Jersey Institute of Technology', 'New Jersey Institute of Technology', 'New Jersey Institute of Technology', 'New Jersey Institute of Technology', 'New Jersey Institute of Technology']","['General']","Du, W., Ye, J., Gu, J., Li, J., Wei, H., & Wang, G. (2023). SafeLight: A Reinforcement Learning Method toward Collision-Free Traffic Signal Control. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14801-14810. https://doi.org/10.1609/aaai.v37i12.26729","Abstract 					Traffic signal control is safety-critical for our daily life. Roughly one-quarter of road accidents in the U.S. happen at intersections due to problematic signal timing, urging the development of safety-oriented intersection control. However, existing studies on adaptive traffic signal control using reinforcement learning technologies have focused mainly on minimizing traffic delay but neglecting the potential exposure to unsafe conditions. We, for the first time, incorporate road safety standards as enforcement to ensure the safety of existing reinforcement learning methods, aiming toward operating intersections with zero collisions. We have proposed a safety-enhanced residual reinforcement learning method (SafeLight) and employed multiple optimization techniques, such as multi-objective loss function and reward shaping for better knowledge integration. Extensive experiments are conducted using both synthetic and real-world benchmark datasets. Results show that our method can significantly reduce collisions while increasing traffic mobility.","https://ojs.aaai.org/index.php/AAAI/article/view/26729/26501"
"26730","PatchNAS: Repairing DNNs in Deployment with Patched Network Architecture Search","['Yuchu Fang', 'Wenzhong Li', 'Yao Zeng', 'Yang Zheng', 'Zheng Hu', 'Sanglu Lu']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'TTE Lab, Huawei Technologies Co Ltd', 'TTE Lab, Huawei Technologies Co Ltd', 'Nanjing University']","['General']","Fang, Y., Li, W., Zeng, Y., Zheng, Y., Hu, Z., & Lu, S. (2023). PatchNAS: Repairing DNNs in Deployment with Patched Network Architecture Search. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14811-14819. https://doi.org/10.1609/aaai.v37i12.26730","Abstract 					Despite being widely deployed in safety-critical applications such as autonomous driving and health care, deep neural networks (DNNs) still suffer from non-negligible reliability issues. Numerous works had reported that DNNs were vulnerable to either natural environmental noises or man-made adversarial noises. How to repair DNNs in deployment with noisy samples is a crucial topic for the robustness of neural networks. While many network repairing methods based on data argumentation and weight adjustment have been proposed, they require retraining and redeploying the whole model, which causes high overhead and is infeasible for varying faulty cases on different deployment environments. In this paper, we propose a novel network repairing framework called PatchNAS from the architecture perspective, where we freeze the pretrained DNNs and introduce a small patch network to deal with failure samples at runtime. PatchNAS introduces a novel network instrumentation method to determine the faulty stage of the network structure given the collected failure samples. A small patch network structure is searched unsupervisedly using neural architecture search (NAS) technique with data samples from deployment environment. The patch network repairs the DNNs by correcting the output feature maps of the faulty stage, which helps to maintain network performance on normal samples and enhance robustness in noisy environments. Extensive experiments based on several DNNs across 15 types of natural noises show that the proposed PatchNAS outperforms the state-of-the-arts with significant performance improvement as well as much lower deployment overhead.","https://ojs.aaai.org/index.php/AAAI/article/view/26730/26502"
"26731","Similarity Distribution Based Membership Inference Attack on Person Re-identification","['Junyao Gao', 'Xinyang Jiang', 'Huishuai Zhang', 'Yifan Yang', 'Shuguang Dou', 'Dongsheng Li', 'Duoqian Miao', 'Cheng Deng', 'Cairong Zhao']","['Tongji University', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Microsoft Research Asia', 'Tongji University', 'Microsoft Research Asia', 'Tongji University', 'Xidian University', 'Tongji University']","['General']","Gao, J., Jiang, X., Zhang, H., Yang, Y., Dou, S., Li, D., Miao, D., Deng, C., & Zhao, C. (2023). Similarity Distribution Based Membership Inference Attack on Person Re-identification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14820-14828. https://doi.org/10.1609/aaai.v37i12.26731","Abstract 					While person Re-identification (Re-ID) has progressed rapidly due to its wide real-world applications, it also causes severe risks of leaking personal information from training data. Thus, this paper focuses on quantifying this risk by membership inference (MI) attack. Most of the existing MI attack algorithms focus on classification models, while Re-ID follows a totally different training and inference paradigm. Re-ID is a fine-grained recognition task with complex feature embedding, and model outputs commonly used by existing MI like logits and losses are not accessible during inference. Since Re-ID focuses on modelling the relative relationship between image pairs instead of individual semantics, we conduct a formal and empirical analysis which validates that the distribution shift of the inter-sample similarity between training and test set is a critical criterion for Re-ID membership inference. As a result, we propose a novel membership inference attack method based on the inter-sample similarity distribution. Specifically, a set of anchor images are sampled to represent the similarity distribution conditioned on a target image, and a neural network with a novel anchor selection module is proposed to predict the membership of the target image. Our experiments validate the effectiveness of the proposed approach on both the Re-ID task and conventional classification task.","https://ojs.aaai.org/index.php/AAAI/article/view/26731/26503"
"26732","Out-of-Distribution Detection Is Not All You Need","['Joris Guerin', 'Kevin Delmas', 'Raul Ferreira', 'Jérémie Guiochet']","['Espace-Dev, IRD, Université de Montpellier, Montpellier, France\nLAAS-CNRS, Université de Toulouse, Toulouse, France', 'ONERA, Toulouse, France', 'LAAS-CNRS, Université de Toulouse, Toulouse, France', 'LAAS-CNRS, Université de Toulouse, Toulouse, France']","['General']","Guerin, J., Delmas, K., Ferreira, R., & Guiochet, J. (2023). Out-of-Distribution Detection Is Not All You Need. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14829-14837. https://doi.org/10.1609/aaai.v37i12.26732","Abstract 					The usage of deep neural networks in safety-critical systems is limited by our ability to guarantee their correct behavior. Runtime monitors are components aiming to identify unsafe predictions and discard them before they can lead to catastrophic consequences. Several recent works on runtime monitoring have focused on out-of-distribution (OOD) detection, i.e., identifying inputs that are different from the training data. In this work, we argue that OOD detection is not a well-suited framework to design efficient runtime monitors and that it is more relevant to evaluate monitors based on their ability to discard incorrect predictions. We call this setting out-of-model-scope detection and discuss the conceptual differences with OOD. We also conduct extensive experiments on popular datasets from the literature to show that studying monitors in the OOD setting can be misleading: 1. very good OOD results can give a false impression of safety, 2. comparison under the OOD setting does not allow identifying the best monitor to detect errors. Finally, we also show that removing erroneous training data samples helps to train better monitors.","https://ojs.aaai.org/index.php/AAAI/article/view/26732/26504"
"26733","Contrastive Self-Supervised Learning Leads to Higher Adversarial Susceptibility","['Rohit Gupta', 'Naveed Akhtar', 'Ajmal Mian', 'Mubarak Shah']","['University of Central Florida', 'University of Western Australia', 'University of Western Australia', 'University of Central Florida']","['General']","Gupta, R., Akhtar, N., Mian, A., & Shah, M. (2023). Contrastive Self-Supervised Learning Leads to Higher Adversarial Susceptibility. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14838-14846. https://doi.org/10.1609/aaai.v37i12.26733","Abstract 					Contrastive self-supervised learning (CSL) has managed to match or surpass the performance of supervised learning in image and video classification. However, it is still largely unknown if the nature of the representations induced by the two learning paradigms is similar. We investigate this under the lens of adversarial robustness. Our analysis of the problem reveals that CSL has intrinsically higher sensitivity to perturbations over supervised learning. We identify the uniform distribution of data representation over a unit hypersphere in the CSL representation space as the key contributor to this phenomenon. We establish that this is a result of the presence of false negative pairs in the training process, which increases model sensitivity to input perturbations. Our finding is supported by extensive experiments for image and video classification using adversarial perturbations and other input corruptions. We devise a strategy to detect and remove false negative pairs that is simple, yet effective in improving model robustness with CSL training. We close up to 68% of the robustness gap between CSL and its supervised counterpart. Finally, we contribute to adversarial learning by incorporating our method in CSL. We demonstrate an average gain of about 5% over two different state-of-the-art methods in this domain.","https://ojs.aaai.org/index.php/AAAI/article/view/26733/26505"
"26734","AutoCost: Evolving Intrinsic Cost for Zero-Violation Reinforcement Learning","['Tairan He', 'Weiye Zhao', 'Changliu Liu']","['Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University']","['General']","He, T., Zhao, W., & Liu, C. (2023). AutoCost: Evolving Intrinsic Cost for Zero-Violation Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14847-14855. https://doi.org/10.1609/aaai.v37i12.26734","Abstract 					Safety is a critical hurdle that limits the application of deep reinforcement learning to real-world control tasks. To this end, constrained reinforcement learning leverages cost functions to improve safety in constrained Markov decision process. However, constrained methods fail to achieve zero violation even when the cost limit is zero. This paper analyzes the reason for such failure, which suggests that a proper cost function plays an important role in constrained RL. Inspired by the analysis, we propose AutoCost, a simple yet effective framework that automatically searches for cost functions that help constrained RL to achieve zero-violation performance. We validate the proposed method and the searched cost function on the safety benchmark Safety Gym. We compare the performance of augmented agents that use our cost function to provide additive intrinsic costs to a Lagrangian-based policy learner and a constrained-optimization policy learner with baseline agents that use the same policy learners but with only extrinsic costs. Results show that the converged policies with intrinsic costs in all environments achieve zero constraint violation and comparable performance with baselines.","https://ojs.aaai.org/index.php/AAAI/article/view/26734/26506"
"26735","Test Time Augmentation Meets Post-hoc Calibration: Uncertainty Quantification under Real-World Conditions","['Achim Hekler', 'Titus J. Brinker', 'Florian Buettner']","['German Cancer Research Center (DKFZ) Heidelberg, Germany\nGoethe University Frankfurt, Germany', 'German Cancer Research Center (DKFZ) Heidelberg, Germany', 'German Cancer Research Center (DKFZ) Heidelberg, Germany\nGerman Cancer Consortium (DKTK), Germany\nGoethe University Frankfurt, Germany']","['General']","Hekler, A., Brinker, T. J., & Buettner, F. (2023). Test Time Augmentation Meets Post-hoc Calibration: Uncertainty Quantification under Real-World Conditions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14856-14864. https://doi.org/10.1609/aaai.v37i12.26735","Abstract 					Communicating the predictive uncertainty of deep neural networks transparently and reliably is important in many safety-critical applications such as medicine. However, modern neural networks tend to be poorly calibrated, resulting in wrong predictions made with a high confidence. While existing post-hoc calibration methods like temperature scaling or isotonic regression yield strongly calibrated predictions in artificial experimental settings, their efficiency can significantly reduce in real-world applications, where scarcity of labeled data or domain drifts are commonly present. In this paper, we first investigate the impact of these characteristics on post-hoc calibration and introduce an easy-to-implement extension of common post-hoc calibration methods based on test time augmentation. In extensive experiments, we demonstrate that our approach results in substantially better calibration on various architectures. We demonstrate the robustness of our proposed approach on a real-world application for skin cancer classification and show that it facilitates safe decision-making under real-world uncertainties.","https://ojs.aaai.org/index.php/AAAI/article/view/26735/26507"
"26736","Robust Training of Neural Networks against Bias Field Perturbations","['Patrick Henriksen', 'Alessio Lomuscio']","['Imperial College London\nSafe Intelligence', 'Safe Intelligence']","['General']","Henriksen, P., & Lomuscio, A. (2023). Robust Training of Neural Networks against Bias Field Perturbations. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14865-14873. https://doi.org/10.1609/aaai.v37i12.26736","Abstract 					We introduce the problem of training neural networks such that they are robust against a class of smooth intensity perturbations modelled by bias fields. We first develop an approach towards this goal based on a state-of-the-art robust training method utilising Interval Bound Propagation (IBP). We analyse the resulting algorithm and observe that IBP often produces very loose bounds for bias field perturbations, which may be detrimental to training. We then propose an alternative approach based on Symbolic Interval Propagation (SIP), which usually results in significantly tighter bounds than IBP. We present ROBNET, a tool implementing these approaches for bias field robust training. In experiments networks trained with the SIP-based approach achieved up to 31% higher certified robustness while also maintaining a better accuracy than networks trained with the IBP approach.","https://ojs.aaai.org/index.php/AAAI/article/view/26736/26508"
"26737","Redactor: A Data-Centric and Individualized Defense against Inference Attacks","['Geon Heo', 'Steven Euijong Whang']","['KAIST', 'KAIST']","['General']","Heo, G., & Whang, S. E. (2023). Redactor: A Data-Centric and Individualized Defense against Inference Attacks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14874-14882. https://doi.org/10.1609/aaai.v37i12.26737","Abstract 					Information leakage is becoming a critical problem as various information becomes publicly available by mistake, and machine learning models train on that data to provide services. As a result, one's private information could easily be memorized by such trained models. Unfortunately, deleting information is out of the question as the data is already exposed to the Web or third-party platforms. Moreover, we cannot necessarily control the labeling process and the model trainings by other parties either. In this setting, we study the problem of targeted disinformation generation where the goal is to dilute the data and thus make a model safer and more robust against inference attacks on a specific target (e.g., a person's profile) by only inserting new data. Our method finds the closest points to the target in the input space that will be labeled as a different class. Since we cannot control the labeling process, we instead conservatively estimate the labels probabilistically by combining decision boundaries of multiple classifiers using data programming techniques. Our experiments show that a probabilistic decision boundary can be a good proxy for labelers, and that our approach is effective in defending against inference attacks and can scale to large data.","https://ojs.aaai.org/index.php/AAAI/article/view/26737/26509"
"26738","Improving Adversarial Robustness with Self-Paced Hard-Class Pair Reweighting","['Pengyue Hou', 'Jie Han', 'Xingyu Li']","['University of Alberta', 'University of Alberta', 'University of Alberta']","['General']","Hou, P., Han, J., & Li, X. (2023). Improving Adversarial Robustness with Self-Paced Hard-Class Pair Reweighting. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14883-14891. https://doi.org/10.1609/aaai.v37i12.26738","Abstract 					Deep Neural Networks are vulnerable to adversarial attacks. Among many defense strategies, adversarial training with untargeted attacks is one of the most effective methods. Theoretically, adversarial perturbation in untargeted attacks can be added along arbitrary directions and the predicted labels of untargeted attacks should be unpredictable. However, we find that the naturally imbalanced inter-class semantic similarity makes those hard-class pairs become virtual targets of each other. This study investigates the impact of such closely-coupled classes on adversarial attacks and develops a self-paced reweighting strategy in adversarial training accordingly. Specifically, we propose to upweight hard-class pair losses in model optimization, which prompts learning discriminative features from hard classes. We further incorporate a term to quantify hard-class pair consistency in adversarial training, which greatly boosts model robustness. Extensive experiments show that the proposed adversarial training method achieves superior robustness performance over state-of-the-art defenses against a wide range of adversarial attacks. The code of the proposed SPAT is published at https://github.com/puerrrr/Self-Paced-Adversarial-Training.","https://ojs.aaai.org/index.php/AAAI/article/view/26738/26510"
"26739","CodeAttack: Code-Based Adversarial Attacks for Pre-trained Programming Language Models","['Akshita Jha', 'Chandan K. Reddy']","['Virginia Tech', 'Virginia Tech']","['General']","Jha, A., & Reddy, C. K. (2023). CodeAttack: Code-Based Adversarial Attacks for Pre-trained Programming Language Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14892-14900. https://doi.org/10.1609/aaai.v37i12.26739","Abstract 					Pre-trained programming language (PL) models (such as CodeT5, CodeBERT, GraphCodeBERT, etc.,) have the potential to automate software engineering tasks involving code understanding and code generation. However, these models operate in the natural channel of code, i.e., primarily concerned with the human understanding of code. They are not robust to changes in the input and thus, are potentially susceptible to adversarial attacks in the natural channel. We propose, Code Attack, a simple yet effective black-box attack model that uses code structure to generate effective, efficient, and imperceptible adversarial code samples and demonstrates the vulnerabilities of the state-of-the-art PL models to code-specific adversarial attacks. We evaluate the transferability of CodeAttack on several code-code (translation and repair) and code-NL (summarization) tasks across different programming languages. Code Attack outperforms state-of-the-art adversarial NLP attack models to achieve the best overall drop in performance while being more efficient, imperceptible, consistent, and fluent. The code can be found at https://github.com/reddy-lab-code-research/CodeAttack.","https://ojs.aaai.org/index.php/AAAI/article/view/26739/26511"
"26740","Formalising the Robustness of Counterfactual Explanations for Neural Networks","['Junqi Jiang', 'Francesco Leofante', 'Antonio Rago', 'Francesca Toni']","['Imperial College London', 'Imperial College London', 'Imperial College London', 'Imperial College London']","['General']","Jiang, J., Leofante, F., Rago, A., & Toni, F. (2023). Formalising the Robustness of Counterfactual Explanations for Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14901-14909. https://doi.org/10.1609/aaai.v37i12.26740","Abstract 					The use of counterfactual explanations (CFXs) is an increasingly popular explanation strategy for machine learning models. However, recent studies have shown that these explanations may not be robust to changes in the underlying model (e.g., following retraining), which raises questions about their reliability in real-world applications. Existing attempts towards solving this problem are heuristic, and the robustness to model changes of the resulting CFXs is evaluated with only a small number of retrained models, failing to provide exhaustive guarantees. To remedy this, we propose ∆-robustness, the first notion to formally and deterministically assess the robustness (to model changes) of CFXs for neural networks. We introduce an abstraction framework based on interval neural networks  to verify the ∆-robustness of CFXs against a possibly infinite set of changes to the model parameters, i.e., weights and biases. We then demonstrate the utility of this approach in two distinct ways. First, we  analyse the ∆-robustness of a number of CFX generation methods from the literature and show that they unanimously host significant deficiencies in this regard. Second, we demonstrate how embedding ∆-robustness within existing methods can provide CFXs which are provably robust.","https://ojs.aaai.org/index.php/AAAI/article/view/26740/26512"
"26741","READ: Aggregating Reconstruction Error into Out-of-Distribution Detection","['Wenyu Jiang', 'Yuxin Ge', 'Hao Cheng', 'Mingcai Chen', 'Shuai Feng', 'Chongjun Wang']","['Nanjing University', 'Nanjing University', 'Nanjing University', 'Nanjing university', 'Nanjing University', 'Nanjing University']","['General']","Jiang, W., Ge, Y., Cheng, H., Chen, M., Feng, S., & Wang, C. (2023). READ: Aggregating Reconstruction Error into Out-of-Distribution Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14910-14918. https://doi.org/10.1609/aaai.v37i12.26741","Abstract 					Detecting out-of-distribution (OOD) samples is crucial to the safe deployment of a classifier in the real world. However, deep neural networks are known to be overconfident for abnormal data. Existing works directly design score function by mining the inconsistency from classifier for in-distribution (ID) and OOD. In this paper, we further complement this inconsistency with reconstruction error, based on the assumption that an autoencoder trained on ID data cannot reconstruct OOD as well as ID. We propose a novel method, READ (Reconstruction Error Aggregated Detector), to unify inconsistencies from classifier and autoencoder. Specifically, the reconstruction error of raw pixels is transformed to latent space of classifier. We show that the transformed reconstruction error bridges the semantic gap and inherits detection performance from the original. Moreover, we propose an adjustment strategy to alleviate the overconfidence problem of autoencoder according to a fine-grained characterization of OOD data. Under two scenarios of pre-training and retraining, we respectively present two variants of our method, namely READ-MD (Mahalanobis Distance) only based on pre-trained classifier and READ-ED (Euclidean Distance) which retrains the classifier. Our methods do not require access to test time OOD data for fine-tuning hyperparameters. Finally, we demonstrate the effectiveness of the proposed methods through extensive comparisons with state-of-the-art OOD detection algorithms. On a CIFAR-10 pre-trained WideResNet, our method reduces the average FPR@95TPR by up to 9.8% compared with previous state-of-the-art.","https://ojs.aaai.org/index.php/AAAI/article/view/26741/26513"
"26742","Sample-Dependent Adaptive Temperature Scaling for Improved Calibration","['Tom Joy', 'Francesco Pinto', 'Ser-Nam Lim', 'Philip H.S. Torr', 'Puneet K. Dokania']","['Five AI, University of Oxford', 'University of Oxford', 'Meta AI', 'University of Oxford', 'Five AI, University of Oxford']","['General']","Joy, T., Pinto, F., Lim, S.-N., Torr, P. H., & Dokania, P. K. (2023). Sample-Dependent Adaptive Temperature Scaling for Improved Calibration. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14919-14926. https://doi.org/10.1609/aaai.v37i12.26742","Abstract 					It is now well known that neural networks can be wrong with high confidence in their predictions, leading to poor calibration. The most common post-hoc approach to compensate for this is to perform temperature scaling, which adjusts the confidences of the predictions on any input by scaling the logits by a fixed value. Whilst this approach typically improves the average calibration across the whole test dataset, this improvement typically reduces the individual confidences of the predictions irrespective of whether the classification of a given input is correct or incorrect. With this insight, we base our method on the observation that different samples contribute to the calibration error by varying amounts, with some needing to increase their confidence and others needing to decrease it. Therefore, for each input, we propose to predict a different temperature value, allowing us to adjust the mismatch between confidence and accuracy at a finer granularity. Our method is applied post-hoc, enabling it to be very fast with a negligible memory footprint and is applied to off-the-shelf pre-trained classifiers. We test our method on the ResNet50 and WideResNet28-10 architectures using the CIFAR10/100 and Tiny-ImageNet datasets, showing that producing per-data-point temperatures improves the expected calibration error across the whole test set.","https://ojs.aaai.org/index.php/AAAI/article/view/26742/26514"
"26743","Heuristic Search in Dual Space for Constrained Fixed-Horizon POMDPs with Durative Actions","['Majid Khonji', 'Duoaa Khalifa']","['Khalifa University', 'Khalifa University']","['General']","Khonji, M., & Khalifa, D. (2023). Heuristic Search in Dual Space for Constrained Fixed-Horizon POMDPs with Durative Actions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14927-14936. https://doi.org/10.1609/aaai.v37i12.26743","Abstract 					The Partially Observable Markov Decision Process (POMDP) is widely used in probabilistic planning for stochastic domains. However, current extensions, such as constrained and chance-constrained POMDPs, have limitations in modeling real-world planning problems because they assume that all actions have a fixed duration. To address this issue, we propose a unified model that encompasses durative POMDP and its constrained extensions. To solve the durative POMDP and its constrained extensions, we first convert them into an Integer Linear Programming (ILP) formulation. This approach leverages existing solvers in the ILP literature and provides a foundation for solving these problems. We then introduce a heuristic search approach that prunes the search space, which is guided by solving successive partial ILP programs. Our empirical evaluation results show that our approach outperforms the current state-of-the-art fixed-horizon chance-constrained POMDP solver.","https://ojs.aaai.org/index.php/AAAI/article/view/26743/26515"
"26744","Iteratively Enhanced Semidefinite Relaxations for Efficient Neural Network Verification","['Jianglin Lan', 'Yang Zheng', 'Alessio Lomuscio']","['University of Glasgow', 'University of California San Diego', 'Imperial College London']","['General']","Lan, J., Zheng, Y., & Lomuscio, A. (2023). Iteratively Enhanced Semidefinite Relaxations for Efficient Neural Network Verification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14937-14945. https://doi.org/10.1609/aaai.v37i12.26744","Abstract 					We propose an enhanced semidefinite program (SDP) relaxation to enable the tight and efficient verification of neural networks (NNs). The tightness improvement is achieved by introducing a nonlinear constraint to existing SDP relaxations previously proposed for NN verification. The efficiency of the proposal stems from the iterative nature of the proposed algorithm in that it solves the resulting non-convex SDP by recursively solving auxiliary convex layer-based SDP problems. We show formally that the solution generated by our algorithm is tighter than state-of-the-art SDP-based solutions for the problem. We also show that the solution sequence converges to the optimal solution of the non-convex enhanced SDP relaxation. The experimental results on standard benchmarks in the area show that our algorithm achieves the state-of-the-art performance whilst maintaining an acceptable computational cost.","https://ojs.aaai.org/index.php/AAAI/article/view/26744/26516"
"26745","A Semidefinite Relaxation Based Branch-and-Bound Method for Tight Neural Network Verification","['Jianglin Lan', 'Benedikt Brückner', 'Alessio Lomuscio']","['University of Glasgow', 'Imperial College London', 'Imperial College London']","['General']","Lan, J., Brückner, B., & Lomuscio, A. (2023). A Semidefinite Relaxation Based Branch-and-Bound Method for Tight Neural Network Verification. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14946-14954. https://doi.org/10.1609/aaai.v37i12.26745","Abstract 					We introduce a novel method based on semidefinite program (SDP) for the tight and efficient verification of neural networks. The proposed SDP relaxation advances the present state of the art in SDP-based neural network verification by adding a set of linear constraints based on eigenvectors. We extend this novel SDP relaxation by combining it with a branch-and-bound method that can provably close the relaxation gap up to zero. We show formally that the proposed approach leads to a provably tighter solution than the present state of the art. We report experimental results showing that the proposed method outperforms baselines in terms of verified accuracy while retaining an acceptable computational overhead.","https://ojs.aaai.org/index.php/AAAI/article/view/26745/26517"
"26746","Robust Image Steganography: Hiding Messages in Frequency Coefficients","['Yuhang Lan', 'Fei Shang', 'Jianhua Yang', 'Xiangui Kang', 'Enping Li']","['Sun Yat-Sen University', 'Sun Yat-Sen University', 'Guangdong Polytechnic Normal University', 'Sun Yat-Sen University', 'Bridgewater State University']","['General']","Lan, Y., Shang, F., Yang, J., Kang, X., & Li, E. (2023). Robust Image Steganography: Hiding Messages in Frequency Coefficients. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14955-14963. https://doi.org/10.1609/aaai.v37i12.26746","Abstract 					Steganography is a technique that hides secret messages into a public multimedia object without raising suspicion from third parties. However, most existing works cannot provide good robustness against lossy JPEG compression while maintaining a relatively large embedding capacity. This paper presents an end-to-end robust steganography system based on the invertible neural network (INN). Instead of hiding in the spatial domain, our method directly hides secret messages into the discrete cosine transform (DCT) coefficients of the cover image, which significantly improves the robustness and anti-steganalysis security. A mutual information loss is first proposed to constrain the flow of information in INN. Besides, a two-way fusion module (TWFM) is implemented, utilizing spatial and DCT domain features as auxiliary information to facilitate message extraction. These two designs aid in recovering secret messages from the DCT coefficients losslessly. Experimental results demonstrate that our method yields significantly lower error rates than other existing hiding methods. For example, our method achieves reliable extraction with 0 error rate for 1 bit per pixel (bpp) embedding payload; and under the JPEG compression with quality factor QF=10, the error rate of our method is about 22% lower than the state-of-the-art robust image hiding methods, which demonstrates remarkable robustness against JPEG compression.","https://ojs.aaai.org/index.php/AAAI/article/view/26746/26518"
"26747","Quantization-Aware Interval Bound Propagation for Training Certifiably Robust Quantized Neural Networks","['Mathias Lechner', 'Đorđe Žikelić', 'Krishnendu Chatterjee', 'Thomas A. Henzinger', 'Daniela Rus']","['Massachusetts Institute of Technology (MIT)', 'Institute of Science and Technology Austria (ISTA)', 'Institute of Science and Technology Austria (ISTA)', 'Institute of Science and Technology Austria (ISTA)', 'Massachusetts Institute of Technology (MIT)']","['General']","Lechner, M., Žikelić, Đorđe, Chatterjee, K., Henzinger, T. A., & Rus, D. (2023). Quantization-Aware Interval Bound Propagation for Training Certifiably Robust Quantized Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14964-14973. https://doi.org/10.1609/aaai.v37i12.26747","Abstract 					We study the problem of training and certifying adversarially robust quantized neural networks (QNNs). Quantization is a technique for making neural networks more efficient by running them using low-bit integer arithmetic and is therefore commonly adopted in industry. Recent work has shown that floating-point neural networks that have been verified to be robust can become vulnerable to adversarial attacks after quantization, and certification of the quantized representation is necessary to guarantee robustness. In this work, we present quantization-aware interval bound propagation (QA-IBP), a novel method for training robust QNNs. Inspired by advances in robust learning of non-quantized networks, our training algorithm computes the gradient of an abstract representation of the actual network. Unlike existing approaches, our method can handle the discrete semantics of QNNs.  Based on QA-IBP, we also develop a complete verification procedure for verifying the adversarial robustness of QNNs, which is guaranteed to terminate and produce a correct answer. Compared to existing approaches, the key advantage of our verification procedure is that it runs entirely on GPU or other accelerator devices.  We demonstrate experimentally that our approach significantly outperforms existing methods and establish the new state-of-the-art for training and certifying the robustness of QNNs.","https://ojs.aaai.org/index.php/AAAI/article/view/26747/26519"
"26748","Revisiting the Importance of Amplifying Bias for Debiasing","['Jungsoo Lee', 'Jeonghoon Park', 'Daeyoung Kim', 'Juyoung Lee', 'Edward Choi', 'Jaegul Choo']","['Graduate School of Artificial Intelligence, KAIST\nKakao Enterprise', 'Korea Advanced Institute of Science and Technology\nKakao Enterprise', 'Korea Advanced Institute of Science and Technology', 'Kakao Enterprise', 'KAIST', 'Korea Advanced Institute of Science and Technology']","['General']","Lee, J., Park, J., Kim, D., Lee, J., Choi, E., & Choo, J. (2023). Revisiting the Importance of Amplifying Bias for Debiasing. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14974-14981. https://doi.org/10.1609/aaai.v37i12.26748","Abstract 					In image classification, debiasing aims to train a classifier to be less susceptible to dataset bias, the strong correlation between peripheral attributes of data samples and a target class. For example, even if the frog class in the dataset mainly consists of frog images with a swamp background (i.e., bias aligned samples), a debiased classifier should be able to correctly classify a frog at a beach (i.e., bias conflicting samples). Recent debiasing approaches commonly use two components for debiasing, a biased model fB and a debiased model fD. fB is trained to focus on bias aligned samples (i.e., overfitted to the bias) while fD is mainly trained with bias conflicting samples by concentrating on samples which fB fails to learn, leading fD to be less susceptible to the dataset bias. While the state of the art debiasing techniques have aimed to better train fD, we focus on training fB, an overlooked component until now. Our empirical analysis reveals that removing the bias conflicting samples from the training set for fB is important for improving the debiasing performance of fD. This is due to the fact that the bias conflicting samples work as noisy samples for amplifying the bias for fB since those samples do not include the bias attribute. To this end, we propose a simple yet effective data sample selection method which removes the bias conflicting samples to construct a bias amplified dataset for training fB. Our data sample selection method can be directly applied to existing reweighting based debiasing approaches, obtaining consistent performance boost and achieving the state of the art performance on both synthetic and real-world datasets.","https://ojs.aaai.org/index.php/AAAI/article/view/26748/26520"
"26749","WAT: Improve the Worst-Class Robustness in Adversarial Training","['Boqi Li', 'Weiwei Liu']","['Wuhan University', 'Wuhan University']","['General']","Li, B., & Liu, W. (2023). WAT: Improve the Worst-Class Robustness in Adversarial Training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14982-14990. https://doi.org/10.1609/aaai.v37i12.26749","Abstract 					Deep Neural Networks (DNN) have been shown to be vulnerable to adversarial examples. Adversarial training (AT) is a popular and effective strategy to defend against adversarial attacks. Recent works have shown that a robust model well-trained by AT exhibits a remarkable robustness disparity among classes, and propose various methods to obtain consistent robust accuracy across classes. Unfortunately, these methods sacrifice a good deal of the average robust accuracy. Accordingly, this paper proposes a novel framework of worst-class adversarial training and leverages no-regret dynamics to solve this problem. Our goal is to obtain a classifier with great performance on worst-class and sacrifice just a little average robust accuracy at the same time. We then rigorously analyze the theoretical properties of our proposed algorithm, and the generalization error bound in terms of the worst-class robust risk. Furthermore, we propose a measurement to evaluate the proposed method in terms of both the average and worst-class accuracies. Experiments on various datasets and networks show that our proposed method outperforms the state-of-the-art approaches.","https://ojs.aaai.org/index.php/AAAI/article/view/26749/26521"
"26750","PLMmark: A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models","['Peixuan Li', 'Pengzhou Cheng', 'Fangqi Li', 'Wei Du', 'Haodong Zhao', 'Gongshen Liu']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['General']","Li, P., Cheng, P., Li, F., Du, W., Zhao, H., & Liu, G. (2023). PLMmark: A Secure and Robust Black-Box Watermarking Framework for Pre-trained Language Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 14991-14999. https://doi.org/10.1609/aaai.v37i12.26750","Abstract 					The huge training overhead, considerable commercial value, and various potential security risks make it urgent to protect the intellectual property (IP) of Deep Neural Networks (DNNs). DNN watermarking has become a plausible method to meet this need. However, most of the existing watermarking schemes focus on image classification tasks. The schemes designed for the textual domain lack security and reliability. Moreover, how to protect the IP of widely-used pre-trained language models (PLMs) remains a blank.  To fill these gaps, we propose PLMmark, the first secure and robust black-box watermarking framework for PLMs. It consists of three phases: (1) In order to generate watermarks that contain owners’ identity information, we propose a novel encoding method to establish a strong link between a digital signature and trigger words by leveraging the original vocabulary tables of PLMs. Combining this with public key cryptography ensures the security of our scheme. (2) To embed robust, task-agnostic, and highly transferable watermarks in PLMs, we introduce a supervised contrastive loss to deviate the output representations of trigger sets from that of clean samples. In this way, the watermarked models will respond to the trigger sets anomaly and thus can identify the ownership. (3) To make the model ownership verification results reliable, we perform double verification, which guarantees the unforgeability of ownership. Extensive experiments on text classification tasks demonstrate that the embedded watermark can transfer to all the downstream tasks and can be effectively extracted and verified. The watermarking scheme is robust to watermark removing attacks (fine-pruning and re-initializing) and is secure enough to resist forgery attacks.","https://ojs.aaai.org/index.php/AAAI/article/view/26750/26522"
"26751","Rethinking Label Refurbishment: Model Robustness under Label Noise","['Yangdi Lu', 'Zhiwei Xu', 'Wenbo He']","['McMaster University', 'McMaster University', 'McMaster University']","['General']","Lu, Y., Xu, Z., & He, W. (2023). Rethinking Label Refurbishment: Model Robustness under Label Noise. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15000-15008. https://doi.org/10.1609/aaai.v37i12.26751","Abstract 					A family of methods that generate soft labels by mixing the hard labels with a certain distribution, namely label refurbishment, are widely used to train deep neural networks. However, some of these methods are still poorly understood in the presence of label noise. In this paper, we revisit four label refurbishment methods and reveal the strong connection between them. We find that they affect the neural network models in different manners. Two of them smooth the estimated posterior for regularization effects, and the other two force the model to produce high-confidence predictions. We conduct extensive experiments to evaluate related methods and observe that both effects improve the model generalization under label noise. Furthermore, we theoretically show that both effects lead to generalization guarantees on the clean distribution despite being trained with noisy labels.","https://ojs.aaai.org/index.php/AAAI/article/view/26751/26523"
"26752","A Holistic Approach to Undesired Content Detection in the Real World","['Todor Markov', 'Chong Zhang', 'Sandhini Agarwal', 'Florentine Eloundou Nekoul', 'Theodore Lee', 'Steven Adler', 'Angela Jiang', 'Lilian Weng']","['OpenAI', 'OpenAI', 'OpenAI', 'OpenAI', 'OpenAI', 'OpenAI', 'OpenAI', 'OpenAI']","['General']","Markov, T., Zhang, C., Agarwal, S., Eloundou Nekoul, F., Lee, T., Adler, S., Jiang, A., & Weng, L. (2023). A Holistic Approach to Undesired Content Detection in the Real World. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15009-15018. https://doi.org/10.1609/aaai.v37i12.26752","Abstract 					We present a holistic approach to building a robust and useful natural language classification system for real-world content moderation. The success of such a system relies on a chain of carefully designed and executed steps, including the design of content taxonomies and labeling instructions, data quality control, an active learning pipeline to capture rare events, and a variety of methods to make the model robust and to avoid overfitting. Our moderation system is trained to detect a broad set of categories of undesired content, including sexual content, hateful content, violence, self-harm, and harassment. This approach generalizes to a wide range of different content taxonomies and can be used to create high-quality content classifiers that outperform off-the-shelf models.","https://ojs.aaai.org/index.php/AAAI/article/view/26752/26524"
"26753","A Risk-Sensitive Approach to Policy Optimization","['Jared Markowitz', 'Ryan W. Gardner', 'Ashley Llorens', 'Raman Arora', 'I-Jeng Wang']","['Johns Hopkins University Applied Physics Laboratory', 'Johns Hopkins University Applied Physics Laboratory', 'Microsoft Corporation', 'Johns Hopkins University', 'Johns Hopkins University Applied Physics Laboratory']","['General']","Markowitz, J., Gardner, R. W., Llorens, A., Arora, R., & Wang, I.-J. (2023). A Risk-Sensitive Approach to Policy Optimization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15019-15027. https://doi.org/10.1609/aaai.v37i12.26753","Abstract 					Standard deep reinforcement learning (DRL) aims to maximize expected reward, considering collected experiences equally in formulating a policy. This differs from human decision-making, where gains and losses are valued differently and outlying outcomes are given increased consideration.  It also fails to capitalize on opportunities to improve safety and/or performance through the incorporation of distributional context. Several approaches to distributional DRL have been investigated, with one popular strategy being to evaluate the projected distribution of returns for possible actions.  We propose a more direct approach whereby risk-sensitive objectives, specified in terms of the cumulative distribution function (CDF) of the distribution of full-episode rewards, are optimized. This approach allows for outcomes to be weighed based on relative quality, can be used for both continuous and discrete action spaces, and may naturally be applied in both constrained and unconstrained settings.  We show how to compute an asymptotically consistent estimate of the policy gradient for a broad class of risk-sensitive objectives via sampling, subsequently incorporating variance reduction and regularization measures to facilitate effective on-policy learning.  We then demonstrate that the use of moderately ""pessimistic"" risk profiles, which emphasize scenarios where the agent performs poorly, leads to enhanced exploration and a continual focus on addressing deficiencies.  We test the approach using different risk profiles in six OpenAI Safety Gym environments, comparing to state of the art on-policy methods.  Without cost constraints, we find that pessimistic risk profiles can be used to reduce cost while improving total reward accumulation.  With cost constraints, they are seen to provide higher positive rewards than risk-neutral approaches at the prescribed allowable cost.","https://ojs.aaai.org/index.php/AAAI/article/view/26753/26525"
"26754","Anonymization for Skeleton Action Recognition","['Saemi Moon', 'Myeonghyeon Kim', 'Zhenyue Qin', 'Yang Liu', 'Dongwoo Kim']","['CSE, POSTECH', 'Scatter Lab', 'Australian National University\nTencent', 'Australian National University', 'CSE, POSTECH\nGSAI, POSTECH']","['General']","Moon, S., Kim, M., Qin, Z., Liu, Y., & Kim, D. (2023). Anonymization for Skeleton Action Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15028-15036. https://doi.org/10.1609/aaai.v37i12.26754","Abstract 					Skeleton-based action recognition attracts practitioners and researchers due to the lightweight, compact nature of datasets. Compared with RGB-video-based action recognition, skeleton-based action recognition is a safer way to protect the privacy of subjects while having competitive recognition performance. However, due to improvements in skeleton recognition algorithms as well as motion and depth sensors, more details of motion characteristics can be preserved in the skeleton dataset, leading to potential privacy leakage. We first train classifiers to categorize private information from skeleton trajectories to investigate the potential privacy leakage from skeleton datasets. Our preliminary experiments show that the gender classifier achieves 87% accuracy on average, and the re-identification classifier achieves 80% accuracy on average with three baseline models: Shift-GCN, MS-G3D, and 2s-AGCN. We propose an anonymization framework based on adversarial learning to protect potential privacy leakage from the skeleton dataset. Experimental results show that an anonymized dataset can reduce the risk of privacy leakage while having marginal effects on action recognition performance even with simple anonymizer architectures. The code used in our experiments is available at https://github.com/ml-postech/Skeleton-anonymization/","https://ojs.aaai.org/index.php/AAAI/article/view/26754/26526"
"26755","Monitoring Model Deterioration with Explainable Uncertainty Estimation via Non-parametric Bootstrap","['Carlos Mougan', 'Dan Saattrup Nielsen']","['University of Southampton', 'The Alexandra Institute']","['General']","Mougan, C., & Nielsen, D. S. (2023). Monitoring Model Deterioration with Explainable Uncertainty Estimation via Non-parametric Bootstrap. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15037-15045. https://doi.org/10.1609/aaai.v37i12.26755","Abstract 					Monitoring machine learning models once they are deployed is challenging. It is even more challenging to decide when to retrain models in real-case scenarios when labeled data is beyond reach, and monitoring performance metrics becomes unfeasible. In this work, we use non-parametric bootstrapped uncertainty estimates and SHAP values to provide explainable uncertainty estimation as a technique that aims to monitor the deterioration of machine learning models in deployment environments, as well as determine the source of model deteri- oration when target labels are not available. Classical methods are purely aimed at detecting distribution shift, which can lead to false positives in the sense that the model has not deterio- rated despite a shift in the data distribution. To estimate model uncertainty we construct prediction intervals using a novel bootstrap method, which improves previous state-of-the-art work. We show that both our model deterioration detection system as well as our uncertainty estimation method achieve better performance than the current state-of-the-art. Finally, we use explainable AI techniques to gain an understanding of the drivers of model deterioration. We release an open source Python package, doubt, which implements our pro- posed methods, as well as the code used to reproduce our experiments.","https://ojs.aaai.org/index.php/AAAI/article/view/26755/26527"
"26756","Certified Policy Smoothing for Cooperative Multi-Agent Reinforcement Learning","['Ronghui Mu', 'Wenjie Ruan', 'Leandro Soriano Marcolino', 'Gaojie Jin', 'Qiang Ni']","['Lancaster University', 'University of Exeter', 'Lancaster University', 'University of Liverpool', 'Lancaster University']","['General']","Mu, R., Ruan, W., Soriano Marcolino, L., Jin, G., & Ni, Q. (2023). Certified Policy Smoothing for Cooperative Multi-Agent Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15046-15054. https://doi.org/10.1609/aaai.v37i12.26756","Abstract 					Cooperative multi-agent reinforcement learning (c-MARL) is widely applied in safety-critical scenarios, thus the analysis of robustness for c-MARL models is profoundly important. However, robustness certification for c-MARLs has not yet been explored in the community. In this paper, we propose a novel certification method, which is the first work to leverage a scalable approach for c-MARLs to determine actions with guaranteed certified bounds. c-MARL certification poses two key challenges compared to single-agent systems:  (i) the accumulated uncertainty as the number of agents increases; (ii) the potential lack of impact when changing the action of a single agent into a global team reward. These challenges prevent us from directly using existing algorithms. Hence, we employ the false discovery rate (FDR) controlling procedure considering the importance of each agent to certify per-state robustness. We further propose a tree-search-based algorithm to find a lower bound of the global reward under the minimal certified perturbation. As our method is general, it can also be applied in a single-agent environment. We empirically show that our certification bounds are much tighter than those of state-of-the-art RL certification solutions. We also evaluate our method on two popular c-MARL algorithms: QMIX and VDN, under two different environments, with two and four agents. The experimental results show that our method can certify the robustness of all c-MARL models in various environments. Our tool CertifyCMARL is available at https://github.com/TrustAI/CertifyCMARL.","https://ojs.aaai.org/index.php/AAAI/article/view/26756/26528"
"26757","Constrained Reinforcement Learning in Hard Exploration Problems","['Pathmanathan Pankayaraj', 'Pradeep Varakantham']","['Singapore Management University', 'Singapore Management University']","['General']","Pankayaraj, P., & Varakantham, P. (2023). Constrained Reinforcement Learning in Hard Exploration Problems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15055-15063. https://doi.org/10.1609/aaai.v37i12.26757","Abstract 					One approach to guaranteeing safety in Reinforcement Learning is through cost constraints that are dependent on the policy. Recent works in constrained RL have developed methods that ensure  constraints are enforced even at learning time while maximizing the overall value of the policy. Unfortunately, as demonstrated in our experimental results, such approaches do not perform well on complex multi-level tasks, with longer episode lengths or sparse rewards. To that end, we propose a scalable hierarchical approach for constrained RL problems that employs backward cost value functions in the context of task hierarchy and a novel intrinsic reward function in lower levels of the hierarchy to enable cost constraint enforcement. One of our key contributions is in proving that backward value functions are theoretically viable even when there are multiple levels of decision making. We also show that our new approach, referred to as Hierarchically Limited consTraint Enforcement (HiLiTE) significantly improves on state of the art Constrained RL approaches for many  benchmark problems from literature. We further demonstrate that this performance (on value and constraint enforcement) clearly outperforms existing best approaches for constrained RL and hierarchical RL.","https://ojs.aaai.org/index.php/AAAI/article/view/26757/26529"
"26758","Defending from Physically-Realizable Adversarial Attacks through Internal Over-Activation Analysis","['Giulio Rossolini', 'Federico Nesti', 'Fabio Brau', 'Alessandro Biondi', 'Giorgio Buttazzo']","[""Scuola Superiore Sant'Anna"", ""Scuola Superiore Sant'Anna"", ""Scuola Superiore Sant'Anna"", ""Scuola Superiore Sant'Anna"", ""Scuola Superiore Sant'Anna""]","['General']","Rossolini, G., Nesti, F., Brau, F., Biondi, A., & Buttazzo, G. (2023). Defending from Physically-Realizable Adversarial Attacks through Internal Over-Activation Analysis. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15064-15072. https://doi.org/10.1609/aaai.v37i12.26758","Abstract 					This work presents Z-Mask, an effective and deterministic strategy to improve the adversarial robustness of convolutional networks against physically-realizable adversarial attacks. The presented defense relies on specific Z-score analysis performed on the internal network features to detect and mask the pixels corresponding to adversarial objects in the input image. To this end, spatially contiguous activations are examined in shallow and deep layers to suggest potential adversarial regions. Such proposals are then aggregated through a multi-thresholding mechanism. The effectiveness of Z-Mask is evaluated with an extensive set of experiments carried out on models for semantic segmentation and object detection. The evaluation is performed with both digital patches added to the input images and printed patches in the real world. The results confirm that Z-Mask outperforms the state-of-the-art methods in terms of detection accuracy and overall performance of the networks under attack. Furthermore, Z-Mask preserves its robustness against defense-aware attacks, making it suitable for safe and secure AI applications.","https://ojs.aaai.org/index.php/AAAI/article/view/26758/26530"
"26759","Formally Verified Solution Methods for Markov Decision Processes","['Maximilian Schäffeler', 'Mohammad Abdulaziz']","['Technische Universität München, Germany', ""Technische Universität München, Germany\nKing's College London, United Kingdom""]","['General']","Schäffeler, M., & Abdulaziz, M. (2023). Formally Verified Solution Methods for Markov Decision Processes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15073-15081. https://doi.org/10.1609/aaai.v37i12.26759","Abstract 					We formally verify executable algorithms for solving Markov decision processes (MDPs) in the interactive theorem prover Isabelle/HOL. We build on existing formalizations of probability theory to analyze the expected total reward criterion on finite and infinite-horizon problems. Our developments formalize the Bellman equation and give conditions under which optimal policies exist. Based on this analysis, we verify dynamic programming algorithms to solve tabular MDPs. We evaluate the formally verified implementations experimentally on standard problems, compare them with state-of-the-art systems, and show that they are practical.","https://ojs.aaai.org/index.php/AAAI/article/view/26759/26531"
"26760","Improving Training and Inference of Face Recognition Models via Random Temperature Scaling","['Lei Shang', 'Mouxiao Huang', 'Wu Shi', 'Yuchen Liu', 'Yang Liu', 'Wang Steven', 'Baigui Sun', 'Xuansong Xie', 'Yu Qiao']","['Alibaba Group', 'The Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences\nUniversity of Chinese Academy of Sciences', 'The Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences', 'Alibaba Group', 'Alibaba Group', 'Alibaba group', 'Alibaba Group', 'Alibaba Group', 'The Guangdong Provincial Key Laboratory of Computer Vision and Virtual Reality Technology, Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences\nShanghai Artifcial Intelligence Laboratory']","['General']","Shang, L., Huang, M., Shi, W., Liu, Y., Liu, Y., Steven, W., Sun, B., Xie, X., & Qiao, Y. (2023). Improving Training and Inference of Face Recognition Models via Random Temperature Scaling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15082-15090. https://doi.org/10.1609/aaai.v37i12.26760","Abstract 					Data uncertainty is commonly observed in the images for face recognition (FR). However, deep learning algorithms often make predictions with high confidence even for uncertain or irrelevant inputs. Intuitively, FR algorithms can benefit from both the estimation of uncertainty and the detection of out-of-distribution (OOD) samples. Taking a probabilistic view of the current classification model, the temperature scalar is exactly the scale of uncertainty noise implicitly added in the softmax function. Meanwhile, the uncertainty of images in a dataset should follow a prior distribution. Based on the observation, a unified framework for uncertainty modeling and FR, Random Temperature Scaling (RTS), is proposed to learn a reliable FR algorithm. The benefits of RTS are two-fold. (1) In the training phase, it can adjust the learning strength of clean and noisy samples for stability and accuracy. (2) In the test phase, it can provide a score of confidence to detect uncertain, low-quality and even OOD samples, without training on extra labels. Extensive experiments on FR benchmarks demonstrate that the magnitude of variance in RTS, which serves as an OOD detection metric, is closely related to the uncertainty of the input image. RTS can achieve top performance on both the FR and OOD detection tasks. Moreover, the model trained with RTS can perform robustly on datasets with noise. The proposed module is light-weight and only adds negligible computation cost to the model.","https://ojs.aaai.org/index.php/AAAI/article/view/26760/26532"
"26761","Task and Model Agnostic Adversarial Attack on Graph Neural Networks","['Kartik Sharma', 'Samidha Verma', 'Sourav Medya', 'Arnab Bhattacharya', 'Sayan Ranu']","['Georgia Institute of Technology, Atlanta', 'Indian Institute of Technology, Delhi', 'University of Illinois, Chicago', 'Indian Institute of Technology, Kanpur', 'Indian Institute of Technology, Delhi']","['General']","Sharma, K., Verma, S., Medya, S., Bhattacharya, A., & Ranu, S. (2023). Task and Model Agnostic Adversarial Attack on Graph Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15091-15099. https://doi.org/10.1609/aaai.v37i12.26761","Abstract 					Adversarial attacks on Graph Neural Networks (GNNs) reveal their security vulnerabilities, limiting their adoption in safety-critical applications. However, existing attack strategies rely on the knowledge of either the GNN model being used or the predictive task being attacked. Is this knowledge necessary? For example, a graph may be used for multiple downstream tasks unknown to a practical attacker. It is thus important to test the vulnerability of GNNs to adversarial perturbations in a model and task-agnostic setting. In this work, we study this problem and show that Gnns remain vulnerable even when the downstream task and model are unknown. The proposed algorithm, TANDIS (Targeted Attack via Neighborhood DIStortion) shows that distortion of node neighborhoods is effective in drastically compromising prediction performance. Although neighborhood distortion is an NP-hard problem, TANDIS designs an effective heuristic through a novel combination of Graph Isomorphism Network with deep Q-learning. Extensive experiments on real datasets show that, on average, TANDIS is up to 50% more effective than state-of-the-art techniques, while being more than 1000 times faster.","https://ojs.aaai.org/index.php/AAAI/article/view/26761/26533"
"26762","Robust Sequence Networked Submodular Maximization","['Qihao Shi', 'Bingyang Fu', 'Can Wang', 'Jiawei Chen', 'Sheng Zhou', 'Yan Feng', 'Chun Chen']","['Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University', 'Zhejiang University']","['General']","Shi, Q., Fu, B., Wang, C., Chen, J., Zhou, S., Feng, Y., & Chen, C. (2023). Robust Sequence Networked Submodular Maximization. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15100-15108. https://doi.org/10.1609/aaai.v37i12.26762","Abstract 					In this paper, we study the Robust optimization for sequence Networked submodular maximization (RoseNets) problem. We interweave the robust optimization  with the sequence networked submodular maximization. The elements are connected by a directed acyclic graph and the objective function is not submodular on the elements but on the edges in the graph. Under such networked submodular scenario, the impact of removing an element from a sequence depends both on its position in the sequence and in the network. This makes the existing robust algorithms inapplicable and calls for new robust algorithms. In this paper, we take the first step to study the RoseNets problem. We design a robust greedy algorithms, which is robust against the removal of an arbitrary subset of the selected elements. The approximation ratio of the algorithm depends both on the number of the removed elements and the network topology. We further conduct experiments on real applications of recommendation and link prediction. The experimental results demonstrate the effectiveness of the proposed algorithm.","https://ojs.aaai.org/index.php/AAAI/article/view/26762/26534"
"26763","Safe Policy Improvement for POMDPs via Finite-State Controllers","['Thiago D. Simão', 'Marnix Suilen', 'Nils Jansen']","['Radboud University Nijmegen', 'Radboud University Nijmegen', 'Radboud University Nijmegen']","['General']","Simão, T. D., Suilen, M., & Jansen, N. (2023). Safe Policy Improvement for POMDPs via Finite-State Controllers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15109-15117. https://doi.org/10.1609/aaai.v37i12.26763","Abstract 					We study safe policy improvement (SPI) for partially observable Markov decision processes (POMDPs). SPI is an offline reinforcement learning (RL) problem that assumes access to (1) historical data about an environment, and (2) the so-called behavior policy that previously generated this data by interacting with the environment. SPI methods neither require access to a model nor the environment itself, and aim to reliably improve upon the behavior policy in an offline manner. Existing methods make the strong assumption that the environment is fully observable. In our novel approach to the SPI problem for POMDPs, we assume that a finite-state controller (FSC) represents the behavior policy and that finite memory is sufficient to derive optimal policies. This assumption allows us to map the POMDP to a finite-state fully observable MDP, the history MDP. We estimate this MDP by combining the historical data and the memory of the FSC, and compute an improved policy using an off-the-shelf SPI algorithm. The underlying SPI method constrains the policy space according to the available data, such that the newly computed policy only differs from the behavior policy when sufficient data is available. We show that this new policy, converted into a new FSC for the (unknown) POMDP, outperforms the behavior policy with high probability. Experimental results on several well-established benchmarks show the applicability of the approach, even in cases where finite memory is not sufficient.","https://ojs.aaai.org/index.php/AAAI/article/view/26763/26535"
"26764","STL-Based Synthesis of Feedback Controllers Using Reinforcement Learning","['Nikhil Kumar Singh', 'Indranil Saha']","['IIT Kanpur', 'IIT Kanpur']","['General']","Singh, N. K., & Saha, I. (2023). STL-Based Synthesis of Feedback Controllers Using Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15118-15126. https://doi.org/10.1609/aaai.v37i12.26764","Abstract 					Deep Reinforcement Learning (DRL) has the potential to be used for synthesizing feedback controllers (agents) for various complex systems with unknown dynamics. These systems are expected to satisfy diverse safety and liveness properties best captured using temporal logic. In RL, the reward function plays a crucial role in specifying the desired behaviour of these agents. However, the problem of designing the reward function for an RL agent to satisfy complex temporal logic specifications has received limited attention in the literature. To address this, we provide a systematic way of generating rewards in real-time by using the quantitative semantics of Signal Temporal Logic (STL), a widely used temporal logic to specify the behaviour of cyber-physical systems. We propose a new quantitative semantics for STL having several desirable properties, making it suitable for reward generation. We evaluate our STL-based reinforcement learning mechanism on several complex continuous control benchmarks and compare our STL semantics with those available in the literature in terms of their efficacy in synthesizing the controller agent. Experimental results establish our new semantics to be the most suitable for synthesizing feedback controllers for complex continuous dynamical systems through reinforcement learning.","https://ojs.aaai.org/index.php/AAAI/article/view/26764/26536"
"26765","Understanding and Enhancing Robustness of Concept-Based Models","['Sanchit Sinha', 'Mengdi Huai', 'Jianhui Sun', 'Aidong Zhang']","['University of Virginia', 'University of Virginia\nIowa Sate University', 'University of Virginia', 'University of Virginia']","['General']","Sinha, S., Huai, M., Sun, J., & Zhang, A. (2023). Understanding and Enhancing Robustness of Concept-Based Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15127-15135. https://doi.org/10.1609/aaai.v37i12.26765","Abstract 					Rising usage of deep neural networks to perform decision making in critical applications like medical diagnosis and fi- nancial analysis have raised concerns regarding their reliability and trustworthiness. As automated systems become more mainstream, it is important their decisions be transparent, reliable and understandable by humans for better trust and confidence. To this effect, concept-based models such as Concept Bottleneck Models (CBMs) and Self-Explaining Neural Networks (SENN) have been proposed which constrain the latent space of a model to represent high level concepts easily understood by domain experts in the field. Although concept-based models promise a good approach to both increasing explainability and reliability, it is yet to be shown if they demonstrate robustness and output consistent concepts under systematic perturbations to their inputs. To better understand performance of concept-based models on curated malicious samples, in this paper, we aim to study their robustness to adversarial perturbations, which are also known as the imperceptible changes to the input data that are crafted by an attacker to fool a well-learned concept-based model. Specifically, we first propose and analyze different malicious attacks to evaluate the security vulnerability of concept based models. Subsequently, we propose a potential general adversarial training-based defense mechanism to increase robustness of these systems to the proposed malicious attacks. Extensive experiments on one synthetic and two real-world datasets demonstrate the effectiveness of the proposed attacks and the defense approach. An appendix of the paper with more comprehensive results can also be viewed at https://arxiv.org/abs/2211.16080.","https://ojs.aaai.org/index.php/AAAI/article/view/26765/26537"
"26766","Misspecification in Inverse Reinforcement Learning","['Joar Skalse', 'Alessandro Abate']","['University of Oxford', 'University of Oxford']","['General']","Skalse, J., & Abate, A. (2023). Misspecification in Inverse Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15136-15143. https://doi.org/10.1609/aaai.v37i12.26766","Abstract 					The aim of Inverse Reinforcement Learning (IRL) is to infer a reward function R from a policy pi. To do this, we need a model of how pi relates to R. In the current literature, the most common models are optimality, Boltzmann rationality, and causal entropy maximisation. One of the primary motivations behind IRL is to infer human preferences from human behaviour. However, the true relationship between human preferences and human behaviour is much more complex than any of the models currently used in IRL. This means that they are misspecified, which raises the worry that they might lead to unsound inferences if applied to real-world data. In this paper, we provide a mathematical analysis of how robust different IRL models are to misspecification, and answer precisely how the demonstrator policy may differ from each of the standard models before that model leads to faulty inferences about the reward function R. We also introduce a framework for reasoning about misspecification in IRL, together with formal tools that can be used to easily derive the misspecification robustness of new IRL models.","https://ojs.aaai.org/index.php/AAAI/article/view/26766/26538"
"26767","Planning and Learning for Non-markovian Negative Side Effects Using Finite State Controllers","['Aishwarya Srivastava', 'Sandhya Saisubramanian', 'Praveen Paruchuri', 'Akshat Kumar', 'Shlomo Zilberstein']","['IIIT Hyderabad', 'Oregon State University', 'IIIT Hyderabad', 'Singapore Management University', 'University of Massachusetts Amherst']","['General']","Srivastava, A., Saisubramanian, S., Paruchuri, P., Kumar, A., & Zilberstein, S. (2023). Planning and Learning for Non-markovian Negative Side Effects Using Finite State Controllers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15144-15151. https://doi.org/10.1609/aaai.v37i12.26767","Abstract 					Autonomous systems are often deployed in the open world where it is hard to obtain complete specifications of objectives and constraints. Operating based on an incomplete model can produce negative side effects (NSEs), which affect the safety and reliability of the system. We focus on mitigating NSEs in environments modeled as Markov decision processes (MDPs). First, we learn a model of NSEs using observed data that contains state-action trajectories and severity of associated NSEs. Unlike previous works that associate NSEs with state-action pairs, our framework associates NSEs with entire trajectories, which is more general and captures non-Markovian dependence on states and actions. Second, we learn finite state controllers (FSCs) that predict NSE severity for a given trajectory and generalize well to unseen data. Finally, we develop a constrained MDP model that uses information from the underlying MDP and the learned FSC for planning while avoiding NSEs. Our empirical evaluation demonstrates the effectiveness of our approach in learning and mitigating Markovian and non-Markovian NSEs.","https://ojs.aaai.org/index.php/AAAI/article/view/26767/26539"
"26768","Toward Robust Uncertainty Estimation with Random Activation Functions","['Yana Stoyanova', 'Soroush Ghandi', 'Maryam Tavakol']","['Eindhoven University of Technology', 'Eindhoven University of Technology', 'Eindhoven University of Technology']","['General']","Stoyanova, Y., Ghandi, S., & Tavakol, M. (2023). Toward Robust Uncertainty Estimation with Random Activation Functions. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15152-15160. https://doi.org/10.1609/aaai.v37i12.26768","Abstract 					Deep neural networks are in the limelight of machine learning with their excellent performance in many data-driven applications. However, they can lead to inaccurate predictions when queried in out-of-distribution data points, which can have detrimental effects especially in sensitive domains, such as healthcare and transportation, where erroneous predictions can be very costly and/or dangerous. Subsequently, quantifying the uncertainty of the output of a neural network is often leveraged to evaluate the confidence of its predictions, and ensemble models have proved to be effective in measuring the uncertainty by utilizing the variance of predictions over a pool of models. In this paper, we propose a novel approach for uncertainty quantification via ensembles, called Random Activation Functions (RAFs) Ensemble, that aims at improving the ensemble diversity toward a more robust estimation, by accommodating each neural network with a different (random) activation function. Extensive empirical study demonstrates that RAFs Ensemble outperforms state-of-the-art ensemble uncertainty quantification methods on both synthetic and real-world datasets in a series of regression tasks.","https://ojs.aaai.org/index.php/AAAI/article/view/26768/26540"
"26769","Improving Robust Fariness via Balance Adversarial Training","['Chunyu Sun', 'Chenye Xu', 'Chengyuan Yao', 'Siyuan Liang', 'Yichao Wu', 'Ding Liang', 'Xianglong Liu', 'Aishan Liu']","['SenseTime Research', 'SenseTime Research', 'SenseTime Research', 'Institute of Information Engineering, Chinese Academy of Sciences', 'SenseTime Research', 'SenseTime Research', 'Zhongguancun Laboratory, Beijing, China;\nInstitute of Dataspace, Hefei, Anhui, China;\nNLSDE, Beihang University, Beijing, China', 'NLSDE, Beihang University, Beijing, China']","['General']","Sun, C., Xu, C., Yao, C., Liang, S., Wu, Y., Liang, D., Liu, X., & Liu, A. (2023). Improving Robust Fariness via Balance Adversarial Training. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15161-15169. https://doi.org/10.1609/aaai.v37i12.26769","Abstract 					Adversarial training (AT) methods are effective against adversarial attacks, yet they introduce severe disparity of accuracy and robustness between different classes, known as the robust fairness problem. Previously proposed Fair Robust Learning (FRL) adaptively reweights different classes to improve fairness. However, the performance of the better-performed classes decreases, leading to a strong performance drop. In this paper, we observed two unfair phenomena during adversarial training: different difficulties in generating adversarial examples from each class (source-class fairness) and disparate target class tendencies when generating adversarial examples (target-class fairness). From the observations, we propose Balance Adversarial Training (BAT) to address the robust fairness problem. Regarding source-class fairness, we adjust the attack strength and difficulties of each class to generate samples near the decision boundary for easier and fairer model learning; considering target-class fairness, by introducing a uniform distribution constraint, we encourage the adversarial example generation process for each class with a fair tendency. Extensive experiments conducted on multiple datasets (CIFAR-10, CIFAR-100, and ImageNette) demonstrate that our BAT can significantly outperform other baselines in mitigating the robust fairness problem (+5-10\% on the worst class accuracy)(Our codes can be found at https://github.com/silvercherry/Improving-Robust-Fairness-via-Balance-Adversarial-Training).","https://ojs.aaai.org/index.php/AAAI/article/view/26769/26541"
"26770","DPAUC: Differentially Private AUC Computation in Federated Learning","['Jiankai Sun', 'Xin Yang', 'Yuanshun Yao', 'Junyuan Xie', 'Di Wu', 'Chong Wang']","['ByteDance Inc.', 'ByteDance Inc.', 'ByteDance Inc.', 'ByteDance Ltd.', 'ByteDance Ltd.', 'Apple Inc.']","['General']","Sun, J., Yang, X., Yao, Y., Xie, J., Wu, D., & Wang, C. (2023). DPAUC: Differentially Private AUC Computation in Federated Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15170-15178. https://doi.org/10.1609/aaai.v37i12.26770","Abstract 					Federated learning (FL) has gained significant attention recently as a privacy-enhancing tool to jointly train a machine learning model by multiple participants.  The prior work on FL has mostly studied how to protect label privacy during model training. However, model evaluation in FL might also lead to the potential leakage of private label information. In this work, we propose an evaluation algorithm that can accurately compute the widely used AUC (area under the curve) metric when using the label differential privacy (DP) in FL. Through extensive experiments, we show our algorithms can compute accurate AUCs compared to the ground truth. The code is available at https://github.com/bytedance/fedlearner/tree/master/example/privacy/DPAUC","https://ojs.aaai.org/index.php/AAAI/article/view/26770/26542"
"26771","Conflicting Interactions among Protection Mechanisms for Machine Learning Models","['Sebastian Szyller', 'N. Asokan']","['Aalto University', 'University of Waterloo\nAalto University']","['General']","Szyller, S., & Asokan, N. (2023). Conflicting Interactions among Protection Mechanisms for Machine Learning Models. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15179-15187. https://doi.org/10.1609/aaai.v37i12.26771","Abstract 					Nowadays, systems based on machine learning (ML) are widely used in different domains. Given their popularity, ML models have become targets for various attacks. As a result, research at the intersection of security/privacy and ML has flourished. Typically such work has focused on individual types of security/privacy concerns and mitigations thereof.  However, in real-life deployments, an ML model will need to be protected against several concerns simultaneously. A protection mechanism optimal for a specific security or privacy concern may interact negatively with mechanisms intended to address other concerns. Despite its practical relevance, the potential for such conflicts has not been studied adequately.  In this work, we first provide a framework for analyzing such conflicting interactions. We then focus on systematically analyzing pairwise interactions between protection mechanisms for one concern, model and data ownership verification, with two other classes of ML protection mechanisms: differentially private training, and robustness against model evasion. We find that several pairwise interactions result in conflicts.  We also explore potential approaches for avoiding such conflicts. First, we study the effect of hyperparameter relaxations, finding that there is no sweet spot balancing the performance of both protection mechanisms. Second, we explore whether modifying one type of protection mechanism (ownership verification) so as to decouple it from factors that may be impacted by a conflicting mechanism (differentially private training or robustness to model evasion) can avoid conflict. We show that this approach can indeed avoid the conflict between ownership verification mechanisms when combined with differentially private training, but has no effect on robustness to model evasion. We conclude by identifying the gaps in the landscape of studying interactions between other types of ML protection mechanisms.","https://ojs.aaai.org/index.php/AAAI/article/view/26771/26543"
"26772","Neural Policy Safety Verification via Predicate Abstraction: CEGAR","['Marcel Vinzent', 'Siddhant Sharma', 'Jöerg Hoffmann']","['Saarland University', 'Indian Institute of Technology Delhi', 'Saarland University\nGerman Research Center for Artificial Intelligence (DFKI)']","['General']","Vinzent, M., Sharma, S., & Hoffmann, J. (2023). Neural Policy Safety Verification via Predicate Abstraction: CEGAR. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15188-15196. https://doi.org/10.1609/aaai.v37i12.26772","Abstract 					Neural networks (NN) are an increasingly important representation of action policies pi. Recent work has extended predicate abstraction to prove safety of such pi, through policy predicate abstraction (PPA) which over-approximates the state space subgraph induced by pi. The advantage of PPA is that reasoning about the NN – calls to SMT solvers – is required only locally, at individual abstract state transitions, in contrast to bounded model checking (BMC) where SMT must reason globally about sequences of NN decisions. Indeed, it has been shown that PPA can outperform a simple BMC implementation. However, the abstractions underlying these results (i.e., the abstraction predicates) were supplied manually. Here we automate this step. We extend counterexample guided abstraction refinement (CEGAR) to PPA. This involves dealing with a new source of spuriousness in abstract unsafe paths, pertaining not to transition behavior but to the decisions of the neural network pi. We introduce two methods tackling this issue based on the states involved, and we show that global SMT calls deciding spuriousness exactly can be avoided. We devise algorithmic enhancements leveraging incremental computation and heuristic search. We show empirically that the resulting verification tool has significant advantages over an encoding into the state-of-the-art model checker nuXmv. In particular, ours is the only approach in our experiments that succeeds in proving policies safe.","https://ojs.aaai.org/index.php/AAAI/article/view/26772/26544"
"26773","Towards Verifying the Geometric Robustness of Large-Scale Neural Networks","['Fu Wang', 'Peipei Xu', 'Wenjie Ruan', 'Xiaowei Huang']","['University of Exeter', 'University of Liverpool', 'University of Exeter', 'Liverpool University']","['General']","Wang, F., Xu, P., Ruan, W., & Huang, X. (2023). Towards Verifying the Geometric Robustness of Large-Scale Neural Networks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15197-15205. https://doi.org/10.1609/aaai.v37i12.26773","Abstract 					Deep neural networks (DNNs) are known to be vulnerable to adversarial geometric transformation. This paper aims to verify the robustness of large-scale DNNs against the combination of multiple geometric transformations with a provable guarantee.  Given a set of transformations (e.g., rotation, scaling, etc.), we develop GeoRobust, a black-box robustness analyser built upon a novel global optimisation strategy, for locating the worst-case combination of transformations that affect and even alter a network's output.  GeoRobust can provide provable guarantees on finding the worst-case combination based on recent advances in Lipschitzian theory. Due to its black-box nature, GeoRobust can be deployed on large-scale DNNs regardless of their architectures, activation functions, and the number of neurons. In practice, GeoRobust can locate the worst-case geometric transformation with high precision for the ResNet50 model on ImageNet in a few seconds on average. We examined 18 ImageNet classifiers, including the ResNet family and vision transformers, and found a positive correlation between the geometric robustness of the networks and the parameter numbers. We also observe that increasing the depth of DNN is more beneficial than increasing its width in terms of improving its geometric robustness. Our tool GeoRobust is available at https://github.com/TrustAI/GeoRobust.","https://ojs.aaai.org/index.php/AAAI/article/view/26773/26545"
"26774","Revisiting Item Promotion in GNN-Based Collaborative Filtering: A Masked Targeted Topological Attack Perspective","['Yongwei Wang', 'Yong Liu', 'Zhiqi Shen']","['Nanyang Technological University', 'Nanyang Technological University', 'Nanyang Technological University']","['General']","Wang, Y., Liu, Y., & Shen, Z. (2023). Revisiting Item Promotion in GNN-Based Collaborative Filtering: A Masked Targeted Topological Attack Perspective. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15206-15214. https://doi.org/10.1609/aaai.v37i12.26774","Abstract 					Graph neural networks (GNN) based collaborative filtering (CF) has attracted increasing attention in e-commerce and financial marketing platforms. However, there still lack efforts to evaluate the robustness of such CF systems in deployment. Fundamentally different from existing attacks, this work revisits the item promotion task and reformulates it from a targeted topological attack perspective for the first time. Specifically, we first develop a targeted attack formulation to maximally increase a target item's popularity. We then leverage gradient-based optimizations to find a solution. However, we observe the gradient estimates often appear noisy due to the discrete nature of a graph, which leads to a degradation of attack ability. To resolve noisy gradient effects, we then propose a masked attack objective that can remarkably enhance the topological attack ability. Furthermore, we design a computationally efficient approach to the proposed attack, thus making it feasible to evaluate large-large CF systems. Experiments on two real-world datasets show the effectiveness of our attack in analyzing the robustness of GNN-based CF more practically.","https://ojs.aaai.org/index.php/AAAI/article/view/26774/26546"
"26775","Robust Average-Reward Markov Decision Processes","['Yue Wang', 'Alvaro Velasquez', 'George Atia', 'Ashley Prater-Bennette', 'Shaofeng Zou']","['University at Buffalo, the State University of New York', 'University of Colorado Boulder', 'University of Central Florida', 'Air Force Research Laboratory', 'University at Buffalo, the State University of New York']","['General']","Wang, Y., Velasquez, A., Atia, G., Prater-Bennette, A., & Zou, S. (2023). Robust Average-Reward Markov Decision Processes. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15215-15223. https://doi.org/10.1609/aaai.v37i12.26775","Abstract 					In robust Markov decision processes (MDPs), the uncertainty in the transition kernel is addressed by finding a policy that optimizes the worst-case performance over an uncertainty set of MDPs. While much of the literature has focused on discounted MDPs, robust average-reward MDPs remain largely unexplored. In this paper, we focus on robust average-reward MDPs, where the goal is to find a policy that optimizes the worst-case average reward over an uncertainty set. We first take an approach that approximates average-reward MDPs using discounted MDPs. We prove that the robust discounted value function converges to the robust average-reward as the discount factor goes to 1, and moreover when it is large, any optimal policy of the robust discounted MDP is also an optimal policy of the robust average-reward. We further design a robust dynamic programming approach, and theoretically characterize its convergence to the optimum. Then, we investigate robust average-reward MDPs directly without using discounted MDPs as an intermediate step. We derive the robust Bellman equation for robust average-reward MDPs, prove that the optimal policy can be derived from its solution, and further design a robust relative value iteration algorithm that provably finds its solution, or equivalently, the optimal robust policy.","https://ojs.aaai.org/index.php/AAAI/article/view/26775/26547"
"26776","Robust Graph Meta-Learning via Manifold Calibration with Proxy Subgraphs","['Zhenzhong Wang', 'Lulu Cao', 'Wanyu Lin', 'Min Jiang', 'Kay Chen Tan']","['The Hong Kong Polytechnic University', 'Xiamen University', 'The Hong Kong Polytechnic University', 'Xiamen University', 'The Hong Kong Polytechnic University']","['General']","Wang, Z., Cao, L., Lin, W., Jiang, M., & Tan, K. C. (2023). Robust Graph Meta-Learning via Manifold Calibration with Proxy Subgraphs. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15224-15232. https://doi.org/10.1609/aaai.v37i12.26776","Abstract 					Graph meta-learning has become a preferable paradigm for graph-based node classification with long-tail distribution, owing to its capability of capturing the intrinsic manifold of support and query nodes. Despite the remarkable success, graph meta-learning suffers from severe performance degradation when training on graph data with structural noise. In this work, we observe that the structural noise may impair the smoothness of the intrinsic manifold supporting the support and query nodes, leading to the poor transferable priori of the meta-learner. To address the issue, we propose a new approach for graph meta-learning that is robust against structural noise, called Proxy subgraph-based Manifold Calibration method (Pro-MC). Concretely, a subgraph generator is designed to generate proxy subgraphs that can calibrate the smoothness of the manifold. The proxy subgraph compromises two types of subgraphs with two biases, thus preventing the manifold from being rugged and straightforward. By doing so, our proposed meta-learner can obtain generalizable and transferable prior knowledge. In addition, we provide a theoretical analysis to illustrate the effectiveness of Pro-MC. Experimental results have demonstrated that our approach can achieve state-of-the-art performance under various structural noises.","https://ojs.aaai.org/index.php/AAAI/article/view/26776/26548"
"26777","HOTCOLD Block: Fooling Thermal Infrared Detectors with a Novel Wearable Design","['Hui Wei', 'Zhixiang Wang', 'Xuemei Jia', 'Yinqiang Zheng', 'Hao Tang', ""Shin'ichi Satoh"", 'Zheng Wang']","['National Engineering Research Center for Multimedia Software, Institute of Artificial Intelligence, School of Computer Science, Wuhan University\nHubei Key Laboratory of Multimedia and Network Communication Engineering', 'The University of Tokyo\nRIISE\nNational Institute of Informatics', 'National Engineering Research Center for Multimedia Software, Institute of Artificial Intelligence, School of Computer Science, Wuhan University\nHubei Key Laboratory of Multimedia and Network Communication Engineering', 'The University of Tokyo', 'CVL, ETH Zurich', 'National Institute of Informatics\nThe University of Tokyo', 'National Engineering Research Center for Multimedia Software, Institute of Artificial Intelligence, School of Computer Science, Wuhan University\nHubei Key Laboratory of Multimedia and Network Communication Engineering']","['General']","Wei, H., Wang, Z., Jia, X., Zheng, Y., Tang, H., Satoh, S., & Wang, Z. (2023). HOTCOLD Block: Fooling Thermal Infrared Detectors with a Novel Wearable Design. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15233-15241. https://doi.org/10.1609/aaai.v37i12.26777","Abstract 					Adversarial attacks on thermal infrared imaging expose the risk of related applications. Estimating the security of these systems is essential for safely deploying them in the real world. In many cases, realizing the attacks in the physical space requires elaborate special perturbations. These solutions are often impractical and attention-grabbing. To address the need for a physically practical and stealthy adversarial attack, we introduce HotCold Block, a novel physical attack for infrared detectors that hide persons utilizing the wearable Warming Paste and Cooling Paste. By attaching these readily available temperature-controlled materials to the body, HotCold Block evades human eyes efficiently. Moreover, unlike existing methods that build adversarial patches with complex texture and structure features, HotCold Block utilizes an SSP-oriented adversarial optimization algorithm that enables attacks with pure color blocks and explores the influence of size, shape, and position on attack performance. Extensive experimental results in both digital and physical environments demonstrate the performance of our proposed HotCold Block. Code is available: https://github.com/weihui1308/HOTCOLDBlock.","https://ojs.aaai.org/index.php/AAAI/article/view/26777/26549"
"26778","Beyond NaN: Resiliency of Optimization Layers in the Face of Infeasibility","['Wai Tuck Wong', 'Sarah Kinsey', 'Ramesha Karunasena', 'Thanh H. Nguyen', 'Arunesh Sinha']","['Singapore Management University', 'University of Oregon', 'Singapore Management University', 'University of Oregon', 'Rutgers University']","['General']","Wong, W. T., Kinsey, S., Karunasena, R., Nguyen, T. H., & Sinha, A. (2023). Beyond NaN: Resiliency of Optimization Layers in the Face of Infeasibility. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15242-15250. https://doi.org/10.1609/aaai.v37i12.26778","Abstract 					Prior work has successfully incorporated optimization layers as the last layer in neural networks for various problems, thereby allowing joint learning and planning in one neural network forward pass. In this work, we identify a weakness in such a set-up where inputs to the optimization layer lead to undefined output of the neural network. Such undefined decision outputs can lead to possible catastrophic outcomes in critical real time applications. We show that an adversary can cause such failures by forcing rank deficiency on the matrix fed to the optimization layer which results in the optimization failing to produce a solution. We provide a defense for the failure cases by controlling the condition number of the input matrix. We study the problem in the settings of synthetic data, Jigsaw Sudoku, and in speed planning for autonomous driving. We show that our proposed defense effectively prevents the framework from failing with undefined output. Finally, we surface a number of edge cases which lead to serious bugs in popular optimization solvers which can be abused as well.","https://ojs.aaai.org/index.php/AAAI/article/view/26778/26550"
"26779","DeepGemini: Verifying Dependency Fairness for Deep Neural Network","['Xuan Xie', 'Fuyuan Zhang', 'Xinwen Hu', 'Lei Ma']","['University of Alberta', 'Kyushu University', 'Hunan Normal University', 'University of Alberta\nKyushu University\nHunan Normal University']","['General']","Xie, X., Zhang, F., Hu, X., & Ma, L. (2023). DeepGemini: Verifying Dependency Fairness for Deep Neural Network. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15251-15259. https://doi.org/10.1609/aaai.v37i12.26779","Abstract 					Deep neural networks (DNNs) have been widely adopted in many decision-making industrial applications. Their fairness issues, i.e., whether there exist unintended biases in the DNN, receive much attention and become critical concerns, which can directly cause negative impacts in our daily life and potentially undermine the fairness of our society, especially with their increasing deployment at an unprecedented speed. Recently, some early attempts have been made to provide fairness assurance of DNNs, such as fairness testing, which aims at finding discriminatory samples empirically, and fairness certification, which develops sound but not complete analysis to certify the fairness of DNNs. Nevertheless, how to formally compute discriminatory samples and fairness scores (i.e., the percentage of fair input space), is still largely uninvestigated. In this paper, we propose DeepGemini, a novel fairness formal analysis technique for DNNs, which contains two key components: discriminatory sample discovery and fairness score computation. To uncover discriminatory samples, we encode the fairness of DNNs as safety properties and search for discriminatory samples by means of state-of-the-art verification techniques for DNNs. This reduction enables us to be the first to formally compute discriminatory samples. To compute the fairness score, we develop counterexample guided fairness analysis, which utilizes four heuristics to efficiently approximate a lower bound of fairness score. Extensive experimental evaluations demonstrate the effectiveness and efficiency of DeepGemini on commonly-used benchmarks, and DeepGemini outperforms state-of-the-art DNN fairness certification approaches in terms of both efficiency and scalability.","https://ojs.aaai.org/index.php/AAAI/article/view/26779/26551"
"26780","Auditing and Robustifying COVID-19 Misinformation Datasets via Anticontent Sampling","['Clay H. Yoo', 'Ashiqur R. KhudaBukhsh']","['Carnegie Mellon University', 'Rochester Institute of Technology']","['General']","Yoo, C. H., & KhudaBukhsh, A. R. (2023). Auditing and Robustifying COVID-19 Misinformation Datasets via Anticontent Sampling. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15260-15268. https://doi.org/10.1609/aaai.v37i12.26780","Abstract 					This paper makes two key contributions. First, it argues that highly specialized rare content classifiers trained on small data typically have limited exposure to the richness and topical diversity of the negative class (dubbed anticontent) as observed in the wild. As a result, these classifiers' strong performance observed on the test set may not translate into real-world settings. In the context of COVID-19 misinformation detection, we conduct an in-the-wild audit of multiple datasets and demonstrate that models trained with several prominently cited recent datasets are vulnerable to anticontent when evaluated in the wild. Second, we present a novel active learning pipeline that requires zero manual annotation and iteratively augments the training data with challenging anticontent, robustifying these classifiers.","https://ojs.aaai.org/index.php/AAAI/article/view/26780/26552"
"26781","User-Oriented Robust Reinforcement Learning","['Haoyi You', 'Beichen Yu', 'Haiming Jin', 'Zhaoxing Yang', 'Jiahui Sun']","['Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University', 'Shanghai Jiao Tong University']","['General']","You, H., Yu, B., Jin, H., Yang, Z., & Sun, J. (2023). User-Oriented Robust Reinforcement Learning. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15269-15277. https://doi.org/10.1609/aaai.v37i12.26781","Abstract 					Recently, improving the robustness of policies across different environments attracts increasing attention in the reinforcement learning (RL) community. Existing robust RL methods mostly aim to achieve the max-min robustness by optimizing the policy’s performance in the worst-case environment. However, in practice, a user that uses an RL policy may have different preferences over its performance across environments. Clearly, the aforementioned max-min robustness is oftentimes too conservative to satisfy user preference. Therefore, in this paper, we integrate user preference into policy learning in robust RL, and propose a novel User-Oriented Robust RL (UOR-RL) framework. Specifically, we define a new User-Oriented Robustness (UOR) metric for RL, which allocates different weights to the environments according to user preference and generalizes the max-min robustness metric. To optimize the UOR metric, we develop two different UOR-RL training algorithms for the scenarios with or without a priori known environment distribution, respectively. Theoretically, we prove that our UOR-RL training algorithms converge to near-optimal policies even with inaccurate or completely no knowledge about the environment distribution. Furthermore, we carry out extensive experimental evaluations in 6 MuJoCo tasks. The experimental results demonstrate that UOR-RL is comparable to the state-of-the-art baselines under the average-case and worst-case performance metrics, and more importantly establishes new state-of-the-art performance under the UOR metric.","https://ojs.aaai.org/index.php/AAAI/article/view/26781/26553"
"26782","Safety Verification of Nonlinear Systems with Bayesian Neural Network Controllers","['Xia Zeng', 'Zhengfeng Yang', 'Li Zhang', 'Xiaochao Tang', 'Zhenbing Zeng', 'Zhiming Liu']","['Southwest University', 'East China Normal University', 'East China Normal University', 'East China Normal University', 'Shanghai University', 'Southwest University']","['General']","Zeng, X., Yang, Z., Zhang, L., Tang, X., Zeng, Z., & Liu, Z. (2023). Safety Verification of Nonlinear Systems with Bayesian Neural Network Controllers. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15278-15286. https://doi.org/10.1609/aaai.v37i12.26782","Abstract 					Bayesian neural networks (BNNs) retain NN structures with a probability distribution placed over their weights. With the introduced uncertainties and redundancies, BNNs are proper choices of robust controllers for safety-critical control systems. This paper considers the problem of verifying the safety of nonlinear closed-loop systems with BNN controllers over unbounded-time horizon. In essence, we compute a safe weight set such that as long as the BNN controller is always applied with weights sampled from the safe weight set, the controlled system is guaranteed to be safe. We propose a novel two-phase method for the safe weight set computation. First, we construct a reference safe control set that constraints the control inputs, through polynomial approximation to the BNN controller followed by polynomial-optimization-based barrier certificate generation. Then, the computation of safe weight set is reduced to a range inclusion problem of the BNN on the system domain w.r.t. the safe control set, which can be solved incrementally and the set of safe weights can be extracted. Compared with the existing method based on invariant learning and mixed-integer linear programming, we could compute safe weight sets with larger radii on a series of linear benchmarks. Moreover, experiments on a series of widely used nonlinear control tasks show that our method can synthesize large safe weight sets with probability measure as high as 95% even for a large-scale system of dimension 7.","https://ojs.aaai.org/index.php/AAAI/article/view/26782/26554"
"26783","Reachability Analysis of Neural Network Control Systems","['Chi Zhang', 'Wenjie Ruan', 'Peipei Xu']","['University of Exeter', 'University of Exeter', 'University of Liverpool']","['General']","Zhang, C., Ruan, W., & Xu, P. (2023). Reachability Analysis of Neural Network Control Systems. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15287-15295. https://doi.org/10.1609/aaai.v37i12.26783","Abstract 					Neural network controllers (NNCs) have shown great promise in autonomous and cyber-physical systems. Despite the various verification approaches for neural networks, the safety analysis of NNCs remains an open problem. Existing verification approaches for neural network control systems (NNCSs) either can only work on a limited type of activation functions, or result in non-trivial over-approximation errors with time evolving. This paper proposes a verification framework for NNCS based on Lipschitzian optimisation, called DeepNNC. We first prove the Lipschitz continuity of closed-loop NNCSs by unrolling and eliminating the loops. We then reveal the working principles of applying Lipschitzian optimisation on NNCS verification and illustrate it by verifying an adaptive cruise control model. Compared to state-of-the-art verification approaches, DeepNNC shows superior performance in terms of efficiency and accuracy over a wide range of NNCs. We also provide a case study to demonstrate the capability of DeepNNC to handle a real-world, practical, and complex system. Our tool DeepNNC is available at https://github.com/TrustAI/DeepNNC.","https://ojs.aaai.org/index.php/AAAI/article/view/26783/26555"
"26784","BIFRNet: A Brain-Inspired Feature Restoration DNN for Partially Occluded Image Recognition","['Jiahong Zhang', 'Lihong Cao', 'Qiuxia Lai', 'Bingyao Li', 'Yunxiao Qin']","['State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China\nNeuroscience and Intelligent Media Institute, Communication University of China, Beijing, China', 'State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China\nNeuroscience and Intelligent Media Institute, Communication University of China, Beijing, China', 'State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China\nNeuroscience and Intelligent Media Institute, Communication University of China, Beijing, China', 'Neuroscience and Intelligent Media Institute, Communication University of China, Beijing, China', 'State Key Laboratory of Media Convergence and Communication, Communication University of China, Beijing, China\nNeuroscience and Intelligent Media Institute, Communication University of China, Beijing, China']","['General']","Zhang, J., Cao, L., Lai, Q., Li, B., & Qin, Y. (2023). BIFRNet: A Brain-Inspired Feature Restoration DNN for Partially Occluded Image Recognition. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15296-15304. https://doi.org/10.1609/aaai.v37i12.26784","Abstract 					The partially occluded image recognition (POIR) problem has been a challenge for artificial intelligence for a long time. A common strategy to handle the POIR problem is using the non-occluded features for classification. Unfortunately, this strategy will lose effectiveness when the image is severely occluded, since the visible parts can only provide limited information. Several studies in neuroscience reveal that feature restoration which fills in the occluded information and is called amodal completion is essential for human brains to recognize partially occluded images. However, feature restoration is commonly ignored by CNNs, which may be the reason why CNNs are ineffective for the POIR problem. Inspired by this, we propose a novel brain-inspired feature restoration network (BIFRNet) to solve the POIR problem. It mimics a ventral visual pathway to extract image features and a dorsal visual pathway to distinguish occluded and visible image regions. In addition, it also uses a knowledge module to store classification prior knowledge and uses a completion module to restore occluded features based on visible features and prior knowledge. Thorough experiments on synthetic and real-world occluded image datasets show that BIFRNet outperforms the existing methods in solving the POIR problem. Especially for severely occluded images, BIRFRNet surpasses other methods by a large margin and is close to the human brain performance. Furthermore, the brain-inspired design makes BIFRNet more interpretable.","https://ojs.aaai.org/index.php/AAAI/article/view/26784/26556"
"26785","Robustness to Spurious Correlations Improves Semantic Out-of-Distribution Detection","['Lily H. Zhang', 'Rajesh Ranganath']","['New York University', 'New York University']","['General']","Zhang, L. H., & Ranganath, R. (2023). Robustness to Spurious Correlations Improves Semantic Out-of-Distribution Detection. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15305-15312. https://doi.org/10.1609/aaai.v37i12.26785","Abstract 					Methods which utilize the outputs or feature representations of predictive models have emerged as promising approaches for out-of-distribution (OOD) detection of image inputs. However, as demonstrated in previous work, these methods struggle to detect OOD inputs that share nuisance values (e.g. background) with in-distribution inputs. The detection of shared-nuisance OOD (SN-OOD) inputs is particularly relevant in real-world applications, as anomalies and in-distribution inputs tend to be captured in the same settings during deployment. In this work, we provide a possible explanation for these failures and propose nuisance-aware OOD detection to address them. Nuisance-aware OOD detection substitutes a classifier trained via Empirical Risk Minimization (ERM) with one that 1. approximates a distribution where the nuisance-label relationship is broken and 2. yields representations that are independent of the nuisance under this distribution, both marginally and conditioned on the label. We can train a classifier to achieve these objectives using Nuisance-Randomized Distillation (NuRD), an algorithm developed for OOD generalization under spurious correlations. Output- and feature-based nuisance-aware OOD detection perform substantially better than their original counterparts, succeeding even when detection based on domain generalization algorithms fails to improve performance.","https://ojs.aaai.org/index.php/AAAI/article/view/26785/26557"
"26786","Evaluating Model-Free Reinforcement Learning toward Safety-Critical Tasks","['Linrui Zhang', 'Qin Zhang', 'Li Shen', 'Bo Yuan', 'Xueqian Wang', 'Dacheng Tao']","['Tsinghua University', 'Tsinghua University', 'JD Explore Academy', 'Qianyuan Institute of Sciences', 'Tsinghua University', 'JD Explore Academy']","['General']","Zhang, L., Zhang, Q., Shen, L., Yuan, B., Wang, X., & Tao, D. (2023). Evaluating Model-Free Reinforcement Learning toward Safety-Critical Tasks. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15313-15321. https://doi.org/10.1609/aaai.v37i12.26786","Abstract 					Safety comes first in many real-world applications involving autonomous agents. Despite a large number of reinforcement learning (RL) methods focusing on safety-critical tasks, there is still a lack of high-quality evaluation of those algorithms that adheres to safety constraints at each decision step under complex and unknown dynamics. In this paper, we revisit prior work in this scope from the perspective of state-wise safe RL and categorize them as projection-based, recovery-based, and optimization-based approaches, respectively.  Furthermore, we propose Unrolling Safety Layer (USL), a joint method that combines safety optimization and safety projection. This novel technique explicitly enforces hard constraints via the deep unrolling architecture and enjoys structural advantages in navigating the trade-off between reward improvement and constraint satisfaction. To facilitate further research in this area,  we reproduce related algorithms in a unified pipeline and incorporate them into SafeRL-Kit, a toolkit that provides off-the-shelf interfaces and evaluation utilities for safety-critical tasks. We then perform a comparative study of the involved algorithms on six benchmarks ranging from robotic control to autonomous driving. The empirical results provide an insight into their applicability and robustness in learning zero-cost-return policies without task-dependent handcrafting. The project page is available at https://sites.google.com/view/saferlkit.","https://ojs.aaai.org/index.php/AAAI/article/view/26786/26558"
"26787","Video-Audio Domain Generalization via Confounder Disentanglement","['Shengyu Zhang', 'Xusheng Feng', 'Wenyan Fan', 'Wenjing Fang', 'Fuli Feng', 'Wei Ji', 'Shuo Li', 'Li Wang', 'Shanshan Zhao', 'Zhou Zhao', 'Tat-Seng Chua', 'Fei Wu']","['Zhejiang University', 'University of Electronic Science and Technology of China', 'Zhejiang University', 'Ant group', 'University of Science and Technology of China', 'National University of Singapore', 'National University of Singapore', 'Ant Group', 'The University of Sydney', 'Zhejiang University', 'National University of Singapore', 'Zhejiang University\nShanghai AI Laboratory']","['General']","Zhang, S., Feng, X., Fan, W., Fang, W., Feng, F., Ji, W., Li, S., Wang, L., Zhao, S., Zhao, Z., Chua, T.-S., & Wu, F. (2023). Video-Audio Domain Generalization via Confounder Disentanglement. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15322-15330. https://doi.org/10.1609/aaai.v37i12.26787","Abstract 					Existing video-audio understanding models are trained and evaluated in an intra-domain setting, facing performance degeneration in real-world applications where multiple domains and distribution shifts naturally exist. The key to video-audio domain generalization (VADG) lies in  alleviating spurious correlations over multi-modal features. To achieve this goal, we resort to causal theory and attribute such correlation to confounders affecting both video-audio features and labels. We propose a DeVADG framework that conducts uni-modal and cross-modal deconfounding through back-door adjustment. DeVADG performs cross-modal disentanglement and obtains fine-grained confounders at both class-level and domain-level using half-sibling regression and unpaired domain transformation, which essentially identifies domain-variant factors and class-shared factors that cause spurious correlations between features and false labels. To promote VADG research, we collect a VADG-Action dataset for video-audio action recognition with over 5,000 video clips across four domains (e.g., cartoon and game) and ten action classes (e.g., cooking and riding). We conduct extensive experiments, i.e., multi-source DG, single-source DG, and qualitative analysis, validating the rationality of our causal analysis and the effectiveness of the DeVADG framework.","https://ojs.aaai.org/index.php/AAAI/article/view/26787/26559"
"26788","Rethinking Safe Control in the Presence of Self-Seeking Humans","['Zixuan Zhang', 'Maitham AL-Sunni', 'Haoming Jing', 'Hirokazu Shirado', 'Yorie Nakahira']","['Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University', 'Carnegie Mellon University']","['General']","Zhang, Z., AL-Sunni, M., Jing, H., Shirado, H., & Nakahira, Y. (2023). Rethinking Safe Control in the Presence of Self-Seeking Humans. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15331-15339. https://doi.org/10.1609/aaai.v37i12.26788","Abstract 					Safe control methods are often designed to behave safely even in worst-case human uncertainties. Such design can cause more aggressive human behaviors that exploit its conservatism and result in greater risk for everyone. However, this issue has not been systematically investigated previously. This paper uses an interaction-based payoff structure from evolutionary game theory to model humans’ short-sighted, self-seeking behaviors. The model captures how prior human-machine interaction experience causes behavioral and strategic changes in humans in the long term. We then show that deterministic worst-case safe control techniques and equilibrium-based stochastic methods can have worse safety and performance trade-offs than a basic method that mediates human strategic changes. This finding suggests an urgent need to fundamentally rethink the safe control framework used in human-technology interaction in pursuit of greater safety for all.","https://ojs.aaai.org/index.php/AAAI/article/view/26788/26560"
"26789","Towards Safe AI: Sandboxing DNNs-Based Controllers in Stochastic Games","['Bingzhuo Zhong', 'Hongpeng Cao', 'Majid Zamani', 'Marco Caccamo']","['Technical University of Munich', 'Technical University of Munich', 'University of Colorado Boulder', 'Technical University of Munich']","['General']","Zhong, B., Cao, H., Zamani, M., & Caccamo, M. (2023). Towards Safe AI: Sandboxing DNNs-Based Controllers in Stochastic Games. Proceedings of the AAAI Conference on Artificial Intelligence, 37(12), 15340-15349. https://doi.org/10.1609/aaai.v37i12.26789","Abstract 					Nowadays, AI-based techniques, such as deep neural networks (DNNs), are widely deployed in autonomous systems for complex mission requirements (e.g., motion planning in robotics). However, DNNs-based controllers are typically very complex, and it is very hard to formally verify their correctness, potentially causing severe risks for safety-critical autonomous systems. In this paper, we propose a construction scheme for a so-called Safe-visor architecture to sandbox DNNs-based controllers. Particularly, we consider the construction under a stochastic game framework to provide a system-level safety guarantee which is robust to noises and disturbances. A supervisor is built to check the control inputs provided by a DNNs-based controller and decide whether to accept them.  Meanwhile, a safety advisor is running in parallel to provide fallback control inputs in case the DNN-based controller is rejected. We demonstrate the proposed approaches on a quadrotor employing an unverified DNNs-based controller.","https://ojs.aaai.org/index.php/AAAI/article/view/26789/26561"
