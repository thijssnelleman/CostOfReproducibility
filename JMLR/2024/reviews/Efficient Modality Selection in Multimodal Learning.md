
## Efficient Modality Selection in Multimodal Learning
Yifei He, Runxiang Cheng, Gargi Balasubramaniam, Yao-Hung Hubert Tsai, Han Zhao
Keywords: 
JMLR/2024/Proceedings/230439 - Efficient Modality Selection in Multimodal Learning.pdf
Project URL: nan

### Implementation
_Given the documentation given by the authors on the method, how much time investment would it be to re-implement the method from scratch?_

[10]

The atuhors do not share their implementation.

### Data
_Given the data description in the documentation, how much effort take to either: Find the same dataset the authors used, or similar datasets and defend the comparability, or acquire one from scratch?_

[2]

(3/3)

The authors use Patch MNIST, PEMS-SF and CMU-MOSI dataset and describe them with detail and citations in 6.1. Statistics given. No direct links.

### Configuration 
_Given the (hyper)parameters, including semantic parameters, of the method: How much effort would it take to acquire the algorithm configurations used for their results, and compare against their budgetary constraints?_

[4]

The hyperparameters are stated in section 6.1.1. Overview or acquisition not given.

### Experimental Procedure
_Given the experimental set-up of the work, how difficult is it to set up a new experiment, similar to those presented in the original work, with the same procedure?_

[1]

The authors use static dataset split and specify them in 6.1. Results are over training loss, Test accuracy and the authors measure it over cross-entropy loss. Full procedure given in 6.1. Patch MNIST results are on the test set. Results are single runs. 

### Expertise
_How much effort would it take to acquire the expertise required to reproduce the work independently relying on the available documentation?_

[7]

Requries expertise on multimodal learning.
