## Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only
Kangjie Chen, Xiaoxuan Lou, Guowen Xu, Jiwei Li, Tianwei Zhang
Keywords: 
ICLR/2023/Proceedings/11656 - Clean-image Backdoor: Attacking Multi-label Models with Poisoned Labels Only.pdf
Project URL: nan

### Implementation
_Given the documentation shared by the authors on a new method, how much effort would it be to re-implement the method from scratch?_

[8]

The authors do not provide their implementation. Overview in figure 2. Pseudo code in the appendix. No technical details, except for a few statements in the appendix.

### Data
_Given the data description in the documentation, how much effort would it take to either: Find the same data set the authors used, or a similar data set and defend the comparability, or acquire one from scratch?_

[3]

(3/3)

The authors use Pascal-VOC 2007, VOC 2012, and MS-COCO and provide citations. Few details are given.

### Configuration 
_Given the (hyper)parameters, including semantic parameters, of the method: How much effort would it take to acquire the algorithm configurations used for obtaining the reported results, and compare them against their computation budget?_

[10]

Not specified.

### Experimental Procedure
_Given the setup of experiments reported in the work, how difficult is it to set up a new experiment with the same procedure, similar to those presented in the original work?_

[3]

The authors measure ean Average Precision (mAP), average precision (CP), recall (CR), F1 (CF1), and the average overall precision (OP), recall (OR) and F1 (OF1). Results are on the test set, split not specified. Results are single run.

### Expertise
_How much effort would it take to acquire the expertise required to reproduce the work independently relying solely on the available documentation?_

[5]

-
